- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 15:04:19'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 15:04:19'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Nvidia announces GB200 Blackwell AI chip, launching later this year
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Nvidia 宣布 GB200 Blackwell AI 芯片，将于今年晚些时候推出。
- en: 来源：[https://www.cnbc.com/2024/03/18/nvidia-announces-gb200-blackwell-ai-chip-launching-later-this-year.html](https://www.cnbc.com/2024/03/18/nvidia-announces-gb200-blackwell-ai-chip-launching-later-this-year.html)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.cnbc.com/2024/03/18/nvidia-announces-gb200-blackwell-ai-chip-launching-later-this-year.html](https://www.cnbc.com/2024/03/18/nvidia-announces-gb200-blackwell-ai-chip-launching-later-this-year.html)
- en: Nvidia CEO Jensen Huang delivers a keynote address during the Nvidia GTC Artificial
    Intelligence Conference at SAP Center on March 18, 2024 in San Jose, California.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: Nvidia CEO Jensen Huang 在 2024 年 3 月 18 日于加利福尼亚州圣何塞的 Nvidia GTC 人工智能大会上发表主题演讲。
- en: Justin Sullivan | Getty Images
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: Justin Sullivan | Getty Images
- en: '[Nvidia](/quotes/NVDA/) on Monday announced a new generation of artificial
    intelligence chips and software for running artificial intelligence models. The
    announcement, made during Nvidia''s developer''s conference in San Jose, comes
    as the chipmaker seeks to solidify its position as the go-to supplier for AI companies.'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Nvidia](/quotes/NVDA/) 在周一宣布了一款新一代人工智能芯片和运行人工智能模型的软件。此项宣布是在 Nvidia 于圣何塞举行的开发者大会上进行的，旨在巩固其作为
    AI 公司首选供应商的地位。'
- en: Nvidia's share price is up five-fold and total sales have more than tripled
    since OpenAI's ChatGPT kicked off the AI boom in late 2022\. Nvidia's high-end
    server GPUs are essential for training and deploying large AI models. Companies
    like [Microsoft](/quotes/MSFT/) and [Meta](/quotes/META/) have spent billions
    of dollars buying the chips.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 自 2022 年底 OpenAI 的 ChatGPT 掀起 AI 热潮以来，Nvidia 的股价猛涨五倍，总销售额也增长了三倍以上。Nvidia 的高端服务器
    GPU 对于训练和部署大型 AI 模型至关重要。像[Microsoft](/quotes/MSFT/)和[Meta](/quotes/META/)这样的公司已经花费数十亿美元购买这些芯片。
- en: The new generation of AI graphics processors is named Blackwell. The first Blackwell
    chip is called the GB200 and will ship later this year. Nvidia is enticing its
    customers with more powerful chips to spur new orders. Companies and software
    makers, for example, are still scrambling to get their hands on the current generation
    of "Hopper" H100s and similar chips.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 新一代 AI 图形处理器命名为 Blackwell。第一款 Blackwell 芯片名为 GB200，将于今年晚些时候发货。Nvidia 通过更强大的芯片来吸引客户，以刺激新订单。例如，公司和软件制造商仍在争相获取当前一代的“Hopper”
    H100 和类似的芯片。
- en: “Hopper is fantastic, but we need bigger GPUs,” Nvidia CEO Jensen Huang said
    on Monday at the company's developer conference in California.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: “霍珀很棒，但我们需要更大的 GPU，”Nvidia CEO Jensen Huang 在周一于公司加利福尼亚州开发者大会上说道。
- en: Nvidia shares fell more than 1% in extended trading on Monday.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: Nvidia 的股价在周一延长交易中下跌超过 1%。
- en: The company also introduced revenue-generating software called NIM that will
    make it easier to deploy AI, giving customers another reason to stick with Nvidia
    chips over [a rising field of competitors](https://www.cnbc.com/2023/12/07/amd-stock-spikes-after-company-launches-ai-chip-to-rival-nvidia.html).
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 公司还推出了名为 NIM 的收入生成软件，将更易于部署 AI，这让客户有更多理由选择 Nvidia 芯片而不是[日益增长的竞争对手](https://www.cnbc.com/2023/12/07/amd-stock-spikes-after-company-launches-ai-chip-to-rival-nvidia.html)。
- en: Nvidia executives say that the company is becoming less of a mercenary chip
    provider and more of a platform provider, like Microsoft or Apple, on which other
    companies can build software.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: Nvidia 的高管们表示，公司正在逐渐从一个雇佣军芯片提供商转变为像 Microsoft 或 Apple 这样的平台提供商，其他公司可以在其上构建软件。
- en: '"Blackwell''s not a chip, it''s the name of a platform," Huang said.'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: '"Blackwell 不仅是一款芯片，更是一个平台的名称，" Huang 表示。'
- en: '"The sellable commercial product was the GPU and the software was all to help
    people use the GPU in different ways," said Nvidia enterprise VP Manuvir Das in
    an interview. "Of course, we still do that. But what''s really changed is, we
    really have a commercial software business now."'
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: '"可销售的商业产品是 GPU，而软件则是帮助人们以不同方式使用 GPU 的一切，" Nvidia 企业副总裁 Manuvir Das 在一次采访中说道。"当然，我们仍然在这样做。但真正改变的是，我们现在真正拥有一个商业软件业务。"'
- en: Das said Nvidia's new software will make it easier to run programs on any of
    Nvidia's GPUs, even older ones that might be better suited for deploying but not
    building AI.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: Das 表示，Nvidia 的新软件将使得在任何 Nvidia GPU 上运行程序变得更加容易，即使是那些可能更适合部署而不是构建 AI 的旧型号。
- en: '"If you''re a developer, you''ve got an interesting model you want people to
    adopt, if you put it in a NIM, we''ll make sure that it''s runnable on all our
    GPUs, so you reach a lot of people," Das said.'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: '"如果你是开发者，你有一个有趣的模型想让人们采用，如果你把它放在 NIM 上，我们会确保它可以在我们所有的 GPU 上运行，这样你就能触及到很多人群，"
    Das 说道。'
- en: Meet Blackwell, the successor to Hopper
  id: totrans-split-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 会见Blackwell，霍珀的继任者
- en: Nvidia's GB200 Grace Blackwell Superchip, with two B200 graphics processors
    and one Arm-based central processor.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: Nvidia的GB200 Grace Blackwell超级芯片，配备两个B200图形处理器和一个基于Arm架构的中央处理器。
- en: Every two years Nvidia updates its GPU architecture, unlocking a big jump in
    performance. Many of the AI models released over the past year were trained on
    the company's Hopper architecture — used by chips such as the H100 — which was
    announced in 2022.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 每两年，Nvidia更新其GPU架构，实现了性能的大幅提升。过去一年发布的许多AI模型是在该公司的霍珀架构上训练的，这些架构被诸如H100之类的芯片所使用，该架构于2022年宣布。
- en: Nvidia says Blackwell-based processors, like the GB200, offer a huge performance
    upgrade for AI companies, with 20 petaflops in AI performance versus 4 petaflops
    for the H100\. The additional processing power will enable AI companies to train
    bigger and more intricate models, Nvidia said.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: Nvidia表示，像GB200这样基于Blackwell的处理器为AI公司提供了巨大的性能升级，AI性能达到20 petaflops，而H100仅为4
    petaflops。Nvidia表示，额外的处理能力将使AI公司能够训练更大更复杂的模型。
- en: The chip includes what Nvidia calls a "transformer engine specifically built
    to run transformers-based AI, one of the core technologies underpinning ChatGPT.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 该芯片包括Nvidia称为“变压器引擎”，专门用于运行基于transformers的AI，这是ChatGPT的核心技术之一。
- en: The Blackwell GPU is large and combines two separately manufactured dies into
    one chip manufactured by [TSMC](/quotes/TSM/). It will also be available as an
    entire server called the GB200 NVLink 2, combining 72 Blackwell GPUs and other
    Nvidia parts designed to train AI models.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: Blackwell GPU非常大，将两个分别制造的芯片整合到一个由[TSMC](/quotes/TSM/)制造的芯片中。它还将作为一个名为GB200 NVLink
    2的整个服务器出售，结合了72个Blackwell GPU和其他Nvidia部件，旨在训练AI模型。
- en: Nvidia CEO Jensen Huang compares the size of the new "Blackwell" chip versus
    the current "Hopper" H100 chip at the company's developer conference, in San Jose,
    California.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: Nvidia首席执行官黄仁勋在公司的开发者大会上，比较了新的“Blackwell”芯片与当前的“Hopper” H100芯片的大小，该大会在加州圣何塞举行。
- en: Nvidia
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: Nvidia
- en: '[Amazon](/quotes/AMZN/), [Google](/quotes/GOOGL/), [Microsoft](/quotes/MSFT/),
    and [Oracle](/quotes/ORCL/) will sell access to the GB200 through cloud services.
    The GB200 pairs two B200 Blackwell GPUs with one Arm-based Grace CPU. Nvidia said
    Amazon Web Services would build a server cluster with 20,000 GB200 chips.'
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊，谷歌，微软和甲骨文将通过云服务销售GB200的访问权限。GB200将两个B200 Blackwell GPU与一个基于Arm架构的Grace CPU配对。Nvidia表示，亚马逊Web服务将建立一个包含20000个GB200芯片的服务器集群。
- en: Nvidia said that the system can deploy a 27-trillion-parameter model. That's
    much larger than even the biggest models, such as GPT-4, which reportedly has
    1.7 trillion parameters. Many artificial intelligence researchers believe bigger
    models with more parameters and data [could unlock new capabilities](https://openai.com/research/ai-and-compute).
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: Nvidia表示，该系统可以部署一个27000亿参数的模型。这比如GPT-4这样的最大模型要大得多，据报道GPT-4有1.7万亿个参数。许多人工智能研究人员认为，具有更多参数和数据的更大模型可能会开启新的能力[链接](https://openai.com/research/ai-and-compute)。
- en: Nvidia didn't provide a cost for the new GB200 or the systems it's used in.
    Nvidia's Hopper-based H100 costs between $25,000 and $40,000 per chip, with whole
    systems that cost as much as $200,000, according to analyst estimates.
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: Nvidia没有为新的GB200或其所用系统提供成本。根据分析师的估计，Nvidia基于Hopper的H100芯片的成本在每个芯片25,000至40,000美元之间，整个系统的成本高达200,000美元。
- en: Nvidia will also sell B200 graphics processors as part of a complete system
    that takes up an entire server rack.
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: Nvidia还将B200图形处理器作为整个服务器机架的一部分进行销售。
- en: Nvidia inference microservice
  id: totrans-split-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Nvidia推理微服务
- en: Nvidia also announced it's adding a new product named NIM, which stands for
    Nvidia Inference Microservice, to its Nvidia enterprise software subscription.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: Nvidia还宣布将其Nvidia企业软件订阅中增加一个名为NIM的新产品，全称为Nvidia推理微服务。
- en: NIM makes it easier to use older Nvidia GPUs for inference, or the process of
    running AI software, and will allow companies to continue to use the hundreds
    of millions of Nvidia GPUs they already own. Inference requires less computational
    power than the initial training of a new AI model. NIM enables companies that
    want to run their own AI models, instead of buying access to AI results as a service
    from companies like OpenAI.
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: NIM使得使用旧版Nvidia GPU进行推理（或者运行AI软件的过程）变得更加容易，并将允许公司继续使用他们已经拥有的数亿个Nvidia GPU。推理所需的计算能力比新AI模型的初始训练少。NIM使得那些希望运行自己AI模型的公司能够实现这一目标，而不是通过像OpenAI这样的公司购买AI结果的访问权限。
- en: The strategy is to get customers who buy Nvidia-based servers to sign up for
    Nvidia enterprise, which costs $4,500 per GPU per year for a license.
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 策略是让购买基于 Nvidia 的服务器的客户注册 Nvidia 企业服务，每 GPU 每年需支付 4,500 美元的许可费用。
- en: Nvidia will work with AI companies like Microsoft or Hugging Face to ensure
    their AI models are tuned to run on all compatible Nvidia chips. Then, using a
    NIM, developers can efficiently run the model on their own servers or cloud-based
    Nvidia servers without a lengthy configuration process.
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: Nvidia 将与微软或 Hugging Face 等 AI 公司合作，确保它们的 AI 模型经过调整，可以在所有兼容的 Nvidia 芯片上运行。然后，开发者可以使用
    NIM，在他们自己的服务器或基于云的 Nvidia 服务器上高效地运行模型，而不需要漫长的配置过程。
- en: '"In my code, where I was calling into OpenAI, I will replace one line of code
    to point it to this NIM that I got from Nvidia instead," Das said.'
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: '"在我的代码中，我原本调用 OpenAI 的地方，我只需要替换一行代码，让它指向我从 Nvidia 获得的这个 NIM，" Das 说道。'
- en: Nvidia says the software will also help AI run on GPU-equipped laptops, instead
    of on servers in the cloud.
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: Nvidia 表示，该软件还将帮助 AI 在配备 GPU 的笔记本电脑上运行，而不是在云服务器上运行。
