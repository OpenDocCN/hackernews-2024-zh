- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 14:41:22'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-27 14:41:22
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Social learning: Collaborative learning with large language models'
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[社会学习：与大型语言模型的协作学习](https://arxiv.org/pdf/2312.11441.pdf)'
- en: 来源：[https://blog.research.google/2024/03/social-learning-collaborative-learning.html?m=1](https://blog.research.google/2024/03/social-learning-collaborative-learning.html?m=1)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://blog.research.google/2024/03/social-learning-collaborative-learning.html?m=1](https://blog.research.google/2024/03/social-learning-collaborative-learning.html?m=1)
- en: Large language models (LLMs) have significantly improved the state of the art
    for solving tasks specified using natural language, often reaching performance
    close to that of people. As these models increasingly enable assistive agents,
    it could be beneficial for them to learn effectively from each other, much like
    people do in social settings, which would allow LLM-based agents to improve each
    other’s performance.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）显著提高了使用自然语言解决指定任务的现有技术水平，通常达到接近人类的表现。随着这些模型越来越多地启用辅助代理，让它们像人类在社会环境中一样有效地相互学习可能是有益的，这将使基于LLM的代理能够改进彼此的性能。
- en: To discuss the learning processes of humans, Bandura and Walters [described](https://books.google.ch/books/about/Social_Learning_Theory.html?id=IXvuAAAAMAAJ&redir_esc=y)
    the concept of *social learning* in 1977, outlining different models of observational
    learning used by people. One common method of learning from others is through
    a *verbal instruction* (e.g., from a teacher) that describes how to engage in
    a particular behavior. Alternatively, learning can happen through a *live model*
    by mimicking a live example of the behavior.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论人类学习过程时，班杜拉和沃尔特斯于1977年[描述了](https://books.google.ch/books/about/Social_Learning_Theory.html?id=IXvuAAAAMAAJ&redir_esc=y)社会学习的概念，概述了人们使用的观察学习不同模型。从他人学习的一种常见方法是通过*口头指导*（例如来自教师的指导），描述如何进行特定行为。另一种方式是通过*实时模型*，模仿行为的现场示范来学习。
- en: 'Given the success of LLMs mimicking human communication, in our paper “[Social
    Learning: Towards Collaborative Learning with Large Language Models](https://arxiv.org/pdf/2312.11441.pdf)”,
    we investigate whether LLMs are able to learn from each other using social learning.
    To this end, we outline a framework for social learning in which LLMs share knowledge
    with each other in a privacy-aware manner using natural language. We evaluate
    the effectiveness of our framework on various datasets, and propose quantitative
    methods that measure privacy in this setting. In contrast to previous approaches
    to collaborative learning, such as common [federated learning](https://blog.research.google/2017/04/federated-learning-collaborative.html)
    approaches that often rely on gradients, in our framework, agents teach each other
    purely using natural language.'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于LLM（大型语言模型）在模仿人类交流方面取得的成功，在我们的论文“[社会学习：走向与大型语言模型的协作学习](https://arxiv.org/pdf/2312.11441.pdf)”中，我们调查了LLM是否能够通过社会学习互相学习。为此，我们提出了一个隐私意识的社会学习框架，其中LLM以自然语言的方式分享知识。我们评估了我们框架在各种数据集上的有效性，并提出了衡量这一设置中隐私的定量方法。与以往的协作学习方法（例如常见的[联邦学习](https://blog.research.google/2017/04/federated-learning-collaborative.html)方法通常依赖于梯度）相比，在我们的框架中，代理通过纯粹使用自然语言相互教导。
