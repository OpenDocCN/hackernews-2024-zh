- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 15:01:28'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 15:01:28'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Why is shuffle support needed?. An Analysis of Shuffle Execution Plan | by MatrixOrigin
    | Medium
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么需要 shuffle 支持？洗牌执行计划分析 | MatrixOrigin | Medium
- en: 来源：[https://medium.com/@matrixorigin-database/why-is-shuffle-support-needed-5df13e8edaf2](https://medium.com/@matrixorigin-database/why-is-shuffle-support-needed-5df13e8edaf2)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://medium.com/@matrixorigin-database/why-is-shuffle-support-needed-5df13e8edaf2](https://medium.com/@matrixorigin-database/why-is-shuffle-support-needed-5df13e8edaf2)
- en: Why is shuffle support needed?
  id: totrans-split-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么需要 shuffle 支持？
- en: An Analysis of Shuffle Execution Plan
  id: totrans-split-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 洗牌执行计划分析
- en: The basic principle of the shuffle algorithm is to bucket the input data, where
    each bucket’s data can be processed independently and output results. This reduces
    the size of the hash table when aggregating data.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 洗牌算法的基本原理是将输入数据分桶，每个桶的数据可以独立处理并输出结果。这样做可以在聚合数据时减小哈希表的大小。
- en: 'Taking the group operator as an example, there are two implementation methods:
    sort group and hash group.'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 以分组操作符为例，有两种实现方法：sort group 和 hash group。
- en: In hash group, with multiple concurrent operations, each operation hashes the
    input data and processes it in a hash table. All hash tables need to be merged
    together to obtain the final result. This method is called merge group.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在 hash group 中，通过多个并发操作，每个操作对输入数据进行哈希并在哈希表中处理。所有哈希表都需要合并在一起才能获得最终结果。这种方法称为 merge
    group。
- en: Another method is to first shuffle and distribute the data, where each concurrent
    operation receives and processes different data, and directly outputs the results,
    without needing to merge the hash tables together. This method is called shuffle
    group.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是首先洗牌和分发数据，每个并发操作接收和处理不同的数据，并直接输出结果，而无需将哈希表合并在一起。这种方法称为 shuffle group。
- en: '**Why is shuffle support needed? The main reasons are as follows.**'
  id: totrans-split-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**为什么需要 shuffle 支持？主要原因如下。**'
- en: '**Solving the problem of memory allocation failure due to large hash tables:**
    Taking merge group as an example, since all data need to be merged together, if
    the cardinality of the final merged hash table is too large, the required memory
    allocation will be very large, leading to memory allocation failure. Exceeding
    the memory limit of a single CN (compute node) and not considering the spill scenario
    can also cause out-of-memory (OOM) errors. Meanwhile, shuffle can split a large
    hash table into multiple smaller hash tables for processing.'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**解决因大型哈希表导致的内存分配失败问题：** 以 merge group 为例，由于所有数据需要合并在一起，如果最终合并的哈希表的基数过大，所需的内存分配将非常大，导致内存分配失败。超出单个
    CN（计算节点）的内存限制并且不考虑溢出情况还可能导致内存不足（OOM）错误。与此同时，shuffle 可以将一个大型哈希表分割成多个较小的哈希表进行处理。'
- en: '**Enhancing the horizontal scalability of compute nodes:** Still taking merge
    group as an example, since all data need to be merged together, processing is
    done in single concurrency on a single CN. If the hash table has a large cardinality,
    this step becomes slow and a bottleneck, and adding more CNs cannot speed up such
    queries. Shuffle group does not have this single-point bottleneck.'
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**增强计算节点的水平可伸缩性：** 仍以 merge group 为例，由于所有数据需要合并在一起，处理在单个 CN 上的单一并发。如果哈希表的基数很大，此步骤将变慢且成为瓶颈，并且增加更多的
    CN 也无法加速这样的查询。shuffle group 不具有这种单点瓶颈。'
- en: '**Improving performance:** When hash tables are too large, random access to
    the hash table leads to a very high probability of cache misses, and cache misses
    significantly reduce performance. By using shuffle to split the hash table into
    multiple smaller hash tables for processing, the cache hit rate for random access
    to each small hash table is greatly increased, thereby improving overall performance.'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**提高性能：** 当哈希表过大时，对哈希表的随机访问会导致非常高的缓存未命中率，而缓存未命中显著降低性能。通过使用 shuffle 将哈希表分割成多个较小的哈希表进行处理，可以大大提高对每个小哈希表的随机访问缓存命中率，从而提高整体性能。'
- en: 'Part2: Shuffle Implementation Principle'
  id: totrans-split-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Part2: Shuffle Implementation Principle'
- en: Shuffle buckets data, and the number of buckets is dynamically determined by
    the number of CNs and CPU cores in the runtime environment during pipeline compilation.
    For example, if the current tenant’s environment has 3 CNs, each with 10 cores,
    the shuffle operator will automatically calculate the number of buckets as 30.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 洗牌将数据分桶，桶的数量在流水线编译期间根据运行时环境中的 CNs 和 CPU 核心数动态确定。例如，如果当前租户的环境有 3 个 CN，每个 CN 有
    10 个核心，洗牌操作符将自动计算桶的数量为 30。
- en: 'There are two bucketing algorithms for shuffle: range shuffle and hash shuffle.'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: shuffle 有两种分桶算法：range shuffle 和 hash shuffle。
- en: Hash shuffle directly obtains the bucket number of the data through a hash function.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 哈希 shuffle 直接通过哈希函数获取数据的桶编号。
- en: Range shuffle requires the optimizer to provide a bucketing strategy during
    the compilation stage.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: Range shuffle 要求优化器在编译阶段提供分桶策略。
- en: For uniformly distributed data, the bucketing strategy is relatively simple.
    For example, take the tpch1T, lineitem table as an example. The range of l_orderkey
    is from 1 to 6 billion, and it is evenly distributed. The strategy for shuffling
    this column is to evenly distribute it based on the minimum and maximum values,
    with 100 million to 200 million going to bucket 1, 200 million to 400 million
    to bucket 2, and so on.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 对于均匀分布的数据，分桶策略相对简单。例如，以 tpch1T 的 lineitem 表为例，l_orderkey 的范围是从 1 到 60 亿，且均匀分布。对这一列进行
    shuffle 的策略是基于最小值和最大值均匀分布，如 1 亿到 2 亿进入桶 1，2 亿到 4 亿进入桶 2，依此类推。
- en: For non-uniformly distributed data, the processing algorithm is more complex
    and will be detailed later.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于非均匀分布的数据，处理算法会更加复杂，稍后将详细介绍。
- en: During the compilation stage, MO’s optimizer decides whether to use range shuffle
    or hash shuffle, usually prioritizing range shuffle. If, for some reason, range
    shuffle cannot be used, hash shuffle will be used to ensure the uniformity of
    bucket distribution.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在编译阶段，MO 的优化器决定是否使用 range shuffle 或者 hash shuffle，通常优先选择 range shuffle。如果由于某些原因无法使用
    range shuffle，则会使用 hash shuffle 来确保桶分布的均匀性。
- en: '**In the MO Pipeline, there are two operators corresponding to the shuffle
    algorithm: shuffle and dispatch.**'
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**在 MO 管道中，有两个与 shuffle 算法对应的运算符：shuffle 和 dispatch。**'
- en: '**The function of the shuffle operator is to bucket the input data** and output
    the data after bucketing.'
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**shuffle 运算符的功能是对输入数据进行分桶**，并输出分桶后的数据。'
- en: For example, input a batch (MO is a columnar storage database, and the operator
    processes data in batches as the basic unit), the batch contains 8192 rows of
    data, valued from 1, 2, 3 … up to 8192\. If it needs to be split into two buckets,
    a possible bucketing result is to put 1–4096 into a new batch, and 4097–8192 into
    another new batch, and then send these two new batches out.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，输入一个批次（MO 是列存储数据库，运算符将数据批次作为基本单位处理），批次包含 8192 行数据，值从 1 到 8192。如果需要将其分成两个桶，可能的分桶结果是将
    1 到 4096 放入一个新批次，4097 到 8192 放入另一个新批次，然后发送这两个新批次出去。
- en: Due to the possibility of very high concurrency, the data in each bucket may
    be sparse after bucketing, so direct output is not suitable. Therefore, the shuffle
    operator needs to maintain an internal memory pool to store the bucketed data
    and send it out when a certain amount is accumulated. Or, when the shuffle operator
    has read all the input data, it needs to send out all the data internally.
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 由于可能存在非常高的并发性，每个桶中的数据在分桶后可能非常稀疏，因此直接输出是不适合的。因此，shuffle 运算符需要维护一个内部内存池，用于存储分桶后的数据，并在积累到一定量时发送出去。或者，在
    shuffle 运算符读取完所有输入数据后，需要将所有数据内部发送出去。
- en: In the pipeline, most operators have one batch input corresponding to one batch
    output, but the shuffle operator does not work this way. Due to the internal memory
    pool, shuffle may have no output for a while, or it may continuously output multiple
    batches. The strategy of the memory pool has a significant impact on the performance
    of the shuffle operator.
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在流水线中，大多数运算符的一个批次输入对应一个批次输出，但是 shuffle 运算符不是这样工作的。由于内部内存池的存在，shuffle 可能有一段时间没有输出，或者可能连续输出多个批次。内存池的策略对
    shuffle 运算符的性能有重大影响。
- en: '**The dispatch operator is responsible for sending the data bucketed** by shuffle
    to a specified location. The shuffle operator sets a field named shuffleIDX in
    the batch, and the dispatch operator reads this field and sends the batch to the
    destination according to a specified strategy. It is important to note that the
    shuffleIDX field does not participate in the serialization and deserialization
    of the batch, so there must not be cross-CN network transmission between the shuffle
    and dispatch operators, otherwise, it will cause errors.'
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**调度运算符负责将经过 shuffle 分桶的数据发送到指定位置**。shuffle 运算符在批处理中设置一个名为 shuffleIDX 的字段，调度运算符读取此字段，并根据指定的策略将批次发送到目的地。需要注意的是
    shuffleIDX 字段不参与批次的序列化和反序列化过程，因此 shuffle 和 dispatch 运算符之间不应该跨 CN 网络传输，否则会导致错误。'
- en: The dispatch operator has three strategies for sending data. The first strategy
    is used in the vast majority of cases, while the latter two strategies are used
    in hybrid shuffle, which will be introduced later.
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: dispatch 运算符有三种发送数据的策略。第一种策略在绝大多数情况下使用，而后两种策略用于稍后引入的混合 shuffle 中。
- en: 1\. Directly find the unique corresponding destination based on shuffleIDX (which
    may be in a local CN or a remote CN) and send it there. There may be cross-CN
    network transmission.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 根据 shuffleIDX 直接找到唯一对应的目的地（可能在本地 CN 或远程 CN），并发送数据。可能会跨 CN 进行网络传输。
- en: 2\. Based on shuffleIDX, find the corresponding destination in the current CN
    and send it there. In this case, only a local copy is sent, and there will be
    no cross-CN network transmission.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 根据 shuffleIDX，在当前 CN 中找到相应的目的地并发送数据。在这种情况下，只会发送本地副本，不会跨 CN 进行网络传输。
- en: 3\. Based on shuffleIDX, find the corresponding destination for each CN and
    send it there. In this case, a copy is sent to every CN, and there will definitely
    be cross-CN network transmission.
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 根据 shuffleIDX，为每个 CN 找到相应的目的地并发送数据。在这种情况下，每个 CN 都会收到一份副本，肯定会跨 CN 进行网络传输。
- en: '**Currently, MO supports enabling shuffle for four operators: load, scan, group,
    and join.** However, in theory, any operator is agnostic to shuffle, and MO will
    support enabling the shuffle algorithm for more operators in the future.'
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**目前，MO 支持为四种操作符启用 shuffle：load、scan、group 和 join。** 然而，理论上，任何操作符都可以与 shuffle
    无关，MO 将来会支持更多操作符的 shuffle 算法启用。'
- en: Load Operator
  id: totrans-split-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载运算符
- en: The Load operator partially reuses the distribution logic of shuffle to ensure
    that data written to S3 can retain its original order in the case of multiple
    concurrent reads and writes.
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: Load 运算符部分重用 shuffle 的分发逻辑，以确保写入 S3 的数据在多个并发读写时保持其原始顺序。
- en: Scan Operator
  id: totrans-split-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: scan 运算符
- en: The shuffle for the scan operator is done during the pipeline compilation stage,
    distributing all blocks that need to be read across multiple CNs. The shuffle
    here is done by block, before the actual block data reading stage. If it’s hash
    shuffle, it hashes the block name. If it’s range shuffle, it takes the mid-value
    of the min max in the block zonemap for range calculation.
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: scan 运算符的 shuffle 在管道编译阶段完成，将需要读取的所有块分布到多个 CN 中。这里的 shuffle 是按块进行的，在实际块数据读取阶段之前完成。如果是哈希
    shuffle，则对块名称进行哈希处理。如果是范围 shuffle，则取块 zonemap 中最小最大值的中间值进行范围计算。
- en: Group Operator
  id: totrans-split-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: group 运算符
- en: The shuffle for the group operator statically expands the group operator into
    multiple pipelines during pipeline compilation, shuffling the block data actually
    read by the scan operator, theoretically on a per-row basis. Each pipeline receives
    the data outputted by the shuffle. At this point, the group operator does not
    need to merge groups, as each separate pipeline can directly output data to the
    next pipeline.
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: group 运算符的 shuffle 在管道编译期间静态地将 group 运算符展开为多个管道，对 scan 运算符实际读取的块数据进行洗牌，理论上是按行进行的。每个管道接收
    shuffle 输出的数据。此时，group 运算符不需要合并组，因为每个独立的管道可以直接将数据输出给下一个管道。
- en: Join Operator
  id: totrans-split-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 连接运算符
- en: The shuffle for the join operator also statically expands the join operator
    into multiple pipelines during the pipeline compilation. The input of a join is
    divided into the probe and build sides, and the same shuffle algorithm is used
    for the input data on both sides to ensure that the same data is distributed to
    the same bucket. Each join operator can also directly output the join result without
    needing to merge.
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
  zh: join 运算符的 shuffle 在管道编译期间也静态地将 join 运算符展开为多个管道。join 的输入被分为探测和构建两侧，并且使用相同的 shuffle
    算法来处理两侧的输入数据，以确保相同的数据分布到同一个桶中。每个 join 运算符也可以直接输出 join 结果，无需合并。
- en: To check if a statement’s execution plan has shuffle enabled, you can use the
    explain statement to see if the execution plan contains the shuffle keyword.
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查语句的执行计划是否启用了 shuffle，可以使用 explain 语句查看执行计划中是否包含 shuffle 关键字。
- en: For example, in tpch q4, you can see the lineitem table join the orders table,
    with the join type being right semi, lineitem as the probe table, and orders as
    the build table. Shuffle join is enabled, and a range shuffle is performed on
    the l_orderkey column of the lineitem table. Since the same shuffle algorithm
    is used for joining the two tables, a shuffle will also be performed on the o_orderkey
    column of the orders table.
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在tpch q4中，您可以看到lineitem表与orders表进行了连接，连接类型为右半连接，lineitem作为探测表，orders作为构建表。启用了Shuffle连接，并对lineitem表的l_orderkey列执行了范围Shuffle。由于连接两个表使用了相同的Shuffle算法，因此也将对orders表的o_orderkey列执行Shuffle。
- en: '[PRE0]'
  id: totrans-split-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
