- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 15:03:27'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 15:03:27'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Things I Don't Know About AI - by Elad Gil - Elad Blog
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我不了解的关于AI的事情 - 由Elad Gil - Elad Blog
- en: 来源：[https://blog.eladgil.com/p/things-i-dont-know-about-ai](https://blog.eladgil.com/p/things-i-dont-know-about-ai)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://blog.eladgil.com/p/things-i-dont-know-about-ai](https://blog.eladgil.com/p/things-i-dont-know-about-ai)
- en: In most markets, the more time passes the clearer things become. In generative
    AI (“AI”), it has been the opposite. The more time passes, the less I think I
    actually understand.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数市场中，随着时间的推移，事物变得更加清晰。在生成式人工智能（AI）领域，情况正好相反。时间越长，我觉得自己理解的东西就越少。
- en: For each level of the AI stack, I have open questions. I list these out below
    to stimulate dialog and feedback.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 对于AI堆栈的每个层级，我都有一些问题。我在下面列出这些问题，以促进对话和反馈。
- en: There are in some sense two types of LLMs - frontier models - at the cutting
    edge of performance (think GPT-4 vs other models until recently), and everything
    else. [In 2021 I wrote that I thought the frontier models](https://blog.eladgil.com/p/ai-platforms-markets-and-open-source)
    market would collapse over time into an oligopoly market due to the scale of capital
    needed. In parallel, non-frontier models would more commodity / pricing driven
    and have a stronger opensource presence (note this was pre-Llama and pre-Mistral
    launches).
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 从某种意义上说，有两种类型的LLMs - 前沿模型 - 在性能的最前沿（比如GPT-4与其他模型相比直到最近），以及其他所有模型。[2021年我曾写道，我认为前沿模型市场会随着资本规模的增长而逐渐崩溃，进入寡头市场。与此同时，非前沿模型可能更加商品化/价格驱动，并且具有更强的开源存在（请注意，这是Llama和Mistral推出之前的情况）。
- en: 'Things seem to be evolving towards the above:'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 事情似乎在朝着上述方向发展：
- en: Frontier LLMs are likely to be an oligopoly market. Current contenders include
    closed source models like OpenAI, Google, Anthropic, and perhaps Grok/X.ai, and
    Llama (Meta) and Mistral on the open source side. This list may of course change
    in the coming year or two. Frontier models keep getting more and more expensive
    to train, while commodity models drop in price each year as performance goes up
    (for example, it is probably ~5X cheaper to train GPT-3.5 equivalent now than
    2 years ago)
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 前沿LLMs可能会形成寡头市场。当前的竞争者包括像OpenAI、Google、Anthropic，以及也许还有Grok/X.ai、以及开源方面的Llama（Meta）和Mistral。这份名单在未来一两年可能会有所变化。前沿模型的训练成本不断上升，而商品化模型的价格每年都在下降，因为性能不断提升（例如，现在训练一个相当于GPT-3.5的模型大约比两年前便宜了约5倍）。
- en: As model scale has gotten larger, funding increasingly has been primarily coming
    from the cloud providers / big tech. For example, Microsoft invested $10B+ in
    OpenAI, while Anthropic raised $7B between Amazon and Google. NVIDIA is also a
    big investor in foundation model companies of many types. The venture funding
    for these companies in contrast is a tiny drop in the ocean in comparison. As
    frontier model training booms in cost, the emerging funders are largely concentrated
    amongst big tech companies (typically with strong incentives to fund the area
    for their own revenue - ie cloud providers or NVIDIA), or nation states wanting
    to back local champions (see eg [UAE and Falcon](https://falconllm.tii.ae/)).
    This is impacting the market and driving selection of potential winners early.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型规模的扩大，资金主要来源于云服务提供商/大科技公司。例如，微软对OpenAI的投资超过了10亿美元，而Anthropic则从亚马逊和谷歌处筹集了70亿美元。NVIDIA也是多种类型基础模型公司的重要投资者。与此相比，这些公司的风险投资在整体资金中仅占极小比例。随着前沿模型训练成本的激增，新兴的资助方主要集中在大科技公司（通常有强烈的动机，出于自身收入的考虑，资助该领域，例如云服务提供商或NVIDIA），或者是希望支持本地冠军的国家（例如阿联酋和Falcon）。这正在影响市场，并在早期推动潜在赢家的选择。
- en: It is important to note that the scale of investments being made by these cloud
    providers is dwarfed by actual cloud revenue. For example, Azure from Microsoft
    generates $25B in revenue a quarter. The ~$10B OpenAI investment by Microsoft
    is roughly 6 weeks of Azure revenue. AI is having a big impact on Azure revenue
    revently. [Indeed Azure grew 6 percentage points](https://www.wsj.com/business/earnings/microsoft-msft-q2-earnings-report-2024-57743658)
    in Q2 2024 from AI - which would put it at an annualized increase of $5-6B (or
    50% of its investment in OpenAI! Per year!). Obviously revenue is not net income
    but this is striking nonetheless, and suggests the big clouds have an economic
    reason to fund more large scale models over time.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，这些云提供商的投资规模远远超过了实际的云收入。例如，微软的Azure每个季度的收入为$25B。微软对OpenAI的约$10B投资大约相当于Azure收入的6周。AI最近对Azure收入产生了重大影响。[确实，Azure在2024年第二季度增长了6个百分点](https://www.wsj.com/business/earnings/microsoft-msft-q2-earnings-report-2024-57743658)，其中AI占据了一半（年增加$5-6B的计算）的投资在OpenAI!每年！）。显然，收入并非净收入，但仍然令人印象深刻，并表明大型云端有经济理由随着时间推移资助更多大规模模型。
- en: In parallel, Meta has done outstanding work with Llama models and recently announced
    [$20B compute budget](https://www.pcmag.com/news/zuckerbergs-meta-is-spending-billions-to-buy-350000-nvidia-h100-gpus),
    in part to fund massive model training. I [posited 18 months ago that an open
    source sponsor for AI models](https://blog.eladgil.com/p/ai-platforms-markets-and-open-source)
    should emerge, but assumed it would be Amazon or NVIDIA with a lower chance of
    it being Meta. (Zuckerberg & Yann Lecunn have been visionary here).
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，Meta在Llama模型方面做出了杰出的工作，并最近宣布了[$20B的计算预算](https://www.pcmag.com/news/zuckerbergs-meta-is-spending-billions-to-buy-350000-nvidia-h100-gpus)，部分用于资助大规模模型训练。我[18个月前提出过一个开源的AI模型赞助商](https://blog.eladgil.com/p/ai-platforms-markets-and-open-source)，但假设会是亚马逊或NVIDIA，而Meta的可能性较低（扎克伯格和Yann
    Lecunn在这里表现得很有远见）。
- en: '**Are cloud providers king-making a handful of players at the frontier and
    locking in the oligopoly market via the sheer scale of compute/capital they provide?**
    When do cloud providers stop funding new LLM foundation companies versus continuing
    to fund existing? Cloud providers are easily the biggest funders of foundation
    models, not venture capitalists. Given they are constrained in M&A due to FTC
    actions, and the revenue that comes from cloud usage, it is rational for them
    to do so. This may lead / has led to some distortion of market dynamics. How does
    this impact the long term economics and market structure for LLMs? Does this mean
    we will see the end of new frontier LLM companies soon due to a lack of enough
    capital and talent for new entrants? Or do they keep funding large models hoping
    some will convert on their clouds to revenue?'
  id: totrans-split-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**云提供商是否正在通过提供的计算/资本规模，王者制造一小部分先锋，并通过奥利哥多形市场？** 云提供商何时停止资助新的LLM基金会公司而继续资助现有的公司？云提供商很容易成为基础模型的最大资助者，而非风险投资家。考虑到它们由于FTC的行动而在并购方面受到限制，并且来自云使用的收入，这样做是合理的。这可能导致/已经导致市场动态的某些扭曲。这对LLM的长期经济学和市场结构有何影响？这是否意味着由于新参与者缺乏足够的资本和人才，我们很快将看到新的先锋LLM公司的终结？或者它们继续资助大型模型，希望其中一些会在他们的云端转化为收入？'
- en: '**Does OSS models flip some of the economics in AI from foundation models to
    clouds? Does Meta continue to fund OS models? If so, does eg Llama-N catch up
    to the very frontier?** A fully open source model performing at the very frontier
    of AI has the potential to flip a subportion the economic share of AI infra from
    LLMs towards cloud and inference providers and decreases revenue away from the
    other LLM foundation model companies. Again, this is likely an oligopoly market
    with no singular winner (barring AGI), but has implications on how to think about
    the relative importance of cloud and infrastructure companies in this market (and
    of course both can be very important!).'
  id: totrans-split-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开源软件模型是否会改变AI经济学中基础模型向云的部分经济份额？Meta是否会继续资助开源模型？如果是这样，例如Llama-N是否会赶上最前沿？**
    在AI的最前沿表现出色的全面开源模型有潜力将AI基础设施的经济份额从LLM转向云和推断提供商，并减少了其他LLM基金会模型公司的收入。再次强调，这很可能是一个没有单一赢家的奥利哥多市场，但这对于如何思考市场中云和基础设施公司的相对重要性有着重要意义（当然，两者都可能非常重要！）。'
- en: '**How do we think about speed and price vs performance for models?** One could
    imagine extremely slow incredibly performant models may be quite valuable if compared
    to normal human speed to do things. The latest largest [Gemini models](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/)
    seem to be heading in this direction with large 1 million+ token [context windows
    a la Magic](https://magic.dev/blog/ltm-1), which announced a 5 million token window
    in June 2023\. Large context windows and depth of understanding can really change
    how we think about AI uses and engineering. On the other side of the spectrum,
    Mistral has shown the value of small, fast and cheap to inference performant models.
    The 2x2 below suggests a potential segmentation of where models will matter most.'
  id: totrans-split-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**关于模型的速度、价格和性能如何思考？** 如果将极其缓慢但性能卓越的模型与正常人类速度进行比较，可以想象它们可能会非常有价值。最新的最大规模[Gemini
    模型](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/)似乎正在朝着这个方向发展，具有超过100万令牌的大[上下文窗口，如
    Magic](https://magic.dev/blog/ltm-1)，在2023年6月宣布了一个500万令牌的窗口。大型的上下文窗口和深入的理解可以真正改变我们对AI使用和工程的看法。在光谱的另一端，Mistral展示了小型、快速且性能优异的模型的价值。以下的2x2表格显示了模型最为关键的潜在分割点。'
- en: '**Do governments back (or direct their purchasing to) regional AI champions?**  **Will
    national governments differentially spend on local models a la Boeing vs Airbus
    in aerospace? Do governments want to support models that reflect their local values,
    languages, etc?** Besides cloud providers and global big tech (think also e.g.
    Alibaba, Rakuten etc) the other big sources of potential capital are countries.
    There are now great model companies in Europe (e.g. Mistral), Japan, India, UAE,
    China and other countries. If so, there may be a few multi-billion AI foundation
    model regional companies created just off of government revenue.'
  id: totrans-split-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**政府是否支持（或指导他们的采购向）地区AI冠军？** 国家政府是否会不同程度地支持本地模型，类似于航空航天业中的波音与空客？政府是否希望支持体现其本地价值观、语言等的模型？除了云服务提供商和全球大科技公司（还包括如阿里巴巴、乐天等），潜在资本的另一大来源是国家。现在欧洲（例如Mistral）、日本、印度、阿联酋、中国和其他国家都有出色的模型公司。如果是这样，可能会有几家凭借政府收入创建的数十亿美元的多国AI基础模型公司。'
- en: '**What happens in China?** One could anticipate Chinese LLMs to be backed by
    Tencent, Alibaba, Xiaomi, ByteDance and others investing in big ways into local
    LLMs companies. China’s government has long used regulatory and literal firewalls
    to prevent competition from non-Chinese companies and to build local, government
    supported and censored champions. One interesting thing to note is the trend of
    Chinese OSS models. Qwen from Alibaba for example has moved higher on the broader
    [LMSYS leaderboards](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard).'
  id: totrans-split-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**中国会发生什么？** 可以预见，中国的LLM可能会得到腾讯、阿里巴巴、小米、字节跳动等公司大笔投资支持。中国政府长期以来利用法规和文字防火墙阻止非中国公司的竞争，并建立本地、政府支持和审查的冠军企业。值得注意的一点是中国开源软件模型的趋势。例如，阿里巴巴的Qwen在更广泛的[LMSYS排行榜](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)上有所提升。'
- en: '**What happens with X.ai?** Seems like a wild card.'
  id: totrans-split-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**X.ai 会发生什么？** 看起来像一个不确定因素。'
- en: '**How good does Google get?** Google has the compute, scale, talent to make
    amazing things and is organized and moving fast. Google was always the worlds
    first AI-first company. Seems like a wild card.'
  id: totrans-split-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**谷歌有多强？** 谷歌拥有计算能力、规模和人才，可以创造惊人的东西，并且组织有序、行动迅速。谷歌一直是世界上第一家以人工智能为先的公司。似乎是一个不确定因素。'
- en: There are a few types of infrastructure companies with very different uses.
    For example, [Braintrust](https://www.braintrustdata.com/) provides eval, prompt
    playgrounds, logging and proxies to help companies move from “vibe based” analysis
    of AI to data driven. [Scale.ai](http://scale.ai) and others play a key role in
    data labeling, fine tuning, and other areas. A number of these have open but less
    existential questions (for example how much of RLHF turns into RLAIF).
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种类型的基础设施公司，它们具有非常不同的用途。例如，[Braintrust](https://www.braintrustdata.com/) 提供评估、提示平台、日志记录和代理，以帮助公司从“基于感觉”的AI分析过渡到数据驱动。[Scale.ai](http://scale.ai)
    和其他公司在数据标记、精细调整和其他领域发挥关键作用。其中一些问题已经开放，但并非生死攸关（例如RLHF有多少会转变成RLAIF）。
- en: The biggest uncertainties and questions in AI infra have to do with the AI Cloud
    Stack and how it evolves. It seems like there are very different needs between
    startups and enterprises for AI cloud services. For startups, the new cloud providers
    and tooling (think Anyscale, Baseten, Modal, Replicate, Together, etc) seem to
    be taking a useful path resulting in fast adoption and revenue growth.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: AI基础设施中最大的不确定性和问题与AI云堆栈及其如何演变有关。初创公司和企业对AI云服务的需求似乎有很大不同。对于初创公司来说，新的云提供商和工具（如Anyscale、Baseten、Modal、Replicate、Together等）似乎正在走一条有用的路径，导致快速采用和收入增长。
- en: 'For enterprises, who tend to have specialized needs, there are some open questions.
    For example:'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对于倾向于具有专业需求的企业，有一些未解的问题。例如：
- en: '**Does the current AI cloud companies need to build an on-premise/BYOC/VPN
    version of their offerings for larger enterprises?** It seems like enterprises
    will optimize for (a) using their existing cloud marketplace credits which they
    already have budget for, to buy services (b) will be hesitant to round trip out
    from where their webapp / data is hosted (ie AWS, Azure, GCP) due to latency &
    performance and (c) will care about security, compliance (FedRAMP, HIPAA etc).
    The short term startup market for AI cloud may differ from long term enterprise
    needs.'
  id: totrans-split-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**当前的AI云公司是否需要为大企业构建本地/BYOC/VPN版本的产品？** 看起来企业将优化（a）使用他们已经预算的现有云市场积分来购买服务（b）由于延迟和性能问题，可能不愿从其Web应用程序/数据托管的位置出发（即AWS、Azure、GCP）往返转移，（c）关心安全性、合规性（如FedRAMP、HIPAA等）。短期内AI云的初创市场可能与长期企业需求不同。'
- en: '**How much of AI cloud adoption is due to constrained GPU / GPU arb?** In the
    absence of GPU on the main cloud providers companies are scrambling to find sufficient
    GPU for their needs, accelerating adoption of new startups with their own GPU
    clouds. One potential strategy NVIDIA could be doing is preferentially allocating
    GPU to these new providers to decrease bargaining power of hyperscalers and to
    fragment the market, as well as to accelerate the industry via startups. **When
    does the GPU bottleneck end and how does that impact new AI cloud providers?**
    It seems like an end to GPU shortages on the main clouds would be negative for
    companies whose only business is GPU cloud, while those with more tools and services
    should have an easier transition if this were to happen.'
  id: totrans-split-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AI云采用有多少是由于GPU / GPU arb的限制？** 在主要云提供商缺少GPU的情况下，公司正在竭力寻找足够的GPU来满足其需求，加速了拥有自己GPU云的新创企业的采用。
    NVIDIA可能正在采取的一个潜在策略是优先分配GPU给这些新提供商，以减少超大规模云服务供应商的议价能力，并通过新创企业加速行业的碎片化。**GPU瓶颈何时结束，这如何影响新的AI云提供商？**
    如果主要云上的GPU短缺结束，那些唯一依赖于GPU云的公司可能会受到负面影响，而那些拥有更多工具和服务的公司在这种情况下应该会更容易过渡。'
- en: '**How do new AI ASICS like [Groq](https://groq.com/) impact AI clouds?**'
  id: totrans-split-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**新的AI ASICS（例如[Groq](https://groq.com/)）会如何影响AI云？**'
- en: '**What else gets consolidated into AI clouds?** Do they cross sell embeddings
    & RAG? Continuous updates? Fine tuning? Other services? How does that impact data
    labelers or others with overlapping offerings? What gets consolidated directly
    into model providers vs via the clouds?'
  id: totrans-split-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AI云还将整合什么？** 它们是否会跨卖嵌入和RAG？连续更新？精细调整？其他服务？这如何影响数据标注者或其他具有重叠提供的人？直接整合到模型提供者中的内容与通过云服务提供的内容有何不同？'
- en: '**Which companies in the AI cloud will pursue which business model?**'
  id: totrans-split-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AI云中的哪些公司将采用哪种商业模式？**'
- en: It is important to note there are really 2 market segments in the AI cloud world
    (a) startups (b) mid-market and enterprise. It seems likely that “GPU only” business
    model default works with the startup segment(who have fewer cloud needs), but
    for large enterprises adoption may be more driven by GPU cloud constraints on
    major platforms. **Do companies providing developer tooling, API endpoints, and/or
    specialized hardware, or other aspects morph into two other analogous models -
    (a) “Snowflake/Databricks for AI” model or (b) “Cloudflare for AI”? If so, which
    ones adopt which model?**
  id: totrans-split-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要注意AI云世界中确实存在两个市场细分（a）初创公司（b）中市场和企业。看起来“仅GPU”业务模式默认适用于初创公司（其云需求较少），但对于大企业而言，GPU云平台上的限制可能更多地驱动了其采用。**提供开发者工具、API端点和/或专用硬件或其他方面的公司，是否会演变成两种其他类似的模式
    - (a) “AI的Snowflake/Databricks”模型或者(b) “AI的Cloudflare”？如果是这样，哪些公司采用了哪种模式？**
- en: '**How big do the new AI clouds become? As large as Heroku, Digital Ocean, Snowflake,
    or AWS? What is the size of outcome and utilization scale for this class of company?**'
  id: totrans-split-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**新的AI云会有多大？像Heroku、Digital Ocean、Snowflake或AWS一样大吗？对于这类公司，产出和利用规模有多大？**'
- en: '**How does the AI stack evolve with very long context window models? How do
    we think about the interplay of context window & prompt engineering, fine tuning,
    RAG, and inference costs?**'
  id: totrans-split-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AI堆栈如何随着非常长的上下文窗口模型发展？我们如何考虑上下文窗口与提示工程、微调、RAG和推理成本的相互作用？**'
- en: '**How does FTC (and other regulator) prevention of M&A impact this market?**
    There are at least a dozen credible companies building AI cloud related products
    and services - too many for all of them to be stand alone. How does one think
    about exits under an administration that is aggressively against tech M&A? Should
    the AI clouds themselves consolidate amongst themselves to consolidate share and
    services offered?'
  id: totrans-split-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FTC（及其他监管机构）如何预防并购对这一市场的影响？目前至少有十几家可靠公司正在开发与AI云相关的产品和服务——这些公司不能都是独立运作的。在一个强烈反对科技并购的政府下，我们如何看待这些公司的退出？AI云本身是否应该在其中进行整合，以整合市场份额和提供的服务？**'
- en: ChatGPT was the starting gun for many AI founders. Prior to ChatGPT (and right
    before that Midjourney and Stable Diffusion) most people in tech were not paying
    close attention to the Transformer/Diffusion model revolution and dislocation
    we are now experiencing.
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT是许多AI创始人的起跑线。在ChatGPT（以及之前的Midjourney和Stable Diffusion）之前，大多数科技人员并未密切关注Transformer/Diffusion模型的革命和我们现在正在经历的分化。
- en: This means that people closest to the model and technology - ie AI researchers
    and infra engineers - were the first people to leave to start new companies based
    on this technology. The people farther away from the core model world - many product
    engineers, designers, and PMs, did not become aware of how important AI is until
    now.
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，最接近模型和技术的人——即AI研究人员和基础架构工程师——是第一批离开以此技术为基础创立新公司的人。而远离核心模型世界的人——许多产品工程师、设计师和产品经理——直到现在才意识到AI的重要性。
- en: ChatGPT launched ~15 months ago. If it takes 9-12 months to decide to quit your
    job, a few months to do it, and a few months to brainstorm an initial idea with
    a cofounder, we should start to see a wave of app builders showing up now / shortly.
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT发布约15个月了。如果决定辞职需要9-12个月的时间，再花几个月去实施，再与联合创始人头脑风暴一个初步想法，我们应该现在/很快就会看到一批应用程序开发者的浪潮涌现。
- en: '**B2B apps. What will be the important companies and markets in the emerging
    wave of B2B apps?**  **Where will incumbents gain value versus startups?** I have
    a long post on this coming shortly.'
  id: totrans-split-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**B2B应用程序。新兴B2B应用程序浪潮中的重要公司和市场将是什么？** **现有公司在哪些领域将获得价值优势？** 我即将发布一篇长文讨论这个问题。'
- en: '**Consumer.** Arguably a number of the earliest AI products are consumer or
    “prosumer” - ie used in both personal and business use cases. Apps like ChatGPT,
    Midjourney, Perplexity and Pika are examples of this. **That said, why are there
    so few consumer builders in the AI ecosystem? Is it purely the time delay mentioned
    above?** It seems like the 2007-2012 social product cohort has aged out. New blood
    is needed to build the next great wave of AI consumer.'
  id: totrans-split-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消费者。** 可以说，最早期的AI产品中有一些是面向消费者或“职业消费者”的——即在个人和业务用例中都有使用。像ChatGPT、Midjourney、Perplexity和Pika等应用程序就是例子。**尽管如此，为什么AI生态系统中的消费者建设者如此之少？这纯粹是上述提到的时间延迟吗？**
    看起来，2007年至2012年社交产品队伍已经老去。我们需要新血液来构建下一个伟大的AI消费者浪潮。'
- en: '**Agents.** Lots and lots of things can happen with agents. **What will be
    strong focused product areas versus startups looking for a use case?**'
  id: totrans-split-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**代理商。** 代理商可能会有很多变化。**哪些将是重点产品领域，而哪些是寻找用例的初创公司？**'
- en: This is one of the most exciting and fast-changing moments in technology in
    my lifetime. It will be fun to see what everyone builds. Looking forward to thoughts
    on the questions above.
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我一生中最激动人心和快速变化的时刻之一。很期待看到大家会构建什么。期待关于上述问题的思考。
- en: Thanks to [Amjad Masad](https://twitter.com/amasad) and [Vipul Prakash](https://twitter.com/vipulved)
    for comments on a draft of this post.
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢[Amjad Masad](https://twitter.com/amasad)和[Vipul Prakash](https://twitter.com/vipulved)在本文草稿中的评论。
- en: '**NOTES**'
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**注**'
- en: '[1] Yes I occasionally read terms of use for fun.'
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[1] 是的，我偶尔会出于兴趣阅读使用条款。'
- en: '**MY BOOK**'
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**我的书**'
- en: You can [order the High Growth Handbook here](https://www.amazon.com/High-Growth-Handbook-Elad-Gil/dp/1732265100/).
    Or [read it online for free](https://growth.eladgil.com/).
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以[在这里订购《高增长手册》](https://www.amazon.com/High-Growth-Handbook-Elad-Gil/dp/1732265100/)。或者[免费在线阅读](https://growth.eladgil.com/)。
- en: '**OTHER POSTS**'
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**其他文章**'
- en: '**Firesides & Podcasts**'
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**炉边谈话与播客**'
- en: '**Markets:**'
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**市场：**'
- en: '**Startup life**'
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**创业生活**'
- en: '**Co-Founders**'
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**联合创始人**'
- en: '**Raising Money**'
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**筹集资金**'
