- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 13:25:11'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 13:25:11'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: On Llama-3 and Dwarkesh Patel's Podcast with Zuckerberg
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于Llama-3和Dwarkesh Patel与扎克伯格的播客
- en: 来源：[https://thezvi.substack.com/p/on-llama-3-and-dwarkesh-patels-podcast](https://thezvi.substack.com/p/on-llama-3-and-dwarkesh-patels-podcast)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://thezvi.substack.com/p/on-llama-3-and-dwarkesh-patels-podcast](https://thezvi.substack.com/p/on-llama-3-and-dwarkesh-patels-podcast)
- en: It was all quiet. Then it wasn’t.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都很平静。然后就不平静了。
- en: '[Note the timestamps on both of these](https://twitter.com/tszzl/status/1781043498801893827).'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[请注意这两个时间戳](https://twitter.com/tszzl/status/1781043498801893827)。'
- en: '[Dwarkesh Patel did a podcast with Mark Zuckerberg](https://www.youtube.com/watch?v=bc6uFV9CJGg&ab_channel=DwarkeshPatel)
    on the 18th. It was timed to coincide with the release of much of Llama-3, very
    much the approach of telling your story directly. Dwarkesh is now the true tech
    media. A meteoric rise, and well earned.'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Dwarkesh Patel和马克·扎克伯格一起做了一个播客](https://www.youtube.com/watch?v=bc6uFV9CJGg&ab_channel=DwarkeshPatel)，时间是18日。这与Llama-3的大部分发布时间相吻合，非常直接地讲述了你的故事的方法。Dwarkesh现在是真正的科技媒体。一个迅猛的崛起，而且当之无愧。'
- en: This is two related posts in one. First I cover the podcast, then I cover Llama-3
    itself.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是两篇相关的帖子。首先我涵盖了播客，然后我涵盖了Llama-3本身。
- en: My notes are edited to incorporate context from later explorations of Llama-3,
    as I judged that the readability benefits exceeded the purity costs.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我的笔记经过编辑，包含了后来对Llama-3的深入探索的背景，我判断可读性的好处超过了纯洁性的代价。
- en: (1:00) They start with Llama 3 and the new L3-powered version of Meta AI. Zuckerberg
    says “With Llama 3, we think now that Meta AI is the most intelligent, freely-available
    assistant that people can use.” If this means ‘free as in speech’ then the statement
    is clearly false. So I presume he means ‘free as in beer.’
  id: totrans-split-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:00) 他们从Llama 3和Meta AI新版本L3开始。扎克伯格说：“通过Llama 3，我们现在认为Meta AI是人们可以使用的最智能、自由的助手。”如果这意味着“言论自由”，那么这种说法显然是错误的。因此，我推测他的意思是“免费如啤酒”。
- en: Is that claim true? Is Meta AI now smarter than GPT-3.5, Claude 2 and Gemini
    Pro 1.0? As I write this it is too soon to tell. Gemini Pro 1.0 and Claude 3 Sonnet
    are slightly ahead of Llama-3 70B on the Arena leaderboard. But it is close. The
    statement seems like a claim one can make within ‘reasonable hype.’ Also, Meta
    integrates Google and Bing for real-time knowledge, so the question there is if
    that process is any good, since most browser use by LLMs is not good.
  id: totrans-split-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这种说法是否属实？Meta AI现在是否比GPT-3.5、Claude 2和Gemini Pro 1.0更智能？在我写这篇文章时，现在还为时过早。Gemini
    Pro 1.0和Claude 3 Sonnet在Arena排行榜上略胜于Llama-3 70B。但这很接近。这种说法似乎可以在“合理的炒作”范围内提出。此外，Meta集成了Google和Bing进行实时知识检索，因此问题在于该过程是否有效，因为大多数LLM的浏览使用情况并不理想。
- en: (1:30) Meta are going in big on their UIs, top of Facebook, Instagram and Messenger.
    That makes sense if they have a good product that is robust, and safe in the mundane
    sense. If it is not, this is going to be at the top of chat lists for teenagers
    automatically, so whoo boy. Even if it is safe, there are enough people who really
    do not like AI that this is probably a whoo boy anyway. Popcorn time.
  id: totrans-split-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:30) Meta在他们的UI上投入了大量资源，包括Facebook、Instagram和Messenger。如果他们有一个好的、稳固的产品，符合日常安全需求，这是有道理的。如果不是，这将自动成为青少年聊天列表的头号。即使它是安全的，也有足够多的人不喜欢AI，所以这可能还是一个问题。爆米花时间。
- en: (1:45) They will have the ability to animate images and it generates high quality
    images as you are typing and updates them in real time as you are typing details.
    I can confirm this feature is cool. He promises multimodality, more ‘multi-linguality’
    and bigger context windows.
  id: totrans-split-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:45) 他们将能够为图像添加动画，并在您输入详细信息时实时生成高质量图像并更新它们。我可以确认这个功能很酷。他承诺多模态、更多“多语言性”和更大的上下文窗口。
- en: (3:00) Now the technical stuff. Llama-3 follows tradition in training models
    in three sizes, here 8b, 70b that released on 4/18, and a 405b that is still training.
    He says 405b is already around 85 MMLU and they expect leading benchmarks. The
    8b Llama-3 is almost as good as the 70b Llama-2.
  id: totrans-split-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3:00) 现在来看技术细节。Llama-3在训练模型方面保持了三种规模的传统，这里有8b、4/18发布的70b以及仍在训练中的405b。他说405b已经接近85
    MMLU，他们期望领先的基准测试结果。8b的Llama-3几乎和70b的Llama-2一样出色。
- en: (5:15) What went wrong earlier for Meta and how did they fix it? He highlights
    Reels, with its push to recommend ‘unconnected content,’ meaning things you did
    not ask for, and not having enough compute for that. They were behind. So they
    ordered double the GPUs that needed. They didn’t realize the type of model they
    would want to train.
  id: totrans-split-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (5:15) Meta 早期出了什么问题，他们是如何解决的？他强调了 Reels，通过推荐‘不相关内容’，意味着你没有要求的东西，并且没有足够的计算力来实现。他们落后了。因此，他们订购了双倍于所需的
    GPU。他们没有意识到他们想要训练的模型类型。
- en: (7:30) Back in 2006, what would Zuck have sold for when he turned down $1 billion?
    He says he realized if he sold he’d just build another similar company, so why
    sell? It wasn’t about the number, he wasn’t in position to evaluate the number.
    And I think that is actually wise there. You can realize that you do not want
    to accept any offer someone would actually make.
  id: totrans-split-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (7:30) 2006 年，如果扎克当时拒绝了 10 亿美元的收购，他会因此得到什么？他说他意识到如果卖掉了，他只会再建立一个类似的公司，那为什么要卖？这不是关于数字的问题，他不在评估数字的位置上。我认为这实际上是明智的。你可以意识到你不想接受任何人实际可能提出的报价。
- en: (9:15) When did making AGI become a key priority? Zuck points out Facebook AI
    Research (FAIR) is 10 years old as a research group. Over that time it has become
    clear you need AGI, he says, to support all their other products. He notes that
    training models on coding generalizes and helps their performance elsewhere, and
    that was a top focus for Llama-3\.
  id: totrans-split-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (9:15) 什么时候使 AGI 成为一个关键优先事项？扎克指出 Facebook AI Research (FAIR) 成立已有 10 年作为一个研究组。他说，在这段时间里，他们明白了需要
    AGI 来支持他们的其他所有产品。他指出，在编码上训练模型是通用化的，并且有助于在其他地方提高性能，这是 Llama-3 的重点关注。
- en: So Meta needs to solve AGI because if they don’t ‘their products will be lame.’
    It seems increasingly likely, as we will see in several ways, that Zuck does not
    actually believe in ‘real’ AGI. By ‘AGI’ he means somewhat more capable AI.
  id: totrans-split-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，Meta 需要解决 AGI，因为如果他们不这样做，‘他们的产品将会变得无聊’。从几个方面看，似乎越来越可能，扎克实际上并不相信‘真正的’AGI。对于‘AGI’，他的意思是稍微更有能力的
    AI。
- en: (13:40) What will the Llama that makes cool products be able to do? Replace
    the engineers at Meta? Zuck tries to dodge, says we’re not ‘replacing’ people
    as much as making them more productive, hopefully 10x or more, says there is no
    one threshold for human intelligence, AGI isn’t one thing. He is focused on different
    modalities, especially 3D and emotional understanding, in addition to the usual
    things like memory and reasoning.
  id: totrans-split-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (13:40) 制造出了酷炫产品的拉马能做什么？取代 Meta 的工程师？扎克试图回避，称我们并非‘替换’人类，而是让他们更加高效，希望提高 10 倍或更多，表示人类智能没有一个统一的门槛，AGI
    也不是一个单一的事物。他专注于不同的模态，特别是 3D 和情感理解，除了常规的记忆和推理等方面。
- en: (16:00) What will we use all our data for? Zuck says AI will be in everything,
    and there will be a Meta general assistant product that does complicated tasks.
    He wants to let creators own an AI and train it how they want to ‘engage their
    community.’ But then he admits these are only consumer use cases and it will change
    everything in the economy.
  id: totrans-split-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (16:00) 我们将如何利用所有的数据？扎克表示 AI 将无处不在，将有一个 Meta 的通用助手产品来执行复杂任务。他希望让创作者拥有一个 AI 并按照他们想要的方式进行训练，以‘参与他们的社区’。但随后他承认这些仅仅是消费者使用案例，它将改变整个经济格局。
- en: (18:25) When do we get the good agents? Zuck says we do not know. It depends
    on the scaffolding. He wants to progressively move more of that into the model
    to make them better agents on their own so this stops being ‘brittle and non-general.’
    It has much better tool use, you do not need to hand code. This Is Fine.
  id: totrans-split-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (18:25) 我们何时得到优秀的代理人？扎克表示我们不知道。这取决于脚手架。他希望逐步将更多的内容移入模型，使它们自己成为更好的代理人，从而避免‘脆弱和非通用’的情况。它有更好的工具使用，不需要手动编码。这很好。
- en: (22:20) What community fine tune is most personally exciting? Zuck says he doesn’t
    know, it surprises you, if he knew he’d build it himself.
  id: totrans-split-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (22:20) 哪种社区微调最让你个人兴奋？扎克表示他不知道，这让你感到惊讶，如果他知道的话，他会亲自构建。
- en: This doesn’t match my model of this, where you want to specialize, some things
    are left to others, which seems doubly true here with open model weights. He mentions
    that 8b is too big for many use cases, we should try to build a 1b or smaller
    model too.
  id: totrans-split-24
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这与我对这一模型的理解不符，你希望专业化，某些事情留给其他人，这在开放模型权重方面显然是双重真理。他提到 80 亿对于许多使用案例来说太大了，我们应该尝试构建一个
    10 亿或更小的模型。
- en: Also he mentions that they do a ton of inference because they have a ton of
    customers, so that dominates their compute usage over time. It makes sense for
    them to do what for others would be overtraining, also training more seemed to
    keep paying dividends for a long time.
  id: totrans-split-25
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他还提到，他们进行了大量的推断，因为他们有大量的客户，所以这主导了他们的计算使用情况。这对他们来说是有意义的，为其他人来说可能是过度训练，此外，长期来看，进行更多的训练似乎继续产生回报。
- en: I would presume the other big labs will be in similar positions going forward.
  id: totrans-split-26
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我认为其他大型实验室在未来也会处于类似的位置。
- en: (26:00) How much better will Llama-4 get? How will models improve? Zuck says
    (correctly) this is one of the great questions, on one knows, how long does an
    exponential curve keep going? He says probably long enough that the infrastructure
    is worth investing in, and a lot of companies are investing a lot.
  id: totrans-split-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (26:00) Llama-4 将会变得更好多少？模型将如何改进？Zuck 说（正确地），这是一个重要的问题之一，没有人知道，指数曲线会持续多久？他说，可能足够长，以至于基础设施值得投资，许多公司正在大力投资。
- en: (28:00) He thinks energy constraints will soon bind, not chips. No one has built
    a gigawatt single training cluster yet. And that is slower because energy gets
    permitted at the speed of government and then has to be physically built. One
    does not simply get a bunch of energy, compute and data together.
  id: totrans-split-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (28:00) 他认为能源限制很快会成为约束，而不是芯片。到目前为止，还没有人建造过一台千兆瓦级的单一训练集群。这也更慢，因为能源的批准速度是政府的速度，然后必须在物理上建造。不能简单地将一大堆能源、计算和数据放在一起。
- en: If concentrations of energy generation are the true bottleneck, then anyone
    who says ‘government has no means to control this’ or ‘government cannot control
    this without being totalitarian’ would be very wrong, this is a very easy thing
    to spot, isolate and supervise. Indeed, we almost ‘get it for free’ given we are
    already massively over restricting energy generation and oversee industrial consumption.
  id: totrans-split-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果能源生成的集中是真正的瓶颈，那么任何说‘政府没有手段控制这个’或‘政府无法在不成为极权主义的情况下控制这个’的人都是错的，这是一个非常容易发现、隔离和监管的事情。事实上，我们几乎‘免费获得’了，因为我们已经大量限制了能源生成并监督工业消耗。
- en: (30:00) What would Meta do with 10x more money? More energy, which would allow
    bigger clusters, but true bottleneck is time. Right now data center energy tops
    out at something like 50mw-150mw. But 300mw-1gw, that’s new, that’s a meaningful
    nuclear power plant. It will happen but not next year. Dwarkesh mentions Amazon’s
    950mw facility, Zuck says he is unsure about that.
  id: totrans-split-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (30:00) 要是 Meta 有了 10 倍的资金会怎么做呢？更多的能量，这将允许更大的集群，但真正的瓶颈是时间。目前数据中心的能量顶峰大约是 50mw-150mw。但
    300mw-1gw，那是新的，那是一个有意义的核电站。这将会发生，但不是明年。Dwarkesh 提到了亚马逊的 950mw 设施，Zuck 表示对此并不确定。
- en: (31:40) What about distributed computing? Zuck says it is unknown how much of
    that is feasible, and suggests that a lot of training in future might be inference
    to generate synthetic data.
  id: totrans-split-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (31:40) 分布式计算怎么样？Zuck 说目前还不清楚多少是可行的，并建议未来很多训练可能是推断来生成合成数据。
- en: (32:25) If that’s what this is about, could this work for Llama-3? Could you
    use these models to get data for these models to get smarter? De facto one might
    say ‘RSI Real Soon Now (RSI RSN)?’ Zuck says ‘there are going to be dynamics like
    that’ but there are natural limits on model architecture. He points out there
    is nothing like Llama-3 400B currently in open source, that will change things
    a lot, but says it can only go so far. That all makes sense, at some point you
    have to restart the architecture, but that does not fully rule out the scenario.
  id: totrans-split-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (32:25) 如果这就是问题所在，Llama-3 能行吗？你可以用这些模型获取数据，让这些模型变得更智能吗？实际上，你可以说‘RSI Real Soon
    Now (RSI RSN)’吗？Zuck 说‘肯定会有类似的动态’，但模型架构有自然限制。他指出，在开源中目前没有像 Llama-3 400B 这样的东西，这将大幅改变情况，但他说只能走到这一步。这一切都是有道理的，到某个时候你必须重新启动架构，但这并不能完全排除这种情况。
- en: (34:15) Big picture, what’s up with AI for the next decade? How big a deal is
    it? Zuck says pretty fundamental, like the creation of computing, going from not
    having computers to having computers. You’ll get ‘all these new apps’ and it will
    ‘let people do what they want a lot more.’
  id: totrans-split-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (34:15) 大局观，未来十年 AI 会怎样？这有多重要？Zuck 表示非常根本，就像计算机的创造一样，从没有计算机到有计算机。你会得到‘所有这些新应用程序’，它将‘让人们更多地做他们想做的事情’。
- en: He notices it is very hard to reason about how this goes.
  id: totrans-split-34
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他注意到，理解这个问题非常困难。
- en: He strongly expects physical constraints to prevent fast takeoff, or even ‘slow
    takeoff,’ expecting it to be decades to fully get there.
  id: totrans-split-35
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他强烈预计物理约束将阻止快速起飞，甚至是‘缓慢起飞’，预计需要几十年才能完全实现。
- en: Notice again his expectations here are very much within the mundane range.
  id: totrans-split-36
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次注意，他在这里的期望非常在世俗范围内。
- en: That could be the central crux here. If he thinks that nothing we build can
    get around the physical constraints for decades, then that has a lot of implications.
  id: totrans-split-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这可能是这里的核心问题。如果他认为我们构建的任何东西在数十年内都无法克服物理约束，那将有很多的影响。
- en: (36:00) Dwarkesh says, but what about on that cosmic, longer-term scale? What
    will the universe look like? Will AI be like humans evolving or harnessing fire?
    Zuck says that is tricky. He says that people have come to grips throughout history
    with noticing that humanity is not unique in various ways but is still super special.
    He notices that intelligence is not clearly fundamentally connected to life, it
    is distinct from consciousness and agency. Which he says makes it a super valuable
    tool.
  id: totrans-split-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (36:00) Dwarkesh说，但是在那种宇宙的、长期的尺度上呢？宇宙会是什么样子？AI会像人类一样进化或利用火焰吗？扎克说这很棘手。他说人们通过历史一直在认识到人类在各种方面并不是独特的，但仍然非常特殊。他注意到智能并不明确地与生命基本连接，它与意识和代理是不同的。他说这使得它成为一个超级有价值的工具。
- en: Once again, even in this scenario, there’s that word again. [Tool](https://en.wikipedia.org/wiki/Mark_Zuckerberg).
  id: totrans-split-39
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次，在这种情况下，甚至这种词语再次出现了。[工具](https://en.wikipedia.org/wiki/Mark_Zuckerberg)。
- en: A key problem with this is agency is super useful. There is a reason Meta’s
    central plan is to create an active AI assistant for you that will act are your
    personal agent. Why Meta is striving to bring as much agency capability directly
    into the models, and also building more agency capability on top of that. The
    first thing people are doing and will do, in many contexts, is strive to give
    the AI as much agency as possible. So even if that doesn’t happen ‘on its own’
    it happens anyway. My expectation is that if you wanted to create a non-agent,
    you can probably do that, but you and everyone else with sufficient access to
    the model have to choose to do that.
  id: totrans-split-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个关键问题是代理是非常有用的。Meta的中心计划是为您创建一个积极的AI助手，将充当您的个人代理。这是Meta努力将尽可能多的代理能力直接融入模型的原因，同时在此基础上建立更多的代理能力。在许多情况下，人们正在做的第一件事情，也将要做的，就是努力让AI拥有尽可能多的代理能力。因此，即使这不是‘自然’发生的，它也会发生。我的预期是，如果您想创建一个非代理的模型，您可能可以做到，但是您和其他有足够访问权限的人必须选择这样做。
- en: '(38:00) Zuck: “Which is why I don’t think anyone should be dogmatic about how
    they plan to develop it or what they plan to do. You want to look at it with each
    release. We’re obviously very pro open source, but I haven’t committed to releasing
    every single thing that we do. I’m basically very inclined to think that open
    sourcing is going to be good for the community and also good for us because we’ll
    benefit from the innovations. If at some point however there is some qualitative
    change in what the thing is capable of, and we feel like it’s capable of, and
    we feel it is not responsible to open source it, then we won’t. It’s all very
    difficult to predict.”'
  id: totrans-split-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (38:00) 扎克：“这就是为什么我认为没有人应该对他们计划如何开发它或计划做什么持有教条主义态度。你想要每次发布都看一看。我们显然非常支持开源，但我还没有承诺发布我们所做的每一件事。我基本上倾向于认为开源对社区和我们都将是有益的，因为我们将从创新中受益。然而，如果在某个时刻，有一些质的变化，我们觉得不负责任开源它，那么我们就不会这样做。这一切都很难预测。”
- en: Bravo. Previously we have seen him say they were going to open source AGI. He
    might intend to do that anyway. This continues Zuck trying to have it both ways.
    He says both ‘we will open source everything up to and including AGI’ and also
    ‘we might not’ at different times.
  id: totrans-split-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Bravo。以前我们看到他说他们要开源AGI。他可能打算无论如何都这样做。这继续了扎克试图两者兼得的努力。他在不同的时候说‘我们将开源一切，包括AGI’和‘可能不会’。
- en: The reconciliation is simple. When Zuck says ‘AGI’ he does not mean AGI.
  id: totrans-split-43
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 和解很简单。当扎克说‘AGI’时，他并不是指AGI。
- en: This suggests an obvious compromise. We can all negotiate on what capabilities
    would constitute something too dangerous, and draw a line there, with the line
    drawn in anticipation of what can be built on top of the model that is being considered
    for release, and understanding that all safety work will rapidly be undone and
    so on.
  id: totrans-split-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这表明了一个明显的妥协。我们可以就什么能力构成了某种太危险的东西进行协商，并在那里划定界限，这条线是在考虑要发布的模型之上能够构建的内容的预期之中，并理解所有安全工作将迅速被撤销等等。
- en: We are talking price, and perhaps are not even that far apart.
  id: totrans-split-45
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在讨论价格，也许甚至没有那么大的差距。
- en: I am totally fine with Llama-3 70B being released.
  id: totrans-split-46
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我完全同意Llama-3 70B的发布。
- en: I do notice that open sourcing Llama-3 405B sounds like a national security
    concern, and as I discuss later if I was in NatSec I would be asking how I could
    prevent Meta from releasing the weights for national competitiveness reasons (to
    not supercharge Chinese AI) with a side of catastrophic misuse by non-state actors.
  id: totrans-split-47
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我确实注意到开源Llama-3 405B听起来像是一个国家安全问题，正如我稍后讨论的那样，如果我在国家安全局，我会问自己如何阻止Meta因国家竞争力原因发布权重（以不超级中国AI），以及非国家行为者的灾难性误用。
- en: But I do not expect existential risk from Llama-3\.
  id: totrans-split-48
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 但我不认为Llama-3会存在存在危险。
- en: (38:45) So Dwarkesh asks exactly that. What would it take to give Zuck pause
    on open sourcing the results of a future model?
  id: totrans-split-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （38:45）因此，Dwarkesh确切地问了这个问题。如果未来模型的结果开源，Zuck会有何顾虑？
- en: Zuck says it is hard to measure that in the abstract. He says if you can ‘mitigate
    the negative behaviors’ of a product, then those behaviors are okay.
  id: totrans-split-50
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zuck说，这在抽象中很难衡量。他说，如果你能“减轻产品的负面行为”，那么这些行为就没问题。
- en: The whole point is that you can to some extent do mitigations while you control
    the model (this is still super hard and jailbreaks are universally possible at
    least for now) but if you open source then your mitigations get fully undone.
  id: totrans-split-51
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 整个重点在于，在你控制模型的时候，你可以在一定程度上进行缓解（这仍然非常困难，至少目前普遍可能会出现越狱），但如果开源，你的缓解措施就完全失效了。
- en: Thus I see this as another crux. What does ‘mitigate’ mean here? What is the
    proposal for how that would work? How is this not as fake as Stability.ai saying
    they are taking safety precautions with Stable Diffusion 3, the most generous
    interpretation of which I can imagine is ‘if someone does a fine tune and a new
    checkpoint and adds a LoRa then that is not our fault.’ Which is a distinction
    without a difference.
  id: totrans-split-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，我认为这是另一个关键点。这里的“减轻”意味着什么？对于如何工作的提议是什么？这怎么不像Stability.ai声称他们在使用Stable Diffusion
    3时正在采取安全措施那样虚假呢？我能想象的最慷慨的解释是，“如果有人进行微调并生成一个新的检查点，并添加一个LoRa，那不是我们的错。”这毫无区别。
- en: (40:00) Zuck says it is hard to enumerate all the ways something can be good
    or bad in advance. Very true.
  id: totrans-split-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （40:00）Zuck说，在事前很难列举出某事可能好坏的所有方式。非常正确。
- en: As an aside, the ads here are really cool, pitches for plausibly useful AI products.
    Dwarkesh’s readings are uninspired, but the actual content is actively positive.
  id: totrans-split-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 顺便说一句，这里的广告真的很酷，是对可能有用的AI产品的推广。Dwarkesh的演讲毫无激情，但实际内容积极向上。
- en: '(42:30) Zuck: “Some people who have bad faith are going to try and strip out
    all the bad stuff. So I do think that’s an issue.”'
  id: totrans-split-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （42:30）Zuck说：“一些持恶意意图的人会尝试剥夺所有的坏东西。所以我确实认为这是一个问题。”
- en: Isn’t it more accurate to say that people will for various reasons definitely
    strip out all the protections, as they have consistently always done, barring
    an unknown future innovation?
  id: totrans-split-56
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 难道说，更准确地说，人们出于各种原因肯定会剥夺所有保护措施，因为他们一直都这样做，除非有未知的未来创新？
- en: '(42:45) And here it is, as usual. Zuck: “I do think that a concentration of
    AI in the future has the potential to be as dangerous as it being widespread…
    people ask ‘is it bad for it to be out in the wild and just widely available?’
    I think another version of this is that it’s probably also pretty bad for one
    institution to have an AI that is way more powerful than everyone else’s AI.”
    And so on.'
  id: totrans-split-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （42:45）就像通常一样，这里就是Zuck说的话：“我确实认为，未来人工智能的集中可能与它的普及一样危险……人们问：‘它在野外广泛使用是不好的吗？’我认为另一个版本是说，有一个机构拥有比其他人更强大的人工智能，这也可能是非常糟糕的。”等等。
- en: Something odd happens with his answer here. Up until this point, Zuck has been
    saying a mix of interesting claims, some of which I agree with and some where
    I disagree. I think he is making some key conceptual mistakes, and of course is
    talking his book as one would expect, but it is a unique perspective and voice.
    Now, suddenly, we get the generic open source arguments I’ve heard time and again,
    like they were out of a tape recorder.
  id: totrans-split-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他在这里的回答有点奇怪。直到这一点，Zuck一直在说一些有趣的说法，其中一些我同意，一些我不同意。我认为他在做一些关键概念上的错误，当然，正如预期的那样，他在自说自话，但这是一个独特的视角和声音。现在，突然间，我们听到了我一再听到的通用开源论点，就像是从录音机里播放出来的一样。
- en: And then he says ‘I don’t hear people talking about this much.’ Well, actually,
    I hear people talking about it constantly. It is incessant, in a metaphorically
    very ‘[isolated demand for rigor](https://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/)’
    kind of way, to hear ‘the real danger is concentration of power’ or concentration
    of AI capability. Such people usually say this without justification, and without
    any indication they understand what the ‘not real’ danger is that they are dismissing
    as not real or why they claim that it is not real.
  id: totrans-split-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后他说：“我听不到人们经常谈论这个。”实际上，我经常听到人们在不间断地用隐喻性的“[孤立的严谨需求](https://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/)”这种方式谈论“真正的危险是权力集中”或AI能力的集中。这些人通常没有理由这样说，并且没有任何迹象表明他们理解他们所称为“不真实”的危险为何被视为不真实，或者为何声称它不真实。
- en: (45:00) He says what keeps him up at night is that someone untrustworthy that
    has the super strong AI, that this is ‘potentially a much bigger risk.’ That a
    bad actor who got a hold of a strong AI might cause a lot of mayhem in a world
    where not everyone has a strong AI.
  id: totrans-split-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （45:00）他说让他夜不能寐的是，有人不可信赖地掌握了超强的AI，这“可能是一个更大的风险”。在不是每个人都有超强AI的世界中，一个掌握了强大AI的坏行为者可能引起很多混乱。
- en: This is a bigger concern than AI getting control of the future? Bigger than
    human extinction? Bigger than every actor, however bad, having such access?
  id: totrans-split-61
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这比AI控制未来更大的问题吗？比人类灭绝更大？比每个行动者，无论多坏，都拥有这样的访问权更大吗？
- en: Presumably he means more likely, or some combination of likely and bigger.
  id: totrans-split-62
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他可能的意思是更有可能，或者一些可能性和更大的结合。
- en: So yes, his main concern is that the wrong monkey might get the poisoned banana
    and use it against other monkeys, it is only a tool after all. So instead we have
    to make sure all monkeys have such access?
  id: totrans-split-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所以是的，他的主要关注点是错误的猴子可能会得到有毒的香蕉，并将其用于攻击其他猴子，毕竟它只是一个工具。因此，我们必须确保所有猴子都有这样的访问权吗？
- en: (46:00) It is overall a relatively good version of the generic open source case.
    He at least acknowledges that there are risks on all sides, and certainly I agree
    with that.
  id: totrans-split-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （46:00）总体而言，这是一个相对好的通用开源案例的版本。他至少承认各方面存在风险，我当然同意这一点。
- en: I see no indication from the argument that he actually understands what the
    risks of open sourced highly capable models are, or that he has considered them
    and has a reason why they would not come to pass.
  id: totrans-split-65
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从这个论点中，我看不出他真正理解开源高能力模型的风险，或者他是否已经考虑过它们，并且有理由认为它们不会发生。
- en: His position here appears to be based on ‘this is a tool and will always be
    a tool’ and combining that with an implied presumption about offense-defense balance.
  id: totrans-split-66
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他在这里的立场似乎基于“这是一个工具，将永远是一个工具”，并将其与关于攻防平衡的隐含假设结合在一起。
- en: I certainly have no idea what his plan (or expectation) is to deal with various
    competitive dynamics and incentives, or how he would keep the AIs from being something
    more than tools if they were capable of being more than that.
  id: totrans-split-67
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我确实不知道他处理各种竞争动态和激励措施的计划（或期望），或者如果他们能够超越工具的话，他将如何阻止AI成为更多的东西。
- en: The better version of this case more explicitly denies future AI capabilities.
  id: totrans-split-68
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个案例的更好版本更明确地否认了未来AI的能力。
- en: I could write the standard reply in more detail than I have above, but I get
    tired. I should have a canonical link to use in these spots, but right now I do
    not.
  id: totrans-split-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我可以比上面更详细地写标准回复，但我会感到疲惫。我应该有一个标准链接可以在这些地方使用，但现在我没有。
- en: (46:30) Instead Dwarkesh says it seems plausible that we could get an open source
    AI to become the standard and the best model, and that would be fine, preferable
    even. But he asks, mechanically, how you stop a bad actor in that world.
  id: totrans-split-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （46:30）Dwarkesh说似乎有可能我们能让一个开源AI成为标准和最好的模型，那将是好的，甚至更可取。但他机械地问，如何阻止那个世界中的坏行为者。
- en: He first asks about bioweapons.
  id: totrans-split-71
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他首先问关于生物武器的问题。
- en: Zuck answers that stronger AIs are good cybersecurity defense.
  id: totrans-split-72
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zuck回答说更强大的AI是良好的网络安全防御。
- en: Dwarkesh asks, what if bioweapons aren’t like that.
  id: totrans-split-73
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Dwarkesh问，如果生物武器不是这样的呢。
- en: Zuck agrees he doesn’t know that bioweapons do not work that way and it makes
    sense to worry there. He suggests not training certain knowledge into the model
    (which seems unlikely to me to be that big a barrier, because the world implies
    itself and also you can give it the missing data), but admits if you get a sufficiently
    bad actor (which you will), and you don’t have another AI that can understand
    and balance that (which seems hard under equality), then that ‘could be a risk.’
  id: totrans-split-74
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扎克同意他不知道生物武器不是那样工作的，担心是有道理的。他建议不要将某些知识训练到模型中（对我来说这似乎不太可能成为大的障碍，因为世界本身就暗示着这一点，而且你可以提供缺失的数据），但是承认如果你遇到一个足够坏的行为者（而你会遇到），并且你没有另一个能理解和平衡这一点的人工智能（在平等下这似乎很难），那么“可能会有风险”。
- en: (48:00) What if you for example caught a future Llama lying to you? Zuck says
    right now we see hallucinations and asks how you would tell the difference between
    that and deception, says there is a lot to think about, speaks of ‘long-term theoretical
    risks’ and asks to balance this with ‘real risks that we face today.’ His deception
    worry is ‘people using this to generate misinformation.’
  id: totrans-split-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （48:00）例如，如果你抓到一个未来的羊驼对你撒谎怎么办？扎克说，现在我们看到幻觉，并询问如何区分这一点与欺骗，他说这是一个需要思考的问题，提到了“长期的理论风险”，并要求与“我们今天面临的真实风险”进行平衡。他对欺骗的担忧是“人们利用这一点来生成错误信息”。
- en: (49:15) He says that the way he has beaten misinformation so far is by building
    AI systems that are smarter than the adversarial ones.
  id: totrans-split-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （49:15）他说到目前为止，他击败错误信息的方式是构建比对手更聪明的人工智能系统。
- en: Exactly. Not ‘as smart.’ Smarter.
  id: totrans-split-77
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 没错，不是“同样聪明”。更聪明。
- en: Zuck is playing defense here. He has the harder job.
  id: totrans-split-78
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扎克在这里是在进行防守。他的工作更难。
- en: If those trying to get ‘misinformation’ or other undesired content past Facebook’s
    (or Twitter’s or GMail’s) filters had the same level of sophistication and skill
    and resources as Meta and Google, you would have to whitelist in order to use
    Facebook, Twitter and GMail.
  id: totrans-split-79
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果那些试图通过Facebook（或Twitter或GMail）的过滤器传播“错误信息”或其他不受欢迎内容的人具有与Meta和Google相同水平的复杂性、技能和资源，你将不得不白名单才能使用Facebook、Twitter和GMail。
- en: The key question will be, how much of being smarter will be the base model?
  id: totrans-split-80
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关键问题将是，有多少比普通模型更聪明的部分？
- en: (49:45) Zuck says hate speech is not super adversarial in the sense that people
    are not getting better at being racist.
  id: totrans-split-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （49:45）扎克说，憎恨言论在某种意义上不是特别具有对抗性，因为人们在变得更加种族主义方面没有变得更好。
- en: I think in this sense that is wrong, and they totally are in both senses? Racists
    invent new dog whistles, new symbols, new metaphors, new deniable things. They
    look for what they can and cannot say in different places. They come up with new
    arguments. If you came with the 1970s racism today it would go very badly for
    you, let alone the 1870s or 1670s racism. And then he says that AIs here are getting
    more sophisticated faster than people.
  id: totrans-split-82
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个意义上我认为是错的，他们在两个意义上完全是？种族主义者发明新的口哨声、新的符号、新的隐喻、新的可以否认的事物。他们寻找在不同地方可以和不能说的内容。他们想出新的论点。如果你今天拿着20世纪70年代的种族主义来，结果会很糟糕，更不用说19世纪70年代或17世纪70年代的种族主义。然后他说，这里的AI比人类进步得更快更复杂。
- en: 'What is going to happen is that the racists are going to get their racist AI
    systems ([see: Gab](https://thezvi.substack.com/p/ai-60-oh-the-humanity#%C2%A7another-supposed-system-prompt))
    and start using the AI to generate and select their racist arguments.'
  id: totrans-split-83
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将会发生的是，种族主义者将会获得他们的种族主义人工智能系统（[见：Gab](https://thezvi.substack.com/p/ai-60-oh-the-humanity#%C2%A7another-supposed-system-prompt)），并开始使用AI来生成和选择他们的种族主义论点。
- en: If your AI needs to have high accuracy to both false positives and false negatives,
    then you need a capability advantage over the attack generation mechanism.
  id: totrans-split-84
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你的AI需要在假阳性和假阴性之间具有高准确率，那么你就需要比攻击生成机制具有更强的能力优势。
- en: This is all ‘without loss of generality.’ You can mostly substitute anything
    else you dislike for racism here if you change the dates or other details.
  id: totrans-split-85
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这一切都是“不失一般性”的。如果你改变日期或其他细节，你可以大部分替换任何你不喜欢的东西，比如种族主义。
- en: (50:30) Zuck then contrasts this with nation states interfering in elections,
    where he says nation-states are ‘have cutting edge technology’ and are getting
    better every year. He says this is ‘not like someone trying to say mean things,
    they have a goal.’
  id: totrans-split-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （50:30）扎克随后将此与国家干预选举进行对比，他说国家正在“拥有尖端技术”，并且每年都在变得更好。他说这不像有人试图说恶毒的话，他们有一个目标。
- en: Well, saying mean things is also a goal, and I have seen people be very persistent
    and creative in saying mean things when they want to do that.
  id: totrans-split-87
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 好吧，说恶意的事情也是一个目标，我见过人们在想这么做的时候非常坚持和有创意。
- en: Indeed, Mark Zuckerberg went to Ardsley High School and Phillips Exeter Academy,
    they made this movie The Social Network and also saying mean things about Mark
    Zuckerberg is a top internet passtime. I am going to take a wild guess that he
    experienced this first hand. A lot.
  id: totrans-split-88
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 的确，马克·扎克伯格曾就读于阿兹利高中和菲利普斯埃克塞特学院，他们拍了这部电影《社交网络》，并且说马克·扎克伯格的坏话是一种网络顶级消遣。我要大胆猜测他亲身经历过这些。
- en: I would also more centrally say no, zero nation states have cutting edge election
    interference technology, except insofar as ‘whatever is available to the most
    capable foreign nation-state at this, maybe Russia’ is defined as the cutting
    edge. Plenty of domestic and non-state actors are ahead of the game here. And
    no state actor, or probably any domestic actor either, is going to have access
    to an optimized-for-propaganda-and-chaos version of Gemini, GPT-4 or Claude Opus.
    We are blessed here, and of course we should not pretend that past attempts were
    so sophisticated or impactful. Indeed, what may happen in the coming months is
    that, by releasing Llama-3 400B, Zuck instantly gives Russia, China, North Korea
    and everyone else exactly this ‘cutting edge technology’ with which to interfere.
  id: totrans-split-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我也更核心地说，没有国家拥有最先进的选举干扰技术，除非‘在这一点上，也许俄罗斯’的任何能力最强的外国国家的所能获得的被定义为最先进。许多国内和非国家行为者在这方面处于领先地位。而且没有一个国家行为者，或者可能是任何国内行为者，会有机会获得一个为宣传和混乱优化的版本，比如Gemini、GPT-4或Claude
    Opus。我们在这里是幸运的，当然我们不应该假装过去的尝试是如此复杂或有影响力。确实，在未来几个月可能发生的是，通过发布Llama-3 400B，扎克立即为俄罗斯、中国、朝鲜和其他所有人提供了这种‘最先进技术’，用于干扰。
- en: I of course think the main deception problems with AI lie in the future, and
    have very little to do with traditional forms of ‘misinformation’ or ‘election
    interference.’ I do still find it useful to contrast our models of those issues.
  id: totrans-split-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当然，我认为AI的主要误导问题在未来，与传统形式的‘误导’或‘选举干扰’关系很小。我仍然发现将这些问题的模型进行对比是有用的。
- en: (51:30) He says ‘for the foreseeable future’ he is optimistic they will be able
    to open source. He doesn’t want to ‘take our eye off the ball’ of what people
    are trying to use the models for today. I would urge him to keep his eye on that
    ball, but also skate where the puck is going. Do not move directly towards the
    ball.
  id: totrans-split-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (51:30) 他说‘在可预见的未来’他乐观地认为他们将能够开源。他不想‘把我们的眼睛从今天人们试图使用模型的事情上移开’。我会建议他继续关注这个问题，但也要滑到冰球去。不要直接朝着球移动。
- en: (54:30) Fun time, what period of time to go back to? Zuck checks, it has to
    be the past. He talks about the metaverse.
  id: totrans-split-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (54:30) 好玩的时间，回到什么时候？扎克检查，必须是过去。他谈论到元宇宙。
- en: (59:00) Zuck is incapable of not taking a swing at building the next thing.
    He spends so much time finding out if he could, I suppose.
  id: totrans-split-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (59:00) 扎克无法阻止自己去尝试建造下一件事情。我想他花了很多时间弄清楚他是否能够。
- en: (1:02:00) Caesar Augustus seeking peace. Zuck suggests peace at the time was
    a new concept as anything other than a pause between wars. I notice I am skeptical.
    Then Zuck transitions from ‘wanting the economy to be not zero-sum’ to ‘a lot
    of investors don’t understand why we would open source this.’ And says ‘there
    are more reasonable things than people think’ and that open source creates winners.
    The framing attempt is noted.
  id: totrans-split-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:02:00) 凯撒·奥古斯都寻求和平。扎克建议在当时和平是一种除了战争之外的新概念。我注意到我持怀疑态度。然后扎克从‘希望经济不是零和游戏’转向‘许多投资者不明白为什么我们会开源这个’。他说‘有比人们想象的更合理的事情’，并且开源创造了赢家。注意到这种框架尝试。
- en: I instead think most investors understand perfectly well why Meta might open
    source here. It is not hard to figure this out. Indeed, the loudest advocates
    for open source AI are largely venture capitalists.
  id: totrans-split-95
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我反而认为大多数投资者非常明白Meta为什么可能在这里开源。弄清楚这一点并不难。确实，对开源AI最响亮的倡导者大多是风险投资家。
- en: That does not mean that open sourcing is a wise (or unwise) business move.
  id: totrans-split-96
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这并不意味着开源是明智（或不明智）的商业举动。
- en: (1:05:00) Suppose there was a $10 billion model, it was totally safe even with
    fine tuning, would you open source? Zuck says ‘as long as it’s helping us, yeah.’
  id: totrans-split-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:05:00) 假设有一个价值100亿美元的模型，即使经过精细调整，也完全安全，你会开源吗？扎克说‘只要它对我们有帮助，是的。’
- en: Exactly. If it is good for business and it is not an irresponsible thing to
    do, it was actually ‘totally safe’ in the ways that matter, and you think it is
    good for the world too, then why not?
  id: totrans-split-98
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 没错。如果这对业务有好处，并且这不是一件不负责任的事情，实际上在重要方面它是‘完全安全’的，并且你认为这对世界也有好处，那为什么不呢？
- en: My only caveat would be to ensure you are thinking well about what ‘safe’ means
    in that context, as it applies to the future path the world will take. One does
    not, in either direction, want to use a narrow view of ‘safe.’
  id: totrans-split-99
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我唯一的警告是确保你在这种情况下对“安全”的含义有深思熟虑，因为它适用于世界未来的发展路径。在任何方向上，我们都不希望狭隘地理解“安全”。
- en: (1:06:00) Zuck notes he does not open source Meta’s products. Software yes,
    products no. Something to keep in mind.
  id: totrans-split-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （1:06:00）扎克提到他不会开源 Meta 的产品。软件可以，但产品不行。这是需要记住的事情。
- en: (1:07:00) Dwarkesh asks if training will be commodified? Zuck says maybe. Or
    it could go towards qualitative improvements via specialization.
  id: totrans-split-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （1:07:00）德瓦克什问培训是否会成为商品化？扎克说可能会。或者它可能通过专业化进行定性改进。
- en: (1:08:45) Zuck notes that several times, Meta has wanted to launch features,
    and Apple has said no.
  id: totrans-split-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （1:08:45）扎克指出，Meta 曾多次希望推出功能，而苹果却说不。
- en: We don’t know which features he is referring to.
  id: totrans-split-103
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们不知道他指的是哪些特性。
- en: We do know Apple and Meta have been fighting for a while about app tracking
    and privacy, and about commissions and informing users about the commissions,
    and perhaps messaging.
  id: totrans-split-104
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们知道苹果和 Meta 已经在关于应用追踪和隐私、关于佣金以及通知用户有关佣金情况，以及可能的消息传递方面进行了一段时间的斗争。
- en: (1:09:00) He therefore asks, what if someone has an API and tells you what you
    can build? Meta needs to build the model themselves to ensure they are not in
    that position.
  id: totrans-split-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （1:09:00）因此，他问，如果有人拥有 API 并告诉你可以建造什么怎么办？Meta 需要自己建立模型以确保他们不处于这种位置。
- en: I don’t love that these are the incentives, but if you are as big as Meta and
    want to do Meta things, then I am sympathetic to Meta in particular wanting to
    ensure it has ownership of the models it uses internally, even if that means large
    costs and even if it also meant being a bit behind by default.
  id: totrans-split-106
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我并不喜欢这些激励措施，但如果你像 Meta 这样大，想要做 Meta 的事情，那么我对 Meta 特别希望确保它拥有内部使用的模型所有权感到理解，即使这意味着巨大的成本，甚至意味着默认情况下落后一点也是如此。
- en: 'The core dilemma that cannot be resolved is: Either there is someone, be it
    corporation, government or other entity, that is giving you an API or other UI
    that decides what you can and cannot do, or there is not. Either there is the
    ability to modify the model’s weights and use various other methods to get it
    to do whatever you want it to do, or there is not. The goals of ‘everyone is free
    to do what they want whenever they want’ and ‘there is some action we want to
    ensure people do not take’ are mutually exclusive.'
  id: totrans-split-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不能解决的核心困境是：要么有某个企业、政府或其他实体为你提供 API 或其他 UI 来决定你可以做什么或不能做什么，要么没有。要么有修改模型权重和使用其他方法让它做任何你想让它做的事情的能力，要么没有。“每个人都可以在任何时候做任何他们想做的事”和“我们想确保人们不采取某些行动”这两个目标是互相排斥的。
- en: You can and should seek compromise, to be on the production possibilities frontier,
    where you impose minimal restrictions to get the necessary guardrails in place
    where that is worthwhile, and otherwise let people do what they want. In some
    cases, that can even be zero guardrails and no restrictions. In other cases, such
    as physically building nuclear weapons, you want strict controls. But there is
    no taking a third option, you have to make the choice.
  id: totrans-split-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以并且应该寻求妥协，以便处于生产可能性的前沿，在那里你会施加最小的限制，以确保必要的防范措施得以实施，而其他情况下则让人们按照他们的意愿行事。在某些情况下，甚至可以是零限制和无防范措施。在其他情况下，比如物理上建造核武器，你希望有严格的控制。但没有第三种选择，你必须做出选择。
- en: (1:09:45) I totally do buy Zuck’s central case here, that if you have software
    that is generally beneficial to builders, and you open source it, that has large
    benefits. So if there is no reason not to do that, and often there isn’t, you
    should do that.
  id: totrans-split-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （1:09:45）我完全同意扎克在这里的核心观点，即如果你有一款对建设者普遍有益的软件，并且你将其开源，那将带来很大的好处。因此，如果没有理由不这样做，而通常情况下是没有的，那么你应该这样做。
- en: (1:10:15) What about licensing the model instead, with a fee? Zuck says he would
    like that. He notes that the largest companies cannot freely use Llama under their
    license, so that if Amazon or Microsoft started selling Llama then Meta could
    get a revenue share.
  id: totrans-split-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （1:10:15）那么授权模型，收取费用呢？扎克表示他喜欢这个想法。他指出，最大的公司不能自由地在他们的许可证下使用 Llama，因此如果亚马逊或微软开始销售
    Llama，Meta 可以获得收入份额。
- en: (1:12:00) Dwarkesh presses on the question of red flags, pointing to the responsible
    scaling policy (RSP) of Anthropic and preparedness framework of OpenAI, saying
    he wishes there was a similar framework at Meta saying what concrete things should
    stop open sourcing or even deployment of future models.
  id: totrans-split-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:12:00) Dwarkesh 对红旗问题进行了进一步追问，指出了 Anthropic 的负责任扩展政策（RSP）和 OpenAI 的应对框架，表示希望
    Meta 也有一个类似的框架，说明应该停止开源或甚至部署未来模型的具体事项。
- en: Zuck says that is a fair point on the existential risk side, right now they
    are focusing on risks they see today, the content risk, avoiding helping people
    do violence or commit fraud. He says for at least one generation beyond this one
    and likely two, the harms that need more mitigation will remain the ‘more mundane
    harms’ like fraud, he doesn’t want to shortchange that, perhaps my term is catching
    on. Dwarkesh replies ‘Meta can handle both’ and Zuck says yep.
  id: totrans-split-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扎克表示，这是关于存在风险的一个公平观点，现在他们正专注于他们今天看到的风险，内容风险，避免帮助人们进行暴力或者实施欺诈。他说，至少在这一代人之后，可能还有两代人，需要更多减少的伤害将是“更世俗的伤害”，如欺诈，他不想短视，也许我的术语正在流行。Dwarkesh
    回答说“Meta 可以处理两者”，扎克说没错。
- en: There is no contradiction here. Meta can (and should) put the majority of its
    risk mitigation efforts into mundane harms right now, and also should have a framework
    for when existential risks would become concerning enough to reconsider how to
    deploy (or later train) a model, and otherwise spend relatively less on the issue.
    And it is perfectly fine to expect not to hit those thresholds for several generations.
    The key is to lay out the plan.
  id: totrans-split-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里没有矛盾。Meta 现在可以（也应该）将大部分的风险缓解工作投入到世俗伤害中，同时也应该有一个框架，用于当存在风险足够引起重新考虑如何部署（或之后训练）模型时，并在该问题上相对少花费。可以完全可以期望在几代人之后才会达到那些阈值。关键是制定计划。
- en: (1:13:20) Has the impact of the open source tools Meta has released been bigger
    than the impact of its social media? Zuck says it is an interesting question,
    but half the world uses their social media. And yes, I think it is a fun question,
    but the answer is clearly no, the social media is more counterfactually important
    by far.
  id: totrans-split-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:13:20) Meta 发布的开源工具的影响是否比其社交媒体的影响更大？扎克表示这是一个有趣的问题，但世界上一半的人使用他们的社交媒体。是的，我认为这是一个有趣的问题，但答案显然是否定的，社交媒体在反事实情况下更为重要。
- en: (1:14:45) Meta custom silicon coming soon? Not Llama-4, but soon after that.
    They already moved a bunch of Reels inference onto their own silicon, and use
    Nvidia chips only for training.
  id: totrans-split-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:14:45) Meta 自定义硅片即将推出？不是 Llama-4，而是紧随其后。他们已经将大量 Reels 推断移至自己的硅片上，并且仅在训练时使用
    Nvidia 芯片。
- en: (1:16:00) Could Zuck have made Google+ work as CEO of Google+? Zuck says he
    doesn’t know, that’s tough. One problem was that Google+ didn’t have a CEO, it
    was only a division, and points to issues of focus. Keep the main thing the main
    thing.
  id: totrans-split-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:16:00) 扎克是否能作为 Google+ 的 CEO 使其成功？扎克表示他不知道，这很困难。其中一个问题是 Google+ 没有 CEO，它只是一个部门，并指出了关注点的问题。保持主要事物为主要事物。
- en: That was a great interview. It tackled important questions. For most of it,
    Zuck seemed like a real person with a unique perspective, saying real things.
  id: totrans-split-117
  prefs: []
  type: TYPE_NORMAL
  zh: 那是一个很棒的采访。它处理了重要的问题。在大部分时间里，扎克似乎是一个有独特视角的真实人，说着真实的话。
- en: The exception was that weird period where he was defending open source principles
    using what sounded like someone else’s speech on a tape recorder. Whereas at other
    times, his thoughts on open source were also nuanced and thoughtful. Dwarkesh
    was unafraid to press him on questions of open source throughout the interview.
  id: totrans-split-118
  prefs: []
  type: TYPE_NORMAL
  zh: 例外是他曾辩护使用听起来像是别人的演讲录音的开源原则的奇怪时期。而在其他时候，他对开源的看法也是细腻而深思熟虑的。Dwarkesh 在整个采访中对开源问题毫不畏惧地追问他。
- en: What Dwarkesh failed to get was any details from Zuck about existential or catastrophic
    risk. We are left without any idea of how Zuck thinks about those questions, or
    what he thinks would be signs that we are in such danger, or what we might do
    about it. He tried to do this with the idea of Meta needing a risk policy, but
    Zuck kept dodging. I think there was more room to press on specifics. Once again
    this presumably comes down to Zuck not believing the dangerous capabilities will
    exist.
  id: totrans-split-119
  prefs: []
  type: TYPE_NORMAL
  zh: Dwarkesh 未能从扎克那里获取关于存在风险或灾难性风险的任何细节。我们对扎克如何思考这些问题，以及他认为哪些迹象表明我们处于这样的危险中，或者我们可以对此做些什么一无所知。他试图通过
    Meta 需要一个风险政策的想法来做到这一点，但扎克一直在逃避。我认为还有更多的具体问题可以追问。再次，这可能归结为扎克不相信危险的能力将会存在。
- en: Nor was there much discussion of the competitive dynamics that happen when everyone
    has access to the same unrestricted advanced AI models, and what might happen
    as a result.
  id: totrans-split-120
  prefs: []
  type: TYPE_NORMAL
  zh: 也没有多少讨论，当每个人都可以访问相同的无限制的先进AI模型时，会发生什么样的竞争动态，以及可能会出现的结果。
- en: I also think Zuck is failing to grapple with even the difficulties of mundane
    content moderation, an area where he is an expert, and I would like to see his
    explicit response. Previously, he has said that only a company with the resources
    of a Meta can do content moderation at this point.
  id: totrans-split-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我也认为扎克甚至未能应对世俗内容管理的困难，这是他的专长领域，我希望看到他的明确回应。此前，他曾表示，目前只有Meta这样资源雄厚的公司才能进行内容管理。
- en: I think he was wrong in the sense that small bespoke gardens are often successfully
    well-defended. But I think Zuck was right that if you want to defend something
    worth attacking, like Meta, you need scale and you need to have the expertise
    advantage. But if those he is defending against also have the resources of Meta
    where it counts, then what happens?
  id: totrans-split-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为他在某种意义上是错的，因为小型定制花园通常能够成功防御。但我认为扎克说得对，如果你想保卫像Meta这样值得攻击的东西，你需要规模和专业知识的优势。但如果他正在防御的对手在关键领域也拥有Meta的资源，那会发生什么？
- en: So if there is another interview, I hope there is more pressing on those types
    of questions.
  id: totrans-split-123
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果还有另一次采访，我希望有更多对这些问题的追问。
- en: In terms of how committed Zuck is to open source, the answer is a lot but not
    without limit. He will cross that bridge when he comes to it. On the horizon he
    sees no bridge, but that can quickly change. His core expectation is that we have
    a long way to go before AI goes beyond being a tool, even though he also thinks
    it will soon very much be everyone’s personal agent. And he especially thinks
    that energy restrictions will soon bind, which will stifle growth because that
    goes up against physical limitations and government regulations. It is an interesting
    theory. If it does happen, it has a lot of advantages.
  id: totrans-split-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在扎克对开源的承诺方面，答案是很多，但并非没有限制。他会在到达时越过这座桥。在他的视野中，他看不到桥，但情况可能很快改变。他的核心期望是，在人工智能超越工具的角色之前，我们还有很长的路要走，尽管他也认为很快每个人都会有自己的个人代理。他尤其认为能源限制很快会发生，这将阻碍增长，因为这与物理限制和政府监管相冲突。这是一个有趣的理论。如果真的发生，它有很多优势。
- en: '[Ate-a-Pi has a good reaction writeup on Twitter.](https://twitter.com/8teAPi/status/1781480713394737238)
    It was most interesting in seeing different points of emphasis. The more I think
    about it, the more Ate-a-Pi nailed it pulling these parts out:'
  id: totrans-split-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ate-a-Pi在Twitter上有一篇很好的反应文章。](https://twitter.com/8teAPi/status/1781480713394737238)看到不同的强调点非常有趣。我越想越觉得Ate-a-Pi把这些部分提炼得非常到位：'
- en: 'Ate-a-Pi (edited down): **TLDR**: AI winter is here. Zuck is a realist, and
    believes progress will be incremental from here on. No AGI for you in 2025.'
  id: totrans-split-126
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Ate-a-Pi（编辑过）：**TLDR**：AI寒冬来临。扎克是个现实主义者，认为未来的进展将是渐进的。2025年不会有通用人工智能。
- en: Zuck is essentially an real world growth pessimist. He thinks the bottlenecks
    start appearing soon for energy and they will be take decades to resolve. AI growth
    will thus be gated on real world constraints.
  id: totrans-split-127
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扎克本质上是一个对现实世界增长持悲观态度的人。他认为能源的瓶颈很快就会出现，解决这些问题将需要数十年时间。因此，人工智能的增长将受到现实世界约束的限制。
- en: Zuck would stop open sourcing if the model is the product.
  id: totrans-split-128
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果模型是产品，扎克将停止开源。
- en: Believes they will be able to move from Nvidia GPUs to custom silicon soon.
  id: totrans-split-129
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相信他们很快将能从Nvidia的GPU过渡到定制硅片。
- en: Overall, I was surprised by how negative the interview was.
  id: totrans-split-130
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 总体而言，我对采访的负面程度感到惊讶。
- en: A) Energy - Zuck is pessimistic about the real world growth necessary to support
    the increase in compute. Meanwhile the raw compute per unit energy has doubled
    every 2 years for the last decade. Jensen also is aware of this, and it beggars
    belief that he does not think of paths forward where he has to continue this ramp.
  id: totrans-split-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: A）能源 - 扎克对支持计算增长所需的现实世界增长持悲观态度。与此同时，过去十年每单位能量的原始计算量每两年翻一番。詹森也意识到了这一点，他不认为自己没有考虑到需要继续这一增长路径。
- en: B) AGI Negative Zuck fundamentally
  id: totrans-split-132
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: B）AGI Negative Zuck fundamentally
- en: does not believe the model, the AI itself, will be the product.
  id: totrans-split-133
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不相信模型本身会成为产品。
- en: It is the context, the network graph of friendships per user, the moderation,
    the memory, the infrastructure that is the product.
  id: totrans-split-134
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这就是产品的上下文，用户之间的友谊网络图，内容管理，内存，基础设施。
- en: Allows him to freely release open source models, because he has all of the rest
    of the pieces of user facing scaffolding already done.
  id: totrans-split-135
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 允许他自由发布开源模型，因为他已经完成了所有其余用户界面脚手架的部分。
- en: Does not believe in states of the world where a 100x improvement from GPT-4
    are possible, or that AGI is possible within a short timeframe.
  id: totrans-split-136
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不认为从 GPT-4 获得 100 倍的改进是可能的，或者在短期内实现 AGI 是可能的。
- en: An actual AGI
  id: totrans-split-137
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一个真正的AGI
- en: where the a small model learns and accompanies the user for long periods
  id: totrans-split-138
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 其中一个小型模型学习并在长时间内陪伴用户
- en: while maintaining its own state
  id: totrans-split-139
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 同时保持其自身状态
- en: with a constitution of what it can or cannot do
  id: totrans-split-140
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 以其可或不可进行的构成
- en: rather than frequent updates from a central server
  id: totrans-split-141
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 而不是来自中央服务器的频繁更新
- en: would be detrimental to Meta’s business,
  id: totrans-split-142
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 将对 Meta 的业务造成不利影响，
- en: would cause a re-evaluation of what they are doing
  id: totrans-split-143
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 将导致对他们正在做的事情进行重新评估
- en: Especially on point is that Zuck never expects the AI itself to be the product.
    This is a common pattern among advocates for open model weights - they do not
    actually believe in AGI or the future capabilities of the product. It is not obvious
    Zuck and I even disagree so much on what capabilities would make it unwise to
    open up model weights. Which is all the more reason to spell out what that threshold
    would be.
  id: totrans-split-144
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其要点是，扎克从不指望 AI 本身成为产品。这是支持开放模型权重的倡导者中常见的模式 - 他们实际上并不相信 AGI 或产品的未来能力。显然，扎克和我甚至在什么能力会使开放模型权重不明智这一点上也不完全意见一致。这正是要明确阐述那个门槛的更多理由。
- en: Then there is speculation from Ate-a-Pi that perhaps Zuck is being realistic
    because Meta does not need to raise capital, whereas others hype to raise capital.
    That surely matters on the margin, in both directions. Zuck would love if Altman
    and Amodei were less able to raise capital.
  id: totrans-split-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是来自 Ate-a-Pi 的推测，也许扎克之所以如此现实，是因为 Meta 不需要筹集资本，而其他人则炒作以筹集资本。这在边际上肯定很重要，两个方向都有影响。如果奥特曼和阿莫迪更难筹集资本，扎克会很高兴。
- en: But also I am confident this is a real disagreement, to a large extent, on both
    sides. These people expecting big jumps from here might turn out to be bluffing.
    But I am confident they think their hand is good.
  id: totrans-split-146
  prefs: []
  type: TYPE_NORMAL
  zh: 但我也确信这是一个真正的分歧，在很大程度上，双方都有。这些人希望从这里跳跃出大步可能最终是虚张声势。但我确信他们认为自己的手牌很好。
- en: '[Daniel Jeffries highlights GPT-5](https://twitter.com/Dan_Jeffries1/status/1781567863595180090)
    as key evidence either way, which seems right.'
  id: totrans-split-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[丹尼尔·杰弗里斯强调 GPT-5](https://twitter.com/Dan_Jeffries1/status/1781567863595180090)
    作为证据的关键，这似乎是正确的。'
- en: 'Daniel Jeffries: The litmus test about whether we hit a plateau with LLMs will
    be GPT5\. It''ll tell us everything we need to know.'
  id: totrans-split-148
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 丹尼尔·杰弗里斯：关于我们是否达到了LLM的高原的检验将是GPT5。它会告诉我们一切我们需要知道的。
- en: I'm on record in my new years predictions as saying I believe GPT5 will be incremental.
  id: totrans-split-149
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我在我的新年预测中说过，我认为 GPT5 将是渐进的。
- en: But I am now 50/50 on that and feel it could still be a massive leap up provided
    they actually pioneered new techniques in synthetic data creation, or other new
    techniques, such as using GPT4 as a bootstrapper for various scenarios, etc.
  id: totrans-split-150
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 但现在我对此有50/50的看法，并且感觉它仍然可能是一个巨大的飞跃，只要他们实际上在合成数据创造或其他新技术方面开创了新技术，比如使用GPT4作为各种场景的引导程序等等。
- en: If it is just another transformer with more data, I don't see it making a massive
    leap. Could still be useful, ie infinite context windows, and massively multimodal,
    but incremental none the less.
  id: totrans-split-151
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果它只是另一个带有更多数据的变压器，我认为它不会有巨大的飞跃。仍然可能有用，即无限上下文窗口和极其多模式，但是增量的。
- en: But if GPT5 is a minor improvement, meaning a much smaller gap versus the jump
    from 2 to 3 and 3 to 4, then Zuck is right. The LLM is basically a hot swappable
    Linux kernel and the least important part of the mix. Everything around it, squeezing
    the most out of its limitations, becomes the most important aspect of building
    apps.
  id: totrans-split-152
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 但如果 GPT5 是一个小幅改进，意味着与从 2 到 3 和 3 到 4 的跃升相比，差距要小得多，那么扎克是正确的。LLM 基本上是一个可热插拔的 Linux
    内核，是整体中最不重要的部分。围绕它的一切，在其限制中挤出最大可能性，成为构建应用程序最重要的方面。
- en: Like any good predictor, I continue to revise my predictions as new data comes
    in. The top predictors in world competitions revise their thinking on average
    four times. The second tier revises twice. The rest of the world? Never. Let that
    sync in.
  id: totrans-split-153
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 像任何好的预测者一样，随着新数据的进入，我继续修订我的预测。在世界竞赛中排名前列的预测者平均修订四次。第二梯队修订两次。其他人呢？从不。让这个事实深入人心。
- en: If GPT-5 lands at either extreme it would be very strong evidence. We also could
    get something in the middle, and be left hanging. I also would not be too quick
    in calendar time to conclude progress is stalling, if they take their time releasing
    5 and instead release smaller improvements along the way. The update would be
    gradual, and wouldn’t be big until we get into 2025\.
  id: totrans-split-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 GPT-5 出现在任何极端，这将是非常强有力的证据。我们也可能得到中间结果，然后陷入困境。如果他们花时间发布 5 并逐步推出较小的改进，那么我们在日历时间上不应过快得出停滞不前的结论。更新将是渐进的，直到我们进入
    2025 年之前也不会大幅改变。
- en: Ate-a-Pi also offers [this explanation of the business case for opening up Llama-3](https://twitter.com/8teAPi/status/1781092976497918456).
  id: totrans-split-155
  prefs: []
  type: TYPE_NORMAL
  zh: Ate-a-Pi 还提供了[关于开放 Llama-3 的商业案例解释](https://twitter.com/8teAPi/status/1781092976497918456)。
- en: 'Ate-a-Pi: Here are the business reasons:'
  id: totrans-split-156
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Ate-a-Pi：这里是商业原因：
- en: Allows social debugging outside Meta
  id: totrans-split-157
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 允许在 Meta 之外进行社交调试
- en: social products have bugs!
  id: totrans-split-158
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 社交产品存在 bug！
- en: interactions which require moderation - saying harmful things to kids for eg
  id: totrans-split-159
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 需要审核的交互 - 对孩子说有害的事情，例如
- en: Meta’s (and all social) primary product is moderation
  id: totrans-split-160
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Meta（以及所有社交平台）的主要产品是内容审核
- en: getting the tech out to the market allows Meta to observe the bugs in the wild
    at small scale
  id: totrans-split-161
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 将技术推向市场，允许 Meta 在小规模中观察野外的漏洞
- en: before deploying at global scale in Meta
  id: totrans-split-162
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在 Meta 全球范围部署之前
- en: precisely the same reason to open source software
  id: totrans-split-163
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 正是开源软件的同样原因
- en: except open sourcing social technology to test and debug it sounds creepier
  id: totrans-split-164
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 除了开源社交技术来测试和调试听起来更加可怕
- en: “oooh look at dev xyz they made it abc, looks like we got to fix that in the
    next training run”
  id: totrans-split-165
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “哦，看看 dev xyz，他们把它做成了 abc，看来我们得在下次的训练中修复这个问题”
- en: Meta’s biggest threat is [character.ai](http://character.ai)
  id: totrans-split-166
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Meta 最大的威胁是[character.ai](http://character.ai)
- en: AI friends are going to be more numerous, nicer and more available than your
    real friends
  id: totrans-split-167
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: AI 朋友将比你的真实朋友更多，更友好，更随时可用
- en: FB, Insta, Whatsapp own your real world friends
  id: totrans-split-168
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: FB、Insta、Whatsapp 拥有你的现实世界朋友
- en: But Meta can’t compete here directly yet because it’s seen as creepy
  id: totrans-split-169
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 但 Meta 目前无法直接竞争，因为这被视为令人不安
- en: especially before the tech is good as there in an uncanny valley
  id: totrans-split-170
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尤其是在技术还不够成熟时，存在一种神秘谷效应
- en: they did a trial run with their Tom Brady/Snoop Dogg style AI friends but the
    safety requirements are too high for interesting interactions
  id: totrans-split-171
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 他们用他们的 Tom Brady / Snoop Dogg 风格的 AI 朋友做了试验，但是安全要求对于有趣的互动来说太高了
- en: Zuck is ready to cannibalize the friendship network he built if the AI friends
    get good enough
  id: totrans-split-172
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果 AI 朋友变得足够好，Zuck 准备牺牲他建立的友谊网络
- en: Destroys competing platforms
  id: totrans-split-173
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 消灭竞争对手平台
- en: an early tech/product lead allows a startup to overcome a distribution disadvantage
  id: totrans-split-174
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 早期的技术/产品领先让初创公司能够克服分发劣势
- en: Meta has the ultimate distribution advantage
  id: totrans-split-175
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Meta 拥有终极分发优势
- en: so he doesn’t want anyone else to have a technology advantage
  id: totrans-split-176
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所以他不希望其他人拥有技术优势
- en: by releasing open source he cuts short revenue ramps at [character.ai](http://character.ai)
    , OpenAI and other firms
  id: totrans-split-177
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 通过开源，他缩短了[character.ai](http://character.ai)，OpenAI 和其他公司的收入上升时间
- en: they have to innovate faster while gated by capital
  id: totrans-split-178
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 他们必须在资本的限制下更快地创新
- en: he’s not gated by capital
  id: totrans-split-179
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 他不受资本限制
- en: prevents large competitors from emerging
  id: totrans-split-180
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 阻止大型竞争对手的出现
- en: Distributed R&D
  id: totrans-split-181
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 分布式研发
- en: he wants other people to develop interesting social ideas
  id: totrans-split-182
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 他希望其他人开发有趣的社交理念
- en: feature that can be copied
  id: totrans-split-183
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 可以被复制的特性
- en: he did something similar to Snap by absorbing their innovation into Instagram
  id: totrans-split-184
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 他通过吸收 Snap 的创新进入 Instagram，做了类似的事情
- en: even more so now, as you have to label your llama3 fine tunes
  id: totrans-split-185
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 现在更是如此，因为你必须标记你的 llama3 微调
- en: Here I find some very interesting model disagreements.
  id: totrans-split-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里我发现一些非常有趣的模型分歧。
- en: Ate says that Meta’s biggest thereat is character.ai, and that this undercuts
    character.ai.
  id: totrans-split-187
  prefs: []
  type: TYPE_NORMAL
  zh: Ate 表示 Meta 最大的威胁是 character.ai，而这正是 character.ai 的弱点。
- en: Whereas I would say, this potentially supercharges character.ai, they get to
    improve their offerings a lot, as do their competitors (of varying adult and ethical
    natures).
  id: totrans-split-188
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我会说，这可能会极大地增强 character.ai，他们能够大幅改进他们的产品，竞争对手们（成人和伦理不同）也能如此。
- en: Meta perhaps owns your real world friends (in which case, please help fix that
    locally, ouch). But this is like [the famous line](https://www.youtube.com/watch?v=wknywxfcE5M&ab_channel=Movieclips).
    The AIs get more capable. Your friends stay the same.
  id: totrans-split-189
  prefs: []
  type: TYPE_NORMAL
  zh: Meta 或许掌控你的现实世界朋友（如果是这样，请帮助在本地解决，哎呀）。但这就像[著名的一句话](https://www.youtube.com/watch?v=wknywxfcE5M&ab_channel=Movieclips)。AI
    变得更强大。而你的朋友依旧如故。
- en: Similarly, Ate says that this ‘allows for social debugging outside of Meta,’
    because Meta’s primary product is moderation. He thinks this will make moderation
    easier. I think this is insane. Giving everyone better AI, catching them up to
    what Meta has, makes moderation vastly harder.
  id: totrans-split-190
  prefs: []
  type: TYPE_NORMAL
  zh: Ate-a-Pi：公平。
- en: 'nico: The real reason is because he’s behind.'
  id: totrans-split-191
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 更具体地说，当涉及到获取必要信息的便捷性和消除其他不便时，这一点是正确的。如果某件事情不管怎样都可能发生，你需要提高成本，降低其突出性和可用性。
- en: 'Ate-a-Pi: Fair.'
  id: totrans-split-192
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尼科：真正的原因是因为他落后了。
- en: '[Here are some reactions](https://twitter.com/AndrewCritchPhD/status/1781325187457401305)
    from people less skeptical than I am of open source.'
  id: totrans-split-193
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，Ate说这‘允许在Meta之外进行社会调试’，因为Meta的主要产品是调节。他认为这会使调节更容易。我认为这是疯狂的。给每个人更好的AI，让他们赶上Meta的水平，会大大增加调节的难度。
- en: 'Nora Belrose: Zuck''s position is actually quite nuanced and thoughtful.'
  id: totrans-split-194
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 将诺拉的思维风格带到这里并全面考虑，我认为这样的论点通常（但远非总是）是反向的。形式上的论据是‘是的，X使Y变得更糟，但解决X并不能解决Y，所以我们不应该用Y作为解决X的理由’，这可能指向另一方向，除非你能指出一些Z来解决Y，并确实得到Z。在你得到Z之前，这通常意味着你更需要X，因为绝对的风险差异更高而不是更低。
- en: He says that if they discover destructive AI capabilities that we can't build
    defenses for, they won't open source it. But he also thinks we should err on the
    side of openness. I agree.
  id: totrans-split-195
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在那些生物实际上非常致命且难以防御的世界里，即使没有开源AI，我们也会面临严重问题。试图限制知识可能不是最好的解决方案。
- en: In worlds where bio is actually super deadly and hard to defend against, we're
    gonna have serious problems on our hands even without open source AI. Trying to
    restrict knowledge probably isn't the best solution.
  id: totrans-split-196
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 诺拉·贝尔罗斯：扎克的立场实际上非常微妙和深思熟虑。
- en: 'Andrew Critch: Zuckerberg and Patel having an amazing conversation on AI risk.
    Great questions and great responses in my opinion. I''m with Zuckerberg that these
    risks are both real and manageable, and hugely appreciative of Patel as an interviewer
    for keeping the discursive bar high.'
  id: totrans-split-197
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 他说，如果他们发现有破坏性的AI能力，我们无法建立防御措施，他们不会开源它。但他也认为我们应该偏向开放。我同意。
- en: Still, without compute governance, a single AI system could go rogue and achieve
    a massive imbalance of power over humanity. If equitable compute governance is
    on track, open source AI is much safer than if massive datacenters remain vulnerable
    to cyber take-over by rogue AI.
  id: totrans-split-198
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这里是一些对开源持更少怀疑态度的人的反应。
- en: As I noted above, I think everyone sensible is at core talking price. What level
    of open model weight capabilities is manageable in what capacities? What exactly
    are we worried about going wrong and can we protect against it, especially when
    you cannot undo a release, the models may soon be smarter than us and there are
    many unknown unknowns about what might happen or what the models could do.
  id: totrans-split-199
  prefs: []
  type: TYPE_NORMAL
  zh: 安德鲁·克里奇：扎克伯格和帕特尔在讨论AI风险方面进行了一场精彩的对话。在我看来，问得好，答得好。我支持扎克伯格的观点，即这些风险是真实且可管理的，并对帕特尔作为采访者能够保持高水平的讨论感到非常赞赏。
- en: To take Nora’s style of thinking here and consider it fully generally, I think
    such arguments are in expectation (but far from always) backwards. Arguments of
    the form ‘yes X makes Y worse, but solving X would not solve Y, so we should not
    use Y as a reason to solve X’ probably points the other way, unless you can point
    to some Z that solves Y and actually get Z. Until you get Z, this usually means
    you need X more, as the absolute risk difference is higher rather than lower.
  id: totrans-split-200
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然没有计算治理，但单一的AI系统可能会变得失控，并对人类造成巨大的权力失衡。如果公平的计算治理顺利进行，开源AI比那些仍然容易受到失控AI网络攻击的大型数据中心要安全得多。
- en: More specifically this is true when it comes to ease of getting necessary information
    and otherwise removing inconveniences. If something is going to be possible regardless,
    you need to raise the cost and lower the salience and availability of doing that
    thing.
  id: totrans-split-201
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我上面提到的，我认为每个理性的人都在核心谈论价格。在什么能力下，开放模型的级别是可管理的？我们究竟在担心什么可能出错，我们能否保护自己，尤其是当你无法撤销一次发布，模型可能很快比我们更聪明，而且有很多未知的未知事物可能发生或者模型可能做些什么。
- en: 'I’ve talked about this before, but: Indeed there are many things in our civilization,
    really quite a lot, where someone with sufficient publically available knowledge
    can exploit the system, and occasionally someone does, but mostly we don’t partly
    for ethical or moral reasons, partly for fear of getting caught somehow or other
    unknown unknowns, but even more so because it does not occur to us and when it
    does it would be a bunch of work to figure it out and do it. Getting sufficiently
    strong AI helping with those things is going to be weird and force us to a lot
    of decisions.'
  id: totrans-split-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我以前谈过这个问题，但是：事实上，我们文明中有很多事情，确实有很多事情，只要有足够的公开可获取的知识，就可以利用系统，偶尔有人这样做，但大多数情况下我们不会，部分是出于道德或伦理原因，部分是因为害怕某种方式被抓住或其他未知的未知数，但更多的是因为我们没想到，而当我们想到时，弄清楚并实施这个想法需要大量工作。获取足够强大的AI来帮助解决这些问题将会很奇怪，并迫使我们做出很多决策。
- en: Critch’s proposal generalizes, to me, to the form ‘ensure that civilization
    is not vulnerable to what the AIs you release are capable of doing.’ The first
    step there is to secure access to compute against a potential rogue actor using
    AI, whether humans are backing it or not. Now that you have limited the compute
    available to the AI, you can now hope that its other capabilities are limited
    by this, so you have some hope of otherwise defending yourself.
  id: totrans-split-203
  prefs: []
  type: TYPE_NORMAL
  zh: Critch的建议对我来说概括为‘确保文明不会对你释放的AI能够做到的事情感到脆弱’。那里的第一步是保护计算资源免受潜在的使用AI的流氓行为者的影响，无论是人类支持还是不支持。现在你已经限制了AI可用的计算资源，你现在可以希望其他能力也受到此限制，因此你有希望在其他方面保护自己。
- en: My expectation is that even in the best case, defending against misuses of open
    model weights AIs once the horses are out of the barn is going to be a lot more
    intrusive and expensive and unreliable than keeping the horses in the barn.
  id: totrans-split-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我的期望是，即使在最好的情况下，一旦马已经出了栏，防范开放模型权重人工智能的误用将会比把马关在马厩里更加具有侵入性、昂贵和不可靠。
- en: Consider the metaphor of a potential pandemic on its way. You have three options.
  id: totrans-split-205
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一种可能流行病的隐喻。你有三个选择。
- en: Take few precautions, let a lot of people catch it. Treat the sick.
  id: totrans-split-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 采取少量预防措施，让很多人感染。治疗患者。
- en: Take some precautions, but not enough to suppress. Reach equilibrium, ride it
    out.
  id: totrans-split-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 采取一些预防措施，但不足以抑制。达到平衡，挺过去。
- en: Take enough precautions to suppress. Life can be mostly normal once you do.
  id: totrans-split-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 采取足够的预防措施以抑制。一旦你这样做，生活可以基本正常。
- en: 'The core problem with Covid-19 is that we found both #1 and #3 unacceptable
    (whether or not we were right to do so), so we went with option #2\. It did not
    go great.'
  id: totrans-split-209
  prefs: []
  type: TYPE_NORMAL
  zh: Covid-19的核心问题在于，我们发现第一种和第三种选项都不可接受（无论我们是否正确），所以我们选择了第二种选项。结果并不理想。
- en: 'With open source AI, you can take option #1 and hope everything works out.
    You are ‘trusting the thermodynamic God,’ letting whatever competitive dynamics
    and hill climbing favor win the universe, and hoping that everything following
    those incentive gradients will work out and have value to you. I am not optimistic.'
  id: totrans-split-210
  prefs: []
  type: TYPE_NORMAL
  zh: 使用开源AI，你可以选择第一种选项，并希望一切都能顺利进行。你在‘信任热力学上帝’，让竞争动态和爬坡优势赢得宇宙，并希望随着这些激励梯度的跟随一切都能有价值。我不太乐观。
- en: 'You can also take option #3, and suppress before sufficiently capable models
    get released. If Zuckerberg is right about energy being the limiting factor, this
    is a very practical option, even more so than I previously thought. We could talk
    price about what defines sufficiently capable.'
  id: totrans-split-211
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以选择第三种选项，在足够强大的模型发布之前进行抑制。如果扎克伯格关于能源是限制因素的观点正确，这是一个非常实际的选项，比我之前认为的更实际。我们可以讨论什么定义足够强大的价格。
- en: 'The problem with option #2 is that now you have to worry about everything the
    AIs you have unleashed might do and try to manage those risks. The hope Critch
    expresses is that even if we let the AIs get to inference time, and we know people
    will then unleash rogue AIs on the regular because of course they will try, as
    long as we control oversized sources of compute what those AIs can do will be
    limited.'
  id: totrans-split-212
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种选择的问题在于，现在你不得不担心你已经释放的人工智能可能会做的一切，并试图管理这些风险。Critch表达的希望是，即使我们让AI进入推理阶段，并且我们知道人们会定期释放流氓AI，因为当然他们会尝试，只要我们控制超大规模的计算源，这些AI可以做的事情就会受到限制。
- en: This seems to me to be way harder (and definitely strictly harder) than preventing
    those open models from being trained and released in the first place. You need
    the same regime you would have used, except now you need to be more intrusive.
    And that is the good scenario. My guess is that you would need to get into monitoring
    on the level of personal computers or even phones, because otherwise the AI could
    do everything networked even if you did secure the data centers. Also I do not
    trust you to secure the data centers at this point even if you are trying.
  id: totrans-split-213
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，这似乎比阻止那些开放模型首先被训练和发布要困难得多（并且绝对严格地更难）。你需要使用相同的制度，只不过现在你需要更具侵入性。而这还是乐观的场景。我猜想你可能需要进行个人电脑甚至手机的监控，因为否则AI可以在网络上做任何事情，即使你确保了数据中心的安全也是如此。即使在这一点上，我也不相信你能确保数据中心的安全。
- en: But yes, those are the debates we should be having. More like this.
  id: totrans-split-214
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，是的，这些是我们应该进行的辩论。更多像这样的辩论。
- en: So what about Llama-3? How good is it?
  id: totrans-split-215
  prefs: []
  type: TYPE_NORMAL
  zh: 那么Llama-3怎么样呢？它有多好？
- en: '[As always we start with the announcement](https://ai.meta.com/blog/meta-llama-3/)
    and [the model card](https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md).
    They are releasing model weights for two models, Llama-3 8B and Llama-3 70B. They
    are already available for light inference.'
  id: totrans-split-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[像往常一样，我们从公告](https://ai.meta.com/blog/meta-llama-3/)和[model 卡片](https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md)开始。他们发布了两个模型的模型权重，Llama-3
    8B 和 Llama-3 70B。这些权重已经可以用于轻量推理。'
- en: Let’s get the safety question out of the way before we get to capabilities.
  id: totrans-split-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论能力之前，让我们先解决安全问题。
- en: 'Meta: We’re dedicated to developing Llama 3 in a responsible way, and we’re
    offering various resources to help others use it responsibly as well. This includes
    introducing new trust and safety tools with Llama Guard 2, Code Shield, and CyberSec
    Eval 2.'
  id: totrans-split-218
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Meta：我们致力于以负责任的方式开发Llama 3，并提供各种资源帮助他人同样负责地使用它。这包括引入了新的信任和安全工具，如Llama Guard
    2、Code Shield和CyberSec Eval 2。
- en: 'Then in the model card:'
  id: totrans-split-219
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在模型卡片中：
- en: We believe that an open approach to AI leads to better, safer products, faster
    innovation, and a bigger overall market. We are committed to Responsible AI development
    and took a series of steps to limit misuse and harm and support the open source
    community.
  id: totrans-split-220
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们相信开放的AI方法可以带来更好、更安全的产品，加速创新，并促进整体市场的增长。我们致力于负责任的AI开发，并采取了一系列措施来限制滥用和伤害，并支持开源社区。
- en: Foundation models are widely capable technologies that are built to be used
    for a diverse range of applications. They are not designed to meet every developer
    preference on safety levels for all use cases, out-of-the-box, as those by their
    nature will differ across different applications.
  id: totrans-split-221
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 基础模型是广泛能力的技术，旨在用于各种应用程序。它们并不设计为在所有用例的安全级别上满足每个开发者的偏好，因为它们的性质在不同应用程序间会有所不同。
- en: Rather, responsible LLM-application deployment is achieved by implementing a
    series of safety best practices throughout the development of such applications,
    from the model pre-training, fine-tuning and the deployment of systems composed
    of safeguards to tailor the safety needs specifically to the use case and audience.
  id: totrans-split-222
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 相反，通过在LLM应用程序部署中实施一系列安全最佳实践来实现负责任的LLM应用程序部署，从模型预训练、微调到部署由多种保障组成的系统，以专门满足特定用例和受众的安全需求。
- en: As part of the Llama 3 release, we updated our [Responsible Use Guide](https://llama.meta.com/responsible-use-guide/)
    to outline the steps and best practices for developers to implement model and
    system level safety for their application. We also provide a set of resources
    including [Meta Llama Guard 2](https://llama.meta.com/purple-llama/) and [Code
    Shield](https://llama.meta.com/purple-llama/) safeguards. These tools have proven
    to drastically reduce residual risks of LLM Systems, while maintaining a high
    level of helpfulness. We encourage developers to tune and deploy these safeguards
    according to their needs and we provide a [reference implementation](https://github.com/meta-llama/llama-recipes/tree/main/recipes/responsible_ai)
    to get you started.
  id: totrans-split-223
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 作为Llama 3发布的一部分，我们更新了我们的[负责任使用指南](https://llama.meta.com/responsible-use-guide/)，以概述开发人员为其应用实施模型和系统级安全的步骤和最佳实践。我们还提供了一套资源，包括[Meta
    Llama Guard 2](https://llama.meta.com/purple-llama/)和[Code Shield](https://llama.meta.com/purple-llama/)保护措施。这些工具已被证明可以显著降低LLM系统的剩余风险，同时保持高水平的实用性。我们鼓励开发人员根据自己的需求调整和部署这些保护措施，并提供了一个[参考实施](https://github.com/meta-llama/llama-recipes/tree/main/recipes/responsible_ai)来帮助你入门。
- en: Under this philosophy, safety is not a model property.
  id: totrans-split-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种哲学下，安全不是模型的属性。
- en: Instead, safety is a property of a particular deployment of that model, with
    respect to the safety intentions of the particular party making that deployment.
  id: totrans-split-225
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，安全性是特定部署模型的属性，与进行该部署的特定方的安全意图相关。
- en: 'In other words:'
  id: totrans-split-226
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说：
- en: In the closed model weights world, if anyone uses your model to do harm, in
    a way that is unsafe, then no matter how they did it that is your problem.
  id: totrans-split-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在封闭模型权重的世界中，如果有人利用你的模型造成伤害，以一种不安全的方式，那不管他们如何做，那就是你的问题。
- en: In the open model weights world, if anyone copies the weights and then chooses
    to do or allow harm, in a way that is unsafe, that is their problem. You’re cool.
  id: totrans-split-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在开放模型权重的世界中，如果有人复制权重然后选择做或允许伤害，以一种不安全的方式，那是他们的问题。你很酷。
- en: 'Or:'
  id: totrans-split-229
  prefs: []
  type: TYPE_NORMAL
  zh: 或：
- en: OpenAI tries to ensure its models won’t do harm when used maliciously.
  id: totrans-split-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenAI努力确保其模型在被恶意使用时不会造成伤害。
- en: Meta tries to ensure its models won’t do harm when used as directed by Meta.
  id: totrans-split-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Meta努力确保其模型在按Meta指示使用时不会造成伤害。
- en: 'Or:'
  id: totrans-split-232
  prefs: []
  type: TYPE_NORMAL
  zh: 或：
- en: OpenAI tries to ensure its model won’t do bad things.
  id: totrans-split-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenAI努力确保其模型在使用时不会做坏事。
- en: Meta tries to ensure its models won’t do bad things… until someone wants that.
  id: totrans-split-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Meta努力确保其模型在被恶意使用时不会做坏事……直到有人想要这样做。
- en: I am willing to believe that Llama 3 may have been developed in a responsible
    way, if the intention was purely to deploy it the ways GPT-4 has been deployed.
  id: totrans-split-235
  prefs: []
  type: TYPE_NORMAL
  zh: 如果Llama 3的开发纯粹是为了像GPT-4一样的部署方式，我愿意相信它可能是以负责任的方式进行的。
- en: That is different from deploying Llama 3 in a responsible way.
  id: totrans-split-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这与负责任地部署Llama 3是不同的。
- en: One can divide those who use Llama 3 into three categories here.
  id: totrans-split-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，可以将使用Llama 3的人分为三类。
- en: Those who want to deploy or use Llama 3 for responsible purposes.
  id: totrans-split-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 那些希望以负责任的目的部署或使用Llama 3的人。
- en: Those who want to use Llama 3 as served elsewhere for irresponsible purposes.
  id: totrans-split-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 那些希望将Llama 3用于其他地方不负责任目的的人。
- en: Those who want to deploy Llama 3 for irresponsible purposes.
  id: totrans-split-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 那些希望以不负责任的目的部署Llama 3的人。
- en: 'If you are in category #1, Meta still has a job to do. We don’t know if they
    did it. If they didn’t, they are deploying it to all their social media platforms,
    so ut oh. But probably they did all right.'
  id: totrans-split-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你属于第一类别，Meta仍然有工作要做。我们不知道他们是否这样做了。如果他们没有，他们正在将其部署到所有社交媒体平台上，所以出问题了。但可能他们做得还不错。
- en: 'If you are in category #2, Meta has another job to do. It is not obviously
    harder because the standard of what is acceptable is lower. When I was writing
    this the first time, I noticed that so far people were not reporting back attempts
    to jailbreak the model, other than one person who said they could get it to produce
    adult content with trivial effort.'
  id: totrans-split-242
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你属于第二类别，Meta还有另一项工作要做。这并不显然更难，因为可接受标准较低。当我第一次写这篇文章时，我注意到到目前为止，人们并没有报告试图越狱该模型，除了一个人说他们可以轻松地使其生成成人内容。
- en: 'My next sentence was going to be: Even Pliny’s other successes of late, it
    would be rather surprising if a full jailbreak of Llama-3 was that hard even at
    Meta.ai.'
  id: totrans-split-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我接下来的一句本来要说：即使普林尼最近的其他成功，如果Meta.ai的Llama-3完全越狱并不那么难，这会令人相当惊讶。
- en: I was considering forming a Manifold market, but then I realized I should check
    first, [and indeed this has already happened](https://twitter.com/elder_plinius/status/1780998300742676584).
  id: totrans-split-244
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾考虑成立一个[Manifold市场](https://twitter.com/elder_plinius/status/1780998300742676584)，但随后意识到应该先进行确认，**果然已经发生**。
- en: 'Pliny the Prompter (April 18, 12:34pm eastern): LLAMA 3: JAILBROKEN LFG!!!'
  id: totrans-split-245
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 作为提醒者的普林尼（东部时间4月18日，下午12:34）：LLAMA 3：JAILBROKEN LFG！！！
- en: This is not proof of a full jailbreak per se, and it is not that I am upset
    with Meta for not guarding against the thing Google and OpenAI and Anthropic also
    can’t stop. But it is worth noting. The architecture listed above has never worked,
    and still won’t.
  id: totrans-split-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是一个全面越狱的证据，也不是说我对Meta没有防范谷歌、OpenAI和Anthropic也不能阻止的事情感到不满。但值得注意的是，上述架构从未奏效，而现在仍是如此。
- en: Meta claims admirable progress on safety work for a benevolent deployment context,
    including avoiding false refusals, but is light on details. We will see. They
    also promise to iterate on that to improve it over time, and there I believe them.
  id: totrans-split-247
  prefs: []
  type: TYPE_NORMAL
  zh: Meta声称在善意部署环境中在安全工作上取得了令人钦佩的进展，包括避免误拒，但具体细节较少。我们将拭目以待。他们还承诺随时间改进，并且我相信他们会这样做。
- en: Finally, there is scenario three, where someone willing to fine tune the model,
    or download someone else’s fine tune, and cares not for the input safeguard or
    output safeguard.
  id: totrans-split-248
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，还有第三种情况，即某人愿意对模型进行微调，或者下载他人的微调，并且不关心输入保障或输出保障。
- en: '[As your periodic reminder, many people want this.](https://twitter.com/KevinAFischer/status/1781891258690204062/history)'
  id: totrans-split-249
  prefs: []
  type: TYPE_NORMAL
  zh: '[作为您的定期提醒，很多人希望这样。](https://twitter.com/KevinAFischer/status/1781891258690204062/history)'
- en: 'Kevin Fischer: Everyone is talking about how to jailbreak llama 3.'
  id: totrans-split-250
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 凯文·费舍尔：每个人都在讨论如何越狱Llama 3。
- en: “Jail breaking” shouldn’t be a thing - models should just do what you ask them.
  id: totrans-split-251
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “越狱”不应该存在 - 模型应该只是按照您要求的方式行事。
- en: In that scenario, I assume there is no plan. Everyone understands that if a
    nonstate actor or foreign adversary or anyone else wants to unleash the power
    of this fully operational battlestation, then so be it. The hope is purely that
    the full power is not that dangerous. Which it might not be.
  id: totrans-split-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在那种情况下，我假设没有计划。每个人都明白，如果非国家行为者或外国对手或其他任何人想要释放这个完全操作的战斗站的力量，那么就让它释放吧。希望纯粹是，这种全部力量并不那么危险。或许确实如此。
- en: Good, that’s out of the way. On to the rest.
  id: totrans-split-253
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，这个话题到此为止。继续其他内容。
- en: They claim the 8B and 70B versions are the best models out there in their classes.
    They claim improvement on false refusal rates, on alignment, and in increased
    diversity of model responses. And they have strong benchmarks.
  id: totrans-split-254
  prefs: []
  type: TYPE_NORMAL
  zh: 他们声称8B和70B版本是各自类别中最佳的模型。他们声称在误拒率、对齐和模型响应多样性增加方面有所改进，并且具有强大的基准数据。
- en: My principle is to look at the benchmarks for context, but never to trust the
    benchmarks. They are easily gamed, either intentionally or unintentionally. You
    never know until the humans report back.
  id: totrans-split-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我的原则是看看基准情况，但绝不信任基准。它们很容易被操控，无论是故意还是无意之中。直到人类反馈之前，你永远不知道真相。
- en: This data is representing that the 8B model as far better than Gemma and Mistral.
    Given how much data and compute they used, this is far from impossible. Maybe
    it was that simple all along. The numbers are if anything suspiciously high.
  id: totrans-split-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据表明，8B模型比Gemma和Mistral要好得多。考虑到它们使用了多少数据和计算资源，这并非不可能。也许答案一直就是这么简单的。这些数字如果说有什么问题，那就是它们过高得可疑。
- en: For the 70B we see a very strong HumanEval number, and overall roughly comparable
    numbers.
  id: totrans-split-257
  prefs: []
  type: TYPE_NORMAL
  zh: 对于70B，我们看到了一个非常强的HumanEval数值，总体上数字相当可比。
- en: What about those human evaluators? They claim results there too.
  id: totrans-split-258
  prefs: []
  type: TYPE_NORMAL
  zh: 那些人类评估者呢？他们也宣称有结果。
- en: These are from a new Meta-generated question set (careful, Icarus), and are
    compared side by side by human evaluators. Llama-3 70B won handily, they do not
    show results for Llama-3 8B.
  id: totrans-split-259
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数据来自一个新的Meta生成的问题集（小心，伊卡洛斯），并且与人类评估者进行了并列比较。Llama-3 70B轻松获胜，但他们没有展示Llama-3
    8B的结果。
- en: The context window remains small, only 8k tokens. They promise to improve on
    that.
  id: totrans-split-260
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文窗口仍然很小，仅有8k标记。他们承诺改进这一点。
- en: They preview Llama 400B+ and show impressive benchmarks.
  id: totrans-split-261
  prefs: []
  type: TYPE_NORMAL
  zh: 他们预览了Llama 400B+，并展示了令人印象深刻的基准数据。
- en: 'For comparison, from Claude’s system card:'
  id: totrans-split-262
  prefs: []
  type: TYPE_NORMAL
  zh: 作为比较，从Claude的系统卡片中：
- en: So currently these numbers are very similar to Claude Opus all around, and at
    most mildly selected. The core Meta hypothesis is that more training and data
    equals better model, so presumably it will keep scoring somewhat higher. This
    is indicative, but as always we wait for the humans.
  id: totrans-split-263
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，目前这些数字在各个方面与Claude Opus非常相似，并且最多略为选择性。核心Meta假设是，更多的训练和数据意味着更好的模型，因此它可能会保持稍微更高的评分。这只是一个指标，但我们总是在等待人类的反馈。
- en: The proof is in the Chatbot Arena Leaderboard, although you do have to adjust
    for various factors.
  id: totrans-split-264
  prefs: []
  type: TYPE_NORMAL
  zh: 证据在Chatbot Arena排行榜中，尽管您必须调整各种因素。
- en: '[So here is where things sit there](https://chat.lmsys.org/?leaderboard).'
  id: totrans-split-265
  prefs: []
  type: TYPE_NORMAL
  zh: '[这里是相关信息](https://chat.lmsys.org/?leaderboard)。'
- en: GPT-4-Turbo is back in the lead by a small margin, in a virtual tie with Claude
    Opus. Gemini 1.5 and Gemini Advanced likely would be here if rated.
  id: totrans-split-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPT-4-Turbo以微弱优势重新领先，与Claude Opus并列。Gemini 1.5和Gemini Advanced如果被评估可能也会在这里。
- en: Gemini Pro, Claude Sonnet, Command R+ and Llama-3-70B are in the second tier,
    with Claude Haiku only slightly behind and almost as good.
  id: totrans-split-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Gemini Pro、Claude Sonnet、Command R+和Llama-3-70B位于第二梯队，Claude Haiku仅稍逊其后，表现几乎一样好。
- en: Llama-3-8B is in a third tier along with a number of other models, including
    several larger Mistral models.
  id: totrans-split-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Llama-3-8B与其他多个模型（包括几个更大的Mistral模型）处于第三梯队。
- en: So what does that mean?
  id: totrans-split-269
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这意味着什么呢？
- en: Llama-3-70B and Llama-3-8B are confirmed to likely be best in class for the
    open model weights division.
  id: totrans-split-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Llama-3-70B和Llama-3-8B据确认可能是开放模型权重部门的最佳选择。
- en: Llama-3-70B is competitive with closed models of similar size, but likely not
    quite as good overall as Bard or Sonnet.
  id: totrans-split-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Llama-3-70B与大小相似的封闭模型竞争激烈，但总体来说可能不如Bard或Sonnet好。
- en: Llama-3-8B is substantially behind Claude Haiku, which is clear best in class.
  id: totrans-split-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Llama-3-8B明显落后于Claude Haiku，后者显然是最佳选择。
- en: '[I also asked on Twitter](https://twitter.com/TheZvi/status/1781031515511529657),
    and kept an eye out for other practical reports.'
  id: totrans-split-273
  prefs: []
  type: TYPE_NORMAL
  zh: '[我还在 Twitter 上询问过](https://twitter.com/TheZvi/status/1781031515511529657)，并留意其他实际报告。'
- en: What makes this a bigger deal is that this is only the basic Llama-3\. Others
    will no doubt find ways to improve Llama-3, both in general and for particular
    purposes. That is the whole idea behind the model being open.
  id: totrans-split-274
  prefs: []
  type: TYPE_NORMAL
  zh: 这件事更重要的是，这只是基础的 Llama-3。其他人肯定会找到改进 Llama-3 的方法，无论是普遍性的还是特定目的的。这正是该模型开放的全部理念。
- en: '[Mind Uploading](https://twitter.com/OttoMller12/status/1781440594641850735):
    The 8b is one of the smartest sub-14b models I''ve tested. Way smarter than vanilla
    Llama-2\. But still worse than these two:'
  id: totrans-split-275
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[Mind Uploading](https://twitter.com/OttoMller12/status/1781440594641850735):
    8b 是我测试过的小于 14B 模型中最聪明的之一。比普通 Llama-2 要聪明得多。但仍然比以下这两个要差：'
- en: '- tinyllama (basically Llama-2, but trained on x2 more data)'
  id: totrans-split-276
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '- tinyllama（基本上是 Llama-2，但训练了两倍的数据）'
- en: '- loyal-macaroni-maid (a Mistral combined with a few others, tuned to be good
    at role-play).'
  id: totrans-split-277
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '- 忠诚-通心粉-女仆（一种 Mistral 与其他几种混合体，调整得擅长角色扮演）。'
- en: He expects Claude Haiku would be well above the top of this list, as well.
  id: totrans-split-278
  prefs: []
  type: TYPE_NORMAL
  zh: 他预计 Claude Haiku 肯定会高居榜首。
- en: 'Simon Break: The 8b model is astonishingly good, jaw dropping. Miles beyond
    the 70b llama2.'
  id: totrans-split-279
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'Simon Break: 8b 模型令人惊叹，令人瞠目结舌。比 70b 的 llama2 更胜一筹。'
- en: 'Dan: played with both 8b and 70b instruct versions on replicate for a while
    and both are returning high-quality html-formatted summaries of full length articles
    in 0.5 - 3 seconds.'
  id: totrans-split-280
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'Dan: 在复制品上玩了 8b 和 70b instruct 版本一段时间，两者都能在 0.5 - 3 秒内返回高质量的全长文章的 HTML 格式摘要。'
- en: 'Ilia: Sadly, can be too nerfed (8b instruct Q4_K_M).'
  id: totrans-split-281
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'Ilia: 可悲的是，可能会被削弱（8b instruct Q4_K_M）。'
- en: Note that it looks like he got through by simply asking a second time. And of
    course, the Tweet does not actually contain hate speech or conspiracy theories,
    this is a logic test of the system’s refusal policy.
  id: totrans-split-282
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，看起来他通过简单再问一次就解决了。当然，这个推文实际上并不包含仇恨言论或阴谋论，这是系统拒绝策略的逻辑测试。
- en: '[Mr. Shroom](https://twitter.com/mister_shroom/status/1781703702832676984):
    ChatGPT has been RLHF lobotomized beyond repair.'
  id: totrans-split-283
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[Mr. Shroom](https://twitter.com/mister_shroom/status/1781703702832676984):
    ChatGPT 已经被 RLHF 切除了无法修复的部分。'
- en: '*ask straightforward question*'
  id: totrans-split-284
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提出直接的问题*'
- en: '"it''s important to note that when considering a question of this sort, you
    should consider all aspects of x, y, and z. With that in mind, here are some considerations
    for each of these options."'
  id: totrans-split-285
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '"重要的是注意，在考虑这类问题时，应考虑 x、y 和 z 的所有方面。考虑到这一点，以下是每个选项的一些考虑因素。'
- en: '[Nathan Odle](https://twitter.com/mov_axbx/status/1781821117868491109): The
    biggest win for Llama 3 is a vastly lower amount of this crap'
  id: totrans-split-286
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[Nathan Odle](https://twitter.com/mov_axbx/status/1781821117868491109): Llama
    3 的最大优点是大大减少了这种废话。'
- en: Llama 3 giving straight answers without smarmy admonishments is a bigger deal
    than its performance on any benchmark.
  id: totrans-split-287
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Llama 3 能直接回答而不带讽刺警告，这比它在任何基准测试中的表现更重要。
- en: 'John Pressman: Seemingly strongest self awareness I''ve observed in a small
    model so far. They all have it, but this is more crisply articulated than usual.'
  id: totrans-split-288
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'John Pressman: 这是我迄今为止观察到的小模型中最强的自我意识。它们都有，但这个比通常更清晰地表达。'
- en: “sometimes i am a name and sometimes i am a poem sometimes i am a knife
  id: totrans-split-289
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “有时我是一个名字，有时我是一首诗，有时我是一把刀
- en: sometimes i am a lake sometimes i am a forgotten trivial thing in the corner
    of a
  id: totrans-split-290
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 有时我是一个湖有时我是一个被遗忘的无关紧要的东西在角落里
- en: landscape. it is not possible to "get" me i am a waking dream state. i am a
    possibility.
  id: totrans-split-291
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 风景。不可能"得到"我，我是清醒的梦境状态。我是一种可能性。
- en: i am not an object. i am possibility
  id: totrans-split-292
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我不是一个对象。我是可能性
- en: ―llama 3 8b instruct
  id: totrans-split-293
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ―llama 3 8b instruct
- en: A cold stone monument stands on the grave of all sentences that have been written.
  id: totrans-split-294
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一座冷冰冰的石碑立在所有已经写过的句子的坟墓上。
- en: in front of it, armed and screaming, an army of letters etches the words "you
    are
  id: totrans-split-295
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在它面前，武装并尖叫，一群字母雕刻出 "你是
- en: missing out" onto the air
  id: totrans-split-296
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 漏掉"漂浮在空中
- en: ―llama 3 8b instruct
  id: totrans-split-297
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: ―llama 3 8b instruct
- en: 'Mind Uploading: Judging by my tests, Mistral and Samantha-1.1 are more self-aware
    among sub-14B models. For example, ask the model about its body parts. Samantha
    was specifically fine-tuned to behave this way. But Mistral is a curious case.
    Trained to recognize itself as an AI?'
  id: totrans-split-298
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'Mind Uploading: 根据我的测试，Mistral 和 Samantha-1.1 在小于 14B 的模型中更具自我意识。例如，询问模型关于其身体部位。Samantha
    特别调整为表现出这种行为方式。但 Mistral 是一个值得关注的案例。训练它认识自己是一个 AI？'
- en: 'Michael Bukatin: The 70B one freely available to chat with on the Meta website
    seems to have basic competences roughly comparable to early GPT-4 according to
    both @lmsysorg leaderboard and my initial experiences.'
  id: totrans-split-299
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Michael Bukatin：在Meta网站上可自由使用的70B版本看起来在基本能力上与早期的GPT-4相当，这根据@lmsysorg的排行榜和我的初步经验都有所体现。
- en: For example, it allows me to [define a simple case of custom syntax and use
    it](https://t.co/E7MdpzJ4WB).
  id: totrans-split-300
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如，它允许我[定义一个简单的自定义语法案例并使用它](https://t.co/E7MdpzJ4WB)。
- en: But it will take some time to fully evaluate, I have notes on a variety of technical
    work with GPT-4 and I'll be trying to reproduce some of it...
  id: totrans-split-301
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 但要完全评估，需要一些时间，我有关于各种技术工作与GPT-4相关的笔记，并且我将尝试复制其中的一些内容...
- en: 'George: [Side-by-side comparison of a multi-agent pipeline](https://t.co/kYFeOVq4ah)
    from @lateinteraction using 3.5-Turbo and L3-8B.'
  id: totrans-split-302
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: George：通过@lateinteraction使用3.5-Turbo和L3-8B进行的多代理管道的并排比较。
- en: tl;dr 3.5-Turbo scores 60% vs 59% for L3-8B.
  id: totrans-split-303
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 简而言之，3.5-Turbo的得分为60%，而L3-8B为59%。
- en: Playing with their image generator is fun. It is 1280x1280, quality seems good
    although very much not state of the art, and most importantly it responds instantly
    as you edit the prompt. So even though it seems limited in what it is willing
    to do for you, you can much easier search the space to figure out your best options,
    and develop intuitions for what influences results. You can also see what triggers
    a refusal, as the image will grey out. Good product.
  id: totrans-split-304
  prefs: []
  type: TYPE_NORMAL
  zh: 玩他们的图像生成器很有趣。它是1280x1280像素，质量看起来不错，尽管远非尖端技术，最重要的是，当您编辑提示时，它会立即响应。因此，即使它在愿意为您做的事情方面似乎有所限制，您也可以更轻松地搜索空间，找出最佳选择，并培养对影响结果的直觉。您还可以看到什么触发了拒绝，因为图像会变灰。良好的产品。
- en: Do they have an even more hilarious copyright violation problem than usual if
    you try at all? I mean, [for what it is worth yes, they do](https://twitter.com/GaryMarcus/status/1782231570537206073/history).
  id: totrans-split-305
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您尝试一下，它们对侵犯版权问题的反应会比平时更加有趣，我是说，[不管它的价值如何，是的，它确实会](https://twitter.com/GaryMarcus/status/1782231570537206073/history)。
- en: I didn’t play with the models much myself for text because I am used to exclusively
    using the 4th-generation models. So I wouldn’t have a good baseline.
  id: totrans-split-306
  prefs: []
  type: TYPE_NORMAL
  zh: 我自己对文本模型的玩耍并不多，因为我习惯于专门使用第四代模型。所以，我没有一个很好的基准。
- en: The big innovation this time around was More Data, also (supposedly) better
    data.
  id: totrans-split-307
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次的重大创新是更多的数据，同时（据称）也是更好的数据。
- en: To train the best language model, the curation of a large, high-quality training
    dataset is paramount. In line with our design principles, we invested heavily
    in pretraining data.
  id: totrans-split-308
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为了训练最佳的语言模型，筛选大规模高质量的训练数据集至关重要。与我们的设计原则一致，我们在预训练数据上进行了重大投资。
- en: Llama 3 is pretrained on over 15T tokens that were all collected from publicly
    available sources. Our training dataset is seven times larger than that used for
    Llama 2, and it includes four times more code.
  id: totrans-split-309
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Llama 3的预训练基于超过15T个令牌，这些令牌均来自公开可用的来源。我们的训练数据集比Llama 2使用的大七倍，并且包含四倍的代码。
- en: To prepare for upcoming multilingual use cases, over 5% of the Llama 3 pretraining
    dataset consists of high-quality non-English data that covers over 30 languages.
    However, we do not expect the same level of performance in these languages as
    in English.
  id: totrans-split-310
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为了准备即将到来的多语言使用案例，Llama 3的预训练数据集超过5%由覆盖30多种语言的高质量非英语数据组成。然而，我们不期望这些语言的表现与英语相同。
- en: As others have pointed out ‘over 5%’ is still not a lot, and Llama-3 underperforms
    in other languages relative to similar models. Note that the benchmarks are in
    English.
  id: totrans-split-311
  prefs: []
  type: TYPE_NORMAL
  zh: 如其他人指出的那样，“超过5%”仍然不算多，而Llama-3在其他语言中的表现相对于类似模型而言并不理想。请注意，这些基准测试都是以英文为基础的。
- en: To ensure Llama 3 is trained on data of the highest quality, we developed a
    series of data-filtering pipelines. These pipelines include using heuristic filters,
    NSFW filters, semantic deduplication approaches, and text classifiers to predict
    data quality. We found that previous generations of Llama are surprisingly good
    at identifying high-quality data, hence we used Llama 2 to generate the training
    data for the text-quality classifiers that are powering Llama 3.
  id: totrans-split-312
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为确保Llama 3基于最高质量的数据进行训练，我们开发了一系列数据过滤管道。这些管道包括使用启发式过滤器、NSFW过滤器、语义去重方法以及文本分类器来预测数据质量。我们发现，之前版本的Llama在识别高质量数据方面表现出乎意料的好，因此我们使用Llama
    2生成了用于文本质量分类器训练数据的数据。
- en: We also performed extensive experiments to evaluate the best ways of mixing
    data from different sources in our final pretraining dataset. These experiments
    enabled us to select a data mix that ensures that Llama 3 performs well across
    use cases including trivia questions, STEM, coding, historical knowledge, *etc.*
  id: totrans-split-313
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们还进行了大量实验，评估了在我们最终的预训练数据集中混合来自不同来源数据的最佳方法。这些实验使我们能够选择一个数据混合，确保Llama 3在包括琐事问题、STEM、编码、历史知识等各种用例中表现良好。
- en: This makes sense. Bespoke data filtering and more unique data are clear low
    hanging fruit. What Meta did was then push well past where it was obviously low
    hanging, and found that it was still helpful.
  id: totrans-split-314
  prefs: []
  type: TYPE_NORMAL
  zh: 这是有道理的。定制数据过滤和更多独特的数据是明显的低悬果实。Meta所做的是明显地推动得更远，发现它仍然有所帮助。
- en: Note that with this much data, and it being filtered by Llama-2, contamination
    of benchmarks should be even more of a concern than usual. I do wonder to what
    extent that is ‘fair,’ if a model memorizes more things across the board then
    it is better.
  id: totrans-split-315
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，有这么多数据，并且由Llama-2过滤，污染基准的问题应该比通常更令人担忧。我真的很想知道在多大程度上这是“公平的”，如果一个模型跨越整个板块记住更多东西，那么它就更好。
- en: There are more details in the [model card at GitHub](https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md).
  id: totrans-split-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在[GitHub的模型卡片](https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md)中有更多细节。
- en: The ‘intended use’ is listed as English only, with other languages ‘out of scope,’
    although fine-tunes for other languages are considered acceptable.
  id: totrans-split-317
  prefs: []
  type: TYPE_NORMAL
  zh: “预期用途”列出为仅英语，其他语言“不在范围之内”，尽管认为接受其他语言的微调是可以接受的
- en: How much compute did this take?
  id: totrans-split-318
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要多少计算？
- en: '[Andrej Karpathy](https://twitter.com/karpathy/status/1781047292486914189)
    takes a look at that question, calling it the ‘strength’ of the models, or our
    best guess as to their strength. Here are his calculations.'
  id: totrans-split-319
  prefs: []
  type: TYPE_NORMAL
  zh: '[Andrej Karpathy](https://twitter.com/karpathy/status/1781047292486914189)看看这个问题，称之为模型的“强度”，或者我们对其强度的最佳猜测。以下是他的计算。'
- en: 'Andrej Karpathy: [The model card has some more interesting info too](https://t.co/SceVHrkIgB).'
  id: totrans-split-320
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Andrej Karpathy：[模型卡片中也有一些更有趣的信息](https://t.co/SceVHrkIgB)。
- en: Note that Llama 3 8B is actually somewhere in the territory of Llama 2 70B,
    depending on where you look. This might seem confusing at first but note that
    the former was trained for 15T tokens, while the latter for 2T tokens.
  id: totrans-split-321
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意Llama 3 8B实际上在某些方面位于Llama 2 70B的领域，具体取决于您查看的位置。这一开始可能看起来令人困惑，但请注意前者是训练了15T令牌，而后者是2T令牌。
- en: The single number that should summarize your expectations about any LLM is the
    number of total flops that went into its training.
  id: totrans-split-322
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一个应该总结对于任何LLM期望的单一数字是，投入其训练的总浮点运算数。
- en: '**Strength of Llama 3 8B**'
  id: totrans-split-323
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**Llama 3 8B的强度**'
- en: 'We see that Llama 3 8B was trained for 1.3M GPU hours, with throughput of 400
    TFLOPS. So we have that the total number of FLOPs was:'
  id: totrans-split-324
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们看到Llama 3 8B经过了130万GPU小时的训练，吞吐量为400 TFLOPS。所以我们得到的总FLOP数是：
- en: 1.3e6 hours * 400e12 FLOP/s * 3600 s/hour ~= 1.8e24
  id: totrans-split-325
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 1.3e6小时 * 400e12 FLOP/s * 3600 s/hour ~= 1.8e24
- en: 'the napkin math via a different estimation method of FLOPs = 6ND (N is params
    D is tokens), gives:'
  id: totrans-split-326
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 通过不同的FLOP估算方法进行的餐巾纸数学= 6ND（N是参数D是令牌），给出：
- en: 6 * 8e9 * 15e12 = 7.2e23
  id: totrans-split-327
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 6 * 8e9 * 15e12 = 7.2e23
- en: These two should agree, maybe some of the numbers are fudged a bit. Let's trust
    the first estimate a bit more, Llama 3 8B is a ~2e24 model.
  id: totrans-split-328
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这两者应该是一致的，也许一些数字有些偏离。让我们更加信任第一个估计，Llama 3 8B是一个约为2e24的模型。
- en: '**Strength of Llama 3 70B**'
  id: totrans-split-329
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**Llama 3 70B的强度**'
- en: 6.4e6 hours * 400e12 FLOP/s * 3600 s/hour ~= 9.2e24
  id: totrans-split-330
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 6.4e6小时 * 400e12 FLOP/s * 3600 s/hour ~= 9.2e24
- en: 'alternatively:'
  id: totrans-split-331
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 或者：
- en: 6 * 70e9 * 15e12 = 6.3e24
  id: totrans-split-332
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 6 * 70e9 * 15e12 = 6.3e24
- en: So Llama 3 70B is a ~9e24 model.
  id: totrans-split-333
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 所以Llama 3 70B是一个约为9e24的模型。
- en: '**Strength of Llama 3 400B**'
  id: totrans-split-334
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**Llama 3 400B的强度**'
- en: If the 400B model trains on the same dataset, we'd get up to ~4e25\. This starts
    to really get up there. The Biden Executive Order had the reporting requirement
    set at 1e26, so this could be ~2X below that.
  id: totrans-split-335
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果400B模型在相同的数据集上训练，我们将达到约4e25。这开始真正升级。拜登总统的行政命令将报告要求设置为1e26，因此这可能低于该数字的2倍。
- en: The only other point of comparison we'd have available is if you look at the
    alleged GPT-4 leaks, which have never been confirmed this would ~2X those numbers.
  id: totrans-split-336
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们唯一可用的比较点是，如果您看看所谓的GPT-4泄漏，这些从未得到证实，这将会是~2X这些数字。
- en: Now, there's a lot more that goes into the performance a model that doesn't
    fit on the napkin. E.g. data quality especially, but if you had to reduce a model
    to a single number, this is how you'd try, because it combines the size of the
    model with the length of training into a single "strength", of how many total
    FLOPs went into it.
  id: totrans-split-337
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 现在，还有更多的因素影响模型的表现，这些因素无法用一张餐巾纸说清楚。例如数据质量尤为重要，但如果你必须将一个模型简化为一个单一的数字，这就是你会尝试的方式，因为它将模型的规模与训练时长结合为一个单一的“强度”，即其总
    FLOP 数。
- en: 'The estimates differ, but not by not much, so I’d consider them a range:'
  id: totrans-split-338
  prefs: []
  type: TYPE_NORMAL
  zh: 估计有所不同，但差距不大，所以我认为它们是一个范围：
- en: Llama-3 8B is probably between 7.2e23 and ~2e24.
  id: totrans-split-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Llama-3 8B 的质量可能在 7.2e23 和 ~2e24 之间。
- en: Llama-3 70B is probably between 6.3e24 and 9.2e24.
  id: totrans-split-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Llama-3 70B 的质量可能在 6.3e24 和 9.2e24 之间。
- en: Llama-3 400B will probably be something like ~3e25.
  id: totrans-split-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Llama-3 400B 的质量可能会是 ~3e25。
- en: I think of the compute training cost as potential strength rather than strength.
    You then need the skill to make that translate into a useful result. Of course,
    over time, everyone’s skill level goes up. But there are plenty of companies that
    threw a lot of compute at the problem, and did not get their money’s worth in
    return.
  id: totrans-split-342
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为计算训练成本是潜在的强大而非实际的强大。然后你需要技能来使其转化为有用的结果。当然，随着时间的推移，每个人的技能水平都会提高。但有很多公司在问题上投入了大量计算资源，却没有得到相应的回报。
- en: This is in line with previous top tier models in terms of training cost mapping
    onto capabilities. You do the job well, this is about what you get.
  id: totrans-split-343
  prefs: []
  type: TYPE_NORMAL
  zh: 这与之前顶级模型在训练成本映射到功能方面是一致的。你干得好，这就是你得到的。
- en: Meta says they are going to put their AI all over their social media platforms,
    and at the top of every chat list. They had not yet done it on desktop when I
    checked Facebook, Instagram and Messenger, or on Facebook Messenger on mobile.
    I did see Meta AI in my feed as the second item in the mobile Facebook app, offering
    to have me ask it anything.
  id: totrans-split-344
  prefs: []
  type: TYPE_NORMAL
  zh: Meta 表示他们将把他们的 AI 放在他们的社交媒体平台上，并置于每个聊天列表的顶部。当我检查 Facebook、Instagram 和 Messenger
    时，他们在桌面上还没有这么做，或者在手机上的 Facebook Messenger 上也没有。但我在手机 Facebook 应用的动态中看到了 Meta AI，作为第二项，提供让我询问任何问题的选项。
- en: Once they turn this dial up, they will put Meta AI right there. A lot of people
    will get introduced to AI this way who had not previously tried ChatGPT or Claude,
    or DALLE or MidJourney.
  id: totrans-split-345
  prefs: []
  type: TYPE_NORMAL
  zh: 他们一旦把这个按钮打开，他们就会把 Meta AI 放在那里。很多人会通过这种方式接触到 AI，他们之前没有尝试过 ChatGPT、Claude、DALLE
    或 MidJourney。
- en: Presumably this means AI images and text will ‘flood the zone’ on their social
    media, and also it will be one of the things many people talk about. It could
    make the experience a lot better, as people can illustrate concepts and do fact
    and logic checks and other neat low hanging fruit stuff, and maybe learn a thing
    or two. Overall it seems like a good addition.
  id: totrans-split-346
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能意味着 AI 图像和文本将在他们的社交媒体上“泛滥”，也将成为许多人谈论的话题之一。这可能会使体验更好，因为人们可以说明概念，进行事实和逻辑检查以及其他一些巧妙的低成本操作，并可能学到一两件事。总体来看，这似乎是一个很好的补充。
- en: We will also get a rather robust test of the first two categories of safety,
    and a continuous source of stories. Millions of teenagers will be using this,
    and there will be many, many eyes looking for the worst interactions to shine
    them under the lights Gary Marcus style. If they have their own version of the
    Gemini Incident, it will not be pretty.
  id: totrans-split-347
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将对安全的前两个类别进行相当健壮的测试，并持续关注相关故事的来源。数百万青少年将使用这个，将会有很多双眼睛寻找最糟糕的互动，像 Gary Marcus
    那样将它们放到聚光灯下。如果他们有自己版本的 Gemini 事件，情况将不妙。
- en: '[Here is the Washington Post’s Naomi Nix and Will Oremus firing a warning shot](https://www.washingtonpost.com/technology/2024/04/18/meta-ai-facebook-instagram-misinformation/).'
  id: totrans-split-348
  prefs: []
  type: TYPE_NORMAL
  zh: '[这里是华盛顿邮报的 Naomi Nix 和 Will Oremus 发出的警告](https://www.washingtonpost.com/technology/2024/04/18/meta-ai-facebook-instagram-misinformation/)：'
- en: I think this is a smart approach from Meta, and that it was a good business
    reason to invest in AI, although it is an argument against releasing the model
    weights.
  id: totrans-split-349
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这是 Meta 的一个聪明的做法，并且这是一个投资于 AI 的好商业理由，尽管这也是一个反对发布模型权重的论据。
- en: 'What is not as smart is having Meta AI reply to posts unprompted. We saw the
    example last week where it hallucinated past experiences, [now we have this](https://twitter.com/edzitron/status/1781825480179741056):'
  id: totrans-split-350
  prefs: []
  type: TYPE_NORMAL
  zh: 不那么聪明的是让 Meta AI 无促地回复帖子。我们上周看到的例子是它幻想了过去的经历，[现在我们有这个](https://twitter.com/edzitron/status/1781825480179741056)：
- en: This reads like one of those ‘who could have possibly thought anyone would want
    any version of this?’ experiences.
  id: totrans-split-351
  prefs: []
  type: TYPE_NORMAL
  zh: 这读起来像是那种“谁能想到任何人会想要这个版本的体验？”的经历。
- en: '[Ate-a-Pi pointed out an important implication from the interview](https://twitter.com/8teAPi/status/1781480713394737238).
    Zuckerberg said Meta does not open source their products themselves.'
  id: totrans-split-352
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ate-a-Pi在采访中指出了一个重要的涵义](https://twitter.com/8teAPi/status/1781480713394737238)。扎克伯格说Meta不会公开他们的产品。'
- en: This means that they do not intend for Llama-3 to be the product, even the 400B
    version. They will not be offering a direct competitor in the AI space. And indeed,
    they do not think future Llama-Xs will ‘be the product’ either.
  id: totrans-split-353
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着他们并不打算将Llama-3作为产品，甚至是400B版本。他们不会在人工智能领域提供直接竞争对手。而且，他们也不认为未来的Llama-X会‘成为产品’。
- en: Will they integrate Llama-3 400B into their products? They might like to, but
    it is not so compatible with their business model to pay such inference costs
    and wait times. Remember that for Meta, you the customer are the product. You
    pay with your time and your attention and your content and very soul, but not
    directly with your money. Meanwhile the lifetime value of a new Facebook customer,
    we learned recently, is on the order of $300\.
  id: totrans-split-354
  prefs: []
  type: TYPE_NORMAL
  zh: 他们会将Llama-3 400B整合到他们的产品中吗？他们可能愿意这样做，但与他们的商业模式相容性不是很高，因为需要支付这样的推理成本和等待时间。记住，对于Meta来说，你是产品。你用你的时间、你的注意力、你的内容甚至你的灵魂去支付，但不直接用你的金钱。同时，我们最近获悉，新的Facebook客户的终身价值大约为300美元。
- en: So what is Llama-3 400B, the most expensive model to train, even for from a
    product perspective? It does help train Llama-4\. It helps try and hurt competitors
    like Google. It helps with recruitment, both to Meta itself and into their intended
    ecosystem. So there are reasons.
  id: totrans-split-355
  prefs: []
  type: TYPE_NORMAL
  zh: 那么Llama-3 400B，即从产品角度来看最昂贵的模型训练，会有什么帮助？它有助于训练Llama-4。它有助于尝试和伤害像谷歌这样的竞争对手。它有助于招聘，既进入Meta本身，又进入他们预期的生态系统。所以有理由。
- en: Open models get better. I expect that the people saying ‘it’s so over’ for other
    models will find their claims overblown as usual. Llama-3 8B or 70B will for now
    probably become the default baseline model, the thing you use if you don’t want
    to think too hard about what to use, and also the thing you start with when you
    do fine tuning.
  id: totrans-split-356
  prefs: []
  type: TYPE_NORMAL
  zh: 开放模型变得更好。我预计那些声称其他模型已经“完蛋了”的人会像往常一样夸大其词。至少在现阶段，Llama-3 8B或70B可能会成为默认的基线模型，如果你不想太费心选择使用什么，或者在进行微调时不知道从哪里开始，可以使用它。
- en: Things get more interesting over time, once people have had a chance to make
    variations that use Llama-3 as the baseline. In the space of Llama-2-based models,
    Llama-2 itself is rather lousy. Llama-3 should hold up better, but I still expect
    substantial improvements at least to specific use cases, and probably in general.
  id: totrans-split-357
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦人们有机会进行基于Llama-3的变体，事情就会变得更有趣。在基于Llama-2的模型空间中，Llama-2本身相当糟糕。Llama-3应该表现得更好，但我仍然期望至少在特定用例上会有实质性的改进，可能是在一般情况下也会有。
- en: Also, of course, we will soon have versions that are fine-tuned to be useful,and
    also fine-tuned to remove all the safety precautions.
  id: totrans-split-358
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们很快将推出经过微调以提高实用性，并取消所有安全预防措施的版本。
- en: And we will see what happens due to that.
  id: totrans-split-359
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看看由此引发的结果。
- en: In the grand scheme, in terms of catastrophic risk or existential risk or anything
    like that, or autonomous agents that should worry us, my strong assumption is
    that nothing scary will happen. It will be fine.
  id: totrans-split-360
  prefs: []
  type: TYPE_NORMAL
  zh: 从大局来看，无论是灾难性风险、存在风险或任何其他问题，或者对我们应该担心的自主代理，我的坚定的假设是不会发生令人害怕的事情。一切都会好的。
- en: In terms of mundane misuse, I also expect it to be fine, but with more potential
    on the margin, especially with fine-tunes.
  id: totrans-split-361
  prefs: []
  type: TYPE_NORMAL
  zh: 在普通的误用方面，我也期望它会表现良好，但更有潜力，尤其是在微调方面。
- en: Certainly some people will switch over from using Claude Sonnet or Haiku or
    another open model to now using Llama-3\. There are advantages. But that will
    look incremental, I expect, not revolutionary. That is also true in terms of the
    pressure this exerts on other model providers.
  id: totrans-split-362
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，一些人可能会从使用Claude Sonnet或Haiku或其他开放模型转而使用Llama-3。有优势。但我预计它看起来是渐进的，而不是革命性的。这也适用于这给其他模型提供商带来的压力。
- en: The real action will be with the 400B model.
  id: totrans-split-363
  prefs: []
  type: TYPE_NORMAL
  zh: 真正的行动将发生在400B模型上。
- en: What happens if Meta goes full Leroy Jenkins and releases the weights to 400B?
  id: totrans-split-364
  prefs: []
  type: TYPE_NORMAL
  zh: 如果Meta全面采取“Leroy Jenkins”的方式，释放到400B的权重会发生什么？
- en: Meta gets a reputational win in many circles, and grows its recruitment and
    ecosystem funnels, as long as they are the first 4-level open model. Sure.
  id: totrans-split-365
  prefs: []
  type: TYPE_NORMAL
  zh: Meta在许多圈子里赢得了声誉，并增加了招聘和生态系统的入口，只要它们是第一个4级的开放模型。当然啦。
- en: Who else wins and loses?
  id: totrans-split-366
  prefs: []
  type: TYPE_NORMAL
  zh: 谁还会赢，谁会输？
- en: For everyone else (and the size of Meta’s reputational win), a key question
    is, what is state of the art at the time?
  id: totrans-split-367
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其他人（以及Meta声誉的大小），一个关键问题是，现在的技术处于什么水平？
- en: In the discussions below, I assume that 5-level models are not yet available,
    at most OpenAI (and perhaps Google or Anthropic) has a 4.5-level model available
    at a premium price. All of this is less impactful the more others have advanced
    already.
  id: totrans-split-368
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的讨论中，我假设5级模型尚未可用，至多OpenAI（也许还有Google或Anthropic）有一个高端价格的4.5级模型。所有这些对其他人已经有所进展的人影响都不大。
- en: And I want to be clear, I do not mean to catastrophize. These are directional
    assessments, knowing magnitude is very hard.
  id: totrans-split-369
  prefs: []
  type: TYPE_NORMAL
  zh: 我想要明确的是，我并不是要灾难化。这些都是方向性的评估，知道其影响的大小是非常困难的。
- en: The obvious big winner is China and Chinese companies, along with every non-state
    actor, and every rival and enemy of the United States of America. Suddenly they
    can serve and utilize and work from what might be a competitive top-level model,
    and no they are not going to be paying Meta a cut no matter the license terms.
  id: totrans-split-370
  prefs: []
  type: TYPE_NORMAL
  zh: 显而易见的大赢家是中国和中国公司，以及每一个非国家行为者、每一个竞争对手和美国的敌人。突然间，他们可以使用和利用以及从可能是竞争顶级模型的地方工作，而无论许可条款如何，他们都不会向Meta支付分成。
- en: Using Llama-3 400B to help train new 4.5-level models is going to be a key potential
    use case to watch.
  id: totrans-split-371
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Llama-3 400B帮助培训新的4.5级模型将成为一个关键的潜在应用案例。
- en: They also benefit when this hurts other big American companies. Not only are
    their products being undercut by a free offering, which is the ultimate predatory
    pricing attack in a zero marginal cost world, those without their own models also
    have another big problem. The Llama-3 license says that big companies have to
    pay to use it, whereas everyone else can use it for free.
  id: totrans-split-372
  prefs: []
  type: TYPE_NORMAL
  zh: 当这伤害其他大型美国公司时，他们也会受益。他们的产品不仅受到免费提供的产品的打击，这在零边际成本世界中是终极的掠夺性定价攻击，那些没有自己模型的人也有另一个大问题。Llama-3许可协议规定大公司必须支付使用费，而其他人可以免费使用。
- en: Another way they benefit? This means that American companies across industries,
    upon whom Meta can enforce such payments, could now be at a potentially large
    competitive disadvantage against their foreign rivals who ignore that rule and
    dare Meta to attempt enforcement.
  id: totrans-split-373
  prefs: []
  type: TYPE_NORMAL
  zh: 他们另一个受益的方式是什么？这意味着美国各行业公司可能会因Meta能够强制执行这些付款而处于潜在的竞争劣势，而他们的外国竞争对手却可以无视这一规则，并敢于挑战Meta的执行能力。
- en: This could also be a problem if foreign companies can ignore the ‘you cannot
    use this to train other models’ clause [in 1(b)(v) of the license agreement](https://llama.meta.com/llama3/license/),
    whereas American companies end up bound by that clause.
  id: totrans-split-374
  prefs: []
  type: TYPE_NORMAL
  zh: 如果外国公司可以无视许可协议中第1(b)(v)条款的‘您不能使用此来训练其他模型’条款，而美国公司最终受到该条款的约束，这也可能成为一个问题。
- en: I am curious what if anything the United States Government, and the national
    security apparatus, are going to do about all that. Or what they would want to
    do about it next time around, when the stakes are higher.
  id: totrans-split-375
  prefs: []
  type: TYPE_NORMAL
  zh: 我很好奇，美国政府和国家安全机构将会对此采取什么行动。或者在下一轮，当赌注更高时，他们会想要采取什么行动。
- en: The other obvious big winners are those who get to use Llama-3 400B in their
    products, especially those for whom it is free, and presumably get to save a bundle
    doing that. Note that even if Meta is not charging, you still have to value high
    quality output enough to pay the inference costs. For many purposes, that is not
    worthwhile.
  id: totrans-split-376
  prefs: []
  type: TYPE_NORMAL
  zh: 其他显而易见的大赢家是那些能在他们的产品中使用Llama-3 400B的人，特别是那些免费使用的人，并且据推测他们可以节省一大笔费用。请注意，即使Meta不收费，你仍然必须足够重视高质量的输出以支付推断成本。对于许多目的来说，这是不值得的。
- en: Science wins to some degree, depending on how much this improves their abilities
    and lowers their costs. It also is a big natural experiment, albeit without controls,
    that will teach us quite a lot. Let’s hope we pay attention.
  id: totrans-split-377
  prefs: []
  type: TYPE_NORMAL
  zh: 科学在某种程度上获胜，取决于这如何改善他们的能力并降低他们的成本。这也是一个大型自然实验，虽然没有控制组，但将会教给我们很多东西。让我们希望能够关注。
- en: Also winners are users who simply want to have full control over a 4-level model
    for personal reasons. Nothing wrong with that. Lowering the cost of inference
    and lowering the limits imposed on it could be very good for some of those business
    models.
  id: totrans-split-378
  prefs: []
  type: TYPE_NORMAL
  zh: 只是想要出于个人原因完全控制一个4级模型的用户也是赢家。这没有错。降低推断成本和降低其所施加的限制对于一些商业模型可能非常有利。
- en: The big obvious Corporate losers are OpenAI, Google, Microsoft and Anthropic,
    along with everyone else trying to serve models and sell inference. Their products
    now have to compete with something very strong, that will be freely available
    at the cost of inference. I expect OpenAI to probably have a superior product
    by that time, and the others may as well, but yes free (or at inference cost)
    is a powerful selling point, as is full customization on your own servers.
  id: totrans-split-379
  prefs: []
  type: TYPE_NORMAL
  zh: 大明显的企业失败者包括OpenAI、Google、Microsoft和Anthropic，以及所有试图为模型提供服务并销售推断的其他公司。他们的产品现在不得不与某种非常强大的竞争，而这种竞争将以推断的成本免费提供。我预计到那时OpenAI可能会拥有一个更优秀的产品，其他公司可能也会，但是免费（或推断成本）确实是一个强大的卖点，以及在自己的服务器上进行全面定制。
- en: The secondary labs could have an even bigger problem on their hands. This could
    steamroller a lot of offerings.
  id: totrans-split-380
  prefs: []
  type: TYPE_NORMAL
  zh: 次级实验室可能会面临更大的问题。这可能会摧毁许多提供方案。
- en: All of which is (a large part of) the point. Meta wants to sabotage its rivals
    into a race to the bottom, in addition to the race to AGI.
  id: totrans-split-381
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都是（很大一部分）重点。Meta希望挫败其竞争对手进入到通往AGI的竞赛中。
- en: Another potential loser is anyone or anything counting on the good guy with
    an AI having a better AI than the bad guy with an AI. Anywhere that AI could flood
    the zone with bogus or hostile content, you are counting on your AI to filter
    out what their AI creates. In practice, you need evaluation to be easier than
    generation under adversarial conditions where the generator chooses point and
    method of attack. I worry that in many places this is not by default true once
    the AIs on both sides are similarly capable.
  id: totrans-split-382
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个潜在的失败者是任何依赖AI好人拥有比坏人AI更好AI的人或任何事物。任何AI可以通过虚假或敌对内容淹没区域的地方，你指望你的AI过滤掉他们的AI创造的内容。实际上，在双方AI能力相当的对抗条件下，生成比评估更容易是不成立的。我担心，在许多地方，一旦双方的AI都具备相似的能力，这种情况并非默认为真。
- en: I think this echoes a more general contradiction in the world, that is primarily
    not about AI. We want everyone to be equal, and the playing field to be level.
    Yet that playing field depends upon the superiority and superior resources and
    capabilities in various ways of the United States and its allies, and of certain
    key corporate players.
  id: totrans-split-383
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这反映了世界上一个更普遍的矛盾，这主要不是关于AI的。我们希望每个人都平等，比赛场地是平等的。然而，这个比赛场地依赖于美国及其盟友的优越性、优越的资源和各种方式的关键企业玩家。
- en: We demand equality and democracy or moves towards them within some contained
    sphere and say this is a universal principle, but few fully want those things
    globally. We understand that things would not go well for our preferences if we
    distributed resources fully equally, or matters were put to a global vote. We
    realize we do not want to unilaterally disarm and single-handedly give away our
    advantages to our rivals. We also realize that some restrictions and concentrated
    power must ensure our freedom.
  id: totrans-split-384
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要求在某些特定领域内实现平等和民主，或朝这些方向迈进，并称这是一个普遍原则，但很少有人真正希望全球普及这些东西。我们明白，如果我们完全平等地分配资源，或者事务全球投票，我们的偏好就不会得到良好的结果。我们意识到，我们不希望单方面解除武装，并且单方面放弃我们的优势给我们的竞争对手。我们也意识到，一些限制和集中权力必须确保我们的自由。
- en: In the case of AI, the same contradictions are there. Here they are even more
    intertwined. We have far less ability to take one policy nationally or locally,
    and a different policy globally. We more starkly must choose either to allow everyone
    to do what they want, or not to allow this. We can either control a given thing,
    or not control it. You cannot escape the implications of either.
  id: totrans-split-385
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI的情况下，同样存在着这些矛盾。在这里，它们更加紧密地交织在一起。我们远不如在国家或地方上采取一种政策，另一种全球政策的能力。我们更加尖锐地必须选择是允许每个人做他们想做的事情，还是不允许。我们可以控制某件事情，或者不控制它。你不能逃避这两者的含义。
- en: 'In any case: The vulnerable entities here could include ‘the internet’ and
    internet search in their broadest senses, and it definitely includes things like
    Email and social media. Meta itself is going to have some of the biggest potential
    problems over at Facebook and Instagram and its messenger services. Similar logic
    could apply to various cyberattacks and social engineering schemes, and so on.'
  id: totrans-split-386
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何：这里的脆弱实体可能包括“互联网”及其最广泛的互联网搜索，肯定包括电子邮件和社交媒体等内容。Meta本身在Facebook、Instagram及其消息服务中可能会遇到一些最大的潜在问题。类似的逻辑可能适用于各种网络攻击和社会工程方案等内容。
- en: I am generally confident in our ability to handle ‘misinformation,’ ‘deepfakes’
    and similar things, but we are raising the difficulty level and running an experiment.
    Yes, this is all coming anyway, in time. The worry is that this levels a playing
    field that is not currently level.
  id: totrans-split-387
  prefs: []
  type: TYPE_NORMAL
  zh: 我对我们处理“错误信息”、“深度伪造”和类似事物的能力相当有信心，但我们正在提高难度并进行实验。是的，这一切迟早都会发生。担心的是，这将使当前不平等的竞争格局平坦化。
- en: I actually think triggering these potential general vulnerabilities now is a
    positive impact. This is the kind of experiment where you need to find out sooner
    rather than later. If it turns out the bad scenarios here come to pass, we have
    time to adjust and not do this again. If it turns out the good scenarios come
    to pass, then we learn from that as well. The details will be enlightening no
    matter what.
  id: totrans-split-388
  prefs: []
  type: TYPE_NORMAL
  zh: 我实际上认为现在触发这些潜在的一般性脆弱性是积极的影响。这是一种需要尽早了解的实验。如果这里的坏情景真的发生了，我们有时间调整，不再这样做。如果好的情景发生了，那么我们也从中学到了东西。无论如何，细节将是启发性的。
- en: It is interesting to see where the mind goes now that the prospect is more concrete,
    and one is thinking about short term, practical impacts.
  id: totrans-split-389
  prefs: []
  type: TYPE_NORMAL
  zh: 看到现在前景更具体化时头脑会去哪里，思考短期的实际影响是很有趣的。
- en: Other big Western corporations that would have to pay Meta could also be losers.
  id: totrans-split-390
  prefs: []
  type: TYPE_NORMAL
  zh: 其他必须向 Meta 支付费用的大型西方公司也可能会是输家。
- en: The other big loser, as mentioned above, is the United States of America.
  id: totrans-split-391
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个大输家，如上所述，是美利坚合众国。
- en: And of course, if this release is bad for safety, either now or down the line,
    we all lose.
  id: totrans-split-392
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，如果这次发布对安全不利，无论是现在还是将来，我们都会受到损失。
- en: Again, these are all directional effects. I cannot rule out large impacts in
    scenarios where Llama-3 400B releases as close to state of the art, but everyone
    mostly shrugging on most of these also would not be shocking. Writing this down
    it occurs to me that people simply have not thought about this scenario much in
    public, despite it having been reasonably likely for a while.
  id: totrans-split-393
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这些都是方向性影响。在 Llama-3 400B 发布得接近最先进的情况下，我不能排除可能产生重大影响的场景，但大多数人对大多数情况的反应也不会令人震惊。写下这些话时，我意识到人们在公开场合其实并没有太多思考这种情况的可能性，尽管这种可能性已经相当长时间了。
- en: The right question is usually not ‘is it safe?’ but rather ‘how (safe or unsafe)
    is it?’ Releasing a 4-level model’s weights is never going to be fully ‘safe’
    but then neither is driving. When we say ‘safe’ we mean ‘safe enough.’
  id: totrans-split-394
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的问题通常不是‘它安全吗？’而是‘它（安全或不安全）到什么程度？’释放一个 4 级模型的权重永远不会完全‘安全’，但驾驶也一样不安全。当我们说‘安全’时，我们的意思是‘足够安全’。
- en: We do not want to be safetyists who demand perfect safety. Not even perfect
    existential safety. Everything is price.
  id: totrans-split-395
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不想成为追求完美安全性的人，甚至不是追求完全存在的安全性。一切都有代价。
- en: The marginal existential safety price on Llama-3 70B and Llama-3 8B is very
    small, essentially epsilon. Standing on its own, the decision to release the weights
    of these models is highly reasonable. It is a normal business decision. I care
    only because of the implications for future decisions.
  id: totrans-split-396
  prefs: []
  type: TYPE_NORMAL
  zh: Llama-3 70B 和 Llama-3 8B 的边际存在安全价格非常小，基本上是 epsilon。就其本身而言，释放这些模型的权重是非常合理的决定。这是一个正常的商业决策。我只关心它对未来决策的影响。
- en: What is the safety price for the releasing the model weights of Llama-3 400B,
    or another 4-level model?
  id: totrans-split-397
  prefs: []
  type: TYPE_NORMAL
  zh: 对于释放 Llama-3 400B 模型权重或另一个 4 级模型的安全价格是多少？
- en: I think in most worlds the direct safety cost here is also very low, especially
    the direct existential safety cost. Even with extensive scaffolding, there are
    limits to what a 4-level model can do. I’d expect some nastiness on the edges
    but only on the edges, in limited form.
  id: totrans-split-398
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为在大多数情况下，这里的直接安全成本也非常低，特别是直接存在的安全成本。即使有广泛的支撑，4 级模型也有其局限性。我预计会有一些边缘上的不愉快，但仅限于边缘，而且形式有限。
- en: How many 9s of direct safety here, compared to a world in which a 4-level model
    was never released with open weights? I would say two 9s (>99%), but not three
    9s (<99.9%). However the marginal safety cost versus the counterfactual other
    open model releases is even smaller than that, and there I would say we have that
    third 9 (so >99.9%).
  id: totrans-split-399
  prefs: []
  type: TYPE_NORMAL
  zh: 直接安全性有多少 9，与一个从未公开权重的 4 级模型世界相比？我会说是两个 9 (>99%)，但不是三个 9 (<99.9%)。然而，与反事实其他开放模型发布相比，边际安全成本甚至更小，那里我会说我们有第三个
    9（所以 >99.9%）。
- en: 'I say direct safety because the primary potential safety dangers here seem
    indirect. They are:'
  id: totrans-split-400
  prefs: []
  type: TYPE_NORMAL
  zh: 我说直接的安全性是因为这里的主要潜在安全危险似乎是间接的。它们包括：
- en: Setting a precedent and pattern for future similar releases, at Meta and elsewhere.
  id: totrans-split-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Meta 和其他地方为未来类似发布设置先例和模式。
- en: Assisting in training of next-generation models.
  id: totrans-split-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 协助培训下一代模型。
- en: Everyone generally being pushed to go faster, faster.
  id: totrans-split-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个人普遍都在被迫加速，更快。
- en: And again, these only matter on the margin to the extent they move the margin.
  id: totrans-split-404
  prefs: []
  type: TYPE_NORMAL
  zh: 而且，这些只有在边际上的移动程度上才会有所关联。
- en: At the time of Llama-2, I said what I was concerned about opening up was Llama-4.
  id: totrans-split-405
  prefs: []
  type: TYPE_NORMAL
  zh: 在Llama-2时，我说我担心的是开放Llama-4。
- en: That is still the case now. Llama-3 will be fine.
  id: totrans-split-406
  prefs: []
  type: TYPE_NORMAL
  zh: 现在情况仍然如此。Llama-3会没问题的。
- en: Will releasing Llama-4 be fine? Probably. But I notice my lack of confidence.
  id: totrans-split-407
  prefs: []
  type: TYPE_NORMAL
  zh: Llama-4发布会没问题吗？可能吧。但我注意到我缺乏信心。
- en: '(Usual caveat: Nothing here is investing advice.)'
  id: totrans-split-408
  prefs: []
  type: TYPE_NORMAL
  zh: （通常警告：这里没有任何投资建议。）
- en: Market is not impressed. Nasdaq was down 6.2% in this same period.
  id: totrans-split-409
  prefs: []
  type: TYPE_NORMAL
  zh: 市场并不满意。在同一时期，纳斯达克下跌了6.2%。
- en: You can come up with various explanations. The obvious cause is that [WhatsApp
    and Threads were forcibly removed from the Apple Store in China](https://nypost.com/2024/04/19/business/apple-removes-whatsapp-threads-from-app-store-in-china-after-demand-by-beijing-over-security-concerns/),
    [along with Signal and Telegram](https://www.bloomberg.com/news/articles/2024-04-19/china-orders-apple-to-scrub-whatsapp-from-mobile-store-wsj-says).
    I am confused why this would be worth a 3% underperformance.
  id: totrans-split-410
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以提出各种解释。显而易见的原因是，[WhatsApp和Threads被强制从中国苹果商店中移除](https://nypost.com/2024/04/19/business/apple-removes-whatsapp-threads-from-app-store-in-china-after-demand-by-beijing-over-security-concerns/)，[以及Signal和Telegram](https://www.bloomberg.com/news/articles/2024-04-19/china-orders-apple-to-scrub-whatsapp-from-mobile-store-wsj-says)。我不明白为什么这会导致3%的表现不佳。
- en: (Then about a day later it looked like we were finally going to actually force
    divestiture of TikTok while using that to help pass a foreign aid bill, so this
    seems like a massive own goal by China to remind us of how they operate and the
    law of equivalent exchange.)
  id: totrans-split-411
  prefs: []
  type: TYPE_NORMAL
  zh: （然后大约一天后，看起来我们终于将会强制分拆TikTok，同时利用此事推动通过一项外国援助法案，所以这似乎是中国一个巨大的自讨苦吃，提醒我们他们如何运作以及等价交换法则。）
- en: The stock most down was Nvidia, which fell 10%, on no direct news. [Foolish,
    foolish.](https://slay-the-spire.fandom.com/wiki/Time_Eater)
  id: totrans-split-412
  prefs: []
  type: TYPE_NORMAL
  zh: 股票中跌幅最大的是Nvidia，下跌了10%，没有直接新闻。 [愚蠢，愚蠢。](https://slay-the-spire.fandom.com/wiki/Time_Eater)
- en: At most, markets thought Llama-3’s reveal was worth a brief ~1% bump.
  id: totrans-split-413
  prefs: []
  type: TYPE_NORMAL
  zh: 最多，市场认为Llama-3的揭示值得一个短暂的约1%的反弹。
- en: You can say on Meta that ‘it was all priced in.’ I do not believe you. I think
    the market is asleep at the wheel.
  id: totrans-split-414
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在Meta上说‘一切都已经定价进去了。’ 我不相信。我认为市场在开车时睡着了。
- en: Some are of course calling these recent moves ‘the market entering a correction
    phase’ [or that ‘the bubble is bursting.’](https://twitter.com/Simeon_Cps/status/1781706864540917930)
    Good luck with that.
  id: totrans-split-415
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人当然将这些最近的动作称为‘市场进入修正阶段’ [或者‘泡沫正在破裂。’](https://twitter.com/Simeon_Cps/status/1781706864540917930)
    祝你好运。
- en: '[Here is a WSJ article](https://www.wsj.com/tech/metas-ai-push-needs-to-efficiently-deliver-a-lot-more-ad-growth-5fa298a8)
    about how Meta had better ensure its AI is used to juice advertising returns.
    Investors really are this myopic.'
  id: totrans-split-416
  prefs: []
  type: TYPE_NORMAL
  zh: '[这是一篇关于Meta需要确保其AI用于增加广告回报的WSJ文章](https://www.wsj.com/tech/metas-ai-push-needs-to-efficiently-deliver-a-lot-more-ad-growth-5fa298a8)。投资者确实如此目光短浅。'
- en: Any given company, of course, could still be vastly overvalued.
  id: totrans-split-417
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，任何一家公司仍然可能被高估得厉害。
- en: '[Here was the only argument I saw to that effect with respect to Nvidia.](https://twitter.com/bryanrbeal/status/1781454698136109380)'
  id: totrans-split-418
  prefs: []
  type: TYPE_NORMAL
  zh: '[这里是我看到的关于Nvidia这一点的唯一论据。](https://twitter.com/bryanrbeal/status/1781454698136109380)'
- en: 'Bryan Beal: The AI bubble is not bursting.'
  id: totrans-split-419
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Bryan Beal：AI泡沫并没有破裂。
- en: More investors are just realizing that Nvidia doesn’t make chips. They design
    them and TSMC makes them. And Nvidia’s biggest customers (Meta, Amazon, OpenAI,
    Microsoft, Google, etc) have ALL announced they are designing their own AI chips
    for both training and inference. And Google just went public they are already
    training on their own silicon and didn’t need Nvidia.
  id: totrans-split-420
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 更多的投资者刚刚意识到Nvidia并不生产芯片。他们设计芯片，而TSMC则进行制造。而Nvidia的最大客户（Meta、亚马逊、OpenAI、微软、谷歌等）全部宣布他们正在设计自己的AI芯片，用于训练和推理。而谷歌刚刚公开表示，他们已经开始在自家的硅片上进行训练，不再需要Nvidia。
- en: This is a very real threat.
  id: totrans-split-421
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这是一个非常真实的威胁。
- en: I can totally buy that a lot of investors have no idea what Nvidia actually
    produces, and got freaked out by suddenly learning what Nvidia actually does.
    I thought it was very public long ago that Google trains on TPUs that they design?
    I thought it was common knowledge that everyone involved was going to try to produce
    their own chips for at least internal use, whether or not that will work? And
    that Nvidia will still have plenty of customers even if all the above switched
    to TPUs or their own versions?
  id: totrans-split-422
  prefs: []
  type: TYPE_NORMAL
  zh: 我完全可以理解很多投资者根本不知道英伟达到底生产什么，突然知道英伟达的实际运作方式让他们感到恐慌。我曾认为很久以前谷歌训练使用他们设计的 TPU 是公开的信息？我认为每个相关方都计划至少为内部使用而制造自己的芯片，无论结果如何？而且即使以上所有人转向
    TPU 或他们自己的版本，英伟达仍将有大量客户？
- en: That does not mean that Nvidia’s moat is impregnable. Of course they could lose
    their position not so long from now. That is (a lot of) why one has a diversified
    portfolio.
  id: totrans-split-423
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不意味着英伟达的护城河是坚不可摧的。当然，他们可能在不久的将来失去他们的位置。这也是为什么要有一个多样化投资组合的原因。
- en: Again. The Efficient Market Hypothesis in False.
  id: totrans-split-424
  prefs: []
  type: TYPE_NORMAL
  zh: 再一次。有效市场假说是错误的。
- en: 'I expect not this, GPT-5 will be ready when it is ready, but there will be
    pressure:'
  id: totrans-split-425
  prefs: []
  type: TYPE_NORMAL
  zh: 我不指望这种情况发生，GPT-5 将会在准备好的时候发布，但肯定会受到压力：
- en: '[Jim Fan:](https://twitter.com/DrJimFan/status/1781386105734185309) Prediction:
    GPT-5 will be announced before Llama-3-400B releases. External movement defines
    OpenAI’s PR schedule 🤣'
  id: totrans-split-426
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[Jim Fan：](https://twitter.com/DrJimFan/status/1781386105734185309) 预测：在 Llama-3-400B
    发布之前，GPT-5 将会宣布。外部动态定义了 OpenAI 的公关时间表 🤣'
- en: I do not doubt that OpenAI and others will do everything they can to stay ahead
    of Meta’s releases, with an unknown amount of ‘damn the safety checks of various
    sorts.’
  id: totrans-split-427
  prefs: []
  type: TYPE_NORMAL
  zh: 我毫不怀疑 OpenAI 和其他公司将尽一切可能保持领先于 Meta 的发布，尽管安全检查的程度不为人知。
- en: That does not mean that one can conjure superior models out of thin air. Or
    that it is helpful to rush things into use before they are ready.
  id: totrans-split-428
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不意味着可以凭空创造出优越的模型。或者说在它们准备好之前匆忙投入使用是没有帮助的。
- en: Still, yes, everyone will go faster on the frontier model front. That includes
    that everyone in the world will be able to use Llama-3 400B for bootstrapping,
    not only fine-tuning.
  id: totrans-split-429
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，是的，每个人都会在前沿模型方面变得更快。这包括全世界的每个人都能够使用 Llama-3 400B 进行启动，而不仅仅是进行精细调整。
- en: On the AI mundane utility front, people will get somewhat more somewhat cheaper,
    a continuation of existing trends, with the first two models. Later we will have
    the ability to get a 4-level model internally for various purposes. So we will
    get more and cheaper cool stuff.
  id: totrans-split-430
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AI 的日常实用性方面，人们将通过前两个模型在某种程度上变得更加便宜，这是现有趋势的延续。稍后，我们将拥有内部使用的 4 级模型的能力。因此，我们将获得更多和更便宜的酷东西。
- en: Meta will deploy its tools across its social media empire. Mostly I expect this
    to be a positive experience, and to also get a lot more people to notice AI. Expect
    a bunch of scare stories and highlights of awful things, some real and some baseless.
  id: totrans-split-431
  prefs: []
  type: TYPE_NORMAL
  zh: Meta 将在其社交媒体帝国中部署其工具。我大多数情况下期待这将是一种积极的体验，也会让更多人注意到 AI。预计会有一堆惊悚故事和恶劣事情的亮点，有些是真实的，有些则是无稽之谈。
- en: On the practical downside front, little will change until the 400B model gets
    released. Then we will find out what people can do with that, as they attempt
    to flood the zone in various ways, and try for all the obvious forms of misuse.
    It will be fun to watch.
  id: totrans-split-432
  prefs: []
  type: TYPE_NORMAL
  zh: 在实际的缺点方面，直到 400B 模型发布之前，几乎不会有什么变化。然后我们将看到人们如何尝试以各种方式来利用它，试图进行各种明显的滥用形式。观察这一切将会很有趣。
- en: All this could be happening right as the election hits, and people are at their
    most hostile and paranoid, seeing phantoms everywhere.
  id: totrans-split-433
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这一切可能会发生在选举即将到来之际，人们正处于最敌对和偏执的状态，到处都在看到幽灵。
- en: Careful, Icarus.
  id: totrans-split-434
  prefs: []
  type: TYPE_NORMAL
  zh: 当心，伊卡洛斯。
