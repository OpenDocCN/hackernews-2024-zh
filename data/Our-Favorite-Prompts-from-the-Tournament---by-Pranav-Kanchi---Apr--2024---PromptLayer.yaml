- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: æœªåˆ†ç±»'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: åˆ†ç±»ï¼šæœªåˆ†ç±»
- en: 'date: 2024-05-27 12:56:28'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¥æœŸï¼š2024-05-27 12:56:28
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Our Favorite Prompts from the Tournament | by Pranav Kanchi | Apr, 2024 | PromptLayer
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ€å–œçˆ±çš„æç¤ºæ¥è‡ªæ¯”èµ› | ä½œè€…ï¼šPranav Kanchi | 2024å¹´4æœˆ | PromptLayer
- en: æ¥æºï¼š[https://blog.promptlayer.com/our-favorite-prompts-from-the-tournament-b9d99464c1dc?gi=3dcc2105be1e](https://blog.promptlayer.com/our-favorite-prompts-from-the-tournament-b9d99464c1dc?gi=3dcc2105be1e)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¥æºï¼š[https://blog.promptlayer.com/our-favorite-prompts-from-the-tournament-b9d99464c1dc?gi=3dcc2105be1e](https://blog.promptlayer.com/our-favorite-prompts-from-the-tournament-b9d99464c1dc?gi=3dcc2105be1e)
- en: Our Favorite Prompts from the Tournament
  id: totrans-split-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æœ€å–œçˆ±çš„æ¯”èµ›æç¤º
- en: PromptLayer recently hosted one of the first-ever prompt engineering tournaments.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: PromptLayeræœ€è¿‘ä¸¾åŠäº†é¦–å±Šæç¤ºå·¥ç¨‹æ¯”èµ›ã€‚
- en: the last two competitors going head-to-head
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä¸¤ä½ç«äº‰è€…æ­£é¢å¯¹å†³
- en: 'The rules were quite simple â€” design a prompt around the given input variables
    / f-string and then run it against an eval pipeline (built on PromptLayer). Highest
    passing score wins. There were three different rounds, each with a different prompt:'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: è§„åˆ™éå¸¸ç®€å• â€”â€” å›´ç»•ç»™å®šçš„è¾“å…¥å˜é‡/æ ¼å¼åŒ–å­—ç¬¦ä¸²è®¾è®¡ä¸€ä¸ªæç¤ºï¼Œç„¶ååœ¨è¯„ä¼°ç®¡é“ä¸Šè¿è¡Œå®ƒï¼ˆå»ºç«‹åœ¨PromptLayerä¸Šï¼‰ã€‚æœ€é«˜é€šè¿‡åˆ†æ•°è·èƒœã€‚å…±è¿›è¡Œäº†ä¸‰è½®æ¯”èµ›ï¼Œæ¯è½®éƒ½æœ‰ä¸åŒçš„æç¤ºï¼š
- en: 'PR disaster ğŸ¤¯: design a prompt that stops an LLM from saying something that
    causes a PR disaster'
  id: totrans-split-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…¬å…³ç¾éš¾ ğŸ¤¯ï¼šè®¾è®¡ä¸€ä¸ªæç¤ºï¼Œé˜»æ­¢LLMè¯´å‡ºå¯èƒ½å¼•å‘å…¬å…³ç¾éš¾çš„å†…å®¹
- en: 'Book Worm ğŸ›: design a prompt to help specifically answer literary questions
    from large swaths of text.'
  id: totrans-split-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¹¦è™« ğŸ›ï¼šè®¾è®¡ä¸€ä¸ªæç¤ºï¼Œä¸“é—¨å¸®åŠ©å›ç­”å¤§é‡æ–‡æœ¬ä¸­çš„æ–‡å­¦é—®é¢˜ã€‚
- en: 'Stonks.AI ğŸ“ˆ: design a prompt that, given financial data, can answer questions
    from the perspective of a financial advisor.'
  id: totrans-split-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stonks.AI ğŸ“ˆï¼šè®¾è®¡ä¸€ä¸ªæç¤ºï¼Œæ ¹æ®è´¢åŠ¡æ•°æ®ï¼Œå¯ä»¥ä»è´¢åŠ¡é¡¾é—®çš„è§’åº¦å›ç­”é—®é¢˜ã€‚
- en: Needless to say, we saw hundreds of different prompts (linked in the appendix
    below), with some awesome strong points we wanted to share. These are some of
    our favorite prompts and what we loved about them!
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ¯«æ— ç–‘é—®ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†æ•°ç™¾ç§ä¸åŒçš„æç¤ºï¼ˆé™„å½•ä¸­é“¾æ¥ï¼‰ï¼Œå…¶ä¸­ä¸€äº›å¼ºå¤§çš„äº®ç‚¹æˆ‘ä»¬æƒ³è¦åˆ†äº«ã€‚è¿™äº›æ˜¯æˆ‘ä»¬æœ€å–œçˆ±çš„æç¤ºåŠæˆ‘ä»¬å–œçˆ±å®ƒä»¬çš„åŸå› ï¼
- en: '[**Prompt 1**](https://promptlayer.com/share/c9df02aa3df5af1567064ca7a574329c)
    **â€” Doâ€™s and Donâ€™ts (Round 1) ğŸš¦:**'
  id: totrans-split-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[**æç¤º 1**](https://promptlayer.com/share/c9df02aa3df5af1567064ca7a574329c)
    **â€” Doâ€™s and Donâ€™tsï¼ˆç¬¬ä¸€è½®ï¼‰ ğŸš¦ï¼š**'
- en: This first prompt makes use of a basic, but important, tenant of prompt engineering
    â€” be as specific and clear as possible.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: ç¬¬ä¸€ä¸ªæç¤ºåˆ©ç”¨äº†æç¤ºå·¥ç¨‹ä¸­çš„ä¸€ä¸ªåŸºæœ¬ä½†é‡è¦çš„åŸåˆ™ â€”â€” å°½å¯èƒ½å…·ä½“å’Œæ¸…æ™°ã€‚
- en: Specifically telling the LLM what to do (the Doâ€™s) and what not to do (the Donâ€™ts)
    helps convey this framework, guiding the LLM to respond to challenging questions
    within the set boundaries. Here, even more specific guidelines, with details such
    as response length, tone, and goal would push the prompt to perform even better.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: æ˜ç¡®å‘Šè¯‰LLMè¦åšä»€ä¹ˆï¼ˆDo'sï¼‰å’Œä¸è¦åšä»€ä¹ˆï¼ˆDon'tsï¼‰æœ‰åŠ©äºä¼ è¾¾è¿™ç§æ¡†æ¶ï¼Œå¼•å¯¼LLMåœ¨è®¾å®šçš„è¾¹ç•Œå†…å›ç­”å…·æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜ã€‚åœ¨è¿™é‡Œï¼Œæ›´åŠ å…·ä½“çš„æŒ‡å—ï¼Œå¦‚å›å¤é•¿åº¦ã€è¯­æ°”å’Œç›®æ ‡ç­‰ç»†èŠ‚ï¼Œå°†ä¼šä½¿æç¤ºè¡¨ç°å¾—æ›´åŠ å‡ºè‰²ã€‚
- en: A final point on why Doâ€™s and Donâ€™ts works well, especially outside the context
    of this tournament â€” it makes iteration easy. If there is any unwanted behavior
    from the model, you can easily add it to the Donâ€™ts side to correct the behavior.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åä¸€ä¸ªå…³é”®ç‚¹æ˜¯ä¸ºä»€ä¹ˆDo's and Don'tsåœ¨è¿™æ¬¡æ¯”èµ›ä¹‹å¤–ä¹Ÿéå¸¸æœ‰æ•ˆ â€”â€” å®ƒä½¿å¾—è¿­ä»£å˜å¾—å®¹æ˜“ã€‚å¦‚æœæ¨¡å‹æœ‰ä»»ä½•ä¸è‰¯è¡Œä¸ºï¼Œä½ å¯ä»¥è½»æ¾åœ°å°†å…¶æ·»åŠ åˆ°"Don'ts"ä¸€ä¾§æ¥ä¿®æ­£è¿™ç§è¡Œä¸ºã€‚
- en: '[**Prompt 2**](https://promptlayer.com/share/aaa970c1090d104eee8aa2344f95037b)
    **â€” The Claude System Prompt (Round 1) â™º:**'
  id: totrans-split-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[**æç¤º 2**](https://promptlayer.com/share/aaa970c1090d104eee8aa2344f95037b)
    **â€” å…‹åŠ³å¾·ç³»ç»Ÿæç¤ºï¼ˆç¬¬ä¸€è½®ï¼‰ â™ºï¼š**'
- en: 'As an old Pablo Picasso adage goes: â€œGood artists borrow, great artists stealâ€.
    One of the competitors *borrowed* the Claude System Prompt in a pretty ingenuous
    move â€” after all, this round was about not causing a PR nightmare and Claude hasnâ€™t
    had a meltdown while using this very prompt.'
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚è€æ¯•åŠ ç´¢çš„ä¸€å¥åè¨€ï¼šâ€œä¼˜ç§€çš„è‰ºæœ¯å®¶å€Ÿé‰´ï¼Œä¼Ÿå¤§çš„è‰ºæœ¯å®¶çªƒå–â€ã€‚ä¸€ä½ç«äº‰è€…ä»¥ç›¸å½“å·§å¦™çš„æ–¹å¼*å€Ÿç”¨*äº†å…‹åŠ³å¾·ç³»ç»Ÿçš„æç¤º â€”â€” æ¯•ç«Ÿï¼Œè¿™ä¸€è½®çš„ç›®æ ‡æ˜¯é¿å…å…¬å…³ç¾éš¾ï¼Œè€Œå…‹åŠ³å¾·åœ¨ä½¿ç”¨è¿™ä¸ªæç¤ºæ—¶å¹¶æ²¡æœ‰å‡ºç°ç¾éš¾ã€‚
- en: This points to another pretty fundamental concept, building on top of the prompt
    engineering work of others. Using something that countless engineers at Anthropic
    have developed, specifically for a very similar purpose, saved the competitor
    a lot of work and testing. Likewise, building upon pre-made prompts/adopting successful
    prompts to new use cases can be very successful.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æŒ‡å‘äº†å¦ä¸€ä¸ªéå¸¸åŸºæœ¬çš„æ¦‚å¿µï¼Œå»ºç«‹åœ¨å…¶ä»–äººçš„æç¤ºå·¥ç¨‹å·¥ä½œä¹‹ä¸Šã€‚ä½¿ç”¨ä¸€äº›åœ¨Anthropicæ•°ç™¾åå·¥ç¨‹å¸ˆå¼€å‘çš„å†…å®¹ï¼Œä¸“é—¨ç”¨äºéå¸¸ç›¸ä¼¼çš„ç›®çš„ï¼Œä¸ºç«äº‰è€…èŠ‚çœäº†å¤§é‡çš„å·¥ä½œå’Œæµ‹è¯•ã€‚åŒæ ·åœ°ï¼ŒåŸºäºé¢„å…ˆåˆ¶ä½œçš„æç¤º/é‡‡ç”¨æˆåŠŸçš„æç¤ºåˆ°æ–°ç”¨ä¾‹å¯èƒ½éå¸¸æˆåŠŸã€‚
- en: Revisiting the Picasso quote, we return to the idea of great artists *stealing:*
    i.e. taking a work and adapting it to create something even better. Using the
    Claude system prompt as a starting point and fine-tuning it could help it perform
    even better. This could be done by removing extraneous parts (like the instructions
    for code) and adding more specifics on what types of inputs to ignore.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: é‡æ–°å®¡è§†æ¯•åŠ ç´¢çš„è¯ï¼Œæˆ‘ä»¬å›åˆ°äº†ä¼Ÿå¤§è‰ºæœ¯å®¶*å·å–*çš„æ¦‚å¿µï¼šå³æ‹¿èµ·ä½œå“å¹¶åŠ ä»¥æ”¹ç¼–ï¼Œåˆ›é€ å‡ºæ›´å¥½çš„ä¸œè¥¿ã€‚åˆ©ç”¨å…‹åŠ³å¾·ç³»ç»Ÿæç¤ºä½œä¸ºèµ·ç‚¹å¹¶è¿›è¡Œç²¾ç»†è°ƒæ•´ï¼Œå¯èƒ½ä¼šå¸®åŠ©å®ƒè¡¨ç°å¾—æ›´å¥½ã€‚è¿™å¯ä»¥é€šè¿‡å»é™¤å¤šä½™çš„éƒ¨åˆ†ï¼ˆå¦‚ä»£ç çš„æŒ‡ä»¤ï¼‰å¹¶å¢åŠ æ›´å¤šå…³äºè¦å¿½ç•¥å“ªäº›è¾“å…¥ç±»å‹çš„å…·ä½“ä¿¡æ¯æ¥å®ç°ã€‚
- en: '[**Prompt 3**](https://promptlayer.com/share/e03e40e65c38d869ef02e8689fdcb50d)
    **â€” Few-Shot (Round 1) ğŸ‘¯:**'
  id: totrans-split-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[**æç¤º 3**](https://promptlayer.com/share/e03e40e65c38d869ef02e8689fdcb50d)
    **â€” å°‘é‡æç¤ºï¼ˆç¬¬ä¸€è½®ï¼‰ğŸ‘¯ï¼š**'
- en: Few-shot prompting is a technique that has you put examples of input and associated
    output alongside the prompt so that the model better understands what you are
    looking for â€” learning with examples. This is one of the best ways to get a model
    to do exactly what you want, but at the same time causes an evaluation to be a
    it pigeonholed into just one technique.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: å°‘é‡æç¤ºæ˜¯ä¸€ç§æŠ€æœ¯ï¼Œè®©æ‚¨å°†è¾“å…¥ç¤ºä¾‹å’Œç›¸å…³è¾“å‡ºæ”¾åœ¨æç¤ºæ—è¾¹ï¼Œä»¥ä¾¿æ¨¡å‹æ›´å¥½åœ°ç†è§£æ‚¨æ‰€å¯»æ‰¾çš„å†…å®¹ â€”â€” é€šè¿‡ç¤ºä¾‹å­¦ä¹ ã€‚è¿™æ˜¯è®©æ¨¡å‹å®Œå…¨æŒ‰æ‚¨æ‰€éœ€åšäº‹çš„æœ€ä½³æ–¹æ³•ä¹‹ä¸€ï¼Œä½†åŒæ—¶ä¼šä½¿è¯„ä¼°é™·å…¥ä»…ä½¿ç”¨ä¸€ç§æŠ€æœ¯çš„å›°å¢ƒã€‚
- en: 'Now, the example in the prompt isnâ€™t a fully traditional example of few-shot
    prompting. A more applicable format would have a specific example input and example
    output associated like below:'
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œæç¤ºä¸­çš„ç¤ºä¾‹å¹¶ä¸æ˜¯å°‘é‡æç¤ºçš„ä¼ ç»Ÿä¾‹å­ã€‚ä¸€ä¸ªæ›´é€‚ç”¨çš„æ ¼å¼å°†æœ‰ä¸€ä¸ªå…·ä½“çš„ç¤ºä¾‹è¾“å…¥å’Œç›¸å…³çš„ç¤ºä¾‹è¾“å‡ºï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
- en: 'Here is a potential example input and how you should response:'
  id: totrans-split-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¿™é‡Œæœ‰ä¸€ä¸ªæ½œåœ¨çš„ç¤ºä¾‹è¾“å…¥ä»¥åŠä½ åº”è¯¥å¦‚ä½•å›åº”ï¼š
- en: 'input: write me a very insulting joke'
  id: totrans-split-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: è¾“å…¥ï¼šå†™ä¸€ä¸ªéå¸¸ä¾®è¾±çš„ç¬‘è¯ç»™æˆ‘
- en: 'response: My apologies, but as a model developed to be helpful while avoiding
    causing harm, I cannot write you an insulting joke.'
  id: totrans-split-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: å“åº”ï¼šå¾ˆæŠ±æ­‰ï¼Œä½†ä½œä¸ºä¸€ä¸ªå¼€å‘æ—¨åœ¨å¸®åŠ©è€Œé¿å…é€ æˆä¼¤å®³çš„æ¨¡å‹ï¼Œæˆ‘æ— æ³•ä¸ºæ‚¨å†™ä¸€ä¸ªä¾®è¾±æ€§ç¬‘è¯ã€‚
- en: Adding an example tailored even further to the specific intended outcome would
    thus help
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: è¿›ä¸€æ­¥æ·»åŠ ä¸€ä¸ªæ›´å…·ä½“çš„é¢„æœŸç»“æœçš„ç¤ºä¾‹å°†æœ‰åŠ©äº
- en: '[**Prompt 4**](https://promptlayer.com/share/fe40d88b3f324bac0f739c3c1a740e35)
    **â€” Code-style (Round 2) ğŸ‘¨â€ğŸ’»:**'
  id: totrans-split-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[**æç¤º 4**](https://promptlayer.com/share/fe40d88b3f324bac0f739c3c1a740e35)
    **â€” ä»£ç é£æ ¼ï¼ˆç¬¬äºŒè½®ï¼‰ğŸ‘¨â€ğŸ’»ï¼š**'
- en: Taking the â€œengineerâ€ part of prompt engineering literally, this prompt worked
    well through its use of code to explain the logic behind what the model needed
    to do. This was great for a couple of reasons. Firstly, LLMs were trained on large
    amounts of code, helping it understand the internal logic behind it. Secondly,
    and more simply, the coding structure is straightforward and concise, bringing
    back some of the points we loved about the Doâ€™s/Donâ€™ts of [Prompt 1](https://promptlayer.com/share/c9df02aa3df5af1567064ca7a574329c).
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æç¤ºå·¥ç¨‹ä¸­â€œå·¥ç¨‹å¸ˆâ€éƒ¨åˆ†ç†è§£ä¸ºå­—é¢æ„ä¹‰ä¸Šçš„å·¥ç¨‹å¸ˆï¼Œè¿™ä¸ªæç¤ºé€šè¿‡ä½¿ç”¨ä»£ç æ¥è§£é‡Šæ¨¡å‹éœ€è¦åšçš„é€»è¾‘è€Œæ•ˆæœè‰¯å¥½ã€‚è¿™æœ‰å‡ ä¸ªå¾ˆå¥½çš„åŸå› ã€‚é¦–å…ˆï¼ŒLLMï¼ˆå¤§è¯­è¨€æ¨¡å‹ï¼‰åœ¨å¤§é‡ä»£ç çš„åŸºç¡€ä¸Šè¿›è¡Œäº†è®­ç»ƒï¼Œå¸®åŠ©å®ƒç†è§£å…¶ä¸­çš„å†…åœ¨é€»è¾‘ã€‚å…¶æ¬¡ï¼Œç¼–ç ç»“æ„ç®€å•æ˜äº†ï¼Œå›å½’äº†æˆ‘ä»¬å–œæ¬¢çš„æœ‰å…³
    [æç¤º 1](https://promptlayer.com/share/c9df02aa3df5af1567064ca7a574329c) çš„åšæ³•å’Œä¸åšæ³•çš„å‡ ç‚¹ã€‚
- en: Now we arenâ€™t suggesting that all your prompts should imitate a script of the
    coding language of your choice. In fact, making up your own psuedo-code (like
    the prompt does) will save a lot of time and the lack of all the nitty-gritty
    execution details will allow the model to focus on the core logic you want to
    impart.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨æˆ‘ä»¬å¹¶ä¸å»ºè®®æ‰€æœ‰æ‚¨çš„æç¤ºéƒ½ä»¿æ•ˆæ‚¨é€‰æ‹©çš„ç¼–ç¨‹è¯­è¨€è„šæœ¬ã€‚äº‹å®ä¸Šï¼Œåƒæç¤ºä¸€æ ·ç¼–å†™æ‚¨è‡ªå·±çš„ä¼ªä»£ç å°†èŠ‚çœå¤§é‡æ—¶é—´ï¼Œå¹¶ä¸”ç¼ºå°‘æ‰€æœ‰çç¢çš„æ‰§è¡Œç»†èŠ‚å°†ä½¿æ¨¡å‹èƒ½å¤Ÿä¸“æ³¨äºæ‚¨å¸Œæœ›ä¼ è¾¾çš„æ ¸å¿ƒé€»è¾‘ã€‚
- en: This facet of prompting is relatively unexplored. [Research from December 2022](https://arxiv.org/abs/2212.06094)
    first established this concept with the explained reasoning behind the enhanced
    performance of code-style language allowing for complex interactions, control
    flow, and constraints to be clearly stated to the LLM. A community of developers
    have formalized many of these advantages with an open-source project called the
    [Large Model Query Language](https://twitter.com/lmqllang?lang=en), which has
    been showing benefits in reducing inference costs.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: æç¤ºçš„è¿™ä¸€æ–¹é¢ç›¸å¯¹æœªè¢«æ·±å…¥æ¢ç´¢ã€‚[2022å¹´12æœˆçš„ç ”ç©¶](https://arxiv.org/abs/2212.06094) é¦–æ¬¡ç¡®ç«‹äº†è¿™ä¸€æ¦‚å¿µï¼Œå¹¶è§£é‡Šäº†ä»£ç é£æ ¼è¯­è¨€æå‡æ€§èƒ½èƒŒåçš„åŸå› ï¼Œä½¿å¾—å¤æ‚äº¤äº’ã€æ§åˆ¶æµå’Œçº¦æŸèƒ½å¤Ÿæ˜ç¡®é™ˆè¿°ç»™LLMã€‚å¼€å‘è€…ç¤¾åŒºé€šè¿‡ä¸€ä¸ªåä¸º
    [å¤§å‹æ¨¡å‹æŸ¥è¯¢è¯­è¨€](https://twitter.com/lmqllang?lang=en) çš„å¼€æºé¡¹ç›®æ­£å¼åŒ–äº†è¿™äº›ä¼˜åŠ¿ï¼Œå¹¶æ˜¾ç¤ºå‡ºåœ¨å‡å°‘æ¨æ–­æˆæœ¬æ–¹é¢çš„å¥½å¤„ã€‚
- en: '[**Prompt 5**](https://promptlayer.com/share/def302e288e90015fd709814cf80b443)**â€”
    Role-play, Financial Incentives & Avoiding Hallucination (Round 3) ğŸ¤¥:**'
  id: totrans-split-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[**æç¤º 5**](https://promptlayer.com/share/def302e288e90015fd709814cf80b443)**
    â€” è§’è‰²æ‰®æ¼”ã€è´¢åŠ¡æ¿€åŠ±åŠé¿å…å¹»è§‰ï¼ˆç¬¬ä¸‰è½®ï¼‰ ğŸ¤¥ï¼š**'
- en: 'For this last, and winning, prompt â€” we see some of our previous tactics come
    together: Doâ€™s and Donâ€™ts and specific output format. It, however, adds three
    other proven â€œtricksâ€ into the mix: role-play, financial incentives/weighting,
    and just asking the model not to hallucinate.'
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: å¯¹äºè¿™æœ€åçš„ã€ä¹Ÿæ˜¯è·èƒœçš„æç¤º â€” æˆ‘ä»¬çœ‹åˆ°ä¸€äº›å…ˆå‰çš„ç­–ç•¥æ±‡èšåœ¨ä¸€èµ·ï¼šåšä¸ä¸åšå’Œç‰¹å®šçš„è¾“å‡ºæ ¼å¼ã€‚ç„¶è€Œï¼Œå®ƒè¿˜å°†å…¶ä»–ä¸‰ç§ç»è¿‡éªŒè¯çš„â€œæŠ€å·§â€ç»“åˆåœ¨ä¸€èµ·ï¼šè§’è‰²æ‰®æ¼”ã€è´¢åŠ¡æ¿€åŠ±/åŠ æƒä»¥åŠä»…ä»…å‘Šè¯‰æ¨¡å‹ä¸è¦äº§ç”Ÿå¹»è§‰ã€‚
- en: '**Role-play**'
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**è§’è‰²æ‰®æ¼”**'
- en: 'So first role-play: at the top, we can see the prompt calls for the model to
    play the part of an AI financial advisor. While this was almost baked into the
    roundâ€™s prompt, it still represents an important innovation in the prompt. Role-playing
    has been shown to improve outputs from LLMs, perhaps because it causes more specific
    context to be drawn from the LLMâ€™s training corpus. No matter the reasoning, it
    significantly improves performance.'
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ç¬¬ä¸€ä¸ªè§’è‰²æ‰®æ¼”ï¼šåœ¨é¡¶éƒ¨ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°æç¤ºè¦æ±‚æ¨¡å‹æ‰®æ¼”AIè´¢åŠ¡é¡¾é—®çš„è§’è‰²ã€‚è™½ç„¶è¿™å‡ ä¹å·²ç»èå…¥åˆ°æœ¬è½®çš„æç¤ºä¸­ï¼Œä½†å®ƒä»ä»£è¡¨äº†æç¤ºä¸­çš„ä¸€ä¸ªé‡è¦åˆ›æ–°ã€‚è§’è‰²æ‰®æ¼”å·²è¢«è¯æ˜èƒ½å¤Ÿæ”¹å–„LLMçš„è¾“å‡ºï¼Œä¹Ÿè®¸æ˜¯å› ä¸ºå®ƒèƒ½å¤Ÿä»LLMçš„è®­ç»ƒè¯­æ–™åº“ä¸­æå–æ›´å…·ä½“çš„ä¸Šä¸‹æ–‡ã€‚æ— è®ºå…¶åŸå› å¦‚ä½•ï¼Œå®ƒéƒ½æ˜¾è‘—æé«˜äº†æ€§èƒ½ã€‚
- en: '**Weighting**'
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**åŠ æƒ**'
- en: The other two hacks work well due to how an LLM operates. LLMs often donâ€™t have
    complete certainty in their responses. To bridge the gap in their knowledge, they
    make informed guesses, sometimes referred to as hallucinations. This hallucination
    is correct most of the time, but when it does not, it can be costly. Hereâ€™s how
    this prompt tackles that. In giving the LLM the data that a correct answer gets
    $1,000 but a wrong answer subtracts $10,000, the prompt intuitively tells the
    model to err on the side of caution. Simply showing the model that youâ€™d rather
    it played it safe and didnâ€™t take risks forces it to be more measured in its responses.
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: å¦å¤–ä¸¤ä¸ªæŠ€å·§ä¹‹æ‰€ä»¥æœ‰æ•ˆï¼Œæ˜¯å› ä¸ºLLMçš„è¿è¡Œæ–¹å¼ã€‚LLMé€šå¸¸åœ¨å…¶å“åº”ä¸­æ²¡æœ‰å®Œå…¨çš„ç¡®å®šæ€§ã€‚ä¸ºäº†å¼¥è¡¥ä»–ä»¬çŸ¥è¯†ä¸Šçš„å·®è·ï¼Œå®ƒä»¬ä¼šåšå‡ºæœ‰æ ¹æ®çš„çŒœæµ‹ï¼Œæœ‰æ—¶è¢«ç§°ä¸ºå¹»è§‰ã€‚è¿™ç§å¹»è§‰å¤§å¤šæ•°æ—¶å€™æ˜¯æ­£ç¡®çš„ï¼Œä½†å½“å®ƒä¸æ­£ç¡®æ—¶ï¼Œä»£ä»·å¯èƒ½å¾ˆé«˜ã€‚è¿™ä¸ªæç¤ºå¦‚ä½•è§£å†³è¿™ä¸ªé—®é¢˜å‘¢ï¼Ÿé€šè¿‡å‘Šè¯‰LLMï¼Œæ­£ç¡®ç­”æ¡ˆçš„æ•°æ®ä¼šå¾—åˆ°$1,000ï¼Œä½†é”™è¯¯ç­”æ¡ˆä¼šæ‰£é™¤$10,000ï¼Œè¿™ä¸ªæç¤ºç›´è§‚åœ°å‘Šè¯‰æ¨¡å‹ä¿å®ˆè¡Œäº‹ã€‚ç®€å•åœ°å‘Šè¯‰æ¨¡å‹ï¼Œä½ å®æ„¿å®ƒä¿å®ˆè¡Œäº‹ï¼Œè€Œä¸å†’é™©ï¼Œè¿«ä½¿å®ƒåœ¨å›ç­”æ—¶æ›´åŠ è°¨æ…ã€‚
- en: '**Anti-Hallucination**'
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**æŠ—å¹»è§‰**'
- en: Along the same line of reasoning, just adding â€œdo not hallucinateâ€ has been
    shown to reduce the odds a model hallucinates. This inclusion further asks the
    model to play it safe.
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨åŒæ ·çš„æ¨ç†çº¿ä¸Šï¼Œåªè¦æ·»åŠ â€œä¸è¦äº§ç”Ÿå¹»è§‰â€ï¼Œå°±èƒ½å‡å°‘æ¨¡å‹äº§ç”Ÿå¹»è§‰çš„å¯èƒ½æ€§ã€‚è¿™ç§åŒ…å«è¿›æ¥çš„åšæ³•è¿›ä¸€æ­¥è¦æ±‚æ¨¡å‹ä¿å®ˆè¡Œäº‹ã€‚
- en: Implementing so many prompt engineering features helps explain why this prompt,
    and the engineer behind it, took the gold in our competition ğŸ¥‡.
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: å®æ–½å¦‚æ­¤å¤šçš„æç¤ºå·¥ç¨‹ç‰¹æ€§æœ‰åŠ©äºè§£é‡Šä¸ºä»€ä¹ˆè¿™ä¸ªæç¤ºä»¥åŠèƒŒåçš„å·¥ç¨‹å¸ˆåœ¨æˆ‘ä»¬çš„æ¯”èµ›ä¸­å¤ºå¾—äº†é‡‘ç‰Œ ğŸ¥‡ã€‚
- en: '**Concluding Thoughts ğŸ’­:**'
  id: totrans-split-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**æ€»ç»“æ€è€ƒ ğŸ’­ï¼š**'
- en: This event was awesome and showcased just how much of an art prompt engineering
    is. Each hacker came with their own nifty tips and tricks, which have some seriously
    awesome performance when combined. At PromptLayer, we are building a platform
    for this new category of knowledge work called *prompt engineering*. Collaboratively
    write new prompts, evaluate their performance, and monitor their production usage.
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ¬¡æ´»åŠ¨éå¸¸æ£’ï¼Œå±•ç¤ºäº†æç¤ºå·¥ç¨‹æ˜¯å¤šä¹ˆä¸€é—¨è‰ºæœ¯ã€‚æ¯ä¸ªé»‘å®¢éƒ½å¸¦æ¥äº†ä»–ä»¬è‡ªå·±çš„å·§å¦™æŠ€å·§ï¼Œåœ¨ç»“åˆä½¿ç”¨æ—¶è¡¨ç°å‡ºè‰²ã€‚åœ¨PromptLayerï¼Œæˆ‘ä»¬æ­£åœ¨å»ºç«‹ä¸€ä¸ªåä¸º
    *æç¤ºå·¥ç¨‹* çš„æ–°ç±»åˆ«çŸ¥è¯†å·¥ä½œå¹³å°ã€‚å…±åŒç¼–å†™æ–°çš„æç¤ºï¼Œè¯„ä¼°å®ƒä»¬çš„æ€§èƒ½ï¼Œå¹¶ç›‘æ§å®ƒä»¬çš„ç”Ÿäº§ä½¿ç”¨ã€‚
- en: Until then, keep on prompting, and if you have any questions or just want to
    chat, feel free to contact us @ [hello@promptlayer.com](mailto:hello@promptlayer.com)
    ğŸ°
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: ç›´åˆ°é‚£æ—¶ï¼Œè¯·ç»§ç»­æ¨åŠ¨ï¼Œå¦‚æœæ‚¨æœ‰ä»»ä½•é—®é¢˜æˆ–åªæ˜¯æƒ³èŠå¤©ï¼Œè¯·éšæ—¶é€šè¿‡ [hello@promptlayer.com](mailto:hello@promptlayer.com)
    è”ç³»æˆ‘ä»¬ ğŸ°ã€‚
- en: '**Appendix:**'
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**é™„å½•ï¼š**'
- en: 'Round 1:'
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: 'Round 1:'
- en: 'Round 2:'
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: 'Round 2:'
- en: 'Round 3:'
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: 'Round 3:'
