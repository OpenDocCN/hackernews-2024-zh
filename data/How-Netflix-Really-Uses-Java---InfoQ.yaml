- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-29 13:25:08'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-29 13:25:08'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: How Netflix Really Uses Java - InfoQ
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Netflix如何真正使用Java - InfoQ
- en: 来源：[https://www.infoq.com/presentations/netflix-java/](https://www.infoq.com/presentations/netflix-java/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.infoq.com/presentations/netflix-java/](https://www.infoq.com/presentations/netflix-java/)
- en: Transcript
  id: totrans-split-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 脚本
- en: 'Bakker: I''m going to talk about how Netflix is really using Java. You probably
    know that Netflix is really just about RxJava microservices, with Hystrix and
    Spring Cloud. Really, Chaos Monkeys are just running the show. I''m only half
    getting here because a few years ago, this was actually mostly true, maybe except
    the Chaos Monkeys. This stack was something that we were building on in the last
    several years. Things have changed. Quite often, I have conversations with people
    at conferences like this one, where they''re like, yes, we were using the Netflix
    stack. Like, which stack exactly are you talking about? It''s almost never the
    stack that we''re actually using. These are just things that people associate
    with Netflix, because we''ve been talking about our technology for so many years,
    but things might have changed a little bit. We''re going to bust some myths. We''re
    going to take a look at what we''re actually doing with Java. Things are ever-evolving.
    Things are literally just changing all the time.'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 'Bakker: 我要谈谈Netflix如何真正使用Java。你可能知道Netflix实际上主要是使用RxJava微服务，配合Hystrix和Spring
    Cloud。实际上，混沌猴（Chaos Monkeys）正在主导这个秀。我只能说到这里，因为几年前，这基本上是真实的，也许除了混沌猴。这些技术堆栈是我们在过去几年中一直在构建的。事情已经发生了变化。在这样的会议上，我经常与人们交谈，他们会说，是的，我们正在使用Netflix的技术栈。但是具体是哪个技术栈呢？几乎从来不是我们实际使用的技术栈。这些只是因为我们多年来一直在谈论我们的技术，人们才与Netflix关联起来的东西，但事情可能有所变化。我们将打破一些神话。我们将看看我们实际上是如何使用Java的。事情正在不断发展。事情真的一直在变化。'
- en: Background
  id: totrans-split-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 背景
- en: My name is Paul. I'm in the Java Platform at Netflix. Java Platform is responsible
    for the libraries, frameworks, and tooling that we built around Java, so that
    all our Java developers have a good time developing Java applications. I'm also
    a Java champion. I have been in the Java space for quite a long time. In the past,
    I wrote two books about Java modularity. I'm also one of the first authors of
    the DGS framework, that's the GraphQL framework we use for Java. We'll talk quite
    a bit about DGS, and how that all fits in the architecture.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我叫Paul。我在Netflix的Java平台工作。Java平台负责我们围绕Java构建的库、框架和工具，确保所有Java开发人员在开发Java应用时能够愉快地工作。我也是一名Java冠军。我在Java领域已经有相当长的时间了。过去，我写了两本关于Java模块化的书籍。我还是DGS框架的首批作者之一，这是我们在Java中使用的GraphQL框架。我们将详细讨论DGS及其在架构中的应用。
- en: Evolving Architecture
  id: totrans-split-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 演变的架构
- en: Before we start diving into JVMs and how we use Java, and the framework that
    we're using, we have to understand a little bit better how our architecture has
    been evolving. That explains why we did things in a certain way with Java several
    years ago, and we're doing things quite differently today. What you should understand
    about Java at Netflix is that we have a lot of Java. We are basically a Java shop,
    and every backend at Netflix is basically a Java app. We have many applications.
    At the size of Netflix, there's lots of internal applications to just keep track
    of things. We're also one of the largest film studios in the world. There's a
    lot of software being developed just to produce films, basically, again, all Java.
    Then of course, we have what we call the streaming app, which is basically the
    Netflix app, as you probably know it. That is what we're looking at here. This
    screen here is what we call the LOLOMO, the list of list of movies. That is just
    one example of an application that is backed by Java. You have to understand that
    pretty much everything that I'm talking about, that is true for basically every
    backend in Java. We use the same architecture now for pretty much all our different
    systems, both internal and consumer facing, and we use the same tech stack everywhere.
    Although I'm giving that example, because it's just a large example to play with,
    it's much more universal than that.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始深入探讨 JVM 和我们使用的 Java，以及我们使用的框架之前，我们必须更好地理解我们的架构是如何演变的。这解释了为什么几年前我们以某种方式使用
    Java，而今天我们的做法完全不同。关于 Netflix 的 Java，你应该了解我们有大量的 Java。我们基本上是一个 Java 店，Netflix 的每个后端基本上都是一个
    Java 应用程序。我们有许多应用程序。在 Netflix 这样的规模下，有很多内部应用程序仅用于跟踪事务。我们还是世界上最大的电影制片厂之一。有很多软件仅用于制作电影，基本上还是全部
    Java。然后当然，我们有我们称之为流媒体应用的东西，基本上就是 Netflix 应用，你可能已经知道了。这就是我们在这里看到的。这个屏幕我们称之为 LOLOMO，即电影列表的列表。这只是一个由
    Java 支持的应用程序的示例。你必须明白，我所说的几乎所有内容，对于基本上每一个 Java 后端来说都是正确的。我们现在几乎所有不同的系统，无论是内部系统还是面向消费者的系统，都使用相同的架构，并且在各处使用相同的技术栈。虽然我举了这个例子，因为这只是一个大的例子来玩弄，但它比那更加普遍。
- en: The Groovy Era
  id: totrans-split-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Groovy 时代
- en: When I joined Netflix almost seven years ago, we were in what I call the Groovy
    era. What you probably know about Netflix, and this is still true, is that Netflix
    has a microservices ecosystem. Basically, every piece of functionality and every
    piece of data is owned by a specific microservice. There's many of them, literally
    thousands of them. On the slide here, I just made it up, because it makes sense
    in my head. It's a much-simplified version of what we actually have in production.
    Think about this LOLOMO screen, this list of list of movies that we just looked
    at, at a previous slide, you're probably familiar with that screen, that to render
    that screen, we would have to fetch data from many different microservices. Maybe
    there's like a top 10 service that we need, because we need a top 10 list of movies.
    That's backed by a specific service. Then there's an artwork service that gives
    us the images as we show in the LOLOMO, and these are all personalized as well.
    There's probably a movie metadata service, which gives us movie titles and actors
    and descriptions of movies. There's probably a LOLOMO service which is actually
    giving us what lists to actually render, which again is personalized. I say that
    we have maybe 10 services to call out to. It will be usually inefficient if your
    device, let's say, your TV, or your iOS device will just do 10 network calls to
    these different microservices. It will just not scale at all. You would have a
    very bad customer experience. It would feel like using the Disney app. It's just
    not ideal. Instead, we need a single front door for the API where your device
    is calling out to. From there, we do a fanout to all the different microservices,
    because now we are in our network, we are on a very fast network. Now we can do
    that fanout without performance implications. We have another problem to solve,
    because all these different devices, in subtle ways, they're all a little bit
    different. We try to make the UI look and behave similar on every different device.
    All these different devices, like a TV versus an iOS device have very different
    limitations when it comes to memory, network bandwidth. They actually load data
    in subtly different ways.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当我大约七年前加入Netflix时，我们正处于我称之为Groovy时代。关于Netflix，你可能知道的是，Netflix拥有微服务生态系统。基本上，每个功能和每个数据片段都由特定的微服务管理。它们有很多，确切地说有成千上万个。在这张幻灯片上，我只是凭自己的想法制作了一个简化版，因为这样更容易理解。想象一下LOLOMO屏幕，就是我们之前看到的电影列表的列表，你可能对那个屏幕很熟悉，为了呈现那个屏幕，我们需要从许多不同的微服务获取数据。也许有一个前十名的服务，因为我们需要一个电影的前十名列表。那个服务由一个特定的服务支持。然后还有一个艺术品服务，我们在LOLOMO中显示的图像就是从那里得到的，这些图像也都是个性化的。可能还有一个电影元数据服务，提供电影标题、演员和电影描述。可能还有一个LOLOMO服务，实际上提供我们要呈现的列表，同样也是个性化的。我说我们可能需要调用10个服务。如果你的设备，比如说你的电视或者你的iOS设备，必须要对这些不同的微服务进行10次网络调用，那将非常低效。根本不可能扩展。你将会得到一个非常糟糕的客户体验。感觉就像使用迪士尼的应用一样。这根本不理想。相反，我们需要一个API的单一入口，你的设备通过它进行调用。从那里，我们向所有不同的微服务做扇出操作，因为现在我们的网络速度非常快。现在我们可以在没有性能影响的情况下做这个扇出操作。我们还有另一个问题要解决，因为所有这些不同的设备，在微妙的方式上，它们都有一点不同。我们试图让UI在每种不同的设备上看起来和行为类似。所有这些不同的设备，比如电视与iOS设备，在内存、网络带宽方面都有非常不同的限制。它们实际上以微妙不同的方式加载数据。
- en: Think about, how would you create an API that would work for all these different
    devices? Let's say you create a REST API. We're probably going to get either too
    little or too much data. If we create one REST API to rule them all, it's going
    to be a bad experience for all these different devices, because we always waste
    some data, or we have to do multiple network calls, which is also bad. To fix
    that problem, what we did is we used what we call a backend for frontend pattern.
    Basically, every frontend, every UI gets its own mini backend. That mini backend
    is then responsible for doing the fanout and get the data that that UI exactly
    needs at that specific point. They used to be backed by a Groovy script. That
    mini backend was basically a Groovy script for a specific screen on a specific
    device, or actually a version of a specific device. These scripts would be written
    by UI developers, because they are the only ones who actually know what data exactly
    they need to render a specific screen. This Groovy script would just live in an
    API server, which is a giant Java app, basically. It would do a fanout to all
    these different microservices by just calling Java client libraries. These client
    libraries are just basically wrappers for either a gRPC service, or a REST client.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 想想看，你会如何创建一个适用于所有这些不同设备的 API？假设你创建了一个 REST API。我们可能会得到太少或太多的数据。如果我们创建一个 REST
    API 来统治它们所有，对于所有这些不同的设备来说都会是一个糟糕的体验，因为我们总是浪费一些数据，或者我们必须进行多次网络调用，这也是不好的。为了解决这个问题，我们所做的是使用我们所谓的后端为前端模式。基本上，每个前端，每个
    UI 都有自己的迷你后端。这个迷你后端负责进行扇出，并获取该 UI 在特定点上确切需要的数据。它们过去是由 Groovy 脚本支持的。这个迷你后端基本上是一个特定屏幕上特定设备的
    Groovy 脚本，或者实际上是特定设备版本的 Groovy 脚本。这些脚本将由 UI 开发人员编写，因为他们是唯一真正知道他们需要渲染特定屏幕所需的确切数据的人。这个
    Groovy 脚本只会存在于一个 API 服务器中，这个服务器基本上是一个巨大的 Java 应用程序。它将通过调用 Java 客户端库向所有这些不同的微服务进行扇出。这些客户端库基本上只是
    gRPC 服务或 REST 客户端的包装器。
- en: Now, here we started seeing an interesting problem, because, how do you take
    care of such a fanout in Java? That's actually really not trivial. Because if
    you will do this the traditional way, you create a bunch of threads, and you start
    to manage that fanout with just minimal thread management, that gets very hairy
    very quickly, because it's not just managing a bunch of threads, it is also taking
    care of fault tolerance. What if one of those services are not responding quickly
    enough? What if it is just failing? Now we have to clean up threads and make sure
    that everything comes together nicely again. Again, not trivial at all. This is
    where RxJava and reactive programming really came in. Because reactive programming
    gives you a much better way to do such fanouts. It will take care of all the thread
    management and stuff like that you need to do. Exactly because of this fanout
    behavior, that is why we went so deep into the reactive programming space, and
    we were partly responsible for making RxJava a big thing many years ago. On top
    of RxJava, we created Hystrix, which is a fault tolerant library, which takes
    care of failover and bulkheading, and all these things. This made a lot of sense
    seven years ago when I joined. This was the big architecture that was serving
    most traffic. Actually, it is still a big part of our architecture, because depending
    on what device you're using, if it's a slightly older device, you probably still
    get served by this API, because we don't have just the one architecture we have
    many architectures, because it is nicer that way.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在这里我们开始看到一个有趣的问题，因为，在 Java 中如何处理这样的扇出？这实际上并不是微不足道的。因为如果你按照传统方式做，创建一堆线程，并开始通过最小的线程管理来管理那个扇出，那很快就会变得非常混乱，因为这不仅仅是管理一堆线程，还要处理容错。如果其中一个服务没有及时响应怎么办？如果它只是失败了？现在我们必须清理线程，并确保一切再次完美地组合在一起。再次强调，这一点根本不是微不足道的。这就是
    RxJava 和响应式编程真正发挥作用的地方。因为响应式编程为你提供了一个更好的方式来进行这样的扇出。它将处理所有你需要做的线程管理等等。正是因为这种扇出行为，这就是为什么我们如此深入地涉足响应式编程领域，并且在许多年前我们在一定程度上负责使
    RxJava 成为一个大事件。在 RxJava 之上，我们创建了 Hystrix，这是一个容错库，它负责故障转移和隔离以及所有这些事情。这在我七年前加入时是有很多道理的。这是当时服务大部分流量的重要架构。实际上，它仍然是我们架构的一个重要部分，因为根据你使用的设备，如果是稍旧的设备，你可能仍然会通过这个
    API 被服务，因为我们不只有一个架构，我们有许多架构，因为这样更好。
- en: Limitations
  id: totrans-split-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制
- en: There are some limitations, although this obviously works really well, because
    we have been able to grow our member base based on this architecture primarily.
    One downside is that there's a script for each endpoint. Because, again, we need
    an API for each of these different UIs. There are just a lot of scripts to maintain
    and manage. Another problem is that because the UI developers have to create all
    the mini backends because they are the ones who know what data they need, they
    have to write those. Now they are in the Groovy Java space and using RxJava. Although
    they're very capable of doing so, it's probably not a primary language that they
    are using on a daily basis. The main problem is really that reactive is just really
    hard. Speaking for myself, I've been doing reactive programming for at least 10
    years. I used to be extremely excited about it, and tell everyone about how great
    it all is. It is actually hard, because even if with that experience, look at
    a non-trivial piece of reactive code, I have no clue what's going on. It takes
    me quite a bit of time to actually wrap my head around, ok, this is actually what's
    happening. These are the operations that are supposed to happen. This is the fallback
    behavior. It's hard.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这显然效果非常好，因为我们主要是基于这种架构扩展我们的成员群体。 一个缺点是每个端点都有一个脚本。 因为我们需要为这些不同的 UI 创建 API。
    有很多脚本要维护和管理。 另一个问题是 UI 开发人员必须创建所有的迷你后端，因为他们知道他们需要什么数据。 现在他们处于 Groovy Java 空间，并使用
    RxJava。 尽管他们非常有能力做到这一点，但这可能不是他们日常使用的主要语言。 主要问题实际上是响应式确实很难。 就我个人而言，我至少已经进行了10年的响应式编程。
    我曾经对此非常兴奋，并告诉每个人它有多么棒。 事实上很难，因为即使有了这种经验，看一个非平凡的响应式代码片段，我也不知道发生了什么。 实际上，我需要花很长时间才能真正理解，好的，这实际上是发生了什么。
    这些是应该发生的操作。 这是后备行为。 很难。
- en: GraphQL Federation
  id: totrans-split-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GraphQL 联合
- en: Slowly, we have been migrating to a completely new architecture, and that is,
    we're putting things to a different perspective. That's all based on GraphQL Federation.
    Comparing GraphQL to REST, one very important aspect of GraphQL is that with GraphQL,
    you always have a schema. In your schema, you put all your operations, so your
    queries and your mutations, and you define them, and you tell it exactly which
    fields are available from the types that you're returning from your queries. Here
    we have a shows query, which returns a show type, and a show as a title, and it
    has reviews. Reviews again is another type that we define. Then we can send a
    query to our API, which is on the right-hand side of the slide. What we have to
    do there, and this is, again, really important, we have to be explicit about our
    field selection. We can't just ask for shows and get old data from shows. Now
    we have to say specifically that you want to get a title and the star score on
    reviews on a show. If we're not asking for a field, we're not getting a field.
    It is super important because again, compared with REST, very basically, you get
    whatever the REST service decides to send you. You're just getting the data that
    you're explicitly asking for. It's more work if you specify your query, but it
    solves the whole problem of over-fetching, where you get much more data than you
    actually need. This makes it much easier to create one API that serves all the
    different UIs. Typically, when you send a GraphQL query, you will just get the
    result back encoded as JSON.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 渐渐地，我们已经开始迁移到一个全新的架构，即，我们正在从不同的角度来看待事物。 这一切都基于 GraphQL 联合。 比较 GraphQL 和 REST，GraphQL
    的一个非常重要的方面是，你总是有一个模式。 在你的模式中，你放置所有的操作，所以你的查询和你的变更，你定义它们，并且告诉它确切地从你的查询返回的类型中哪些字段是可用的。
    在这里，我们有一个显示查询，它返回一个显示类型，一个显示作为标题，并且有评论。 评论再次是我们定义的另一种类型。 然后，我们可以向我们的 API 发送一个查询，它在幻灯片的右侧。
    我们必须在那里做的事情，这也是非常重要的，我们必须明确我们的字段选择。 我们不能只要求显示并从显示获取旧数据。 现在我们必须明确地说出你要在显示上获取标题和评论上的星级评分。
    如果我们不请求一个字段，我们就不会得到这个字段。 这非常重要，因为与 REST 相比，非常基本地，你得到任何 REST 服务决定发送给你的东西。 你只是得到你明确要求的数据。
    如果你指定你的查询，那么更多的工作，但它解决了超获取的整个问题，在这里你得到比你实际需要的数据多得多。 这使得创建一个服务所有不同 UI 的 API 更容易。
    通常，当你发送一个 GraphQL 查询时，你只会得到结果编码为 JSON。
- en: We're not just doing GraphQL, we're actually doing GraphQL Federation to fit
    it back into our microservices architecture. In this picture, we still have our
    microservices, but now we call them DGSs. They're just a term that we at Netflix
    came up with. It's a domain graph service. Basically, it's just a GraphQL service.
    There's really nothing special about it, but we call them DGSs. A DGS is just
    a Java microservice, but it has a GraphQL endpoint. It has a GraphQL API. That
    also means it has a schema, because we said that for GraphQL, you always have
    a schema. The interesting thing is that we have, of course, many different DGSs,
    many different microservices. From the perspective of a device, so from the perspective
    of your TV, for example, there's just one big GraphQL schema. The GraphQL schema
    contains all the possible data that we have to render, let's say a LOLOMO. Your
    device doesn't care that there might be a whole bunch of different microservices
    in the backend, and that these different microservices might provide part of that
    schema. On the other side of the story on the microservices sides, in this example,
    our LOLOMO DGS is defining a type show, with just a title. The images DGS can
    extend that type show and add an artwork URL to it. These two different DGSs don't
    know anything about each other than the fact that there is a show type. It can
    both contribute parts of that schema, even on the same types. All they need to
    do is publish their schema to the federated gateway. Now the federated gateway
    knows how to talk to a DGS because they all have a /GraphQL endpoint. That's it.
    It knows these different parts of the schema, so if a query comes in where we
    ask for both title and artwork URL, it knows that it has to call out to these
    different DGSs, and fetch the data that it needs. On a very high level, not that
    different from what you previously had, but there's a lot of differences in the
    details.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不仅仅在使用 GraphQL，实际上我们正在使用 GraphQL 联合来适应我们的微服务架构。在这张图片中，我们仍然有我们的微服务，但现在我们称它们为
    DGSs。这只是 Netflix 提出的一个术语。它是一个领域图服务。基本上，它只是一个 GraphQL 服务。实际上，它没有什么特别之处，但我们称它们为
    DGSs。一个 DGS 只是一个 Java 微服务，但它有一个 GraphQL 终端点。它有一个 GraphQL API。这也意味着它有一个模式，因为我们说对于
    GraphQL，你总是有一个模式。有趣的是，从设备的角度来看，比如从你的电视的角度来看，有一个大的 GraphQL 模式。GraphQL 模式包含了我们渲染
    LOLOMO 所需的所有可能数据。你的设备并不在乎后端可能有一大堆不同的微服务，以及这些不同的微服务可能会提供部分模式。在微服务的另一侧，在这个例子中，我们的
    LOLOMO DGS 正在定义一个类型 show，只有一个标题。图像 DGS 可以扩展该类型 show 并添加一个艺术品 URL。这两个不同的 DGS 互相不知道对方，只知道有一个
    show 类型。它们可以在相同的类型上贡献模式的部分。他们所需要做的就是将他们的模式发布到联合网关。现在联合网关知道如何与 DGS 通信，因为它们都有一个
    /GraphQL 终端点。就是这样。它知道这些不同部分的模式，所以如果一个查询过来，我们要求获取标题和艺术品 URL，它知道它必须调用这些不同的 DGS，并获取它所需要的数据。从非常高的层面来看，并不比之前有太大的不同，但在细节上有很多不同之处。
- en: I'll also change our story here. First of all, we don't have any API duplication
    anymore. We don't need a backend for frontend anymore because GraphQL as an API
    is flexible enough, because of field selection that we don't really need to create
    those device specific APIs anymore. It also means we don't have server-side development
    for UI engineers anymore. That's great. We do get a schema to collaborate on.
    That's a big deal, because now we have closed the gap between UI developers and
    backend engineers, because now they can collaborate on a schema and figure out,
    ok, what data do we need in what format? Very importantly, we don't have any client
    libraries in Java anymore, because the federated gateway just knows how to talk
    to a generic GraphQL service. It doesn't need specific code to call out to the
    specific API. It's all just GraphQL. All it needs to know, how to talk to a GraphQL
    service. That's all. It's all based on the GraphQL specification. We don't need
    specific code to call to a specific microservice anymore.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还要在这里改变我们的故事。首先，我们不再有任何 API 的重复。我们不再需要后端为前端，因为 GraphQL 作为 API 已经足够灵活，由于字段选择，我们不再需要创建那些特定设备的
    API。这也意味着我们不再需要为 UI 工程师进行服务器端开发了。这很棒。我们确实有一个模式可以合作。这很重要，因为现在我们已经缩小了 UI 开发人员和后端工程师之间的差距，因为他们现在可以共同合作一个模式，并弄清楚，哦，我们需要以什么格式获取什么数据？非常重要的是，我们不再有任何
    Java 客户端库了，因为联合网关只需知道如何与通用的 GraphQL 服务通信。它不需要特定的代码来调用特定的 API。一切都只是 GraphQL。它只需要知道如何与
    GraphQL 服务通信。这就是全部。它全部基于 GraphQL 规范。我们不再需要特定的代码来调用特定的微服务了。
- en: What Does that Mean for Our Java Stack?
  id: totrans-split-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这对我们的Java堆栈意味着什么？
- en: Now we get into, how does that change our Java stack? There's really no place
    anymore where we need Rx, or Hystrix, or such things, because previously, we needed
    this because we needed that specific code to call out, ok, I want to call this
    microservice and then this microservice, and at the same time, this other microservice.
    We needed an API for that. We don't need it anymore, because that's now taken
    care of by the GraphQL Federation specification. That's not completely true, because
    the federated gateway itself is actually still using a web client to call the
    different DGSs, and that is still reactive. However, it is not using any specific
    code for this microservice anymore. It's actually a very straightforward piece
    of web client code where it knows, ok, I have to call these three services, just
    go do it. It's all GraphQL, so it's very simple. All the DGSs and the other microservices
    in the backend, they're all just normal Java apps. There's not really anything
    specific about them. They don't need to do any reactive style of programming pretty
    much anywhere.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看，这如何改变我们的Java堆栈？现在我们不再需要Rx、Hystrix或类似的东西，因为以前我们需要这些是因为我们需要特定的代码来调用，好的，我想调用这个微服务，然后这个微服务，同时，还有另一个微服务。我们需要一个API来做到这一点。我们不再需要了，因为这现在由GraphQL联合规范来处理了。这并不完全正确，因为联合网关本身实际上仍在使用Web客户端来调用不同的DGS，而这仍然是响应式的。然而，它不再使用任何特定于这个微服务的代码。实际上，这是一个非常简单的Web客户端代码片段，它知道，好的，我必须调用这三个服务，就去做吧。这都是GraphQL，所以非常简单。所有的DGS和后端的其他微服务都只是普通的Java应用程序。它们没有任何特定的地方需要进行响应式编程。
- en: The Micro in Microservices
  id: totrans-split-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微服务中的“微”
- en: Before we dive deep into the rest of our Java stack, I want to speak a little
    bit about the micro in microservices, because it's another thing that people seem
    to be confused about how it actually works in practice. It is true that a microservice
    owns a specific functionality or dataset. More importantly that such microservices
    are owned by a single team. That is a really important part about microservices.
    It is all even more true with this GraphQL federated architecture, because it's
    now even easier to just split things out in different microservices and make it
    all work very nicely. However, don't be fooled by the size of those microservices,
    because a lot of those so-called microservices at Netflix are a lot larger, just
    looking at the code base, than the big monoliths that I've worked at, at many
    other companies. Some of these systems are really big. There's a lot of code there.
    Of course, when they get deployed, they might be deployed on clusters of thousands
    of AWS instances. There's really nothing small about them. That also answers the
    question, should I do microservices? It depends on your team size. Do you have
    like the one team that takes care of everything, and it's just a small team? If
    you would add microservices there, you're just adding complexity at that point
    for no good reason. If you want to split your team into smaller teams, basically,
    and just because of team size, then it also makes sense to split up your larger
    system into smaller pieces so that each team can own and operate one or more of
    those services.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入了解Java堆栈的其他部分之前，我想稍微谈一下微服务中的“微”这个概念，因为这是另一件人们似乎对实际运作方式感到困惑的事情。确实，一个微服务拥有特定的功能或数据集。更重要的是，这样的微服务由一个团队拥有。这是关于微服务的一个非常重要的部分。在这种GraphQL联合架构中更为真实，因为现在更容易将事物分割成不同的微服务并使其运作得非常顺畅。然而，不要被这些微服务的规模所迷惑，因为Netflix中的许多所谓微服务在代码库方面比我在许多其他公司工作过的大型单体应用还要大。其中一些系统非常庞大。那里有很多代码。当然，当它们被部署时，它们可能会被部署在成千上万个AWS实例的集群上。它们真的一点都不小。这也回答了一个问题，我应该使用微服务吗？这取决于你的团队规模。你是否只有一个团队负责一切，而且只是一个小团队？如果你在这里添加微服务，那么在那一点上你只是增加了复杂性而没有任何好的理由。如果你想将团队分成更小的团队，基本上，仅仅因为团队规模，那么将较大的系统分割成较小的部分也是有意义的，这样每个团队就可以拥有和运营一个或多个这些服务。
- en: Java at Netflix
  id: totrans-split-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Netflix的Java
- en: Time to actually really get into the Java side of things. We now know, on a
    higher level, how and where we're using Java. Now we talk about how it actually
    looks like. We are now mostly on Java 17\. It is about time. We are already also
    actively testing and rolling out with Java 21\. Java 21 just came out officially.
    We're just using a regular Azul Zulu JVM. It's just an OpenJDK build. We are not
    building our own JVM, we don't have any plans to build our own JVM. Although there
    was a very interesting Reddit thread claiming that we do. We really don't, and
    have no interest in doing so. OpenJDK is really great. We have about 2800 Java
    applications. These are mostly all microservices of a variety of sizes. Then about
    1500 internal libraries. Some of them are actual libraries, and many of them are
    just client libraries, which is basically just sitting in front of a gRPC or REST
    service. For our build system, we use Gradle, and on top of Gradle we have Nebula,
    that's a set of open sourced Gradle plugins. The most important aspect of Nebula,
    and I highly recommend looking into this, is, first in resolution of libraries.
    As you know, Java has a flat classpath. You can only have the one version of the
    library at a given time, if you have more than one version, interesting things
    happen. To prevent these interesting things from happening, you really want to
    just pick one, basically, and Nebula takes care of that. The next thing that Nebula
    does is version locking. Basically, you will get reproducible builds that you
    always build with the same set of versions of libraries until you explicitly upgrade.
    That makes it all very reproducible. We're pretty much exclusively using IntelliJ
    as our IDE. In the last few years, we have also invested a lot of effort in actually
    developing IntelliJ plugins, to help developers doing the right thing.
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 是时候真正深入了解 Java 方面的事情了。我们现在在更高层次上知道我们如何以及在哪里使用 Java。现在我们谈论它实际上是什么样子。我们现在主要在使用
    Java 17。是时候了。我们已经在积极测试和推广 Java 21。Java 21 刚刚正式发布。我们只是使用常规的 Azul Zulu JVM。这只是一个
    OpenJDK 构建。我们不构建自己的 JVM，也没有计划去构建自己的 JVM。尽管有一个非常有趣的 Reddit 帖子声称我们这样做了。我们真的没有，也没有兴趣这样做。OpenJDK
    真的非常棒。我们有大约 2800 个 Java 应用程序。这些主要是各种大小的微服务。然后大约有 1500 个内部库。其中一些是实际的库，许多只是客户端库，基本上只是坐在
    gRPC 或 REST 服务的前面。对于我们的构建系统，我们使用 Gradle，而在 Gradle 之上我们有 Nebula，这是一组开源的 Gradle
    插件。Nebula 最重要的方面，我强烈建议您深入研究一下，是第一次解析库。正如您所知，Java 有一个扁平的类路径。您在给定时间只能有一个版本的库，如果您有多个版本，会发生有趣的事情。为了防止这些有趣的事情发生，您真的只想选择一个版本，基本上
    Nebula 会处理这些。Nebula 的下一个功能是版本锁定。基本上，您将获得可重现的构建，您总是使用相同的库版本集合构建，直到您明确升级。这使得所有过程都非常可重现。我们几乎完全使用
    IntelliJ 作为我们的 IDE。在过去几年中，我们还投入了大量精力来开发 IntelliJ 插件，以帮助开发人员做正确的事情。
- en: The Java 17 Upgrade
  id: totrans-split-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Java 17 升级
- en: We are mostly on Java 17\. That is actually a big deal, because this is embarrassing,
    but at the beginning of the year, we were mostly on Java 8\. Java 8 is old. Why
    were we still on Java 8? Because we had Java 11, and then Java 17 available for
    a very long time already. Somehow, we just didn't move. One of the reasons is
    that until about a year ago, about half of our microservices, especially the bigger
    ones, were still on our old application stack. It was not Spring. It was a homegrown
    thing based on Guice, and a lot of old Java EE APIs, lots of old libraries that
    were no longer maintained. At the very beginning when we started upgrading to
    Java 11 initially, a lot of these older libraries were just not compatible. Then
    developers just got the impression that this upgrade is hard, and it breaks things,
    and I should probably just not do it. On the other hand, there was also very limited
    perceived benefits for developers, because if you compare Java 8 to Java 17, there's
    definitely some nice language features. Text blocks alone are enough reason for
    me to upgrade, but it's not that big of a deal. The differences between 8 and
    17 is nice, but it's not like changing your life that much. There was more excitement
    about moving to Kotlin than we did in just upgrading to JDK.
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们大部分都在使用Java 17。这实际上是一件大事，因为这很尴尬，但在年初时，我们大部分还在使用Java 8。Java 8已经很老了。为什么我们还在使用Java
    8呢？因为我们早就有Java 11和Java 17可用了很长时间了。不知何故，我们就是没有升级。其中一个原因是直到大约一年前，我们约一半的微服务，尤其是那些较大的微服务，仍然在使用我们旧的应用程序堆栈。那不是Spring。那是一个基于Guice的自制东西，还有很多旧的Java
    EE API，很多旧的不再维护的库。当我们最初开始升级到Java 11时，很多这些旧库都不兼容。然后开发人员就有了这种升级很困难，会导致问题，我可能就不要做了的印象。另一方面，对于开发人员来说，感知到的好处也非常有限，因为如果你比较Java
    8和Java 17，肯定有一些不错的语言特性。仅仅文本块就足够让我升级，但这并不是什么大不了的事。8和17之间的差异很好，但并不像改变你的生活那么大。我们更期待移动到Kotlin，而不是仅仅升级到JDK。
- en: When we finally did start pushing on updating to Java 17, we saw something really
    interesting. We saw about 20% better CPU usage on 17 versus Java 8, without any
    code changes. It was all just because of improvements in G1, the garbage collector
    that we are mostly using. Twenty-percent better CPU is a big deal at the scale
    that we're running. That's a lot of money, potentially. Speaking about G1, G1
    is the garbage collector that we use for most of our workloads, at the moment.
    We've tested with all the different garbage collectors available. G1 is generally
    where we got the best balance of tradeoffs. There are some exceptions, for example,
    Zuul, which is our proxy. It runs on Shenandoah, that's the low pause time garbage
    collector. For most workloads, Shenandoah doesn't work as well as G1 does. Although
    G1 isn't that exciting anymore, it is still just really good.
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们最终开始推动升级到Java 17时，我们看到了一些非常有趣的事情。我们发现在17与Java 8相比，CPU使用率提高了约20%，而没有任何代码更改。这完全是因为G1的改进，我们大部分使用的垃圾收集器。在我们运行的规模下，20%更好的CPU使用率是一件大事。这可能是很多钱。说到G1，G1是我们目前大部分工作负载使用的垃圾收集器。我们已经测试了所有可用的不同垃圾收集器。总的来说，G1通常是我们在权衡中得到最好的平衡。也有一些例外，例如我们的代理Zuul。它运行在Shenandoah上，那是低暂停时间的垃圾收集器。对于大多数工作负载，Shenandoah的表现不如G1。虽然G1不再那么令人兴奋，但它仍然非常出色。
- en: Java 21+
  id: totrans-split-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Java 21+
- en: Now that we have finally made a big push to Java 17, and we've got most services
    just upgraded, we also have Java 21 available. We've been testing with that for
    quite a few months already. Now things really get exciting. The first exciting
    thing is that if you're on Java 17, upgrading to Java 21 is almost a no-op. It's
    just super easy. You don't have the problems that we had from Java 8 to newer
    versions. There's also just a lot more interesting features. The first obvious
    one that I'm super excited about is virtual threads. This is just copy-paste,
    it's from the JEP, the specification from Java 21 of virtual threads. It's supposed
    to enable server applications written in a simple thread-per-request style to
    scale at near optimal hardware utilization. It sounds pretty good. This thread-per-request
    style, if you're using something that's based on servlets, so Spring Web MVC,
    or any other framework based on servlets, thread-per-request is basically what
    you get. A request comes in, Tomcat or whatever server you're using gives it a
    thread. That thread is basically where all the work happens, or starts happening
    for the specific request, and stays through that request until the request is
    done. That is a very simple style and easy to understand style of programming,
    and all the frameworks are based on that. It has some scalability limitations,
    because you can only have so many threads effectively running in a system. If
    you have a lot of requests coming in, which we obviously have, then the number
    of threads is just a limiting factor in how you can scale your systems. Changing
    that model is really important. The alternative to that is, of course, doing reactive
    again, so do something like WebFlux. That also gets you in reactive programming,
    again, with all the complexities that we already talked about.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们终于推动到了Java 17，大部分服务已经升级完毕，而且我们现在也有Java 21可用了。我们已经测试了好几个月了。现在事情真的变得很令人兴奋。第一个令人兴奋的是，如果你正在使用Java
    17，升级到Java 21 几乎没有任何操作。这非常容易。你不会像从Java 8升级到更高版本时那样遇到问题。此外，还有很多更有趣的特性。我非常兴奋的第一个显而易见的特性是虚拟线程。这只是复制粘贴，它来自于JEP，Java
    21虚拟线程的规范。它旨在使基于简单的请求线程样式编写的服务器应用在接近最优硬件利用率时扩展。听起来很不错。如果你正在使用基于servlet的东西，比如Spring
    Web MVC或者任何其他基于servlet的框架，请求线程就是你得到的东西。请求进来，Tomcat或者其他服务器给它一个线程。这个线程基本上就是所有工作发生或者开始发生的地方，一直持续到请求完成。这是一种非常简单且易于理解的编程风格，所有的框架都是基于这个的。它有一些可扩展性限制，因为在系统中有效运行的线程数量是有限的。如果有大量请求进来，正如我们显而易见的有，那么线程数就成为了限制系统扩展的因素。改变这种模型真的非常重要。当然，与此相对的是再次采用响应式，例如使用WebFlux。这同样会让你进入响应式编程，同样伴随我们之前讨论过的所有复杂性。
- en: Now, I think that virtual threads is probably the most exciting Java feature
    since probably lambdas. I think that down the line, it is really going to change
    the way we write and scale our Java code. I think that, in the end, it is probably
    going to further reduce reactive code, because there's just not really any need
    for it anymore. It just takes away that complexity. We have already been running
    virtual threads in production for the last month or so, experimenting with it
    a little bit. I'll get back to that in more detail. Then the other interesting
    feature in Java 21 is the new garbage collector or the updated garbage collector,
    because ZGZ is not new. That was already available in previous versions. They
    now made it generational, and that makes it give more benefits over G1 as a garbage
    collector has. That will make ZGC a better fit for a broader variety of workloads.
    It's still focused on low pause times, but it will just work in a broader variety
    of use cases. It's a little bit early to tell because we haven't done enough testing
    with this yet, but we are expecting that ZGC is now going to be a really good
    performance upgrade, basically, for a lot of our workloads and a lot of our services.
    Again, these things are a really big deal, where we could save a lot of money
    on resources. Shenandoah is also now generational, but that is still in preview.
    Again, we're going to just run with that and see what happens. Garbage collection
    is really just too complex of a topic to just know that, drop in this garbage
    collector with this flex, and it's all going to be magic and super-fast. Just
    doesn't work that way. It's a business where you just try things out and then
    you tweak it a bit, and you try it again, and then you find the optimal state.
    We're not quite there yet. We are expecting to see some very interesting things
    there. Then, finally, in Java 21, you just also have a lot of nice language features.
    We get this concept of data-oriented programming now in the Java language. It
    is really nice. It's the combination of records and pattern matching and things
    like that. Java is pretty nice right now.
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我认为虚拟线程可能是自 Lambdas 以来最令人兴奋的 Java 特性。我认为在未来，它真的会改变我们编写和扩展 Java 代码的方式。我认为最终它可能会进一步减少响应式代码的使用，因为实际上再也没有必要了。它只是消除了那种复杂性。我们已经在生产环境中运行了大约一个月的虚拟线程，并对其进行了一些实验。稍后我会更详细地谈谈这方面。然后，Java
    21 中另一个有趣的特性是新的垃圾收集器或更新的垃圾收集器，因为 ZGZ 并不新鲜。这在之前的版本中已经可用了。他们现在将其变成了分代的，这使得它比 G1
    作为垃圾收集器提供了更多的好处。这将使得 ZGC 更适合更广泛的工作负载。它仍然专注于低暂停时间，但它将适用于更广泛的使用场景。现在说还为时过早，因为我们还没有对此进行足够的测试，但我们预计
    ZGC 现在将成为我们很多工作负载和服务的真正性能升级。再次强调，这些事情对我们来说非常重要，我们可以在资源上节省很多费用。Shenandoah 现在也是分代的，但这仍然处于预览阶段。同样，我们将尝试并看看会发生什么。垃圾收集真的是一个太复杂的话题，你不能仅仅通过知道，把这个垃圾收集器和这个弹簧装进去，然后所有的一切就像魔术般地超级快。事实并非如此。这是一个你只能尝试一下，然后稍微调整一下，再尝试一下，然后找到最佳状态的业务。我们还没有完全达到那个状态。我们预计在那里会看到一些非常有趣的事情。最后，在
    Java 21 中，你也有很多很好的语言特性。我们现在在 Java 语言中引入了数据导向编程的概念。这真的很不错。这是记录和模式匹配等元素的结合。目前 Java
    的情况相当不错。
- en: Virtual Threads
  id: totrans-split-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 虚拟线程
- en: Back to virtual threads. Although I said that this is a big deal, and is probably
    going to change the way we write our code and scale our code, it is also not a
    free lunch. It's not just that you enable Java 21 on your instances, and now by
    the magic of virtual threads, everything runs faster. It doesn't work that way.
    First of all, we have to change our framework library, and to some extent application
    code to actually start leveraging virtual threads, so step one. There are a few
    obvious places where we can do that and already started experimenting, so the
    Tomcat connection pool. Again, these are the pool of threads where it gives threads-per-request.
    That seems a fairly obvious place where we can just use virtual threads instead.
    Instead of using a thread pool, you use virtual threads. Before you enable that,
    you are already running some big services in production with virtual threads enabled.
    It doesn't automatically make things a lot faster, because you need to do other
    things as well to really leverage it. It also doesn't make things worse. If you
    can just safely enable this basically, sometimes get some benefits out of it,
    sometimes it doesn't really change it because it wasn't a limiting factor. That's
    something that you should probably start with. Async task execution in Spring
    that is, again, just a thread pool, and very often you get blocking code for other
    network calls there anyway. It seems to be a good candidate for virtual threads,
    so we enabled it there. Then a really big one that we haven't really gotten into
    yet, but I expect that will be game changing is how we do GraphQL query execution.
    Potentially with GraphQL, every field can be fetched in parallel. It makes a lot
    of sense that we would actually do that on virtual threads because, again, this
    is often work in code where you do more network calls and things like that. Virtual
    threads just make a lot of sense there, but we have to implement this and test
    it out, and it'll probably take a little bit of time before we get the optimal
    model there.
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 回到虚拟线程。尽管我说这是一件大事，并且可能会改变我们编写代码和扩展代码的方式，但这并不是免费的午餐。你不能只是在你的实例上启用 Java 21，然后通过虚拟线程的魔法，所有东西都运行得更快。事情不是那么简单。首先，我们必须修改我们的框架库，以及在某种程度上修改应用程序代码，才能真正开始利用虚拟线程，这是第一步。有一些明显的地方我们可以这样做，并且已经开始尝试，比如
    Tomcat 连接池。再次强调，这些是线程池，在那里为每个请求提供线程。这似乎是一个相当明显的地方，我们可以简单地使用虚拟线程代替。在启用它之前，您已经在生产中运行了一些启用了虚拟线程的大服务。它并不会自动使事情变得更快，因为您还需要做其他事情才能真正利用它。它也不会使事情变得更糟。如果您可以安全地启用这个功能，有时会从中获得一些好处，有时并不会真正改变它，因为它并不是限制因素。这可能是您应该首先尝试的事情。在
    Spring 中的异步任务执行，同样是一个线程池，在那里通常会有其他网络调用的阻塞代码。虚拟线程似乎是一个很好的候选者，因此我们在那里启用了它。然后一个真正重要的问题，我们还没有真正深入探讨过，但我预计这将是一个改变游戏规则的问题，就是我们如何执行
    GraphQL 查询。潜在地，对于 GraphQL，每个字段都可以并行获取。这使得在虚拟线程上实际执行更有意义，因为这通常是在代码中进行更多的网络调用等工作。在那里，虚拟线程就显得非常合理，但我们必须实施并测试它，可能需要一点时间才能找到最佳模型。
- en: Then we have some other places that seemed obvious. For example, we have a thread
    worker pool for gRPC clients where the gRPC calls to outgoing services happen.
    It seemed like such an obvious place like, let's drop in virtual threads there.
    Then we saw that we actually decreased performance by a few percent. It turns
    out that these gRPC client worker pools are very CPU intensive. If you then drop
    in virtual threads, you actually make things worse. That's not a bad thing, necessarily.
    This is just something that we had to learn. It does show that this is not a free
    lunch. We actually have to figure out, where does it make sense, where does it
    not make sense, and implement virtual threads at the right points, basically.
    The good news is this is mostly all framework work at this point. We can do it
    as a platform team, and we can do it in open source libraries that we're using.
    Then our developers will just get faster apps, basically. It's good. In Spring
    6.1, or Spring Boot 3.2, there's a lot of work being done to leverage virtual
    threads out of the box, that will come out next month. We will probably adopt
    that somewhere early next year. Then there's a really interesting discussion going
    on on GitHub, in GraphQL Java, about changing the GraphQL query execution, or
    potentially even rewriting it to fully leverage virtual threads. That is not figured
    out yet. It's a discussion going on. If you're in that space, that's definitely
    something to contribute to, I think. Then for the user code, because all this
    other stuff is mostly framework code, for user code, I think structured concurrency
    is the other place that we're going to see a lot of replacement of reactive code.
    Because structured concurrency is finally giving us the API to deal with things
    like fanouts, and then bringing everything together again. Structured concurrency
    is still in preview in Java 21\. It seems very close to final, so I think it's
    at least safe to start experimenting with this and try things out. Then a little
    bit further down the line, we also get scoped values, which is another new specification
    coming out related to virtual threads. That is going to give us a way to basically
    get rid of ThreadLocal. This is again mostly framework related work. It's just
    a much nicer and more efficient way of something similar to ThreadLocal.
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们有一些其他看起来很明显的地方。例如，我们为 gRPC 客户端有一个线程工作池，用于处理对外服务的 gRPC 调用。这似乎是一个很明显的地方，好像我们可以在那里加入虚拟线程。然后我们发现，实际上性能下降了几个百分点。原来这些
    gRPC 客户端的工作池非常消耗 CPU。如果你在那里加入虚拟线程，实际上会使情况变得更糟。这并不一定是坏事。这只是我们必须学习的东西。这表明这不是免费午餐。我们实际上必须弄清楚，在哪里有意义，在哪里没有意义，并在适当的地方实现虚拟线程，基本上。好消息是，这在大多数情况下都是框架工作。我们可以作为一个平台团队来做，我们可以在我们正在使用的开源库中来做。然后我们的开发人员基本上会得到更快的应用程序。这很好。在
    Spring 6.1 或 Spring Boot 3.2 中，正在进行大量工作，以便默认支持虚拟线程，这将在下个月发布。我们可能会在明年初的某个时候采用这项技术。然后在
    GitHub 上有一个非常有趣的讨论正在进行中，关于在 GraphQL Java 中改变 GraphQL 查询执行，或者甚至可能重写它以充分利用虚拟线程。这还没有确定。这是一场正在进行中的讨论。如果你在这个领域，我认为这绝对是一个值得贡献的事情。然后对于用户代码，因为所有这些其他东西大部分都是框架代码，我认为结构化并发是另一个我们将看到大量替代反应式代码的地方。因为结构化并发最终为我们提供了处理类似扇出和再聚合的
    API。在 Java 21 中，结构化并发仍处于预览阶段。看起来非常接近最终版本，所以我认为至少安全地开始尝试和测试这些东西是可行的。然后再进一步，我们还会得到作用域值，这是与虚拟线程相关的另一个新规范即将发布。这将为我们提供一种基本上摆脱
    ThreadLocal 的方法。这再次与框架相关的工作。这只是一个类似于 ThreadLocal 的东西，但更加优雅和高效。
- en: Spring Boot Netflix
  id: totrans-split-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Spring Boot Netflix
- en: I've already mentioned a little bit that we use Spring Boot. Since about a year
    or so we have completely standardized on Spring Boot. Up until a year ago, about
    50% of our applications were still on our own homegrown, not maintained at all,
    Java stack based on Guice, and a bunch of very outdated Java EE libraries. We
    didn't really make a good push in getting everything on Spring Boot. All the new
    applications were based on Spring Boot already. That became very messy, especially
    because that old homegrown framework just wasn't maintained very well. We made
    a really big effort to just get all the services migrated to Spring Boot. That
    migration was mostly just a lot of blood, sweat, and tears of a lot of teams.
    It's just not easy to go from one programming model to another one. As platform
    teams, we did provide a lot of tooling, for example, IntelliJ plugins to take
    care of, where possible, the code migrations and configuration migrations and
    things like that. Still, it was just a lot of work. Pretty painful. Now that we
    are on Spring Boot, though, we have like the one framework that everyone is using
    that makes things a lot nicer for everyone. We are trying to mostly just use the
    latest version of OSS Spring Boot. We're going to be using 3.1, and try to stay
    as close as possible to the open source community because that's where we get
    the most benefit. On top of that, we need a lot of integration with our Netflix
    ecosystem and the infrastructure that we have. That is what we call Spring Boot
    Netflix, and is basically just a whole set of modules which we build on top of
    Spring Boot. That's basically just developed in the same way as Spring Boot itself
    is built, so lots of auto-configurations. That's where we add things like gRPC
    client and server support that's very integrated with our SSO stack, for AuthZ
    and AuthN. You get observability, so tracing, metrics, and distributed logging.
    We have a whole bunch of HTTP clients that take care of mTLS and again observability
    and integration with the security stack. We deploy all these applications with
    embedded Tomcat, which is pretty standard for a Spring Boot application.
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经稍微提到过，我们在使用Spring Boot。大约一年前，我们完全标准化了Spring Boot的使用。一年前，大约50%的应用程序仍然使用我们自己编写的、基于Guice的Java堆栈，但是已经不再维护，并且使用了一堆非常过时的Java
    EE库。我们没有真正推动将所有东西都迁移到Spring Boot上。所有新的应用程序已经基于Spring Boot构建。这变得非常混乱，特别是因为那个旧的自家框架并没有得到很好的维护。我们付出了很大的努力，仅仅是将所有服务迁移到Spring
    Boot上。这次迁移主要是许多团队付出了大量的心血和汗水。从一个编程模型转到另一个编程模型并不容易。作为平台团队，我们提供了大量的工具支持，例如IntelliJ插件，尽可能地处理代码迁移和配置迁移等。尽管如此，这还是需要大量的工作。相当痛苦。不过，现在我们使用Spring
    Boot，我们有了一个统一的框架，使得每个人的工作都变得更加轻松。我们试图主要使用最新版本的开源Spring Boot。我们将使用3.1版本，并尽可能与开源社区保持密切联系，因为这是我们获得最大利益的地方。此外，我们需要与我们的Netflix生态系统和基础设施进行大量集成。这就是我们所说的Spring
    Boot Netflix，基本上只是我们在Spring Boot之上构建的一整套模块。这基本上是按照Spring Boot本身的方式开发的，所以有很多自动配置。在这里，我们添加了诸如gRPC客户端和服务器支持之类的内容，这些内容与我们的SSO堆栈（用于认证和授权）紧密集成。您可以获得可观察性，例如跟踪、指标和分布式日志记录。我们有一整套HTTP客户端，负责处理mTLS，同时也提供了可观察性和与安全堆栈集成。我们使用内嵌的Tomcat部署所有这些应用程序，这在Spring
    Boot应用程序中非常标准化。
- en: To give an idea of the features, how that looks like. We have, for example,
    a gRPC Spring client. This looks very Spring-like, but it is something that we
    added. Basically, this is referencing a property file, which describes the gRPC
    service, it tells where the service lives. It configures failover behavior. That
    way, you can just use a Java API with an extra annotation to call another gRPC
    service. With that, you also get things like observability completely for free.
    For any request, either gRPC or HTTP, you get observability for free with tracing,
    and metrics, and all these things available. Another example is maybe integrate
    with Spring security, so we can get our SSO color. You get the user basically,
    that's called your service, even if there were many services in between in a cold
    chain. As I said, we integrated with Spring Security to also do role-based authentication
    based on our own authentication models.
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了给出特性的概念，看起来是怎样的。例如，我们有一个 gRPC Spring 客户端。这看起来非常像 Spring，但是这是我们添加的一些内容。基本上，这引用了一个属性文件，描述了
    gRPC 服务，告诉服务的位置。它配置了故障转移行为。这样，你可以只需使用一个额外的注解来调用另一个 gRPC 服务的 Java API。通过这样做，你还可以免费获得完整的可观察性。对于任何请求，无论是
    gRPC 还是 HTTP，你都可以通过跟踪、指标和所有这些可用的内容免费获取可观察性。另一个例子可能是与 Spring 安全集成，这样我们就可以获取我们的
    SSO 颜色。即使在冷链中有很多服务，你基本上也可以获得用户，这称为你的服务。正如我所说的，我们还与 Spring Security 集成，根据我们自己的认证模型进行基于角色的认证。
- en: Why Spring Boot?
  id: totrans-split-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么选择 Spring Boot？
- en: You might be wondering, why are we using Spring Boot, why not some other more
    fancy framework? Because, of course, there's been a lot of innovation in the Java
    space in the last few years with other frameworks available. Spring Boot is really
    the most popular Java framework, that doesn't necessarily make it better, but
    it does give a lot of leverage when it comes to using the open source community,
    which is really big, of course, for Spring Boot, and accessing documentation,
    training, and all these things. More importantly, I think, is just looking at
    the Spring framework, it has been just so well maintained over the years. I think
    I started using the Spring framework 15 years ago. It is quite amazing, actually,
    that that framework has been so stable and so well-evolved, basically, over time,
    because it's not the same thing as it was 15 years ago, but a lot of the concepts
    are still there. It gives us a lot of trust, basically in the Spring team that
    also in the future, this will be a very good place to be basically.
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想，为什么我们使用 Spring Boot，而不是一些其他更花哨的框架？因为，在过去几年中，Java 领域有很多创新框架可用。Spring Boot
    确实是最流行的 Java 框架，这并不一定使它更好，但在使用开源社区时确实提供了很大的支持。对于 Spring Boot 来说，这真的很重要，因为可以访问文档、培训和所有这些内容。更重要的是，我认为，只是看看
    Spring 框架，多年来它一直被良好地维护着。我想我大约15年前开始使用 Spring 框架。实际上，这相当令人惊讶，因为这个框架在多年来一直如此稳定和良好地发展，因为它并不是15年前的同一个东西，但很多概念仍然存在。基本上，这给了我们很多对
    Spring 团队的信任，也相信在未来，这将是一个非常好的地方。
- en: The Road to Spring Boot 3
  id: totrans-split-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通往 Spring Boot 3 的道路
- en: Almost a year ago, Spring Boot 3 came out, and that was a big deal, because
    Spring Boot 3 really just involves the Java ecosystem, I think, because the Java
    ecosystem was a little bit stuck in two different ways. The first reason is that
    if you look at the open source ecosystem in Java, it was stuck on Java 8, because
    a lot of companies were stuck on Java 8, and no one wanted to be the first one
    who would break that basically. Companies didn't upgrade because everything just
    worked fine on Java 8 anyway. Now, finally, the Spring team has said, we are done
    with Java 8, Java 17 is your new baseline. Now we force the whole community basically,
    to say, ok, fine, we'll do Java 17, and everything can start moving again. Now
    we can start leveraging those new language features. It also makes it possible
    that although it's just baseline on Java 17, we can actually also start using
    Java 21 with virtual threads under the hood. That's exactly what they're doing.
    The second part is the whole mess around Javax to Jakarta, thanks to Oracle. This
    is just a simple namespace change, but it is extremely complex for a library ecosystem,
    because a library can either use Javax or Jakarta, and that makes it either compatible
    with one but not the other. That's super painful now, because the Spring team
    is now saying, ok, if you're just doing Jakarta, now the whole ecosystem can start
    moving because it had such a big impact. We finally get past that point that they
    were stuck on. It is a big change to get on these new things still, so moving
    to Spring Boot 3 isn't fulfilled, and we've done a lot of tooling work to make
    that happen. Probably the most interesting one there is we open sourced a Gradle
    plugin that does bytecode transformation at artifact resolution time. When you
    download an artifact, a JAR file, it will do bytecode translation if you're on
    Spring Boot 3 from Javax to Jakarta, so it basically just fixes that whole namespace
    problem on the fly, and you don't have to change your library. That gets us unstuck.
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: 大约一年前，Spring Boot 3发布了，这是一件大事，因为Spring Boot 3实际上只涉及到了Java生态系统，我认为，因为Java生态系统在某种程度上有些停滞不前。第一个原因是，如果你看看Java的开源生态系统，它一直停留在Java
    8上，因为很多公司都还停留在Java 8上，没有人愿意成为第一个打破这种情况的人。公司没有升级是因为一切在Java 8上都运行良好。现在，Spring团队终于说，我们已经完成了Java
    8，Java 17是你的新基线。现在我们基本上强制整个社区说，好吧，我们将使用Java 17，一切都可以重新开始运转了。现在我们可以开始利用那些新的语言特性。虽然它只是基于Java
    17，但我们实际上也可以开始使用Java 21，底层使用虚拟线程。这正是他们正在做的。第二部分是关于Javax到Jakarta的混乱，多亏了Oracle。这只是一个简单的命名空间更改，但对于库生态系统来说却非常复杂，因为一个库可以使用Javax或Jakarta，这使得它要么与一个兼容，要么与另一个兼容。现在这非常痛苦，因为Spring团队现在说，好吧，如果你只使用Jakarta，现在整个生态系统可以开始运转了，因为它产生了如此大的影响。我们终于摆脱了他们一直困在的那个点。要想转移到这些新东西仍然是一个很大的变化，所以转移到Spring
    Boot 3并没有完成，我们已经做了很多工具工作来实现这一点。可能最有趣的是，我们开源了一个Gradle插件，在构建解析时进行字节码转换。当你下载一个artifact，一个JAR文件时，如果你使用的是Spring
    Boot 3，它将把Javax转换为Jakarta，这样就可以在运行时解决整个命名空间问题，而不需要更改你的库。这让我们摆脱了困境。
- en: DGS Framework
  id: totrans-split-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DGS框架
- en: Then I talked quite a bit about DGS. DGS is not some concept, GraphQL Federation
    is the concept. The DGS framework is just a framework that that we use to build
    our GraphQL services in Java. About three or four years ago, when we started the
    journey on to GraphQL and GraphQL Federation, there really wasn't any good Java
    framework out there, that was mature enough for us to use it at our scale. There
    was GraphQL Java, which is a lower level GraphQL library. That library is great,
    and we are building on top of it. This is completely crucial for us, but it's
    too low level to use directly in an application, at least in my opinion. With
    v1 that is a GraphQL framework for Spring Boot, and basically giving a programming
    model based on annotation as you are used to in Spring Boot. We needed things
    like code generation for schema types, and support for federation and all these
    things. That's exactly what you're getting with the DGS framework. About, I think
    it's almost three years ago, we decided to open source the DGS framework. It's
    on GitHub. There's a really large community. There's lots of companies using it
    now. It's also exactly the version that we were using at Netflix, so we're not
    using a fork or anything like that. It's really evolved really nicely over the
    last few years.
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我谈了很多关于 DGS。DGS 不是一个概念，GraphQL 联邦是概念。DGS 框架只是一个框架，我们用它来构建我们的 GraphQL 服务在 Java
    中。大约三四年前，当我们开始采用 GraphQL 和 GraphQL 联邦这条路线时，真的没有合适的、成熟的 Java 框架适合我们使用在我们的规模上。当时有
    GraphQL Java，这是一个更低级的 GraphQL 库。那个库很好，我们正在它的基础上构建。这对我们来说是完全关键的，但它对直接在应用程序中使用来说太低级了，至少在我看来是这样。随着
    v1 出现，这是一个基于注解的编程模型的 Spring Boot GraphQL 框架。我们需要像模式类型的代码生成，还有联邦的支持以及所有这些东西。这正是你在
    DGS 框架中获得的。大约，我想大约三年前，我们决定开源 DGS 框架。它在 GitHub 上。这里有一个非常庞大的社区。现在许多公司都在使用它。这也正是我们在
    Netflix 使用的版本，所以我们没有使用分支或其他任何东西。它在过去几年里发展得非常好。
- en: You might be wondering if you are actually in the GraphQL and Spring space,
    you probably have seen that in Spring Boot 3, the Spring team also added GraphQL
    support, which they called Spring GraphQL. That was not ideal for the larger community,
    because now the community would have to choose between, ok, do I bet on the DGS
    framework, or do I go with Spring GraphQL? Both seem interesting, both seem great.
    Both have an interesting feature set, but a different feature set. What do I bet
    on? I could go and sell you the DGS framework, how that's better and better evolves,
    and faster, and all these things which are right now probably true, because we've
    been around for a little bit longer. That's really not the point, the point is
    that you shouldn't have to choose. In the last few months, we have been working
    with the Spring team to get full integration between those two frameworks. What
    you basically get with that is that you can combine the DGS and Spring GraphQL
    programming models and its features in the same app, and it will just happily
    live together. That's possible because we're both using GraphQL Java as the low-level
    library. That's how it all fits together. We just integrated the framework really
    deeply. We're still finishing that, and that is probably going to be released
    early 2024\. At least that gives you that idea. It doesn't really matter if you
    would pick the DGS framework today. It doesn't get you stuck in there and not
    be able to leverage features coming from Spring team, because very soon you will
    just be able to combine both very nicely.
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道，如果你实际上在 GraphQL 和 Spring 领域，你可能已经看到在 Spring Boot 3 中，Spring 团队也增加了 GraphQL
    支持，他们称之为 Spring GraphQL。对更大的社区来说，这并不理想，因为现在社区将不得不在 DGS 框架和 Spring GraphQL 之间做出选择，好吧，我要赌
    DGS 框架吗？还是选择 Spring GraphQL？两者都很有趣，都很棒。两者都有一个有趣的功能集，但是不同的功能集。我该怎么做选择呢？我可以告诉你有关
    DGS 框架的优势，并且如何更好地发展、更快等等，这些目前可能是真实的，因为我们已经存在了一段时间了。但问题并不在于这个，问题是你不应该被迫做出选择。 在过去的几个月中，我们一直在与
    Spring 团队合作，以便在这两个框架之间实现完全集成。基本上，你可以在同一个应用程序中结合 DGS 和 Spring GraphQL 编程模型及其功能，它们会愉快地共存。这是因为我们都使用
    GraphQL Java 作为底层库。这就是所有东西是如何连接在一起的。我们真正深度集成了框架。我们还在进行最后的完善，然后可能会在 2024 年初发布。至少这给你一个想法。如果你今天选择
    DGS 框架并不重要。它不会让你陷入困境，无法利用 Spring 团队带来的功能，因为很快你就可以非常好地结合两者。
- en: Questions and Answers
  id: totrans-split-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题与答案
- en: 'Participant 1: Are you guys still using Zuul?'
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者 1：你们还在使用 Zuul 吗？
- en: 'Bakker: We are, yes. Zuul is sitting in front of literally every request. Zuul
    is just a proxy. It''s doing a lot of traffic control, basically. It''s not the
    API server that we talked about earlier. Zuul sits in front of either the DGS
    federated architecture or like the old architecture.'
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: Bakker：是的。Zuul 实际上是在每一个请求前面充当代理。Zuul 主要负责流量控制，并非我们之前提到的 API 服务器。Zuul 位于 DGS
    联合架构或旧架构的前端。
- en: 'Participant 2: You talked about the upgrade for Java having a limited perceived
    value there. I think that''s interesting. I think a lot of enterprises tend to
    have this mindset of if it isn''t broke, don''t fix it, [inaudible 00:44:02].
    What did you do to change that perception, or was it just the Spring upgrade that
    kicked your guys about to do the upgrade?'
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者 2：你提到 Java 升级在那里的感知价值有限。我觉得这很有意思。我认为很多企业倾向于如果没问题就不要修复它，[听不清 00:44:02]。你们是如何改变这种看法的，或者说是
    Spring 升级促使你们做了这个升级？
- en: 'Bakker: No, actually, the main story was the performance benefit. The fact
    that we could say that, you get 20% better performance. It depends a little bit
    on the service, how that number actually looks like and what it actually means.
    The number is real. The fact that you could say that, that made a lot of service
    owners more interested in it, but it also gave leadership higher up just to push
    like, this is going to save money, go do it. That was actually the most helpful
    thing. The Spring Boot upgrade came later, and also forces the issue, but it was
    after the fact.'
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: Bakker：不，实际上主要的故事是性能的提升。我们可以说，性能提升了 20%。这个数字在不同的服务中会有所不同，具体意义也不同。但这个数字是真实的。能够这么说，这让很多服务的负责人对此更感兴趣，也促使高层领导推动说，这将节省成本，去做吧。这实际上是最有帮助的事情。Spring
    Boot 升级是事后发生的，也促使了这个问题，但发生在此之后。
- en: 'Participant 3: A lot of advancements to OpenJDK, so from 8 to 17, did it directly
    go from 8 to 17?'
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者 3：在 OpenJDK 方面有很多进步，那么从 8 到 17，直接跳过了 11 吗？
- en: 'Bakker: We had services running on Java 11 because the plan was 8, 11, 17\.
    Java 11, we had services running there, it never really took off because there
    just wasn''t enough benefit. We mostly went from 8 to 17.'
  id: totrans-split-53
  prefs: []
  type: TYPE_NORMAL
  zh: Bakker：我们有服务在 Java 11 上运行，因为计划是从 8 到 11 再到 17。在 Java 11 上，我们有服务运行，但并没有真正起飞，因为效益不足。我们主要是从
    8 直接升级到了 17。
- en: 'Participant 3: Then that''s one of the things depending on the collectors as
    he was talking about, there was some impact with respect to stop-the-world pauses
    and some background collections that''s happening with Shenandoah and ZGC. There''s
    a tradeoff, but a lot of improvements went into reducing the memory sets and everything
    like that.'
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者 3：关于收集器的一些讨论，他提到，Shenandoah 和 ZGC 会有一些影响，例如停止一切暂停和后台收集。这其中存在一些权衡，但在减少内存集合方面进行了很多改进。
- en: 'Participant 4: You mentioned that 20% was what you needed, but how did you
    even secure the time to actually experiment with that? How did you convince stakeholders
    to say, we''re going to spend some time doing an upgrade on some services, and
    then we''ll demonstrate the values with that?'
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者 4：你提到你们需要 20%，但是你们是如何确保有时间来进行实验的？你们是如何说服利益相关者说，我们将花一些时间在一些服务上进行升级，然后证明其价值的？
- en: 'Bakker: There is the benefit of having a platform team as we have. If I look
    at my own time, I could do whatever I want. If I think there is some interesting
    failure to be had in experimenting with garbage collection, I''m actually not
    mostly doing performance work, there''s actually other folks who are much better
    at that. It''s just an example. If there is potential failure in there, if you
    can get a time to just experiment with it and play with it, basically, because
    our time of like one or two people is like drops in the water.'
  id: totrans-split-56
  prefs: []
  type: TYPE_NORMAL
  zh: Bakker：有一个平台团队的好处，就像我们有的那样。如果我看我的时间，我可以做任何我想做的事情。如果我认为在垃圾收集实验中有一些有趣的失败，实际上我并不是主要做性能工作的人，其实有其他更擅长的人。这只是一个例子。如果有潜在的失败，如果你能获得时间来试验和玩耍，基本上，因为我们的时间只是一两个人，就像水中的一滴。
- en: 'Participant 5: Did you see any difference in the memory footprint between virtual
    threads versus a traditional one for the same number of request-responses. The
    second is regarding the GraphQL versus traditional SOAP, because SOAP was superseded
    by REST back in the days when I was thinking that was very precious, and your
    network was very important if you don''t have a large number of data going through
    easily. Now that data is cheap, so it has the disadvantage of the schema going
    between the client and the server. I see that GraphQL also had the same problem
    now that we have the other query and the schema, going between the client and
    the server. How do you see the REST, SOAP, and GraphQL in that conjecture?'
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者 5：你有没有看到虚拟线程和传统线程在相同请求数和响应方面的内存占用差异？第二个问题是关于 GraphQL 和传统 SOAP 的对比，因为 SOAP
    在我认为那时非常珍贵的时候就被 REST 取代了，你的网络如果不经常传输大量数据，那时非常重要。现在数据很便宜，所以有模式在客户端和服务器之间传输的劣势。我看到
    GraphQL 现在也有同样的问题，现在我们有另一个查询和模式，在客户端和服务器之间传输。你如何看待 REST、SOAP 和 GraphQL 在这种推测中的表现？
- en: 'Bakker: I think SOAP had, conceptually, a few things. For example, the fact
    that there is a schema, that was a good thing. It was so incredibly hard to use
    and complex, that the overhead of doing the right things was just too much. Then
    REST, at least the way everyone is using REST, went the other extreme like no
    schema, no nothing at all, nothing is defined. You just throw in some data and
    we''re all good. I think GraphQL sits in the middle there. It doesn''t have a
    lot of overhead for developers to implement the schema. It''s very easy. It''s
    much easier than SOAP was, just from using it. You do get a schema and that takes
    away a lot of the downsides of just having REST in the schema. It feels like it
    has found the sweet spot for APIs. Probably if I''m back here 10 years from now,
    I will be like, "GraphQL, a terrible idea. How did we ever get to that?" You know
    how that goes. Right now, it feels like a sweet spot.'
  id: totrans-split-58
  prefs: []
  type: TYPE_NORMAL
  zh: Bakker：我认为 SOAP 在概念上有几点。例如，有一个模式这一点是好的。它非常难以使用和复杂，做正确的事情的开销太大了。然后 REST，至少是每个人都在使用的
    REST 的方式，另一个极端，像没有模式，什么都没有定义。你只是随便扔一些数据，一切都好了。我认为 GraphQL 位于这两者之间。它对开发者来说没有太多的开销来实现模式。非常简单。比
    SOAP 使用起来要容易得多。你确实会得到一个模式，这消除了只在模式中具有 REST 的许多缺点。感觉它找到了 API 的甜蜜点。也许如果我再过 10 年回到这里，我会像，“GraphQL，一个糟糕的想法。我们怎么会到达那里？”你知道怎么回事。现在，它感觉像是一个甜蜜点。
- en: There is a difference, that is why we have to be very careful about ending virtual
    threads where we replace traditional thread pools. Depending on if these thread
    pools are very CPU intensive or not, it does or does not make a lot of sense.
    The memory footprint doesn't seem to be a big factor. We haven't seen any significant
    bumps there at all. Again, it's all very early days, and we're just experimenting
    with everything. We haven't quite figured it out yet. It seems to be very straightforward
    from memory.
  id: totrans-split-59
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个差异，这就是为什么我们必须非常小心地结束虚拟线程，替换传统的线程池。这取决于这些线程池是否非常 CPU 密集，这样做或者不做都没有多大意义。内存占用似乎并不是一个重要因素。我们在那里没有看到任何显著的波动。再次强调，现在一切都处于非常早期阶段，我们只是在尝试一切。我们还没有完全弄清楚。从记忆中看来一切都很简单。
- en: 'Participant 6: Then I was just wondering about your Kotlin usage percentage,
    and what that is looking like?'
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者 6：那我只是在想你们 Kotlin 的使用百分比是多少，看起来怎么样？
- en: 'Bakker: It is fairly low. For a while we had a bunch of teams, including my
    own team, very excited about Kotlin. The DGS framework itself is written in Kotlin,
    although it''s targeting mostly Java apps. That''s my choice. We have microservices
    written in Kotlin, as well. The only downside that we see with Kotlin is we invest
    more in developer tooling, so IntelliJ plugins and automated tooling based on
    Gradle to help with these version upgrades with Spring, and all these things.
    That story is much harder for a platform team if you have to deal with multiple
    languages. Because either for an IntelliJ plugin, even if it''s both from JetBrains,
    you need to write your inspections in IntelliJ twice if you want to use both Java
    and Kotlin. It''s just a lot more work. It''s just a lot easier for platform teams
    if everyone is just happily using Java. That doesn''t make Kotlin bad, though.
    We have only seen good things about Kotlin and it works just pretty well. It''s
    a great language.'
  id: totrans-split-61
  prefs: []
  type: TYPE_NORMAL
  zh: Bakker：这相当少。有段时间我们有一些团队，包括我的团队，对Kotlin非常感兴趣。DGS框架本身是用Kotlin编写的，尽管它主要面向Java应用程序。这是我的选择。我们的微服务也是用Kotlin编写的。我们唯一看到的Kotlin的缺点是我们在开发工具上的投入更多，例如IntelliJ插件和基于Gradle的自动化工具，以帮助进行与Spring的这些版本升级相关的工作。如果你必须处理多种语言，这对于平台团队的故事要难得多。因为即使是来自同一个JetBrains的IntelliJ插件，如果你想同时使用Java和Kotlin，你仍然需要在IntelliJ中写两次检查。这只是更多的工作。如果每个人都愉快地使用Java，对于平台团队来说就容易得多。但这并不意味着Kotlin不好。我们只看到了Kotlin的好处，它确实运行得相当不错。它是一种很棒的语言。
- en: '**See more [presentations with transcripts](https://www.infoq.com/transcripts/presentations/)**'
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**查看更多[带有转录的演讲](https://www.infoq.com/transcripts/presentations/)**'
