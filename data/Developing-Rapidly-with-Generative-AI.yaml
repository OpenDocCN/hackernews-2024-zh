- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 13:28:34'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 13:28:34'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Developing Rapidly with Generative AI
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用生成AI快速开发
- en: 来源：[https://discord.com/blog/developing-rapidly-with-generative-ai](https://discord.com/blog/developing-rapidly-with-generative-ai)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://discord.com/blog/developing-rapidly-with-generative-ai](https://discord.com/blog/developing-rapidly-with-generative-ai)
- en: '**Prototyping AI applications: From Idea to MVP**'
  id: totrans-split-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**AI 应用原型设计：从想法到MVP**'
- en: The product requirements we define then play into our selection of which off-the-shelf
    LLM we'll use for our prototype. We generally lean towards picking more advanced
    commercial LLMs to quickly validate our ideas and obtain early feedback from users.
    Although they may be expensive, the general idea is that if problems can't be
    adequately solved with state-of-the-art foundational models like GPT-4, then more
    often than not, those problems may not be addressable using current generative
    AI tech. If an off-the-shelf LLM can address our problem, then we can step into
    the learning stage and concentrate on iterating on our product rather than diverting
    engineering resources towards building and maintaining machine learning infrastructure.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们定义的产品要求会影响我们选择用于原型的现成LLM。我们通常倾向于选择更先进的商业LLM，以快速验证我们的想法并从用户那里获得早期反馈。尽管它们可能昂贵，但总体思路是，如果无法使用像GPT-4这样的最先进基础模型充分解决问题，那么很多时候这些问题可能无法通过当前的生成AI技术解决。如果现成LLM可以解决我们的问题，那么我们可以进入学习阶段，并集中精力在产品迭代上，而不是将工程资源转向构建和维护机器学习基础设施。
- en: Evaluating Prompts
  id: totrans-split-8
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估提示
- en: The key step at this stage is to create the right prompt. We start with a basic
    prompt that tells ChatGPT (or whatever LLM we selected for our prototype) what
    we want it to do. Then, we make adjustments to this prompt, changing the wording
    to make the task clearer. However, after a lot of adjustments, it's often difficult
    to tell if these changes are actually improving our results. That's where evaluating
    the prompts becomes crucial. By using metrics to guide our changes, we know we
    are moving the needle on the quality of our results.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段的关键步骤是创建正确的提示。我们从一个基本提示开始，告诉ChatGPT（或者我们选择的任何LLM原型）我们希望它做什么。然后，我们对这个提示进行调整，改变措辞以使任务更清晰。然而，在经过大量调整之后，很难确定这些变化是否真正改善了我们的结果。这就是评估提示变得至关重要的地方。通过使用度量指标来指导我们的改变，我们知道我们正在提高我们结果的质量。
- en: To do this, we employ a technique known as [AI-assisted evaluation](https://arize.com/blog-course/llm-evaluation-the-definitive-guide/),
    alongside traditional metrics for measuring performance. This helps us pick the
    prompts that lead to better quality outputs, making the end product more appealing
    to users. AI-assisted evaluation uses best-in-class LLMs (like GPT-4) to automatically
    critique how well the AI's outputs match what we expected or how they score against
    a set of criteria. This method uses GPT-4 in a way that’s similar to the critic
    model found in the [actor-critic algorithm](https://www.tensorflow.org/tutorials/reinforcement_learning/actor_critic)
    in reinforcement learning where a separate model is used to evaluate how well
    the model used for inference performed. Automating evaluation allows us to quickly
    see what's working well and what needs to be tweaked in our prompts, without having
    to manually check everything. When evaluating, we design prompts that ask for
    simple yes or no answers or rate the outputs on a scale, making the evaluation
    process straightforward.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们采用一种称为[AI辅助评估](https://arize.com/blog-course/llm-evaluation-the-definitive-guide/)的技术，以及用于衡量性能的传统度量标准。这有助于我们选择导致更高质量输出的提示，使最终产品对用户更具吸引力。AI辅助评估利用最优秀的LLM（如GPT-4）自动批评AI输出与我们预期的匹配程度或它们根据一组标准的评分。这种方法类似于强化学习中发现的[演员-评论家算法](https://www.tensorflow.org/tutorials/reinforcement_learning/actor_critic)，其中使用单独的模型评估用于推理的模型的表现如何。自动化评估使我们能够快速看到哪些工作良好，哪些需要在我们的提示中进行调整，而无需手动检查所有内容。在评估时，我们设计提示，要求简单的是或否答案或者按比例评估输出，使评估过程变得简单直接。
- en: 'AI-assisted evaluation consists of 2 separate prompts: one for your task and
    another to evaluate your results. The task prompt is passed to the inference model
    whereas the critic prompt is passed to the more advanced critic model.'
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: AI辅助评估包括两个单独的提示：一个用于您的任务，另一个用于评估您的结果。任务提示传递给推理模型，而评论家提示传递给更高级的评论家模型。
- en: Launch and Learn
  id: totrans-split-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 启动和学习
- en: Once we are sufficiently confident in the quality of the results our prompt
    generates, we roll out a limited release (e.g. A/B test) of our product and observe
    the system’s performance in situ. The exact metrics we use depend on the application
    — our main goal is to understand how users use the feature and quickly make improvements
    to better meet their needs. For internal applications, this might mean measuring
    efficiency and sentiment. For consumer-facing applications, we similarly focus
    on measures of user satisfaction - direct user feedback, user engagement measures,
    etc.  This feedback is critical to identify areas for improvement, including highlighting
    incorrect answers or instances where LLM hallucinations might be causing a strange
    user experience.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们对我们的提示生成的结果质量足够自信，我们就会推出产品的有限发布（例如 A/B 测试），并观察系统在实际环境中的表现。我们使用的确切指标取决于应用程序
    —— 我们的主要目标是了解用户如何使用该功能，并快速进行改进以更好地满足他们的需求。对于内部应用，这可能意味着测量效率和情感。对于面向消费者的应用，我们同样关注用户满意度的衡量标准
    - 直接用户反馈，用户参与度等。这些反馈对于确定改进的方向至关重要，包括突出显示不正确的答案或导致奇怪用户体验的 LLM 幻觉的实例。
- en: Beyond user satisfaction, we also pay attention to system health metrics, such
    as response speed (latency), throughput (tokens per second), and error rates.
    LLMs sometimes have trouble generating output in a consistently structured format,
    which is crucial for minimizing data parsing errors and ensuring the output is
    robustly usable in our services. Insights here can inform how much post-hoc processing
    might be needed to fully productionize this capability at scale.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 除了用户满意度之外，我们还关注系统健康指标，例如响应速度（延迟），吞吐量（每秒令牌数）和错误率。LLM 有时在生成输出时可能会遇到一致性结构化格式的困难，这对于减少数据解析错误并确保输出在我们的服务中的可靠使用至关重要。这里的见解可以指导我们在多大程度上需要事后处理来完全将此功能在规模上投入生产。
- en: Keeping an eye on costs is equally important for understanding how much we will
    spend when we fully scale up the feature. We look at how many tokens per second
    we're using in our initial limited release to predict the costs of a complete
    launch if we were to use the same technology that’s powering our prototype.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对成本的密切关注同样重要，以便了解我们在完全扩展功能时将花费多少。我们查看我们在初始有限发布中每秒使用的令牌数量，以预测如果我们使用驱动我们原型的同样技术进行完全发布时的成本。
- en: 'All of the above information is critical to understanding if our product is
    working as intended and providing value to users.  If it is, then we can proceed
    to the next step: deploying at scale.  If not, then we look to take our learnings,
    iterate on the system, and try again.'
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 所有上述信息对于理解我们的产品是否按预期运行并为用户提供价值至关重要。如果是，那么我们可以继续下一步：大规模部署。如果不是，那么我们会寻求我们的经验教训，对系统进行迭代，并再次尝试。
