- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 13:03:11'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 13:03:11'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'ScreenAI: A visual language model for UI and visually-situated language understanding'
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ScreenAI：一个用于用户界面和视觉语境语言理解的视觉语言模型
- en: 来源：[https://research.google/blog/screenai-a-visual-language-model-for-ui-and-visually-situated-language-understanding/](https://research.google/blog/screenai-a-visual-language-model-for-ui-and-visually-situated-language-understanding/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://research.google/blog/screenai-a-visual-language-model-for-ui-and-visually-situated-language-understanding/](https://research.google/blog/screenai-a-visual-language-model-for-ui-and-visually-situated-language-understanding/)
- en: '*This project is the result of joint work with Maria Wang, Fedir Zubach, Hassan
    Mansoor, Vincent Etter, Victor Carbune, Jason Lin, Jindong Chen and Abhanshu Sharma.
    We thank Fangyu Liu, Xi Chen, Efi Kokiopoulou, Jesse Berent, Gabriel Barcik, Lukas
    Zilka, Oriana Riva, Gang Li,Yang Li, Radu Soricut, and Tania Bedrax-Weiss for
    their insightful feedback and discussions, along with Rahul Aralikatte, Hao Cheng
    and Daniel Kim for their support in data preparation. We also thank Jay Yagnik,
    Blaise Aguera y Arcas, Ewa Dominowska, David Petrou, and Matt Sharifi for their
    leadership, vision and support. We are very grateful toTom Small for helping us
    create the animation in this post.*'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*这个项目是与Maria Wang, Fedir Zubach, Hassan Mansoor, Vincent Etter, Victor Carbune,
    Jason Lin, Jindong Chen和Abhanshu Sharma共同完成的成果。我们感谢Fangyu Liu, Xi Chen, Efi Kokiopoulou,
    Jesse Berent, Gabriel Barcik, Lukas Zilka, Oriana Riva, Gang Li, Yang Li, Radu
    Soricut和Tania Bedrax-Weiss提供的深刻反馈和讨论，以及Rahul Aralikatte, Hao Cheng和Daniel Kim在数据准备中的支持。我们还要感谢Jay
    Yagnik, Blaise Aguera y Arcas, Ewa Dominowska, David Petrou和Matt Sharifi的领导、愿景和支持。非常感谢Tom
    Small在本文中帮助我们创建动画。*'
