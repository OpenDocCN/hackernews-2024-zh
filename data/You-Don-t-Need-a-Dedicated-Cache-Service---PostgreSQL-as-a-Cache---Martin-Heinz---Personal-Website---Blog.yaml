- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:39:33'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: You Don't Need a Dedicated Cache Service - PostgreSQL as a Cache | Martin Heinz
    | Personal Website & Blog
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://martinheinz.dev/blog/105](https://martinheinz.dev/blog/105)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: PostgreSQL became a go-to SQL database for many developers over the past couple
    of years. While being an SQL database, Postgres also includes a lot of features
    that make it suitable for other uses, e.g. using it as NoSQL database (JSON and
    HStore datatypes) or vector database.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: Another - more unusual and possibly unexpected use-case for Postgres - is using
    it as a cache!
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: In this article we will explore how we can leverage features of PostgreSQL to
    turn it into fully featured and very efficient caching service.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: Why?
  id: totrans-split-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You might be asking: *"Why would anyone do this, though?"*, To answer that
    question, let''s take a look at what we might expect from a traditional caching
    service:'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
- en: Expiration - Ability to set expiration times for cached data so that the cache
    doesn't store outdated information
  id: totrans-split-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eviction - Remove less frequently used data when the cache is full
  id: totrans-split-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Invalidation - Overwrite data when it changes
  id: totrans-split-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performance - Main reason to use cache is to avoid slow database queries. SQL
    databases generally also have slower writes compared to caches
  id: totrans-split-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No persistence - Caching services will generally have limited or no persistence
  id: totrans-split-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Key-value storage
  id: totrans-split-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Well, as we will see in the next section, we can get all of the above when
    using PostgreSQL, on top of that we also get the following as a bonus:'
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
- en: Familiar interface - Using SQL and common PostgreSQL client libraries, makes
    it easier to integrate into application
  id: totrans-split-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cost - No need to set up and maintain another service. This decreases operational
    costs. You also don't need a Redis/Memcached/... expert to maintain it
  id: totrans-split-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How
  id: totrans-split-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the *"Why?"* out of the way, let's now talk about *"how"*. To implement
    cache in PostgreSQL effectively, we will use `UNLOGGED` table(s). How are these
    different from normal tables?
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
- en: '`UNLOGGED` tables don''t generate *WAL ([Write Ahead Log](https://www.postgresql.org/docs/current/wal-intro.html))*
    information. That gives us huge improvements in write performance and saves us
    some disk space. There''s obviously a trade-off - `UNLOGGED` tables aren''t crash-safe
    - without WAL record, if database server crashes, an unlogged table is automatically
    truncated, but with cache we don''t really expect proper persistence, so that''s
    OK. Additionally, `UNLOGGED` tables are only available on primary, not on replicas,
    so no distributed cache, which might or might not be an issue, you decide.'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
- en: 'That''s the theory, now let''s actually try it out. In the examples I will
    be using PostgreSQL running in container, if you want to follow along you can
    use:'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-split-24
  prefs: []
  type: TYPE_PRE
- en: 'To then create a `cache` table we can run:'
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-split-26
  prefs: []
  type: TYPE_PRE
- en: Only difference from normal table is the `UNLOGGED` keyword. As for the columns,
    here we use `JSONB` values, but you could use whatever suits your needs, e.g.
    `text`, `varchar` or `hstore`. We also include `inserted_at` column, which will
    be used for cache invalidation. Optionally, we also create an index for better
    read performance.
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
- en: 'As was already mentioned, one of the features that we expect from caching service
    is ability to expire records. To do this in PostgreSQL, we can create a stored
    procedure that removes old rows periodically:'
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-split-29
  prefs: []
  type: TYPE_PRE
- en: We will need to call this `expire_rows` procedure on a schedule. To do that
    we can use `pg_cron` extension. To use it, you will need to install it on OS level
    and then create the extension in database. You can do that using `Dockerfile`
    and scripts included in this [Gist](https://gist.github.com/MartinHeinz/2ea26ad81a5984de6befdacf855a9255).
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
- en: 'After installing (`CREATE EXTENSION pg_cron;`), we can schedule the procedure
    call with:'
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-split-32
  prefs: []
  type: TYPE_PRE
- en: 'If you don''t want to install the extension for this, then you can alternatively
    write a trigger that runs everytime a row is inserted (I wouldn''t recommend this
    though):'
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-split-34
  prefs: []
  type: TYPE_PRE
- en: Obliviously, the actual expiry/purge schedule depends on your data and use-case.
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
- en: That was expiration, but what about eviction (removing old data to make space
    for new records)?
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
- en: I'd consider eviction optional, considering that expiration should keep the
    size down, but we could implement that as well - we can add `last_read timestamp`
    column which would get updated on every read. We could then run stored procedure
    every once-in-a-while to clean-up rows that haven't been used recently, giving
    us an LRU cache. You decide whether updating rows on every read is worth it.
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
- en: With that, we created a simple cache, which has fast writes, fast reads, key-value
    storage, better persistence than traditional caching services, cache expiration,
    eviction and invalidation, without having to deploy yet another (costly) service.
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
- en: Performance
  id: totrans-split-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, I mostly only mentioned how great it is to use PostgreSQL as a cache,
    but obviously, there are also downsides. One of them being performance, which
    will be (slightly) worse than with purpose-built optimized caching service. How
    much worse, depends on your data and usage patterns (read-heavy or write-heavy
    operations, data sizes, types of queries, etc.)
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
- en: 'Benchmarking and comparing `UNLOGGED` tables against Memcached or Redis is
    out-of-scope of this article, but if you want to test performance (and you should)
    you could start with generating some data:'
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-split-42
  prefs: []
  type: TYPE_PRE
- en: 'And then analyze queries to get a sense of what the performance might look
    like:'
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-split-44
  prefs: []
  type: TYPE_PRE
- en: I would also recommend reading [this great article](https://www.crunchydata.com/blog/postgresl-unlogged-tables)
    about `UNLOGGED` tables which shows more details about the feature including some
    performance comparisons.
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
- en: Closing Thoughts
  id: totrans-split-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In my opinion, most of the time, you don't need an additional service or special
    database. There's a reason why half the new fancy DBs are implemented on top of
    good old SQL databases. Just look at the list of [PostgreSQL-derived databases](https://wiki.postgresql.org/wiki/PostgreSQL_derived_databases).
    Not to mention things like [Timescale](https://www.timescale.com/) and many others,
    which are really just PostgreSQL with some extra features sprinkled on top.
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
- en: While purpose-built, optimized solutions have their place, it's good to consider
    pros and cons of running extra service for every little thing, such as cache,
    scheduler, vector database, etc.
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
- en: Maybe, just maybe, using one tool for multiple things and saving costs and overhead
    outweighs the few benefits the extra service provides.
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
