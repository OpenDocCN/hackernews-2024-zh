- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-05-27 14:33:29'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-27 14:33:29
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Why Postgres RDS didn’t work for us (and why it won’t work for you if you’re
    implementing a big data solution) | by Max Kremer | Medium
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么对我们而言 Postgres RDS 不适用（以及如果您正在实施大数据解决方案，它为什么也不适用）| 作者 Max Kremer | Medium
- en: 来源：[https://medium.com/@mkremer_75412/why-postgres-rds-didnt-work-for-us-and-why-it-won-t-work-for-you-if-you-re-implementing-a-big-6c4fff5a8644](https://medium.com/@mkremer_75412/why-postgres-rds-didnt-work-for-us-and-why-it-won-t-work-for-you-if-you-re-implementing-a-big-6c4fff5a8644)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://medium.com/@mkremer_75412/why-postgres-rds-didnt-work-for-us-and-why-it-won-t-work-for-you-if-you-re-implementing-a-big-6c4fff5a8644](https://medium.com/@mkremer_75412/why-postgres-rds-didnt-work-for-us-and-why-it-won-t-work-for-you-if-you-re-implementing-a-big-6c4fff5a8644)
- en: Why Postgres RDS didn’t work for us (and why it won’t work for you if you’re
    implementing a big data solution)
  id: totrans-split-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么对我们而言 Postgres RDS 不适用（以及如果您正在实施大数据解决方案，它为什么也不适用）
- en: Background
  id: totrans-split-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 背景
- en: We were building a startup that measured marketing effectivness via a statistical
    attribution model. For this to work we had to collect a ton of online user behavior.
    Every click, every field input, every action. Data was stored in postgres and
    end users, via our UI, ran dashboards and reports that crunched the above (sometimes
    very large) data sets. Important to note that we were building a multi-tenant
    SAAS application, so data was being ingested and stored per tenant across hundreds
    of tenants. It needed to be scalable and performant. We started with AWS RDS managed
    postgreSQL.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在构建一个通过统计归因模型来衡量营销效果的初创公司。为了使其工作，我们必须收集大量在线用户行为数据。每次点击，每次字段输入，每个操作。数据存储在
    postgres 中，通过我们的用户界面，终端用户运行可以处理上述（有时非常大）数据集的仪表板和报告。需要注意的是，我们正在构建一个多租户 SAAS 应用程序，因此数据根据数百个租户进行摄取和存储。它需要可扩展性和性能。我们从
    AWS RDS 托管的 PostgreSQL 开始。
- en: 'The big problem is with EBS: throughput opacity'
  id: totrans-split-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对于 EBS 存在的大问题：吞吐量的不透明性
- en: It’s almost impossible to accurately measure throughput on EBS. The metrics
    AWS gives you are latency and IOPS. Neither of these provide a measure of throughput.
    When you’re storing a large time-series table (say 20 million rows) and the size
    of the table on disk is 10GB and you want to scan the table (for whatever reason
    — say a sequential scan) then you need an accurate measure of throughput to understand
    how long it will take to scan the data from disk.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在 EBS 上几乎不可能准确测量吞吐量。AWS 提供的指标是延迟和 IOPS。这两者都不能提供吞吐量的衡量。当您存储一个大型时间序列表（例如 2000
    万行），并且表在磁盘上的大小为 10GB，您希望扫描该表（无论出于何种原因——比如顺序扫描），那么您需要准确的吞吐量测量来理解从磁盘扫描数据将需要多长时间。
- en: Bursting and throttled IOPS — the slippery slope
  id: totrans-split-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 爆发和被限制的 IOPS —— 一个滑坡
- en: Queries like the one above quickly use up IO credits. We want more IOPS so what
    do we do? Naturally we increase the storage volume so we can get a higher baseline
    of 10000 IOPS from the measly 3000 you get with smaller volumes. But then backup
    costs increase because you’re paying for the entire volume, not just what’s used.
    Costs increase, performance doesn’t get much better — it snowballs from there.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 像上面的查询会快速消耗 IO credits。我们想要更多的 IOPS，那么我们该怎么办？自然地，我们增加存储卷的大小，这样我们可以从较小的卷得到的每秒
    IO 操作次数（IOPS）的基线增加到 10000 IOPS，而不是只有 3000。但随之而来的是备份成本的增加，因为您需要为整个卷付费，而不仅仅是使用的部分。成本增加，性能并没有得到很大的提升——问题就此恶化。
- en: We also kept uping our instance size to get more memory for caching. It’s easy
    to make the DB fast if it can fit it all in memory. There was also the promise
    of greater parallelization that came with PG v10, but sadly that brought us very
    little benefit due to the IO throttling.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还不断提升实例的大小，以获取更多的内存用于缓存。如果可以将所有数据都放入内存中，数据库的速度会很快。此外，PG v10 还带来了更大的并行化的承诺，但遗憾的是由于
    IO 限制，它给我们带来的好处非常有限。
- en: 'The problems with measuring throughput are described in more detail here:'
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 更详细地描述了测量吞吐量的问题：
- en: '[https://www.datadoghq.com/blog/aws-ebs-latency-and-iops-the-surprising-truth/](https://www.datadoghq.com/blog/aws-ebs-latency-and-iops-the-surprising-truth/)'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.datadoghq.com/blog/aws-ebs-latency-and-iops-the-surprising-truth/](https://www.datadoghq.com/blog/aws-ebs-latency-and-iops-the-surprising-truth/)'
- en: Aurora
  id: totrans-split-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Aurora
- en: So then we migrated to Aurora. Promises of 5–7 X performance increases over
    standard postgres are hard to ignore. However the caveat is that these performance
    metrics are based on pgbench (in the case of postgresql). That’s great if you
    have an OLTP system and want to measure the speed (or latency) of transactions
    with a large number of parallel clients but is not a good performance indicator
    for large data-sets and data-mining operations.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们迁移到了Aurora。对于标准的postgresql，承诺的5-7倍性能提升很难忽视。然而，这些性能指标是基于pgbench（在postgresql的情况下）。如果您有OLTP系统并希望测量具有大量并行客户端的事务速度（或延迟），那么这是很好的。但对于大数据集和数据挖掘操作来说，这不是一个好的性能指标。
- en: Costs went up instead of down.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 成本上升而不是下降。
- en: This thread covers IOPS and billable IOPS [https://forums.aws.amazon.com/message.jspa?messageID=835303#835303](https://forums.aws.amazon.com/message.jspa?messageID=835303#835303)
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此线程涵盖了IOPS和可计费IOPS [https://forums.aws.amazon.com/message.jspa?messageID=835303#835303](https://forums.aws.amazon.com/message.jspa?messageID=835303#835303)
- en: Again the biggest frustration was getting accurate measurements of throughput.
    Simply dividing the amount of data scanned by the time it took (using tack_io_timing)
    we saw that performance for a large dataset was nowhere near SSD speeds, more
    like magnetic disks.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 再次最大的挫折是获取吞吐量的准确测量。简单地将扫描的数据量除以使用tack_io_timing花费的时间，我们发现大数据集的性能远远不及SSD速度，更接近于磁盘。
- en: Adding to the frustration was the endless hours dealing with support. While
    support staff were always very knowledgeable and eager to assist it always came
    down to tuning the query or tuning the DB. Again this came down to throughput
    — I would’ve loved to hear something along the lines of “This service is not a
    good choice given your workloads”. But eventually we figured that out for ourselves.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 增加挫折的是与支持团队打交道的无尽时间。虽然支持人员总是非常知识渊博并且乐于帮助，但最终都归结为调整查询或调整数据库。再次回到吞吐量 — 我很乐意听到类似“考虑到您的工作负载，这项服务不是一个好的选择”。但最终我们自己找到了解决方法。
- en: 'The Solution: Roll your own'
  id: totrans-split-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解决方案：自己动手做
- en: 'For us the solution was fairly simple: don’t use a managed database services
    and roll our own infrastructure on EC2.'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们来说，解决方案相当简单：不要使用托管数据库服务，而是在EC2上自己构建基础设施。
- en: We did this using relatively low-grade EC2 instances (We were running 4XL on
    RDS) xl and 2xls.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用相对低档的EC2实例来做到这一点（我们在RDS上运行了4XL xl和2xls）。
- en: The key was to separate READ and WRITE workloads between a master and standby
    replica that was kept up to date using WAL-G ([https://github.com/wal-g/wal-g](https://github.com/wal-g/wal-g))
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: 关键在于在主备复制物之间分离READ和WRITE工作负载，通过WAL-G（[https://github.com/wal-g/wal-g](https://github.com/wal-g/wal-g)）保持更新。
- en: The WRITE node could be slow, it’s only ingesting data, so EBS was good enough
    but we were able to **DOUBLE** EBS throughput using ZFS with compression.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: WRITE节点可能会很慢，它只是在摄取数据，所以EBS已经足够好了，但我们能够通过使用带有压缩的ZFS将EBS吞吐量**翻了一番**。
- en: For the READ node we had a setup with ephemeral NVMe drives, and again ZFS to
    boost performance.
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 对于READ节点，我们有一个带有临时NVMe驱动器的设置，再次使用ZFS来提升性能。
- en: 'The results speak for themselves:'
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 结果不言自明：
- en: $11K bill down to a $2100 (projected for September which will the first full
    month we’re clear of any RDS baggage)
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: $11K的账单降到了$2100（预计在九月，这将是我们完全摆脱任何RDS负担的第一个完整月）
- en: Queries that would take hours or timeout altogether run in **seconds**.
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: 原本需要数小时甚至超时的查询现在可以在**几秒钟**内完成。
- en: We are able to measure actual throughput using command line tools on the unix
    instances (zpool iostat)
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能够使用unix实例上的命令行工具来测量实际的吞吐量（zpool iostat）
- en: Conclusion
  id: totrans-split-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Sure it’s easy to hit a button and spin up an instance and never worry about
    backup and recovery. But that comes at a cost, both monetary and performance in
    our case. If you need REAL speed for crunching TBs or GBs of data then use bare
    metal, and if you can’t use bare metal then the next best thing is EC2 with NVMe
    drives. Read [part two](/p/748c391fce51) where I provide the recipe for how to
    spin up your own Postgres Cluster on AWS using instances with NVMe drives.
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，按下按钮并启动实例而无需担心备份和恢复是很容易的。但这是有成本的，在我们的情况下是货币和性能。如果您需要处理TB或GB级数据的真正速度，那么使用裸金属服务器，如果不能使用裸金属服务器，那么下一个最佳选择是带有NVMe驱动器的EC2。阅读[第二部分](/p/748c391fce51)，我将介绍如何在AWS上使用带有NVMe驱动器的实例自行构建Postgres集群的步骤。
