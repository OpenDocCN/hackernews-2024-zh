- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-27 14:46:30'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-27 14:46:30
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Korean researchers power-shame Nvidia with new neural AI chip — claim 625 times
    less power draw, 41 times smaller | Tom's Hardware
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 韩国研究人员以新的神经AI芯片对Nvidia进行了功耗比较 —— 声称功耗减少了625倍，体积减少了41倍 | Tom's Hardware
- en: 来源：[https://www.tomshardware.com/tech-industry/artificial-intelligence/korean-researchers-power-shame-nvidia-with-new-neural-ai-chip-claim-625-times-less-power-41-times-smaller](https://www.tomshardware.com/tech-industry/artificial-intelligence/korean-researchers-power-shame-nvidia-with-new-neural-ai-chip-claim-625-times-less-power-41-times-smaller)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.tomshardware.com/tech-industry/artificial-intelligence/korean-researchers-power-shame-nvidia-with-new-neural-ai-chip-claim-625-times-less-power-41-times-smaller](https://www.tomshardware.com/tech-industry/artificial-intelligence/korean-researchers-power-shame-nvidia-with-new-neural-ai-chip-claim-625-times-less-power-41-times-smaller)
- en: A team of scientists from the Korea Advanced Institute of Science and Technology
    (KAIST) detailed their 'Complementary-Transformer' AI chip during the recent 2024
    International Solid-State Circuits Conference (ISSCC). The new C-Transformer chip
    is claimed to be the world's first ultra-low power AI accelerator chip capable
    of large language model (LLM) processing.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 来自韩国科学技术院(KAIST)的科学家团队在最近的2024年国际固态电路会议(ISSCC)上详细介绍了他们的“Complementary-Transformer”人工智能芯片。新的C-Transformer芯片被称为世界上第一款能够进行大型语言模型(LLM)处理的超低功耗AI加速器芯片。
- en: In a [press release](http://koreabizwire.com/kaist-develops-next-generation-ultra-low-power-llm-accelerator/274663),
    the researchers power-shame Nvidia, claiming that the C-Transformer uses 625 times
    less power and is 41x smaller than the green team's A100 Tensor Core GPU. It also
    reveals that the Samsung fabbed chip's achievements largely stem from refined
    [neuromorphic computing](https://www.tomshardware.com/news/intel-loihi-chip-neuromorphic-computing,35537.html)
    technology.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在一篇[新闻稿](http://koreabizwire.com/kaist-develops-next-generation-ultra-low-power-llm-accelerator/274663)中，研究人员对Nvidia进行了功耗比较，声称C-Transformer的功耗是绿队A100张量核心GPU的625倍少，体积也小了41倍。它还揭示，三星制造的芯片主要来源于精细的[神经形态计算](https://www.tomshardware.com/news/intel-loihi-chip-neuromorphic-computing,35537.html)技术。
- en: '(Image credit: KAIST)'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: (图片来源：KAIST)
- en: Though we are told that the KAIST C-Transformer chip can do the same LLM processing
    tasks as one of Nvidia's beefy [A100 GPUs](https://www.tomshardware.com/news/nvidia-ampere-A100-gpu-7nm),
    none of the press nor conference materials we have provided any direct comparative
    performance metrics. That's a significant statistic, conspicuous by its absence,
    and the cynical would probably surmise that a performance comparison doesn't do
    the C-Transformer any favors.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们被告知，KAIST的C-Transformer芯片可以执行与Nvidia的[A100 GPUs](https://www.tomshardware.com/news/nvidia-ampere-A100-gpu-7nm)相同的LLM处理任务，但我们提供的所有新闻和会议材料都没有提供任何直接的性能比较数据。这是一个显著的统计数字，由于其缺失而显眼，愤世嫉俗的人可能会推测，性能比较对C-Transformer不利。
- en: The above gallery has a 'chip photograph' and a summary of the processor's specs.
    You can see that the C-Transformer is currently fabbed on Samsung's 28nm process
    and has a die area of 20.25mm2\. It runs at a maximum frequency of 200 MHz, consuming
    under 500mW. At best, it can achieve 3.41 TOPS. At face value, that's 183x slower
    than the claimed 624 TOPS of the Nvidia A100 PCIe card (but the KAIST chip is
    claimed to use 625x less power). However, we'd prefer some kind of benchmark performance
    comparison rather than look at each platform's claimed TOPS.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 上述画廊有一个“芯片照片”和处理器规格的摘要。您可以看到，C-Transformer目前采用三星的28纳米工艺制造，芯片面积为20.25平方毫米。它以最大频率运行在200
    MHz，功耗低于500毫瓦。在最佳情况下，它可以达到3.41 TOPS。从表面上看，这比Nvidia A100 PCIe卡声称的624 TOPS要慢183倍（但KAIST芯片声称功耗减少了625倍）。然而，我们更希望看到某种基准性能比较，而不是看每个平台声称的TOPS。
- en: The architecture of the C-Transformer chip is interesting to look at and is
    characterized by three main functional feature blocks. Firstly, there is a Homogeneous
    DNN-Transformer / Spiking-transformer Core (HDSC) with a Hybrid Multiplication-Accumulation
    Unit (HMAU) to efficiently process the dynamically changing distribution energy.
    Secondly, we have an Output Spike Speculation Unit (OSSU) to reduce the latency
    and computations of spike domain processing. Thirdly, the researchers implemented
    an Implicit Weight Generation Unit (IWGU) with Extended Sign Compression (ESC)
    to reduce External Memory Access (EMA) energy consumption.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: C-Transformer芯片的架构非常有趣，由三个主要功能特征块组成。首先，有一个具有混合乘积累加单元（HMAU）的同质DNN-Transformer
    / 脉冲变换器核心（HDSC），以有效处理动态变化的分布能量。其次，我们有一个输出脉冲推测单元（OSSU），用于减少脉冲域处理的延迟和计算量。第三，研究人员实现了一个具有扩展符号压缩（ESC）的隐式权重生成单元（IWGU），以减少外部存储器访问（EMA）能耗。
- en: It is explained that the C-Transformer chip doesn't just add some off-the-shelf
    neuromorphic processing as its 'special sauce' to compress the large parameters
    of LLMs. Previously, neuromorphic computing technology wasn't accurate enough
    for use with [LLMs](https://www.tomshardware.com/pc-components/cpus/intels-npu-acceleration-library-goes-open-source),
    says the KAIST press release. However, the research team says it "succeeded in
    improving the accuracy of the technology to match that of [deep neural networks]
    DNNs."
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 据KAIST新闻稿解释，C-Transformer芯片并非仅仅将一些现成的神经形态处理作为其“特殊酱料”来压缩LLM的大参数。此前，神经形态计算技术在[LLMs](https://www.tomshardware.com/pc-components/cpus/intels-npu-acceleration-library-goes-open-source)中的使用精度还不够，KAIST称。然而，研究团队表示，“已经成功改进了技术的精度，使其达到了[深度神经网络]
    DNNs的水平”。
- en: Though there are uncertainties about the performance of this first C-Transformer
    chip due to no direct comparisons with industry-standard [AI accelerators](https://www.tomshardware.com/news/rtx-4090-blowers-stripped-for-ai),
    it is hard to dispute claims that it will be an attractive option for mobile computing.
    It is also encouraging that the researchers have got this far with a Samsung test
    chip and extensive GPT-2 testing.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管由于与行业标准[AI加速器](https://www.tomshardware.com/news/rtx-4090-blowers-stripped-for-ai)没有直接比较，对这款首个C-Transformer芯片的性能存在不确定性，但很难质疑它将成为移动计算的一个吸引人选项的说法。同样令人鼓舞的是，研究人员已经通过三星测试芯片和广泛的GPT-2测试取得了如此进展。
- en: Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 获取Tom's Hardware最佳新闻和深度评论，直接发送到您的收件箱。
