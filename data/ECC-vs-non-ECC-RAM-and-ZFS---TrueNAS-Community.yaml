- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-27 15:00:26'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-27 15:00:26
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: ECC vs non-ECC RAM and ZFS | TrueNAS Community
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ECC vs non-ECC RAM and ZFS | TrueNAS Community
- en: 来源：[https://www.truenas.com/community/threads/ecc-vs-non-ecc-ram-and-zfs.15449/](https://www.truenas.com/community/threads/ecc-vs-non-ecc-ram-and-zfs.15449/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.truenas.com/community/threads/ecc-vs-non-ecc-ram-and-zfs.15449/](https://www.truenas.com/community/threads/ecc-vs-non-ecc-ram-and-zfs.15449/)
- en: 'I''ve seen many people unfortunately lose their zpools over this topic, so
    I''m going to try to provide as much detail as possible. If you don''t want to
    read to the end then just go with ECC RAM. For those of you that want to understand
    just how destructive non-ECC RAM can be, then I''d encourage you to keep reading.
    Remember, ZFS itself functions entirely inside of system RAM. Normally your hardware
    RAID controller would do the same function as the ZFS code. And every hardware
    RAID controller you''ve ever used that has a cache has ECC cache. The simple reason:
    they know how important it is to not have a few bits that get stuck from trashing
    your entire array. The hardware RAID controller(just like ZFS) absolutely NEEDS
    to trust that the data in RAM is correct.'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我看到很多人不幸因为这个问题失去了他们的zpools，所以我会尽量提供尽可能详细的信息。如果你不想读到最后，那就选择ECC RAM吧。对于那些想要了解非ECC
    RAM可能有多破坏性的人，我鼓励你继续阅读。记住，ZFS本身完全在系统RAM内运行。通常你的硬件RAID控制器会执行与ZFS代码相同的功能。而且你使用过的每个硬件RAID控制器都有ECC缓存。简单的原因是：他们知道不要让少数位从垃圾桶中损坏整个阵列。硬件RAID控制器（就像ZFS一样）绝对需要信任RAM中的数据是正确的。
- en: For those that don't want to read, just understand that ECC is one of the legs
    on your kitchen table, and you've removed that leg because you wanted to reuse
    old hardware that uses non-ECC RAM. Just buy ECC RAM and trust ZFS. Bad RAM is
    like your computer having dementia. And just like those old folks homes, you can't
    go ask them what they forgot. They don't remember, and neither will your computer.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些不想阅读的人，理解ECC就像你厨房桌子上的一条腿，你拿掉了那条腿，因为你想重新使用使用非ECC RAM的旧硬件。只需购买ECC RAM并信任ZFS。坏的RAM就像你的计算机患上了痴呆症。就像那些老人院一样，你不能去问他们忘记了什么。他们不记得，你的计算机也不会记得。
- en: 'Here''s some assumptions I''ve made and some explanation for them:'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是我做出的一些假设并对它们进行解释：
- en: 1\. We're going to deal with a system that has a single bit error. A memory
    location is stuck at "1". Naturally more than a single bit error is going to cause
    more widespread corruption. For my examples I'm going to provide a hypothetical
    8 bits of RAM. Bit number 2 will be stuck at "1". I will properly mark it with
    an
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 我们将处理一个存在单个位错误的系统。一个内存位置卡在“1”上。显然，如果存在多个位错误，将导致更广泛的损坏。在我的示例中，我将提供一个假设的8位RAM。第2位将卡在“1”上。我会正确标记它
- en: '**underline and bold**'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**下划线和粗体**'
- en: for bits that end up corrupted. Later I will move this location, but I will
    discuss that with you at that time.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对于最终损坏的位。稍后我会移动这个位置，但那时我会和你讨论这个问题。
- en: 2\. Most servers have very little RAM used by the system processes and large
    amounts of RAM for the cache, so we're going to assume that the system runs stable
    without problems as the errors are most likely in the cache. Even if the system
    happens to run into the bad RAM location resulting in a crash, you are more than
    likely going to reset it and keep going until you realize after multiple crashes
    in a short period of time that something else is wrong. At that point, you're
    going to already be in "oh crap" territory.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 大多数服务器系统进程使用的RAM非常少，而大量RAM用于缓存，因此我们假设系统运行稳定，没有问题，因为错误很可能在缓存中。即使系统偶尔在错误的RAM位置导致崩溃，你很可能会重新启动并继续，直到在短时间内多次崩溃后意识到有其他问题。在那时，你可能已经进入了“哦，糟糕”的境地。
- en: 3\. I'm going to ignore any potential corruption of the file system for my examples.
    Clearly corrupting the file system itself is VERY serious and can be fatal for
    your data. I will cover this topic at the very end of this discussion.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 对于我的示例，我将忽略文件系统的任何潜在损坏。显然，文件系统本身的损坏非常严重，可能对数据造成致命影响。我将在讨论的最后阶段涉及这个主题。
- en: 4\. No additional corruption from any other subsystem or data path will occur.
    Obviously any additional corruption won't make things any easier.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 不会有来自任何其他子系统或数据路径的额外损坏。显然，任何额外的损坏都不会让事情变得更容易。
- en: 5\. What I am about to explain is a limitation of ZFS. This is
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. 我将解释的内容是ZFS的一个限制。这是
- en: not
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 不
- en: FreeNAS specific. It is ZFS specific.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 特指FreeNAS。它是特指ZFS的。
- en: 'Now on to some examples:'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在开始一些示例：
- en: '**What happens when non-ECC RAM goes bad in a system for file systems that
    don''t do their own parity and checksumming?**'
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**当非ECC RAM在不做自己的奇偶校验和校验的文件系统中损坏时会发生什么？**'
- en: So pretend a file is loaded into RAM and then saved to an NTFS/ext4/UFS/whatever-file-system-you-want-that-doesn't-do-its-own-parity/checksumming.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 所以假装一个文件加载到RAM中，然后保存到不执行自己的奇偶校验/校验和的NTFS/ext4/UFS/任何您想要的文件系统中。
- en: The file is 8bits long. 00110011.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 文件长度为8位。00110011。
- en: Since our file got stored in RAM, its been corrupted. Now its 0
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们的文件存储在RAM中，它已经损坏了。现在它是0
- en: '**1**'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**1**'
- en: 110011\. Then that is forwarded to the disk subsystems and subsequently stored
    on the disk trashed. If this were file system data you might have bigger problems
    too. So now, despite what your destination is, a hard disk, an SSD, or a redundant
    array, the file will be saved wrong. No big deal except for that file. It might
    make the file unable to be opened in your favorite office suite or it might cause
    a momentary corruption of the image on your streaming video.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: 110011。然后这被转发到磁盘子系统，随后存储在磁盘上被破坏了。如果这是文件系统数据，你可能会有更大的问题。所以现在，不管你的目的地是什么，硬盘、固态硬盘还是冗余阵列，这个文件都会被错误保存。对于那个文件来说没什么大不了的，但它可能导致你的最爱办公套件无法打开文件，或者导致你流媒体视频画面暂时损坏。
- en: '**What happens when non-ECC RAM goes bad in a ZFS system?**'
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**当非ECC RAM在ZFS系统中损坏时会发生什么？**'
- en: So pretend that our same 8bit file is stored in RAM wrong.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 所以假设我们的相同8位文件存储在错误的RAM中。
- en: 'Same file as above and same length: 00110011.'
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述相同的文件和相同的长度：00110011。
- en: The file is loaded into RAM, and since its going to be stored on your ultra-safe
    zpool it goes to ZFS to be paritied and checksummed. So your RAIDZ2 zpool gets
    the file. But, here's the tricky part. The file is corrupted now thanks to your
    bad RAM location.
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 文件加载到RAM中，由于它将被存储在您的超安全zpool上，因此将会传输到ZFS进行奇偶校验和校验和。所以您的RAIDZ2 zpool得到了文件。但这里是棘手的部分。由于您的坏RAM位置，文件现在已经损坏了。
- en: ZFS gets 0
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: ZFS得到0
- en: '**1**'
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**1**'
- en: 110011 and is told to safely store that in the pool. So it calculates parity
    data and checksums for the corrupted data. Then, this data is saved to the disk.
    Ok, not much worse than above since the file is trashed. But your parity and checksum
    isn't going to help you since those were made
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 110011并被告知安全地存储在池中。因此，它为损坏的数据计算奇偶校验和校验和。然后，将这些数据保存到磁盘中。嗯，比上面糟糕得不多，因为文件已经被摧毁了。但是您的奇偶校验和校验和不会帮助您，因为它们是在
- en: '*after*'
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: '*之后*'
- en: the data was corrupted.
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: 数据已损坏。
- en: 'But, now things get messy. What happens when you read that data back? Let''s
    pretend that the bad RAM location is moved relative to the file being loaded into
    RAM. Its off by 3 bits and move it to position 5\. So now I read back the data:'
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，现在情况变得混乱。当您读取该数据时会发生什么？假设坏RAM位置相对于加载到RAM中的文件移动了。它偏离了3位并移动到第5位置。所以现在我读取回来的数据是：
- en: 'Read from the disk: 0'
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从磁盘读取：0
- en: '**1**'
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**1**'
- en: '110011.'
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: 110011。
- en: But what gets stored in RAM? 0
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: 但是什么存储在RAM中？0
- en: '**1**'
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**1**'
- en: '11'
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: '11'
- en: '**1**'
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**1**'
- en: '011.'
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
  zh: 011。
- en: Ok, no problem. ZFS will check against its parity. Oops, the parity failed since
    we have a
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，没问题。ZFS将根据其奇偶校验进行检查。糟糕，奇偶校验失败了，因为我们有一个
- en: '*new*'
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: '*新*'
- en: corrupted bit. Remember, the checksum data was calculated after the corruption
    from the first memory error occurred. So now the parity data is used to "repair"
    the bad data. So the data is "fixed" in RAM. Now it's supposed to be corrected
    to 01110011, right? But, since we have that bad 5th position, its
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: 损坏的位。请记住，校验和数据是在第一个内存错误损坏后计算的。因此现在奇偶校验数据被用来“修复”坏数据。所以数据在RAM中“修复”了。现在应该被修正为01110011，对吧？但是，由于我们有一个坏的第五位置，它就变成了
- en: '*still*'
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*仍然*'
- en: bad! Its corrected for potentially one clock cycle, but thanks to our bad RAM
    location its corrupted immediately again. So we really didn't "fix" anything.
    0
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: 糟糕！修正了可能的一个时钟周期，但由于我们糟糕的RAM位置，立即又损坏了。所以我们并没有真正“修复”任何东西。0
- en: '**1**'
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**1**'
- en: '11'
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: '11'
- en: '**1**'
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**1**'
- en: 011 is still in RAM. Now, since ZFS has detected corrupted data from a disk,
    its going to write the fix to the drive. Except its actually corrupting it even
    more because the repair didn't repair anything. So as you can see, things will
    only get worse as time goes on.
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: 011仍然在RAM中。现在，由于ZFS检测到来自磁盘的损坏数据，它将修复写入驱动器。但实际上它会更糟，因为修复没有修复任何东西。所以你可以看到，随着时间的推移，事情只会变得更糟。
- en: Now let's think about your backups.
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们考虑一下你的备份。
- en: If you use rsync, then rsync is going to backup the file in its corrupted form.
    But what if the file was correct and later corrupted? Well, thanks to rsync the
    backup itself is actually corrupted.
  id: totrans-split-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用 rsync，那么 rsync 将会备份该文件的损坏形式。但如果文件一开始是正确的，后来才损坏呢？嗯，多亏了 rsync，备份本身实际上也是损坏的。
- en: What about ZFS replication? Surely that's better, right? Well sort of. Thanks
    to those regular snapshots your server will happily replicate the corruption to
    your backup server. And lets not forget the added risk of corruption during replication
    because when the ZFS checksums are being calculated to be piped over SSH those
    might be corrupted too!
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: ZFS 复制呢？肯定比这个更好吧？嗯，有点道理。多亏了那些定期快照，你的服务器会愉快地将损坏复制到备份服务器上。还别忘了，在复制过程中出现损坏的风险也增加了，因为当计算
    ZFS 校验和以通过 SSH 传输时，这些数据可能也会损坏！
- en: But we're really smart. We also do religious zpool scrubs. Well, guess what
    happens when you scrub the pool. As that stuck memory location is continually
    read and written to, zfs will attempt to "fix" corrupted data that it thinks is
    from your hard disk and write that data back. But instead it is actually reading
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们非常聪明。我们也会定期进行 zpool scrub。那么当你对池进行 scrub 时会发生什么呢？当那个卡住的内存位置被持续读写时，ZFS 将尝试“修复”它认为来自硬盘的损坏数据，并将数据写回。但实际上，它读取
- en: '*good*'
  id: totrans-split-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*好的*'
- en: data from your drive, corrupting it in RAM, fixing it in RAM(which doesn't fix
    it as I've shown above), and then writing the "fixed" data to your disk. This
    means the data in entire pool is being trashed while trying to do a scrub.
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
  zh: 从你的驱动器中获取数据，在 RAM 中损坏它，在 RAM 中修复它（这并不像上面展示的那样修复它），然后将“修复”的数据写入你的磁盘。这意味着在尝试执行
    scrub 时整个池的数据都被破坏了。
- en: 'So in conclusion:'
  id: totrans-split-58
  prefs: []
  type: TYPE_NORMAL
  zh: 因此总结：
- en: 1\. All that stuff about ZFS self-healing goes down the drain if the system
    isn't using ECC RAM.
  id: totrans-split-59
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 所有关于 ZFS 自我修复的东西如果系统没有使用 ECC RAM，就毫无意义了。
- en: 2\. Backups will quite possibly be trashed because of bad RAM. Based on forum
    users over the last 18 months, you've got almost no chance your backups will be
    safe by the time you realize your RAM is bad.
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 备份很可能因为坏 RAM 而被破坏。根据过去 18 个月论坛用户的经验，你几乎没有机会在意识到 RAM 坏掉时保持你的备份安全。
- en: 3\. Scrubs are the best thing you can do for ZFS, but they can also be your
    worst enemy if you use bad RAM.
  id: totrans-split-61
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 对于 ZFS 来说，Scrub 是你能做的最好的事情，但如果使用了坏的 RAM，它们也可能成为你的大敌。
- en: 4\. The parity data, checksums, and actual data need to all match. If not, then
    repairs start taking place. And what are you to do a disk needs replaced and parity
    data and actual data don't match because of corruption? The data is lost.
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 校验数据、校验和以及实际数据必须完全匹配。如果不匹配，则会开始修复。如果因为损坏而需要更换磁盘，而校验数据和实际数据不匹配，数据将会丢失。
- en: 'To protect your data from loss with ZFS, here''s what you need to know:'
  id: totrans-split-63
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保护你的数据免受 ZFS 的损失，这里有些你需要知道的事情：
- en: 1\. Use ECC RAM. It's a fundamental truth.
  id: totrans-split-64
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 使用 ECC RAM。这是一个基本的真理。
- en: 2\. ZFS uses parity, checksums, mirrors, and the copies parameter to protect
    your data in various ways. Checksums prove that the data on the disk isn't corrupted,
    parity/mirrors/copies corrects those errors. As long as you have enough parity/mirrors/copies
    to fix any error that ever occurs, your data is 100% safe(again, assuming you
    are using ECC RAM). So running a RAIDZ1 is
  id: totrans-split-65
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. ZFS 使用校验、镜像、和 copies 参数以各种方式保护你的数据。校验证明磁盘上的数据没有损坏，校验/镜像/副本纠正这些错误。只要你有足够的校验/镜像/副本来修复任何可能发生的错误，你的数据就是
    100% 安全的（再次强调，假设你使用的是 ECC RAM）。所以运行 RAIDZ1 是
- en: '**very**'
  id: totrans-split-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**非常**'
- en: dangerous because when one disk fails you have no more protection. During the
    long(and strenuous) task of resilvering your pool you run a very high risk of
    encountering errors on the remaining disks. So any error is detected, but not
    corrected. Let's hope that the error isn't in your file system where corruption
    could be fatal for your entire pool. In fact, about 90% of users that lose their
    data had a RAIDZ1 and suffered 2 disk failures.
  id: totrans-split-67
  prefs: []
  type: TYPE_NORMAL
  zh: 危险，因为当一个磁盘失败时，你将失去更多的保护。在重新构建池的漫长（而费力）任务期间，你很可能会遇到剩余磁盘上的错误的高风险。所以任何错误都被检测到了，但没有被纠正。希望这个错误不是在你的文件系统中，因为对整个池来说，这种损坏可能是致命的。实际上，约
    90% 的用户丢失数据是因为他们使用了 RAIDZ1 并遭受了 2 个磁盘故障。
- en: 3\. If you run out of parity/mirrors and your pool is unmountable, you are in
  id: totrans-split-68
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 如果你的校验/镜像用完了，你的池就无法挂载，你就陷入了
- en: deep
  id: totrans-split-69
  prefs: []
  type: TYPE_NORMAL
  zh: 深入
- en: trouble. There are no recovery tools for ZFS, and quotes from data recovery
    specialists
  id: totrans-split-70
  prefs: []
  type: TYPE_NORMAL
  zh: 麻烦。对于 ZFS 没有恢复工具，而且数据恢复专家的报价
- en: start
  id: totrans-split-71
  prefs: []
  type: TYPE_NORMAL
  zh: 开始
- en: in the 5 digit range. All those tools people normally use for recovery of desktop
    file systems don't work with ZFS. ZFS is nothing like any of those file systems,
    and recovery tools typically only find billions of 4k blocks of data that looks
    like fragments to a file. Clearly it would be cheaper(and more reliable) to just
    make a backup, even if you have to build a second FreeNAS server. Let's not forget
    that if ZFS is corrupted
  id: totrans-split-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在5位数范围内。人们通常用于恢复桌面文件系统的所有那些工具在ZFS上都不起作用。ZFS与任何其他文件系统都不同，恢复工具通常只能找到看起来像文件碎片的数十亿个4K数据块。显然，即使您不得不建立第二个FreeNAS服务器，只需制作备份会更便宜（而且更可靠）。别忘了，如果ZFS损坏了
- en: '*just*'
  id: totrans-split-73
  prefs: []
  type: TYPE_NORMAL
  zh: '*只是*'
- en: badly enough to be unmountable because of bad RAM, even if your files are mostly
    safe, you'll have to consider that 5 digit price tag too.
  id: totrans-split-74
  prefs: []
  type: TYPE_NORMAL
  zh: 足够糟糕以至于由于坏内存而无法卸载，即使您的文件大部分是安全的，您也必须考虑那5位数的价格标签。
- en: 4\. Usually, when RAM goes bad you will normally lose more than a single memory
    location. The corruption is usually a breakdown of the insulation between locations,
    so adjacent locations start getting trashed too. This only creates more multi-bit
    errors.
  id: totrans-split-75
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 通常，当内存损坏时，您通常会失去多个内存位置，而不仅仅是一个。损坏通常是位置之间绝缘断裂，因此相邻位置也开始受到破坏。这只会产生更多的多位错误。
- en: 5\. ZFS is designed to repair corruption and isn't designed to handle corruption
    that you can't correct. That's why there's no fsck/chkdsk for ZFS. So once you're
    at the point that ZFS' file structure is corrupted and you can't repair it because
    you have no redundancy, you are probably going to lose the pool(and the system
    will probably kernel panic).
  id: totrans-split-76
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. ZFS被设计用来修复损坏，而不是处理您无法纠正的损坏。这就是为什么ZFS没有fsck/chkdsk的原因。所以一旦您到达ZFS的文件结构被损坏且由于没有冗余性而无法修复的时候，您可能会丢失池（并且系统可能会内核崩溃）。
- en: So now that you're convinced that ECC really is
  id: totrans-split-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您确信ECC真的是
- en: '*that*'
  id: totrans-split-78
  prefs: []
  type: TYPE_NORMAL
  zh: '*那*'
- en: important, you can build a system with ECC for relatively cheap...
  id: totrans-split-79
  prefs: []
  type: TYPE_NORMAL
  zh: 很重要，您可以用相对便宜的价格建立一个带ECC的系统...
- en: 'Motherboard:'
  id: totrans-split-80
  prefs: []
  type: TYPE_NORMAL
  zh: 主板：
- en: '[Supermicro X9SCM-F ($160ish)](http://www.amazon.com/dp/SUPERMICRO/?tag=ozlp-20)'
  id: totrans-split-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[Supermicro X9SCM-F（约160美元）](http://www.amazon.com/dp/SUPERMICRO/?tag=ozlp-20)'
- en: 'CPU:'
  id: totrans-split-82
  prefs: []
  type: TYPE_NORMAL
  zh: CPU：
- en: '[Pentium G2020 ($60ish)](http://www.amazon.com/dp/B00D5ZZZ70/?tag=ozlp-20)'
  id: totrans-split-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[奔腾 G2020（约60美元）](http://www.amazon.com/dp/B00D5ZZZ70/?tag=ozlp-20)'
- en: 'RAM:'
  id: totrans-split-84
  prefs: []
  type: TYPE_NORMAL
  zh: 内存：
- en: '[KVR16E11K4/32 32GB of DDR3-ECC-1600Mhz RAM($350ish)](http://www.amazon.com/dp/B008LMO1DG/?tag=ozlp-20)'
  id: totrans-split-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[KVR16E11K4/32 32GB DDR3-ECC-1600MHz RAM（约350美元）](http://www.amazon.com/dp/B008LMO1DG/?tag=ozlp-20)'
- en: So total cost is about
  id: totrans-split-86
  prefs: []
  type: TYPE_NORMAL
  zh: 总成本大约是
- en: '**$570**'
  id: totrans-split-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**570美元**'
- en: . Less if you don't want to go to a full 32GB of RAM. If you went with a 2x8GB
    RAM stick kit you can get the total price down about
  id: totrans-split-88
  prefs: []
  type: TYPE_NORMAL
  zh: 。如果您不想使用32GB的全套内存，那么价格可以降低约
- en: '**$370**'
  id: totrans-split-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**370美元**'
- en: . The G2020 is a great CPU for FreeNAS.
  id: totrans-split-90
  prefs: []
  type: TYPE_NORMAL
  zh: 。G2020对于FreeNAS来说是一个很棒的CPU。
- en: Of course, if you plan to use plugins like Plex that can be CPU intensive for
    transcoding you will need a little more power. Be wary of what CPUs do and don't
    support ECC. All Xeons do, and some i3s do. Check with Intels specification sheets
    to be sure
  id: totrans-split-91
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，如果您计划使用像Plex这样对转码要求较高的插件，您将需要更多的计算能力。要注意哪些CPU支持ECC，哪些不支持。所有的Xeon都支持，有些i3也支持。请查阅Intel的规格表以确保
- en: before
  id: totrans-split-92
  prefs: []
  type: TYPE_NORMAL
  zh: 之前
- en: you spend the money. I use an
  id: totrans-split-93
  prefs: []
  type: TYPE_NORMAL
  zh: 您花了钱。我使用
- en: '[E3-1230v2](http://www.amazon.com/dp/B0085MQUTU/?tag=ozlp-20)'
  id: totrans-split-94
  prefs: []
  type: TYPE_NORMAL
  zh: '[E3-1230v2](http://www.amazon.com/dp/B0085MQUTU/?tag=ozlp-20)'
- en: (about $250) and it is AMAZING! No matter what I throw at it I can't get more
    than about 30% CPU usage. Don't go by the TDP to try to pick the "greenest" CPU
    either. TDP is for full load heat output. That provides no information on what
    kind of power usage you will see when idle(which is what your system will probably
    be doing 99% of the time). My system with no disks installed and the system idle
    is at about 35w. Unfortunately I can't help with AMD CPUs since I'm not a fan
    of AMD. I do know that trying to go with "Green" CPUs for AMDs has disappointed
    many people here. "Green" CPUs perform slower than other CPUs, so be careful and
    don't buy a CPU that can't perform fast enough to make you happy.
  id: totrans-split-95
  prefs: []
  type: TYPE_NORMAL
  zh: （大约250美元），而且非常棒！无论我用它做什么，我都不能超过大约30%的CPU使用率。也不要只看TDP来选择“最环保”的CPU。TDP是指满负荷时的热量输出。这并不能说明您在空闲时（通常情况下系统会处于空闲状态99%的时间）将看到什么样的功耗。我的系统在没有安装硬盘且系统空闲时功耗约为35瓦。不幸的是，我无法帮助AMD
    CPU，因为我不喜欢AMD。我知道尝试选择AMD的“绿色”CPU已经让这里的许多人感到失望。“绿色”CPU的性能比其他CPU要慢，所以要小心，不要买一个速度不能让您满意的CPU。
- en: The motherboard I listed above is ideal too. It has dual Intel Gb LAN, IPMI(never
    need a keyboard, mouse and monitor ever again!), and PCIe slots for that M1015
    SAS controller you might want someday. I can't tell you how awesome IPMI is. But
    its basically remote desktop for your system. Except you can even use it during
    bootup. For example, you can go into your BIOS and change settings remotely! And
    you can mount CDs without a CD-ROM on the computer, remotely! How cool is that!?
    Add in the ability to remotely power on and off the server with IPMI and you have
    something for that server you want to shove in the corner and forget about.
  id: totrans-split-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我列出的主板也很理想。它具有双英特尔Gb LAN、IPMI（永远不需要键盘、鼠标和显示器！）以及用于未来可能需要的M1015 SAS控制器的PCIe插槽。我无法告诉你IPMI有多棒。但它基本上是你系统的远程桌面。除了你甚至可以在启动期间使用它。例如，你可以进入你的BIOS并远程更改设置！你甚至可以在没有计算机上的CD-ROM的情况下远程挂载CD！多酷啊！再加上通过IPMI远程开关和关闭服务器的能力，你对于那些想要塞到角落并忘记的服务器有了解决方案。
- en: ECC RAM can only detect
  id: totrans-split-97
  prefs: []
  type: TYPE_NORMAL
  zh: ECC RAM只能检测
- en: and
  id: totrans-split-98
  prefs: []
  type: TYPE_NORMAL
  zh: 和
- en: correct single bit errors. When you have multi-bit errors(if my experience is
    any indication) the system can detect(but not correct) those errors and immediately
    halts the system with a warning message on the screen with the bad memory location.
    Naturally, halting the system is bad as the system becomes unavailable. But its
    better to halt the system and let you remove the bad DIMM than to let your zpool
    get corrupted because of bad RAM. Remember, the whole goal is to protect your
    zpool and a system halt is the best bet once you've realized things are going
    badly in RAM.
  id: totrans-split-99
  prefs: []
  type: TYPE_NORMAL
  zh: 正确的单比特错误。当你有多比特错误（如果我的经验是任何指示），系统可以检测（但不能纠正）这些错误，并立即在屏幕上显示带有坏内存位置的警告消息停止系统。当然，停止系统是不好的，因为系统变得不可用。但一旦意识到内存出现问题，停止系统比让你的zpool因为坏内存而损坏是最好的选择。记住，整个目标是保护你的zpool，一旦意识到情况不妙，系统停止是最好的选择。
- en: 'Here''s another way to look at it:'
  id: totrans-split-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有另一种看待它的方式：
- en: 'Example 1: Running a server with its native file system(probably ext3, NTFS,
    or HFS+), non-ECC RAM. The only way you can expect to lose your entire drive''s
    worth of data is if your drive actually fails completely. If your RAM goes bad
    you''ll potentially lose a few files to corruption that have been recently opened.
    You may have to run a chkdsk/fsck on the partition to get it back in good shape.
    But you''ll be able to take that disk and put it in another machine and get most(if
    not all) of your data back. Even a worst case scenario there''s plenty of tools
    like'
  id: totrans-split-101
  prefs: []
  type: TYPE_NORMAL
  zh: 示例1：运行具有其本机文件系统（可能是ext3、NTFS或HFS+）的服务器，非ECC RAM。你唯一可能期望丢失整个驱动器数据的方式是如果你的驱动器完全失败。如果你的RAM坏了，你可能会因最近打开的几个文件的损坏而丢失一些文件。你可能需要在分区上运行chkdsk/fsck来使其恢复良好。但你可以把那张盘放到另一台机器上，并恢复大部分（如果不是全部）数据。即使在最糟糕的情况下，也有很多工具像
- en: '[Ontrack EasyRecovery DIY](http://www.krollontrack.com/data-recovery/recovery-software/)'
  id: totrans-split-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ontrack EasyRecovery DIY](http://www.krollontrack.com/data-recovery/recovery-software/)'
- en: Software that will work for NTFS and you can expect to have a reasonable chance
    of getting most(if not all) of your data back. You can also call those data recovery
    professionals and for 4-figures they might get your data back from a failed disk.
  id: totrans-split-103
  prefs: []
  type: TYPE_NORMAL
  zh: 可用于NTFS的软件，你可以期望有合理的机会恢复大部分（如果不是全部）的数据。你还可以打电话给那些数据恢复专业人员，他们可能会从失败的磁盘中恢复你的数据，需要4位数的费用。
- en: 'Example 2: Server with ZFS and non-ECC RAM. Now you have more ways to lose
    your data:'
  id: totrans-split-104
  prefs: []
  type: TYPE_NORMAL
  zh: 示例2：服务器使用ZFS和非ECC RAM。现在你有更多丢失数据的方法：
- en: 1\. If the drive completely dies(obviously).
  id: totrans-split-105
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 如果驱动器完全损坏（显然）。
- en: 2\. Based on prior users that have had non-ECC RAM fail you'll reboot to find
    your pool unmountable. This means your data is gone. There is no data recovery
    tools out there for ZFS. NONE. It's ALL gone for good.
  id: totrans-split-106
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 基于以前使用过非ECC RAM失败的用户，你将重新启动以发现你的池子无法安装。这意味着你的数据丢失了。对于ZFS没有数据恢复工具。没有。它们全部永远丢失了。
- en: '3\. What about the fact that you used those non-server grade parts? Guess what,
    they can also trash your pool and make it unmountable. The outcome is exactly
    the same as #2\. You just lost'
  id: totrans-split-107
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 那你用那些非服务器级部件呢？猜猜看，它们也能损坏你的池子并使其无法安装。结果与#2完全相同。你刚刚丢失了
- en: all
  id: totrans-split-108
  prefs: []
  type: TYPE_NORMAL
  zh: 所有
- en: of your data because the pool won't mount.
  id: totrans-split-109
  prefs: []
  type: TYPE_NORMAL
  zh: 你的数据是否能够被加载，因为池不会安装。
- en: The problem is that your native file systems have tools like chkdsk and fsck
    to fix file system errors. You also have plenty of options for software recovery
    with utilities like
  id: totrans-split-110
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于你的本机文件系统有像chkdsk和fsck这样的工具来修复文件系统错误。你还有许多选项可以使用像
- en: '[Ontrack EasyRecovery DIY](http://www.krollontrack.com/data-recovery/recovery-software/)'
  id: totrans-split-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ontrack EasyRecovery DIY](http://www.krollontrack.com/data-recovery/recovery-software/)'
- en: Software.
  id: totrans-split-112
  prefs: []
  type: TYPE_NORMAL
  zh: 软件。
- en: But, no matter how much searching you do, there is no ZFS recovery tools out
    there. You are welcome to call companies like Ontrack for data recovery. I know
    one person that did, and they spent $3k just to find out
  id: totrans-split-113
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，无论你做多少搜索，都找不到ZFS恢复工具。您可以联系像Ontrack这样的公司进行数据恢复。我知道有人这样做了，他们花了3000美元只是为了找出
- en: '*if*'
  id: totrans-split-114
  prefs: []
  type: TYPE_NORMAL
  zh: '*if*'
- en: their data was recoverable. Then they spent another $15k to get just 200GB of
    data back.
  id: totrans-split-115
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的数据是可恢复的。然后，他们又花了15000美元仅恢复了200GB的数据。
- en: 'So tell me which example you''d rather fall into? #1 where you have fewer opportunities
    to lose everything and have recovery options. Or #2 where you have quite alot
    more opportunities to lose everything and have zero recovery options to boot?
    I''d rather be in scenario 1 than scenario 2\. I can''t imagine you''d want scenario
    2 either.'
  id: totrans-split-116
  prefs: []
  type: TYPE_NORMAL
  zh: 那么告诉我你更愿意陷入哪个例子？＃1 在这里，您有更少的机会失去一切并且有恢复选项。或＃2，在这里，您有更多机会失去一切并且没有恢复选项。我宁愿处于情景1而不是情景2。我无法想象您也会希望情景2。
- en: So when you read about how using ZFS is an "all or none" I'm not just making
    this up. I'm really serious as it really does work that way. ZFS either works
    great or doesn't work at all. That
  id: totrans-split-117
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当您了解如何使用ZFS是“全有或全无”时，我并不是在编造。我是认真的，因为它确实是这样运作的。ZFS要么工作得很好，要么根本不工作。那
- en: really
  id: totrans-split-118
  prefs: []
  type: TYPE_NORMAL
  zh: 确实
- en: truthfully how it works
  id: totrans-split-119
  prefs: []
  type: TYPE_NORMAL
  zh: 真实的工作原理
- en: Don't like it, be one of the few that "stick it to the man" with non-recommended
    components. It's your win(or loss). But you will get absolutely no sympathy when
    you show up and your pool doesn't mount like many people that think they can build
    a cheap system and get away with it.
  id: totrans-split-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果不喜欢，可以选择使用不推荐的组件中的少数人。这是你的胜利（或失败）。但是，当您出现时，您的存储池无法挂载时，绝对不会得到同情，就像许多认为可以建立便宜系统并逃脱惩罚的人一样。
- en: '**PLEASE TAKE THIS AS A WARNING TO NOT USE NON-ECC RAM WITH ZFS.** [Cool presentation
    from Intel about RAM errors and non-ECC vs ECC.](http://cache-www.intel.com/cd/00/00/46/78/467819_467819.pdf)'
  id: totrans-split-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**请注意，不要使用非ECC RAM与ZFS。** [Intel关于RAM错误和非ECC与ECC的精彩演讲。](http://cache-www.intel.com/cd/00/00/46/78/467819_467819.pdf)'
- en: 'Someone else that confirms this:'
  id: totrans-split-122
  prefs: []
  type: TYPE_NORMAL
  zh: 另一位证实这一点的人是
- en: '[https://pthree.org/2013/12/10/zfs-administration-appendix-c-why-you-should-use-ecc-ram/](https://pthree.org/2013/12/10/zfs-administration-appendix-c-why-you-should-use-ecc-ram/)'
  id: totrans-split-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://pthree.org/2013/12/10/zfs-administration-appendix-c-why-you-should-use-ecc-ram/](https://pthree.org/2013/12/10/zfs-administration-appendix-c-why-you-should-use-ecc-ram/)'
- en: 'List of threads where people unfortunately experienced data loss with bad non-ECC
    RAM. (Updated when I can remember to):'
  id: totrans-split-124
  prefs: []
  type: TYPE_NORMAL
  zh: 一些不幸经历了因坏的非ECC RAM导致的数据丢失的帖子列表（我记得时更新）：
- en: 'List of people that have posted info that asserts the fact that ECC saved them:'
  id: totrans-split-125
  prefs: []
  type: TYPE_NORMAL
  zh: 已发布信息并确认ECC救了他们的一些人的列表：
