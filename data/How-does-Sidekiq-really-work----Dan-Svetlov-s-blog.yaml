- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-27 14:37:12'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-27 14:37:12
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: How does Sidekiq really work? | Dan Svetlov’s blog
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sidekiq到底是如何工作的？| 丹·斯维特洛夫的博客
- en: 来源：[https://dansvetlov.me/sidekiq-internals/](https://dansvetlov.me/sidekiq-internals/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://dansvetlov.me/sidekiq-internals/](https://dansvetlov.me/sidekiq-internals/)
- en: Since its publication, [this post was endorsed by Mike Perham](https://www.mikeperham.com/2024/02/22/how-does-sidekiq-work/),
    the creator of Sidekiq.
  id: totrans-split-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 自发布以来，[Mike Perham已背书这篇文章](https://www.mikeperham.com/2024/02/22/how-does-sidekiq-work/)，Sidekiq的创造者。
- en: '[Hacker News discussion](https://news.ycombinator.com/item?id=39257174)'
  id: totrans-split-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[Hacker News讨论](https://news.ycombinator.com/item?id=39257174)'
- en: '[Sidekiq](https://github.com/sidekiq/sidekiq) is one of the most ubiquitous
    ^(Ruby background job processors out there. To anybody who has worked with Ruby
    on and off Rails, it needs no introduction. Sidekiq has a 10+ year track record
    of being an efficient, battle-tested and simple-to-use solution for offloading
    the execution of application logic into the background.)'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Sidekiq](https://github.com/sidekiq/sidekiq)是最常见的Ruby后台作业处理器之一。对于任何有经验的Ruby开发者而言，它无需介绍。Sidekiq以其高效、经过实战检验且易于使用的解决方案，拥有超过10年的记录，用于将应用程序逻辑的执行转移到后台。'
- en: It utilizes a threaded model for job processing, uses Redis as a backend and
    claims to have an ‘at least once’ semantic when it comes to processing jobs (with
    a caveat) in a free open-source version. Sidekiq also offers 2 additional paid
    versions - Pro and Enterprise, each of them introducing additional features and
    extensions. For obvious reasons, I will not go into the details of these versions.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 它利用线程模型进行作业处理，使用Redis作为后端，并声称在免费的开源版本中在处理作业时具有“至少一次”的语义（带有一个警告）。Sidekiq还提供了另外两个付费版本
    - Pro和Enterprise，每个版本都引入了额外的功能和扩展。由于明显的原因，我不会详细介绍这些版本的细节。
- en: This article will delve into the internals of Sidekiq to highlight its key aspects,
    as well as design and implementation decisions that I personally find interesting
    or peculiar, by diving directly into the source code and following a job through
    its full lifecycle.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本文将深入探讨Sidekiq的内部结构，突出其关键方面以及我个人认为有趣或奇特的设计和实现决策，通过直接深入源代码并跟踪作业的完整生命周期。
- en: I will not cover the user-facing API and general “how-to’s” of Sidekiq. Its
    [wiki](https://github.com/sidekiq/sidekiq/wiki/Getting-Started) provides a better
    resource for this. Basic acquaintance with the library, as well as Ruby, is expected.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会涵盖Sidekiq的用户界面API和一般的“如何操作”。它的[wiki](https://github.com/sidekiq/sidekiq/wiki/Getting-Started)提供了更好的资源。预期具备对该库及Ruby的基本了解。
- en: The code examined in this article was sourced from Sidekiq version 7.2 and Ruby
    3.2 on [MRI/cruby](https://github.com/ruby/ruby). Even though the code discussed
    may become obsolete with newer Sidekiq versions, it would take a drastic philosophy
    change on the maintainers’ part for the general principles and architecture to
    become outdated. Nonetheless, the article could serve as a valuable resource for
    anyone looking to practice their systems programming skills by building a job
    processor.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中检查的代码来自Sidekiq 7.2版本和Ruby 3.2，运行在[MRI/cruby](https://github.com/ruby/ruby)上。尽管所讨论的代码可能会随着Sidekiq的更新而过时，但除非维护者在哲学上做出
    drast 的变化，否则其一般原则和架构不会过时。尽管如此，本文可能对希望通过构建作业处理器练习其系统编程技能的任何人都是宝贵的资源。
- en: It’s worth noting that I’m neither a maintainer nor a contributor of Sidekiq.
    All of my observations and conclusions stem from reading the source code, comments,
    and discussions from issues and pull requests sourced via `git blame`.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，我既不是Sidekiq的维护者，也不是贡献者。我所有的观察和结论都源于阅读源代码、注释以及通过`git blame`获取的问题和拉取请求的讨论。
- en: Booting up
  id: totrans-split-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动过程
- en: I believe that the best way to get acquainted with code is by examining its
    entry points first. Sidekiq, being a *background* job processor, must be initiated
    as a separate process. `bin/sidekiq` is the script that is used to initiate this
    process, with its primary responsibility being the instantiation of the `Sidekiq::CLI`
    singleton class.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为熟悉代码的最佳方式是首先检查其入口点。作为*后台*作业处理器的Sidekiq必须作为单独的进程初始化。`bin/sidekiq`是用于启动此过程的脚本，其主要职责是实例化`Sidekiq::CLI`单例类。
- en: The `CLI` object parses the configuration passed to the process as command line
    arguments via Ruby’s [`OptionParser`](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/cli.rb#L26-L32),
    and initialises the [global default `Sidekiq::Config`](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/config.rb#L11-L35).
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`CLI` 对象使用 Ruby 的 [`OptionParser`](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/cli.rb#L26-L32)
    解析传递给进程的命令行参数配置，并初始化了[全局默认的 `Sidekiq::Config`](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/config.rb#L11-L35)。'
- en: If a valid path to a YAML config is passed via `--config/-C` CLI argument, it
    will be used; otherwise, it will assume that this configuration can be found under
    the relative `./config` path. Alternatively it’s also possible to supply a custom
    `--require/-R` argument that is supposed to point to the root directory of an
    application where the job classes are located. Configuration in that case would
    be sourced from `<path-specified-by-require>/config`.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果通过 `--config/-C` CLI 参数传递了有效的 YAML 配置路径，它将被使用；否则，假定该配置可以在相对路径 `./config` 下找到。此外，也可以提供自定义的
    `--require/-R` 参数，该参数应指向作业类所在的应用程序根目录。在这种情况下，配置将从 `<require 指定的路径>/config` 获取。
- en: If the configuration file exists, Sidekiq will evaluate it using `ERB`. This
    allows defining the config file as a template. However, one notable caveat is
    that this file will be evaluated before the Rails application or a file specified
    via `--require` is required, which makes referencing constants defined in the
    application code impossible.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果配置文件存在，Sidekiq 将使用 `ERB` 进行评估。这允许将配置文件定义为模板。然而，一个显著的注意事项是，在需要 Rails 应用程序或通过
    `--require` 指定的文件之前，将会对此文件进行评估，这使得引用应用程序代码中定义的常量成为不可能。
- en: Then, `queues` and `concurrency` configuration options are [populated](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/cli.rb#L275-L277)
    if their values were not explicitly set. With default values, Sidekiq will process
    only the `default` queue and set its `concurrency` to the value of the `RAILS_MAX_THREADS`
    environment variable if Sidekiq is being used with a Rails application.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，如果它们的值未明确设置，默认值的情况下，将填充 `queues` 和 `concurrency` 配置选项。使用默认值时，Sidekiq 仅处理
    `default` 队列，并将其 `concurrency` 设置为 `RAILS_MAX_THREADS` 环境变量的值（如果 Sidekiq 与 Rails
    应用程序一起使用）。
- en: As a penultimate step in the configuration process, both the `queues` and `concurrency`
    options get set on every capsule. Capsules will be examined in detail in the following
    sections, but for now, capsules can be thought of as compartmentalised groups
    of configuration options. In a basic Sidekiq setup, capsules are not exposed to
    the user; however, a default capsule is implicitly used. It is possible to define
    custom capsules in the configuration YAML file and via `Sidekiq.configure_server`.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 作为配置过程中的倒数第二步，每个胶囊都设置了 `queues` 和 `concurrency` 选项。胶囊将在后续部分详细介绍，但目前可以将胶囊视为配置选项的分区化组。在基本的
    Sidekiq 设置中，胶囊不对用户公开；但是，默认胶囊会隐式使用。可以在配置 YAML 文件和通过 `Sidekiq.configure_server`
    中定义自定义胶囊。
- en: Finally, `CLI` instance validates that the `--require` argument points to an
    existing file, or, in case it points to a directory, that `config/application.rb`
    exists. It also checks that `concurrency` and `timeout` are positive integer numbers.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`CLI` 实例验证 `--require` 参数指向的是现有文件，或者如果它指向目录，则 `config/application.rb` 存在。还检查
    `concurrency` 和 `timeout` 是否为正整数。
- en: Entering the main loop
  id: totrans-split-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进入主循环
- en: After loading and validating the configuration, the `bin/sidekiq` executable
    calls `run` on the CLI instance. At this point, the application gets loaded.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 加载和验证配置后，`bin/sidekiq` 可执行文件在 CLI 实例上调用 `run`。在这一点上，应用程序被加载。
- en: If the path in the `require` config param is a directory, which is `.` by default
    unless explicitly configured, Sidekiq assumes that it’s being [used in a Rails
    application](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/cli.rb#L294-L308)
    and requires `rails` and `sidekiq/rails`, followed by a `require File.expand_path("#{@config[:require]}/config/environment.rb")`.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `require` 配置参数中的路径是一个目录，默认情况下是 `.`，除非明确配置，Sidekiq 假定它正在[用于 Rails 应用程序](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/cli.rb#L294-L308)，并要求
    `rails` 和 `sidekiq/rails`，随后通过 `require File.expand_path("#{@config[:require]}/config/environment.rb")`。
- en: Otherwise, if `require` points to a file, that file gets required. This means
    that the `require` config param always has to be explicitly supplied and point
    to an entry point that loads the application code if used in a non-Rails application.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，如果 `require` 指向一个文件，该文件将被加载。这意味着如果在非 Rails 应用程序中使用，`require` 配置参数必须始终明确提供，并且指向一个加载应用程序代码的入口点。
- en: Calls to `Sidekiq.configure_server` and `Sidekiq.configure_client` also get
    evaluated during the application boot since they’re typically part of the eagerly
    loadable application code. This setup most commonly occurs in a `config/initializers/sidekiq.rb`
    Rails initializer.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 调用 `Sidekiq.configure_server` 和 `Sidekiq.configure_client` 也会在应用程序启动期间进行评估，因为它们通常是可以急加载的应用程序代码的一部分。这种设置最常见于
    `config/initializers/sidekiq.rb` Rails 初始化程序中。
- en: Signal handling
  id: totrans-split-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 信号处理
- en: Before proceeding to the next step in the `run` method, it might be worth refreshing
    our memory on what [signals](https://man7.org/linux/man-pages/man7/signal.7.html)
    are.
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `run` 方法的下一步之前，值得回顾一下 [信号](https://man7.org/linux/man-pages/man7/signal.7.html)
    是什么。
- en: In essence, signals can be considered a type of inter-process communication.
    It’s possible to define custom handlers for most signals, which will execute arbitrary
    logic once the process receives a corresponding one. One use case for signals
    is controlling long-lived daemon processes, such as Sidekiq. For example, Kubernetes
    sends a SIGTERM to pods so that they can shut down gracefully and perform necessary
    cleanup, which is relevant for a job processor like Sidekiq. Most modern orchestration
    tools and hosting platforms support graceful termination by sending either a SIGINT
    or SIGTERM to running processes.
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，信号可以被视为一种进程间通信的类型。可以为大多数信号定义自定义处理程序，一旦进程接收到相应的信号，它们将执行任意逻辑。信号的一个用例是控制长时间运行的守护进程，例如
    Sidekiq。例如，Kubernetes 发送 SIGTERM 到 Pod，以便它们可以优雅地关闭并执行必要的清理工作，这对于像 Sidekiq 这样的作业处理器是相关的。大多数现代编排工具和托管平台通过发送
    SIGINT 或 SIGTERM 给运行中的进程来支持优雅终止。
- en: 'With theory out of the way, let’s see how Sidekiq interacts with signals [here](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/cli.rb#L49-L74):'
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: 理论讲解结束后，让我们看看 Sidekiq 如何在这里与信号交互 [here](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/cli.rb#L49-L74)
    ：
- en: '[PRE0]'
  id: totrans-split-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The first interesting thing to note is the creation of an unnamed pipe using
    the `IO.pipe` API provided by Ruby. Its [return value](https://github.com/ruby/ruby/blob/a7335e11e354d1ee2e15233f32f087230069ad5c/io.c#L408-L440)
    is a 2-member array of `IO` instances wrapping the file descriptors returned by
    the underlying system call ([`pipe2` or `pipe`](https://man7.org/linux/man-pages/man2/pipe.2.html)
    on most UNIX-like systems):'
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的第一件事是使用 Ruby 提供的 `IO.pipe` API 创建一个未命名管道。它的 [返回值](https://github.com/ruby/ruby/blob/a7335e11e354d1ee2e15233f32f087230069ad5c/io.c#L408-L440)
    是一个包含由底层系统调用（在大多数类 UNIX 系统上为 `pipe2` 或 `pipe`）返回的文件描述符的 `IO` 实例数组：
- en: '[PRE1]'
  id: totrans-split-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Unnamed pipes are extremely handy in forking environments since they can be
    used by the parent process to communicate with its children and vice versa without
    much complicated setup. However, Sidekiq does not employ a forking model (in a
    free OS version) and instead utilizes threads extensively, which all share the
    process’s memory. So why use a pipe? Before we answer this question, let’s examine
    what happens in Sidekiq’s signal handlers.
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 未命名管道在分叉环境中非常有用，因为父进程可以与其子进程及其反之进行通信，而不需要进行复杂的设置。但是，Sidekiq 在免费操作系统版本中不使用分叉模型，而是广泛使用线程，所有线程共享进程的内存。那么为什么要使用管道？在回答这个问题之前，让我们来看看
    Sidekiq 的信号处理程序中发生了什么。
- en: 'As evident from the Ruby snippet above, Sidekiq sets up handlers for SIGINT,
    SIGTERM, SIGTTIN, and SIGTSTP. Each handler is defined sequentially using `Signal.trap`,
    which, on UNIX-like systems, internally constructs a handler and invokes the [`sigaction`](https://man7.org/linux/man-pages/man2/sigaction.2.html)
    system call:'
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的 Ruby 片段可以看出，Sidekiq 设置了对 SIGINT、SIGTERM、SIGTTIN 和 SIGTSTP 的处理程序。每个处理程序都是使用
    `Signal.trap` 按顺序定义的，在类 UNIX 系统上，它内部构造了一个处理程序并调用了 [`sigaction`](https://man7.org/linux/man-pages/man2/sigaction.2.html)
    系统调用：
- en: '[PRE2]'
  id: totrans-split-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: As observed, this function returns an instance of a handler previously registered
    for the same signal.
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: 如观察所示，此函数返回了先前为同一信号注册的处理程序的实例。
- en: 'Let’s revisit the signal registration in `Sidekiq::CLI`:'
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新审视 `Sidekiq::CLI` 中的信号注册：
- en: '[PRE3]'
  id: totrans-split-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This code might appear confusing at first glance - how is `old_handler` being
    called from within a block when `old_handler` itself is the return value of the
    said block? To unravel this little Inception moment, consider the following facts:'
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码乍一看可能会令人困惑 - `old_handler`如何在块内部调用，而`old_handler`本身又是该块的返回值？为了解开这个小的“盗梦空间”时刻，考虑以下事实：
- en: As we have seen, `Signal.trap` returns the handler that was previously registered
    for the signal, which is propagated from the `ruby_signal` C function. This can
    be an instance of `Proc` or a string. For possible string return values, you can
    refer to [this part of the `trap` function](https://github.com/ruby/ruby/blob/a7335e11e354d1ee2e15233f32f087230069ad5c/signal.c#L1310-L1323),
    which is responsible for returning the old handler to the Ruby land.
  id: totrans-split-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正如我们所见，`Signal.trap`返回先前为信号注册的处理程序，该处理程序从`ruby_signal` C函数传播而来。这可以是`Proc`的实例或字符串。有关可能的字符串返回值，请参考`trap`函数的[这部分](https://github.com/ruby/ruby/blob/a7335e11e354d1ee2e15233f32f087230069ad5c/signal.c#L1310-L1323)，负责将旧处理程序返回到Ruby环境。
- en: The block passed to `Signal.trap` is not evaluated instantly; instead, it is
    called only when the corresponding signal is received by the process. The proc
    object is [stored in the global `vm->trap_list` struct](https://github.com/ruby/ruby/blob/a7335e11e354d1ee2e15233f32f087230069ad5c/signal.c#L1325).
  id: totrans-split-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传递给`Signal.trap`的块不会立即评估；相反，它仅在进程接收到相应的信号时才被调用。proc对象存储在全局`vm->trap_list`结构中。
- en: Local `old_handler` variable is available within a block due to the way bindings
    work in Ruby; `old_handler` is simply inherited by the inner scope of the block.
    This behavior is akin to how it’s possible to reference local variables in a rescue
    block even if an exception is raised before they are defined.
  id: totrans-split-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于Ruby中绑定的工作方式，局部变量`old_handler`在块内部是可用的；`old_handler`只是通过块的内部作用域继承而来。这种行为类似于即使在引发异常之前未定义它们，也可以在救援块中引用局部变量。
- en: So, `Signal.trap` converts the passed block into an instance of `Proc`, does
    not evaluate it, and registers it in the global `trap_list` instead. When a signal
    is received, the corresponding handler gets called. `old_handler` will evaluate
    to either a string signifying the handler behavior (e.g., DEFAULT or IGNORE),
    which will be the case if no custom signal traps were defined previously, or an
    old custom handler. Sidekiq politely handles previously defined trap handlers
    since it cannot make assumptions about the environment it is running in. It’s
    possible that a developer or another library already declared a signal handler
    that is expected to be called.
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，`Signal.trap`将传递的块转换为`Proc`实例，不会立即评估它，并在全局`trap_list`中注册。当接收到信号时，相应的处理程序将被调用。`old_handler`将评估为表示处理程序行为的字符串（例如，默认或忽略），如果之前未定义自定义信号陷阱，则为此情况，或者是旧的自定义处理程序。Sidekiq礼貌地处理了以前定义的陷阱处理程序，因为它无法对其运行的环境进行假设。开发人员或其他库可能已经声明了预期被调用的信号处理程序。
- en: However, the trap context ends with the signal name being written to the unnamed
    pipe created earlier. The fact that the exception is emitted directly to STDOUT
    in case it’s raised instead of being logged using `Sidekiq.logger` could serve
    as a hint as to why the handler logic is not being evaluated directly. For the
    exact reason why this happens and for the actual behavior of SIGINT, SIGTERM,
    and other handlers, read on.
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，陷阱上下文以信号名称被写入先前创建的未命名管道结束。异常直接发出到STDOUT而不是使用`Sidekiq.logger`记录可能是提示处理程序逻辑未直接评估的原因。关于为何会发生这种情况以及SIGINT、SIGTERM和其他处理程序的实际行为，请继续阅读。
- en: The rest of `run`’s method execution is spent on eagerly loading resources,
    namely the [Redis connection pool](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/cli.rb#L73-L76)
    and the [server middleware chain](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/cli.rb#L101-L102).
    This pattern is commonly used to avoid race conditions during the initialization
    of global resources in multi-threaded environments. The `run` method is the perfect
    opportunity to do so, since at this point there’s only one main thread, making
    synchronization redundant for the creation of state. Alternatively, if the resource
    were lazily loadable, its accessor would have to be wrapped in a synchronization
    primitive such as a mutex, which would incur performance penalties for every happy
    path triggered, where the resource is already allocated and just has to be referenced.
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`run`方法的其余执行时间用于急切加载资源，即[Redis连接池](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/cli.rb#L73-L76)和[服务器中间件链](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/cli.rb#L101-L102)。这种模式通常用于在多线程环境中初始化全局资源时避免竞态条件。`run`方法是这样做的绝佳机会，因为此时只有一个主线程，使得在创建状态时同步变得多余。或者，如果资源是惰性加载的，那么其访问器必须用同步原语（如互斥锁）包装，这会导致在每次触发正常路径时都会产生性能损失，而资源已分配并且只需要被引用。'
- en: 'Finally, `run` calls `launch` and passes the reader end of the pipe as an argument.
    `launch` is the method where the main thread will spend the rest of its time while
    the Sidekiq process is running:'
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`run`调用`launch`并将管道的读取端作为参数传递。`launch`方法是主线程在Sidekiq进程运行时所花费其余时间的地方：
- en: '[PRE4]'
  id: totrans-split-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: A `Sidekiq::Launcher` instance is created, and `run` is called on it. The block
    where this happens is wrapped in a `rescue Interrupt`.
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: 创建了一个`Sidekiq::Launcher`实例，并调用了`run`方法。这个过程发生的地方被包裹在一个`rescue Interrupt`块中。
- en: By default, `Interrupt` is raised only when the process [does not have a custom
    `SIGINT` handler registered](https://github.com/ruby/ruby/blob/a7335e11e354d1ee2e15233f32f087230069ad5c/signal.c#L1105-L1109),
    which is not the case here as `Signal.trap` was already explicitly called with
    SIGINT. In that case, let’s see where it might be getting raised from.
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，仅当进程[没有注册自定义`SIGINT`处理程序时](https://github.com/ruby/ruby/blob/a7335e11e354d1ee2e15233f32f087230069ad5c/signal.c#L1105-L1109)才会引发`Interrupt`，而这里的情况并非如此，因为`Signal.trap`已经显式调用了SIGINT。在这种情况下，让我们看看它可能是从哪里引发的。
- en: 'After the launcher gets commanded to run, the main thread enters an endless
    loop that calls `self_read.wait_readable`. This method, without a timeout argument,
    waits indefinitely until the underlying file descriptor has any data available
    to read. Whenever any signal that was trapped with `Signal.trap` earlier gets
    sent to the process, it will eventually be written to the writer end of the pipe
    and get read here. `handle_signal` will call a corresponding handler [defined
    in the `Sidekiq::CLI::SIGNAL_HANDLERS` hash](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/cli.rb#L190-L217):'
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动器被命令运行之后，主线程进入一个无限循环，调用`self_read.wait_readable`。这个方法在没有超时参数的情况下无限期地等待，直到底层文件描述符有可读数据可用。当之前使用`Signal.trap`陷阱捕获的任何信号被发送到进程时，它最终将被写入管道的写入端并在此处读取。`handle_signal`将调用[在`Sidekiq::CLI::SIGNAL_HANDLERS`哈希表中定义的相应处理程序](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/cli.rb#L190-L217)。
- en: '[PRE5]'
  id: totrans-split-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The key signal handlers to note are SIGINT, SIGTERM, and SIGTSTP. ^(The former
    two handlers consist only of a `raise Interrupt`, which will be rescued in the
    `CLI.launch` loop we looked at previously. SIGTSTP is a bit different - it calls
    `quiet` on the `Sidekiq::Launcher` instance.)
  id: totrans-split-53
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的关键信号处理程序是SIGINT、SIGTERM和SIGTSTP。^(前两个处理程序仅包含`raise Interrupt`，这将在之前我们查看过的`CLI.launch`循环中被捕获。SIGTSTP有些不同
    - 它调用`Sidekiq::Launcher`实例上的`quiet`方法。)
- en: Before we dive deeper into the launcher, let’s first answer why the signal handlers
    are not being executed directly from trap contexts and instead get sent to a pipe
    and processed in a main thread loop.
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨启动器之前，让我们首先回答为什么信号处理程序不直接从陷阱上下文执行，而是被发送到管道并在主线程循环中处理。
- en: Any code invoked from a trap context must be reentrant. What this means in practice
    is that a handful of Ruby constructs and methods cannot be used inside `Signal.trap`
    blocks, most notably `Mutex`.
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
  zh: 从陷阱上下文调用的任何代码必须是可重入的。实际上意味着一些Ruby结构和方法不能在`Signal.trap`块中使用，尤其是`Mutex`。
- en: 'The reason why such operations are not permitted in the trap context is simple:
    custom signal handlers defined in Ruby (i.e., `Signal.trap` called with a block)
    can get executed at mostly any point in a Ruby program. This means that even thread-safe
    code, which may be considered ‘correct’ when executed concurrently, will encounter
    deadlocks if the signal trap code accesses any synchronization resources shared
    not only by other threads, but also by the main thread itself.'
  id: totrans-split-56
  prefs: []
  type: TYPE_NORMAL
  zh: 之所以不允许在陷阱上下文中进行此类操作很简单：在Ruby中定义的自定义信号处理程序（即带有块的`Signal.trap`调用）可以在Ruby程序的任何时点执行。这意味着，即使是线程安全的代码，在并发执行时可能被认为是“正确”的，但如果信号陷阱代码访问任何不仅由其他线程共享，而且还由主线程本身共享的同步资源，将会遇到死锁。
- en: 'None of the Sidekiq signal handlers reference a mutex directly. However, almost
    all of them emit messages using `Sidekiq.logger`, which by default is a subclass
    of the plain Ruby `Logger` class. `Logger`, in turn, [uses a mutex](https://github.com/ruby/ruby/blob/a7335e11e354d1ee2e15233f32f087230069ad5c/lib/logger/log_device.rb#L33-L45)
    to synchronize writes internally:'
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
  zh: Sidekiq的任何信号处理程序都不直接引用互斥锁。然而，几乎所有信号处理程序都使用`Sidekiq.logger`发出消息，默认情况下是纯Ruby的`Logger`类的子类。`Logger`又使用互斥锁来在内部同步写入：
- en: '[PRE6]'
  id: totrans-split-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This means that it’s possible for the signal handler, which accesses the same
    logger instance, to be called while the main thread owns the mutex during logging.
  id: totrans-split-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着在主线程拥有互斥锁期间调用信号处理程序时，可能会访问相同的日志记录器实例。
- en: Keeping the signal traps short and deferring the actual logic by notifying the
    main thread through a pipe allows for lifting restrictions that are usually applied
    to signal handlers.
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
  zh: 保持信号陷阱简短，并通过通知主线程的方式推迟实际逻辑，允许解除通常应用于信号处理程序的限制。
- en: Managing the lifecycle
  id: totrans-split-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管理生命周期
- en: As covered in the previous section, the `Sidekiq::CLI` instance instantiates
    a `Sidekiq::Launcher` instance, calls `run` on it, and enters an infinite loop
    waiting for incoming signals. SIGINT and SIGTERM call `stop`, and SIGTSTP calls
    `quiet` on the launcher instance, and so far that’s the extent of our knowledge
    of the launcher. Let’s dissect it.
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如前一节所述，`Sidekiq::CLI`实例化一个`Sidekiq::Launcher`实例，调用其`run`方法，并进入一个无限循环，等待传入信号。SIGINT和SIGTERM调用启动器实例的`stop`，而SIGTSTP调用其`quiet`方法，到目前为止，这就是我们对启动器的知识的全部。让我们来剖析它。
- en: 'It’s worth to note the creation of managers during initialization of a launcher:'
  id: totrans-split-63
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，在启动器初始化期间创建管理器：
- en: '[PRE7]'
  id: totrans-split-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Here’s where the capsules come fully into the spotlight. Their configuration
    is done in the `Sidekiq::CLI` instance, and now they’re being used to instantiate
    instances of `Sidekiq::Manager`. Capsules can be thought of as compartments inside
    a Sidekiq process. They are represented as Ruby objects containing individual
    `concurrency` and `queues` configuration parameters.
  id: totrans-split-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是胶囊完全进入聚光灯下的地方。它们的配置是在`Sidekiq::CLI`实例中完成的，现在它们被用来实例化`Sidekiq::Manager`的实例。胶囊可以被看作是Sidekiq进程内的隔间。它们被表示为包含个别`concurrency`和`queues`配置参数的Ruby对象。
- en: Without custom configuration, Sidekiq uses a single ‘default’ capsule implicitly,
    and it’s possible to define custom capsules if the need arises.
  id: totrans-split-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有自定义配置，Sidekiq隐式地使用单一的“默认”胶囊，而且可以在需要时定义自定义胶囊。
- en: Before we proceed to researching the launcher lifecycle methods, let’s first
    go deeper down the stack for a moment and examine the key components relevant
    to the main processing loop.
  id: totrans-split-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续研究启动器生命周期方法之前，让我们先深入了解一下栈的更深层次，并检查与主处理循环相关的关键组件。
- en: Each capsule is manifested as a manager, serving as a container that oversees
    the lifecycle of a set of processors. The number of processors is determined by
    the `concurrency` setting. Managers provide control over their processors through
    publicly exposed methods such as `start`, `quiet`, and `stop`.
  id: totrans-split-68
  prefs: []
  type: TYPE_NORMAL
  zh: 每个胶囊都表现为一个管理器，充当监督一组处理器生命周期的容器。处理器的数量由`concurrency`设置确定。管理器通过公开的`start`、`quiet`和`stop`等方法来控制其处理器。
- en: A processor serves as the unit of execution within Sidekiq, responsible for
    performing jobs. Its public API includes methods such as `terminate`, `kill`,
    and `start`, providing control over its execution lifecycle to its manager.
  id: totrans-split-69
  prefs: []
  type: TYPE_NORMAL
  zh: 处理器作为Sidekiq内的执行单元，负责执行作业。其公共API包括`terminate`、`kill`和`start`等方法，提供对其执行生命周期的控制给其管理器。
- en: Starting up
  id: totrans-split-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 启动
- en: 'Let’s now return to the launcher. The following is its simplified [`run`](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/launcher.rb#L38-L44)
    method:'
  id: totrans-split-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们回到启动器。以下是其简化的 [`run`](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/launcher.rb#L38-L44)
    方法：
- en: '[PRE8]'
  id: totrans-split-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: It initially starts a heartbeat thread that dumps some stats into Redis every
    10 seconds.
  id: totrans-split-73
  prefs: []
  type: TYPE_NORMAL
  zh: 它最初启动一个心跳线程，每 10 秒将一些统计信息转储到 Redis 中。
- en: '`safe_thread` is essentially a helper method provided by Sidekiq, which wraps
    the passed proc in a rescue block, calling the internal exception handler via
    `Config#handle_exception`. By default, this handler simply logs the exception
    without re-raising it.'
  id: totrans-split-74
  prefs: []
  type: TYPE_NORMAL
  zh: '`safe_thread` 本质上是 Sidekiq 提供的一个辅助方法，它在传递的 proc 周围包装了一个 rescue 块，通过 `Config#handle_exception`
    调用内部异常处理程序。默认情况下，此处理程序仅记录异常而不会重新引发它。'
- en: 'Manager’s `start` method looks like this:'
  id: totrans-split-75
  prefs: []
  type: TYPE_NORMAL
  zh: 管理器的 `start` 方法如下所示：
- en: '[PRE9]'
  id: totrans-split-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`@workers` contains instances of the `Processor` class.'
  id: totrans-split-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`@workers` 包含了 `Processor` 类的实例。'
- en: 'Digging one stack frame deeper, here’s the processor’s `start` method:'
  id: totrans-split-78
  prefs: []
  type: TYPE_NORMAL
  zh: 深入到一个堆栈帧更深处，这里是处理器的 `start` 方法：
- en: '[PRE10]'
  id: totrans-split-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In a similar fashion to the launcher, a processor starts a thread that executes
    the `Processor#run` method. For now, let’s consider it as a black box and just
    assume that it starts an endless loop that picks jobs from the queue and executes
    them.
  id: totrans-split-80
  prefs: []
  type: TYPE_NORMAL
  zh: 与启动器类似，处理器启动一个执行 `Processor#run` 方法的线程。目前，让我们将其视为一个黑盒子，只假设它启动一个从队列中提取作业并执行它们的无限循环。
- en: At this point, the Sidekiq process actually starts performing enqueued jobs.
    However, this is not sufficient for stability, as shutdown is an inevitable part
    of every process lifecycle. Handling them gracefully in a job processor such as
    Sidekiq is arguably even more important than it is in web servers, and the reasons
    for this will be covered in the following sections.
  id: totrans-split-81
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，Sidekiq 进程实际开始执行排队的作业。然而，这对于稳定性来说是不够的，因为关机是每个进程生命周期中不可避免的一部分。在诸如 Sidekiq
    这样的作业处理器中优雅地处理它们可能比在 Web 服务器中更重要，这些原因将在接下来的章节中讨论。
- en: Quieting down
  id: totrans-split-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 安静下来
- en: As we have seen already, certain signals translate into calls to the launcher
    - namely `quiet` and `stop`. Let’s start with `quiet` first as it usually should
    precede `stop`.
  id: totrans-split-83
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经看到的，某些信号会转换为对启动器的调用 - 即 `quiet` 和 `stop`。我们先从 `quiet` 开始，因为它通常应该在 `stop`
    之前。
- en: 'Here’s a trimmed version of `Launcher#quiet`:'
  id: totrans-split-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 `Launcher#quiet` 的修剪版本：
- en: '[PRE11]'
  id: totrans-split-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The early return is there in order to handle a case where the process receives
    several extra SIGTSTP signals.
  id: totrans-split-86
  prefs: []
  type: TYPE_NORMAL
  zh: 早期的返回语句是为了处理进程接收到多个额外的 SIGTSTP 信号的情况。
- en: '`Manager#quiet` takes the same precaution:'
  id: totrans-split-87
  prefs: []
  type: TYPE_NORMAL
  zh: '`Manager#quiet` 采取了同样的预防措施：'
- en: '[PRE12]'
  id: totrans-split-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'And this is how processors handle `terminate`:'
  id: totrans-split-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是处理 `terminate` 的处理器方法：
- en: '[PRE13]'
  id: totrans-split-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'That’s it. Despite its name, the method doesn’t perform anything more drastic
    than setting an instance variable. This is where we pull the curtain on the `Processor#run`
    method:'
  id: totrans-split-91
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样。尽管名字如此，该方法并没有执行更多比设置实例变量更激烈的事情。这就是我们揭示 `Processor#run` 方法的地方：
- en: '[PRE14]'
  id: totrans-split-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This aligns with our previous assumption: the `run` method is executed within
    a thread spawned by the processor in its `start` method, and it enters a loop
    where the break condition is the `@done` instance variable being false.'
  id: totrans-split-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们先前的假设一致：`run` 方法在处理器的 `start` 方法中由一个线程执行，并进入一个循环，其中断开条件是 `@done` 实例变量为 false。
- en: It’s important to realize that invoking terminate does not immediately stop
    the processor from processing the current job. Instead, it will continue processing
    the current job until it completes.
  id: totrans-split-94
  prefs: []
  type: TYPE_NORMAL
  zh: 需要明白的是，调用 `terminate` 并不会立即停止处理器处理当前作业。相反，它会继续处理当前作业直到完成。
- en: So, when `terminate` is called, the `run` method will exit the loop after finishing
    the current job. At this point, a `@callback` is invoked. This callback is actually
    a `Method` instance that wraps `Manager#processor_result`, which is passed by
    the manager during the initialization of each processor.
  id: totrans-split-95
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当调用 `terminate` 时，`run` 方法将在完成当前作业后退出循环。此时，会调用一个 `@callback`。此回调实际上是一个 `Method`
    实例，它包装了 `Manager#processor_result`，在每个处理器初始化期间由管理器传递。
- en: '[PRE15]'
  id: totrans-split-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Reading through the source code of `processor_result`, it becomes clear that
    processors themselves are responsible for checking out of the `Manager`’s `@workers`
    set. Therefore, if a processor encounters a `Sidekiq::Shutdown` or any other uncaught
    exception, it will remove itself from the set, create a new processor in a similar
    manner to how it’s done in `Manager#initialize`, add that processor to the set,
    and call `start` on it.
  id: totrans-split-97
  prefs: []
  type: TYPE_NORMAL
  zh: 通过阅读 `processor_result` 的源代码，可以明确地看到处理器本身负责检出 `Manager` 的 `@workers` 集合。因此，如果处理器遇到
    `Sidekiq::Shutdown` 或任何其他未捕获的异常，它将从集合中移除自己，以与 `Manager#initialize` 中所做的方式创建新处理器相似，将该处理器添加到集合，并在其上调用
    `start`。
- en: However, in the code path we’re examining, which follows a call to `quiet`,
    the callback will only remove the processor from the workers set. Therefore, invoking
    `quiet` will cause processors to stop picking up new jobs to run, and *eventually*,
    the worker set will become empty. As we’ve already noticed, the jobs currently
    being executed by processors will not be abruptly halted; instead, they will continue
    until completion naturally.
  id: totrans-split-98
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，在我们正在检查的代码路径中，在调用 `quiet` 后，回调只会从工作集中移除处理器。因此，调用 `quiet` 将导致处理器停止接收新任务运行，并且
    *最终* 工作集将变为空。正如我们已经注意到的那样，当前由处理器执行的作业不会突然停止；相反，它们将继续自然完成。
- en: This makes the SIGTSTP signal the perfect candidate to be sent some time before
    the process is terminated. `Launcher#quiet` is a way to inform Sidekiq that processors
    should avoid picking up new jobs after they finish processing their current ones,
    as the process is about to be terminated. This minimizes the need for intrusive
    actions when a process needs to fully stop.
  id: totrans-split-99
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得 SIGTSTP 信号成为在进程终止之前一段时间发送的完美选择。`Launcher#quiet` 是通知 Sidekiq 处理器在处理完当前作业后避免接收新作业的方法，因为进程即将终止。这最大程度地减少了进程需要完全停止时的侵入性动作的需求。
- en: Stopping
  id: totrans-split-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 停止
- en: 'The `Launcher#stop` method begins with a calculation of a deadline utilizing
    POSIX `clock_gettime`. `CLOCK_MONOTONIC` is employed to acquire the current absolute
    elapsed time rather than wall clock time, which can vary unpredictably:'
  id: totrans-split-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`Launcher#stop` 方法从使用 POSIX 的 `clock_gettime` 开始计算截止时间。使用 `CLOCK_MONOTONIC`
    来获取当前的绝对经过时间，而不是墙上时间，因为墙上时间可能无法预测地变化：'
- en: '[PRE16]'
  id: totrans-split-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The default `timeout` config is set to 25 seconds and this number is not picked
    randomly; historically a lot of hosting platforms and orchestrators have been
    using a 30 second grace period for processes to react to SIGTERM gracefully. Sidekiq
    makes this timeout a bit lower in order to have better chances at finishing the
    required cleanup work.
  id: totrans-split-103
  prefs: []
  type: TYPE_NORMAL
  zh: 默认的 `timeout` 配置设置为 25 秒，这个数字并非随意选择；在历史上，许多托管平台和编排器使用 30 秒的宽限期，以使进程能够优雅地响应 SIGTERM。Sidekiq
    将这个超时时间设置得稍低，以便更有机会完成必要的清理工作。
- en: '`quiet` gets called as the first step in the `stop` method in order to minimize
    work that will have to be waited on in the next step. Another purpose of calling
    `quiet` here is to ensure that processors stop picking up new jobs in case SIGTSTP
    was not explicitly sent prior to SIGINT or SIGTERM:'
  id: totrans-split-104
  prefs: []
  type: TYPE_NORMAL
  zh: '`quiet` 作为 `stop` 方法的第一步被调用，以减少下一步需要等待的工作量。调用 `quiet` 的另一个目的是确保，如果在 SIGINT
    或 SIGTERM 之前没有明确发送 SIGTSTP，处理器停止接收新作业：'
- en: '[PRE17]'
  id: totrans-split-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: In case processors manage to finish their current work in time, they will remove
    themselves from their manager’s `@workers` array after completing their current
    job. The 2 conditionals in `stop` are there to handle the happy path by preemptively
    terminating execution without additional unnecessary work in such cases. This
    is why it’s important to make sure that `quiet` gets called first.
  id: totrans-split-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果处理器设法及时完成其当前工作，它们将在完成当前作业后从其管理器的 `@workers` 数组中移除自己。`stop` 中的两个条件语句用于处理通过预先终止执行来处理快乐路径的情况，避免不必要的额外工作。这就是为什么确保首先调用
    `quiet` 是重要的原因。
- en: 'If the manager sees that there are any processors that couldn’t finish immediately
    before the first `return if @workers.empty?` check, it must wait for them in its
    `stop` method. Remember that the deadline, set to 25 seconds by default, is passed
    down from the launcher. The `wait_for` method executes the block in a loop until
    the block’s return value is truthy:'
  id: totrans-split-107
  prefs: []
  type: TYPE_NORMAL
  zh: 如果经理发现在第一个 `return if @workers.empty?` 检查之前有任何处理器无法立即完成，它必须在其 `stop` 方法中等待它们。请记住，默认情况下截止时间为
    25 秒，由启动器传递。`wait_for` 方法会在循环中执行块，直到块的返回值为真：
- en: '[PRE18]'
  id: totrans-split-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'If there are still active processors lingering after the deadline, `hard_shutdown`
    is called. Here’s the [body of this method](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/manager.rb#L87-L119)
    with the original comments preserved:'
  id: totrans-split-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果截止时间后仍有活动处理器滞留，将调用 `hard_shutdown`。这里是这个方法的 [实现](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/manager.rb#L87-L119)，并保留了原始注释：
- en: '[PRE19]'
  id: totrans-split-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We won’t explore the functionality of `capsule.fetcher.bulk_requeue` at this
    point. This is one of the most critical pieces of logic in Sidekiq and for now,
    let’s assume that, as the method’s name implies, it requeues jobs.
  id: totrans-split-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们暂时不会探讨 `capsule.fetcher.bulk_requeue` 的功能。这是 Sidekiq 中最关键的逻辑之一，暂时假设它根据方法名称的暗示重新排列作业。
- en: 'Every processor that did not check itself out of the `@workers` array by the
    time `hard_shutdown` was invoked gets killed. Here’s what [`Processor#kill`](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/processor.rb#L49-L59)
    does:'
  id: totrans-split-112
  prefs: []
  type: TYPE_NORMAL
  zh: 每个处理器在调用 `hard_shutdown` 时未从 `@workers` 数组中检出自身，都将被终止。这里是 [`Processor#kill`](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/processor.rb#L49-L59)
    的执行内容：
- en: '[PRE20]'
  id: totrans-split-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: It’s similar to `quiet`, but it additionally raises a `Sidekiq::Shutdown`, a
    subclass of `Interrupt`, on the processor thread.
  id: totrans-split-114
  prefs: []
  type: TYPE_NORMAL
  zh: 它类似于 `quiet`，但额外在处理器线程上引发 `Sidekiq::Shutdown`，这是 `Interrupt` 的子类。
- en: This exception being raised, however, does not impose an upper time bound on
    when the thread will be truly finished. That’s why right after every process has
    been killed, the manager waits 3 seconds to give them an opportunity to terminate
    gracefully. We’ll get to what this graceful termination consists of later.
  id: totrans-split-115
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，引发此异常并不意味着线程将在上限时间内真正完成。因此，每个进程被杀死后，管理器会等待 3 秒钟，以便它们有机会优雅地终止。稍后我们将详细讨论这种优雅的终止方式。
- en: We’ve explored how Sidekiq establishes the necessary class hierarchy to ensure
    the smooth handling of the process lifecycle. The launcher oversees managers,
    which in turn manage processors responsible for fetching and processing jobs.
    Let’s now look at how the processors obtain jobs to execute.
  id: totrans-split-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经探讨了 Sidekiq 如何建立必要的类层次结构，以确保处理过程的顺利进行。启动器监督管理器，管理器又管理处理作业的处理器。现在让我们来看看处理器如何获取要执行的作业。
- en: Queue processing
  id: totrans-split-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 队列处理
- en: Sidekiq jobs get routed to queues. At the very least each Sidekiq installation
    will use a `default` queue. The queues that Sidekiq should be processing can be
    defined globally or on a per-capsule basis. You can specify the set of queues
    using the `config/sidekiq.yml` configuration file, the `-q` command-line argument,
    or `Sidekiq.configure_server`. This configuration populates the `queues` parameter
    of the `default` capsule, unless specific configuration was provided for a particular
    capsule in the config file or server configuration.
  id: totrans-split-118
  prefs: []
  type: TYPE_NORMAL
  zh: Sidekiq 作业会路由到队列。至少每个 Sidekiq 安装将使用 `default` 队列。应该处理的 Sidekiq 队列可以在全局范围或每个
    capsule 基础上定义。您可以使用 `config/sidekiq.yml` 配置文件、`-q` 命令行参数或 `Sidekiq.configure_server`
    指定队列集。此配置会填充 `default` capsule 的 `queues` 参数，除非在配置文件或服务器配置中为特定 capsule 提供了特定配置。
- en: 'Eventually, all provided queue lists end up in the `Capsule#queues=` setter
    method, which is crucial for the queue processing logic. Here’s [its contents](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/capsule.rb#L48-L70)
    copied verbatim with the original comment:'
  id: totrans-split-119
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，所有提供的队列列表都会传递到 `Capsule#queues=` 设置器方法中，这对于队列处理逻辑至关重要。这里是 [其内容](https://github.com/sidekiq/sidekiq/blob/4ec059d53dbf1de67e41e3bd1687c7d90c12d580/lib/sidekiq/capsule.rb#L48-L70)
    的逐字复制，保留了原始注释：
- en: '[PRE21]'
  id: totrans-split-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: There are three options for how queues are polled. If none of the queues have
    a weight defined (using the `default,10` notation), the mode is set to `strict`.
    If all of the queues have their weights set to 1 explicitly, the mode is set to
    `random`. In any other case, the mode is set to `weighted`.
  id: totrans-split-121
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种队列轮询方式可选。如果没有队列定义权重（使用 `default,10` 标记），模式将设置为 `strict`。如果所有队列都明确设置了权重为 1，模式将设置为
    `random`。在任何其他情况下，模式将设置为 `weighted`。
- en: One peculiar thing to note is that the `@queues` array will contain `m` copies
    of each queue, where `m` is their weight. For example, if the queues are configured
    in a weighted manner with `default,10 queue_one,5 queue_two,3`, `@queues` will
    consist of 10 `:default` elements, 5 `:queue_one` elements, and 3 `:queue_two`
    elements.
  id: totrans-split-122
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的一点是，`@queues`数组将包含每个队列的`m`个副本，其中`m`是它们的权重。例如，如果队列按照`default,10 queue_one,5
    queue_two,3`的权重配置，`@queues`将由10个`:default`元素，5个`:queue_one`元素和3个`:queue_two`元素组成。
- en: 'Let’s come back over to `Processor#run`. As we have already seen, this method
    makes the processor enter a loop that calls `Processor#process_one` until `terminate`
    or `kill` is called:'
  id: totrans-split-123
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到`Processor#run`。正如我们已经看到的，此方法使处理器进入一个循环，直到调用`terminate`或`kill`为止调用`Processor#process_one`：
- en: '[PRE22]'
  id: totrans-split-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The conditional branch is there in case Sidekiq recovers from a backoff initiated
    by `handle_fetch_exception` in the rescue block. That method simply `sleep`s for
    1 second if there’s a transient connectivity issue when contacting Redis.
  id: totrans-split-125
  prefs: []
  type: TYPE_NORMAL
  zh: 条件分支是为了防止Sidekiq在`handle_fetch_exception`触发的回退后恢复。如果与Redis联系时存在瞬态连接问题，则该方法简单地`sleep`
    1秒。
- en: '`Sidekiq::Shutdown` is muted here to reduce noise created by the error handler
    invoked from `handle_fetch_exception`. Processing of new jobs stops regardless
    since `@done` ivar is set to `false` at this point.'
  id: totrans-split-126
  prefs: []
  type: TYPE_NORMAL
  zh: '`Sidekiq::Shutdown`在此处被静音以减少由从`handle_fetch_exception`调用的错误处理程序引起的噪音。由于此时`@done`实例变量被设置为`false`，新作业的处理停止。'
- en: 'The `fetcher` method in the `Capsule` class extracts the fetcher object. Here’s
    its implementation:'
  id: totrans-split-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`Capsule`类中的`fetcher`方法提取获取器对象。以下是其实现：'
- en: '[PRE23]'
  id: totrans-split-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The OS version of Sidekiq comes with a single fetcher option, `BasicFetch`.
  id: totrans-split-129
  prefs: []
  type: TYPE_NORMAL
  zh: Sidekiq的操作系统版本带有单个获取器选项`BasicFetch`。
- en: The Pro version includes [`SuperFetch`](https://github.com/sidekiq/sidekiq/wiki/Reliability#using-super_fetch),
    which offers a more robust durability guarantee for Sidekiq jobs. However, the
    specifics of this fetcher are not covered in this article.
  id: totrans-split-130
  prefs: []
  type: TYPE_NORMAL
  zh: Pro版本包括[`SuperFetch`](https://github.com/sidekiq/sidekiq/wiki/Reliability#using-super_fetch)，为Sidekiq作业提供了更强大的耐久性保证。但是，本文未涉及此获取器的具体信息。
- en: 'Let’s examine the internals of `BasicFetch`. Here are the relevant methods,
    with original comments preserved:'
  id: totrans-split-131
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看`BasicFetch`的内部。以下是相关方法，保留了原始注释：
- en: '[PRE24]'
  id: totrans-split-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'True to its name, the logic in this class is straightforward: construct an
    array of queues (keep in mind that queue weights result in duplicate entries in
    the `@queues` array), shuffle it if there’s no strict ordering, and then pass
    it to Redis’ `BRPOP` command.'
  id: totrans-split-133
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名，这个类中的逻辑很简单：构造一个队列数组（请记住，队列权重会导致`@queues`数组中出现重复条目），如果没有严格的顺序，则对其进行洗牌，然后将其传递给Redis的`BRPOP`命令。
- en: It might seem counterintuitive to call `#uniq!` on the resulting array when
    there are weighted queues, but it’s not. The more identical entries there are
    in the array, the higher the chance that one of these entries will appear at the
    head of the array. `uniq!` preserves the ordering of elements.
  id: totrans-split-134
  prefs: []
  type: TYPE_NORMAL
  zh: 当存在加权队列时，在结果数组上调用`#uniq!`可能看起来违反直觉，但事实并非如此。数组中存在的相同条目越多，其中一个条目出现在数组头部的几率就越高。`uniq!`保留了元素的顺序。
- en: '[`BRPOP`](https://redis.io/commands/brpop/) takes multiple [list](https://redis.io/docs/data-types/lists/)
    names as arguments and pops the tail element of the first non-empty list in a
    blocking manner. This means that the first queue in the `@queues` array gets priority.
    An important detail here is the timeout. As the comment above the `TIMEOUT` constant
    suggests, Sidekiq wants these operations to time out regularly so that a process
    can check if `terminate` or `kill` was called in the meantime.'
  id: totrans-split-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[`BRPOP`](https://redis.io/commands/brpop/)接受多个[list](https://redis.io/docs/data-types/lists/)名称作为参数，并以阻塞方式弹出第一个非空列表的尾元素。这意味着`@queues`数组中的第一个队列具有优先级。这里一个重要的细节是超时。正如`TIMEOUT`常量上面的注释所述，Sidekiq希望这些操作定期超时，以便进程可以检查是否在此期间调用了`terminate`或`kill`。'
- en: If the command successfully fetches a job from the list, the return values are
    wrapped in a `UnitOfWork` DTO.
  id: totrans-split-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果命令成功从列表中获取作业，则返回值将封装在`UnitOfWork` DTO中。
- en: 'The critical aspect of `BasicFetch` is that `BRPOP` removes the job from the
    list. Despite Sidekiq’s efforts to be as resilient as possible and cover most
    failure scenarios, this has a significant implication: jobs can be lost. We’ll
    explore some of the scenarios where this might occur and how Sidekiq attempts
    to mitigate them in a later section.'
  id: totrans-split-137
  prefs: []
  type: TYPE_NORMAL
  zh: '`BasicFetch` 的关键在于 `BRPOP` 从列表中移除作业。尽管 Sidekiq 尽力使自身尽可能弹性，并覆盖大多数失败场景，但这带来一个重要影响：作业可能会丢失。稍后我们将探讨可能发生这种情况的一些场景，以及
    Sidekiq 如何在后续章节中试图减少这些影响。'
- en: As you have probably noticed, the `acknowledge` method is empty for a `BasicFetch`
    `UnitOfWork`. While I haven’t had the opportunity to explore the Pro or Enterprise
    licensed versions of Sidekiq myself, it’s reasonable to assume that this method
    is relevant for the `SuperFetch` fetcher. `SuperFetch` preserves the job in Redis
    in some form instead of removing it immediately after fetching, which contributes
    to its enhanced reliability, but makes it necessary to somehow mark the jobs as
    being successfully processed. `SuperFetch`’s `acknowledge` most likely does exactly
    that. We will encounter situations where the `acknowledge` method becomes relevant
    as we dive deeper.
  id: totrans-split-138
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能已经注意到的，对于 `BasicFetch` 的 `UnitOfWork`，`acknowledge` 方法是空的。虽然我自己还没有探索过 Sidekiq
    的 Pro 或 Enterprise 版本，但合理地假设该方法对于 `SuperFetch` 提取器是相关的。`SuperFetch` 在从 Redis 获取后不立即移除作业，而是以某种形式保留它，这提高了可靠性，但也使得必须以某种方式标记作业已成功处理。`SuperFetch`
    的 `acknowledge` 很可能正是用于此目的。随着我们深入探讨，`acknowledge` 方法将会变得更加重要。
- en: Back in `Processor#process_one`, if the fetch was successful, `Processor#process`
    is invoked. Since this method is lengthy, we’ll examine modified smaller segments
    at a time.
  id: totrans-split-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `Processor#process_one` 中，如果获取成功，则调用 `Processor#process`。由于这个方法很长，我们将分段检查修改后的较小段落。
- en: '[PRE25]'
  id: totrans-split-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The job fetched from Redis is a JSON payload represented as a string, so it
    needs to be parsed first. Here, we encounter the concept of the morgue and dead
    jobs. Trying to process a malformed job won’t yield positive results no matter
    how many times it is retried, so marking the job as ‘dead’ is a practical approach.
  id: totrans-split-141
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Redis 获取的作业是表示为字符串的 JSON 负载，因此需要首先解析它。在这里，我们遇到了尸房和无效作业的概念。试图处理格式错误的作业无论重试多少次都不会产生积极的结果，因此将作业标记为‘无效’是一个实际的方法。
- en: This is achieved by the [`ZADD`](https://redis.io/commands/zadd/) command, which
    adds a member to a [sorted set](https://redis.io/docs/data-types/sorted-sets/),
    where sorting key is the time at which the job was pronounced dead.
  id: totrans-split-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这通过 [`ZADD`](https://redis.io/commands/zadd/) 命令实现，该命令将成员添加到 [排序集合](https://redis.io/docs/data-types/sorted-sets/)
    中，其中排序键是作业被宣告为无效的时间。
- en: The next 2 commands are there to remove dead jobs that surpassed the allowed
    time in the morgue, which is 6 months by default, and preserve only the latest
    10000 jobs in the set. All of this is done in a Redis transaction using the [`MULTI`](https://redis.io/commands/multi/)
    command.
  id: totrans-split-143
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的两个命令用于删除在尸房中超过默认允许时间的无效作业，即 6 个月，并仅保留集合中最新的 10000 个作业。所有这些操作都在 Redis 事务中使用
    [`MULTI`](https://redis.io/commands/multi/) 命令完成。
- en: 'After the job payload gets parsed successfully, it needs to be executed. The
    rest of the `#process` method does exactly that (comments are preserved):'
  id: totrans-split-144
  prefs: []
  type: TYPE_NORMAL
  zh: 作业负载成功解析后，需要执行它。`#process` 方法的其余部分正是如此（保留了注释）：
- en: '[PRE26]'
  id: totrans-split-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: First thing that stands out is the use of `Thread.handle_interrupt`. In short,
    it allows to alter the handling of internal Ruby asynchronous events such as `Thread#raise`
    and `Thread#kill` - the former is exactly what is being used by `Processor#kill`
    as we have already seen.
  id: totrans-split-146
  prefs: []
  type: TYPE_NORMAL
  zh: 首先显眼的是 `Thread.handle_interrupt` 的使用。简而言之，它允许修改内部 Ruby 异步事件的处理方式，例如 `Thread#raise`
    和 `Thread#kill` - 前者正是 `Processor#kill` 已经使用的方法。
- en: In this particular case, first `handle_interrupt` is called with `Sidekiq::Shutdown
    => :never` and wraps the `ensure` block that calls `#acknowledge` on the unit
    of work. The second call is nested directly after the first one, and it resets
    the behaviour back to `:immediate`.
  id: totrans-split-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种特定情况下，首先使用 `Sidekiq::Shutdown => :never` 调用 `handle_interrupt`，并包装调用工作单元上的
    `#acknowledge` 的 `ensure` 块。第二个调用直接嵌套在第一个之后，并将行为重置回 `:immediate`。
- en: 'This achieves the following: if a processor is killed (using `Thread#raise(Sidekiq::Shutdown)`)
    when the ensure block is being evaluated, the raised exception will be ignored
    and the work will be acknowledged. Without setting the behaviour to `:never`,
    an acknowledgment would be missed in such case. The inner block resets it back
    to `:immediate` immediately afterward because this is the desired behavior - `Sidekiq::Shutdown`
    should interrupt the execution of the job’s code.'
  id: totrans-split-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这样做的好处是：如果处理器被终止（使用 `Thread#raise(Sidekiq::Shutdown)`），而 ensure 块正在评估时，抛出的异常将被忽略，并且工作将被确认。如果行为未设置为
    `:never`，在这种情况下将错过确认。内部块立即将其重置为 `:immediate`，因为这是期望的行为 - `Sidekiq::Shutdown` 应该中断作业代码的执行。
- en: This is not that relevant in the OS version since `BasicFetch`’s `UnitOfWork#acknowledge`
    is a no op, but it’s important for `SuperFetch`, since its version of `acknowledge`
    most likely removes the job from Redis in order to mark it as processed.
  id: totrans-split-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这在 OS 版本中并不那么重要，因为 `BasicFetch` 的 `UnitOfWork#acknowledge` 是一个无操作，但对于 `SuperFetch`
    来说，它的 `acknowledge` 版本很可能会从 Redis 中移除作业，以标记其已处理。
- en: The rescue blocks are self-explanatory thanks to the comments. One noteworthy
    aspect is that `Sidekiq::JobRetry::Handled` exceptions, which are raised when
    a retry is successfully created, get re-raised and propagated all the way up to
    `Processor#run`. This, in turn, triggers the callback supplied by the `Manager`,
    which deletes the processor and creates a new one. As a result, job retries will
    force the processor to be recreated, spawning a new Ruby thread in place of the
    original.
  id: totrans-split-150
  prefs: []
  type: TYPE_NORMAL
  zh: 救援块由注释自解释。一个值得注意的方面是，当成功创建重试时，`Sidekiq::JobRetry::Handled` 异常被重新抛出并传播到 `Processor#run`。这反过来触发了
    `Manager` 提供的回调，该回调删除处理器并创建新的处理器。因此，作业重试将强制重新创建处理器，以新的 Ruby 线程替代原始线程。
- en: 'Let’s unwrap the `Processor#dispatch` and `Processor#execute_job` methods:'
  id: totrans-split-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们分解 `Processor#dispatch` 和 `Processor#execute_job` 方法：
- en: '[PRE27]'
  id: totrans-split-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The `@job_logger` variable is an instance of `Sidekiq::JobLogger`. Its `prepare`
    method is responsible for putting job metadata into thread-local context, ensuring
    that logs emitted further down the stack contain useful correlation information.
  id: totrans-split-153
  prefs: []
  type: TYPE_NORMAL
  zh: '`@job_logger` 变量是 `Sidekiq::JobLogger` 的一个实例。它的 `prepare` 方法负责将作业元数据放入线程局部上下文中，确保在堆栈更深处发出的日志包含有用的相关信息。'
- en: Another crucial step in this pipeline is the `@reloader.call` invocation. This
    is where Sidekiq integrates with the Rails framework. A [reloader](https://guides.rubyonrails.org/threading_and_code_execution.html#reloader),
    as the name suggests, is responsible for code reloading. This is relevant because
    jobs typically reside in the `app/` directory of a Rails application, which should
    be reloadable. Additionally, the reloader handles [ActiveRecord connection cleanup](https://github.com/rails/rails/blob/a255742b2eb711baa8fd7a8937852851ddc8a679/activerecord/lib/active_record/railtie.rb#L326-L331)
    and other related concerns.
  id: totrans-split-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这个管道中的另一个关键步骤是 `@reloader.call` 的调用。这是 Sidekiq 与 Rails 框架集成的地方。如其名称所示，[reloader](https://guides.rubyonrails.org/threading_and_code_execution.html#reloader)
    负责代码重载。这很重要，因为作业通常驻留在 Rails 应用程序的 `app/` 目录中，应该可以重新加载。此外，reloader 处理 [ActiveRecord
    连接清理](https://github.com/rails/rails/blob/a255742b2eb711baa8fd7a8937852851ddc8a679/activerecord/lib/active_record/railtie.rb#L326-L331)
    和其他相关问题。
- en: Sidekiq extracts the job class via `Object.const_get(job_hash["class"])` and
    calls `#perform` on it after invoking the server middleware chain. Sidekiq’s middlewares
    are similar to those of Rack - arbitrary classes that respond to `#call` and yield
    if the chain should not be halted. This is the public API for integrations that
    want to augment or alter Sidekiq’s processing logic, which is exactly what monitoring
    libraries like [Sentry](https://github.com/getsentry/sentry-ruby/blob/master/sentry-sidekiq/lib/sentry/sidekiq/sentry_context_middleware.rb),
    [Datadog](https://github.com/DataDog/dd-trace-rb/blob/e4498741b7e85b7f886a8feb72ec62e64f86ad25/lib/datadog/tracing/contrib/sidekiq/server_tracer.rb)
    and others do.
  id: totrans-split-155
  prefs: []
  type: TYPE_NORMAL
  zh: Sidekiq 通过 `Object.const_get(job_hash["class"])` 提取作业类，并在调用服务器中间件链之后调用其 `#perform`
    方法。Sidekiq 的中间件类似于 Rack 的中间件 - 是响应 `#call` 并在链不应停止时执行的任意类。这是希望增强或改变 Sidekiq 处理逻辑的集成的公共
    API，这正是像 [Sentry](https://github.com/getsentry/sentry-ruby/blob/master/sentry-sidekiq/lib/sentry/sidekiq/sentry_context_middleware.rb)、[Datadog](https://github.com/DataDog/dd-trace-rb/blob/e4498741b7e85b7f886a8feb72ec62e64f86ad25/lib/datadog/tracing/contrib/sidekiq/server_tracer.rb)
    等监控库所做的。
- en: Handling exceptions
  id: totrans-split-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 处理异常
- en: Naturally, application code called from within jobs can raise exceptions. Sidekiq
    provides several ways to handle them, with the default behavior being to retry
    failed jobs up to 25 times with an exponential backoff.
  id: totrans-split-157
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，作业内调用的应用程序代码可能会引发异常。Sidekiq提供了几种处理它们的方式，默认行为是使用指数退避重试失败的作业最多25次。
- en: 'Let’s examine the `#local` method of `Processor`’s `@retrier` ivar, an instance
    of `Sidekiq::JobRetry` which wraps the `#perform` method of every job class:'
  id: totrans-split-158
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看`Processor`的`@retrier`实例变量的`#local`方法，它是`Sidekiq::JobRetry`的实例，包装了每个作业类的`#perform`方法：
- en: '[PRE28]'
  id: totrans-split-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: This method is called “local” since it can be directly correlated to a particular
    instantiated job instance. We will see why it’s relevant once we get to `#process_retry`.
  id: totrans-split-160
  prefs: []
  type: TYPE_NORMAL
  zh: 由于此方法可以直接与特定实例化的作业实例相关联，因此称为“local”。一旦我们到达`#process_retry`，我们将看到它为何相关。
- en: '`Sidekiq::Shutdown` is re-raised because it should bypass the retry system,
    and `Handled` is being re-raised as well in case a developer decides to manually
    raise it from within a job.'
  id: totrans-split-161
  prefs: []
  type: TYPE_NORMAL
  zh: '`Sidekiq::Shutdown`被重新引发，因为它应该绕过重试系统，`Handled`也被重新引发，以防开发人员决定从作业内部手动引发它。'
- en: Rescuing `Exception` (i.e. all exceptions) is the interesting part.
  id: totrans-split-162
  prefs: []
  type: TYPE_NORMAL
  zh: 救援`Exception`（即所有异常）是有趣的部分。
- en: First of all, Sidekiq detects if an exception was raised due to the thread receiving
    a `Sidekiq::Shutdown` from `Processor#kill`. With this detection, only errors
    that are caused by a bug or some other transient error within the application
    code will trigger a retry. This prevents monitoring tools from being polluted
    unnecessarily and does not force well-behaving jobs into a retry set. We’ll skip
    the internals of `#exception_caused_by_shutdown?` for brevity, only mentioning
    that its secret sauce is Ruby’s [`exception#cause`](https://rubyapi.org/3.3/o/exception#method-i-cause)
    method.
  id: totrans-split-163
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，Sidekiq会检测是否由于线程从`Processor#kill`接收到`Sidekiq::Shutdown`而引发异常。通过此检测，只有由应用程序代码内的错误或其他瞬态错误引起的错误才会触发重试。这可以避免不必要地污染监控工具，并且不会强制良好行为的作业进入重试集。出于简洁起见，我们将跳过`#exception_caused_by_shutdown?`的内部实现，只提到其秘密酱汁是Ruby的[`exception#cause`](https://rubyapi.org/3.3/o/exception#method-i-cause)方法。
- en: Next, Sidekiq checks if the job was explicitly configured without retries -
    it simply re-raises the exception if that’s the case. By default, every Sidekiq
    job is retried up to 25 times.
  id: totrans-split-164
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，Sidekiq检查是否明确配置了不重试作业 - 如果是这样，它将简单地重新引发异常。默认情况下，每个Sidekiq作业最多重试25次。
- en: 'Before we proceed to `#process_retry`, we need to look at the final line: `raise
    Skip`. Instead of re-raising the original exception, Sidekiq raises a subclass
    of `JobRetry::Handled`. We’ll see how it relates to the `#global` method once
    we get to it.'
  id: totrans-split-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续执行`#process_retry`之前，我们需要看最后一行：`raise Skip`。Sidekiq不会重新引发原始异常，而是引发`JobRetry::Handled`的子类。一旦我们到达`#global`方法，我们将看到它与之相关。
- en: 'The original `#process_retry` method handles metadata management and formatting;
    the following snippet is a trimmed-down version of it:'
  id: totrans-split-166
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的`#process_retry`方法处理元数据管理和格式化；以下代码片段是其精简版本：
- en: '[PRE29]'
  id: totrans-split-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: First, note that Sidekiq provides an ability to reroute the job into a different
    queue if it fails; this is what the second line of code is responsible for.
  id: totrans-split-168
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，请注意Sidekiq提供了一个能力，即在作业失败时将其重新路由到不同的队列；这就是代码的第二行负责的内容。
- en: Immediately after, `#retries_exhausted` is called if the job exceeds its maximum
    retry count, or if the time frame during which it should be retried has passed.
  id: totrans-split-169
  prefs: []
  type: TYPE_NORMAL
  zh: 立即之后，如果作业超过其最大重试次数或应该重试的时间段已过去，将调用`#retries_exhausted`。
- en: If Sidekiq should attempt to retry the job, it calls `#delay_for`. This method
    returns a strategy and a delay in seconds. We’ll see where the strategy value
    comes from, but for now, understand that a job can be either `discard`ed or `kill`ed,
    with the former causing Sidekiq to completely forget about the job instead of
    retrying it.
  id: totrans-split-170
  prefs: []
  type: TYPE_NORMAL
  zh: 如果Sidekiq应尝试重试作业，则调用`#delay_for`。此方法返回一个策略和延迟（以秒为单位）。我们将看到策略值来自何处，但现在理解作业可以是`discard`或`kill`，前者导致Sidekiq完全忘记作业而不是重试。
- en: In case the job should actually be retried, the timestamp at which it should
    happen is calculated based on the obtained delay. Jitter is applied to this value
    to avoid the thundering herd problem, where a bunch of jobs are scheduled for
    a retry at the same second.
  id: totrans-split-171
  prefs: []
  type: TYPE_NORMAL
  zh: 如果确实应该重试作业，则根据获得的延迟计算应该发生重试的时间戳。对此值应用抖动以避免雷鸣般的大群作业在同一秒钟安排重试的问题。
- en: Finally, the job is added to a `retry` sorted set using `ZADD`, following a
    simillar process to dead jobs.
  id: totrans-split-172
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用`ZADD`将作业添加到`retry`排序集中，遵循与死作业类似的过程。
- en: '[PRE30]'
  id: totrans-split-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '`#delay_for` sources the `strategy` from an optional `sidekiq_retry_in_block`
    block defined on the job class by a developer. It can either return a symbol representing
    the strategy or an integer value representing the number of seconds for a delay.'
  id: totrans-split-174
  prefs: []
  type: TYPE_NORMAL
  zh: '`#delay_for`从开发人员在作业类上定义的可选`sidekiq_retry_in_block`块中获取`strategy`。它可以返回表示策略的符号，或表示延迟秒数的整数值。'
- en: If the delay value was not provided by a developer, it gets calculated with
    an exponential backoff formula, where `count` is the number of retries already
    conducted. With the default max retry count being 25, this means that a job (without
    a custom `sidekiq_retry_in_block` defined) will be retried 25 times over approximately
    20 days.
  id: totrans-split-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如果延迟值不是由开发人员提供的，则使用指数补偿公式计算，其中`count`是已经执行的重试次数。默认的最大重试次数为25次，这意味着一个作业（没有定义自定义`sidekiq_retry_in_block`）将在大约20天内重试25次。
- en: 'Here’s what happens in the `#retries_exhausted` method:'
  id: totrans-split-176
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是`#retries_exhausted`方法中发生的事情：
- en: '[PRE31]'
  id: totrans-split-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Another optional user-supplied job-level configuration being used here is `sidekiq_retries_exhausted_block`,
    which allows discarding a job once its retries are exhausted. If it’s not provided,
    a job gets sent to the morgue in the exact same fashion as in `Processor#process`
    when a job payload is malformed.
  id: totrans-split-178
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个在此处使用的可选用户提供的作业级配置是`sidekiq_retries_exhausted_block`，它允许在其重试耗尽时丢弃作业。如果未提供，作业将以与`Processor#process`中作业有效载荷格式错误时相同的方式被送入太平间。
- en: 'The last relevant method in the retrier is `#global`. It’s worth remembering
    that it wraps a call to `#local`, `Processor#reloader`, invocation of middlewares,
    and pretty much every other step in the `Processor#process` pipeline. It’s needed
    to catch any exceptions raised when processing a job, including those that are
    not raised from within application code, on a best-effort basis. Its only difference
    from `#local` is that it discards the job if it doesn’t have a `retry` attribute
    set, or if this attribute is set to `false` on the job class:'
  id: totrans-split-179
  prefs: []
  type: TYPE_NORMAL
  zh: 重试器中的最后一个相关方法是`#global`。值得记住的是，它包装了对`#local`、`Processor#reloader`、中间件调用以及`Processor#process`管道中的几乎每一步的调用。它需要捕获在处理作业时引发的任何异常，包括那些不是从应用程序代码中引发的异常，尽力而为。它与`#local`的唯一区别在于，如果作业没有设置`retry`属性，或者该属性在作业类上设置为`false`，它会丢弃该作业：
- en: '[PRE32]'
  id: totrans-split-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: You might notice that similarly to `#local`, this method also rescues `JobRetry::Handled`
    and does not retry in such cases, since these exceptions are already handled in
    the `#local` rescue block that raises a `JobRetry::Skip` - a subclass of `Handled`.
    This avoids duplicate retry processing.
  id: totrans-split-181
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会注意到，与`#local`类似，这种方法也会拯救`JobRetry::Handled`，并且在这种情况下不会重试，因为这些异常已经在引发`#local`救援块的过程中得到处理，而引发了`JobRetry::Skip`
    - 一个`Handled`的子类。这避免了重复的重试处理。
- en: We have now explored the primary process of how Sidekiq handles job processing
    on the server. However, what about jobs that need to be retried? Also, doesn’t
    Sidekiq offer a mechanism for delaying the execution of jobs until a specified
    time in the future? We will learn how Sidekiq handles these in the section following
    the next one.
  id: totrans-split-182
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经探讨了Sidekiq在服务器上处理作业的主要过程。但是，那些需要重试的作业呢？此外，Sidekiq是否提供了一种机制来延迟执行作业直到将来的某个指定时间？我们将在下一部分中学习Sidekiq如何处理这些情况。
- en: Enqueueing jobs
  id: totrans-split-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 排队作业
- en: 'So far, we’ve looked at the internals of Sidekiq server: `Launcher`, `Manager`,
    and `Processor` constructs, which operate within a background process responsible
    for job processing. Now, let’s explore how jobs make their way into the queues,
    which leads us to `Sidekiq::Client`.'
  id: totrans-split-184
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了Sidekiq服务器的内部工作：`Launcher`、`Manager`和`Processor`结构，它们在负责作业处理的后台进程中运行。现在，让我们探索作业如何进入队列，这将引导我们进入`Sidekiq::Client`。
- en: 'Although most Sidekiq users typically don’t interact directly with `Sidekiq::Client`,
    preferring higher-level abstractions like the [Job API](https://github.com/sidekiq/sidekiq/blob/c1607198815d68f60d138010907dd3426d6521bb/lib/sidekiq/job.rb),
    all the convenience methods provided by this module rely on fundamental building
    blocks: `Client#push` and `Client#push_bulk`, which accept different combinations
    of arguments.'
  id: totrans-split-185
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大多数Sidekiq用户通常不直接与`Sidekiq::Client`交互，而更喜欢像[作业API](https://github.com/sidekiq/sidekiq/blob/c1607198815d68f60d138010907dd3426d6521bb/lib/sidekiq/job.rb)这样的高级抽象，但是该模块提供的所有便利方法都依赖于基本构建块：`Client#push`和`Client#push_bulk`，它们接受不同的参数组合。
- en: 'Let’s see what `Client#push` does:'
  id: totrans-split-186
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看`Client#push`做了什么：
- en: '[PRE33]'
  id: totrans-split-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '`normalize_item` performs several operations on the payload, including argument
    validation and generation of a unique job identifier.'
  id: totrans-split-188
  prefs: []
  type: TYPE_NORMAL
  zh: '`normalize_item` 对有效负载执行多个操作，包括参数验证和生成唯一作业标识符。'
- en: Subsequently, the payload undergoes processing through the client middleware
    chain, mirroring the way `Processor` sends job payloads through server middlewares.
    This enables external integrations to enhance the job payload with extra attributes
    and implement custom logic around job dispatches.
  id: totrans-split-189
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，有效负载通过客户端中间件链进行处理，反映了 `Processor` 将作业有效负载通过服务器中间件发送的方式。这使得外部集成可以通过额外属性增强作业有效负载，并在作业分派周围实现自定义逻辑。
- en: '`verify_json` might not need additional explanation as it does exactly what
    its name suggests, but it’s how it does it that makes it worthwhile to look into:'
  id: totrans-split-190
  prefs: []
  type: TYPE_NORMAL
  zh: '`verify_json` 可能不需要额外的解释，因为它确实做了其名称所示的事情，但它是如何做到的使得它值得深入研究：'
- en: '[PRE34]'
  id: totrans-split-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Boiled down, the `verify_json` method validates job arguments expected by the
    `#perform` method to ensure they adhere to valid JSON format. In versions predating
    Sidekiq 7.0, the `json_unsafe?` method employed a straightforward check by verifying
    if the arguments remained unchanged after being dumped and parsed as JSON: `JSON.parse(JSON.dump(item["args"]))
    == item["args"]`. However, this approach, involving the dumping and parsing of
    potentially large arguments for each job, clearly warranted performance enhancements.'
  id: totrans-split-192
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，`verify_json` 方法验证由 `#perform` 方法期望的作业参数，以确保它们符合有效的 JSON 格式。在 Sidekiq 7.0
    之前的版本中，`json_unsafe?` 方法通过验证作业在转储和解析为 JSON 后是否保持不变来进行简单检查：`JSON.parse(JSON.dump(item["args"]))
    == item["args"]`。然而，这种方法涉及对每个作业的可能大参数进行转储和解析，显然需要性能优化。
- en: To address this, the `RECURSIVE_JSON_UNSAFE` constant was introduced. Additional
    improvement lies in `RECURSIVE_JSON_UNSAFE.compare_by_identity`, which makes the
    hash resolve key objects based on their `object_id` instead of calling [`hash`](https://rubyapi.org/3.3/o/object#method-i-hash),
    resulting in a faster process. Extracting a static `object_id` that remains unchanged
    during an object’s lifetime, albeit recursively, is much faster than going through
    2 iterations of JSON processing.
  id: totrans-split-193
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，引入了 `RECURSIVE_JSON_UNSAFE` 常量。额外的改进在于 `RECURSIVE_JSON_UNSAFE.compare_by_identity`，它使得哈希基于它们的
    `object_id` 来解析键对象，而不是调用 [`hash`](https://rubyapi.org/3.3/o/object#method-i-hash)，从而加快了处理速度。提取一个在对象生命周期内保持不变的静态
    `object_id`，尽管是递归的，比经历两次 JSON 处理要快得多。
- en: In this new version, every Ruby class known to be ‘JSON-safe’ returns a proc
    that returns `nil` when executed. Arrays and hashes receive special treatment
    since they contain other objects, making this hash recursive. If a job payload
    contains an object of any other class not declared as a key in the hash, the arguments
    are deemed unsafe, and an appropriate action will be taken, with the default being
    to raise an error.
  id: totrans-split-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个新版本中，已知为“JSON-safe”的每个 Ruby 类返回一个执行时返回 `nil` 的过程。数组和哈希表接受特殊处理，因为它们包含其他对象，使得这个哈希表递归。如果作业有效负载包含未在哈希表中声明为键的任何其他类的对象，则认为参数不安全，并将采取适当的操作，其默认行为是引发错误。
- en: '`raw_push` is the place where job gets put into Redis:'
  id: totrans-split-195
  prefs: []
  type: TYPE_NORMAL
  zh: '`raw_push` 是作业放入 Redis 的地方：'
- en: '[PRE35]'
  id: totrans-split-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This method accepts an array of payloads to support `#push_bulk`. `#push` passes
    a single array element as an argument.
  id: totrans-split-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法接受一个有效负载数组来支持 `#push_bulk`。`#push` 以单个数组元素作为参数。
- en: The rescue is included to handle Redis failovers that necessitate reopening
    the connection socket, attempting one transparent retry.
  id: totrans-split-198
  prefs: []
  type: TYPE_NORMAL
  zh: 救援措施被包含在内，以处理需要重新打开连接套接字的 Redis 故障转移，尝试进行一次透明重试。
- en: Subsequently, the Redis commands called by `atomic_push` are [pipelined](https://redis.io/docs/manual/pipelining/),
    reducing the round-trip time (RTT). Note that when jobs are pushed in a batch,
    all of them are submitted using a single `LPUSH` command, so pipelining here is
    not as critical as it could have been.
  id: totrans-split-199
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，`atomic_push` 调用的 Redis 命令是通过 [pipelining](https://redis.io/docs/manual/pipelining/)
    进行的，减少了往返时间（RTT）。需要注意的是，当作业批量推送时，所有作业都使用单个 `LPUSH` 命令提交，因此此处的流水线处理并不像可能的那样关键。
- en: '`atomic_push` has 2 branches. The second branch is for immediate dispatches
    of jobs that will be processed as soon as possible. The [`SADD`](https://redis.io/commands/sadd/)
    command is there to store a set of queues for monitoring purposes and is not necessarily
    relevant to job processing itself. However, the subsequent [`LPUSH`](https://redis.io/commands/lpush/)
    command is crucial as it puts jobs into the list that is regularly fetched by
    a `Processor` instance on the server side, which we have already covered. An important
    detail is that `LPUSH` adds the elements to the front of the list - `BasicFetch#retrieve_work`
    pops the element from the tail, making Sidekiq queues employ a FIFO model.'
  id: totrans-split-200
  prefs: []
  type: TYPE_NORMAL
  zh: '`atomic_push`有两个分支。第二个分支是为了尽快处理作业的立即调度。[`SADD`](https://redis.io/commands/sadd/)命令用于存储用于监视目的的队列集合，并不一定与作业处理本身相关。然而，随后的[`LPUSH`](https://redis.io/commands/lpush/)命令非常关键，因为它将作业放入列表中，这些列表会由服务器端的`Processor`实例定期获取，这一点我们已经讨论过了。一个重要的细节是，`LPUSH`将元素添加到列表的前面
    - `BasicFetch#retrieve_work`从尾部弹出元素，使得Sidekiq队列采用FIFO模型。'
- en: It must be strongly emphasized here that despite the first-come first-serve
    nature of queues, Sidekiq does not guarantee the order of job execution. A subsequent
    job can and will be popped from the queue list before the preceding one may be
    finished by another processor. However, it is possible to set the `concurrency`
    setting of a specific capsule responsible for a set of specified queues to 1\.
    This ensures that only 1 `Processor` is active at any time, making job fetching
    sequential. Nevertheless, this still does not guarantee ordering in case a job
    fails to be processed and is sent to the retry set, or in case a preceding job
    is lost. We will explore when the latter case can happen in the following section.
    In any case, if strict ordering of jobs is truly needed, Sidekiq is not the best
    option.
  id: totrans-split-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里必须强调的是，尽管队列的执行顺序是先进先出的，但Sidekiq不保证作业执行的顺序。在另一个处理器处理完之前，后续的作业可能会从队列列表中弹出。然而，可以通过设置特定胶囊的`concurrency`设置为1来确保每次只有一个`Processor`是活动的，使得作业获取是顺序的。然而，这仍然不能保证在作业失败并发送到重试集合，或者前面的作业丢失的情况下的顺序。我们将在下一节中探讨后一种情况可能发生的时机。无论如何，如果确实需要严格的作业顺序，Sidekiq并不是最佳选择。
- en: The first branch of `atomic_push` accommodates scheduled jobs, which we haven’t
    touched until now. Scheduled jobs enable users to defer their job’s execution
    until a specific time in the future. In order to achieve this, `ZADD` is used
    again with a sorted set, similar to `dead` and `retry` sets.
  id: totrans-split-202
  prefs: []
  type: TYPE_NORMAL
  zh: '`atomic_push`的第一个分支用于容纳预定的作业，这是我们到目前为止还没有涉及过的部分。预定的作业允许用户推迟作业的执行，直到将来的特定时间点。为了实现这一点，再次使用`ZADD`与排序集合类似于`dead`和`retry`集合。'
- en: Retrying & scheduling
  id: totrans-split-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重试与调度
- en: By now, we have explored most of the server’s internals, and we have also examined
    how `Sidekiq#client` pushes jobs into the queues, including an option to schedule
    a job for execution in the future. However, we have not yet explored the final
    component that enables the processing of scheduled jobs and jobs that need to
    be retried. We noted that both types of jobs get added into corresponding sorted
    sets using `ZADD`, but how do they get processed?
  id: totrans-split-204
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经探索了大部分服务器的内部结构，也已经检查了`Sidekiq#client`如何将作业推送到队列中，包括将作业安排在将来执行的选项。然而，我们还没有探索能够处理预定作业和需要重试的作业的最终组件。我们注意到，这两种类型的作业都使用`ZADD`添加到相应的排序集合中，但它们如何被处理呢？
- en: When we previously examined the `Launcher`, we intentionally glossed over `Sidekiq::Scheduled::Poller`.
    Whenever a Sidekiq process boots, it calls `Launcher#run`, which in turn initiates
    the poller thread.
  id: totrans-split-205
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们之前检查`Launcher`时，我们有意忽略了`Sidekiq::Scheduled::Poller`。每当一个Sidekiq进程启动时，它调用`Launcher#run`，这将启动轮询线程。
- en: '[PRE36]'
  id: totrans-split-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Its main loop is extremely similar to that of `Processor`, so I won’t cover
    where `@done` is set.
  id: totrans-split-207
  prefs: []
  type: TYPE_NORMAL
  zh: 它的主循环与`Processor`非常相似，因此我不会详细介绍`@done`的设置在哪里。
- en: Before we delve into the details of the `initial_wait`, `enqueue`, and `wait`
    methods, let’s take a step back. Based on what we’ve seen so far, we can confidently
    say that multiple Sidekiq processes require no coordination at all. It’s common
    practice to use a single Redis instance and launch multiple Sidekiq processes,
    each sharing the same set of queues, to increase throughput and availability.
    These processes simply attempt to `BRPOP` jobs from queue lists atomically, and
    each processor gets its share of work.
  id: totrans-split-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入研究 `initial_wait`、`enqueue` 和 `wait` 方法的细节之前，让我们退一步。基于我们迄今所见，我们可以自信地说多个
    Sidekiq 进程根本不需要协调。使用单个 Redis 实例并启动多个 Sidekiq 进程是常见做法，每个进程共享相同的队列集，以提高吞吐量和可用性。这些进程只需原子地从队列列表中
    `BRPOP` 作业，每个处理器都会得到其工作的份额。
- en: However, the `scheduled` and `retry` sets operate differently. Jobs in these
    sets should not be processed immediately; they are pushed into the respective
    queues when their time comes for processing by the `Processor`s. The `Poller`
    handles this task, but what if there are several Sidekiq processes? Each will
    have its own poller thread competing for access to shared Redis sets. While this
    isn’t an issue for normal processing of queue lists, as `BRPOP` operations take
    constant time, extracting desired keys from a `scheduled` or `retry` sorted set
    has a different computational complexity. Continuously bombarding Redis with commands
    used by the poller from several processes negatively impacts its health and performance.
    Therefore, the pollers must either coordinate to ensure that only one runs at
    a time, or their executions must be artificially spread out. Sidekiq opts for
    the latter option, and we’ll explore how it achieves that.
  id: totrans-split-209
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，`scheduled` 和 `retry` 集合的操作方式不同。这些集合中的作业不应立即处理；它们会在处理时间到来时由 `Processor` 推送到各自的队列中。`Poller`
    处理这个任务，但如果有多个 Sidekiq 进程怎么办？每个进程都有自己的轮询线程竞争访问共享的 Redis 集合。虽然这对于正常处理队列列表不是问题，因为
    `BRPOP` 操作需要恒定的时间，但从 `scheduled` 或 `retry` 排序集合中提取所需键具有不同的计算复杂度。从多个进程向 Redis 连续发送轮询器使用的命令会对其健康和性能产生负面影响。因此，轮询器必须要么协调以确保只有一个运行，要么它们的执行必须人为地分散开来。Sidekiq
    选择了后者，并且我们将探讨它是如何实现的。
- en: '`Sidekiq::Scheduled` is one of the most commented modules in Sidekiq, so all
    of the original comments are preserved in following snippets. Here’s `#initial_wait`
    that gets called once per Sidekiq process:'
  id: totrans-split-210
  prefs: []
  type: TYPE_NORMAL
  zh: '`Sidekiq::Scheduled` 是 Sidekiq 中被评论最多的模块之一，所以所有原始评论都在以下片段中保留。这里是每个 Sidekiq
    进程调用一次的 `#initial_wait`：'
- en: '[PRE37]'
  id: totrans-split-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Heartbeat is mentioned in the first comment - similar to a poller, it’s another
    thread that routinely updates some process metadata stored in Redis. The only
    thing relevant to the poller is the updating of the `processes` set, which contains
    unique identifiers of each Sidekiq process; we will see how it exactly comes into
    play shortly.
  id: totrans-split-212
  prefs: []
  type: TYPE_NORMAL
  zh: 心跳在第一个评论中提到 - 与轮询器类似，它是另一个定期更新存储在 Redis 中的某些进程元数据的线程。对于轮询器而言，唯一相关的是更新包含每个 Sidekiq
    进程唯一标识符的 `processes` 集合，我们很快会看到它如何确切地发挥作用。
- en: '`@sleeper.pop(total)` simply makes the thread wait for a specified amount of
    time.'
  id: totrans-split-213
  prefs: []
  type: TYPE_NORMAL
  zh: '`@sleeper.pop(total)` 简单地使线程等待指定的时间量。'
- en: '[PRE38]'
  id: totrans-split-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: As can be seen, the poller is responsible for cleaning out dead processes’ metadata
    from Redis. Despite what the comment in `#initial_wait` says, this only happens
    once a poller starts, and, under normal circumstances, it starts only when a process
    boots up.
  id: totrans-split-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如图所示，轮询器负责清理从 Redis 中删除死进程的元数据。尽管 `#initial_wait` 中的注释说的是一旦轮询器启动就会发生，但在正常情况下，它只会在进程启动时启动。
- en: 'Why exactly this is necessary can be seen in the `#wait` method, which is being
    called in a loop after every `#enqueue`:'
  id: totrans-split-216
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么这是必要的，可以在被称为的 `#wait` 方法中看到，该方法在每次 `#enqueue` 后都被调用：
- en: '[PRE39]'
  id: totrans-split-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Poll interval logic is explained in detail thanks to the comprehensive comments.
    The amount of active Sidekiq processes consuming jobs from the same Redis installation
    is taken into consideration when calculating an interval with which pollers should
    contact Redis. It all boils down to minimizing concurrent poller operations.
  id: totrans-split-218
  prefs: []
  type: TYPE_NORMAL
  zh: 由于详尽的评论，轮询间隔逻辑得到了详细解释。在计算轮询器应该与 Redis 联系的间隔时，考虑了从同一 Redis 安装中消耗作业的活动 Sidekiq
    进程数量。这归结为最小化并发轮询器操作。
- en: 'Finally, let’s see what all of this effort is for. `Poller#enqueue` instantiates
    `Sidekiq::Scheduled::Enq`, which encapsulates scheduled dequeue logic and calls
    `#enqueue_jobs` on it:'
  id: totrans-split-219
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看看所有这些努力是为了什么。`Poller#enqueue` 实例化 `Sidekiq::Scheduled::Enq`，封装了预定出队逻辑，并在其上调用
    `#enqueue_jobs`：
- en: '[PRE40]'
  id: totrans-split-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: First thing to note is the `LUA_ZPOPBYSCORE` string, along with [`SCRIPT`](https://redis.io/commands/script-load/)
    and [`EVALSHA`](https://redis.io/commands/evalsha/) Redis commands. This is Sidekiq
    making use of a [Redis feature](https://redis.io/docs/interact/programmability/eval-intro/)
    that allows execution of atomic Lua scripts on the server. The script is preloaded
    and cached in Redis using `conn.script` so that subsequent commands utilizing
    it can benefit from increased performance.
  id: totrans-split-221
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要注意的是`LUA_ZPOPBYSCORE`字符串，以及[`SCRIPT`](https://redis.io/commands/script-load/)和[`EVALSHA`](https://redis.io/commands/evalsha/)
    Redis命令。这是Sidekiq利用Redis的一个[特性](https://redis.io/docs/interact/programmability/eval-intro/)，允许在服务器上执行原子Lua脚本。该脚本通过`conn.script`预加载和缓存在Redis中，以便后续使用它的命令可以获得增加的性能。
- en: The script itself takes an array of sets (`retry` and `schedule`) and a current
    timestamp (note that Lua array indexing starts with 1). It then calls [`ZRANGE`](https://redis.io/commands/zrange/),
    which returns a single job with the lowest timestamp that should be dispatched
    to the queue. The job element is then removed from the set using [`ZREM`](https://redis.io/commands/zrem/).
  id: totrans-split-222
  prefs: []
  type: TYPE_NORMAL
  zh: 脚本本身接受一组集合（`retry`和`schedule`）以及当前时间戳（请注意Lua数组索引从1开始）。然后调用[`ZRANGE`](https://redis.io/commands/zrange/)，返回应该分派到队列的具有最低时间戳的单个作业。然后使用[`ZREM`](https://redis.io/commands/zrem/)从集合中移除作业元素。
- en: The complexity of `ZRANGE` is O(log(N) + M), where N is the total number of
    elements in the set and M is the number of elements returned. However, Sidekiq
    dequeues one scheduled or to-be-retried job at a time to be safe, as the comment
    suggests, meaning that the overall complexity will be O(M * log(N)).
  id: totrans-split-223
  prefs: []
  type: TYPE_NORMAL
  zh: '`ZRANGE`的复杂度为O(log(N) + M)，其中N是集合中的总元素数，M是返回的元素数。然而，如评论所示，Sidekiq每次只出列一个计划的或待重试的作业，以确保安全，这意味着总体复杂度将为O(M
    * log(N))。'
- en: '`ZREM` itself is already O(M * log(N)), so the overall complexity doesn’t change
    by the fact that the whole script is called for every relevant job.'
  id: totrans-split-224
  prefs: []
  type: TYPE_NORMAL
  zh: '`ZREM`本身已经是O(M * log(N))，所以整体复杂度不会因为整个脚本对每个相关作业的调用而改变。'
- en: For every successfully dequeued job, `Client#push` is called to dispatch the
    job to its target queue.
  id: totrans-split-225
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个成功出列的作业，将调用`Client#push`将作业分派到其目标队列。
- en: This, along with the fact that Redis is mostly single-threaded, makes it clear
    why spreading out the pollers in time is so important. With several processes
    and a large enough retry or scheduled set (and in my experience, retry set sizes
    can easily be in the order of thousands, if not more), executing this logic concurrently
    can significantly impair Redis’s performance or even grind it to a halt.
  id: totrans-split-226
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，Redis大多数情况下是单线程的，这清楚地说明了为什么在时间上分散轮询器如此重要。通过几个进程和足够大的重试或计划集（根据我的经验，重试集大小很容易达到数千个甚至更多），并发执行这个逻辑可以显著地影响Redis的性能，甚至使其停滞不前。
- en: Job loss potential
  id: totrans-split-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 作业丢失的潜力
- en: Now that we’ve explored the complete lifecycle of a job as it’s processed by
    the server, let’s examine potential scenarios where a job might become lost.
  id: totrans-split-228
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了作业在服务器处理过程中的完整生命周期，让我们检查可能导致作业丢失的潜在场景。
- en: We know that the OS version of Sidekiq only provides `BasicFetch` as a means
    to dequeue jobs from Redis, which effectively removes them from the corresponding
    queue lists. This means that if a Sidekiq process is terminated abruptly, such
    as with a SIGKILL, all in-progress jobs will be lost. For instance, this can occur
    if the process exhausts its memory, prompting Kubernetes to forcefully terminate
    the pod with a `kill -9` command, or if other orchestrators and hosting providers
    take similar actions.
  id: totrans-split-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道Sidekiq的操作系统版本只提供`BasicFetch`作为从Redis出列作业的方法，这有效地从相应的队列列表中删除它们。这意味着如果Sidekiq进程突然终止，例如使用SIGKILL，所有正在进行中的作业都将丢失。例如，如果进程耗尽内存，促使Kubernetes强制使用`kill
    -9`命令终止pod，或者如果其他编排器和托管提供商采取类似的操作。
- en: But how does Sidekiq manage hanging, long-running, or simply in-progress jobs
    during a graceful termination?
  id: totrans-split-230
  prefs: []
  type: TYPE_NORMAL
  zh: 那么在优雅终止期间，Sidekiq如何管理挂起的、长时间运行的或者简单地正在进行中的作业呢？
- en: 'Let’s revisit `Manager#hard_shutdown`, which is called when a Sidekiq process
    receives a SIGTERM or SIGINT:'
  id: totrans-split-231
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新审视`Manager#hard_shutdown`，当一个Sidekiq进程接收到SIGTERM或SIGINT信号时会调用它：
- en: '[PRE41]'
  id: totrans-split-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '`capsule.fetcher.bulk_requeue(jobs)` is called before processor threads are
    terminated. At this point, waiting for them to handle the `Sidekiq::Shutdown`
    exception and gracefully exit is not feasible. ^(Therefore, the best option is
    to requeue all jobs that are in progress, even though it means that some jobs
    that finish just before the process exits will also be requeued.)'
  id: totrans-split-233
  prefs: []
  type: TYPE_NORMAL
  zh: '`capsule.fetcher.bulk_requeue(jobs)` 在处理器线程终止之前被调用。此时，等待它们处理`Sidekiq::Shutdown`异常并优雅地退出是不可行的。^(因此，最佳选择是重新排队所有正在进行的作业，即使这意味着一些在进程退出之前完成的作业也将被重新排队。)'
- en: '`BasicFetch#bulk_requeue` simply takes the job payloads extracted from active
    processors and puts them back into the corresponding Redis lists:'
  id: totrans-split-234
  prefs: []
  type: TYPE_NORMAL
  zh: '`BasicFetch#bulk_requeue` 简单地将从活动处理器中提取的作业载荷放回相应的Redis列表：'
- en: '[PRE42]'
  id: totrans-split-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '`BasicFetch`’s requeue logic is a potential scenario where job loss can occur.
    Redis might run out of memory while a job is being processed, making it impossible
    to put the job back into the queue. This is also a concern for ordinary retries.'
  id: totrans-split-236
  prefs: []
  type: TYPE_NORMAL
  zh: '`BasicFetch`的重新排队逻辑是可能导致作业丢失的一个场景。Redis在处理作业时可能会耗尽内存，从而无法将作业放回队列。这对于普通的重试也是一个问题。'
- en: Additionally, although not directly related to Sidekiq, jobs can be lost due
    to specific Redis server misconfigurations. The [eviction policy](https://redis.io/docs/reference/eviction/),
    which determines how Redis handles memory when it’s full, plays a significant
    role here. Any setting other than `noevict` may result in jobs being evicted from
    Redis under certain circumstances. Furthermore, Redis can encounter failures and
    lose data after a reboot, particularly with certain [persistence](https://redis.io/docs/management/persistence/)
    configurations. This situation can lead to Sidekiq clients incorrectly assuming
    that a job will be processed after a successful push, when in fact it may not
    reach the Sidekiq server at all.
  id: totrans-split-237
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，虽然与Sidekiq没有直接关系，但由于特定的Redis服务器配置错误，作业可能会丢失。[驱逐策略](https://redis.io/docs/reference/eviction/)在此处起到了重要作用，它决定了Redis在内存满时的处理方式。除了`noevict`之外的任何设置，在特定情况下都可能导致作业从Redis中被驱逐出去。此外，Redis在重新启动后可能会遇到故障并丢失数据，特别是在某些[persistence](https://redis.io/docs/management/persistence/)配置下。这种情况可能导致Sidekiq客户端错误地假设成功推送后作业将被处理，而实际上它可能根本没有到达Sidekiq服务器。
- en: It is also possible for the SIGTERM or SIGINT handler not to be executed within
    the predefined timeout period, which the orchestrator running Sidekiq waits for
    before sending SIGKILL. Redis connectivity issues are the most likely culprit
    here. Theoretically, GC pauses and the condition of the host machine can also
    impede the Sidekiq process during this crucial task, but I personally have never
    encountered, nor have I heard of, such cases where a Ruby program is stalled for
    25 seconds.
  id: totrans-split-238
  prefs: []
  type: TYPE_NORMAL
  zh: 还有可能是在预定义超时期间内未执行SIGTERM或SIGINT处理程序，Sidekiq运行的编排程序在发送SIGKILL之前等待这一超时。这里最可能的罪魁祸首是Redis连接问题。理论上，GC暂停和主机机器的状态也可能在此关键任务期间阻碍Sidekiq进程，但我个人从未遇到过，也从未听说过25秒内Ruby程序被卡住的情况。
- en: It goes without saying that killing the Sidekiq process with SIGKILL without
    having sent SIGINT or SIGTERM prior will result in all of the in-progress jobs
    being lost.
  id: totrans-split-239
  prefs: []
  type: TYPE_NORMAL
  zh: 毫无疑问，如果在未发送SIGINT或SIGTERM的情况下使用SIGKILL终止Sidekiq进程，所有正在进行的作业都将丢失。
- en: It should be noted that the decision to design `BasicFetch` in its current manner
    is intentional. By using a single `BRPOP` command to fetch a job, Sidekiq remains
    extremely simple and lightweight in terms of its load on Redis. However, this
    also means that if your jobs absolutely must never be lost, relying solely on
    Sidekiq might not be the best choice. Nevertheless, it may be possible to refactor
    the application code and business logic that warrants strong durability guarantees
    to include a liveness component, such as a recurring cron job, that would attempt
    to ensure the completion of a specific workflow by repeatedly enqueuing a job
    until the desired final state is achieved.
  id: totrans-split-240
  prefs: []
  type: TYPE_NORMAL
  zh: 应注意，当前设计`BasicFetch`的决策是有意为之的。通过使用单个`BRPOP`命令来获取作业，Sidekiq在Redis的负载方面保持极其简单和轻量化。然而，这也意味着如果您的作业绝对不能丢失，仅依赖于Sidekiq可能不是最佳选择。尽管如此，可能可以重构应用程序代码和业务逻辑，需要强大的耐久性保证，包括一个像是定期cron作业的活跃组件，它会重复地将作业加入队列，直到达到期望的最终状态。
- en: This makes Sidekiq employ an ‘at least once’ delivery semantic, with the possibility
    of losing jobs during severe degradation of the system’s health. However, the
    Pro version ensures that job loss is impossible, as jobs never leave Redis until
    they are acknowledged with `SuperFetch` enabled, effectively making it truly ‘at
    least once’ without any caveats.
  id: totrans-split-241
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得 Sidekiq 采用了“至少一次”交付语义，系统健康严重降级时可能会丢失作业。然而，专业版确保作业不会丢失，因为作业在未使用 `SuperFetch`
    确认之前永远不会离开 Redis，有效地使其真正成为“至少一次”而没有任何附带条件。
- en: Sidekiq leverages simple Redis data structures like lists with constant-time
    push and pop operations, along with adjustable thread counts, to achieve scalability,
    efficiency, and ease of management. In the OS version, scaling can involve deploying
    multiple Sidekiq processes, each consuming jobs from the same Redis installation.
    The Enterprise version offers a forking model for multi-process execution, providing
    an alternative way to scale. For fine-grained control over queues, capsules can
    be used to organize processing with specific concurrency settings. Additionally,
    you can prioritize certain queues, enforce strict queue processing order (distinct
    from job ordering), or evenly poll queues. However, it’s important to note that
    job ordering within queues isn’t supported. Nevertheless, employing a single processor
    per queue could provide a rudimentary form of ordering, which may suffice depending
    on your application’s requirements.
  id: totrans-split-242
  prefs: []
  type: TYPE_NORMAL
  zh: Sidekiq 利用简单的 Redis 数据结构，如列表，具有常数时间的推送和弹出操作，以及可调整的线程数，实现了可伸缩性、效率和易管理性。在操作系统版本中，扩展可以涉及部署多个
    Sidekiq 进程，每个进程从同一 Redis 安装中消耗作业。企业版提供了一个分叉模型用于多进程执行，提供了一种可扩展的方式。为了对队列进行精细控制，可以使用胶囊来组织具有特定并发设置的处理。此外，您可以优先处理某些队列，强制执行严格的队列处理顺序（与作业排序不同），或均匀轮询队列。但是，需要注意的是，队列内的作业排序不受支持。尽管如此，在每个队列使用单个处理器可能会提供一种基本的排序形式，这可能根据您的应用需求而足够。
