- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-29 13:18:46'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-29 13:18:46'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Meta's new LLM-based test generator is a sneak peek to the future of development
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Meta最新基于LLM的测试生成器是未来开发的一个预览。
- en: 来源：[https://read.engineerscodex.com/p/metas-new-llm-based-test-generator](https://read.engineerscodex.com/p/metas-new-llm-based-test-generator)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://read.engineerscodex.com/p/metas-new-llm-based-test-generator](https://read.engineerscodex.com/p/metas-new-llm-based-test-generator)
- en: '*Engineer’s Codex is a publication about real-world software engineering.*'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*Engineer’s Codex是一个关于现实世界软件工程的出版物。'
- en: '* * *'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: Meta recently released a [paper called “Automated Unit Test Improvement using
    Large Language Models at Meta”](https://arxiv.org/abs/2402.09171). It’s a good
    look at how Big Tech is using AI internally to make development faster and software
    less buggy. For example, [Google is using AI to speed up code reviews](https://read.engineerscodex.com/i/139414745/critique-googles-code-review-tool).
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: Meta最近发布了一篇名为“Meta在自动化单元测试改进中使用大语言模型”的论文（https://arxiv.org/abs/2402.09171）。这是一个深入了解大型科技公司如何内部使用AI来加快开发速度和减少软件缺陷的好机会。例如，[Google正在使用AI加速代码审查](https://read.engineerscodex.com/i/139414745/critique-googles-code-review-tool)。
- en: A major win of this paper is that while it integrates LLMs into a developer’s
    workflow, it also recommends fully-formed software improvements that are verified
    to be both correct and an improvement to current code coverage. This is **not
    a magic pill, but it’s a good start on making LLMs more useful**. Compare this
    to ChatGPT, where suggestions still have to be manually verified to work - and
    we all know that [debugging code is twice as hard as writing it](https://read.engineerscodex.com/p/clever-code-is-probably-the-worst).
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的一个重要亮点是，它将LLMs集成到开发者的工作流程中，同时推荐经过验证的完全形成的软件改进，这些改进既正确又能提高当前代码覆盖率。这**不是灵丹妙药，但它是使LLMs更有用的一个良好开端**。与ChatGPT相比，建议仍然需要手动验证才能生效，我们都知道，[调试代码比编写代码难上两倍](https://read.engineerscodex.com/p/clever-code-is-probably-the-worst)。
- en: Meta claims that “this is the first paper to report on LLM-generated code that
    has been developed independent of human intervention (other than final review
    sign off), and landed into large scale industrial production systems with guaranteed
    assurances for improvement over the existing code base.” (Bleh! That was a mouthful.)
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: Meta声称“这是第一篇报告LLM生成的代码，这些代码在没有人类干预（最终审查除外）的情况下开发，并且已经进入了大规模工业生产系统，并保证比现有代码库有所改进。”（哎呀！这话说起来真费口舌。）
- en: Furthermore, there are solid principles that developers can take away in order
    to use AI effectively themselves.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，开发者可以掌握一些坚实的原则，以便自己有效地使用人工智能。
- en: '**Table of Contents:**'
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**目录：**'
- en: '* * *'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '***[SWE Quiz](http://swequiz.com)** is for ambitious developers who want to
    make sure their software fundamentals are rock solid. Reveal gaps in your knowledge
    and make sure you really know what you’re doing both at work and while interviewing.*'
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: '***[SWE Quiz](http://swequiz.com)**是为有雄心的开发者设计的，他们想确保自己的软件基础牢固。揭示你知识中的空白，并确保你在工作和面试时确实知道自己在做什么。*'
- en: '*Take the tests for [authentication](https://www.swequiz.com/learn/authentication-roadmap),
    [caching](https://swequiz.com/learn/caching-roadmap), [databases](https://www.swequiz.com/learn/databases-roadmap),
    [API Design](https://www.swequiz.com/learn/api-design-roadmap), and [more](https://www.swequiz.com/learn).*'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: '*为[身份验证](https://www.swequiz.com/learn/authentication-roadmap)、[缓存](https://swequiz.com/learn/caching-roadmap)、[数据库](https://www.swequiz.com/learn/databases-roadmap)、[API设计](https://www.swequiz.com/learn/api-design-roadmap)和[更多](https://www.swequiz.com/learn)进行测试。*'
- en: '[Check out SWE Quiz](https://swequiz.com)'
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[查看SWE Quiz](https://swequiz.com)'
- en: '* * *'
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: TestGen-LLM uses an approach called ‘Assured LLM-based Software Engineering’
    (Assured LLMSE), using private, internal LLMs that are probably fine-tuned with
    Meta’s codebase. This means that it uses LLMs to generate code improvements that
    are backed by “**verifiable guarantees”of improvement and non-regression.**
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: TestGen-LLM采用一种称为‘保证LLM基础软件工程’（Assured LLMSE）的方法，使用私有的、内部的LLMs，这些LLMs可能与Meta的代码库进行了微调。这意味着它使用LLMs生成的代码改进，支持“**可验证的保证**，确保改进和非回归”。
- en: TestGen-LLM uses an **ensemble approach** to generate code improvements. This
    means that it uses **“LLMs, prompts, and hyper-parameters”** to generate a set
    of candidate improvements, and then selects the best one. This approach can help
    to improve the quality of the generated improvements.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: TestGen-LLM采用**合奏方法**生成代码改进。这意味着它使用**“LLMs、提示和超参数”**生成一组候选改进，然后选择最佳的一个。这种方法有助于提高生成改进的质量。
- en: 'TestGen-LLM is specifically designed to **improve existing human-written tests**
    rather than **generate code from scratch**. A good way to think about this LLM
    is: it''s a junior dev with the task of creating more comprehensive tests for
    existing code. Other devs have more important things to work on, so this LLM gets
    the fun task of improving unit tests.'
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: TestGen-LLM专门设计用于**改进现有的人工编写的测试**，而不是**从头生成代码**。可以这样理解这个LLM：它是一个初级开发人员，负责为现有代码创建更全面的测试。其他开发人员有更重要的事情要做，因此这个LLM有幸负责改进单元测试。
- en: The tests that it creates in its pull requests are often good, and sometimes
    trivial or pointless. Occasionally, a test it produces is really good or uncovers
    a bug inadvertently. Regardless, this work wouldn't have been done by humans anyways
    due to priorities. All of its pull requests require a human reviewer before pushed
    into the codebase.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 它在拉取请求中创建的测试通常是好的，有时是微不足道或无意义的。偶尔，它生成的测试确实很好，或者无意中揭示了一个bug。无论如何，这项工作由于优先事项原因，人类本来也不会做。所有的拉取请求在推入代码库之前都需要人工审查。
- en: TestGen-LLM has been **integrated into Meta's software engineering workflows**.
    This means that it can be used to automatically improve tests as part of the development
    process. It would be cool to see some screenshots of how exactly it’s integrated,
    but the paper doesn’t provide any.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: TestGen-LLM已经**集成到Meta的软件工程工作流程**中。这意味着它可以作为开发过程的一部分自动改进测试。看到它如何确切地集成将会很酷，但论文没有提供任何截图。
- en: These stats are either direct quotes or paraphrased quotes from the paper. A
    short reminder that all tests that were landed required a final sign-off by human
    reviewers.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这些统计数据要么是直接引用要么是引用的摘录。需要提醒一下，所有成功投入的测试都需要人工审查批准。
- en: 'The image above shows that: in an evaluation on Reels and Stories products
    for Instagram, 75% of TestGen-LLM test cases that were generated built correctly,
    57% passed reliably, and *25% increased coverage*.'
  id: totrans-split-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上图显示：在Instagram的Reels和Stories产品的评估中，75%的TestGen-LLM生成的测试用例正确构建，57%可靠通过，而*25%的覆盖率增加*。
- en: TestGen-LLM was able to improve **10% of all classes to which it was applied
    and 73% of its test improvements were accepted by developers**, and landed into
    production.
  id: totrans-split-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TestGen-LLM能够改进应用于的所有类的**10%**，其测试改进**73%**被开发人员接受，并投入生产。
- en: In a “test-a-thon” between engineers, where various Meta engineers created tests
    in order to increase Instagram’s test coverage, “**the median number of lines
    of code added by a TestGen-LLM test was 2.5**.”
  id: totrans-split-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Meta工程师进行的“测试马拉松”中，各种Meta工程师创建测试以增加Instagram的测试覆盖率，“**TestGen-LLM测试平均增加的代码行数为2.5**。”
- en: However, one test case “hit the jackpot” and covered 1,326 lines.
  id: totrans-split-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然而，有一个测试案例“大获成功”，覆盖了1326行代码。
- en: All improved cases generated during the “test-a-thon” did “cover at least one
    additional valid corner case, such as an early return and/or special processing
    for special values such as null and empty list.”
  id: totrans-split-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在“测试马拉松”期间生成的所有改进案例，“至少覆盖了一个额外的有效边界情况，例如提前返回和/或特殊值（如null和空列表）的特殊处理。”
- en: '**TestGen-LLM is a good example of how LLMs can be used to improve dev productivity
    and software reliability in a time-efficient manner.** (Note: many of these are
    my own personal opinions that I’ve taken away from the paper.)'
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**TestGen-LLM是LLMs如何在时间高效的情况下用于提高开发效率和软件可靠性的良好示例。**（注：这些大部分是我从论文中得出的个人观点。）'
- en: Small context windows and scattered dependencies make LLMs nearly unusable for
    non-boilerplate solutions in large codebases. Aside from any privacy concerns,
    it’s not feasible to paste in multiple files of code into an LLM when there could
    be 20+ dependencies from across a codebase in a C++ header file (as an example).
    Even if you do paste in multiple files, there is a time and cognitive cost to
    actually using and trying the code outputted by an LLM in a chat window or even
    in the code editor by GitHub Copilot.
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型代码库中，小的上下文窗口和分散的依赖使LLMs几乎无法用于非样板解决方案。除了隐私问题外，将多个代码文件粘贴到LLM中可能不切实际，例如C++头文件中可能有20个以上的依赖关系。即使粘贴了多个文件，使用LLM在聊天窗口或GitHub
    Copilot代码编辑器中输出的代码也需要时间和认知成本。
- en: The price of extra cognitive load cannot be understated. [Hacker News commenters
    find the inaccuracies of GPT-based tooling exhausting and unreliable.](https://news.ycombinator.com/item?id=39460788)
    This is where the **verification of outputs being both valid and non-regressive
    is extremely important.** Each test by TestGen-LLM requires a human sign-off anyways,
    so any programmatic guarantees are useful here.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 额外的认知负荷的代价不容小觑。[Hacker News的评论者发现基于GPT的工具的不准确性令人筋疲力尽和不可靠。](https://news.ycombinator.com/item?id=39460788)
    这正是**验证输出是否既有效又不回退非常重要的地方**。TestGen-LLM的每个测试都需要人类签署批准，所以这里的任何程序化保证都是有用的。
- en: This means that for a long-term productivity boost in large codebases, **improvements
    will probably come in incremental, specialized use cases**, like test generation
    and [automatic suggestions during code reviews](https://blog.research.google/2023/05/resolving-code-review-comments-with-ml.html).
    These are also low risk ways to save cumulative developer time. Basically, “GPT
    wrappers” will continue to be useful 🙂.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大型代码库的长期生产力提升来说，**改进可能会逐步出现在增量、专业化的用例上**，比如测试生成和[代码审查期间的自动建议](https://blog.research.google/2023/05/resolving-code-review-comments-with-ml.html)。这些也是节省累积开发时间的低风险方式。基本上，“GPT包装”将继续发挥作用
    🙂。
- en: '**The real value of LLMs here are displayed through the edge cases**. The paradox
    of writing good code is that [nobody ever gets credit for fixing problems that
    never happened](https://web.mit.edu/nelsonr/www/Repenning=Sterman_CMR_su01_.pdf).'
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**LLM的真正价值在于显示出边缘情况**。写好代码的悖论在于，[从未发生过的问题修复往往不会得到任何认可](https://web.mit.edu/nelsonr/www/Repenning=Sterman_CMR_su01_.pdf)。'
- en: '[Will Wilson writes](https://antithesis.com/blog/is_something_bugging_you/):'
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[威尔·威尔逊写道](https://antithesis.com/blog/is_something_bugging_you/)：'
- en: '*“The fundamental problem of software testing… is that software has to handle
    many situations that the developer has never thought of or will never anticipate.
    This limits the value of testing, because if you had the foresight to write a
    test for a particular case, then you probably had the foresight to make the code
    handle that case too. This makes conventional testing great for catching regressions,
    but really terrible at catching all the “unknown unknowns” that life, the universe,
    and your endlessly creative users will throw at you.”*'
  id: totrans-split-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“软件测试的根本问题在于……软件必须处理开发者从未考虑过或永远无法预料的许多情况。这限制了测试的价值，因为如果你有预见性地为特定情况编写测试，那么你可能也有预见性地让代码处理该情况。这使得传统测试在捕捉回归方面非常出色，但在捕捉生活、宇宙和你的无穷创意用户将向你投掷的所有“未知未知”方面确实非常糟糕。”*'
- en: '**LLMs can’t really “think outside the box” because they only really know their
    training data. However, their box can be larger than a human’s, so they have the
    potential to think about cases that a human might miss.**'
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**LLM实际上无法“超出盒子”的想法，因为它们只真正了解它们的训练数据。然而，它们的盒子可能比人类的大，因此它们有潜力考虑到人类可能会忽略的情况。**'
- en: 'Most of the test cases created by Meta’s TestGen-LLM only covered an extra
    2.5 lines. However, one test case covered 1326 lines! There are two ways to think
    about this case:'
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: Meta的TestGen-LLM创建的大多数测试案例仅覆盖了额外的2.5行。然而，一个测试案例覆盖了1326行！有两种方式来思考这个案例：
- en: The optimistic case is that the LLM possibly caught an important edge case that
    was missed by humans when testing.
  id: totrans-split-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 乐观的情况是，LLM可能捕捉到了在测试中被人类忽略的重要边缘情况。
- en: The more realistic case is that the LLM caught a codepath that was just missed
    altogether, rather than catching an edge case.
  id: totrans-split-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更现实的情况是LLM捕捉到了一个完全被忽略的代码路径，而不是捕捉到了一个边缘情况。
- en: '**More code coverage != better code**. We don’t want to use lines covered as
    a chaseable metric, though it would be any bad engineering manager’s dream. More
    code coverage is gameable, but the downsides of rote coverage created by LLMs
    is that bugs are also codified, which means they can go unnoticed until they appear
    in production.'
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**更多的代码覆盖率并不等于更好的代码**。我们不希望将覆盖的代码行数作为可以追求的指标，尽管这可能是任何糟糕的工程经理的梦想。更多的代码覆盖率是可以操纵的，但由LLM生成的机械覆盖的缺点是，缺陷也被编码了，这意味着它们在生产中可能被忽略，直到出现问题。'
- en: The value here is mostly bringing edge cases that lie outside of the developer’s
    immediate context, but still within the LLM’s training data, to the developer’s
    attention.
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的价值主要在于将开发者不太关注但仍在LLM培训数据范围内的边缘情况带到开发者的注意力中。
- en: The Blue Box signifies the space where LLMs can come in handy.
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
  zh: 蓝色框表示LLM在这里可能会有用的空间。
- en: Like I mentioned earlier, a good way to think about this LLM is that it's a
    junior dev with the task of creating more comprehensive tests for existing code.
    **LLMs may not generate perfect code on the first try, but it at least provides
    options that otherwise may not have been thought of.** Other devs have more important
    things to work on, so this LLM gets the fun task of improving unit tests. The
    tests that it creates in its pull requests are often good, and sometimes trivial
    or pointless. Occasionally, a test it produces is really good or uncovers a bug
    inadvertently.
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我之前提到的，理解这个LLM的一个好方法是把它看作是一个初级开发人员，负责为现有代码创建更全面的测试。**LLM可能不会在第一次尝试时生成完美的代码，但至少提供了一些否则可能没有被考虑到的选项。**其他开发人员有更重要的事情要做，所以这个LLM得到了改进单元测试的有趣任务。它在拉取请求中创建的测试通常很好，有时是琐碎或毫无意义的。偶尔，它生成的测试非常好，或者无意中发现了一个bug。
- en: In fact, it’s so high that the creator of FoundationDB’s startup, [Antithesis](https://antithesis.com/),
    is entirely based on the fact that software testing edge cases are best found
    by continuously searching software for problems. [For reference, FoundationDB
    was acquired by Apple and is the basis for Apple iCloud’s billions of databases.](https://read.engineerscodex.com/p/how-apple-built-icloud-to-store-billions)
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这一高度是如此之高，以至于FoundationDB创始人的创业公司[Antithesis](https://antithesis.com/)的创造者，完全基于软件测试边缘情况最好通过不断搜索软件来发现问题。[作为参考，FoundationDB被苹果收购，并成为苹果iCloud数十亿数据库的基础。](https://read.engineerscodex.com/p/how-apple-built-icloud-to-store-billions)
- en: Base model LLMs aren’t “plug-n-play" and shouldn’t reasonably ever be expected
    to. Sure, they might output pristine React and Tailwind CSS code, but that’s a
    narrow use case in most production codebases. They need a fair amount of processing
    and filtering for code generation tasks that require correctness. Part of this
    processing means grounding LLMs with examples. Google and Meta both make **suggestions
    based on existing code**, where the results are much, much better than raw generation.LLMs
    used in production should take ideas from how Meta processes and filters LLM outputs,
    and most outputs should be expected to be discarded.
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型LLM并非“即插即用”，合理地不应期望如此。当然，它们可能会输出完美的React和Tailwind CSS代码，但在大多数生产代码库中，这只是一个狭窄的用例。它们需要大量的处理和过滤，以处理需要正确性的代码生成任务。这种处理的一部分意味着用例化LLM与示例。谷歌和Meta都基于现有代码提出**基于现有代码的建议**，在这些情况下，结果比原始生成要好得多。在生产中使用的LLM应该借鉴Meta处理和过滤LLM输出的方法，并且大多数输出都应该预期被丢弃。
- en: LLMs do work best integrated into workflows. This is a reason why GitHub Copilot
    is so popular and another reason why Google’s Workspace integrations are a great
    idea. Asking a chatbot works great for certain use cases, like boilerplate code
    generation, but chatbots can often fail at more complex use cases.
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: LLM最有效的工作方式是集成到工作流程中。这也是为什么GitHub Copilot如此受欢迎，以及Google Workspace集成的另一个原因。像聊天机器人询问一样，对于某些用例，比如生成样板代码，效果很好，但在更复杂的用例中，聊天机器人经常会失败。
- en: 'TestGen-LLM applies a series of semantic filters to candidate solutions generated
    by Meta’s internal LLMs, making sure that only the most valuable tests are preserved.
    Here’s how it works:'
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: TestGen-LLM对Meta内部LLM生成的候选解决方案应用一系列语义筛选器，确保只保留最有价值的测试。以下是它的工作原理：
- en: '**Filter 1: Buildability:** Initially, TestGen-LLM checks if the generated
    code can be built within the app''s existing infrastructure. Any code that fails
    to build is immediately discarded.'
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**筛选器1：可构建性：** 最初，TestGen-LLM检查生成的代码是否可以在应用程序的现有基础设施中构建。任何不能构建的代码都会立即被丢弃。'
- en: '**Filter 2: Execution (does the test pass?):** Next, the system runs the tests
    that passed the buildability filter. Any test that doesn''t pass is discarded.
    This step is crucial because, without a way to automatically determine the validity
    of a failing test (whether it''s due to a bug or an incorrect assertion), TestGen-LLM
    opts to keep only those tests that can be used for regression testing (aka making
    sure they can protect current code against future regressions).'
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**筛选器2：执行（测试是否通过？）：** 接下来，系统运行通过了构建性筛选器的测试。任何不能通过的测试都会被丢弃。这一步骤非常关键，因为如果没有一种自动确定失败测试的有效性的方法（无论是由于bug还是不正确的断言），TestGen-LLM选择保留那些可以用于回归测试的测试（即确保它们可以保护当前代码免受未来回归的影响）。'
- en: '**Filter 3: Flakiness:** To address the issue of [flakiness](https://www.swequiz.com/learn/what-are-flaky-tests)
    (tests that pass or fail inconsistently under the same conditions), TestGen-LLM
    employs repeated execution. A test must pass consistently across multiple (five)
    executions to be considered non-flaky.'
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**过滤器 3：易碎性：** 为了解决[易碎性](https://www.swequiz.com/learn/what-are-flaky-tests)（在相同条件下测试结果不一致的问题），TestGen-LLM采用重复执行。测试必须在多次（五次）执行中始终通过才能被视为非易碎。'
- en: '**Filter 3: Coverage Improvement:** Finally, to ensure that new tests actually
    add value, TestGen-LLM evaluates them for their contribution to test coverage.
    Tests that do not enhance coverage by exploring new code paths or conditions are
    discarded. Only tests that provide new insights or protect against regressions
    are kept.'
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**过滤器 3：覆盖率改进：** 最后，为了确保新测试实际上增加了价值，TestGen-LLM评估它们对测试覆盖率的贡献。不增加通过探索新代码路径或条件来增强覆盖率的测试将被丢弃。只有提供新见解或防止回归的测试才会被保留。'
- en: These processing filters are pretty important as they guarantee improvements
    to a test suite. It also shows that LLMs are very far from being “plug-and-play.”
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这些处理过滤器非常重要，因为它们保证了对测试套件的改进。这也表明LLM远非“即插即用”。
- en: The tests that successfully pass through all these filters are guaranteed to
    enhance the existing test suite, offering reliable regression testing capabilities
    without duplicating effort or wasting resources. Pre- and post-processing steps
    in TestGen-LLM facilitate the extraction and reconstruction of test classes, streamlining
    the integration of new tests into the software development workflow.
  id: totrans-split-53
  prefs: []
  type: TYPE_NORMAL
  zh: 通过所有这些过滤器成功通过的测试可以保证增强现有的测试套件，提供可靠的回归测试能力，而不会重复努力或浪费资源。在TestGen-LLM中，测试前后处理步骤有助于提取和重建测试类，简化新测试集成到软件开发工作流程中。
- en: This paper is a good formalization of an use case that many devs probably already
    use LLMs like ChatGPT, Gemini, and Mistral/LLaMA for. Keeping it in writing is
    a good way of tracking the progress of future improvements on LLMs in the software
    reliability space. So far, we see that LLMs work best as an extension of the human,
    best thought of as a junior dev that needs assistance and prodding. As time goes
    on, we’ll definitely see LLMs be able to catch and test for bugs in increasingly
    complex software systems.
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇论文很好地形式化了一个使用案例，许多开发人员可能已经在像ChatGPT、Gemini和Mistral/LLaMA这样的LLM中使用。将其写下来是追踪未来在软件可靠性空间中改进LLM的进展的好方法。到目前为止，我们看到LLM最适合作为人类的延伸，最好被视为需要帮助和推动的初级开发人员。随着时间的推移，我们肯定会看到LLM能够在日益复杂的软件系统中捕捉和测试错误。
- en: The question is - will that make software easier to develop in the long run
    or will it lead to a proliferation of software complexity in the future?
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
  zh: 问题是 - 长远来看，这是否会使软件开发变得更加容易，还是会导致未来软件复杂性的蔓延？
