- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-27 14:32:21'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-27 14:32:21
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Speed up your code: don''t pass structs bigger than 16 bytes on AMD64 · GitHub'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加速你的代码：不要在AMD64上传递大于16字节的结构体 · GitHub
- en: 来源：[https://gist.github.com/FeepingCreature/5dff669aad380a123b15659e195fb96c](https://gist.github.com/FeepingCreature/5dff669aad380a123b15659e195fb96c)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://gist.github.com/FeepingCreature/5dff669aad380a123b15659e195fb96c](https://gist.github.com/FeepingCreature/5dff669aad380a123b15659e195fb96c)
- en: 'Speed up your code: don''t pass structs bigger than 16 bytes on AMD64'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加速你的代码：不要在AMD64上传递大于16字节的结构体
- en: '[](#speed-up-your-code-dont-pass-structs-bigger-than-16-bytes-on-amd64)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[](#speed-up-your-code-dont-pass-structs-bigger-than-16-bytes-on-amd64)'
- en: Or "How I sped up [Neat](https://neat-lang.github.io) by a factor of 2x".
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 或者称为“如何将[Neat](https://neat-lang.github.io)的速度提升了2倍”。
- en: '* * *'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: If you check the [related_post_gen](https://github.com/jinyus/related_post_gen/)
    benchmark, you will find that Neat, my language, has moved up a few spots. How
    did I achieve this? Did I implement new high-level optimizer passes that use language
    details to expose hidden optimization potential?
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您检查[related_post_gen](https://github.com/jinyus/related_post_gen/)基准测试，您会发现我的语言Neat已经上升了几个位置。我是如何做到这一点的？我是否实现了新的高级优化器通行证，利用语言细节来暴露隐藏的优化潜力？
- en: I changed arrays to be passed as three pointer parameters instead of one parameter
    consisting of a three-pointer struct. That's it.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我将数组更改为作为三个指针参数传递，而不是一个由三个指针结构组成的参数。就是这样。
- en: This problem has been vexing me for a long time. Neat seemed weirdly slower
    than it should have been, particularly compared to D, and if I looked at a profiler
    I would be seeing a lot of weird stack moves. The compiler seemed to be spending
    most of its time rearranging large amounts of the stack for function calls.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题困扰着我很长时间。Neat似乎比应该的慢得多，特别是与D相比，如果我查看分析器，我会看到很多奇怪的堆栈移动。编译器似乎把大部分时间都花在重新排列大量堆栈以进行函数调用上。
- en: Why are Neat arrays three pointers? As opposed to D, Neat employs a refcounter.
    That means that arrays, in addition to start and end, also need a pointer to the
    base of the array object, where the reference count is stored. It turns out the
    reason that D arrays are fast and Neat arrays are so slow is just because having
    24 bytes instead of 16 puts them into a different regime of parameter passing.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么Neat数组是三个指针？与D语言不同，Neat使用引用计数器。这意味着数组除了起始和结束外，还需要指向数组对象基址的指针，该基址存储了引用计数。事实证明，D数组之所以快而Neat数组之所以如此慢，仅仅是因为24字节而不是16字节将它们置于不同的参数传递模式。
- en: If we check [the SystemV AMD64 ABI specification](https://refspecs.linuxbase.org/elf/x86_64-abi-0.99.pdf)
    (PDF), it tells us that any struct greater than 16 bytes is passed by pointer.
    ("If the size of the aggregate exceeds two eightbytes and the first eightbyte
    isn’t SSE or any other eightbyte isn’t SSEUP, the whole argument is passed in
    memory.") To pass a struct by memory, we allocate a struct-sized spot on the stack,
    fill it with the values we pass, then pass the pointer to the function.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们检查[SystemV AMD64 ABI规范](https://refspecs.linuxbase.org/elf/x86_64-abi-0.99.pdf)（PDF），它告诉我们，任何大于16字节的结构体都是通过指针传递的。（“如果聚合物的大小超过两个八字节，并且第一个八字节不是SSE或其他任何八字节不是SSEUP，则整个参数将通过内存传递。”）要通过内存传递结构体，我们在堆栈上分配一个结构体大小的位置，用我们传递的值填充它，然后将指针传递给函数。
- en: Now, LLVM is a very good optimizer, but this does not leave it much room. The
    value *has* to go on the stack, which means there must be space for it there,
    it must be copied out of the register it is probably living in, and it has to
    remember which parts of the stack are in use and which ones can be reused by another
    call, which it turns out to be pretty poor at.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，LLVM是一个非常好的优化器，但这并不给它留下太多余地。值*必须*放在堆栈上，这意味着必须在堆栈上有空间，必须将其从可能存放在的寄存器中复制出来，并且必须记住堆栈的哪些部分正在使用，哪些部分可以被另一个调用重用，而这在这方面表现得相当差。
- en: 'We can demonstrate the issue with this benchmark:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过这个基准测试来证明这个问题：
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As you can see, depending on parameters, this either passes some values as separate
    parameters or a single large struct. The mode and run length are passed on the
    commandline to prevent the optimizer from constant folding everything.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，根据参数的不同，这要么将一些值作为单独的参数传递，要么作为一个单独的大型结构体传递。模式和运行长度被传递到命令行上，以防止优化器将所有内容都折叠成常数。
- en: 'We must compile impl.c separately to avoid inlining:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须单独编译impl.c以避免内联：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This is hardly subtle: with just the change of passing three separate fields
    instead of a vector struct, I go from 12.3 seconds to 5.3 seconds!'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是微妙的变化：仅通过传递三个单独的字段而不是一个向量结构，我就从12.3秒变成了5.3秒！
- en: If we check the assembly, we can indeed see that a lot of instructions are occupied
    with stack shuffles. In fact, a major benefit of the field version is that the
    parameters already enter the function in SSE registers, rather than having to
    be loaded from the stack every time. This was the whole point of the SystemV ABI
    and its focus on passing values in registers as much as possible, so it's kind
    of sad to see it fail here. I believe with the number of registers available on
    AMD64, a benchmark would have shown by-value passing to be valuable even for types
    above 16 bytes.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们检查汇编代码，我们确实可以看到有很多指令用于堆栈重排。事实上，字段版本的一个主要好处是参数已经以 SSE 寄存器的形式进入函数，而不必每次都从堆栈加载。这就是
    SystemV ABI 的整个重点，以及它专注于尽可能在寄存器中传递值的原因，所以看到它在这里失败有点令人沮丧。我相信，考虑到 AMD64 上可用的寄存器数量，基准测试会显示对于超过
    16 字节的类型，按值传递是有价值的。
- en: In fact, if you think about what the code does, by writing the fields on the
    stack and then (explicitly rather than implicitly) passing a pointer, the (new,
    performant) AMD64 System V ABI has effectively regressed to the old x86 cdecl
    ABI, where everything was passed on the stack! Cdecl, famously, was so known for
    its slowness that it spawned multiple calling conventions aimed just at making
    it fast.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，如果你考虑代码所做的事情，通过在堆栈上写入字段，然后（显式而不是隐式地）传递一个指针，（新的、高效的）AMD64 系统 V ABI 事实上已经退化为旧的
    x86 cdecl ABI，其中所有东西都是通过堆栈传递的！Cdecl 以其慢而著称，以至于它衍生出了多种旨在加速的调用约定。
- en: Of course, in any real situation this code would be all inlined. In fact, turning
    on LTO with gcc (though interestingly not clang!) erases any performance difference
    between the two versions. But still, not every function can or should be inlined.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在任何真实的情况下，这段代码都会被全部内联。事实上，使用 gcc 打开 LTO（尽管有趣的是 clang 不会！）会消除两个版本之间的任何性能差异。但是，还是不是每个函数都能或应该被内联。
- en: Now, if you are calling a C API, you have to use the C ABI. But lots of high-level
    types internal to non-C languages, though they may be presented to the compiler's
    backend as a struct (such as Neat's three-pointer arrays), don't strictly speaking
    *need* to be expressed as one. You are the language writer, and it's up to you
    to decide how arrays, tuples, sumtypes etc. are passed. That's why I chose to
    pass all of those (if above 16 bytes) as individual fields instead, and the benchmark
    shows the benefit.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你调用的是 C API，你必须使用 C ABI。但是，许多非 C 语言内部的高级类型，尽管它们可能被呈现给编译器的后端作为一个结构体（例如 Neat
    的三指针数组），严格来说并不需要*严格*被表示为一个。你是语言的编写者，你可以决定如何传递数组、元组、和 sumtypes 等。这就是为什么我选择将这些所有的东西（如果超过
    16 个字节）都作为单独的字段传递，而且基准测试显示了好处。
- en: So if you are on AMD64, and you're either working on languages or microoptimizing
    an API, I advise you to take the free speedup. You should at least benchmark to
    see if you can benefit from splitting structs above 16 bytes manually. Especially
    in inner loops, the benefit can be surprisingly large.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果你在 AMD64 上，并且你要么在开发语言，要么在微优化 API，我建议你利用这个免费的加速。你至少应该进行基准测试，看看是否可以从手动拆分超过
    16 个字节的结构体中受益。特别是在内部循环中，好处可能会出乎意料地大。
- en: 'Addendum:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 附录：
- en: 'Q: Sure, maybe this is true for structs of pointers. But `double` is in class
    SSE, according to the spec. Why isn''t the struct passed in SSE registers anyways?'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Q: 当然，或许对指针结构体来说这是正确的。但是，根据规范，`double`是在 SSE 类中的。为什么结构体不会被传递到 SSE 寄存器中呢？'
- en: 'A: Man I don''t know. All I can tell you is that it doesn''t.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'A: 哥们，我不知道。我能告诉你的就是它没有。'
