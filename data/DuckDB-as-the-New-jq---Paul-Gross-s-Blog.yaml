- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-29 12:32:42'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-29 12:32:42
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: DuckDB as the New jq - Paul Gross’s Blog
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DuckDB 作为新的 jq - Paul Gross 的博客
- en: 来源：[https://www.pgrs.net/2024/03/21/duckdb-as-the-new-jq/](https://www.pgrs.net/2024/03/21/duckdb-as-the-new-jq/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.pgrs.net/2024/03/21/duckdb-as-the-new-jq/](https://www.pgrs.net/2024/03/21/duckdb-as-the-new-jq/)
- en: Recently, I’ve been interested in the [DuckDB](https://duckdb.org/) project
    (like a [SQLite](https://www.sqlite.org/) geared towards data applications). And
    one of the amazing features is that it has many data importers included without
    requiring extra dependencies. This means it can natively read and parse JSON as
    a database table, among many other formats.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我对 [DuckDB](https://duckdb.org/) 项目很感兴趣（类似于面向数据应用的 [SQLite](https://www.sqlite.org/)）。其中一个令人惊讶的特性是，它包含许多数据导入工具，无需额外的依赖项。这意味着它可以原生地读取和解析
    JSON 作为数据库表，还支持多种其他格式。
- en: I work extensively with JSON day to day, and I often reach for [jq](https://jqlang.github.io/jq/)
    when exploring documents. I love `jq`, but I find it hard to use. The syntax is
    super powerful, but I have to study the docs anytime I want to do anything beyond
    just selecting fields.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我每天都在大量使用 JSON，并且在探索文档时常常使用 [jq](https://jqlang.github.io/jq/)。我喜欢 `jq`，但发现它难以使用。语法非常强大，但除了选择字段之外，我想做其他操作时都必须研究文档。
- en: Once I learned DuckDB could read JSON files directly into memory, I realized
    that I could use it for many of the things where I’m currently using `jq`. In
    contrast to the complicated and custom `jq` syntax, I’m very familiar with SQL
    and use it almost daily.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我了解到 DuckDB 可以直接将 JSON 文件读入内存，我意识到我可以用它来替代目前使用 `jq` 的许多工作。与复杂和定制的 `jq` 语法相比，我对
    SQL 非常熟悉，几乎每天都在使用。
- en: 'Here’s an example:'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个例子：
- en: 'First, we fetch some sample JSON to play around with. I used the GitHub API
    to grab the repository information from the golang org:'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们获取一些示例 JSON 进行玩耍。我使用 GitHub API 从 golang org 获取了存储库信息：
- en: '[PRE0]'
  id: totrans-split-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now, as a sample question to answer, let’s get some stats on the types of open
    source licenses used.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，作为一个示例问题来回答，让我们获取一些关于开源许可证类型的统计数据。
- en: 'The JSON structure looks like this:'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 的结构如下：
- en: '[PRE1]'
  id: totrans-split-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This might not be the best way, but here is what I cobbled together after searching
    and reading some docs for how to do this in `jq`:'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能不是最佳方式，但这是我在搜索和阅读一些文档后，使用 `jq` 拼凑起来的东西：
- en: '[PRE2]'
  id: totrans-split-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'And here is what it looks like in DuckDB using SQL:'
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在 DuckDB 中使用 SQL 的样子：
- en: '[PRE3]'
  id: totrans-split-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: For me, this SQL is much simpler and I was able to write it without looking
    at any docs. The only tricky part is querying nested JSON with the `->>` operator.
    The syntax is the same as the [PostgreSQL JSON Functions](https://www.postgresql.org/docs/current/functions-json.html),
    however, so I was familiar with it.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，这个 SQL 更简单，我能够在不查看任何文档的情况下编写它。唯一棘手的部分是使用 `->>` 操作符查询嵌套 JSON。然而，其语法与 [PostgreSQL
    JSON 函数](https://www.postgresql.org/docs/current/functions-json.html) 相同，因此我对此很熟悉。
- en: 'And if we do need the output in JSON, there’s a DuckDB flag for that:'
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们确实需要 JSON 格式的输出，DuckDB 也有相应的标志：
- en: '[PRE4]'
  id: totrans-split-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can still even pretty print with `jq` at the end, after using DuckDB to
    do the heavy lifting:'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在使用 DuckDB 进行大量工作之后，我们仍然可以使用 `jq` 进行漂亮的打印：
- en: '[PRE5]'
  id: totrans-split-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: JSON is just one of the many ways of importing data into DuckDB. This same approach
    would work for CSVs, parquet, Excel files, etc.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: JSON 只是将数据导入 DuckDB 的多种方法之一。这种方法也适用于 CSV、parquet、Excel 文件等。
- en: And I could choose to create tables and persist locally, but often I’m just
    interrogating data and don’t need the persistence.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: 而我可以选择创建表并将数据持久化存储，但通常只是查询数据，不需要持久性。
- en: 'Read more about DuckDB’s great JSON support in this blog post: [Shredding Deeply
    Nested JSON, One Vector at a Time](https://duckdb.org/2023/03/03/json.html)'
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读更多关于 DuckDB 在此博客文章中出色的 JSON 支持：[深度嵌套 JSON 的解析，逐向量进行](https://duckdb.org/2023/03/03/json.html)
- en: '**Update:**'
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**更新：**'
- en: 'I also learned that DuckDB can read the JSON directly from a URL, not just
    a local file:'
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我还了解到 DuckDB 不仅可以从本地文件，而且可以直接从 URL 读取 JSON：
- en: '[PRE6]'
  id: totrans-split-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
