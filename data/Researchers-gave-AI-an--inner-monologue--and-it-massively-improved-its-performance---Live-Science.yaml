- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-29 12:42:46'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-29 12:42:46
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Researchers gave AI an 'inner monologue' and it massively improved its performance
    | Live Science
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 研究人员为AI提供了一种“内心独白”，显著提高了其性能 | Live Science
- en: 来源：[https://www.livescience.com/technology/artificial-intelligence/researchers-gave-ai-an-inner-monologue-and-it-massively-improved-its-performance](https://www.livescience.com/technology/artificial-intelligence/researchers-gave-ai-an-inner-monologue-and-it-massively-improved-its-performance)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.livescience.com/technology/artificial-intelligence/researchers-gave-ai-an-inner-monologue-and-it-massively-improved-its-performance](https://www.livescience.com/technology/artificial-intelligence/researchers-gave-ai-an-inner-monologue-and-it-massively-improved-its-performance)
- en: Giving artificial intelligence (AI) systems an "inner monologue" makes them
    considerably better at reasoning, new research shows.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 给予人工智能（AI）系统一个“内心独白”使它们在推理方面显著提升，新研究显示。
- en: The method trains AI systems to think before they respond to prompts, just as
    many people consider what we should say next before we speak. This is different
    from the way scientists have trained mainstay AI chatbots, like ChatGPT, which
    don't "think" about what they write or anticipate different possibilities for
    the next steps in a conversation.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法训练AI系统在回答提示之前先思考，就像许多人在讲话之前考虑接下来应该说什么一样。这与科学家们训练的像ChatGPT这样的主流AI聊天机器人的方式不同，它们不“思考”自己写的内容或预测对话下一步可能出现的不同可能性。
- en: Dubbed "Quiet-STaR," the new method instructs an AI system to generate many
    inner rationales in parallel before responding to a conversational prompt. When
    the AI answers prompts, it generates a mixture of these predictions with and without
    a rationale, printing the best answer — which can be verified by a human participant
    depending on the nature of the question.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 新方法名为"Quiet-STaR"，指导AI系统在回答对话提示之前并行生成多个内部推理。当AI回答提示时，它生成这些预测的混合，有些带有推理，有些没有，输出最佳答案
    —— 可以由人类参与者根据问题的性质进行验证。
- en: Finally, it learns by discarding rationales that proved incorrect. In effect,
    the training method gives AI agents the capacity to anticipate future conversations
    and learn from ongoing ones.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，它通过丢弃证明不正确的推理来学习。实际上，该训练方法赋予了AI代理能力，使其能够预测未来的对话并从进行中的对话中学习。
- en: '**Related:** [**AI singularity may come in 2027 with artificial ''super intelligence''
    sooner than we think, says top scientist**](https://www.livescience.com/technology/artificial-intelligence/ai-agi-singularity-in-2027-artificial-super-intelligence-sooner-than-we-think-ben-goertzel)'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**相关文章：**[**AI的奇点可能会在2027年到来，人工“超级智能”比我们想象的更早，顶级科学家称**](https://www.livescience.com/technology/artificial-intelligence/ai-agi-singularity-in-2027-artificial-super-intelligence-sooner-than-we-think-ben-goertzel)'
- en: The researchers applied the Quiet-STaR algorithm to Mistral 7B, an open-source
    large language model (LLM), and posted the results March 14 to the pre-print database
    [arXiv](https://arxiv.org/pdf/2403.09629.pdf). (The paper has not yet been peer-reviewed.)
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员将Quiet-STaR算法应用于Mistral 7B，一个开源大型语言模型（LLM），并于3月14日将结果发布到预印本数据库[arXiv](https://arxiv.org/pdf/2403.09629.pdf)。
    （该论文尚未经同行评审。）
- en: The Quiet-STaR-trained version of Mistral 7B scored 47.2% on a reasoning test
    versus 36.3% before any training. It still flunked a school math test, earning
    a score of 10.9%. But that was nearly double the starting score of 5.9% in the
    vanilla version.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: Quiet-STaR训练版本的Mistral 7B在推理测试中得分为47.2%，而之前未经任何训练时仅为36.3%。它仍然在学校数学测试中不及格，得分为10.9%。但这几乎是香草版本起始得分5.9%的两倍。
- en: Get the world’s most fascinating discoveries delivered straight to your inbox.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 将世界上最令人着迷的发现直接发送到您的收件箱。
- en: Models like ChatGPT and Gemini are built from neural networks — collections
    of machine learning algorithms arranged in a way that mimics the structure and
    learning patterns of the [human brain](https://www.livescience.com/29365-human-brain.html).
    However, systems built using this architecture are abysmal at common sense reasoning
    or contextualization — and AI chatbots do not have genuine "understanding."
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 像ChatGPT和Gemini这样的模型是由神经网络构建的 —— 这些机器学习算法的集合排列方式模仿了[人脑](https://www.livescience.com/29365-human-brain.html)的结构和学习模式。然而，使用此架构构建的系统在常识推理或语境化方面表现不佳
    —— AI聊天机器人没有真正的"理解"。
- en: Past attempts to improve the reasoning capabilities of LLMs have been highly
    domain-specific and could not be applied to different types of AI models.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 以往改善LLM推理能力的尝试高度特定于领域，并且无法应用于不同类型的AI模型。
- en: The self-taught reasoner (STaR) algorithm, which the researchers used as a basis
    for their work, is one example of such a training algorithm — but is held back
    by these limitations.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员使用的自学推理算法（STaR），作为他们工作的基础之一，就是这种训练算法的一个例子 — 但受到这些限制的制约。
- en: The scientists who developed Quiet-STaR named it that because the principles
    of STaR can be applied quietly in the background and generally over several different
    types of LLM, independent of the original training data. Now they want to investigate
    how techniques like theirs can reduce the gap between neural network-based AI
    systems and human-like reasoning capabilities.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 开发Quiet-STaR的科学家们将其命名为这样是因为STaR的原则可以在背景中悄悄应用，并且通常可以在多种不同类型的LLM上独立于原始训练数据。现在，他们希望调查像他们这样的技术如何缩小基于神经网络的人工智能系统与类人推理能力之间的差距。
