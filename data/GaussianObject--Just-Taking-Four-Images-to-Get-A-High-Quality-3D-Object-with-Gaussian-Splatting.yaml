- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 15:03:23'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 15:03:23'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'GaussianObject: Just Taking Four Images to Get A High-Quality 3D Object with
    Gaussian Splatting'
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'GaussianObject: 只需四张图像即可实现高质量的三维物体重建与渲染，采用高斯飞溅技术'
- en: 来源：[https://gaussianobject.github.io/](https://gaussianobject.github.io/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://gaussianobject.github.io/](https://gaussianobject.github.io/)
- en: 'Reconstructing and rendering 3D objects from highly sparse views is of critical
    importance for promoting applications of 3D vision techniques and improving user
    experience. However, images from sparse views only contain very limited 3D information,
    leading to two significant challenges: 1) Difficulty in building multi-view consistency
    as images for matching are too few; 2) Partially omitted or highly compressed
    object information as view coverage is insufficient. To tackle these challenges,
    we propose GaussianObject, a framework to represent and render the 3D object with
    Gaussian splatting, that achieves high rendering quality with only **4 input images**.
    We first introduce techniques of visual hull and floater elimination which explicitly
    inject structure priors into the initial optimization process for helping build
    multi-view consistency, yielding a coarse 3D Gaussian representation. Then we
    construct a Gaussian repair model based on diffusion models to supplement the
    omitted object information, where Gaussians are further refined. We design a self-generating
    strategy to obtain image pairs for training the repair model. Our GaussianObject
    is evaluated on several challenging datasets, including MipNeRF360, OmniObject3D,
    and OpenIllumination, achieving strong reconstruction results from **only 4 views**
    and significantly outperforming previous state-of-the-art methods.'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 从高度稀疏视图中重建和渲染三维物体对于推动三维视觉技术的应用和提高用户体验至关重要。然而，来自稀疏视图的图像仅包含非常有限的三维信息，导致存在两个重大挑战：1）由于匹配图像过少，构建多视角一致性困难；2）由于视角覆盖不足，对象信息部分缺失或高度压缩。为了应对这些挑战，我们提出了GaussianObject，一种使用高斯飞溅表示和渲染三维物体的框架，仅使用**4张输入图像**即可实现高质量渲染。我们首先引入了视觉轮廓和浮子消除技术，明确将结构先验注入到初始优化过程中，帮助构建多视角一致性，得到粗略的三维高斯表示。然后，基于扩散模型构建了高斯修复模型，以补充省略的对象信息，进一步细化高斯分布。我们设计了自动生成策略，用于获取训练修复模型的图像对。我们在几个具有挑战性的数据集上评估了GaussianObject，包括MipNeRF360、OmniObject3D和OpenIllumination，从**仅有4个视角**中实现了强大的重建结果，并显著优于先前的最新方法。
