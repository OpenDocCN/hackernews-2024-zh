- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-29 12:44:52'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-29 12:44:52'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: How We’ll Reach a 1 Trillion Transistor GPU - IEEE Spectrum
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何实现1万亿晶体管GPU - IEEE Spectrum
- en: 来源：[https://spectrum.ieee.org/trillion-transistor-gpu](https://spectrum.ieee.org/trillion-transistor-gpu)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://spectrum.ieee.org/trillion-transistor-gpu](https://spectrum.ieee.org/trillion-transistor-gpu)
- en: In 1997 the [IBM Deep Blue](https://www.ibm.com/history/deep-blue) supercomputer
    defeated world chess champion Garry Kasparov. It was a groundbreaking demonstration
    of supercomputer technology and a first glimpse into how high-performance computing
    might one day overtake human-level intelligence. In the 10 years that followed,
    we began to use [artificial intelligence](https://spectrum.ieee.org/topic/artificial-intelligence/)
    for many practical tasks, such as facial recognition, language translation, and
    recommending movies and merchandise.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 1997年，[IBM Deep Blue](https://www.ibm.com/history/deep-blue)超级计算机击败了世界国际象棋冠军加里·卡斯帕罗夫。这是超级计算技术的突破性展示，也是高性能计算有望有一天超越人类智能的第一瞥。在随后的10年里，我们开始将[人工智能](https://spectrum.ieee.org/topic/artificial-intelligence/)应用于许多实际任务，如人脸识别、语言翻译，以及推荐电影和商品。
- en: Fast-forward another decade and a half and artificial intelligence has advanced
    to the point where it can “synthesize knowledge.” Generative AI, such as [ChatGPT](https://spectrum.ieee.org/tag/chatgpt)
    and [Stable Diffusion](https://spectrum.ieee.org/tag/stable-diffusion), can compose
    poems, create artwork, [diagnose](https://spectrum.ieee.org/chatgpt-medical-exam)
    disease, write summary reports and [computer code](https://github.com/features/copilot),
    and even design integrated circuits that rival those made by humans.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 进入另一个十年半的快速发展，人工智能已经发展到可以“综合知识”的程度。生成式人工智能，如[ChatGPT](https://spectrum.ieee.org/tag/chatgpt)和[Stable
    Diffusion](https://spectrum.ieee.org/tag/stable-diffusion)，可以创作诗歌、创建艺术作品，[诊断](https://spectrum.ieee.org/chatgpt-medical-exam)疾病，编写总结报告和[计算机代码](https://github.com/features/copilot)，甚至设计与人类制造的集成电路相媲美的集成电路。
- en: Tremendous opportunities lie ahead for artificial intelligence to become a digital
    assistant to all human endeavors. [ChatGPT](https://spectrum.ieee.org/tag/chatgpt)
    is a good example of how AI has democratized the use of high-performance computing,
    providing benefits to every individual in society.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能有着巨大的机会成为所有人类努力的数字助理。[ChatGPT](https://spectrum.ieee.org/tag/chatgpt)是人工智能如何使高性能计算民主化的一个很好的例子，为社会中的每个个体提供了好处。
- en: 'All those marvelous AI applications have been due to three factors: innovations
    in efficient machine-learning algorithms, the availability of massive amounts
    of data on which to train neural networks, and progress in energy-efficient computing
    through the advancement of semiconductor technology. This last contribution to
    the generative AI revolution has received less than its fair share of credit,
    despite its ubiquity.'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些神奇的人工智能应用都归功于三个因素：高效的机器学习算法的创新，大量数据的可用性用于训练神经网络，以及通过半导体技术的进步在能效计算方面的进展。尽管其普及性，这些对生成式人工智能革命的最后贡献却未能得到应有的赞誉。
- en: Over the last three decades, the major milestones in AI were all enabled by
    the leading-edge semiconductor technology of the time and would have been impossible
    without it. Deep Blue was implemented with a mix of 0.6- and 0.35-micrometer-node
    chip-manufacturing technology. The deep neural network that won the ImageNet competition,
    kicking off the current era of machine learning, was [implemented with 40-nanometer
    technology](https://www.techpowerup.com/gpu-specs/geforce-gtx-580.c270). [AlphaGo
    conquered the game of Go](https://spectrum.ieee.org/alphago-wins-match-against-top-go-player)
    using 28-nm technology, and the initial version of ChatGPT was trained on computers
    built with 5-nm technology. The most recent incarnation of ChatGPT is powered
    by servers using even more advanced [4-nm technology](https://www.tsmc.com/english/dedicatedFoundry/technology/logic/l_5nm).
    Each layer of the computer systems involved, from software and algorithms down
    to the architecture, circuit design, and device technology, acts as a multiplier
    for the performance of AI. But it’s fair to say that the foundational transistor-device
    technology is what has enabled the advancement of the layers above.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的三十年里，AI的重要里程碑都是由当时先进的半导体技术实现的，并且如果没有这些技术，这些里程碑将是不可能的。深蓝使用了0.6微米和0.35微米节点芯片制造技术的混合实现。赢得ImageNet比赛的深度神经网络，开启了当前机器学习时代，使用的是
    [40纳米技术](https://www.techpowerup.com/gpu-specs/geforce-gtx-580.c270)。[AlphaGo征服围棋](https://spectrum.ieee.org/alphago-wins-match-against-top-go-player)
    使用的是28纳米技术，而ChatGPT的最初版本是在使用了5纳米技术的计算机上训练的。最新版本的ChatGPT则由使用更先进的 [4纳米技术](https://www.tsmc.com/english/dedicatedFoundry/technology/logic/l_5nm)
    的服务器驱动。涉及到的计算机系统每一层，从软件和算法到架构、电路设计和器件技术，都是AI性能的乘数。但可以说，作为上述各层的基础的晶体管器件技术正是推动了上述层次进步的关键。
- en: If the AI revolution is to continue at its current pace, it’s going to need
    even more from the semiconductor industry. Within a decade, it will need a 1-trillion-transistor
    GPU—that is, a GPU with 10 times as many devices as is typical today.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果AI革命要以目前的速度继续发展，它将需要半导体行业提供更多支持。在未来十年内，将需要一颗具有1万亿个晶体管的GPU——即比今天典型设备多10倍的设备数量。
- en: Advances in semiconductor technology [top line]—including new materials, advances
    in lithography, new types of transistors, and advanced packaging—have driven the
    development of more capable AI systems [bottom line]
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 半导体技术的进步 [顶线]——包括新材料、光刻技术的进步、新型晶体管和先进封装——推动了更强大AI系统 [底线] 的发展。
- en: Relentless Growth in AI Model Sizes
  id: totrans-split-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI模型大小的无情增长
- en: The computation and memory access required for AI training have increased by
    orders of magnitude in the past five years. Training [GPT-3](https://spectrum.ieee.org/tag/gpt-3),
    for example, requires the equivalent of more than 5 billion billion operations
    per second of computation for an entire day (that’s 5,000 petaflops-days), and
    3 trillion bytes (3 terabytes) of memory capacity.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 过去五年中，用于AI训练的计算和内存访问需求增长了数个数量级。例如，训练 [GPT-3](https://spectrum.ieee.org/tag/gpt-3)
    需要相当于每秒超过5千亿亿次操作的计算能力，持续一整天（即5,000 petaflops-days），以及3万亿字节（3 TB）的内存容量。
- en: 'Both the computing power and the memory access needed for new generative AI
    applications continue to grow rapidly. We now need to answer a pressing question:
    How can semiconductor technology keep pace?'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 新一代生成式AI应用所需的计算能力和内存访问继续快速增长。现在我们需要回答一个紧迫的问题：半导体技术如何跟上这一步伐？
- en: From Integrated Devices to Integrated Chiplets
  id: totrans-split-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从集成设备到集成芯片组
- en: Since the invention of the integrated circuit, semiconductor technology has
    been about scaling down in feature size so that we can cram more transistors into
    a thumbnail-size chip. Today, integration has risen one level higher; we are going
    beyond 2D scaling into [3D system integration](https://spectrum.ieee.org/tag/3d-integration).
    We are now putting together many chips into a tightly integrated, massively interconnected
    system. This is a paradigm shift in semiconductor-technology integration.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 自集成电路发明以来，半导体技术一直致力于特征尺寸的缩小，以便将更多的晶体管集成到拇指大小的芯片中。今天，集成提升了一个层次；我们正在超越2D缩放进入 [3D系统集成](https://spectrum.ieee.org/tag/3d-integration)
    领域。我们现在正在将许多芯片集成到一个紧密连接的、大规模互联的系统中。这是半导体技术集成的一个范式转变。
- en: In the era of AI, the capability of a system is directly proportional to [the
    number of transistors integrated into that system](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9063714).
    One of the main limitations is that lithographic chipmaking tools have been designed
    to make ICs of no more than about 800 square millimeters, what’s called the reticle
    limit. But we can now extend the size of the integrated system beyond lithography’s
    reticle limit. By attaching several chips onto a larger interposer—a piece of
    silicon into which interconnects are built—we can integrate a system that contains
    a much larger number of devices than what is possible on a single chip. For example,
    TSMC’s [chip-on-wafer-on-substrate](https://ieeexplore.ieee.org/document/9501649)
    (CoWoS) technology can accommodate up to six reticle fields’ worth of compute
    chips, along with a dozen high-bandwidth-memory (HBM) chips.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AI 时代，系统的能力与 [集成到该系统中的晶体管数量](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9063714)
    成正比。主要的限制之一是，光刻芯片制造工具被设计为制造不超过约 800 平方毫米的 IC，即所谓的掩模限制。但现在我们可以超越光刻的掩模限制扩展集成系统的大小。通过将多个芯片连接到一个更大的中间接合层——一块内建互连的硅片——我们可以集成一个包含比单个芯片上可能的设备数量多得多的系统。例如，台积电的
    [芯片-晶圆-基板](https://ieeexplore.ieee.org/document/9501649) (CoWoS) 技术可以容纳多达六个掩模字段的计算芯片，以及十几块高带宽内存
    (HBM) 芯片。
- en: 'HBMs are an example of the other key semiconductor technology that is increasingly
    important for AI: the ability to integrate systems by stacking chips atop one
    another, what we at TSMC call [system-on-integrated-chips (SoIC)](https://ieeexplore.ieee.org/document/8811194).
    An HBM consists of a stack of vertically interconnected chips of DRAM atop a control
    logic IC. It uses vertical interconnects called through-silicon-vias (TSVs) to
    get signals through each chip and solder bumps to form the connections between
    the memory chips. Today, high-performance GPUs use HBMextensively.'
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: HBMs 是另一种关键的半导体技术示例，对于人工智能越来越重要：通过在芯片上堆叠，我们在台积电称之为 [系统级集成芯片 (SoIC)](https://ieeexplore.ieee.org/document/8811194)。一个
    HBM 由一个垂直互连的 DRAM 芯片堆叠在控制逻辑 IC 之上组成。它使用称为硅通孔 (TSVs) 的垂直互连来传输每个芯片的信号，并使用焊球连接存储芯片之间的连接。如今，高性能
    GPU 广泛使用 HBM。
- en: Going forward, 3D SoIC technology can provide a “bumpless alternative” to the
    conventional HBM technology of today, delivering far denser vertical interconnection
    between the stacked chips. Recent advances have shown [HBM test structures with
    12 layers](https://ieeexplore.ieee.org/document/9265044) of chips stacked using
    hybrid bonding, a copper-to-copper connection with a higher density than solder
    bumps can provide. Bonded at low temperature on top of a larger base logic chip,
    this memory system has a total thickness of just 600 µm.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 未来，3D SoIC 技术可以提供传统 HBM 技术的 "无突起" 替代方案，提供更密集的垂直互连，用于堆叠芯片。最近的进展展示了使用混合键合的 [具有
    12 层堆叠芯片的 HBM 测试结构](https://ieeexplore.ieee.org/document/9265044)，这种铜-铜连接比焊球提供的密度更高。这种存储系统在更大的基础逻辑芯片上低温键合，总厚度仅为
    600 微米。
- en: With a high-performance computing system composed of a large number of dies
    running large AI models, high-speed wired communication may quickly limit the
    computation speed. Today, optical interconnects are already being used to connect
    server racks in data centers. We will soon need [optical interfaces](https://ieeexplore.ieee.org/document/10195595)
    based on [silicon photonics that are packaged together with GPUs and CPUs](https://spectrum.ieee.org/optical-interconnects).
    This will allow the scaling up of energy- and area-efficient bandwidths for direct,
    optical GPU-to-GPU communication, such that hundreds of servers can behave as
    a single giant GPU with a unified memory. Because of the demand from AI applications,
    silicon photonics will become one of the semiconductor industry’s most important
    enabling technologies.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 一个由大量运行大型 AI 模型的晶片组成的高性能计算系统，高速有线通信可能会迅速限制计算速度。如今，光互连已经被用于连接数据中心中的服务器机架。我们很快将需要基于
    [光学接口](https://ieeexplore.ieee.org/document/10195595)，其基于 [硅光子学与 GPU 和 CPU 打包在一起](https://spectrum.ieee.org/optical-interconnects)。这将允许能效高且面积效率高的带宽直接光学
    GPU 到 GPU 通信的扩展，使得数百台服务器可以作为单一巨型 GPU 运行，拥有统一内存。由于来自 AI 应用的需求，硅光子学将成为半导体行业最重要的支持技术之一。
- en: Toward a Trillion Transistor GPU
  id: totrans-split-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 朝向万亿晶体管 GPU
- en: As noted already, typical GPU chips used for AI training have already reached
    the reticle field limit. And their transistor count is about 100 billion devices.
    The continuation of the trend of increasing transistor count will require multiple
    chips, interconnected with 2.5D or 3D integration, to perform the computation.
    The integration of multiple chips, either by CoWoS or SoIC and related advanced
    packaging technologies, allows for a much larger total transistor count per system
    than can be squeezed into a single chip. We forecast that within a decade a multichiplet
    GPU will have more than 1 trillion transistors.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 正如已经指出的，用于AI训练的典型GPU芯片已经达到了光刻胶片的领域限制。它们的晶体管数量约为1000亿个器件。继续增加晶体管数量的趋势将需要多个芯片通过2.5D或3D集成互连来执行计算。通过CoWoS或SoIC等相关先进封装技术集成多个芯片，允许每个系统的总晶体管数量比单个芯片能够容纳的要多得多。我们预测，在未来十年内，一个多芯片GPU将拥有超过1万亿个晶体管。
- en: We’ll need to link all these [chiplets](https://spectrum.ieee.org/tag/chiplets)
    together in a 3D stack, but fortunately, industry has been able to rapidly scale
    down the pitch of vertical interconnects, increasing the density of connections.
    And there is plenty of room for more. We see no reason why the interconnect density
    can’t grow by an order of magnitude, and even beyond.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要将所有这些[芯片块](https://spectrum.ieee.org/tag/chiplets)堆叠在3D堆栈中，但幸运的是，行业已经能够快速缩小垂直互连的间距，增加连接的密度。而且还有很大的发展空间。我们认为，互连密度的增长不会止步于一个数量级，甚至会超越。
- en: Energy-Efficient Performance Trend for GPUs
  id: totrans-split-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPU的能效性能趋势
- en: So, how do all these innovative hardware technologies contribute to the performance
    of a system?
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，所有这些创新的硬件技术如何为系统的性能做出贡献？
- en: We can see the trend already in server GPUs if we look at the steady improvement
    in a metric called energy-efficient performance. EEP is a combined measure of
    the energy efficiency and speed of a system. Over the past 15 years, the semiconductor
    industry has increased energy-efficient performance about threefold every two
    years. We believe this trend will continue at historical rates. It will be driven
    by innovations from many sources, including new materials, device and integration
    technology, [extreme ultraviolet (EUV) lithography](https://spectrum.ieee.org/high-na-euv),
    circuit design, system architecture design, and the co-optimization of all these
    technology elements, among other things.
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们观察服务器GPU在能效性能方面的稳步提升，就可以看到这种趋势已经开始。能效性能是系统能效和速度的综合衡量标准。在过去15年中，半导体行业每两年将能效性能提高约三倍。我们相信这一趋势将以历史速度继续增长。这将得益于来自多个来源的创新，包括新材料、器件和集成技术、[极紫外（EUV）光刻](https://spectrum.ieee.org/high-na-euv)、电路设计、系统架构设计以及所有这些技术元素的协同优化等。
- en: In particular, the EEP increase will be enabled by the advanced packaging technologies
    we’ve been discussing here. Additionally, concepts such as [system-technology
    co-optimization (STCO)](https://spectrum.ieee.org/stco-system-technology-cooptimization),
    where the different functional parts of a GPU are separated onto their own chiplets
    and built using the best performing and most economical technologies for each,
    will become increasingly critical.
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，能效性能的增加将得益于我们在这里讨论过的先进封装技术。此外，像[系统技术协同优化（STCO）](https://spectrum.ieee.org/stco-system-technology-cooptimization)这样的概念，其中GPU的不同功能部件分别集成在其自己的芯片块上，并使用最佳性能和最经济的技术进行构建，将变得越来越关键。
- en: A Mead-Conway Moment for 3D Integrated Circuits
  id: totrans-split-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[三维集成电路的米德康威时刻](https://spectrum.ieee.org/tag/chiplets)'
- en: In 1978, Carver Mead, a professor at the California Institute of Technology,
    and Lynn Conway at Xerox PARC invented a [computer-aided design method for integrated
    circuits](https://ai.eecs.umich.edu/people/conway/VLSI/VLSIText/PP-V2/V2.pdf).
    They used a set of design rules to describe chip scaling so that engineers could
    easily design very-large-scale integration (VLSI) circuits without much knowledge
    of process technology.
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: 1978年，加州理工学院的教授卡弗·米德和施乐帕克斯研究中心的林恩·康威发明了一种[集成电路的计算机辅助设计方法](https://ai.eecs.umich.edu/people/conway/VLSI/VLSIText/PP-V2/V2.pdf)。他们使用一套设计规则来描述芯片的缩放，使工程师可以在不需要太多工艺技术知识的情况下轻松设计非常大规模集成（VLSI）电路。
- en: 'That same sort of capability is needed for 3D chip design. Today, designers
    need to know chip design, system-architecture design, and hardware and software
    optimization. Manufacturers need to know chip technology, 3D IC technology, and
    advanced packaging technology. As we did in 1978, we again need a common language
    to describe these technologies in a way that electronic design tools understand.
    Such a hardware description language gives designers a free hand to work on a
    3D IC system design, regardless of the underlying technology. It’s on the way:
    An open-source standard, called [3Dblox](https://3dblox.org/), has already been
    embraced by most of today’s technology companies and electronic design automation
    (EDA) companies.'
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 对于三维芯片设计同样需要这种能力。今天，设计师需要了解芯片设计、系统架构设计以及硬件和软件优化。制造商需要了解芯片技术、三维集成电路技术和先进封装技术。正如我们在1978年所做的那样，我们再次需要一种共同的语言，以便电子设计工具理解这些技术。这样的硬件描述语言使设计师可以自由地在不考虑底层技术的情况下进行三维集成电路系统设计。这已经在路上：一个名为[3Dblox](https://3dblox.org/)的开源标准已经被大多数当今的技术公司和电子设计自动化（EDA）公司所接受。
- en: The Future Beyond the Tunnel
  id: totrans-split-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 隧道之外的未来
- en: In the era of artificial intelligence, semiconductor technology is a key enabler
    for new AI capabilities and applications. A new GPU is no longer restricted by
    the standard sizes and form factors of the past. New semiconductor technology
    is no longer limited to scaling down the next-generation transistors on a two-dimensional
    plane. An integrated AI system can be composed of as many energy-efficient transistors
    as is practical, an efficient system architecture for specialized compute workloads,
    and an optimized relationship between software and hardware.
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能时代，半导体技术是新的人工智能能力和应用的关键推动者。一个新的 GPU 不再受限于过去的标准尺寸和形态因素。新的半导体技术不再局限于在二维平面上缩小下一代晶体管。一个集成的
    AI 系统可以由尽可能多的节能晶体管组成，这是实际可行的，专门的计算工作负载的高效系统架构，以及软件和硬件之间优化的关系。
- en: 'For the past 50 years, semiconductor-technology development has felt like walking
    inside a tunnel. The road ahead was clear, as there was a well-defined path. And
    everyone knew what needed to be done: shrink the [transistor](https://spectrum.ieee.org/tag/transistor).'
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的50年中，半导体技术的发展感觉像是在隧道内行走。前方的道路清晰，因为有一条明确的路径。每个人都知道需要做的事情：缩小[晶体管](https://spectrum.ieee.org/tag/transistor)。
- en: Now, we have reached the end of the tunnel. From here, semiconductor technology
    will get harder to develop. Yet, beyond the tunnel, many more possibilities lie
    ahead. We are no longer bound by the confines of the past.
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经到达隧道的尽头。从这里开始，半导体技术的发展将变得更加困难。然而，隧道之外，还有许多更多的可能性。我们不再被过去的局限所束缚。
