- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 14:33:55'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 14:33:55'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'NIST 800-207A: Implementing Zero Trust Architecture - InfoQ'
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'NIST 800-207A: 实施零信任架构 - InfoQ'
- en: 来源：[https://www.infoq.com/presentations/nist-800-207a/](https://www.infoq.com/presentations/nist-800-207a/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.infoq.com/presentations/nist-800-207a/](https://www.infoq.com/presentations/nist-800-207a/)
- en: Transcript
  id: totrans-split-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Transcript
- en: 'Butcher: I''m going to talk a little bit about zero trust. We''re going to
    cover a few different things. We''re going to cover these four things primarily.
    We''re going to get a working definition for zero trust that is tangible for folks.
    I''m really tired of the FUD around zero trust, so we with the SP got a very specific
    definition. I''m going to introduce that as identity-based segmentation. We''re
    going to discuss a possible way that we can implement that using a service mesh
    as one of the architectures. More generally, I''m going to outline how we can
    move incrementally from network-oriented policy into identity-based policy.'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 'Butcher: 我将简要讨论零信任。我们将主要涵盖以下四个方面。我们将为零信任得到一个可感知的工作定义。我对围绕零信任的恐慌感到非常疲倦，因此我们和SP已得到了一个非常具体的定义。我将介绍其为基于身份的分段。我们将讨论一种使用服务网格作为其中一种架构实现的可能方式。更一般地说，我将概述如何从面向网络的策略逐步转向基于身份的策略。'
- en: Why am I here talking to you all about it? I was one of the early engineers
    on the Istio project, one of the more popular service meshes. Before then, I worked
    across Google Cloud on a whole bunch of different stuff. I jokingly say if you
    do enterprise-y things in Google Cloud, I probably worked on some of that code.
    Specifically, like projects were my baby for a long time. From there, we actually
    did very meshy things at Google and deployed that architecture internally, and
    said, we think this might solve some powerful problems in the Kubernetes space
    that are coming up. That's when we then started to work on the Istio project.
    One of the other big hats that I wear, and probably the biggest reason I'm here
    talking to you is that I co-author a set of security guidelines with NIST. I work
    on two sets, the series SP 800-204A and SP 800-204B I helped write, which provide
    guidelines for microservice security. The second one, which is hot off the press,
    in fact, it was just finalized, it's been in draft for a few months. It was just
    published, 207A, and that's all about zero trust. The 207 series is NIST series
    on zero trust. 207A is the second installment in that. That's really what we're
    going to be digging into. This is relatively new stuff. Again, we're going to
    break it down in this way.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我要在这里与你们谈论它？我曾是Istio项目的早期工程师之一，这是一个比较流行的服务网格。在那之前，我在Google Cloud上从事了各种各样的工作。我开玩笑地说，如果你在Google
    Cloud上做企业级的事情，我可能参与过其中一些代码。具体来说，像项目是我长时间以来的宝贝。从那时起，我们在Google内部实际上做了很多网格化的事情，并部署了这种架构，我们认为这可能解决Kubernetes领域即将出现的一些重要问题。这时我们开始了Istio项目的工作。我另外一个主要原因，也可能是我在这里与你们谈论的最大原因是，我与NIST共同撰写了一套安全指南。我参与了两套指南的编写，分别是SP
    800-204A和SP 800-204B，这些指南提供了关于微服务安全的指导。第二套指南刚刚完成，事实上，它刚刚被最终确定，之前草案已经发布了几个月。它刚刚被发布，是207A，它是关于零信任的。207系列是NIST关于零信任的系列指南，207A是其中的第二部分。这真正是我们将要深入探讨的内容。这些都是相对较新的东西。再次强调，我们将以以下方式对其进行分解。
- en: What Does Zero Trust Really Mean?
  id: totrans-split-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是零信任？
- en: First, let's take a step back. What does zero trust actually mean? We'll walk
    into a definition. The key thing I want you to understand is that a motivated
    attacker can already be in the network. The question is, how can we limit the
    damage that they can do? It's all about risk mitigation. I want to take a step
    back, and then we'll build into a definition. It's something hopefully most folks
    are familiar with, is something like an API gateway or just serving an application
    to end users. There are a couple things that we always do. We always authenticate
    the user when they come in. We hopefully always authorize that user to take some
    action. If we're talking about an API gateway, maybe we additionally do some rate
    limiting. Maybe we have some other policy like WAF that we might apply. There's
    a bunch of different stuff that happen in the front door. Two big ones are that
    we always authenticate and authorize the user. As we're thinking about somebody
    can be in the network, somebody can be inside the perimeter, how do we minimize
    the damage? Then, definitely, we probably want to start to do that same kind of
    authentication and authorization for the workloads that are communicating as well.
    Not just, do we have a user in session, but do we know what those users are using.
    We want to be able to say, the frontend can call the backend, the backend can
    call the database. On all those hops, there better be a valid end user credential.
    Maybe we might even go further. We might say, if you're going to do a put on the
    frontend, you better have the right scope in the end user credential. If you're
    just going to do a get, then maybe you just need the read. We can build really
    powerful policies as we start to combine these.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们退一步。零信任实际上是什么意思？我们将给出一个定义。我希望你理解的关键是，一个有动机的攻击者可能已经在网络中了。问题是，我们如何限制他们可能造成的损害？这一切都是关于风险缓解。我想先退后一步，然后我们再来定义。这是希望大多数人熟悉的东西，比如一个API网关或者向最终用户提供应用程序。有一些我们总是做的事情。我们总是在用户进入时进行认证。我们希望总是授权该用户执行某些操作。如果我们谈论的是API网关，也许我们还会额外做一些速率限制。也许我们有一些其他的策略，比如WAF可以应用。在前端门户上发生了很多不同的事情。两个重要的是我们总是对用户进行认证和授权。当我们考虑有人可能在网络中，有人可能在内部围栏之内，我们如何尽量减少损害？然后，肯定地，我们可能想要开始对通信工作负载做同样的认证和授权。不仅仅是，我们有一个用户在会话中，而是我们知道这些用户在使用什么。我们希望能够说，前端可以调用后端，后端可以调用数据库。在所有这些跳跃中，最好有一个有效的最终用户凭据。也许我们甚至可以进一步。我们可能会说，如果你要在前端进行put操作，你就必须在最终用户凭据中具备正确的范围。如果你只是要get，那么也许你只需要读权限。当我们开始结合这些时，我们可以制定非常强大的策略。
- en: Again, I led off with the attacker is already in the network. Every single time
    I give a variation on this 207A talk, there's a different example that I can cite
    of a network breach. In this case, for folks that follow the news, there was a
    big bulletin put out by CISA in conjunction with Japan, about network breaches
    driven by China in a variety of networks, for example. That one's very relevant.
    This one is from a decade ago. Anybody know offhand where that picture is from?
    That is actually from the Snowden leaks. Where U.S. Government was in the infrastructure.
    The point here is that a motivated attacker can be inside the network. If our
    only control, if our only security is at the perimeter, then you're already cooked.
    This then brings us into zero trust. We want trust that is explicit. I actually
    hate the phrase zero trust, it really should be called zero implicit trust, because
    it's all about making where we have trust in the system explicit. Hopefully doing
    that with a policy, so that we actually have a piece of code that enforces it.
    We want trust that's not based on the perimeter because it's breachable. Therefore,
    instead, what we need is a decision that's based on least privilege. We want to
    do it per request, because requests can be, you may be doing different actions.
    We want it to be context based. If you're accessing from the U.S. a whole bunch,
    and then randomly, 5 minutes later, you're accessing from an entirely different
    geography, something's probably a little fishy there. We want to have context-based
    decisions. Again, those need to be on identities. More than just service identity,
    we also want end user identity and potentially also we want device identity. Because
    all of those factor in to the context for how we want to allow a user to access
    a system. If I'm on a corporate approved device, and I'm logged in, and I'm coming
    from my home geography, I probably can have a lot of access. If I'm on an untrusted
    random device that's popping up in a weird geography like Russia, or Eastern Europe,
    or something like that, then probably I want to give less access to that, because
    that's not typical for how the system operates.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，我开头说的是攻击者已经进入了网络。每次我在这个207A演讲中提供的变体都有不同的例子可以引用网络入侵。例如，对于关注新闻的人来说，美国网络安全与基础设施安全局（CISA）与日本联合发布了一份关于由中国驱动的各种网络的网络入侵的重要公告。那个例子非常相关。这个例子来自十年前。有人知道那张图片是从哪里来的吗？那实际上是从斯诺登泄密事件中来的。美国政府介入了基础设施。这里的重点是，一个有动机的攻击者可以进入网络。如果我们唯一的控制措施，唯一的安全措施在边界，那么你已经失控了。这就引出了零信任。我们想要的是显式的信任。事实上，我非常讨厌“零信任”这个短语，它真的应该称为零隐含信任，因为它完全是关于使我们对系统中的信任变得显式化。希望通过策略来实现这一点，这样我们实际上有一个执行它的代码片段。我们想要的信任不是基于边界的，因为它是可以被攻破的。因此，我们需要的是基于最小权限的决策。我们希望每个请求都这样做，因为请求可能会执行不同的操作。我们希望它基于上下文。如果你在美国访问了很多次，然后突然，5分钟后，你从完全不同的地理位置访问，那里可能有些可疑。我们想要基于上下文的决策。再次强调，这些决策需要基于身份。不仅仅是服务身份，我们还想要终端用户身份，可能还有设备身份。因为所有这些因素都影响了我们允许用户访问系统的上下文。如果我使用的是公司批准的设备，并且我已经登录，并且我来自我的家庭地理位置，我可能可以拥有很多访问权限。如果我使用的是一个不受信任的随机设备，突然出现在像俄罗斯或东欧这样的奇怪地理位置，那么我可能想要减少对它的访问权限，因为这不是系统正常操作的典型情况。
- en: Identity-Based Segmentation (Zero Trust Segmentation)
  id: totrans-split-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基于身份的分段（零信任分段）
- en: With that high-level definition for zero trust, let me bring in identity-based
    segmentation. This is the main thrust of 207A. We defined a few different things,
    probably three things in 207A that I'll talk to you about, but identity-based
    segmentation is the big one. Microsegmentation is isolating workloads at the network
    level. Ideally, we want to do that down to the individual IP address, so we have
    pairwise policy for who can access whom. We want to do the same thing at the identity
    layer. We want tamper proof cryptographically verifiable identities for the user,
    for the device, for the service. We want to use those identities to make that
    previous decision that I talked about, this context-based per request, least privilege
    decision. Ideally, we might use network parameters as part of our risk-based assessment.
    They should not be the only discriminate that we're making an access decision
    on. However, again, we're going to be cooked because a privileged spot in the
    network is not a good enough security boundary today.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于零信任的高层次定义，让我介绍一下基于身份的分段。这是207A的主要内容。我们在207A中定义了几件不同的事物，可能是三件，我将与你讨论，但基于身份的分段是其中重要的一部分。微分段是在网络层面隔离工作负载。理想情况下，我们希望将其下降到单个IP地址，因此我们拥有针对谁能访问谁的成对策略。我们希望在身份层面做同样的事情。我们希望为用户、设备和服务提供防篡改的、可加密验证的身份。我们希望利用这些身份来做出我之前谈到的那个决定，即基于上下文的每个请求的最小特权决策。理想情况下，我们可能会将网络参数作为我们基于风险的评估的一部分。它们不应该是我们做出访问决策的唯一区分因素。然而，再次强调，我们将会因为在网络中的特权位置今天不是一个足够好的安全边界而受到影响。
- en: What is identity-based segmentation? It's these five things. If there's anything
    that you walk out of this talk with, if this is it, these are the five runtime
    activities you need to be doing at minimum, these things, and you can call yourself
    a zero-trust posture. There's a lot more we can do besides these, and maybe should
    do besides these. This is a minimal working definition. We want five things, encryption
    in transit. Really, we want this for two reasons. One, we want message authenticity.
    I want to know that somebody can't change the message that I sent. Then, two,
    we want eavesdropping protection. I want to make sure that somebody else can't
    look at the data that I'm sending if the data is sensitive. Then, on top of that,
    we want to know, what are the workloads that are communicating? Is the frontend
    calling the backend? Is the database calling the frontend? Which parts of our
    system are communicating from the software perspective we're deploying? Then,
    with identities, we should authorize that access. Again, we should do that per
    request. Then, exactly like I said before, we want to additionally incorporate
    that end user credential and the end user authorization decision as well. We want
    to do all five of those things. Ideally, we want to do them at every single hop
    in our infrastructure. If we achieve that, if we're doing this, then our answer
    to, what happens if there's an attacker on the network? Hopefully, we have a pretty
    decent answer. Because the answer is, now they need to steal a credential. We'll
    get into the model a little bit more, but they need to steal an end user credential.
    They need to compromise a workload or steal a workload credential. Those are very
    ephemeral credentials too. I'll talk about the service mesh, and Istio in particular,
    workload identities may last 24 hours or even as little as one hour. End user
    credentials typically last on the order of 15 minutes or so without refresh. We
    can start to combine these things, we start to limit an attacker in time and in
    space. We mitigate the damage that they can do. I'll touch on this more.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是基于身份的分段？这就是这五件事。如果有什么是你在这次讲话中带走的，那就是这些，这五个运行时活动是你至少需要做的，这些事情，你可以称自己为零信任姿态。除了这些以外，我们还可以做很多事情，也许应该做得更多。这是一个最低限度的工作定义。我们希望有五件事情，传输中的加密。实际上，我们有两个原因想要这个。一是我们想要消息的真实性。我想知道别人不能改变我发送的消息。然后，第二，我们想要窃听保护。如果数据很敏感，我希望确保别人不能查看我正在发送的数据。然后，除此之外，我们想知道，哪些工作负载正在通信？前端是否在调用后端？数据库是否在调用前端？从软件部署的角度来看，我们的系统的哪些部分正在通信？然后，对于身份信息，我们应该授权该访问。同样，我们应该根据每个请求来执行。然后，就像我之前说的一样，我们还想额外地包含终端用户的凭证和终端用户的授权决策。我们希望做到这五件事情。理想情况下，我们希望在我们基础设施的每一个跳点都做到这一点。如果我们实现了这一点，如果我们正在做这个，那么我们对于网络上出现攻击者的答案是什么？希望我们有一个相当不错的答案。因为答案是，现在他们需要窃取一个凭证。我们稍后将更详细地讨论这个模型，但他们需要窃取一个终端用户凭证。他们需要妥协一个工作负载或窃取一个工作负载凭证。这些凭证也是非常短暂的。我会谈谈服务网格，特别是
    Istio，工作负载标识可能持续 24 小时，甚至只有一小时。终端用户凭证通常在 15 分钟左右没有刷新的情况下持续。我们可以开始结合这些事情，我们开始在时间和空间上限制攻击者。我们减轻他们可以造成的损害。我稍后会更详细地谈论这个问题。
- en: Service Mesh
  id: totrans-split-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务网格
- en: The service mesh is one of the key ways that we discuss implementing this in
    the SPs. It's not the only way that you can implement these capabilities, but
    it is a very powerful way to do that. I'll dig into that. If you're interested
    in some of the other use cases beyond identity-based segmentation, there's some
    of the other SPs that cover microservice security that go into service mesh a
    lot more. How can we use a service mesh to do the segmentation? Just to level
    set for everybody what even is a service mesh, what we do is we take a proxy,
    a web proxy, a reverse proxy, in Istio we use the implementation Envoy, but you
    can think of something like an NGINX, or similar as well. We put that beside every
    instance of every single application, and we force all network traffic into and
    out of the application through that proxy. What that lets us do is have an application
    identity and do encryption on behalf of the application. We can make load balancing
    decisions on behalf of the application. We can do service discovery and load balancing.
    We can do things like resiliency, timeouts, keepalives, retries on behalf of the
    application. You can get operational telemetry out of the system to help you close
    the loop. When you make a change, you can see what the effect of that change is,
    is it doing what you intended or not? Then change it, again, if it's not.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 服务网格是我们在SPs中讨论实施这一点的关键方式之一。这不是你可以实现这些功能的唯一方式，但这是一个非常强大的方法。我将深入探讨这一点。如果您对基于身份的分段之外的一些其他用例感兴趣，有一些其他的SPs涉及到更多服务网格。我们如何使用服务网格来进行分段？只是为了让每个人都知道什么是服务网格，我们所做的是拿一个代理，一个web代理，一个反向代理，在Istio中我们使用Envoy实现，但您也可以考虑类似的东西如NGINX，或者类似的。我们将它放在每个单个应用程序实例旁边，并强制所有网络流量通过该代理进出应用程序。这使我们能够拥有应用程序标识并代表应用程序进行加密。我们可以代表应用程序做出负载均衡决策。我们可以进行服务发现和负载均衡。我们可以执行诸如弹性、超时、保持活动、重试之类的操作。您可以从系统中获得操作遥测数据，以帮助您闭环。当您进行更改时，您可以看到该更改的效果是什么，它是否符合您的意图？然后再次进行更改，如果不符合。
- en: Again, there's quite a few capabilities here. If you're going to have any distributed
    system, you have to have these capabilities. The service mesh is not novel in
    bringing these capabilities into play. What is novel about the service mesh, is
    that it lets us do all of these consistently across your entire fleet of applications,
    regardless of the language that we're in, because we're working at the network
    level, and we're intercepting network traffic. It gives us centralized control,
    so we have those proxies, that sidecar beside every application instance. We have
    a central control plane that manages it. We can push declarative configuration
    to that control plane, and it will enact that configuration on all the sidecars
    in the order of less than a second, typically. We have a very fast, very responsive
    system. We can see signals out to see if it's in the state that we want it to
    be. If it's not, we can push configuration, have it go into effect almost instantaneously.
    Then watch and see if it is in the state that we want it again.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这里有相当多的功能。如果您要建立任何分布式系统，您必须具备这些功能。服务网格在将这些功能引入使用方面并不新颖。服务网格的新颖之处在于，它使我们能够在整个应用程序群中一致地执行所有这些功能，而不论我们使用的是哪种语言，因为我们在网络级别进行操作，并拦截网络流量。这为我们提供了集中控制，因此我们在每个应用程序实例旁都有那些代理，即旁车。我们有一个管理它的中央控制平面。我们可以将声明性配置推送到该控制平面，并且它将在不到一秒的时间内在所有旁车上实施该配置，通常如此。我们有一个非常快速、响应迅速的系统。我们可以查看信号以查看它是否处于我们想要的状态。如果不是，我们可以推送配置，使其几乎即时生效。然后观察并查看它是否处于我们希望的状态。
- en: I worked on Istio. Istio is the most widely deployed mesh. Istio is also a CNCF
    project now. Envoy the CNCF project is the data plane there. Envoy is handling
    the bits and the bytes of your request. It's the sidecar. Istio is what's programming
    that Envoy at runtime. A couple key ideas that I want to give you all as well,
    as we're thinking through this framework of, how do I limit access for zero trust?
    How might we use a service mesh? The first key idea is that that sidecar forms
    a policy enforcement point. The idea is because it's intercepting all the traffic
    in and out, we can use that to put whatever policy we want. I mentioned things
    like encryption. I mentioned things like observability. We can also do things
    like integrate with OPA. We can do things like integrate with our identity provider
    to do SSO on behalf of applications. We can build a custom library that does something
    that's specific to our business, and enforce that it's called via the service
    mesh. The idea is that when we have policy that we want to apply across the board,
    not just to one set of applications, but to most applications in our infrastructure,
    we can leverage integrating at once with the service mesh to do the enforcement
    and not have to go app by app.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾经在 Istio 上工作。Istio 是目前部署最广泛的服务网格。Istio 现在也是一个 CNCF 项目。在那里，Envoy 是数据平面的一部分。Envoy
    处理你请求的比特和字节。它是 sidecar。在运行时，Istio 就是在编程这个 Envoy。还有几个关键的想法我也想给大家，因为我们正在思考这个框架，如何实现零信任的访问控制？我们如何使用服务网格？第一个关键的想法是，这个
    sidecar 形成了一个策略强制执行点。这个想法是因为它拦截了所有进出的流量，我们可以利用它来施加任何我们想要的策略。我提到过像加密这样的事情。我提到过像可观察性这样的事情。我们还可以做一些像与
    OPA 集成的事情。我们可以做一些像与我们的身份提供者集成以代表应用程序进行单点登录的事情。我们可以构建一个自定义库，执行某些特定于我们业务的操作，并强制要求通过服务网格调用它。这个想法是，当我们有要在整个架构中应用的策略时，不仅仅是针对一组应用程序，而是大多数应用程序时，我们可以利用一次与服务网格集成来进行强制执行，而不必逐个应用程序进行操作。
- en: If you go back to the old school access control literature from the 1970s, that's
    where the notion of a kernel comes from. That's where we talk about the idea of
    a reference monitor, the thing that intercepts all the traffic and enforces policy.
    Then extending that, the service mesh itself, and this is one of the key ideas
    why the NIST folks were so interested in the mesh, can potentially be that security
    kernel for our modern distributed system. If we think of the operating system
    kernel and the security capabilities it provides for processes that run on our
    operating system, it provides isolation. These days it provides cgroups and namespaces
    to provide soft multitenancy with containers. It provides the Unix file permissioning,
    as another mechanism of access control. There are quite a few access control systems
    that we build into the operating system kernel, and we leverage them to protect
    our applications. The idea is that the service mesh can be the same thing in our
    distributed system. Rather than deploying processes onto a host, we're deploying
    microservices into our infrastructure. In the same way that the operating system
    provides a key set of capabilities, regardless of the application, the service
    mesh can provide a consistent set of security capabilities, regardless of the
    app that's running.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你回到上世纪七十年代的老派访问控制文献，这就是核心的概念来源。这就是我们讨论参考监视器的概念，它拦截了所有的流量并强制执行策略。然后扩展到服务网格本身，这也是
    NIST 的人们对服务网格如此感兴趣的一个关键理念之一，可能会成为我们现代分布式系统的安全核心。如果我们将操作系统内核和它为运行在操作系统上的进程提供的安全能力联系起来，它提供了隔离。这些天它提供了
    cgroups 和 namespaces，为容器提供软多租户性。它提供了 Unix 文件权限作为另一种访问控制机制。我们在操作系统内核中构建了相当多的访问控制系统，并利用它们来保护我们的应用程序。这个想法是，服务网格可以在我们的分布式系统中扮演同样的角色。与将进程部署到主机上不同，我们将微服务部署到我们的基础设施中。就像操作系统为应用程序提供一套关键的能力集一样，服务网格可以为运行的应用程序提供一致的安全能力集。
- en: In this way, the service mesh facilitates cross-cutting change. I mentioned
    we can integrate whatever policy it is, whether that's traffic routing, whether
    that's security, observability, we can integrate that into the service mesh to
    enforce it. We can change it and manage it centrally, which means that a small
    group of people can act on behalf of the entire organization to enact policy and
    make change. There's no free lunch, we can't get rid of the complexity. We want
    to do encryption everywhere. Somebody still needs to integrate with a PKI, and
    to get certificates there. The service mesh lets you do that one time, integrate
    it with the service mesh, and then all apps benefit. One example. It can be a
    force multiplier that we can use to concentrate the complexity that we need to
    deal with on a small team that's well equipped to deal with it. Rather than, for
    example, in the case of encryption, needing to make every app team go and implement
    some encryption library in their own system.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 通过服务网格实现跨切变更。我提到我们可以集成任何策略，无论是流量路由、安全性还是可观察性，我们都可以将其集成到服务网格中进行强制执行。我们可以集中更改和管理它，这意味着少数人可以代表整个组织来执行政策并进行更改。没有免费午餐，我们无法摆脱复杂性。我们希望在任何地方进行加密。有人仍然需要与PKI集成，并获取证书。服务网格让您只需一次集成，将其与服务网格集成，然后所有应用程序都将受益。一个例子。它可以是我们可以使用的力量倍增器，集中我们需要处理的复杂性，交给一个小团队，他们有能力处理它。例如，在加密的情况下，不需要每个应用团队都去实现一些加密库在他们自己的系统中。
- en: To bring this back, if we look at our five tenets for identity-based segmentation,
    we can use the service mesh to achieve all of them. First off, we can achieve
    encryption in transit. The service mesh gives you a strong application identity.
    We use a system called SPIFFE to do this, and we issue a normal certificate that
    encodes the application identity, and we can use that to do encryption in transit,
    mutual TLS, specifically. Then using that certificate, we can authenticate our
    workloads that are communicating, which means then that we have the opportunity
    to apply authorization. We know exactly what workloads are communicating, we've
    authenticated them. We know for real, it's them. Now we can actually decide, is
    the frontend blob call the database directly? No, probably not, it needs to go
    through the backend. We can start to enforce that policy. Then we can integrate
    the sidecar as a policy enforcement point for our existing identity and authorization
    system for end users. The service mesh itself is not well suited to model user
    to resource access or that kind of thing. It's good at modeling service-to-service
    access. We want to delegate out to our existing systems to handle end user authentication
    and authorization. The service mesh provides tools for integrating with those
    systems.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 归根结底，如果我们看看我们基于身份的分段的五个原则，我们可以使用服务网格来实现所有这些原则。首先，我们可以实现传输中的加密。服务网格为您提供强大的应用程序身份。我们使用一个称为SPIFFE的系统来做到这一点，并发放一个普通证书来编码应用程序身份，我们可以使用它来进行传输加密，具体来说是双向TLS。然后使用该证书，我们可以认证我们正在通信的工作负载，这意味着我们有机会应用授权。我们确切地知道哪些工作负载正在通信，我们已经对它们进行了身份验证。现在我们实际上可以决定，前端blob调用是否可以直接访问数据库？不，可能不能，它需要通过后端。我们可以开始执行该策略。然后，我们可以将sidecar集成为现有身份和授权系统的策略执行点，用于最终用户。服务网格本身不适合模拟用户对资源访问或类似事物。它擅长于建模服务间的访问。我们希望将授权委托给我们现有的系统来处理最终用户的身份验证和授权。服务网格提供了与这些系统集成的工具。
- en: Moving Incrementally
  id: totrans-split-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 逐步迁移
- en: The final thing that I want to cover then, is how can we start to move incrementally
    from the current system that we have today, a perimeter-based system, into some
    of this identity-based policy? What are some of the benefits of doing that? First
    off, policy at any one layer is going to have shortcomings and pain. If we think
    about just network policy and identity-based policy, one of the biggest pain points
    with network-based policy today is it usually takes a long time to change. Who
    here has like a firewall in their organization that they have to go change when
    they do stuff? Who here can change the firewall in less than two weeks? Normally,
    every single organization I think I've ever talked to ever, it's six weeks to
    change the firewall. I don't know why it is. How long does it take? It's six weeks.
    Got to go to the spreadsheet, got to find the CIDR. It's not well suited for the
    highly dynamic environments that we're deploying in today. Cloud, in particular,
    with auto scalability and things like that are not well suited to traditional
    network controls. We either need to use more sophisticated and usually more expensive
    technology to do that, or we need to hamper our ability to use things in cloud,
    slow down the organization to fit it into the existing process, which is a nonstarter.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一件我想讨论的事情是，我们如何能够逐步从今天的现有系统——基于周界的系统，过渡到一些基于身份的政策？这样做有什么好处？首先，任何一个层面的政策都会有其不足和痛点。如果我们仅考虑网络策略和基于身份的策略，那么今天基于网络的策略最大的痛点之一是更改通常需要很长时间。在这里有谁的组织中有防火墙，每次需要更改时都得操作一番？有谁能在两周内更改防火墙？通常情况下，我认为我曾经和任何一个组织谈过的，都需要六周时间来更改防火墙。我不知道为什么是这样。需要多长时间？六周。得去查电子表格，得找到CIDR。这种方式不适合我们今天部署的高度动态的环境。特别是云环境，自动伸缩等特性，传统的网络控制无法胜任。我们要么需要使用更复杂、通常也更昂贵的技术来做到这一点，要么就得妥协，减慢我们在云中使用资源的速度，以适应现有的流程，但这是不可接受的。
- en: Identity-based policies, and this is something as an industry, we don't have
    a lot of experience managing identity-based policy, in this sense, in the same
    way that we have with network-oriented policy. Some of the challenges people haven't
    hit yet. One of the more obvious and initial ones that you hit is that even something
    simple like a service has a different identity in different domains. If I'm running
    it on-prem on a VM, it probably has a Unix username that we've allocated in our
    system for it to run as, but if we're in cloud, GCP, it's going to have a service
    account. If it's in AWS, it's also going to have a service account, in Azure and
    many of the other ones. The problem is those service accounts aren't the same.
    If I want to do something like, the frontends can call the backend, and I want
    to do that regardless of where the two are deployed, then there's some complexity
    in how I map those identities across different identity universes, like different
    cloud providers and on-prem. Then, finally, the other big 800-pound gorilla in
    the room is that even if we totally bought into identity-based policy, and we
    say, yes, that's the way, in most regulated environments, we can't actually get
    rid of the network-based policy yet. Because either auditors or regulators expect
    it, or I have a document that was written in 1992, that sets the security posture
    for the organization. It says that there have to be network segments. It's more
    expensive to change that document than it is to pay Cisco millions of dollars
    to do network segmentation. For a variety of different reasons in organizations,
    we can't totally eliminate network-oriented policies or network level policies,
    even if that's desirable. I don't think it necessarily is.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: 基于身份的策略，对于这个行业而言，我们在管理基于身份的策略方面并没有太多经验，就像我们在网络导向策略方面那样。一些挑战至今未被解决。其中一个更为明显和最初的问题是，即使像服务这样简单的东西在不同的域中也有不同的身份。如果我在本地运行在虚拟机上，它可能有一个我们在系统中为其分配的Unix用户名来运行，但如果我们在云上，比如GCP，它将会有一个服务账户。如果它在AWS上，也会有一个服务账户，在Azure和许多其他云服务提供商上也是如此。问题在于这些服务账户并不相同。如果我想做类似的事情，前端可以调用后端，而我希望无论这两个在哪里部署，我都可以做到，那么在如何映射这些不同身份宇宙（比如不同的云服务提供商和本地）的身份时，会有一些复杂性。最后，房间里的另一个大象级问题是，即使我们完全接受基于身份的策略，并且说，是的，这是正确的方式，在大多数受监管环境中，我们实际上还不能完全摆脱基于网络的策略。因为审计员或监管机构希望有这样的策略，或者我有一份1992年编写的文件，为组织设置了安全姿态。文件中说必须存在网络分段。修改该文件的成本比支付思科数百万美元进行网络分段更高。出于组织中的多种不同原因，我们不能完全取消网络导向的策略或网络层策略，即使这是可取的。我并不认为这一定是正确的选择。
- en: Multi-Tier Policies
  id: totrans-split-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多层策略
- en: Instead, we want these two layers to live together. What we would like to do
    is start to tradeoff between the two, so that we can minimize some types of policy
    in the network level, offset them with identity-based policies. The hope is that
    we can get more agility out of our system, as a result. I'll give you some specific
    examples of doing that. If we talk about multi-tier policies, there's many more
    layers of policy, actually, but we try and keep the SP very short and focused.
    It's about 18 pages long, about 12 pages of content, if you want to go read it.
    Most SPs tend to be 50 or 60 pages long. We really kept it focused. At minimum,
    two policies, network-tier policies, things like firewall rules, identity-tier
    policies, things like I just talked to you about, like application based stronger
    identities with authorization. What we can start to do is, where we need to do
    things like traverse a firewall, we can start to incorporate identity-based policy,
    and relax some of our network rules. In particular, today, with a network-oriented
    scheme, when I have two applications, maybe one's on-prem and one's in cloud,
    or it's my two on-prem data centers or two different cloud providers, doesn't
    really matter, and I want them to be able to communicate. I typically need to
    go change the firewall rules in my organization, pairwise. I need to say App A
    can now call App B, or Service 1 can call Service 2\. If tomorrow Service 1 needs
    to call Service 3, I need a new firewall change, and I'm back in the six-week
    cycle of firewall updates. This is a huge killer of agility in folks that we talk
    with.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们希望这两个层可以共存。我们想要做的是在两者之间进行权衡，以便我们可以在网络级别最小化某些类型的策略，并用基于身份的策略抵消它们。希望这样做可以使系统更加灵活。接下来我会给你一些具体的例子。如果我们谈论多层策略，实际上有更多层的策略，但我们尽量让SP非常简短和专注。大约有18页，内容约12页，如果你想阅读的话。大多数SP通常是50或60页长。我们确实保持了专注。至少有两个策略，网络层策略，例如防火墙规则，身份层策略，例如我刚刚和你讲过的，如基于应用的更强身份授权。我们可以开始做的是，在需要像穿越防火墙这样的事情时，我们可以开始整合基于身份的策略，并放宽一些我们的网络规则。特别是今天，在网络导向的方案中，当我有两个应用程序，可能一个在本地，一个在云中，或者是我的两个本地数据中心或两个不同的云提供商，其实并不重要，并且我希望它们能够通信。我通常需要去更改组织中的防火墙规则，逐对地。我需要说应用A现在可以调用应用B，或者服务1可以调用服务2。如果明天服务1需要调用服务3，我需要一个新的防火墙更改，然后我又回到了六周更新防火墙的周期中。这是我们与之交谈的人中敏捷性的巨大杀手。
- en: Instead, what we can do is deploy identity-aware gateways. Instead of having
    these pairwise rules that we need to update regularly, we can deploy these identity-aware
    proxies or gateways, instantiate a single set of firewall rules that say, these
    two sets of workloads can communicate. Then, when we have pairwise applications
    that need to consume, we can authorize that with an identity-based policy that
    says, Service 1 and Service 2 can communicate over the bridge. In this way, what
    we've done is we still have all of our network controls. Our user requests still
    traverses all the network controls that the organization already had, but we've
    been able to offload the policy change from network to identity. The key idea
    is that a network-based policy is a CIDR range. Who knows what a CIDR is and what
    app it is. An identity-based policy should correlate very strongly to the application
    that's running. If your runtime identity doesn't match the application's identity
    internally, something is probably a little funky. We want these things to line
    up. Typically, we can change an identity-based policy much more rapidly, because
    a human can read and understand the frontends in the default namespace, once it's
    called the backend and the default namespace, a lot more easily than I can understand
    that 10.1.2.4/30, can call 10.2.5/24\. Who knows what that means? That's why we
    can get a faster rate of change by offloading here.
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，我们可以部署具备身份感知的网关。与其不断更新这些成对规则，我们可以部署这些具备身份感知的代理或网关，实例化一组防火墙规则，说明这两组工作负载可以进行通信。然后，当我们有需要消费的成对应用程序时，我们可以通过基于身份的策略授权，说明服务1和服务2可以通过桥接进行通信。通过这种方式，我们所做的是仍然拥有所有我们的网络控制。我们的用户请求仍然穿越组织已有的所有网络控制，但我们已经能够将策略变更从网络转移到身份上。关键思想是，基于网络的策略是一个CIDR范围。谁知道CIDR是什么及其作用？基于身份的策略应该与运行的应用程序强相关。如果您的运行时身份与应用程序内部的身份不匹配，可能有些问题。我们希望这些事情能够对齐。通常情况下，我们可以更快地改变基于身份的策略，因为人们可以更轻松地阅读和理解默认命名空间中的前端，一旦它被称为后端和默认命名空间，比起我能够理解的10.1.2.4/30，可以调用10.2.5/24。谁知道那意味着什么？这就是为什么我们可以通过这里的转嫁获得更快的变化速度。
- en: More than just two layers of policy, typically, we have quite a few layers of
    policy in our systems. We typically have a coarse-grained segmentation of internet,
    intranet. Likely we have broad segments there, a DMZ, an app zone, a business
    zone, the data zone. Again, we already tend to stack these policies today. For
    folks that implement microsegmentation in their networks, how many of you all
    did away with your coarse-grained segments when you moved to microsegments? The
    answer is we tend to keep both and stack them additively. Then Kubernetes brings
    in a whole additional challenge because it's a virtual network. We have a new
    set of techniques like the CNI providers to control network policy there. Those
    have some better tradeoffs versus traditional network rules, because they're built
    for the dynamism. Fundamentally, there's still a layer 3, layer 4 policy. Whereas
    we really want to get application identity and end user identity, those are layer
    7 things. That's why we like to see the service mesh stack on top of all of these.
    I think of it as almost a layered cake, as we're going up. You can think of it
    as Swiss cheese, if you really want to think about the defense in depth. We're
    trying to make it hard to get through.
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 典型情况下，我们的系统中不仅有两层策略，通常还有多层策略。我们通常有粗粒度的互联网、内部网的分割。可能我们在这里有广泛的段，一个DMZ，一个应用区域，一个业务区域，数据区域。再次强调，我们今天已经倾向于堆叠这些策略。对于那些在他们的网络中实施微分段的人来说，当你转向微分段时，你们中有多少人放弃了你们的粗粒度段？答案是我们倾向于保留两者并逐步叠加它们。然后Kubernetes带来了一个全新的挑战，因为它是一个虚拟网络。我们有一套新的技术，比如CNI提供者来控制网络策略。这些与传统的网络规则相比具有更好的权衡，因为它们是为动态性而构建的。从根本上讲，仍然有第3层、第4层的策略。然而，我们真正想要的是应用程序标识和最终用户标识，这些都是第7层的事情。这就是为什么我们喜欢看到服务网格堆叠在所有这些上面的原因。我把它想象成一个层层叠加的蛋糕，随着我们的提升。你可以把它想象成瑞士奶酪，如果你真的想考虑深度防御。我们正在努力增强安全防护。
- en: Advantages of Multi-Tier Policies
  id: totrans-split-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多层策略的优势
- en: Why would we do this? One, if we do it in this way, then we can start to sit
    these new identity-based policies on top of our existing network policies. It
    provides a defense in depth because, again, we're still going through our traditional
    network controls, but we now have this identity layer as well on top of the network
    controls. Of course, the service mesh already mentioned, can enforce this, because
    it's non-bypassable, it's verifiable. We talk about this at length in SP 800-204B.
    The key thing that I want you to take away is that we don't need to get rid of
    firewalls or WAFs or similar. What you should feel comfortable in justifying to
    your organization is that you can relax those controls in exchange for introducing
    identity-based controls. The key is in your organization to get the right balance
    so that you can still move fast, but keep the security and the risk side where
    it needs to be for that part of the org.
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么要这样做？一方面，如果我们以这种方式进行，那么我们可以开始在现有的网络策略之上引入这些新的基于身份的策略。这样做提供了深层防御，因为我们仍然通过传统的网络控制进行操作，但现在在网络控制之上还有这个身份层。当然，已经提到的服务网格可以强制执行这一点，因为它是不可绕过的，是可验证的。我们在SP
    800-204B中详细讨论了这一点。我希望你能明白的关键是，我们不需要去除防火墙、Web应用防火墙或类似的东西。你应该能够向你的组织正当地证明，你可以放宽这些控制措施，以引入基于身份的控制措施作为交换。关键在于你的组织要找到合适的平衡点，这样你就可以保持快速推进，同时保持安全和风险控制在组织的适当部分。
- en: How to Define and Deploy Identity-Tier Policies
  id: totrans-split-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何定义和部署基于身份分层策略
- en: At a high level, how would we start to do this? What we want to do is begin
    to implement identity-based segmentation in the subsets of our infrastructure.
    If we have multiple data centers, start by just trying to implement that policy
    in data center. Then after you have a good notion of this identity-based segmentation,
    then we can start to do some of the more advanced patterns, like tiering these
    gateways together and some of those patterns as well. Certainly, you don't need
    to have 100% identity-based segmentation rolled out to be able to do some of those
    gateway style patterns. You do need at least enough to be able to authenticate
    and authorize the services and the users that are going over that tunnel. Again,
    same controls that their user app traverses, that's key, because we don't want
    to have to go change the existing security policy, but we do want to make things
    better where they are so that we can move faster as an organization.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，我们如何开始做这件事？我们想要做的是在基础设施的子集中开始实施基于身份的分割。如果我们有多个数据中心，首先尝试在一个数据中心中实施这一策略。然后，在你对基于身份的分割有了良好的概念之后，我们可以开始实施一些更高级的模式，比如将这些网关进行分层连接，以及其他一些模式。当然，并不需要完全将基于身份的分割推广开来，就能够实施一些网关样式的模式。但至少需要足够的能力来对通过该隧道的服务和用户进行身份验证和授权。同样的控制方式适用于用户应用程序的遍历，这一点很关键，因为我们不希望改变现有的安全策略，但我们确实希望在原有的基础上做得更好，以便我们作为一个组织能够更快地前进。
- en: Zero-Trust Mental Model (Bound an Attack in Space and Time)
  id: totrans-split-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 零信任心态模型（将攻击限制在空间和时间的边界内）
- en: I mentioned the big mental model when it comes to zero trust. We want to bound
    an attack in space and in time. We want to minimize what an attacker can do inside.
    One of the key things there is that by stacking these identity-based policies
    with the network-based policies, we help bind an attacker in space and in time.
    Obviously, network-based policies impact when an attacker can pivot to attack
    when they already control one workload. In the same way, fine-grained authorization
    policies at L7, help limit the blast radius of what an attacker can get to. Then,
    like I mentioned, those ephemeral credentials. End user credentials usually have
    a 15 minutes expiry, and the service mesh service credentials tend to have anywhere
    from 1 to 24 hours expiry. For an attacker to perpetrate an attack, they need
    to have both the service credential and an end user credential. They need to have
    the right scope so that we can actually get through and pivot to the system that
    we actually want to target. Because of the expiry, I need to either have a persistent
    control of the workload so that I can continue to re-steal those credentials,
    or I need to perpetrate an attack repeatedly to re-steal after they expire. Either
    way, the goal is make it as hard for the attacker as possible. Both of those schemes
    help increase the difficulty, help bound an attacker in space and in time.
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 当谈到零信任时，我提到了一个重要的思维模式。我们希望在空间和时间上限制攻击。我们希望尽量减少攻击者在内部可以做的事情。在这里的一个关键点是，通过堆叠基于身份的政策和基于网络的政策，我们帮助在空间和时间上限制攻击者。显然，基于网络的政策会影响攻击者可以在控制一个工作负载后何时进行攻击的时机。同样地，L7
    上的细粒度授权政策帮助限制攻击者可以访问的影响范围。然后，就像我提到的那样，这些短暂凭证。最终用户凭证通常会在 15 分钟后过期，而服务网格服务凭证则通常在
    1 到 24 小时后过期。为了实施攻击，攻击者需要同时拥有服务凭证和最终用户凭证，并且需要具有正确的范围，以便我们能够实际上达到并攻击我们想要的系统。由于过期时间的限制，我需要要么持续控制工作负载，以便我可以继续重新窃取这些凭证，要么我需要反复进行攻击，以在它们过期后重新窃取。无论哪种方式，目标都是尽可能增加攻击者的难度。这两种方案都有助于增加难度，有助于在空间和时间上限制攻击者。
- en: Questions and Answers
  id: totrans-split-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题与答案
- en: 'Participant 1: With all these identities and [inaudible 00:29:43] with credentials,
    I think debugging this configuration will be tricky. Do you offer any tooling,
    like formal tools to verify the credential?'
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者 1：有了所有这些身份和凭证，我认为调试这个配置会很棘手。你是否提供任何工具，比如正式工具来验证凭证？
- en: 'Butcher: This is an area that''s still pretty nascent today. The service mesh
    is not the only way you can implement those controls. There''s a lot of ways that
    you can implement those. One of the advantages of the service mesh is that it
    produces metrics out. You can actually observe, what is the state of the system?
    Let me apply a policy. Is it correct or not? What we''re starting to see then
    is tooling built on top of that, and it''s still early days there. For example,
    one of the things we have is a CLI that will basically say, give me 30 days of
    telemetry data, and I''ll spit out for you fine-grained authorization policies
    that model that 30 days of access. Tooling is getting there, but it''s still very
    early days for it. That''s one of the things I think we''ll see mature pretty
    quickly.'
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: Butcher：这个领域今天仍然相当初级。服务网格并不是你实现这些控制的唯一方式。有很多方法可以实现这些控制。服务网格的一个优点是它输出指标。你可以观察系统的状态。让我应用一个策略。它是否正确？我们开始看到的是在其上构建的工具，现在仍然处于早期阶段。例如，我们有一个
    CLI 工具，基本上会说，给我 30 天的遥测数据，我会为你生成出基于那 30 天访问的细粒度授权策略。工具正在不断完善，但现在仍然处于早期阶段。我认为这是我们很快会看到成熟的一件事情。
- en: 'Participant 2: Since you mentioned service mesh is just one layer you might
    drop it for this auth. Service meshes have a big [inaudible 00:30:59] especially
    at some very large companies'' scale, if you want to run on the same control plane,
    it can present a large single point of failure. For those of us that will maybe
    sell us service mesh, if you want, but what recommendations do you have for those
    [inaudible 00:31:24]?'
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者 2：由于你提到服务网格只是一个层次，你可能会在这种认证中放弃它。服务网格在一些非常大的公司规模上有着重大的影响，如果你想在同一个控制平面上运行，它可能会带来很大的单点故障。对于那些可能会卖给我们服务网格的人，你有什么建议吗？
- en: 'Butcher: In this world, consistency is your biggest asset. If I''m coming at
    this de novo, I''m either a small organization, or I''m trying to approach this
    without service mesh. There are some maybe modern deployment things that we can
    do with the service mesh to mitigate some of the pain you have, but not all of
    it. In short, what I would start to do is focus on libraries. For example, if
    you''re in a smaller organization, where, hopefully, we have a consistent set
    of languages that we''re dealing with, especially if you''re a pretty small shop,
    you have exactly one language that you''re dealing with. In which case, first
    off, make it a monolith. Secondly, implement those exact five controls, but just
    do it in library. Nowadays, you can get pretty far with a framework like gRPC.
    Even regardless of language, you can get pretty far with a framework like gRPC
    with respect to implementing all five of those controls. My first piece of advice
    would be something like that, tackle it with either a library, if you have a very
    small set of languages. If you''re a small shop with a small number of services
    and small number of developers, don''t do microservices. Why would you do that?
    Keep it as a monolith for as long as you can get away with keep things simple
    for yourself. That''s how I would start.'
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: 屠夫：在这个世界中，一致性是你最大的资产。如果我从头开始，我要么是一个小组织，要么是试图在没有服务网格的情况下解决这个问题。有一些可能是现代部署事务，我们可以通过服务网格来减轻你所遭受的一些痛苦，但不是全部。简而言之，我将开始专注于库。例如，如果你在一个较小的组织中，在那里，希望我们有一组一致的语言，我们正在处理，特别是如果你是一个相当小的店铺，你只有一种语言。在这种情况下，首先，把它做成一个单体。其次，在库中实现这些确切的五个控件，但只需在库中实现。现在，你可以通过像
    gRPC 这样的框架走得更远。即使不管语言，你也可以通过像 gRPC 这样的框架在实现所有这些控制方面走得更远。我给出的第一条建议将会是这样的，用一个库来解决这个问题，如果你只有一个非常小的语言集合。如果你是一个小的商店，有一个小数量的服务和开发者，不要做微服务。为什么要这样做呢？尽可能长时间地将其保持为单体，为了自己简化事务。这就是我会开始的方式。
- en: Then, again, as we're growing up in scale and heterogeneity, either you allocate
    a bigger team to do things like that library work in the different languages that
    developers are developing in. There's a set of challenges there around update
    and deployment and lifecycle. Eventually, that's where we see the tipping point
    for service mesh to become interesting for folks, is that the work to maintain
    a consistent set of libraries updated across the organization, and have compatibility
    across different versions, and all of that, tends to be expensive. Things like
    gRPC make it a lot more tractable, and not just gRPC, you could use Spring Boot
    or other things. Somewhere along that journey, it tends to be that the service
    mesh starts to become more attractive. There's also a lot of things you can do
    these days, to have more refined blast radius with your service mesh deployment.
    In particular, we would recommend keeping them one to one with your Kubernetes
    clusters, so that you have a refined blast radius there, that is your cluster.
    Then there's a set of techniques you can do to either shard workloads in the cluster
    if you're really a huge scale and you need multiple control planes. Or there's
    a set of configurations that you can use with the service mesh to help limit what
    config has to flow where. Things like in Istio, the sidecar API resource that
    gives you much better performance overall. The final thing I'll mention in Istio
    world is Ambient, that is a node-level proxy that does some of these capabilities.
    That is yet again a cheaper way to start service mesh adoption in places where
    you don't have these capabilities yet.
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，再次，随着我们在规模和异构性上的成长，要么你分配一个更大的团队来做像开发者正在开发的不同语言的那种库工作。在这里存在一系列关于更新、部署和生命周期的挑战。最终，我们看到服务网格对人们变得有趣的转折点是，维护整个组织中一致的一组更新的库的工作，以及在不同版本之间保持兼容性等等，成本往往很高。像
    gRPC 这样的东西使得这一切变得更加可控，而不仅仅是 gRPC，你还可以使用 Spring Boot 或其他东西。在这段旅程中的某个地方，服务网格开始变得更加吸引人。现在，你可以做很多事情来在服务网格部署中拥有更精细化的爆炸半径。特别是，我们建议将它们与你的
    Kubernetes 集群一对一地保持一致，这样你就有了一个精炼的爆炸半径，也就是你的集群。然后在集群中，你可以使用一系列技术来分片工作负载，如果你确实处于巨大规模并且需要多个控制平面。或者有一套配置可以用于服务网格，以帮助限制配置流向何处。像在
    Istio 中，sidecar API 资源可以在整体性能上给你更好的表现。我要在 Istio 的世界中提到的最后一件事是 Ambient，这是一个在节点级别执行某些这些能力的代理。这又是一个更便宜的方式，用于在那些尚未具备这些能力的地方开始服务网格的采纳。
- en: 'Participant 3: [inaudible 00:34:32], it''s a very diverse type of shop. The
    moment we bring up zero trust, it''s always the network thing that comes into
    the picture, and this and that, now we''ve connected the network. Do you have
    any recommendations about how we can make the case [inaudible 00:34:51].'
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者3：[不可听00:34:32]，这是一种非常多样化的商店类型。一旦我们提到零信任，总是涉及到网络问题，这个，那个，现在我们已经连接了网络。你对如何提出案例有什么建议吗？[不可听00:34:51]。
- en: 'Butcher: Show them this 207A, that''s why I wrote it. Legitimately, this is
    a big problem that we hit all over the place. I''m joking but I''m not. I regularly
    talk with folks, and people think, or say, or vendors market that zero trust is
    a network activity. What I talked about is only the runtime side of zero trust.
    That''s the easy part. The people, process, changes are the hard part. I totally
    skipped over those. What arguments to make for the network team, one, the agility
    argument that I made. What is the time to change a policy, and is that hurting
    development agility? Then you can case it in terms of, what are the features that
    aren''t getting deployed to our users because of network pain, because of the
    time it takes for us to do things like policy changes? That''s one angle that
    I would attack it at. The other one is just that, again, you need these authentication
    and authorization pieces as well. The network can do only a portion of that. We
    really need a stronger identity, certainly at the user level. Additionally, we
    would like that at the service level too. Those are some of the things I would
    harp on. You can start to get into things like the layer 7 controls. For example,
    you can say, it''s not just that the frontend can call the backend, I could have
    a microsegmentation policy that models that. You can say, the frontends can only
    call put on the backend, only that one method. That''s something that a traditional
    network policy could not model. Then we can go even further and say, you can only
    call put in the presence of a valid end user credential, if that end user credential
    has the right scope, and a put case right scope, for example. Hopefully, it''s
    pretty clear for folks why that would be a tighter boundary or a better security
    posture than strictly a network oriented one. That''s how I would start to do
    it. Legitimately, the reason I helped write some of these with NIST is to move
    the ball for those teams. For folks, especially that are in banking, for example,
    the FFIEC has already included some of this stuff in their guidance, and in their
    IT handbooks. If you''re in the banking or financial spaces, go pull up the FFIEC
    IT handbook on architecture. There''s a microservices section, and it cites all
    this stuff. That would be your justification in that industry, for example. It
    may or may not help yours. In different industries, we''re actually already seeing
    these guidelines be enforced to standards.'
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
  zh: 屠夫：给他们看看这个207A，这就是我写的原因。说真的，这是我们到处都碰到的一个大问题。我开玩笑，但也不是开玩笑。我经常与人们交谈，人们认为，或者说，或者供应商宣传零信任是一种网络活动。我所谈论的仅仅是零信任的运行时部分。那是简单的部分。人员、流程、变更才是困难的部分。我完全忽略了那些。对于网络团队提出的论据，首先是我提到的敏捷性论点。我们更改策略的时间是多久，这是否损害了开发的敏捷性？然后你可以从这样的角度来看待它，因为由于网络痛苦，由于我们执行像策略更改这样的事情的时间，导致我们的用户无法部署的功能是什么？这是我会从一个角度来攻击它的。另一个是，再次强调，您也需要这些认证和授权组件。网络只能完成其中的一部分。我们确实需要更强的身份验证，特别是在用户级别。此外，我们也希望在服务级别也能有。这些是我会强调的一些事情。你可以开始进入像第7层控制这样的东西。例如，你可以说，不仅仅是前端可以调用后端，我可以有一个微分割策略来模拟这个。你可以说，前端只能调用后端的put方法，只能是那一个方法。这是传统网络策略无法模拟的事情。然后我们甚至可以说，只有在有一个有效的终端用户凭证的情况下，才能调用put，如果该终端用户凭证具有正确的范围和put案例正确的范围，例如。希望对大家来说，为什么这会是一个更严格的边界或者说比严格的网络导向更好的安全姿态，这一点是非常清楚的。这是我开始做的方式。说真的，我帮助NIST写这些东西的原因是为了推动这些团队。对于那些特别是在银行业的人们来说，例如，FFIEC已经在他们的指导和IT手册中包括了一些这些内容。如果你在银行或金融领域，去查一下FFIEC关于架构的IT手册。那里有一个微服务的部分，引用了所有这些东西。例如在这个行业，这可能是你的理由。它可能会帮助你的行业，也可能不会。在不同的行业中，我们实际上已经看到这些指导成为标准。
- en: 'Participant 4: I''m pretty sold on service mesh. We''re using it in production
    in a couple different places. A lot of what you''re talking about here resonates
    really well. I''d be curious, you brought all these white papers. One thing we
    worry about is there''s an obvious tradeoff, you worry about all the power of
    the centralized control. I think now at this point, if I''m an attacker of the
    Kubernetes system, what I really want is to take over Istiod. That''s my attack
    vector I''m looking for. I''ll be straight off and I wanted you to speak to that
    a little bit. Is that something you guys think about?'
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: 第四位参与者：我非常支持服务网格。我们在几个不同的地方正在生产中使用它。你在这里谈论的很多内容都非常 resonates。我很好奇，你带来了所有这些白皮书。我们担心的一件事是明显的权衡，你担心所有集中控制的力量。我认为现在在这一点上，如果我是
    Kubernetes 系统的攻击者，我真正想要的是接管 Istiod。这是我正在寻找的攻击向量。我会直接开门见山，我希望你稍微谈一下这个。你们是否考虑过这个问题？
- en: 'Butcher: Yes, it definitely is. This goes back to that core idea of the service
    mesh potentially being in the kernel. One of the implications there is that, in
    the operating system, the kernel code gets pretty close inspection, it gets a
    lot of security review. There are a lot of bug bounties. There''s a lot of value
    in finding a kernel exploit, whether you''re white hat or black hat, there''s
    a lot of value there. The economics of the environment are set up to hopefully
    make that so you''re going to turn to them and do that. We do similar things with
    the service mesh. Would you rather have a service mesh that''s tackling these
    security postures and one code base that you audit? All the enforcement happens
    in Envoy, so let''s do security audits on Envoy data path. The control plane configuration
    happens in the control plane, let''s do audits on that. Or if instead, we could
    do encryption, the AuthN, the AuthZ for end users and for services in every app.
    Either that''s AppDevs writing it 10 different times, or 100 different times,
    or hopefully you use a library or something like that. The point is, there''s
    one code base that we can audit as opposed to many. Because that''s a shared code
    base and it''s open source, and things like bug bounties already exist for the
    Istio code base, we can have some higher level of assurance that it''s secure.'
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: Butcher：是的，我们确实考虑过。这回到了服务网格潜在地成为内核的核心思想。其中一个影响是，在操作系统中，内核代码接受了相当严格的检查，进行了大量的安全审查。有很多漏洞赏金。无论你是白帽子还是黑帽子，找到内核漏洞都非常有价值。环境的经济学设定为，希望你转向它并这样做。我们在服务网格中也在做类似的事情。你更愿意有一个处理这些安全姿态的服务网格，并且只有一个代码库可以审计吗？所有的执行都发生在
    Envoy 中，所以让我们在 Envoy 数据路径上进行安全审计。控制平面配置发生在控制平面上，让我们对此进行审计。或者，我们可以对每个应用程序中的最终用户和服务进行加密、认证和授权。无论是
    AppDevs 写了 10 次、100 次，还是希望你使用一个库或类似的东西。关键是，我们可以审计一个代码库，而不是很多个。因为这是一个共享的代码库，并且是开源的，像
    Istio 代码库已经存在漏洞赏金，我们可以对其安全性有更高水平的保证。
- en: There's no magic there. Just like the operating system kernel is the attack
    vector that people are very interested in, in the distributed world, the service
    meshes can be too. I think all the service mesh vendors have pretty robust security
    practices. The Linkerd folks have pretty good practices there. I know firsthand
    that Istio security practices in response to CVEs is excellent. It is something
    we think about deeply. We know it's an attack vector, it's the clear thing you
    want to take over. The point is, we can focus our inspection there, we can focus
    our security audits there and gain assurance for the whole system.
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这里没有什么魔法。就像操作系统内核是人们非常感兴趣的攻击向量一样，在分布式世界中，服务网格也可以是。我认为所有服务网格供应商都有相当健全的安全实践。Linkerd
    的团队在这方面有非常好的实践。我亲身知道，Istio 在应对 CVE 的安全实践方面是优秀的。这是我们深入思考的事情。我们知道这是一个攻击向量，这是你想要接管的明显事物。关键是，我们可以集中在这里进行检查，我们可以集中我们的安全审计，并为整个系统获得保障。
- en: 'Participant 5: Or definitely, they can add propagating service principles as
    well as user principle context across the vertical. As you hinted at with Istio''s
    particular service mesh, you can propagate service identities through DNs, through
    service mesh encrypt, mutual TLS. What do you think about that versus pushing
    it up slightly further into layer 7 into say a JWT token, [inaudible 00:41:11]?'
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: 第五位参与者：或者，他们也可以添加传播服务原则以及用户原则的上下文到垂直领域。正如你提到的 Istio 的特定服务网格，你可以通过 DN 传播服务身份，通过服务网格加密、双向
    TLS。你认为这与稍微将其推向第 7 层，比如 JWT 令牌，有什么区别，[不可听 00:41:11]？
- en: 'Butcher: There''s actually prior art in the space. The Secure Production Identity
    Framework for Everyone, SPIFFE, is what all the service meshes today use for application
    identity. SPIFFE was created by Joe Beda of Kubernetes creation fame. SPIFFE was
    actually loosely based on a Google internal technology called LOAS. There was
    a white paper written on that they called ALTS, Application-Level Transport Security.
    Exactly what you''re talking about. That has an interesting set of capabilities.
    If we do it at that layer, we can do things like propagate multiple services.
    We can propagate like the service chain, the frontend called the backend, called
    the database. Then we don''t need to look at policy that''s pairwise. We don''t
    have to say the frontend called the backend, and the backend called the database.
    We can have the full provenance of the call graph, and we can make a decision
    on that. We can say, the database can only be written to if the request traverses
    the frontend and the backend, and only these methods of that. It can only be read
    if it traverses these paths. There''s a huge amount of power in having an application
    identity or service identity. One problem there is you still need to handle encryption
    in transit. That''s fine. There''s a lot of ways to do that. That''s not a huge
    deal, but you do need to handle it. Then, two, there seems to be more runtime
    costs there. A lot of folks have not pursued that one, because, due to that chaining,
    you tend to have to reissue JWTs since there''s a lot of signing pressure on your
    JWT server. There''s a set of tradeoffs there. Basically, at runtime, we''ve seen
    that it''s pretty decent to do mTLS for app identity. There''s plenty of prior
    art for doing service identity in the app level, in a thing like a JWT, and even
    nesting the JWTs and having end user and service JWTs together. All of those are
    good and valid. You don''t have to do with SPIFFE and mTLS, like the mesh does.'
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: Butcher：实际上，在这个领域已经有先例。对于应用程序身份，所有的服务网格今天都使用安全生产身份框架（SPIFFE）。SPIFFE是由Kubernetes创建者乔·贝达创建的。SPIFFE实际上是基于谷歌内部技术LOAS的松散架构。他们写了一篇名为ALTS的白皮书。正是你所说的那个。这具有一系列有趣的功能。如果我们在那个层面做，我们可以做一些像传播多个服务这样的事情。我们可以传播像服务链这样的东西，前端称为后端，称为数据库。然后我们不需要看一对一的策略。我们不必说前端称为后端，后端称为数据库。我们可以有呼叫图的完整起源，并且我们可以根据此做出决策。我们可以说，只有请求经过前端和后端才能将数据库写入，并且只有这些方法。如果它经过这些路径，它只能被读取。在具有应用程序身份或服务身份的情况下，有大量的力量。那里的一个问题是，你仍然需要处理传输中的加密。没问题。有很多方法可以做到这一点。这不是一个大问题，但你确实需要处理它。然后，有两点，那里似乎有更多的运行时成本。许多人由于那种链接而没有追求它，因为由于签名服务器上有很多签名压力，你往往必须重新发出JWT。那里有一系列权衡。基本上，在运行时，我们看到对于应用程序身份来说，使用mTLS相当不错。有很多关于在应用程序级别进行服务身份的先例，例如JWT，甚至将JWT进行嵌套并将端用户和服务JWT放在一起。所有这些都是好的和有效的。你不必像网格一样使用SPIFFE和mTLS。
- en: 'Participant 6: In terms of the identity security, how do you see the role-based
    security and the mesh service?'
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: 参与者 6：在身份安全方面，您如何看待基于角色的安全和网格服务？
- en: 'Butcher: How do we see RBAC, role-based access control, and other access control
    paradigms when it comes to the service mesh?'
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: Butcher：当涉及到服务网格时，我们如何看待RBAC（基于角色的访问控制）和其他访问控制范式？
- en: When it comes to authorizing service-to-service access, use what scheme works
    well for you. In Istio, there's a native authorization API that is an RBAC style
    API. In that world, if you're doing just pure upstream Istio, you're just writing
    straight RBAC, basically. That's the only option you have, when it comes to service-to-service
    access. There are definitely other schemes out there. Plenty of folks implement
    it with something like OPA, Open Policy Agent, and they encode their policy about
    service-to-service access there. That has a very different manifestation and policy
    language, comparatively. From the point of 207A, we don't really care what the
    authorization mechanism is. If you go read SP 800-204B, we make the strong argument
    that next generation access control, NGAC, is the access control system you want
    to be using for service-to-service access. It's a modern RBAC. That's one of the
    key areas I do research in, is access control in general and next generation access
    control specifically.
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在授权服务到服务访问时，请使用适合您的方案。在 Istio 中，有一个本地授权 API，这是一种 RBAC 风格的 API。在这个世界中，如果你只是在纯上游
    Istio 中工作，你基本上只是编写直接的 RBAC。这是你在处理服务到服务访问时唯一的选择。肯定还有其他方案。许多人使用像 OPA（Open Policy
    Agent）这样的东西来实现，他们在那里编码关于服务到服务访问的策略。从 207A 的角度来看，我们不太关心授权机制是什么。如果你去读 SP 800-204B，我们强烈主张下一代访问控制，NGAC，是你应该用于服务到服务访问的访问控制系统。这是现代化的
    RBAC。访问控制总体上是我研究的关键领域之一，特别是下一代访问控制。
- en: '**See more [presentations with transcripts](https://www.infoq.com/transcripts/presentations/)**'
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**查看更多 [带有文本](https://www.infoq.com/transcripts/presentations/)的演示**'
