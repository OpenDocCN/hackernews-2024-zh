- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 13:30:29'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 13:30:29'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: apple/OpenELM · Hugging Face
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: apple/OpenELM · Hugging Face
- en: 来源：[https://huggingface.co/apple/OpenELM](https://huggingface.co/apple/OpenELM)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://huggingface.co/apple/OpenELM](https://huggingface.co/apple/OpenELM)
- en: '[](#openelm-an-efficient-language-model-family-with-open-training-and-inference-framework)OpenELM:
    An Efficient Language Model Family with Open Training and Inference Framework'
  id: totrans-split-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[](#openelm-an-efficient-language-model-family-with-open-training-and-inference-framework)OpenELM：一种具有开放训练和推断框架的高效语言模型系列'
- en: '*Sachin Mehta, Mohammad Hossein Sekhavat, Qingqing Cao, Maxwell Horton, Yanzi
    Jin, Chenfan Sun, Iman Mirzadeh, Mahyar Najibi, Dmitry Belenko, Peter Zatloukal,
    Mohammad Rastegari*'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*Sachin Mehta, Mohammad Hossein Sekhavat, Qingqing Cao, Maxwell Horton, Yanzi
    Jin, Chenfan Sun, Iman Mirzadeh, Mahyar Najibi, Dmitry Belenko, Peter Zatloukal,
    Mohammad Rastegari*'
- en: We introduce **OpenELM**, a family of **Open** **E**fficient **L**anguage **M**odels.
    OpenELM uses a layer-wise scaling strategy to efficiently allocate parameters
    within each layer of the transformer model, leading to enhanced accuracy. We pretrained
    OpenELM models using the [CoreNet](https://github.com/apple/corenet) library.
    We release both pretrained and instruction tuned models with 270M, 450M, 1.1B
    and 3B parameters.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们引入**OpenELM**，这是一系列**开放** **高效** **语言** **模型**。OpenELM采用逐层缩放策略，在转换器模型的每一层内高效分配参数，从而提高精度。我们使用[CoreNet](https://github.com/apple/corenet)库预训练了OpenELM模型。我们发布了270M、450M、1.1B和3B参数的预训练和调整模型。
- en: Our pre-training dataset contains RefinedWeb, deduplicated PILE, a subset of
    RedPajama, and a subset of Dolma v1.6, totaling approximately 1.8 trillion tokens.
    Please check license agreements and terms of these datasets before using them.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的预训练数据集包括RefinedWeb、去重的PILE、RedPajama的子集以及Dolma v1.6的子集，总共约1.8万亿个标记。请在使用这些数据集之前查看许可协议和条款。
- en: 'See the list below for the details of each model:'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅以下列表，了解每个模型的详细信息：
- en: '[PRE0]'
  id: totrans-split-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[](#usage)Usage'
  id: totrans-split-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[](#usage)使用方法'
- en: We have provided an example function to generate output from OpenELM models
    loaded via [HuggingFace Hub](https://huggingface.co/docs/hub/) in `generate_openelm.py`.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了一个示例函数，用于从通过[HuggingFace Hub](https://huggingface.co/docs/hub/)加载的OpenELM模型中生成输出，在`generate_openelm.py`中。
- en: 'You can try the model by running the following command:'
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过运行以下命令来尝试该模型：
- en: '[PRE1]'
  id: totrans-split-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Please refer to [this link](https://huggingface.co/docs/hub/security-tokens)
    to obtain your hugging face access token.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考[此链接](https://huggingface.co/docs/hub/security-tokens)获取您的Hugging Face访问令牌。
- en: 'Additional arguments to the hugging face generate function can be passed via
    `generate_kwargs`. As an example, to speedup the inference, you can try [lookup
    token speculative generation](https://huggingface.co/docs/transformers/generation_strategies)
    by passing the `prompt_lookup_num_tokens` argument as follows:'
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 通过`generate_kwargs`参数可以向Hugging Face生成函数传递额外的参数。例如，为了加速推断过程，可以尝试通过传递`prompt_lookup_num_tokens`参数来进行[查找标记推测生成](https://huggingface.co/docs/transformers/generation_strategies)：
- en: '[PRE2]'
  id: totrans-split-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Alternatively, try model-wise speculative generation with an [assistive model](https://huggingface.co/blog/assisted-generation)
    by passing a smaller model through the `assistant_model` argument, for example:'
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，通过将辅助模型传递给`assistant_model`参数，例如，可以尝试按模型进行推测生成：
- en: '[PRE3]'
  id: totrans-split-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[](#main-results)Main Results'
  id: totrans-split-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[](#main-results)主要结果'
- en: '[](#zero-shot)Zero-Shot'
  id: totrans-split-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[](#zero-shot)零样本'
- en: '[](#llm360)LLM360'
  id: totrans-split-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[](#llm360)LLM360'
- en: '[](#openllm-leaderboard)OpenLLM Leaderboard'
  id: totrans-split-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[](#openllm-leaderboard)OpenLLM排行榜'
- en: '| **Model Size** | **ARC-c** | **CrowS-Pairs** | **HellaSwag** | **MMLU** |
    **PIQA** | **RACE** | **TruthfulQA** | **WinoGrande** | **Average** |'
  id: totrans-split-25
  prefs: []
  type: TYPE_TB
  zh: '| **模型大小** | **ARC-c** | **CrowS-Pairs** | **HellaSwag** | **MMLU** | **PIQA**
    | **RACE** | **TruthfulQA** | **WinoGrande** | **平均值** |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-split-26
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| [OpenELM-270M](https://huggingface.co/apple/OpenELM-270M) | 27.65 | **66.79**
    | 47.15 | 25.72 | 69.75 | 30.91 | **39.24** | **53.83** | 45.13 |'
  id: totrans-split-27
  prefs: []
  type: TYPE_TB
  zh: '| [OpenELM-270M](https://huggingface.co/apple/OpenELM-270M) | 27.65 | **66.79**
    | 47.15 | 25.72 | 69.75 | 30.91 | **39.24** | **53.83** | 45.13 |'
- en: '| [OpenELM-270M-Instruct](https://huggingface.co/apple/OpenELM-270M-Instruct)
    | **32.51** | 66.01 | **51.58** | **26.70** | **70.78** | 33.78 | 38.72 | 53.20
    | **46.66** |'
  id: totrans-split-28
  prefs: []
  type: TYPE_TB
  zh: '| [OpenELM-270M-Instruct](https://huggingface.co/apple/OpenELM-270M-Instruct)
    | **32.51** | 66.01 | **51.58** | **26.70** | **70.78** | 33.78 | 38.72 | 53.20
    | **46.66** |'
- en: '| [OpenELM-450M](https://huggingface.co/apple/OpenELM-450M) | 30.20 | **68.63**
    | 53.86 | **26.01** | 72.31 | 33.11 | 40.18 | 57.22 | 47.69 |'
  id: totrans-split-29
  prefs: []
  type: TYPE_TB
  zh: '| [OpenELM-450M](https://huggingface.co/apple/OpenELM-450M) | 30.20 | **68.63**
    | 53.86 | **26.01** | 72.31 | 33.11 | 40.18 | 57.22 | 47.69 |'
- en: '| [OpenELM-450M-Instruct](https://huggingface.co/apple/OpenELM-450M-Instruct)
    | **33.53** | 67.44 | **59.31** | 25.41 | **72.63** | **36.84** | **40.48** |
    **58.33** | **49.25** |'
  id: totrans-split-30
  prefs: []
  type: TYPE_TB
  zh: '| [OpenELM-450M-Instruct](https://huggingface.co/apple/OpenELM-450M-Instruct)
    | **33.53** | 67.44 | **59.31** | 25.41 | **72.63** | **36.84** | **40.48** |
    **58.33** | **49.25** |'
- en: '| [OpenELM-1_1B](https://huggingface.co/apple/OpenELM-1_1B) | 36.69 | **71.74**
    | 65.71 | **27.05** | **75.57** | 36.46 | 36.98 | 63.22 | 51.68 |'
  id: totrans-split-31
  prefs: []
  type: TYPE_TB
  zh: '| [OpenELM-1_1B](https://huggingface.co/apple/OpenELM-1_1B) | 36.69 | **71.74**
    | 65.71 | **27.05** | **75.57** | 36.46 | 36.98 | 63.22 | 51.68 |'
- en: '| [OpenELM-1_1B-Instruct](https://huggingface.co/apple/OpenELM-1_1B-Instruct)
    | **41.55** | 71.02 | **71.83** | 25.65 | 75.03 | **39.43** | **45.95** | **64.72**
    | **54.40** |'
  id: totrans-split-32
  prefs: []
  type: TYPE_TB
  zh: '| [OpenELM-1_1B-Instruct](https://huggingface.co/apple/OpenELM-1_1B-Instruct)
    | **41.55** | 71.02 | **71.83** | 25.65 | 75.03 | **39.43** | **45.95** | **64.72**
    | **54.40** |'
- en: '| [OpenELM-3B](https://huggingface.co/apple/OpenELM-3B) | 42.24 | **73.29**
    | 73.28 | **26.76** | 78.24 | **38.76** | 34.98 | 67.25 | 54.35 |'
  id: totrans-split-33
  prefs: []
  type: TYPE_TB
  zh: '| [OpenELM-3B](https://huggingface.co/apple/OpenELM-3B) | 42.24 | **73.29**
    | 73.28 | **26.76** | 78.24 | **38.76** | 34.98 | 67.25 | 54.35 |'
- en: '| [OpenELM-3B-Instruct](https://huggingface.co/apple/OpenELM-3B-Instruct) |
    **47.70** | 72.33 | **76.87** | 24.80 | **79.00** | 38.47 | **38.76** | **67.96**
    | **55.73** |'
  id: totrans-split-34
  prefs: []
  type: TYPE_TB
  zh: '| [OpenELM-3B-Instruct](https://huggingface.co/apple/OpenELM-3B-Instruct) |
    **47.70** | 72.33 | **76.87** | 24.80 | **79.00** | 38.47 | **38.76** | **67.96**
    | **55.73** |'
- en: See the technical report for more results and comparison.
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 详见技术报告获取更多结果和比较。
- en: '[](#evaluation)Evaluation'
  id: totrans-split-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[](#evaluation)评估'
- en: '[](#setup)Setup'
  id: totrans-split-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[](#setup)设置'
- en: 'Install the following dependencies:'
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: 安装以下依赖项：
- en: '[PRE4]'
  id: totrans-split-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[](#evaluate-openelm)Evaluate OpenELM'
  id: totrans-split-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '[](#evaluate-openelm)评估 OpenELM'
- en: '[PRE5]'
  id: totrans-split-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[](#bias-risks-and-limitations)Bias, Risks, and Limitations'
  id: totrans-split-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[](#bias-risks-and-limitations)偏见、风险和限制'
- en: The release of OpenELM models aims to empower and enrich the open research community
    by providing access to state-of-the-art language models. Trained on publicly available
    datasets, these models are made available without any safety guarantees. Consequently,
    there exists the possibility of these models producing outputs that are inaccurate,
    harmful, biased, or objectionable in response to user prompts. Thus, it is imperative
    for users and developers to undertake thorough safety testing and implement appropriate
    filtering mechanisms tailored to their specific requirements.
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: 开放ELM模型的发布旨在通过提供最先进的语言模型，增强和丰富开放研究社区的能力。这些模型是在公开可用的数据集上训练的，无需任何安全保证。因此，这些模型有可能在响应用户提示时产生不准确、有害、偏见或令人反感的输出。因此，对于用户和开发者来说，进行彻底的安全测试并实施适合其特定需求的适当过滤机制至关重要。
- en: '[](#citation)Citation'
  id: totrans-split-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '[](#citation)引用'
- en: 'If you find our work useful, please cite:'
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您觉得我们的工作有用，请引用：
- en: '[PRE6]'
  id: totrans-split-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
