- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 15:01:09'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 15:01:09'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: GPU's rival? What is Language Processing Unit (LPU)
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPU的竞争对手？什么是语言处理单元（LPU）
- en: 来源：[https://www.turingpost.com/p/fod41](https://www.turingpost.com/p/fod41)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.turingpost.com/p/fod41](https://www.turingpost.com/p/fod41)
- en: 'Next Week in Turing Post:'
  id: totrans-split-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 下周在图灵邮报：
- en: 'Wednesday, Token 1.21: **Model Safety and Data Privacy**'
  id: totrans-split-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期三，Token 1.21：**模型安全与数据隐私**
- en: 'Friday, AI Unicorns: **Scale AI**'
  id: totrans-split-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期五，AI独角兽：**Scale AI**
- en: '*Turing Post is a reader-supported publication. To have full access to our
    most interesting articles and investigations, become a paid subscriber →*'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*图灵邮报是一份由读者支持的出版物。要完全访问我们最有趣的文章和调查，请成为付费订户→*'
- en: This week, a largely unknown company, [Groq](https://groq.com/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu),
    demonstrated unprecedented speed running open-source LLMs such as Llama-2 (70
    billion parameters) at more than 100 tokens per second, and Mixtral at nearly
    500 tokens per second per user on a Groq’s Language Processing Unit (LPU).
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本周，一家鲜为人知的公司，[Groq](https://groq.com/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)，展示了前所未有的速度，在Groq的语言处理单元（LPU）上运行开源LLMs（如Llama-2（700亿参数）每秒超过100个标记，Mixtral每用户每秒接近500个标记。
- en: “According to Groq, in similar tests, ChatGPT loads at 40-50 tokens per second,
    and Bard at 70 tokens per second on typical GPU-based computing systems.
  id: totrans-split-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: “根据Groq的说法，在类似测试中，ChatGPT在典型的基于GPU的计算系统上每秒加载40-50个标记，而Bard每秒70个标记。
- en: Context for 100 tokens per second per user – A user could generate a 4,000-word
    essay in just over a minute.”
  id: totrans-split-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每用户每秒100个标记的背景——用户可以在一分钟多一点的时间内生成一篇4000字的文章。”
- en: 'So: **What is LPU, how does it work**, and where is Groq (such an unfortunate
    name, given Musk''s Grok is all over the media) coming from?'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 所以：**LPU是什么，它是如何工作的**，Groq（这个名字真不幸，鉴于马斯克的Grok在媒体上随处可见）又来自哪里？
- en: Remember that game of Go in 2016 when AlphaGo played against the world champion
    Lee Sedol and won? Well, about a month before the competition, there was a test
    game which AlphaGo lost. The researchers from DeepMind ported AlphaGo to Tensor
    Processing Unit (TPU) and then the computer program was able to win by a wide
    margin.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 记得2016年的围棋比赛吗？AlphaGo对阵世界冠军李世石并取得胜利？嗯，在比赛前大约一个月，有一场测试比赛AlphaGo输了。DeepMind的研究人员将AlphaGo移植到Tensor处理单元（TPU），然后计算机程序以大幅度的优势获胜。
- en: The realization that computational power was a bottleneck for AI's potential
    led to the inception of Groq and the creation of the LPU. This realization came
    to [Jonathan Ross](https://www.linkedin.com/in/ross-jonathan/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    who initially began what became TPU project in Google. He started Groq in 2016\.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 认识到计算能力是AI潜力的瓶颈，这促使了Groq的诞生以及LPU的创建。这一认识最初来自[Jonathan Ross](https://www.linkedin.com/in/ross-jonathan/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)，他最初开始了Google的TPU项目。他于2016年创立了Groq。
- en: '**The LPU is a special kind of computer brain designed to handle language tasks
    very quickly.** Unlike other computer chips that do many things at once (parallel
    processing), the LPU works on tasks one after the other (sequential processing),
    which is perfect for understanding and generating language. Imagine it like a
    relay race where each runner (chip) passes the baton (data) to the next, making
    everything run super fast. The LPU is designed to overcome the two LLM bottlenecks:
    compute density and memory bandwidth.'
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**LPU是一种特殊的计算机大脑，设计用于非常快速地处理语言任务。**与同时执行多项任务的其他计算机芯片（并行处理）不同，LPU依次处理任务（顺序处理），这非常适合理解和生成语言。可以将其想象成接力比赛，每位跑步者（芯片）将接力棒（数据）传递给下一位，使一切运行得非常快速。LPU的设计旨在克服两个LLM的瓶颈：计算密度和内存带宽。'
- en: Groq took a novel approach right from the start, **focusing on software and
    compiler development** before even thinking about the hardware. They made sure
    the software could guide how the chips talk to each other, ensuring they work
    together seamlessly like a team in a factory. This makes the LPU really good at
    processing language efficiently and at high speed, ideal for AI tasks that involve
    understanding or creating text.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: Groq从一开始就采用了新颖的方法，**专注于软件和编译器开发**，甚至在考虑硬件之前。他们确保软件能够指导芯片如何相互通信，确保它们像工厂中的团队一样无缝协作。这使得LPU在处理语言时效率和速度都非常高，非常适合涉及理解或创建文本的AI任务。
- en: This led to a highly optimized system that not only runs circles around traditional
    setups in terms of speed but does so with greater cost efficiency and lower energy
    consumption. This is big news for industries like finance, government, and tech,
    where quick and accurate data processing is key.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这导致了一个高度优化的系统，不仅在速度方面远远超过传统设置，而且在成本效率和能源消耗方面表现出色。对于金融、政府和科技等行业来说，快速和准确的数据处理至关重要。
- en: Now, don't go tossing out your GPUs just yet! While the LPU is a beast when
    it comes to inference, making light work of applying trained models to new data,
    GPUs still reign supreme in the training arena. The LPU and GPU might become the
    dynamic duo of AI hardware, each excelling in their respective roles.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，请不要着急丢弃你们的GPU！虽然LPU在推理方面表现出色，轻松应用训练模型到新数据上，但GPU在训练领域仍然占据主导地位。LPU和GPU可能成为AI硬件的动态二人组，各自在其角色中表现出色。
- en: 'As Elvis Saravia [put](https://www.linkedin.com/feed/update/urn:li:activity:7165371713378074624/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    it: “*With breakthroughs in inference and long context understanding, we are officially
    entering a new era in LLMs.*”'
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 正如Elvis Saravia所说：“*随着推理和长文本理解的突破，我们正式进入了LLM的新时代*。”
- en: 'To better understand architecture, Groq offers two papers: from [2020](https://wow.groq.com/groq-isca-paper-2020/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    (*Think Fast: A Tensor Streaming Processor (TSP) for Accelerating Deep Learning
    Workloads*) and [2022](https://wow.groq.com/isca-2022-paper/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    (*A Soware-defined Tensor Streaming Multiprocessor for Large-scale Machine Learning*). The
    term “LPU” must be a recent addition to Groq’s narrative, since it’s never mentioned
    in the papers.'
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解架构，Groq提供了两篇论文：[2020年](https://wow.groq.com/groq-isca-paper-2020/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)（*快速思考：用于加速深度学习工作负载的张量流处理器（TSP）*）和[2022年](https://wow.groq.com/isca-2022-paper/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)（*用于大规模机器学习的软件定义张量流多处理器*）。由于这些论文中从未提到过“LPU”，这个术语可能是Groq最近才添加的。
- en: 'Compute is also a part of this paper: [Computing Power and the Governance of
    Artificial Intelligence](https://arxiv.org/pdf/2402.08797.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    that discusses managing AI development through compute control, focusing on its
    potential for regulation, benefits, and risks, and suggests balanced governance
    approaches.'
  id: totrans-split-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这篇论文还涉及计算：[计算能力与人工智能治理](https://arxiv.org/pdf/2402.08797.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)，讨论通过计算控制管理AI发展，专注于其监管、利益和风险潜力，并建议平衡的治理方法。
- en: Meanwhile, The U.S. [awards](https://www.reuters.com/technology/us-awards-15-bln-globalfoundries-domestic-semiconductor-production-2024-02-19?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    GlobalFoundries, the world's third-largest contract chipmaker, $1.5 billion to
    boost semiconductor production, enhancing domestic supply chains, with expansions
    in New York and Vermont.
  id: totrans-split-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与此同时，美国向全球第三大合同芯片制造商GlobalFoundries [授予](https://www.reuters.com/technology/us-awards-15-bln-globalfoundries-domestic-semiconductor-production-2024-02-19?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    15亿美元，以增加半导体生产，增强国内供应链，在纽约和佛蒙特州进行扩展。
- en: The paper [published](https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    by Berkeley Artificial Intelligence Research (BAIR) argues that “**compound AI
    systems will likely be the best way to maximize AI results in the future**, and
    might be one of the most impactful trends in AI in 2024.”
  id: totrans-split-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由加州大学伯克利分校人工智能研究（BAIR）发布的论文认为，“**复合人工智能系统可能是未来最大化AI成果的最佳途径**，可能是2024年AI领域最有影响力的趋势之一。”
- en: News from The Usual Suspects ©
  id: totrans-split-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 来自The Usual Suspects ©的消息
- en: Y Combinator
  id: totrans-split-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Y Combinator
- en: 'Since 2009, Y Combinator has published **[Request for Startups](https://www.ycombinator.com/rfs?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)**
    which hints at what “ideas we’d want to see made real, in spaces that we believe
    will be important in the coming decades”. This year, the list contains 20 categories:'
  id: totrans-split-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自2009年以来，Y Combinator发布了**[创业创意征集](https://www.ycombinator.com/rfs?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)**，暗示了“我们希望在未来几十年内成为现实的想法，涉及到我们认为未来重要的领域”。今年的列表包含20个类别：
- en: 20 big names
  id: totrans-split-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20个大名鼎鼎的公司
- en: Twenty tech giants, including Adobe, Amazon, Google, IBM, Meta, Microsoft, OpenAI,
    and TikTok, have [agreed](https://apnews.com/article/ai-generated-election-deepfakes-munich-accord-meta-google-microsoft-tiktok-x-c40924ffc68c94fac74fa994c520fc06?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    to take "reasonable precautions" to prevent the misuse of AI in disrupting elections
    worldwide.
  id: totrans-split-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 二十大科技巨头，包括Adobe、Amazon、Google、IBM、Meta、Microsoft、OpenAI和TikTok，已经同意采取“合理预防措施”，以防止人工智能在全球选举中被滥用，[参考链接](https://apnews.com/article/ai-generated-election-deepfakes-munich-accord-meta-google-microsoft-tiktok-x-c40924ffc68c94fac74fa994c520fc06?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)。
- en: OpenAI
  id: totrans-split-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenAI
- en: 'Models making headlines:'
  id: totrans-split-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 亮点模型：
- en: '**Introducing Sora**: This paper introduces Sora, a breakthrough in video generation
    technology by OpenAI, capable of producing high-fidelity videos. It leverages
    spacetime patches to handle videos of varying durations and resolutions, making
    strides toward simulating the physical world with impressive 3D consistency and
    long-range coherence. It represents a leap in the ability to create detailed simulations
    that could be used for a myriad of applications, from entertainment to virtual
    testing environments [→read the paper](https://openai.com/research/video-generation-models-as-world-simulators?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**介绍Sora**：本文介绍了Sora，这是OpenAI在视频生成技术上的突破，能够生成高保真度视频。它利用时空补丁处理不同长度和分辨率的视频，向模拟物理世界的3D一致性和长程连贯性迈出了重要一步。这代表了在创建详细模拟方面的飞跃，可用于从娱乐到虚拟测试环境等多种应用
    [→阅读论文](https://openai.com/research/video-generation-models-as-world-simulators?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Additional read:**'
  id: totrans-split-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**额外阅读：**'
- en: '**Introducing V-Jepa** (Yann LeCun’s vision of advanced machine intelligence
    (AMI): Meta''s V-JEPA model revolutionizes unsupervised learning from videos by
    using feature prediction as its sole objective. This approach bypasses the need
    for pre-trained image encoders or text annotations, relying instead on the intrinsic
    dynamics of video data to learn versatile visual representations. It''s a significant
    contribution to the field of unsupervised visual learning, promising advancements
    in how machines understand motion and appearance without explicit guidance [→read
    the paper](https://scontent-lga3-1.xx.fbcdn.net/v/t39.2365-6/427986745_768441298640104_1604906292521363076_n.pdf?_nc_cat=103&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=Lpq5IeF5ftUAX_QVyw0&_nc_ht=scontent-lga3-1.xx&oh=00_AfCxzl-IotQM2_EGXbgWfRe66yPVffGfxGm5oSY74v1Slw&oe=65D898F1&utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**介绍V-Jepa**（Yann LeCun对先进机器智能（AMI）的愿景）：Meta的V-JEPA模型通过仅使用特征预测作为其唯一目标，革新了从视频中进行无监督学习的方式。这种方法绕过了需要预先训练的图像编码器或文本注释，而是依靠视频数据的内在动态来学习多功能视觉表示。这是对无监督视觉学习领域的重大贡献，有望在机器理解运动和外观时不需要显式指导方面取得进展
    [→阅读论文](https://scontent-lga3-1.xx.fbcdn.net/v/t39.2365-6/427986745_768441298640104_1604906292521363076_n.pdf?_nc_cat=103&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=Lpq5IeF5ftUAX_QVyw0&_nc_ht=scontent-lga3-1.xx&oh=00_AfCxzl-IotQM2_EGXbgWfRe66yPVffGfxGm5oSY74v1Slw&oe=65D898F1&utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Introducing Gemini 1.5**: Google DeepMind''s Gemini 1.5 introduces a Mixture-of-Experts
    architecture, enhancing the model''s performance across a broader array of tasks.
    Notably, it expands the context window to 1 million tokens, enabling deep analysis
    over large datasets. Gemini 1.5 represents a significant step forward in AI''s
    capability to process and understand extensive contexts, marking a milestone in
    the development of multimodal models [→read the paper](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu#build-experiment)'
  id: totrans-split-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**介绍 Gemini 1.5**：Google DeepMind 的 Gemini 1.5 引入了专家混合架构，增强了模型在更广泛任务上的性能。特别是，它将上下文窗口扩展到
    100 万个标记，能够深入分析大型数据集。Gemini 1.5 代表了人工智能在处理和理解广泛语境方面的重大进展，标志着多模态模型发展的一个里程碑 [→阅读论文](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu#build-experiment)'
- en: '**Introducing Stable Cascade**: Stable Cascade from Stability AI introduces
    a novel text-to-image generation framework that prioritizes efficiency, ease of
    training, and fine-tuning on consumer-grade hardware. The model''s hierarchical
    compression technique represents a significant reduction in the resources required
    for training high-quality generative models, providing a pathway for wider accessibility
    and experimentation in the AI community [→read the paper](https://stability.ai/news/introducing-stable-cascade?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**介绍 Stable Cascade**：Stability AI 的 Stable Cascade 引入了一种新的文本到图像生成框架，优先考虑效率、易于训练以及在消费级硬件上的微调。模型的分层压缩技术显著减少了训练高质量生成模型所需的资源，为人工智能社区提供了更广泛的可访问性和实验路径
    [→阅读论文](https://stability.ai/news/introducing-stable-cascade?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: The freshest research papers, categorized for your convenience
  id: totrans-split-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为您方便分类的最新研究论文
- en: Language Understanding and Generation
  id: totrans-split-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语言理解与生成
- en: '**OpenToM**: Explores evaluating Theory-of-Mind reasoning in LLMs, addressing
    their capability to understand complex social and psychological narratives. [Read
    the paper](https://arxiv.org/pdf/2402.06044.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**OpenToM**：探索评估语言模型的心理理论推理能力，解决它们理解复杂社会和心理叙事的能力。[阅读论文](https://arxiv.org/pdf/2402.06044.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**In Search of Needles in a 10M Haystack**: Demonstrates the capability of
    NLP models to process exceptionally long documents, pushing the boundaries of
    document length comprehension. [Read the paper](https://arxiv.org/pdf/2402.10790.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**在一堆 10M 中寻找针**：展示了自然语言处理模型处理异常长文档的能力，推动了文档长度理解的边界。[阅读论文](https://arxiv.org/pdf/2402.10790.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Premise Order Matters in Reasoning with LLMs**: Investigates the sensitivity
    of LLMs to the order of premises, revealing implications for reasoning tasks.
    [Read the paper](https://arxiv.org/pdf/2402.08939.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**前提顺序在逻辑推理中的重要性**：研究了语言模型对前提顺序的敏感性，揭示了对推理任务的影响。[阅读论文](https://arxiv.org/pdf/2402.08939.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Chain-of-Thought Reasoning Without Prompting**: Uncovers the inherent ability
    of LLMs to generate reasoning paths, suggesting an alternative to explicit prompting.
    [Read the paper](https://arxiv.org/pdf/2402.10200.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无需提示的链式思维推理**：揭示了语言模型生成推理路径的固有能力，提出了一种替代显式提示的方法。[阅读论文](https://arxiv.org/pdf/2402.10200.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Suppressing Pink Elephants with Direct Principle Feedback**: Addresses the
    challenge of topic avoidance in LLMs, proposing a novel fine-tuning method for
    enhanced controllability. [Read the paper](https://arxiv.org/pdf/2402.07896.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用直接原则反馈抑制粉色大象**：解决了LLM中主题回避的挑战，提出了一种新的微调方法，以增强可控性。[阅读论文](https://arxiv.org/pdf/2402.07896.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**GhostWriter**: Develops an AI-powered writing environment focusing on personalization
    and increased user control in collaborative writing. [Read the paper](https://arxiv.org/pdf/2402.08855.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GhostWriter**：开发了一个以AI为动力的写作环境，侧重于个性化和增强用户在协作写作中的控制权。[阅读论文](https://arxiv.org/pdf/2402.08855.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: Speech and Text-to-Speech Technologies
  id: totrans-split-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语音和文本到语音技术
- en: Mathematical and Scientific Reasoning
  id: totrans-split-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数学和科学推理
- en: '**OpenMathInstruct-1**: Develops a dataset for math instruction tuning, aiming
    to improve LLMs'' mathematical reasoning capabilities. [Read the paper](https://arxiv.org/pdf/2402.10176.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**OpenMathInstruct-1**：开发了一个用于数学指导调整的数据集，旨在提高LLM在数学推理能力方面的表现。[阅读论文](https://arxiv.org/pdf/2402.10176.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**InternLM-Math**: Introduces a specialized LLM for math reasoning, incorporating
    various techniques for enhanced problem-solving in mathematics. [Read the paper](https://arxiv.org/pdf/2402.06332.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**InternLM-Math**：介绍了一种专门用于数学推理的语言模型，结合了各种技术，以增强数学问题解决能力。[阅读论文](https://arxiv.org/pdf/2402.06332.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**ChemLLM**: Creates the first LLM dedicated to chemistry, transforming structured
    chemical data into dialogue for diverse chemical tasks. [Read the paper](https://arxiv.org/pdf/2402.06852.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ChemLLM**：创建了第一个专用于化学的LLM，将结构化的化学数据转化为多样化的化学任务对话。[阅读论文](https://arxiv.org/pdf/2402.06852.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: Efficiency and Data Utilization in AI
  id: totrans-split-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AI中的效率和数据利用
- en: '**How to Train Data-Efficient LLMs**: Proposes sampling methods for enhancing
    data efficiency in LLM training, optimizing example selection. [Read the paper](https://arxiv.org/pdf/2402.09668.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**如何训练数据高效的LLM**：提出了增强LLM训练数据效率的采样方法，优化示例选择。[阅读论文](https://arxiv.org/pdf/2402.09668.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**FIDDLER**: Introduces a system for efficient inference of MoE models, leveraging
    CPU-GPU orchestration for improved performance in resource-limited settings. [Read
    the paper](https://arxiv.org/pdf/2402.07033.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FIDDLER**：引入了一种用于有效推断MoE模型的系统，利用CPU-GPU协同作业来提高资源受限环境下的性能。[阅读论文](https://arxiv.org/pdf/2402.07033.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Tandem Transformers**: Presents an architecture for improving inference efficiency
    of LLMs, utilizing a dual-model system for faster and accurate predictions. [Read
    the paper](https://arxiv.org/pdf/2402.08644.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tandem Transformers**：提出了一种用于提高LLM推理效率的架构，利用双模型系统进行更快速和准确的预测。[阅读论文](https://arxiv.org/pdf/2402.08644.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Towards Next-Level Post-Training Quantization of Hyper-Scale Transformers**:
    Proposes an advanced PTQ algorithm for efficient deployment of large Transformer
    models on edge devices. [Read the paper](https://arxiv.org/pdf/2402.08958.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**走向超大规模变压器后训练量化的下一级**: 提出了一种先进的 PTQ 算法，用于在边缘设备上高效部署大型变压器模型。[阅读论文](https://arxiv.org/pdf/2402.08958.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: Multimodal and Vision-Language Models
  id: totrans-split-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多模态和视觉语言模型
- en: Reinforcement Learning and Model Behavior
  id: totrans-split-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 强化学习与模型行为
- en: '**ODIN**: Addresses reward hacking in RLHF, proposing a method to mitigate
    verbosity bias in LLMs for more concise and content-focused responses. [Read the
    paper](https://arxiv.org/pdf/2402.07319.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ODIN**: 处理 RLHF 中的奖励黑客问题，提出了一种方法来减轻 LLM 中的冗长偏见，以获得更简洁和内容聚焦的响应。[阅读论文](https://arxiv.org/pdf/2402.07319.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Mixtures of Experts Unlock Parameter Scaling for Deep RL**: Shows the impact
    of MoE modules on deep RL networks, enhancing parameter scalability and performance.
    [Read the paper](https://arxiv.org/pdf/2402.08609.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专家混合解锁深度 RL 参数缩放**: 展示了 MoE 模块对深度 RL 网络的影响，增强了参数可伸缩性和性能。[阅读论文](https://arxiv.org/pdf/2402.08609.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: Operating Systems and Generalist Agents
  id: totrans-split-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 操作系统和通用代理
- en: Graph Learning and State Space Models
  id: totrans-split-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 图学习和状态空间模型
- en: Challenges and Innovations in AI
  id: totrans-split-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AI 的挑战与创新
- en: '**A Tale of Tails**: Explores the effects of synthetic data on neural model
    performance, theorizing potential risks of model collapse with synthetic data
    reliance. [Read the paper](https://arxiv.org/pdf/2402.07043.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**一个尾巴的故事**: 探讨了合成数据对神经模型性能的影响，理论上推测了模型依赖合成数据可能导致模型崩溃的潜在风险。[阅读论文](https://arxiv.org/pdf/2402.07043.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Transformers Can Achieve Length Generalization But Not Robustly**: Investigates
    Transformers'' ability to generalize to longer sequences, highlighting the challenge
    of maintaining robust performance. [Read the paper](https://arxiv.org/pdf/2402.09371.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**变压器可以实现长度泛化但不够健壮**: 研究变压器对更长序列的泛化能力，突显了保持健壮性能的挑战。[阅读论文](https://arxiv.org/pdf/2402.09371.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '*Become our Premium subscriber today! In most cases,* ***you can expense this
    subscription through your company!***🤍'
  id: totrans-split-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*今天成为我们的高级订阅者！在大多数情况下，* ***您可以通过公司报销此订阅！***🤍'
