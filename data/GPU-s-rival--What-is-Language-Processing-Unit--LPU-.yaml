- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: æœªåˆ†ç±»'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: æœªåˆ†ç±»'
- en: 'date: 2024-05-27 15:01:09'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 15:01:09'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: GPU's rival? What is Language Processing Unit (LPU)
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPUçš„ç«äº‰å¯¹æ‰‹ï¼Ÿä»€ä¹ˆæ˜¯è¯­è¨€å¤„ç†å•å…ƒï¼ˆLPUï¼‰
- en: æ¥æºï¼š[https://www.turingpost.com/p/fod41](https://www.turingpost.com/p/fod41)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¥æºï¼š[https://www.turingpost.com/p/fod41](https://www.turingpost.com/p/fod41)
- en: 'Next Week in Turing Post:'
  id: totrans-split-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸‹å‘¨åœ¨å›¾çµé‚®æŠ¥ï¼š
- en: 'Wednesday, Token 1.21: **Model Safety and Data Privacy**'
  id: totrans-split-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ˜ŸæœŸä¸‰ï¼ŒToken 1.21ï¼š**æ¨¡å‹å®‰å…¨ä¸æ•°æ®éšç§**
- en: 'Friday, AI Unicorns: **Scale AI**'
  id: totrans-split-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ˜ŸæœŸäº”ï¼ŒAIç‹¬è§’å…½ï¼š**Scale AI**
- en: '*Turing Post is a reader-supported publication. To have full access to our
    most interesting articles and investigations, become a paid subscriber â†’*'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*å›¾çµé‚®æŠ¥æ˜¯ä¸€ä»½ç”±è¯»è€…æ”¯æŒçš„å‡ºç‰ˆç‰©ã€‚è¦å®Œå…¨è®¿é—®æˆ‘ä»¬æœ€æœ‰è¶£çš„æ–‡ç« å’Œè°ƒæŸ¥ï¼Œè¯·æˆä¸ºä»˜è´¹è®¢æˆ·â†’*'
- en: This week, a largely unknown company, [Groq](https://groq.com/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu),
    demonstrated unprecedented speed running open-source LLMs such as Llama-2 (70
    billion parameters) at more than 100 tokens per second, and Mixtral at nearly
    500 tokens per second per user on a Groqâ€™s Language Processing Unit (LPU).
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: æœ¬å‘¨ï¼Œä¸€å®¶é²œä¸ºäººçŸ¥çš„å…¬å¸ï¼Œ[Groq](https://groq.com/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)ï¼Œå±•ç¤ºäº†å‰æ‰€æœªæœ‰çš„é€Ÿåº¦ï¼Œåœ¨Groqçš„è¯­è¨€å¤„ç†å•å…ƒï¼ˆLPUï¼‰ä¸Šè¿è¡Œå¼€æºLLMsï¼ˆå¦‚Llama-2ï¼ˆ700äº¿å‚æ•°ï¼‰æ¯ç§’è¶…è¿‡100ä¸ªæ ‡è®°ï¼ŒMixtralæ¯ç”¨æˆ·æ¯ç§’æ¥è¿‘500ä¸ªæ ‡è®°ã€‚
- en: â€œAccording to Groq, in similar tests, ChatGPT loads at 40-50 tokens per second,
    and Bard at 70 tokens per second on typical GPU-based computing systems.
  id: totrans-split-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: â€œæ ¹æ®Groqçš„è¯´æ³•ï¼Œåœ¨ç±»ä¼¼æµ‹è¯•ä¸­ï¼ŒChatGPTåœ¨å…¸å‹çš„åŸºäºGPUçš„è®¡ç®—ç³»ç»Ÿä¸Šæ¯ç§’åŠ è½½40-50ä¸ªæ ‡è®°ï¼Œè€ŒBardæ¯ç§’70ä¸ªæ ‡è®°ã€‚
- en: Context for 100 tokens per second per user â€“ A user could generate a 4,000-word
    essay in just over a minute.â€
  id: totrans-split-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¯ç”¨æˆ·æ¯ç§’100ä¸ªæ ‡è®°çš„èƒŒæ™¯â€”â€”ç”¨æˆ·å¯ä»¥åœ¨ä¸€åˆ†é’Ÿå¤šä¸€ç‚¹çš„æ—¶é—´å†…ç”Ÿæˆä¸€ç¯‡4000å­—çš„æ–‡ç« ã€‚â€
- en: 'So: **What is LPU, how does it work**, and where is Groq (such an unfortunate
    name, given Musk''s Grok is all over the media) coming from?'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: æ‰€ä»¥ï¼š**LPUæ˜¯ä»€ä¹ˆï¼Œå®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„**ï¼ŒGroqï¼ˆè¿™ä¸ªåå­—çœŸä¸å¹¸ï¼Œé‰´äºé©¬æ–¯å…‹çš„Grokåœ¨åª’ä½“ä¸Šéšå¤„å¯è§ï¼‰åˆæ¥è‡ªå“ªé‡Œï¼Ÿ
- en: Remember that game of Go in 2016 when AlphaGo played against the world champion
    Lee Sedol and won? Well, about a month before the competition, there was a test
    game which AlphaGo lost. The researchers from DeepMind ported AlphaGo to Tensor
    Processing Unit (TPU) and then the computer program was able to win by a wide
    margin.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: è®°å¾—2016å¹´çš„å›´æ£‹æ¯”èµ›å—ï¼ŸAlphaGoå¯¹é˜µä¸–ç•Œå† å†›æä¸–çŸ³å¹¶å–å¾—èƒœåˆ©ï¼Ÿå—¯ï¼Œåœ¨æ¯”èµ›å‰å¤§çº¦ä¸€ä¸ªæœˆï¼Œæœ‰ä¸€åœºæµ‹è¯•æ¯”èµ›AlphaGoè¾“äº†ã€‚DeepMindçš„ç ”ç©¶äººå‘˜å°†AlphaGoç§»æ¤åˆ°Tensorå¤„ç†å•å…ƒï¼ˆTPUï¼‰ï¼Œç„¶åè®¡ç®—æœºç¨‹åºä»¥å¤§å¹…åº¦çš„ä¼˜åŠ¿è·èƒœã€‚
- en: The realization that computational power was a bottleneck for AI's potential
    led to the inception of Groq and the creation of the LPU. This realization came
    to [Jonathan Ross](https://www.linkedin.com/in/ross-jonathan/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    who initially began what became TPU project in Google. He started Groq in 2016\.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: è®¤è¯†åˆ°è®¡ç®—èƒ½åŠ›æ˜¯AIæ½œåŠ›çš„ç“¶é¢ˆï¼Œè¿™ä¿ƒä½¿äº†Groqçš„è¯ç”Ÿä»¥åŠLPUçš„åˆ›å»ºã€‚è¿™ä¸€è®¤è¯†æœ€åˆæ¥è‡ª[Jonathan Ross](https://www.linkedin.com/in/ross-jonathan/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)ï¼Œä»–æœ€åˆå¼€å§‹äº†Googleçš„TPUé¡¹ç›®ã€‚ä»–äº2016å¹´åˆ›ç«‹äº†Groqã€‚
- en: '**The LPU is a special kind of computer brain designed to handle language tasks
    very quickly.** Unlike other computer chips that do many things at once (parallel
    processing), the LPU works on tasks one after the other (sequential processing),
    which is perfect for understanding and generating language. Imagine it like a
    relay race where each runner (chip) passes the baton (data) to the next, making
    everything run super fast. The LPU is designed to overcome the two LLM bottlenecks:
    compute density and memory bandwidth.'
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**LPUæ˜¯ä¸€ç§ç‰¹æ®Šçš„è®¡ç®—æœºå¤§è„‘ï¼Œè®¾è®¡ç”¨äºéå¸¸å¿«é€Ÿåœ°å¤„ç†è¯­è¨€ä»»åŠ¡ã€‚**ä¸åŒæ—¶æ‰§è¡Œå¤šé¡¹ä»»åŠ¡çš„å…¶ä»–è®¡ç®—æœºèŠ¯ç‰‡ï¼ˆå¹¶è¡Œå¤„ç†ï¼‰ä¸åŒï¼ŒLPUä¾æ¬¡å¤„ç†ä»»åŠ¡ï¼ˆé¡ºåºå¤„ç†ï¼‰ï¼Œè¿™éå¸¸é€‚åˆç†è§£å’Œç”Ÿæˆè¯­è¨€ã€‚å¯ä»¥å°†å…¶æƒ³è±¡æˆæ¥åŠ›æ¯”èµ›ï¼Œæ¯ä½è·‘æ­¥è€…ï¼ˆèŠ¯ç‰‡ï¼‰å°†æ¥åŠ›æ£’ï¼ˆæ•°æ®ï¼‰ä¼ é€’ç»™ä¸‹ä¸€ä½ï¼Œä½¿ä¸€åˆ‡è¿è¡Œå¾—éå¸¸å¿«é€Ÿã€‚LPUçš„è®¾è®¡æ—¨åœ¨å…‹æœä¸¤ä¸ªLLMçš„ç“¶é¢ˆï¼šè®¡ç®—å¯†åº¦å’Œå†…å­˜å¸¦å®½ã€‚'
- en: Groq took a novel approach right from the start, **focusing on software and
    compiler development** before even thinking about the hardware. They made sure
    the software could guide how the chips talk to each other, ensuring they work
    together seamlessly like a team in a factory. This makes the LPU really good at
    processing language efficiently and at high speed, ideal for AI tasks that involve
    understanding or creating text.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: Groqä»ä¸€å¼€å§‹å°±é‡‡ç”¨äº†æ–°é¢–çš„æ–¹æ³•ï¼Œ**ä¸“æ³¨äºè½¯ä»¶å’Œç¼–è¯‘å™¨å¼€å‘**ï¼Œç”šè‡³åœ¨è€ƒè™‘ç¡¬ä»¶ä¹‹å‰ã€‚ä»–ä»¬ç¡®ä¿è½¯ä»¶èƒ½å¤ŸæŒ‡å¯¼èŠ¯ç‰‡å¦‚ä½•ç›¸äº’é€šä¿¡ï¼Œç¡®ä¿å®ƒä»¬åƒå·¥å‚ä¸­çš„å›¢é˜Ÿä¸€æ ·æ— ç¼åä½œã€‚è¿™ä½¿å¾—LPUåœ¨å¤„ç†è¯­è¨€æ—¶æ•ˆç‡å’Œé€Ÿåº¦éƒ½éå¸¸é«˜ï¼Œéå¸¸é€‚åˆæ¶‰åŠç†è§£æˆ–åˆ›å»ºæ–‡æœ¬çš„AIä»»åŠ¡ã€‚
- en: This led to a highly optimized system that not only runs circles around traditional
    setups in terms of speed but does so with greater cost efficiency and lower energy
    consumption. This is big news for industries like finance, government, and tech,
    where quick and accurate data processing is key.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™å¯¼è‡´äº†ä¸€ä¸ªé«˜åº¦ä¼˜åŒ–çš„ç³»ç»Ÿï¼Œä¸ä»…åœ¨é€Ÿåº¦æ–¹é¢è¿œè¿œè¶…è¿‡ä¼ ç»Ÿè®¾ç½®ï¼Œè€Œä¸”åœ¨æˆæœ¬æ•ˆç‡å’Œèƒ½æºæ¶ˆè€—æ–¹é¢è¡¨ç°å‡ºè‰²ã€‚å¯¹äºé‡‘èã€æ”¿åºœå’Œç§‘æŠ€ç­‰è¡Œä¸šæ¥è¯´ï¼Œå¿«é€Ÿå’Œå‡†ç¡®çš„æ•°æ®å¤„ç†è‡³å…³é‡è¦ã€‚
- en: Now, don't go tossing out your GPUs just yet! While the LPU is a beast when
    it comes to inference, making light work of applying trained models to new data,
    GPUs still reign supreme in the training arena. The LPU and GPU might become the
    dynamic duo of AI hardware, each excelling in their respective roles.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: ç°åœ¨ï¼Œè¯·ä¸è¦ç€æ€¥ä¸¢å¼ƒä½ ä»¬çš„GPUï¼è™½ç„¶LPUåœ¨æ¨ç†æ–¹é¢è¡¨ç°å‡ºè‰²ï¼Œè½»æ¾åº”ç”¨è®­ç»ƒæ¨¡å‹åˆ°æ–°æ•°æ®ä¸Šï¼Œä½†GPUåœ¨è®­ç»ƒé¢†åŸŸä»ç„¶å æ®ä¸»å¯¼åœ°ä½ã€‚LPUå’ŒGPUå¯èƒ½æˆä¸ºAIç¡¬ä»¶çš„åŠ¨æ€äºŒäººç»„ï¼Œå„è‡ªåœ¨å…¶è§’è‰²ä¸­è¡¨ç°å‡ºè‰²ã€‚
- en: 'As Elvis Saravia [put](https://www.linkedin.com/feed/update/urn:li:activity:7165371713378074624/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    it: â€œ*With breakthroughs in inference and long context understanding, we are officially
    entering a new era in LLMs.*â€'
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: æ­£å¦‚Elvis Saraviaæ‰€è¯´ï¼šâ€œ*éšç€æ¨ç†å’Œé•¿æ–‡æœ¬ç†è§£çš„çªç ´ï¼Œæˆ‘ä»¬æ­£å¼è¿›å…¥äº†LLMçš„æ–°æ—¶ä»£*ã€‚â€
- en: 'To better understand architecture, Groq offers two papers: from [2020](https://wow.groq.com/groq-isca-paper-2020/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    (*Think Fast: A Tensor Streaming Processor (TSP) for Accelerating Deep Learning
    Workloads*) and [2022](https://wow.groq.com/isca-2022-paper/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    (*A Soware-defined Tensor Streaming Multiprocessor for Large-scale Machine Learning*).Â The
    term â€œLPUâ€ must be a recent addition to Groqâ€™s narrative, since itâ€™s never mentioned
    in the papers.'
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†æ›´å¥½åœ°ç†è§£æ¶æ„ï¼ŒGroqæä¾›äº†ä¸¤ç¯‡è®ºæ–‡ï¼š[2020å¹´](https://wow.groq.com/groq-isca-paper-2020/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)ï¼ˆ*å¿«é€Ÿæ€è€ƒï¼šç”¨äºåŠ é€Ÿæ·±åº¦å­¦ä¹ å·¥ä½œè´Ÿè½½çš„å¼ é‡æµå¤„ç†å™¨ï¼ˆTSPï¼‰*ï¼‰å’Œ[2022å¹´](https://wow.groq.com/isca-2022-paper/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)ï¼ˆ*ç”¨äºå¤§è§„æ¨¡æœºå™¨å­¦ä¹ çš„è½¯ä»¶å®šä¹‰å¼ é‡æµå¤šå¤„ç†å™¨*ï¼‰ã€‚ç”±äºè¿™äº›è®ºæ–‡ä¸­ä»æœªæåˆ°è¿‡â€œLPUâ€ï¼Œè¿™ä¸ªæœ¯è¯­å¯èƒ½æ˜¯Groqæœ€è¿‘æ‰æ·»åŠ çš„ã€‚
- en: 'Compute is also a part of this paper: [Computing Power and the Governance of
    Artificial Intelligence](https://arxiv.org/pdf/2402.08797.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    that discusses managing AI development through compute control, focusing on its
    potential for regulation, benefits, and risks, and suggests balanced governance
    approaches.'
  id: totrans-split-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è¿™ç¯‡è®ºæ–‡è¿˜æ¶‰åŠè®¡ç®—ï¼š[è®¡ç®—èƒ½åŠ›ä¸äººå·¥æ™ºèƒ½æ²»ç†](https://arxiv.org/pdf/2402.08797.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)ï¼Œè®¨è®ºé€šè¿‡è®¡ç®—æ§åˆ¶ç®¡ç†AIå‘å±•ï¼Œä¸“æ³¨äºå…¶ç›‘ç®¡ã€åˆ©ç›Šå’Œé£é™©æ½œåŠ›ï¼Œå¹¶å»ºè®®å¹³è¡¡çš„æ²»ç†æ–¹æ³•ã€‚
- en: Meanwhile, The U.S. [awards](https://www.reuters.com/technology/us-awards-15-bln-globalfoundries-domestic-semiconductor-production-2024-02-19?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    GlobalFoundries, the world's third-largest contract chipmaker, $1.5 billion to
    boost semiconductor production, enhancing domestic supply chains, with expansions
    in New York and Vermont.
  id: totrans-split-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸æ­¤åŒæ—¶ï¼Œç¾å›½å‘å…¨çƒç¬¬ä¸‰å¤§åˆåŒèŠ¯ç‰‡åˆ¶é€ å•†GlobalFoundries [æˆäºˆ](https://www.reuters.com/technology/us-awards-15-bln-globalfoundries-domestic-semiconductor-production-2024-02-19?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    15äº¿ç¾å…ƒï¼Œä»¥å¢åŠ åŠå¯¼ä½“ç”Ÿäº§ï¼Œå¢å¼ºå›½å†…ä¾›åº”é“¾ï¼Œåœ¨çº½çº¦å’Œä½›è’™ç‰¹å·è¿›è¡Œæ‰©å±•ã€‚
- en: The paper [published](https://bair.berkeley.edu/blog/2024/02/18/compound-ai-systems/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    by Berkeley Artificial Intelligence Research (BAIR) argues that â€œ**compound AI
    systems will likely be the best way to maximize AI results in the future**, and
    might be one of the most impactful trends in AI in 2024.â€
  id: totrans-split-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç”±åŠ å·å¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡äººå·¥æ™ºèƒ½ç ”ç©¶ï¼ˆBAIRï¼‰å‘å¸ƒçš„è®ºæ–‡è®¤ä¸ºï¼Œâ€œ**å¤åˆäººå·¥æ™ºèƒ½ç³»ç»Ÿå¯èƒ½æ˜¯æœªæ¥æœ€å¤§åŒ–AIæˆæœçš„æœ€ä½³é€”å¾„**ï¼Œå¯èƒ½æ˜¯2024å¹´AIé¢†åŸŸæœ€æœ‰å½±å“åŠ›çš„è¶‹åŠ¿ä¹‹ä¸€ã€‚â€
- en: News from The Usual Suspects Â©
  id: totrans-split-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: æ¥è‡ªThe Usual Suspects Â©çš„æ¶ˆæ¯
- en: Y Combinator
  id: totrans-split-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Y Combinator
- en: 'Since 2009, Y Combinator has published **[Request for Startups](https://www.ycombinator.com/rfs?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)**
    which hints at what â€œideas weâ€™d want to see made real, in spaces that we believe
    will be important in the coming decadesâ€. This year, the list contains 20 categories:'
  id: totrans-split-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: è‡ª2009å¹´ä»¥æ¥ï¼ŒY Combinatorå‘å¸ƒäº†**[åˆ›ä¸šåˆ›æ„å¾é›†](https://www.ycombinator.com/rfs?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)**ï¼Œæš—ç¤ºäº†â€œæˆ‘ä»¬å¸Œæœ›åœ¨æœªæ¥å‡ åå¹´å†…æˆä¸ºç°å®çš„æƒ³æ³•ï¼Œæ¶‰åŠåˆ°æˆ‘ä»¬è®¤ä¸ºæœªæ¥é‡è¦çš„é¢†åŸŸâ€ã€‚ä»Šå¹´çš„åˆ—è¡¨åŒ…å«20ä¸ªç±»åˆ«ï¼š
- en: 20 big names
  id: totrans-split-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 20ä¸ªå¤§åé¼é¼çš„å…¬å¸
- en: Twenty tech giants, including Adobe, Amazon, Google, IBM, Meta, Microsoft, OpenAI,
    and TikTok, have [agreed](https://apnews.com/article/ai-generated-election-deepfakes-munich-accord-meta-google-microsoft-tiktok-x-c40924ffc68c94fac74fa994c520fc06?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)
    to take "reasonable precautions" to prevent the misuse of AI in disrupting elections
    worldwide.
  id: totrans-split-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: äºŒåå¤§ç§‘æŠ€å·¨å¤´ï¼ŒåŒ…æ‹¬Adobeã€Amazonã€Googleã€IBMã€Metaã€Microsoftã€OpenAIå’ŒTikTokï¼Œå·²ç»åŒæ„é‡‡å–â€œåˆç†é¢„é˜²æªæ–½â€ï¼Œä»¥é˜²æ­¢äººå·¥æ™ºèƒ½åœ¨å…¨çƒé€‰ä¸¾ä¸­è¢«æ»¥ç”¨ï¼Œ[å‚è€ƒé“¾æ¥](https://apnews.com/article/ai-generated-election-deepfakes-munich-accord-meta-google-microsoft-tiktok-x-c40924ffc68c94fac74fa994c520fc06?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)ã€‚
- en: OpenAI
  id: totrans-split-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenAI
- en: 'Models making headlines:'
  id: totrans-split-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: äº®ç‚¹æ¨¡å‹ï¼š
- en: '**Introducing Sora**: This paper introduces Sora, a breakthrough in video generation
    technology by OpenAI, capable of producing high-fidelity videos. It leverages
    spacetime patches to handle videos of varying durations and resolutions, making
    strides toward simulating the physical world with impressive 3D consistency and
    long-range coherence. It represents a leap in the ability to create detailed simulations
    that could be used for a myriad of applications, from entertainment to virtual
    testing environments [â†’read the paper](https://openai.com/research/video-generation-models-as-world-simulators?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä»‹ç»Sora**ï¼šæœ¬æ–‡ä»‹ç»äº†Soraï¼Œè¿™æ˜¯OpenAIåœ¨è§†é¢‘ç”ŸæˆæŠ€æœ¯ä¸Šçš„çªç ´ï¼Œèƒ½å¤Ÿç”Ÿæˆé«˜ä¿çœŸåº¦è§†é¢‘ã€‚å®ƒåˆ©ç”¨æ—¶ç©ºè¡¥ä¸å¤„ç†ä¸åŒé•¿åº¦å’Œåˆ†è¾¨ç‡çš„è§†é¢‘ï¼Œå‘æ¨¡æ‹Ÿç‰©ç†ä¸–ç•Œçš„3Dä¸€è‡´æ€§å’Œé•¿ç¨‹è¿è´¯æ€§è¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚è¿™ä»£è¡¨äº†åœ¨åˆ›å»ºè¯¦ç»†æ¨¡æ‹Ÿæ–¹é¢çš„é£è·ƒï¼Œå¯ç”¨äºä»å¨±ä¹åˆ°è™šæ‹Ÿæµ‹è¯•ç¯å¢ƒç­‰å¤šç§åº”ç”¨
    [â†’é˜…è¯»è®ºæ–‡](https://openai.com/research/video-generation-models-as-world-simulators?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Additional read:**'
  id: totrans-split-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**é¢å¤–é˜…è¯»ï¼š**'
- en: '**Introducing V-Jepa** (Yann LeCunâ€™s vision of advanced machine intelligence
    (AMI): Meta''s V-JEPA model revolutionizes unsupervised learning from videos by
    using feature prediction as its sole objective. This approach bypasses the need
    for pre-trained image encoders or text annotations, relying instead on the intrinsic
    dynamics of video data to learn versatile visual representations. It''s a significant
    contribution to the field of unsupervised visual learning, promising advancements
    in how machines understand motion and appearance without explicit guidance [â†’read
    the paper](https://scontent-lga3-1.xx.fbcdn.net/v/t39.2365-6/427986745_768441298640104_1604906292521363076_n.pdf?_nc_cat=103&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=Lpq5IeF5ftUAX_QVyw0&_nc_ht=scontent-lga3-1.xx&oh=00_AfCxzl-IotQM2_EGXbgWfRe66yPVffGfxGm5oSY74v1Slw&oe=65D898F1&utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä»‹ç»V-Jepa**ï¼ˆYann LeCunå¯¹å…ˆè¿›æœºå™¨æ™ºèƒ½ï¼ˆAMIï¼‰çš„æ„¿æ™¯ï¼‰ï¼šMetaçš„V-JEPAæ¨¡å‹é€šè¿‡ä»…ä½¿ç”¨ç‰¹å¾é¢„æµ‹ä½œä¸ºå…¶å”¯ä¸€ç›®æ ‡ï¼Œé©æ–°äº†ä»è§†é¢‘ä¸­è¿›è¡Œæ— ç›‘ç£å­¦ä¹ çš„æ–¹å¼ã€‚è¿™ç§æ–¹æ³•ç»•è¿‡äº†éœ€è¦é¢„å…ˆè®­ç»ƒçš„å›¾åƒç¼–ç å™¨æˆ–æ–‡æœ¬æ³¨é‡Šï¼Œè€Œæ˜¯ä¾é è§†é¢‘æ•°æ®çš„å†…åœ¨åŠ¨æ€æ¥å­¦ä¹ å¤šåŠŸèƒ½è§†è§‰è¡¨ç¤ºã€‚è¿™æ˜¯å¯¹æ— ç›‘ç£è§†è§‰å­¦ä¹ é¢†åŸŸçš„é‡å¤§è´¡çŒ®ï¼Œæœ‰æœ›åœ¨æœºå™¨ç†è§£è¿åŠ¨å’Œå¤–è§‚æ—¶ä¸éœ€è¦æ˜¾å¼æŒ‡å¯¼æ–¹é¢å–å¾—è¿›å±•
    [â†’é˜…è¯»è®ºæ–‡](https://scontent-lga3-1.xx.fbcdn.net/v/t39.2365-6/427986745_768441298640104_1604906292521363076_n.pdf?_nc_cat=103&ccb=1-7&_nc_sid=3c67a6&_nc_ohc=Lpq5IeF5ftUAX_QVyw0&_nc_ht=scontent-lga3-1.xx&oh=00_AfCxzl-IotQM2_EGXbgWfRe66yPVffGfxGm5oSY74v1Slw&oe=65D898F1&utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Introducing Gemini 1.5**: Google DeepMind''s Gemini 1.5 introduces a Mixture-of-Experts
    architecture, enhancing the model''s performance across a broader array of tasks.
    Notably, it expands the context window to 1 million tokens, enabling deep analysis
    over large datasets. Gemini 1.5 represents a significant step forward in AI''s
    capability to process and understand extensive contexts, marking a milestone in
    the development of multimodal models [â†’read the paper](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu#build-experiment)'
  id: totrans-split-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä»‹ç» Gemini 1.5**ï¼šGoogle DeepMind çš„ Gemini 1.5 å¼•å…¥äº†ä¸“å®¶æ··åˆæ¶æ„ï¼Œå¢å¼ºäº†æ¨¡å‹åœ¨æ›´å¹¿æ³›ä»»åŠ¡ä¸Šçš„æ€§èƒ½ã€‚ç‰¹åˆ«æ˜¯ï¼Œå®ƒå°†ä¸Šä¸‹æ–‡çª—å£æ‰©å±•åˆ°
    100 ä¸‡ä¸ªæ ‡è®°ï¼Œèƒ½å¤Ÿæ·±å…¥åˆ†æå¤§å‹æ•°æ®é›†ã€‚Gemini 1.5 ä»£è¡¨äº†äººå·¥æ™ºèƒ½åœ¨å¤„ç†å’Œç†è§£å¹¿æ³›è¯­å¢ƒæ–¹é¢çš„é‡å¤§è¿›å±•ï¼Œæ ‡å¿—ç€å¤šæ¨¡æ€æ¨¡å‹å‘å±•çš„ä¸€ä¸ªé‡Œç¨‹ç¢‘ [â†’é˜…è¯»è®ºæ–‡](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu#build-experiment)'
- en: '**Introducing Stable Cascade**: Stable Cascade from Stability AI introduces
    a novel text-to-image generation framework that prioritizes efficiency, ease of
    training, and fine-tuning on consumer-grade hardware. The model''s hierarchical
    compression technique represents a significant reduction in the resources required
    for training high-quality generative models, providing a pathway for wider accessibility
    and experimentation in the AI community [â†’read the paper](https://stability.ai/news/introducing-stable-cascade?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä»‹ç» Stable Cascade**ï¼šStability AI çš„ Stable Cascade å¼•å…¥äº†ä¸€ç§æ–°çš„æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆæ¡†æ¶ï¼Œä¼˜å…ˆè€ƒè™‘æ•ˆç‡ã€æ˜“äºè®­ç»ƒä»¥åŠåœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šçš„å¾®è°ƒã€‚æ¨¡å‹çš„åˆ†å±‚å‹ç¼©æŠ€æœ¯æ˜¾è‘—å‡å°‘äº†è®­ç»ƒé«˜è´¨é‡ç”Ÿæˆæ¨¡å‹æ‰€éœ€çš„èµ„æºï¼Œä¸ºäººå·¥æ™ºèƒ½ç¤¾åŒºæä¾›äº†æ›´å¹¿æ³›çš„å¯è®¿é—®æ€§å’Œå®éªŒè·¯å¾„
    [â†’é˜…è¯»è®ºæ–‡](https://stability.ai/news/introducing-stable-cascade?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: The freshest research papers, categorized for your convenience
  id: totrans-split-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸ºæ‚¨æ–¹ä¾¿åˆ†ç±»çš„æœ€æ–°ç ”ç©¶è®ºæ–‡
- en: Language Understanding and Generation
  id: totrans-split-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è¯­è¨€ç†è§£ä¸ç”Ÿæˆ
- en: '**OpenToM**: Explores evaluating Theory-of-Mind reasoning in LLMs, addressing
    their capability to understand complex social and psychological narratives. [Read
    the paper](https://arxiv.org/pdf/2402.06044.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**OpenToM**ï¼šæ¢ç´¢è¯„ä¼°è¯­è¨€æ¨¡å‹çš„å¿ƒç†ç†è®ºæ¨ç†èƒ½åŠ›ï¼Œè§£å†³å®ƒä»¬ç†è§£å¤æ‚ç¤¾ä¼šå’Œå¿ƒç†å™äº‹çš„èƒ½åŠ›ã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.06044.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**In Search of Needles in a 10M Haystack**: Demonstrates the capability of
    NLP models to process exceptionally long documents, pushing the boundaries of
    document length comprehension. [Read the paper](https://arxiv.org/pdf/2402.10790.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**åœ¨ä¸€å † 10M ä¸­å¯»æ‰¾é’ˆ**ï¼šå±•ç¤ºäº†è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹å¤„ç†å¼‚å¸¸é•¿æ–‡æ¡£çš„èƒ½åŠ›ï¼Œæ¨åŠ¨äº†æ–‡æ¡£é•¿åº¦ç†è§£çš„è¾¹ç•Œã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.10790.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Premise Order Matters in Reasoning with LLMs**: Investigates the sensitivity
    of LLMs to the order of premises, revealing implications for reasoning tasks.
    [Read the paper](https://arxiv.org/pdf/2402.08939.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å‰æé¡ºåºåœ¨é€»è¾‘æ¨ç†ä¸­çš„é‡è¦æ€§**ï¼šç ”ç©¶äº†è¯­è¨€æ¨¡å‹å¯¹å‰æé¡ºåºçš„æ•æ„Ÿæ€§ï¼Œæ­ç¤ºäº†å¯¹æ¨ç†ä»»åŠ¡çš„å½±å“ã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.08939.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Chain-of-Thought Reasoning Without Prompting**: Uncovers the inherent ability
    of LLMs to generate reasoning paths, suggesting an alternative to explicit prompting.
    [Read the paper](https://arxiv.org/pdf/2402.10200.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**æ— éœ€æç¤ºçš„é“¾å¼æ€ç»´æ¨ç†**ï¼šæ­ç¤ºäº†è¯­è¨€æ¨¡å‹ç”Ÿæˆæ¨ç†è·¯å¾„çš„å›ºæœ‰èƒ½åŠ›ï¼Œæå‡ºäº†ä¸€ç§æ›¿ä»£æ˜¾å¼æç¤ºçš„æ–¹æ³•ã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.10200.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Suppressing Pink Elephants with Direct Principle Feedback**: Addresses the
    challenge of topic avoidance in LLMs, proposing a novel fine-tuning method for
    enhanced controllability. [Read the paper](https://arxiv.org/pdf/2402.07896.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ç”¨ç›´æ¥åŸåˆ™åé¦ˆæŠ‘åˆ¶ç²‰è‰²å¤§è±¡**ï¼šè§£å†³äº†LLMä¸­ä¸»é¢˜å›é¿çš„æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§æ–°çš„å¾®è°ƒæ–¹æ³•ï¼Œä»¥å¢å¼ºå¯æ§æ€§ã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.07896.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**GhostWriter**: Develops an AI-powered writing environment focusing on personalization
    and increased user control in collaborative writing. [Read the paper](https://arxiv.org/pdf/2402.08855.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GhostWriter**ï¼šå¼€å‘äº†ä¸€ä¸ªä»¥AIä¸ºåŠ¨åŠ›çš„å†™ä½œç¯å¢ƒï¼Œä¾§é‡äºä¸ªæ€§åŒ–å’Œå¢å¼ºç”¨æˆ·åœ¨åä½œå†™ä½œä¸­çš„æ§åˆ¶æƒã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.08855.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: Speech and Text-to-Speech Technologies
  id: totrans-split-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è¯­éŸ³å’Œæ–‡æœ¬åˆ°è¯­éŸ³æŠ€æœ¯
- en: Mathematical and Scientific Reasoning
  id: totrans-split-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ•°å­¦å’Œç§‘å­¦æ¨ç†
- en: '**OpenMathInstruct-1**: Develops a dataset for math instruction tuning, aiming
    to improve LLMs'' mathematical reasoning capabilities. [Read the paper](https://arxiv.org/pdf/2402.10176.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**OpenMathInstruct-1**ï¼šå¼€å‘äº†ä¸€ä¸ªç”¨äºæ•°å­¦æŒ‡å¯¼è°ƒæ•´çš„æ•°æ®é›†ï¼Œæ—¨åœ¨æé«˜LLMåœ¨æ•°å­¦æ¨ç†èƒ½åŠ›æ–¹é¢çš„è¡¨ç°ã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.10176.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**InternLM-Math**: Introduces a specialized LLM for math reasoning, incorporating
    various techniques for enhanced problem-solving in mathematics. [Read the paper](https://arxiv.org/pdf/2402.06332.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**InternLM-Math**ï¼šä»‹ç»äº†ä¸€ç§ä¸“é—¨ç”¨äºæ•°å­¦æ¨ç†çš„è¯­è¨€æ¨¡å‹ï¼Œç»“åˆäº†å„ç§æŠ€æœ¯ï¼Œä»¥å¢å¼ºæ•°å­¦é—®é¢˜è§£å†³èƒ½åŠ›ã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.06332.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**ChemLLM**: Creates the first LLM dedicated to chemistry, transforming structured
    chemical data into dialogue for diverse chemical tasks. [Read the paper](https://arxiv.org/pdf/2402.06852.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ChemLLM**ï¼šåˆ›å»ºäº†ç¬¬ä¸€ä¸ªä¸“ç”¨äºåŒ–å­¦çš„LLMï¼Œå°†ç»“æ„åŒ–çš„åŒ–å­¦æ•°æ®è½¬åŒ–ä¸ºå¤šæ ·åŒ–çš„åŒ–å­¦ä»»åŠ¡å¯¹è¯ã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.06852.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: Efficiency and Data Utilization in AI
  id: totrans-split-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AIä¸­çš„æ•ˆç‡å’Œæ•°æ®åˆ©ç”¨
- en: '**How to Train Data-Efficient LLMs**: Proposes sampling methods for enhancing
    data efficiency in LLM training, optimizing example selection. [Read the paper](https://arxiv.org/pdf/2402.09668.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å¦‚ä½•è®­ç»ƒæ•°æ®é«˜æ•ˆçš„LLM**ï¼šæå‡ºäº†å¢å¼ºLLMè®­ç»ƒæ•°æ®æ•ˆç‡çš„é‡‡æ ·æ–¹æ³•ï¼Œä¼˜åŒ–ç¤ºä¾‹é€‰æ‹©ã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.09668.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**FIDDLER**: Introduces a system for efficient inference of MoE models, leveraging
    CPU-GPU orchestration for improved performance in resource-limited settings. [Read
    the paper](https://arxiv.org/pdf/2402.07033.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FIDDLER**ï¼šå¼•å…¥äº†ä¸€ç§ç”¨äºæœ‰æ•ˆæ¨æ–­MoEæ¨¡å‹çš„ç³»ç»Ÿï¼Œåˆ©ç”¨CPU-GPUååŒä½œä¸šæ¥æé«˜èµ„æºå—é™ç¯å¢ƒä¸‹çš„æ€§èƒ½ã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.07033.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Tandem Transformers**: Presents an architecture for improving inference efficiency
    of LLMs, utilizing a dual-model system for faster and accurate predictions. [Read
    the paper](https://arxiv.org/pdf/2402.08644.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tandem Transformers**ï¼šæå‡ºäº†ä¸€ç§ç”¨äºæé«˜LLMæ¨ç†æ•ˆç‡çš„æ¶æ„ï¼Œåˆ©ç”¨åŒæ¨¡å‹ç³»ç»Ÿè¿›è¡Œæ›´å¿«é€Ÿå’Œå‡†ç¡®çš„é¢„æµ‹ã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.08644.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Towards Next-Level Post-Training Quantization of Hyper-Scale Transformers**:
    Proposes an advanced PTQ algorithm for efficient deployment of large Transformer
    models on edge devices. [Read the paper](https://arxiv.org/pdf/2402.08958.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**èµ°å‘è¶…å¤§è§„æ¨¡å˜å‹å™¨åè®­ç»ƒé‡åŒ–çš„ä¸‹ä¸€çº§**: æå‡ºäº†ä¸€ç§å…ˆè¿›çš„ PTQ ç®—æ³•ï¼Œç”¨äºåœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šé«˜æ•ˆéƒ¨ç½²å¤§å‹å˜å‹å™¨æ¨¡å‹ã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.08958.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: Multimodal and Vision-Language Models
  id: totrans-split-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¤šæ¨¡æ€å’Œè§†è§‰è¯­è¨€æ¨¡å‹
- en: Reinforcement Learning and Model Behavior
  id: totrans-split-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¼ºåŒ–å­¦ä¹ ä¸æ¨¡å‹è¡Œä¸º
- en: '**ODIN**: Addresses reward hacking in RLHF, proposing a method to mitigate
    verbosity bias in LLMs for more concise and content-focused responses. [Read the
    paper](https://arxiv.org/pdf/2402.07319.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ODIN**: å¤„ç† RLHF ä¸­çš„å¥–åŠ±é»‘å®¢é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–¹æ³•æ¥å‡è½» LLM ä¸­çš„å†—é•¿åè§ï¼Œä»¥è·å¾—æ›´ç®€æ´å’Œå†…å®¹èšç„¦çš„å“åº”ã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.07319.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Mixtures of Experts Unlock Parameter Scaling for Deep RL**: Shows the impact
    of MoE modules on deep RL networks, enhancing parameter scalability and performance.
    [Read the paper](https://arxiv.org/pdf/2402.08609.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸“å®¶æ··åˆè§£é”æ·±åº¦ RL å‚æ•°ç¼©æ”¾**: å±•ç¤ºäº† MoE æ¨¡å—å¯¹æ·±åº¦ RL ç½‘ç»œçš„å½±å“ï¼Œå¢å¼ºäº†å‚æ•°å¯ä¼¸ç¼©æ€§å’Œæ€§èƒ½ã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.08609.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: Operating Systems and Generalist Agents
  id: totrans-split-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ“ä½œç³»ç»Ÿå’Œé€šç”¨ä»£ç†
- en: Graph Learning and State Space Models
  id: totrans-split-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å›¾å­¦ä¹ å’ŒçŠ¶æ€ç©ºé—´æ¨¡å‹
- en: Challenges and Innovations in AI
  id: totrans-split-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AI çš„æŒ‘æˆ˜ä¸åˆ›æ–°
- en: '**A Tale of Tails**: Explores the effects of synthetic data on neural model
    performance, theorizing potential risks of model collapse with synthetic data
    reliance. [Read the paper](https://arxiv.org/pdf/2402.07043.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ä¸€ä¸ªå°¾å·´çš„æ•…äº‹**: æ¢è®¨äº†åˆæˆæ•°æ®å¯¹ç¥ç»æ¨¡å‹æ€§èƒ½çš„å½±å“ï¼Œç†è®ºä¸Šæ¨æµ‹äº†æ¨¡å‹ä¾èµ–åˆæˆæ•°æ®å¯èƒ½å¯¼è‡´æ¨¡å‹å´©æºƒçš„æ½œåœ¨é£é™©ã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.07043.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '**Transformers Can Achieve Length Generalization But Not Robustly**: Investigates
    Transformers'' ability to generalize to longer sequences, highlighting the challenge
    of maintaining robust performance. [Read the paper](https://arxiv.org/pdf/2402.09371.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
  id: totrans-split-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**å˜å‹å™¨å¯ä»¥å®ç°é•¿åº¦æ³›åŒ–ä½†ä¸å¤Ÿå¥å£®**: ç ”ç©¶å˜å‹å™¨å¯¹æ›´é•¿åºåˆ—çš„æ³›åŒ–èƒ½åŠ›ï¼Œçªæ˜¾äº†ä¿æŒå¥å£®æ€§èƒ½çš„æŒ‘æˆ˜ã€‚[é˜…è¯»è®ºæ–‡](https://arxiv.org/pdf/2402.09371.pdf?utm_source=www.turingpost.com&utm_medium=referral&utm_campaign=fod-41-gpu-s-rival-what-is-language-processing-unit-lpu)'
- en: '*Become our Premium subscriber today! In most cases,* ***you can expense this
    subscription through your company!***ğŸ¤'
  id: totrans-split-64
  prefs: []
  type: TYPE_NORMAL
  zh: '*ä»Šå¤©æˆä¸ºæˆ‘ä»¬çš„é«˜çº§è®¢é˜…è€…ï¼åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œ* ***æ‚¨å¯ä»¥é€šè¿‡å…¬å¸æŠ¥é”€æ­¤è®¢é˜…ï¼***ğŸ¤'
