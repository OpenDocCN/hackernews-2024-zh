- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 14:43:52'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 14:43:52'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: The GPT-4 barrier has finally been broken
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GPT-4 障碍终于被打破了。
- en: 来源：[https://simonwillison.net/2024/Mar/8/gpt-4-barrier/](https://simonwillison.net/2024/Mar/8/gpt-4-barrier/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://simonwillison.net/2024/Mar/8/gpt-4-barrier/](https://simonwillison.net/2024/Mar/8/gpt-4-barrier/)
- en: The GPT-4 barrier has finally been broken
  id: totrans-split-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GPT-4 障碍终于被打破了。
- en: 8th March 2024
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 2024 年 3 月 8 日
- en: 'Four weeks ago, GPT-4 remained the undisputed champion: consistently at the
    top of every key benchmark, but more importantly the clear winner in terms of
    “vibes”. Almost everyone investing serious time exploring LLMs agreed that it
    was the most capable default model for the majority of tasks—and had been for
    more than a year.'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 四周前，GPT-4 仍然是无可争议的冠军：在每个关键性能基准上保持领先，但更重要的是在“氛围”方面是明显的赢家。几乎所有认真研究大语言模型的人都同意，它是大多数任务的最佳默认模型——并且已经如此超过一年了。
- en: Today that barrier has finally been smashed. We have four new models, all released
    to the public in the last four weeks, that are benchmarking near or even above
    GPT-4\. And the all-important vibes are good, too!
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 今天这个障碍终于被打破了。我们有四个新模型，所有这些模型都在过去四周内向公众发布，其性能基准接近甚至超过了 GPT-4。而且所有重要的反馈也是积极的！
- en: Those models come from four different vendors.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型来自四个不同的供应商。
- en: '[Google Gemini 1.5](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/),
    February 15th. I wrote about this [the other week](https://simonwillison.net/2024/Feb/21/gemini-pro-video/):
    the signature feature is an incredible one million long token context, nearly
    8 times the length of GPT-4 Turbo. It can also process video, which it does by
    breaking it up into one frame per second—but you can fit a LOT of frames (258
    tokens each) in a million tokens.'
  id: totrans-split-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[谷歌 Gemini 1.5](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/)，2
    月 15 日。我在[前几周](https://simonwillison.net/2024/Feb/21/gemini-pro-video/)写过这个：其标志性功能是一个不可思议的一百万个标记的上下文，几乎是
    GPT-4 Turbo 长度的 8 倍。它还可以处理视频，方法是将视频每秒拆分成一帧，但你可以在一百万个标记中放入大量帧（每帧 258 个标记）。'
- en: '[Mistral Large](https://mistral.ai/news/mistral-large/), February 26th. I have
    a big soft spot for Mistral given how exceptional their openly licensed models
    are—Mistral 7B runs on my iPhone, and Mixtral-8x7B is the best model I’ve successfully
    run on my laptop. Medium and Large are their two hosted but closed models, and
    while Large may not be quite outperform GPT-4 it’s clearly in the same class.
    I can’t wait to see what they put out next.'
  id: totrans-split-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Mistral Large](https://mistral.ai/news/mistral-large/)，2 月 26 日。我对 Mistral
    有很大的好感，因为他们开放授权的模型异常出色——Mistral 7B 在我的 iPhone 上运行，Mixtral-8x7B 是我在笔记本上成功运行过的最佳模型。Medium
    和 Large 是他们两个托管但封闭的模型，虽然 Large 可能并不完全超越 GPT-4，但明显处于同一类别。我迫不及待想看看他们接下来会发布什么。'
- en: '[Claude 3 Opus](https://www.anthropic.com/news/claude-3-family), March 4th.
    This is just a few days old and wow: the vibes on this one are *really* strong.
    People I know who evaluate LLMs closely are rating it as the first clear GPT-4
    beater. I’ve switched to it as my default model for a bunch of things, most conclusively
    for code—I’ve had several experiences recently where a complex GPT-4 prompt that
    produced broken JavaScript gave me a perfect working answer when run through Opus
    instead ([recent example](https://fedi.simonwillison.net/@simon/112057299607427949)).
    I also enjoyed Anthropic research engineer Amanda Askell’s detailed [breakdown
    of their system prompt](https://simonwillison.net/2024/Mar/7/claude-3-system-prompt-explained/).'
  id: totrans-split-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[克劳德 3 音韵](https://www.anthropic.com/news/claude-3-family)，3 月 4 日。这才过去几天，哇，这个的氛围*真的*很强。我认识的那些密切评估大语言模型的人士认为这是首个明显超越
    GPT-4 的模型。我已经把它作为默认模型用在了很多事情上，尤其是在代码方面——最近有几次，复杂的 GPT-4 提示在经过 Opus 处理后，曾经导致 JavaScript
    错误的问题，结果却给我了一个完美的工作答案（[最近的例子](https://fedi.simonwillison.net/@simon/112057299607427949)）。我还喜欢
    Anthropi'
- en: '[Inflection-2.5](https://inflection.ai/inflection-2-5), March 7th. This one
    came out of left field for me: Inflection make [Pi](https://hello.pi.ai/), a conversation-focused
    chat interface that felt a little gimmicky to me when I first tried it. Then just
    the other day they announced that their brand new 2.5 model benchmarks favorably
    against GPT-4, and Ethan Mollick—one of my favourite [LLM sommeliers](https://interconnected.org/home/2023/03/22/tuning)—noted
    that it [deserves more attention](https://twitter.com/emollick/status/1765801629788647468).'
  id: totrans-split-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Inflection-2.5](https://inflection.ai/inflection-2-5)，3月7日。对我来说，这真是个出乎意料的消息：Inflection
    制作了[Pi](https://hello.pi.ai/)，一个以对话为重点的聊天界面，当我第一次尝试它时，感觉有点花哨。然后就在几天前，他们宣布他们全新的2.5模型在基准测试中比GPT-4表现良好，而我最喜欢的[LLM酒侍](https://interconnected.org/home/2023/03/22/tuning)之一Ethan
    Mollick指出，它[值得更多关注](https://twitter.com/emollick/status/1765801629788647468)。'
- en: Not every one of these models is a clear GPT-4 beater, but every one of them
    is a contender. And like I said, a month ago we had none at all.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有这些模型都是明确的GPT-4挑战者，但它们每一个都是有竞争力的。就像我说的，一个月前我们根本没有。
- en: There are a couple of disappointments here.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个令人失望的地方。
- en: Firstly, none of those models are openly licensed or weights available. I imagine
    the resources they need to run would make them impractical for most people, but
    after a year that has seen enormous leaps forward in the openly licensed model
    category it’s sad to see the very best models remain strictly proprietary.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，这些模型中没有一个是公开授权或提供权重的。我想象它们运行所需的资源会使它们对大多数人来说不实用，但在过去一年中，开放授权模型类别取得了巨大的进步，看到最好的模型仍然严格专有感到遗憾。
- en: 'And unless I’ve missed something, none of these models are being transparent
    about their training data. This also isn’t surprising: the lawsuits have started
    flying now over training on unlicensed copyrighted data, and negative public sentiment
    continues to grow over the murky ethical ground on which these models are built.'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 除非我漏掉了什么，否则这些模型都没有透明地公开它们的训练数据。这也不足为奇：现在开始起诉使用非许可版权数据进行训练，公众对这些模型建立在不明确伦理基础上的负面情绪继续增长。
- en: It’s still disappointing to me. While I’d love to see a model trained entirely
    on public domain or licensed content—and it feels like we should start to see
    some strong examples of that pretty soon—it’s not clear to me that it’s possible
    to build something that competes with GPT-4 without dipping deep into unlicensed
    content for the training. I’d love to be proved wrong on that!
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，这仍然令人失望。虽然我很希望看到完全基于公共领域或有许可内容训练的模型，并且感觉我们很快应该能看到一些强有力的例子，但我不清楚是否可能在没有深入非许可内容训练的情况下建立与
    GPT-4 竞争的东西。我很乐意在这方面被证明是错的！
- en: In the absence of such a [vegan model](https://simonwillison.net/2022/Aug/29/stable-diffusion/#ai-vegan)
    I’ll take training transparency over what we are seeing today. I use these models
    a lot, and knowing how a model was trained is a powerful factor in helping decide
    which questions and tasks a model is likely suited for. Without training transparency
    we are all left reading tea leaves, sharing conspiracy theories and desperately
    trying to figure out the vibes.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在缺少这样的[纯素模型](https://simonwillison.net/2022/Aug/29/stable-diffusion/#ai-vegan)的情况下，我更看重训练透明度，而不是我们今天看到的东西。我经常使用这些模型，了解一个模型的训练方式对于帮助决定一个模型可能适用的问题和任务是一个强有力的因素。缺乏训练透明度让我们都在揣测，分享阴谋论，拼命尝试弄清楚背后的真实动机。
