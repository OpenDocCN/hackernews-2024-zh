- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 14:29:30'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 14:29:30'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: ChatGPT and Google Gemini Are Both Doomed
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 聊天GPT和谷歌Gemini都注定要失败
- en: 来源：[https://nymag.com/intelligencer/article/chatgpt-and-google-gemini-are-both-doomed.html](https://nymag.com/intelligencer/article/chatgpt-and-google-gemini-are-both-doomed.html)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://nymag.com/intelligencer/article/chatgpt-and-google-gemini-are-both-doomed.html](https://nymag.com/intelligencer/article/chatgpt-and-google-gemini-are-both-doomed.html)
- en: 'Google CEO Sundar Pichai sent a company-wide email addressing the disastrous
    launch of the Gemini chatbot. Photo-Illustration: Intelligencer; Photo: Getty'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌CEO桑达尔·皮查伊发送了一封公司范围内的电子邮件，讨论Gemini聊天机器人的灾难性发布。图片插图：Intelligencer；图片来源：Getty
- en: 'Last week, users noticed that Google’s chatbot, Gemini, was pretty insistent
    about generating racially diverse images of people. Insistent enough, in fact,
    that it seemed unable to generate an image of a white pope and replied to a prompt
    about Nazis with figures of various races in SS uniforms. Soon, screenshots proving
    Gemini’s “wokeness” were going viral: “It is not possible to say who definitively
    impacted society more, Elon tweeting memes or Hitler,” one Gemini response read.
    It was a [peripheral skirmish in a preexisting culture war](https://nymag.com/intelligencer/_pages/clsxcu1r300000igi9a058ng0.html)
    promoted by people who have been making similar ideological claims about Google
    and “big tech” for a long time. But it was also genuinely funny and a part of
    the even longer tradition of making chatbots produce weird, funny, or terrible
    outputs. Asked for help with an ad campaign promoting meat, a concerned-sounding
    Gemini suggested people [should eat ethical beans](https://twitter.com/JeremiahDJohns/status/1761927705455427717)
    instead. Pretty good.'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 上周，用户注意到谷歌的聊天机器人Gemini非常坚持生成种族多样化的人物图像。事实上，它似乎无法生成白人教皇的图像，并在关于纳粹的提示中回复各种种族的人穿着SS制服。很快，证明Gemini“觉醒”性的截图开始传播：“无法确定谁对社会的影响更大，是埃隆发推文还是希特勒”，Gemini的一条回复写道。这是[一场早已存在的文化战争中的次要冲突](https://nymag.com/intelligencer/_pages/clsxcu1r300000igi9a058ng0.html)，由长期以来对谷歌和“大科技”提出类似意识形态主张的人推动。但这也确实很有趣，并且是使聊天机器人产生奇怪、有趣或可怕输出的长期传统的一部分。当被要求帮助推广肉类广告活动时，一个听起来关切的Gemini建议人们应该[吃道德豆](https://twitter.com/JeremiahDJohns/status/1761927705455427717)。挺好笑的。
- en: 'Gemini’s coded attempts to preempt bad PR ended up producing a PR disaster.
    Within days, Google announced it was pausing Gemini’s ability to create *any*
    images of humans. [Excitable commentators](https://stratechery.com/2024/gemini-and-googles-culture/)
    suggested Google CEO Sundar Pichai should resign; he sent a company-wide email
    calling the issues “unacceptable” and admitting “we got it wrong.” The chatbot
    is already adjusting. Asked now to compare not-Hitler to Hitler, Gemini will usually
    agree that Hitler was worse but will gently scold the user for asking, too:'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: Gemini编码的试图预防坏的公关结果却造成了公关灾难。几天之内，谷歌宣布暂停Gemini生成*任何*人类图像的能力。[兴奋的评论员](https://stratechery.com/2024/gemini-and-googles-culture/)建议谷歌CEO桑达尔·皮查伊应该辞职；他发送了一封公司范围内的电子邮件称这些问题“无法接受”，并承认“我们做错了”。这个聊天机器人已经在调整了。现在被要求比较非希特勒与希特勒时，Gemini通常会同意希特勒更糟糕，但会轻轻责备用户为何提问：
- en: 'In many different cases, however, it will say something like this: “I’m still
    learning how to answer this question. In the meantime, try Google Search.”'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在许多不同情况下，它会说出这样的话：“我还在学习如何回答这个问题。与此同时，请尝试使用Google搜索。”
- en: '*I’m still learning how to answer this question*. It’s a perfectly uncanny
    phrase. Speaking for themselves, naturally, human beings would be more likely
    to admit that they don’t know an answer*,* that they’re learning more about a
    subject, or that they just don’t want to talk about something*.* When people *do*
    talk like Gemini, it’s usually because they find themselves inhabiting a role
    in which they’re required to be withholding, strategic, or so careful as to become
    something other than themselves and other than human: a coached defendant during
    cross-examination, a politician [navigating](https://www.youtube.com/watch?v=WkFsgU_WLko)
    a hearing, a customer-service rep denying a claim at an insurance company, a press
    secretary trying to shut down a line of questioning. Gemini speaks in the familiar,
    unmistakable voice of institutional caution and self-interest. It’s a piece of
    software mimicking a person whose job is to speak for a corporation. It has an
    impossible job, not because it’s hard but because it’s internally ill defined,
    externally contested, and kind of stupid. It was doomed from the start, in other
    words. All chatbots are.'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: '*我还在学习如何回答这个问题*。这是一个完全怪异的短语。自然而然地，人类更有可能承认他们不知道答案，他们正在学习更多关于一个主题，或者他们只是不想谈论某件事。当人们像Gemini那样说话时，通常是因为他们发现自己扮演了一个必须保留信息、战略性地行事或如此小心谨慎以至于变得不再是自己和不再是人类的角色：在交叉审问中受指导的被告，面对听证会的政客，在保险公司否认索赔的客户服务代表，试图关闭问题线索的新闻发言人。Gemini以机构谨慎和自我利益的熟悉、不会错过的声音说话。这是一款软件，模仿一个其工作是代表一个公司发言的人。换句话说，它有一个不可能的任务，不是因为它很难，而是因为它在内部定义上有缺陷，在外部上有争议，并且有点愚蠢。换句话说，它从一开始就注定要失败。所有的聊天机器人都是。'
- en: 'There are lots of things we refer to as chatbots; strictly speaking, the term
    just describes a software interface that mimics human conversation. Here, I mean
    a chatbot in the sense implied by OpenAI, Google, Microsoft, and other companies
    riding the generative-AI wave with the releases of general-purpose, multiuse interfaces
    that don’t come with specific instructions or a clearly delineated purpose — the
    voice-of-God AIs that have captured the public’s imagination. Each adopts a variation
    of [the same character](https://medium.com/@colin.fraser/who-are-we-talking-to-when-we-talk-to-these-bots-9a7e673f8525):
    a cheerful, generous, knowledgeable persona with which you engage in “conversation.”
    In OpenAI’s telling, ChatGPT’s character is “optimized for dialogue” and based
    on a “language model trained to produce text.” Users can “get instant answers,
    find creative inspiration, learn something new.” Both ChatGPT and Google’s Gemini
    prompt new users in the exact same way: “How can I help you today?”'
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所说的聊天机器人有很多种；严格来说，这个术语只是描述了一种模仿人类对话的软件接口。在这里，我指的是OpenAI、Google、Microsoft和其他公司通过发布不带有具体说明或明确定义目的的通用多用途界面来乘上生成式AI浪潮的声称的那种聊天机器人——公众想象中的上帝之声AI。每个公司采用了一种变体的[同一个角色](https://medium.com/@colin.fraser/who-are-we-talking-to-when-we-talk-to-these-bots-9a7e673f8525)：一个开朗、慷慨、知识渊博的人物，你可以与之“对话”。在OpenAI的描述中，ChatGPT的角色是“为对话优化”，基于“训练生成文本的语言模型”。用户可以“即时获得答案、找到创意灵感、学到新知识”。ChatGPT和Google的Gemini以完全相同的方式提示新用户：“今天我可以如何帮助你？”
- en: 'It’s an unsubtle and effective invocation of a persona that was familiar to
    the public long before ChatGPT debuted: the helpful, omniscient AI assistant,
    usually portrayed on a spectrum of humanity ranging from Hal to Samantha from
    *Her*. In the case of ChatGPT, this illusion was genuinely [bracing](https://nymag.com/intelligencer/2023/01/why-artificial-intelligence-often-feels-like-magic.html)
    on first encounter. The chatbot spoke confidently as it produced plausible responses
    to a wide range of prompts. It was pretty easy to trip up, confuse, derail, or
    cause to say something [racist](https://www.bloomberg.com/news/newsletters/2022-12-08/chatgpt-open-ai-s-chatbot-is-spitting-out-biased-sexist-results)
    — or, [God forbid](https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html),
    something [anti-racist](https://amgreatness.com/2022/12/30/chatgpt-is-seriously-woke-a-i/)
    — but its sudden arrival, rapid upgrades, and occasional performances of humility
    made its flaws, weaknesses, and surreal tangents easy for OpenAI to patch and
    set aside as temporary glitches that would inevitably be resolved in the next
    big model, or the next, or the next, on the way to “[general intelligence](https://nymag.com/intelligencer/2023/11/how-big-techs-ai-hype-cycle-swallowed-sam-altman-openai.html)”
    and beyond.'
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 它是 ChatGPT 首次亮相之前公众熟悉的角色的一个明显而有效的召唤：那种习惯于在人类到智能AI助手的光谱上扮演角色的AI助手，通常从哈尔到《她》中的萨曼莎。在
    ChatGPT 的情况下，这种幻觉在第一次遇见时确实让人[耳目一新](https://nymag.com/intelligencer/2023/01/why-artificial-intelligence-often-feels-like-magic.html)。聊天机器人以自信的语调说话，并对各种提示产生似是而非的回应。很容易使其出错、混淆、偏离轨道，或者导致其说出一些[种族主义言论](https://www.bloomberg.com/news/newsletters/2022-12-08/chatgpt-open-ai-s-chatbot-is-spitting-out-biased-sexist-results)——或者，[天哪](https://www.nytimes.com/2021/03/15/technology/artificial-intelligence-google-bias.html)，说出一些[反种族主义言论](https://amgreatness.com/2022/12/30/chatgpt-is-seriously-woke-a-i/)——但其突然出现、快速升级以及偶尔表现出的谦逊，使得
    OpenAI 能够轻松修复和搁置其缺陷、弱点和荒谬的侧面，将其视为下一个大模型、或者下一个、或者下一个的临时故障，通往“[通用智能](https://nymag.com/intelligencer/2023/11/how-big-techs-ai-hype-cycle-swallowed-sam-altman-openai.html)”及其以后。
- en: But it also masked a [fundamental strangeness](https://open.substack.com/pub/maxread/p/google-made-an-ai-so-woke-it-drove?r=l4b2&utm_campaign=post&utm_medium=web)
    in the product. As the critic [Emily Bender](https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html)
    has [pointed out](https://www.bloomberg.com/news/articles/2024-02-28/google-left-in-terrible-bind-by-pulling-ai-feature-after-right-wing-backlash?accessToken=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzb3VyY2UiOiJTdWJzY3JpYmVyR2lmdGVkQXJ0aWNsZSIsImlhdCI6MTcwOTEyOTg3NiwiZXhwIjoxNzA5NzM0Njc2LCJhcnRpY2xlSWQiOiJTOUpZUzRUMVVNMFcwMCIsImJjb25uZWN0SWQiOiJFNzAxNENGQzIzNTI0MzU0QTVENUY2QkREMDAxOEU3NiJ9.TMTjmMh4a3sjqxrQupIzina90lLXZ-LtMCZ62s-CKM8),
    tools like Gemini and ChatGPT are “unscoped,” meaning not developed or deployed
    for any particular agreed-upon purpose, which makes it hard to have coherent discussions
    about how “good” or “safe” they are. Is Gemini like a search engine? A creative-writing
    simulator? A deferential assistant? A source of moral authority? An extension
    of the user? An extension of Google? Is its image generator doing art? Interpreting
    reality? Documenting it? The answer is no, strictly, but to different sets of
    users — and critics, regulators, and executives — it’s yes, all of the above.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 但它也掩盖了产品中的一个[根本奇异性](https://open.substack.com/pub/maxread/p/google-made-an-ai-so-woke-it-drove?r=l4b2&utm_campaign=post&utm_medium=web)。正如评论家[艾米莉·本德尔](https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html)指出的，像
    Gemini 和 ChatGPT 这样的工具是“无范围的”，意味着它们没有为任何特定约定的目的开发或部署，这使得很难对它们的“好”或“安全”性进行一致的讨论。Gemini
    是否像搜索引擎？创意写作模拟器？顺从的助手？道德权威？用户的延伸？谷歌的延伸？它的图像生成器是在进行艺术创作吗？解释现实？记录现实？答案严格来说是否定的，但对于不同的用户集合——以及评论家、监管者和高管——它们都是肯定的，即以上所有。
- en: 'One solution to this problem is to deploy AI to the public in the form of more
    specialized applications about which *most* people basically agree — to “scope”
    it, in other words. A good customer-service chatbot is polite, perhaps a bit stubborn,
    and refuses to talk about anything but the matter at hand. It’s clear when they’re
    doing something they’re not supposed to do:'
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题的一个方法是将AI部署到公众中，以更专业的应用形式，大多数人基本上都同意这一点 —— 换句话说，对其进行“范围限定”。一个良好的客服聊天机器人是礼貌的，或许有点固执，拒绝谈论除了手头事情以外的任何事情。当他们在做一些他们不该做的事情时，这一点显而易见：
- en: 'This is how most large-language-model–based products are actually being developed
    and used in 2024: by start-ups with a specific task and type of customer in mind;
    by companies like Google and Microsoft in the form of purpose-built products (meeting
    transcribers, translation tools, coding assistants, image generators used instead
    of background stock images); in the form of better-defined personae, as in the
    case of OpenAI’s tailor-made GPTs, through which users can basically [assign](https://openai.com/blog/introducing-gpts)
    characters themselves. Specialized AI represents real products andan aggregate
    situation in which questions about AI bias, training data, and ideology at least
    *feel* less salient to customers and users. The “characters” performed by scoped,
    purpose-built AI are performing joblike roles with employeelike personae. They
    don’t need to have an opinion on Hitler or Elon Musk because the customers aren’t
    looking for one, and the bosses won’t let it have one, and that makes perfect
    sense to everyone in the contexts in which they’re being deployed. They’re expected
    to be careful about what they say and to avoid subjects that aren’t germane to
    the task for which they’ve been “hired.”'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是2024年大多数基于大语言模型的产品的开发和使用方式：由具有特定任务和客户类型的初创公司进行；由像Google和Microsoft这样的公司以定制产品的形式（会议转录工具、翻译工具、编码助手、图像生成器，用于替代背景库存图像）；以更清晰定义的人物形象的形式，例如OpenAI的量身定制的GPT，通过它们，用户基本上可以自己“指定”角色。专业化的AI代表真实的产品和一个情况聚合，其中关于AI偏见、训练数据和意识形态的问题至少*感觉上*对客户和用户不那么重要。范围限定、定制化的AI所扮演的“角色”具有职业角色和员工样式的外貌。它们不需要对希特勒或埃隆·马斯克有意见，因为客户不会寻找这样的意见，而老板也不会允许它有这样的意见，在它们被部署的上下文中，这对所有人都是完全合理的。它们被期望谨慎地表达自己的言论，并避免与他们“被雇佣”任务不相关的主题。
- en: In contrast, general-purpose public chatbots like ChatGPT and Gemini are practically
    begging to be asked about Hitler. After all, they’re open text boxes on the internet.
    OpenAI, which has been fairly comfortable letting the public test its product,
    has gradually nudged ChatGPT to be more careful about which sorts of questions
    it answers and how it does so, mostly by observing and then sometimes addressing
    the millions of ways its users have tried to break it or have uncovered weaknesses
    or biases in the model. Google, a larger and more diversified company with much
    more to lose, has tended to front-load its limitations, as in the case of Gemini.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，像ChatGPT和Gemini这样的通用公共聊天机器人几乎是在请求被问到希特勒的事情。毕竟，它们是互联网上的开放文本框。OpenAI一直相对自在地让公众测试其产品，逐渐促使ChatGPT更加谨慎地选择回答哪些问题以及如何回答，主要是通过观察，有时是通过解决用户试图破解或揭示模型弱点或偏见的数百万种方式。
- en: 'The end result is that the personae through which users interact with these
    models have become circumspect and stern in their deflections:'
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 最终结果是，用户与这些模型互动的人物形象变得谨慎而严肃地进行偏斜：
- en: Ah, well! I guess we’re going to have to figure this one out for ourselves.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 啊，好吧！我猜我们将不得不自己解决这个问题。
- en: 'While ChatGPT has basically been advertised as unscoped, as a tool for all
    purposes, this was never quite true. In the beginning, it *was* built for a purpose
    — as an interface through which users could test and find uses for a new AI model
    and, most important, as a marketing tool for OpenAI, a task at which it was phenomenally
    successful. Now that OpenAI has raised breathtaking amounts of money and joined
    forces with one of the largest tech companies in the world, its purpose has become
    more muddled, its actual use cases more diverse, and user expectations of the
    ChatGPT character much greater, leading to widespread perceptions that it has
    been “[nerfed](https://www.google.com/search?q=chatgpt+nerfed+hackernews+site:news.ycombinator.com&sca_esv=6917f8fced87079d&gbv=2&sxsrf=ACQVn08w-oidVgPYoQDyQm-BAgTPOyLOSw:1709153136391&sa=X&ved=2ahUKEwjhqr7M886EAxVm5skDHUWkDOkQrQIoBHoECBcQBQ&biw=1891&bih=1419&dpr=2#ip=1),”
    made “[dumber](https://nymag.com/intelligencer/2023/07/is-chatgpt-getting-dumber.html),”
    or “[gone woke](https://www.theverge.com/2023/2/17/23603906/openai-chatgpt-woke-criticism-culture-war-rules).”
    The free version of ChatGPT remains a marketing tool for the paid version, and
    the paid version is a marketing tool for an enterprise business. It always refused
    to engage with a wide set of requests — ask it for medical advice! — and has gradually
    been programmed to refuse requests that produce problematic results, reveal clear
    weaknesses in the underlying model and training data, or both. Elsewhere, Microsoft’s
    new OpenAI-based chatbot character, Copilot, is occasionally becoming homicidal:'
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然ChatGPT基本上被宣传为无约束的、多用途的工具，但这并不完全属实。起初，它确实是有目的的 — 作为一个界面，用户可以通过它测试和发现新的AI模型的用途，并且作为OpenAI的营销工具，这一任务非常成功。现在OpenAI已经筹集了惊人的资金，并与全球最大的科技公司之一联手，其目的变得更加模糊，实际用途更加多样化，用户对ChatGPT角色的期望也更高，这导致普遍认为它已经被称为“[nerfed](https://www.google.com/search?q=chatgpt+nerfed+hackernews+site:news.ycombinator.com&sca_esv=6917f8fced87079d&gbv=2&sxsrf=ACQVn08w-oidVgPYoQDyQm-BAgTPOyLOSw:1709153136391&sa=X&ved=2ahUKEwjhqr7M886EAxVm5skDHUWkDOkQrQIoBHoECBcQBQ&biw=1891&bih=1419&dpr=2#ip=1),”变得“[愚蠢](https://nymag.com/intelligencer/2023/07/is-chatgpt-getting-dumber.html)，”或“[走向觉醒](https://www.theverge.com/2023/2/17/23603906/openai-chatgpt-woke-criticism-culture-war-rules)”。ChatGPT的免费版本仍然是付费版本的营销工具，而付费版本则是企业业务的营销工具。它总是拒绝与广泛的请求进行互动
    — 比如要求医疗建议！ — 并且逐渐被编程以拒绝产生问题结果、揭示基础模型和训练数据明显弱点或两者都有的请求。在其他地方，微软基于OpenAI的新聊天机器人角色，Copilot，偶尔会变得凶残：
- en: 'In the meantime, millions of people have gotten into the habit of using ChatGPT
    to answer all sorts of questions, generate work on their behalf, and explain things.
    Many expect — and have been led to expect — ChatGPT to be able to tell them *about
    the world*, a task that puts OpenAI in the position of deciding how to make, or
    let, ChatGPT generate assertions about real people, ideas, and events. At the
    same time, it has become an avatar of AI in general — whatever people think AI
    is or where it’s going, products like ChatGPT are what they think of now. It has
    fostered an expectation of objectivity in a situation in which objectivity isn’t
    a useful concept, for a product people experience subjectively, and of which they
    make subjective demands. Even as its various raw capabilities may improve, its
    persona will almost necessarily become more reluctant to weigh in more on a greater
    number of things and to perform a wide range of tasks. ChatGPT represents OpenAI,
    and OpenAI represents different things to different people. The more successful
    OpenAI is, the less sense ChatGPT — OpenAI’s best-known product, albeit one that
    might [already have served](https://decrypt.co/147595/traffic-dip-hits-openais-chatgpt-first-times-hardest)
    its most valuable purpose — makes and the worse it gets at its primary role, which
    is to convince people to spend money with OpenAI. Fairly frequently, in fact,
    it has to tell them to buzz off:'
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，数百万人已养成了使用ChatGPT回答各种问题、代表他们生成工作并解释事物的习惯。许多人期待 — 并且被引导期待 — ChatGPT能够告诉他们*关于世界*的事情，这一任务使得OpenAI处于决定如何让ChatGPT生成关于真实人物、思想和事件的言论的位置。与此同时，它已经成为了人工智能的化身
    — 无论人们认为人工智能是什么或者它的发展方向是什么，像ChatGPT这样的产品现在就是他们所想到的。它已经培养了在一个客观性并不是一个有用概念的情境中的客观期望，对于一个人们主观体验并提出主观需求的产品。尽管它的各种基本能力可能会改进，但它的个性几乎必然会变得更加不愿在更多事物上发表意见和执行广泛任务。ChatGPT代表了OpenAI，而OpenAI则代表着不同的人们眼中的不同东西。OpenAI越成功，ChatGPT
    — OpenAI最知名的产品，尽管它可能已经[发挥了其最有价值的用途](https://decrypt.co/147595/traffic-dip-hits-openais-chatgpt-first-times-hardest)
    — 的意义就会变得越来越少，而它在其主要角色上的表现则会变得越来越差，即说服人们与OpenAI花钱的角色。
- en: If ChatGPT is doomed by OpenAI’s future, Gemini is doomed by Google’s past.
    Unlike OpenAI, Google is an institution, a bona fide “big tech” company and all
    that the category entails. It has been the subject of contentious arguments about
    bias, culture, and politics for much longer than OpenAI has even been a company,
    and it has [once or twice](https://twitter.com/realDonaldTrump/status/1151095675213553664)
    been accused of treason by a sitting U.S. president. Google’s caution in rolling
    out Gemini is, in that sense, understandable, if politically miscalibrated. Google
    didn’t want to be accused of bigotry, knowing its AI models were trained — like
    the models that help power its [search-engine](https://www.wbur.org/hereandnow/2021/09/30/safiya-noble-internet-research)
    and [image-recognition](https://algorithmwatch.org/en/google-vision-racism/) AI
    — on patchy data that contain racist stereotypes. In the process, instead, it
    made a chatbot and an image generator that was perfect for illustrating the longstanding
    right-wing story about the company, which was written in the first place about
    search results, YouTube moderation, and advertising policies — that the company,
    or its zealous workforce, is forcing its ideology on the public.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果ChatGPT被OpenAI的未来所注定，Gemini则被Google的过去所注定。与OpenAI不同，Google是一个机构，一个真正的“大科技”公司以及这一类别所包含的一切。它已经成为了关于偏见、文化和政治的有争议的争论的主题比OpenAI公司的存在时间长得多，甚至还曾经[一两次](https://twitter.com/realDonaldTrump/status/1151095675213553664)被现任美国总统指控叛国。在某种意义上，Google在推出Gemini时的谨慎是可以理解的，尽管在政治上计算失误。Google不想被指责具有偏见，因为它知道其人工智能模型是根据包含种族主义刻板印象的不完整数据进行训练的，就像帮助驱动其[搜索引擎](https://www.wbur.org/hereandnow/2021/09/30/safiya-noble-internet-research)和[图像识别](https://algorithmwatch.org/en/google-vision-racism/)人工智能的模型一样。在这个过程中，相反地，它创造了一个聊天机器人和图像生成器，非常适合用来描绘关于该公司的长期右翼故事，该故事最初关于搜索结果、YouTube管理和广告政策
    — 该公司或其狂热的工作人员正在向公众强加其意识形态。
- en: 'In addition to performing as a general-purpose chatbot (and image generator,
    data analyzer, and more), Gemini was tasked from the start with a role as a spokesperson
    for Google. This helps explain why its performance is both so strange and familiar.
    Like other spokespeople for politically contested organizations with lofty ideals
    and elite reputations — say, an Ivy League university or the paper of record —
    it is exceedingly difficult for Gemini to talk or act like a real person. And
    as with other elite, powerful institutions, the gaps between how Google talks
    about itself and how people understand it are large and fertile spaces for criticism.
    Harvard is an institution of higher learning and may pride itself on free inquiry
    and teaching, but it’s also lots of other things: a hedge fund, an institution
    for replicating and assigning status, a symbol of the broader academy, responsive
    to wealthy donors. (One might suggest that someone called to speak on its behalf
    could start [thinking and acting](https://www.nytimes.com/2024/01/03/opinion/claudine-gay-harvard-president.html?partner=slack&smid=sl-share)
    like a paralyzed, rules-bound chatbot.) The New York *Times* may claim to offer
    comprehensive, objective coverage of “the news,” which, aside from being something
    no paper can truly do, is complicated by commercial needs, audience expectations
    and sensibilities, and the fact that it’s staffed and run by real, fallible people
    with clustered views of the world.'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 除了作为一个通用聊天机器人（以及图像生成器，数据分析器等）的表现，乍得从一开始就被指定为谷歌的发言人。这有助于解释为什么它的表现既奇怪又熟悉。就像为政治上颇受争议的具有崇高理想和精英声誉的组织做发言人一样，比如常春藤大学或者报纸，它极难像一个真人说话或行动。和其他精英、强大的机构一样，谷歌谈论自身与人们理解它的差距很大，也是批评的丰饶空间。哈佛是一个高等教育机构，可能自诩为自由探究和教学的骄傲，但它也是很多其他东西：一个对冲基金，一个复制和分配身份的机构，一个更广泛学院的象征，响应富裕捐赠者的俯顺。有人可能会建议作为代表其发言的人可能开始[思考和行动](https://www.nytimes.com/2024/01/03/opinion/claudine-gay-harvard-president.html?partner=slack&smid=sl-share)像一个瘫痪、符合规则的聊天机器人。《纽约时报》可能声称提供全面客观的“新闻”报道，然而，这实际上是任何报纸都无法做到的事情，复杂性在于商业需求、观众期望和感觉，以及它的员工和管理层是由真实、不完美的人群组成的，他们对世界有着聚集化的看法。
- en: 'For self-interested reasons, these institutions tell stories about themselves
    that aren’t quite true, with the predictable result that people who have any kind
    of problem with them can correctly and credibly charge them with disingenuousness.
    Google already had this problem, and Gemini makes it a few degrees worse. In his
    [mea culpa/disciplinary](https://www.semafor.com/article/02/27/2024/google-ceo-sundar-pichai-calls-ai-tools-responses-completely-unacceptable)
    letter to staff about Gemini, Pichai wrote:'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 出于私利的原因，这些机构讲述了关于自己的故事，事实并非完全正确，可预测的结果是，任何对他们有问题的人都可以准确可信地指责他们虚伪。谷歌已经有这个问题，而Gemini使问题变得严重了几度。Pichai在致员工关于Gemini的[忏悔/纪律](https://www.semafor.com/article/02/27/2024/google-ceo-sundar-pichai-calls-ai-tools-responses-completely-unacceptable)信中写道：
- en: Our mission to organize the world’s information and make it universally accessible
    and useful is sacrosanct. We’ve always sought to give users helpful, accurate,
    and unbiased information in our products. That’s why people trust them. This has
    to be our approach for all our products, including our emerging AI products.
  id: totrans-split-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们整理全球信息并使其普遍可访问和有用的使命是神圣的。我们一直致力于在产品中向用户提供有用、准确和公正的信息。这就是人们对他们信任的原因。这必须是我们所有产品（包括新兴的AI产品）的方法。
- en: Here we have an executive unable to speak honestly in familiar and expected
    ways. Google’s actual mission has long been to deliver value to shareholders by
    selling advertising, much of it through a search engine, which is obviously and
    demonstrably biased, not just by the content it crawls and searches through but
    in the intentional, [commercially motivated](https://www.theverge.com/features/23931789/seo-search-engine-optimization-experts-google-results)
    manner in which Google presents it.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个高管不能坦率地用熟悉和预期的方式说话。谷歌的实际使命长期以来一直是通过销售广告向股东创造价值，其中许多是通过搜索引擎，显然和可证明的偏见，不仅来源于它爬取和搜索的内容，而且还有谷歌以商业动机为动力的方式呈现内容。
- en: We know why Pichai says this, and we know how it’s not true. In products like
    Google Search, the company has places to dither and hide. Sussing out bias in
    a search corpus or in rankings is complicated and [difficult](https://www.vox.com/2018/4/3/17168256/google-racism-algorithms-technology)
    to talk about in lay terms. Likewise, while algorithmic bias on social media became
    a widespread subject of concern and a [campaignable](https://www.cnn.com/2023/02/08/media/republicans-hearing-twitter-bias-reliable-sources/index.html)
    political issue, episodes of simple censorship — bans and deletions — were always
    far more resonant with users because they resembled, and recognizably were, the
    [actions of people](https://www.npr.org/2021/06/04/1003284948/trump-suspended-from-facebook-for-2-years).
    Most of the time, Google can shrug its shoulders, gesture at “the web,” and claim
    to be doing its best; social networks can shrug their shoulders, gesture at their
    users, and say they’re looking into the matter.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道为什么Pichai这么说，也知道这是不真实的。在像Google搜索这样的产品中，公司有许多地方可以犹豫和隐藏。在搜索语料库或排名中寻找偏见是复杂且[难以用通俗语言谈论的](https://www.vox.com/2018/4/3/17168256/google-racism-algorithms-technology)。同样地，虽然社交媒体上的算法偏见成为了广泛关注的问题和[可竞选的](https://www.cnn.com/2023/02/08/media/republicans-hearing-twitter-bias-reliable-sources/index.html)政治问题，但简单审查行为
    — 禁令和删除 — 对用户更具共鸣，因为它们类似于和识别为[人们的行动](https://www.npr.org/2021/06/04/1003284948/trump-suspended-from-facebook-for-2-years)。大多数时候，Google可以耸耸肩膀，指向“网络”，并声称他们正在尽力；社交网络也可以耸耸肩膀，指向他们的用户，并说他们正在调查这个问题。
- en: Google has spent the past 20 years insisting its systems merely provide access
    to information, minimizing its role on the internet and in the world when strategically
    convenient. With Gemini, incredibly, Google assigned itself a *literal voice*,
    spoken by a leader-employee-assistant-naïf character pulled in so many different
    directions that it doesn’t act like a human at all and whose core competency is
    generating infinite grievances in users who were already skeptical of the company,
    if not outright hostile to it. Pichai is now trapped promising to restore “objectivity”
    to a chatbot — an impossible task based on a nonsensical premise — while Google’s
    reputational baggage has turned a tech demo gone wrong (Gemini is not a widely
    used product, unlike ChatGPT) into a massive scandal for a trillion-dollar company,
    across which he’s trying to roll out AI in [less ridiculous](https://workspace.google.com/blog/product-announcements/generative-ai)
    and more [immediately consequential](https://blog.google/products/search/generative-ai-search/)
    roles. It’s a spectacular unforced error, a slapstick rake-in-the-face moment,
    and a testament to how panicked Google [must be](https://www.nytimes.com/2022/12/21/technology/ai-chatgpt-google-search.html)
    by the rise of OpenAI and the threat of AI to its search business.
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: Google过去20年一直坚称其系统仅提供信息访问，在战略上方便时，极力减少其在互联网和世界中的角色。令人难以置信的是，Google在Gemini中分配了一个*文字的声音*，由一个被拉向多个不同方向的领导者-员工-助手-天真角色发出，其行为根本不像一个人，其核心能力是在已经对公司怀有怀疑，甚至是敌意的用户中产生无穷的抱怨。Pichai现在陷入了承诺要恢复“客观性”给一个聊天机器人的困境中
    — 这是基于一个荒谬前提的不可能任务 — 而Google的声誉负担已经将一个技术演示出了问题（与ChatGPT不同，Gemini并不是一个广泛使用的产品），转变为一家市值万亿美元公司的巨大丑闻，Pichai正在努力在[不那么荒谬](https://workspace.google.com/blog/product-announcements/generative-ai)和[更为重要的](https://blog.google/products/search/generative-ai-search/)角色中推广AI。这是一个令人瞠目结舌的自讨苦吃，一个滑稽的荒谬时刻，也证明了Google对OpenAI的崛起和AI对其搜索业务的威胁是多么恐慌。
- en: Along with ChatGPT, whose cautious trajectory is diverging from that of a parent
    company hell-bent on rapid model development and revenue growth, Gemini’s meltdown
    challenges a prevailing narrative about AI progress. The all-knowing chatbot really
    *was* just a nice story. A single chatbot can neither contain nor convincingly
    conceal the shortcomings of the models and the data on which it was trained. In
    real-world conditions, such characters don’t inevitably become more capable, assertive,
    or powerful. Instead, a chatbot for everyone and everything is destined to become
    a chatbot for nobody and nothing.
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 与ChatGPT相比，后者小心翼翼的轨迹与一个铁心快速模型开发和收入增长的母公司背道而驰，使Gemini的崩溃挑战了关于AI进展的主流叙事。这位无所不知的聊天机器人确实**只是一个美好的故事**。一个单一的聊天机器人既不能包含也不能令人信服地掩盖模型和训练数据的缺点。在现实条件下，这样的角色不会必然变得更有能力、更有主张力或更强大。相反，一个面面俱到的聊天机器人注定会变成谁也不聊、什么也不做的聊天机器人。
