- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-27 14:43:01'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024年05月27日14:43:01
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: OpenAI Quietly Deletes Ban on Using ChatGPT for “Military and Warfare”
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenAI悄悄地删除了禁止使用ChatGPT进行“军事和战争”目的的规定。
- en: 来源：[https://theintercept.com/2024/01/12/open-ai-military-ban-chatgpt/](https://theintercept.com/2024/01/12/open-ai-military-ban-chatgpt/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://theintercept.com/2024/01/12/open-ai-military-ban-chatgpt/](https://theintercept.com/2024/01/12/open-ai-military-ban-chatgpt/)
- en: OpenAI this week quietly deleted language expressly prohibiting the use of its
    technology for military purposes from its usage policy, which seeks to dictate
    how powerful and immensely popular tools like ChatGPT can be used.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本周，OpenAI悄悄地从其使用政策中删除了明确禁止将其技术用于军事目的的语言，该政策旨在规定ChatGPT等功能强大而广受欢迎的工具如何使用。
- en: Up until January 10, OpenAI’s “usage policies” [page](https://web.archive.org/web/20240109122522/https:/openai.com/policies/usage-policies)
    included a ban on “activity that has high risk of physical harm, including,” specifically,
    “weapons development” and “military and warfare.” That plainly worded prohibition
    against military applications would seemingly rule out any official, and extremely
    lucrative, use by the Department of Defense or any other state military. The [new
    policy](https://openai.com/policies/usage-policies) retains an injunction not
    to “use our service to harm yourself or others” and gives “develop or use weapons”
    as an example, but the blanket ban on “military and warfare” use has vanished.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 截至1月10日，OpenAI的“使用政策”[网页](https://web.archive.org/web/20240109122522/https:/openai.com/policies/usage-policies)包括禁止“存在高风险物理伤害的活动”，特别是“武器开发”和“军事和战争”。这一明确的禁止军事应用的规定似乎排除了国防部或其他国家军队的任何官方和极具价值的使用。而[新政策](https://openai.com/policies/usage-policies)保留了禁止“使用我们的服务伤害自己或他人”的禁令，并且给出了“开发或使用武器”作为例子，但对“军事和战争”使用的全面禁令已经消失了。
- en: The unannounced redaction is part of a major rewrite of the policy page, which
    the company said was intended to make the document “clearer” and “more readable,”
    and which includes many other substantial language and formatting changes.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 未经宣布的删除是对政策页面的重大重写的一部分，该公司称其旨在使文档“更清晰”“更易读”，并包括许多其他重大的语言和格式更改。
- en: “We aimed to create a set of universal principles that are both easy to remember
    and apply, especially as our tools are now globally used by everyday users who
    can now also build GPTs,” OpenAI spokesperson Niko Felix said in an email to The
    Intercept. “A principle like ‘Don’t harm others’ is broad yet easily grasped and
    relevant in numerous contexts. Additionally, we specifically cited weapons and
    injury to others as clear examples.”
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI发言人尼科·菲利克斯在一封给《The Intercept》的电子邮件中说：“我们的目标是创建一套通用原则，这些原则既容易记住也易于应用，特别是我们的工具现在被全球普通用户广泛使用，他们现在也可以构建GPTs。像‘不伤害他人’这样的原则既广泛又容易理解，并在许多情境中都有相关性。此外，我们特别举了武器和对他人造成伤害的例子。”
- en: Felix declined to say whether the vaguer “harm” ban encompassed all military
    use, writing, “Any use of our technology, including by the military, to ‘[develop]
    or [use] weapons, [injure] others or [destroy] property, or [engage] in unauthorized
    activities that violate the security of any service or system,’ is disallowed.”
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 菲利克斯拒绝透露更模糊的“伤害”禁令是否包罗万象，写道：“任何使用我们的技术，包括军方，用于‘[开发]或[使用]武器，[伤害]他人或[摧毁]财产，或从事违反任何服务或系统安全的未授权活动’，都是被禁止的。”
- en: In a subsequent email, Felix added that OpenAI wanted to pursue certain “national
    security use cases that align with our mission,” citing a plan to create “cybersecurity
    tools” with DARPA, and that “the goal with our policy update is to provide clarity
    and the ability to have these discussions.”
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在随后的一封电子邮件中，菲利克斯补充说，OpenAI希望追求与其使命一致的“国家安全用例”，并计划与DARPA一起创建“网络安全工具”，并且“我们的更新政策的目标是提供清晰性并有这些讨论的能力。”
- en: “OpenAI is well aware of the risk and harms that may arise due to the use of
    their technology and services in military applications,” said Heidy Khlaaf, engineering
    director at the cybersecurity firm Trail of Bits and an expert on machine learning
    and autonomous systems safety, citing a [2022 paper](https://arxiv.org/pdf/2207.14157.pdf)
    she co-authored with OpenAI researchers that specifically flagged the risk of
    military use. Khlaaf added that the new policy seems to emphasize legality over
    safety. “There is a distinct difference between the two policies, as the former
    clearly outlines that weapons development, and military and warfare is disallowed,
    while the latter emphasizes flexibility and compliance with the law,” she said.
    “Developing weapons, and carrying out activities related to military and warfare
    is lawful to various extents. The potential implications for AI safety are significant.
    Given the well-known instances of bias and hallucination present within Large
    Language Models (LLMs), and their overall lack of accuracy, their use within military
    warfare can only lead to imprecise and biased operations that are likely to exacerbate
    harm and civilian casualties.”
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: “OpenAI充分意识到其技术和服务在军事应用中可能引发的风险和危害，”网络安全公司Trail of Bits的工程总监、机器学习和自主系统安全专家Heidy
    Khlaaf说道，她与OpenAI研究人员合著的一篇[2022年的论文](https://arxiv.org/pdf/2207.14157.pdf)专门指出了军事应用的风险。Khlaaf补充说，新政策似乎强调合法性而不是安全性。“这两个政策之间存在明显的区别，因为前者明确规定了不允许武器开发、军事和战争，而后者强调灵活性和遵守法律，”她说。“武器开发和与军事和战争相关的活动在各种程度上都是合法的。对人工智能安全的潜在影响是巨大的。鉴于大型语言模型（LLM）中存在的偏见和幻觉的已知实例，以及它们整体上缺乏准确性，它们在军事战争中的使用只会导致不精确和带有偏见的操作，可能会加剧伤害和平民伤亡。”
- en: The real-world consequences of the policy are unclear. Last year, The Intercept
    reported that OpenAI was [unwilling to say](https://theintercept.com/2023/05/08/chatgpt-ai-pentagon-military/)
    whether it would enforce its own clear “military and warfare” ban in the face
    of increasing interest from the Pentagon and U.S. intelligence community.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 政策的实际后果尚不清楚。去年，《揭示》报道称，OpenAI不愿透露在五角大楼和美国情报界越来越感兴趣的情况下，是否会执行自己明确的“军事和战争”禁令。
- en: “Given the use of AI systems in the targeting of civilians in Gaza, it’s a notable
    moment to make the decision to remove the words ‘military and warfare’ from OpenAI’s
    permissible use policy,” said Sarah Myers West, managing director of the AI Now
    Institute and a former AI policy analyst at the Federal Trade Commission. “The
    language that is in the policy remains vague and raises questions about how OpenAI
    intends to approach enforcement.”
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: “考虑到人工智能系统在以军的平民定点中的使用，现在是做出决定，从OpenAI的可允许使用政策中删除‘军事和战争’这些词的值得注意的时刻，” AI Now
    Institute的执行主任、前联邦贸易委员会人工智能政策分析师Sarah Myers West说道。“政策中的语言仍然含糊，引发了关于OpenAI打算如何执行的问题。”
- en: While nothing OpenAI offers today could plausibly be used to directly kill someone,
    militarily or otherwise — ChatGPT can’t maneuver a drone or fire a missile — any
    military is in the business of killing, or at least maintaining the capacity to
    kill. There are any number of killing-adjacent tasks that a LLM like ChatGPT could
    augment, like writing code or processing [procurement](https://asc.army.mil/web/news-chatgpt-in-dod-acquisitions/)
    orders. A review of custom ChatGPT-powered bots offered by OpenAI suggests U.S.
    military personnel are [already](https://chat.openai.com/g/g-r5Jaw1MFS-following-through-gpt)
    [using](https://chat.openai.com/g/g-G0cfHcef9-army-doctrine-publication-6-22)
    the technology to expedite paperwork. The National Geospatial-Intelligence Agency,
    which directly aids U.S. combat efforts, has [openly](https://www.nga.mil/news/NGA_brings_products_closer_to_action_in_Middle_Eas.html)
    [specul](https://youtu.be/JHLUdsDzTvQ)[ated about using ChatGPT to aid its human
    analysts](https://www.nga.mil/news/NGA_brings_products_closer_to_action_in_Middle_Eas.html).
    Even if OpenAI tools were deployed by portions of a military force for purposes
    that aren’t directly violent, they would still be aiding an institution whose
    main purpose is lethality.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 OpenAI 今天提供的东西不可能直接用于杀人，无论是军事上还是其他方面 —— ChatGPT 无法操纵无人机或发射导弹 —— 但任何军事机构都在杀人的行业中，或至少维持杀人能力。像
    ChatGPT 这样的 LLM 可以增强任何与杀人相关的任务，比如编写代码或处理[采购](https://asc.army.mil/web/news-chatgpt-in-dod-acquisitions/)订单。对
    OpenAI 提供的定制 ChatGPT 驱动机器人的审查表明，美国军事人员已经[开始](https://chat.openai.com/g/g-r5Jaw1MFS-following-through-gpt)
    [使用](https://chat.openai.com/g/g-G0cfHcef9-army-doctrine-publication-6-22) 这项技术来加快文书工作流程。直接支持美国作战行动的国家地理空间情报局已经[公开](https://www.nga.mil/news/NGA_brings_products_closer_to_action_in_Middle_Eas.html)
    [推测](https://youtu.be/JHLUdsDzTvQ)[使用 ChatGPT 来辅助其人员分析员](https://www.nga.mil/news/NGA_brings_products_closer_to_action_in_Middle_Eas.html)。即使
    OpenAI 的工具被部分军事力量用于并非直接暴力的目的，它们仍将帮助一个主要目的是杀伤力的机构。
- en: Experts who reviewed the policy changes at The Intercept’s request said OpenAI
    appears to be silently weakening its stance against doing business with militaries.
    “I could imagine that the shift away from ‘military and warfare’ to ‘weapons’
    leaves open a space for OpenAI to support operational infrastructures as long
    as the application doesn’t directly involve weapons development narrowly defined,”
    said Lucy Suchman, professor emerita of anthropology of science and technology
    at Lancaster University. “Of course, I think the idea that you can contribute
    to warfighting platforms while claiming not to be involved in the development
    or use of weapons would be disingenuous, removing the weapon from the sociotechnical
    system – including command and control infrastructures – of which it’s part.”
    Suchman, a scholar of artificial intelligence since the 1970s and member of the
    International Committee for Robot Arms Control, added, “It seems plausible that
    the new policy document evades the question of military contracting and warfighting
    operations by focusing specifically on weapons.”
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在 The Intercept 的请求下审查政策变化的专家表示，OpenAI 似乎在默默削弱其反对与军事合作的立场。“我可以想象，从‘军事和战争’转向‘武器’留下了一个空间，OpenAI
    可以支持操作基础设施，只要应用程序不直接涉及狭义上的武器开发，”兰开斯特大学科学与技术人类学教授 emerita 卢西·萨查曼说。“当然，我认为声称可以为战争平台做贡献，同时声称不参与武器的开发或使用，这种想法是虚伪的，它将武器从社会技术系统中移除
    —— 包括命令和控制基础设施 —— 它是其一部分。”萨查曼是自 1970 年代以来的人工智能学者，也是国际机器人武器控制委员会的成员，她补充说：“新的政策文件似乎回避了军事承包和战争行动的问题，而是专注于武器。”
- en: Suchman and Myers West both pointed to OpenAI’s close partnership with Microsoft,
    a major defense contractor, which has invested $13 billion in the LLM maker to
    date and resells the company’s software tools.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Suchman 和 Myers West 都指出 OpenAI 与微软的密切合作关系，后者是一家重要的国防承包商，迄今已投资 130 亿美元于 LLM
    制造商，并转售该公司的软件工具。
- en: The changes come as militaries around the world are eager to incorporate machine
    learning techniques to gain an advantage; the Pentagon is still tentatively exploring
    how it might use ChatGPT or other large-language models, a type of software tool
    that can rapidly and dextrously generate sophisticated text outputs. LLMs are
    trained on giant volumes of books, articles, and other web data in order to approximate
    human responses to user prompts. Though the outputs of an LLM like ChatGPT are
    often extremely convincing, they are optimized for coherence rather than a firm
    grasp on reality and often suffer from so-called hallucinations that make accuracy
    and factuality a problem. Still, the ability of LLMs to quickly ingest text and
    rapidly output analysis — or at least the simulacrum of analysis — makes them
    a natural fit for the data-laden Defense Department.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变化发生在世界各地的军队都渴望利用机器学习技术获取优势的背景下；五角大楼仍在试探性地探索如何使用ChatGPT或其他大型语言模型，这是一种可以快速且灵活地生成复杂文本输出的软件工具。LLM受到巨量书籍、文章和其他网络数据的训练，以便模拟人类对用户提示的回应。虽然像ChatGPT这样的LLM的输出通常非常令人信服，但它们被优化为连贯性，而不是对现实的牢固掌握，并且经常出现所谓的幻觉，使准确性和事实性成为问题。尽管如此，LLM快速吸收文本并快速输出分析（或至少模拟分析）的能力使它们成为充满数据的国防部门的天然选择。
- en: While some within U.S. military leadership have expressed [concern](https://www.armscontrol.org/act/2023-06/news/chatgpt-sparks-us-debate-over-military-use-ai)
    about the tendency of LLMs to insert glaring factual errors or other distortions,
    as well as security risks that might come with using ChatGPT to analyze classified
    or otherwise sensitive data, the Pentagon remains generally eager to adopt artificial
    intelligence tools. In a November address, Deputy Secretary of Defense Kathleen
    Hicks [stated](https://www.defense.gov/News/Speeches/Speech/Article/3578046/remarks-by-deputy-secretary-of-defense-kathleen-h-hicks-on-the-state-of-ai-in-t/)
    that AI is “a key part of the comprehensive, warfighter-centric approach to innovation
    that Secretary [Lloyd] Austin and I have been driving from Day 1,” though she
    cautioned that most current offerings “aren’t yet technically mature enough to
    comply with our ethical AI principles.”
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 军方领导中有一些人对LLM倾向于插入明显的事实错误或其他扭曲以及使用ChatGPT分析机密或其他敏感数据可能带来的安全风险表示[担忧](https://www.armscontrol.org/act/2023-06/news/chatgpt-sparks-us-debate-over-military-use-ai)，但五角大楼仍然普遍热衷于采用人工智能工具。在去年十一月的一次讲话中，国防副部长凯瑟琳·希克斯[表示](https://www.defense.gov/News/Speeches/Speech/Article/3578046/remarks-by-deputy-secretary-of-defense-kathleen-h-hicks-on-the-state-of-ai-in-t/)，人工智能是“从一开始我们一直推动的综合、以战士为中心的创新方法的关键部分”，尽管她警告说，大多数当前的产品“在技术上还不够成熟，无法符合我们的道德人工智能原则”。
- en: Last year, Kimberly Sablon, the Pentagon’s principal director for trusted AI
    and autonomy, [told](https://www.nationaldefensemagazine.org/articles/2023/3/8/pentagons-top-ai-official-addresses-chatgpts-possible-benefits-risks)
    a conference in Hawaii that “[t]here’s a lot of good there in terms of how we
    can utilize large-language models like [ChatGPT] to disrupt critical functions
    across the department.”
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 去年，五角大楼信任人工智能和自主主任金伯利·萨布隆在夏威夷的一次会议上[表示](https://www.nationaldefensemagazine.org/articles/2023/3/8/pentagons-top-ai-official-addresses-chatgpts-possible-benefits-risks)：“在如何利用ChatGPT之类的大型语言模型颠覆部门的关键功能方面，有很多好处。”
- en: '**Update: January 16, 2024**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**更新：2024年1月16日**'
- en: '*This article has been updated to include a statement from OpenAI about the
    use of its technology for military purposes* *that was received after publication.*'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '*本文已经更新，包括OpenAI关于其技术用于军事目的的声明，这是在发表后收到的。*'
