- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-29 12:29:14'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-29 12:29:14'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: New algorithm unlocks high-resolution insights for computer vision | MIT News
    | Massachusetts Institute of Technology
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 新算法为计算机视觉解锁高分辨率见解 | MIT 新闻 | 麻省理工学院
- en: 来源：[https://news.mit.edu/2024/featup-algorithm-unlocks-high-resolution-insights-computer-vision-0318](https://news.mit.edu/2024/featup-algorithm-unlocks-high-resolution-insights-computer-vision-0318)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://news.mit.edu/2024/featup-algorithm-unlocks-high-resolution-insights-computer-vision-0318](https://news.mit.edu/2024/featup-algorithm-unlocks-high-resolution-insights-computer-vision-0318)
- en: 'Imagine yourself glancing at a busy street for a few moments, then trying to
    sketch the scene you saw from memory. Most people could draw the rough positions
    of the major objects like cars, people, and crosswalks, but almost no one can
    draw every detail with pixel-perfect accuracy. The same is true for most modern
    computer vision algorithms: They are fantastic at capturing high-level details
    of a scene, but they lose fine-grained details as they process information.'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你匆匆瞥了一眼繁忙的街道，然后试图凭记忆勾画你看到的场景。大多数人可以画出主要物体的大致位置，比如汽车、行人和人行横道，但几乎没有人能够以像素级的精确度绘制每一个细节。对于大多数现代计算机视觉算法也是如此：它们擅长捕捉场景的高层次细节，但在处理信息时会失去细粒度的细节。
- en: Now, MIT researchers have created a system called “[FeatUp](https://mhamilton.net/featup.html)”
    that lets algorithms capture all of the high- and low-level details of a scene
    at the same time — almost like Lasik eye surgery for computer vision.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，MIT的研究人员创建了一个名为“[FeatUp](https://mhamilton.net/featup.html)”的系统，该系统可以让算法同时捕捉到场景的所有高层次和低层次细节，几乎就像计算机视觉的Lasik眼科手术一样。
- en: When computers learn to “see” from looking at images and videos, they build
    up “ideas” of what's in a scene through something called “features.” To create
    these features, deep networks and visual foundation models break down images into
    a grid of tiny squares and process these squares as a group to determine what's
    going on in a photo. Each tiny square is usually made up of anywhere from 16 to
    32 pixels, so the resolution of these algorithms is dramatically smaller than
    the images they work with. In trying to summarize and understand photos, algorithms
    lose a ton of pixel clarity.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当计算机从图像和视频中“学会”“看见”时，它们通过所谓的“特征”积累了对场景中内容的“理解”。为了创建这些特征，深度网络和视觉基础模型将图像分解为一个个小方格，并将这些方格作为一个组来处理，以确定照片中正在发生的事情。每个小方格通常由16到32个像素组成，因此这些算法的分辨率远远低于它们处理的图像。在试图总结和理解照片时，算法会失去大量的像素清晰度。
- en: The FeatUp algorithm can stop this loss of information and boost the resolution
    of any deep network without compromising on speed or quality. This allows researchers
    to quickly and easily improve the resolution of any new or existing algorithm.
    For example, imagine trying to interpret the predictions of a lung cancer detection
    algorithm with the goal of localizing the tumor. Applying FeatUp before interpreting
    the algorithm using a method like class activation maps (CAM) can yield a dramatically
    more detailed (16-32x) view of where the tumor might be located according to the
    model.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: FeatUp算法可以阻止这种信息损失，并提高任何深度网络的分辨率，而不会影响速度或质量。这使得研究人员可以快速而轻松地改进任何新的或现有算法的分辨率。例如，想象一下，试图解释肺癌检测算法的预测，目标是定位肿瘤。在使用类激活映射（CAM）等方法解释算法之前应用FeatUp，可以显著提供模型可能位于何处的更详细（16-32倍）视图。
- en: FeatUp not only helps practitioners understand their models, but also can improve
    a panoply of different tasks like object detection, semantic segmentation (assigning
    labels to pixels in an image with object labels), and depth estimation. It achieves
    this by providing more accurate, high-resolution features, which are crucial for
    building vision applications ranging from autonomous driving to medical imaging.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: FeatUp不仅帮助实践者理解他们的模型，还可以改善众多不同的任务，如目标检测、语义分割（在图像中为像素分配对象标签）和深度估计。它通过提供更准确、高分辨率的特征来实现这一点，这对于构建从自动驾驶到医学成像等视觉应用至关重要。
- en: '“The essence of all computer vision lies in these deep, intelligent features
    that emerge from the depths of deep learning architectures. The big challenge
    of modern algorithms is that they reduce large images to  very small grids of
    ''smart'' features, gaining intelligent insights but losing the finer details,”
    says Mark Hamilton, an MIT PhD student in electrical engineering and computer
    science, MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) affiliate,
    and a co-lead author on a [paper](https://marhamilresearch4.blob.core.windows.net/feature-upsampling-public/FeatUp_ICLR_2024.pdf)
    about the project. “FeatUp helps enable the best of both worlds: highly intelligent
    representations with the original image’s resolution. These high-resolution features
    significantly boost performance across a spectrum of computer vision tasks, from
    enhancing object detection and improving depth prediction to providing a deeper
    understanding of your network''s decision-making process through high-resolution
    analysis.”'
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: “所有计算机视觉的本质都在于这些深度智能特征，这些特征从深度学习架构的深处浮现而出。现代算法的一个重大挑战是将大图像减少到非常小的'智能'特征网格，从中获取智能见解，但却失去了更精细的细节，”
    麻省理工学院电气工程和计算机科学博士生、麻省理工学院计算机科学与人工智能实验室（CSAIL）联合作者之一，[一篇论文](https://marhamilresearch4.blob.core.windows.net/feature-upsampling-public/FeatUp_ICLR_2024.pdf)
    的联合作者马克·汉密尔顿如是说。 “FeatUp有助于实现两者兼得：高度智能的表征与原始图像的分辨率。这些高分辨率特征显著提升了在各类计算机视觉任务中的性能，从增强物体检测和改善深度预测，到通过高分辨率分析更深入地理解网络的决策过程。”
- en: '**Resolution renaissance **'
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**分辨率复兴**'
- en: As these large AI models become more and more prevalent, there’s an increasing
    need to explain what they’re doing, what they’re looking at, and what they’re
    thinking.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 随着这些大型AI模型的普及，越来越需要解释它们在做什么、它们在看什么以及它们在思考什么。
- en: But how exactly can FeatUp discover these fine-grained details? Curiously, the
    secret lies in wiggling and jiggling images.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，FeatUp究竟如何发现这些细微的细节呢？奇妙的是，秘密在于摇动和晃动图像。
- en: In particular, FeatUp applies minor adjustments (like moving the image a few
    pixels to the left or right) and watches how an algorithm responds to these slight
    movements of the image. This results in hundreds of deep-feature maps that are
    all slightly different, which can be combined into a single crisp, high-resolution,
    set of deep features. “We imagine that some high-resolution features exist, and
    that when we wiggle them and blur them, they will match all of the original, lower-resolution
    features from the wiggled images. Our goal is to learn how to refine the low-resolution
    features into high-resolution features using this 'game' that lets us know how
    well we are doing,” says Hamilton. This methodology is analogous to how algorithms
    can create a 3D model from multiple 2D images by ensuring that the predicted 3D
    object matches all of the 2D photos used to create it. In FeatUp’s case, they
    predict a high-resolution feature map that’s consistent with all of the low-resolution
    feature maps formed by jittering the original image.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，FeatUp对原始图像进行微小调整（如将图像向左或向右移动几个像素），并观察算法如何响应这些图像的轻微变动。这产生了数百个略有不同的深度特征图，可以合并成一个清晰的、高分辨率的深度特征集。
    “我们设想一些高分辨率特征存在，并且当我们摇动它们并模糊它们时，它们将与所有来自摇动图像的原始低分辨率特征匹配。我们的目标是通过这种让我们了解自己做得有多好的'游戏'，学会如何将低分辨率特征精炼为高分辨率特征，”
    汉密尔顿说道。这种方法类似于算法如何通过确保预测的3D对象与用于创建它的所有2D照片匹配来从多个2D图像创建3D模型。在FeatUp的情况下，他们预测与通过摇动原始图像形成的所有低分辨率特征图一致的高分辨率特征图。
- en: The team notes that standard tools available in PyTorch were insufficient for
    their needs, and introduced a new type of deep network layer in their quest for
    a speedy and efficient solution. Their custom layer, a special joint bilateral
    upsampling operation, was over 100 times more efficient than a naive implementation
    in PyTorch. The team also showed this new layer could improve a wide variety of
    different algorithms including semantic segmentation and depth prediction. This
    layer improved the network’s ability to process and understand high-resolution
    details, giving any algorithm that used it a substantial performance boost.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 团队指出，PyTorch 中现有的标准工具不足以满足他们的需求，并在追求高速高效解决方案的过程中引入了一种新型深度网络层。他们的定制层——特殊的联合双边上采样操作，比
    PyTorch 中的朴素实现效率提高了100多倍。团队还展示了这一新层可以改进多种不同算法，包括语义分割和深度预测。这一层提升了网络处理和理解高分辨率细节的能力，使任何使用它的算法都能获得显著的性能提升。
- en: “Another application is something called small object retrieval, where our algorithm
    allows for precise localization of objects. For example, even in cluttered road
    scenes algorithms enriched with FeatUp can see tiny objects like traffic cones,
    reflectors, lights, and potholes where their low-resolution cousins fail. This
    demonstrates its capability to enhance coarse features into finely detailed signals,”
    says Stephanie Fu ’22, MNG ’23, a PhD student at the University of California
    at Berkeley and another co-lead author on the new FeatUp paper. “This is especially
    critical for time-sensitive tasks, like pinpointing a traffic sign on a cluttered
    expressway in a driverless car. This can not only improve the accuracy of such
    tasks by turning broad guesses into exact localizations, but might also make these
    systems more reliable, interpretable, and trustworthy.”
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: “另一个应用是称为小物体检索的东西，我们的算法允许对物体进行精确定位。例如，在杂乱的道路场景中，经过 FeatUp 强化的算法可以看到像交通锥、反光镜、灯和坑洞这样的小物体，而低分辨率版本则无法。这表明了它将粗略特征增强为细节信号的能力。”
    斯蒂芬妮·傅（2022级，MNG'23），加州大学伯克利分校的博士生，也是新 FeatUp 论文的另一位共同主笔作者说。“这对于时间敏感任务尤其重要，比如在杂乱的高速公路上准确定位交通标志。这不仅可以通过将广泛猜测转变为精确定位来提高这些任务的准确性，还可能使这些系统更可靠、可解释和值得信赖。”
- en: '**What next?**'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**接下来？**'
- en: Regarding future aspirations, the team emphasizes FeatUp’s potential widespread
    adoption within the research community and beyond, akin to data augmentation practices.
    “The goal is to make this method a fundamental tool in deep learning, enriching
    models to perceive the world in greater detail without the computational inefficiency
    of traditional high-resolution processing,” says Fu.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 关于未来的抱负，团队强调了 FeatUp 在研究社区及其它领域广泛采用的潜力，类似于数据增强的实践。“我们的目标是将这种方法作为深度学习中的一种基本工具，丰富模型，使其能够在不牺牲传统高分辨率处理的计算效率的情况下更详细地感知世界。”
    Fu说。
- en: “FeatUp represents a wonderful advance towards making visual representations
    really useful, by producing them at full image resolutions,” says Cornell University
    computer science professor Noah Snavely, who was not involved in the research.
    “Learned visual representations have become really good in the last few years,
    but they are almost always produced at very low resolution — you might put in
    a nice full-resolution photo, and get back a tiny, postage stamp-sized grid of
    features. That’s a problem if you want to use those features in applications that
    produce full-resolution outputs. FeatUp solves this problem in a creative way
    by combining classic ideas in super-resolution with modern learning approaches,
    leading to beautiful, high-resolution feature maps.”
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: “FeatUp在提供全分辨率的图像表示方面取得了显著进展，使其真正有用。” 康奈尔大学计算机科学教授诺亚·斯纳韦利（未参与研究）说。“学习的视觉表示在过去几年中变得非常好，但几乎总是以非常低的分辨率生成
    —— 你可能输入一张漂亮的全分辨率照片，却只得到一个小小的邮票大小的特征网格。如果你想在生成全分辨率输出的应用中使用这些特征，这就成了问题。FeatUp通过将超分辨率的经典思想与现代学习方法结合在一起，创造性地解决了这个问题，从而产生了美丽而高分辨率的特征图。”
- en: “We hope this simple idea can have broad application. It provides high-resolution
    versions of image analytics that we’d thought before could only be low-resolution,”
    says senior author William T. Freeman, an MIT professor of electrical engineering
    and computer science professor and CSAIL member.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: “我们希望这一简单的想法能有广泛的应用。它提供了我们之前认为只能是低分辨率的图像分析的高分辨率版本。” 麻省理工学院电气工程和计算机科学教授、CSAIL成员William
    T. Freeman 高级作者如是说。
- en: Lead authors Fu and Hamilton are accompanied by MIT PhD students Laura Brandt
    SM ’21 and Axel Feldmann SM ’21, as well as Zhoutong Zhang SM ’21, PhD ’22, all
    current or former affiliates of MIT CSAIL. Their research is supported, in part,
    by a National Science Foundation Graduate Research Fellowship**,** by the National
    Science Foundation and Office of the Director of National Intelligence, by the
    U.S. Air Force Research Laboratory, and by the U.S. Air Force Artificial Intelligence
    Accelerator. The group will present their work in May at the International Conference
    on Learning Representations.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 主要作者Fu和Hamilton与MIT的博士生Laura Brandt SM '21和Axel Feldmann SM '21，以及Zhoutong Zhang
    SM '21，PhD '22，他们都是当前或前MIT CSAIL的成员。他们的研究在一定程度上得到了美国国家科学基金会研究生研究奖助金的支持，以及美国国家科学基金会和国家情报局办公室、美国空军研究实验室以及美国空军人工智能加速器的支持。该团队将于五月份在国际学习表示会议上展示他们的工作。
