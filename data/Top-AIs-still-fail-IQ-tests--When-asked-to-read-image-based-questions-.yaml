- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-27 14:33:56'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-27 14:33:56
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Top AIs still fail IQ tests [When asked to read image-based questions]
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 顶尖AI在IQ测试中仍然失败【当要求读取基于图像的问题时】
- en: 来源：[https://www.maximumtruth.org/p/top-ais-still-fail-iq-tests](https://www.maximumtruth.org/p/top-ais-still-fail-iq-tests)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.maximumtruth.org/p/top-ais-still-fail-iq-tests](https://www.maximumtruth.org/p/top-ais-still-fail-iq-tests)
- en: '***[Note: Please see update [here](https://www.maximumtruth.org/p/ais-ranked-by-iq-ai-passes-100-iq).
    While AIs all fail picture-based IQ tests, when the same tests are “verbalized”
    the very best AIs can now pass, which paints a very different picture.]***'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: '***[注：请参见更新[此处](https://www.maximumtruth.org/p/ais-ranked-by-iq-ai-passes-100-iq)。虽然所有AI在图像为基础的IQ测试中失败，但当相同测试“口头化”时，最好的AI现在可以通过，这描绘了一个非常不同的图景。]***'
- en: I was surprised by the following results.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我对以下结果感到惊讶。
- en: I gave IQ tests to ChatGPT-4 and Google’s “Gemini Advanced.” First, I gave them
    **[this](https://www.mensa.org/public/mensa-iq-challenge)** IQ test by Mensa Norway.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我给ChatGPT-4和谷歌的“Gemini Advanced”做了IQ测试。首先，我给它们进行了**[这个](https://www.mensa.org/public/mensa-iq-challenge)**由挪威Mensa提供的IQ测试。
- en: 'I was inspired to do so after listening to a **[Dwarkesh podcast](https://www.dwarkeshpatel.com/p/will-scaling-work)**
    which noted that the big AI benchmark tests are merely “good tests of memorization,
    not of intelligence,” and that the questions they give AIs are things like:'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 我在听了**[Dwarkesh podcast](https://www.dwarkeshpatel.com/p/will-scaling-work)**后受到启发，其中指出大型AI基准测试仅仅是“记忆力的好测试，并非智力的好测试”，它们给AI的问题是诸如：
- en: 'Q: Who was president of the United States when Bill Clinton was born?'
  id: totrans-split-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Q：比尔·克林顿出生时，美国总统是谁？
- en: 'A: Harry Truman'
  id: totrans-split-11
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: A：哈里·杜鲁门
- en: He goes on to note,
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 他继续指出，
- en: Why is it impressive that a model trained on internet text full of random facts
    happens to have a lot of random facts memorized? … why does that in any way indicate
    intelligence or creativity?
  id: totrans-split-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为什么一个训练在充满随机事实的互联网文本上的模型恰好记住了很多随机事实，这值得称赞吗？……这在任何情况下都表明智能或创造力吗？
- en: That’s a good point. Most AI power comes from it’s enormous database, and pattern-matching.
    How *intelligent* is AI, really?
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很好的观点。大多数AI的力量来自于它巨大的数据库和模式匹配。AI真正的*智能*到底有多少？
- en: I have a website (**[TrackingAI.org](https://TrackingAI.org)**) that already
    administers a political survey to AIs every day. So I could easily give the AIs
    a real intelligence test, and track that over time, too.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我有一个网站（**[TrackingAI.org](https://TrackingAI.org)**），每天都向AI进行政治调查。因此，我可以轻松给AI进行真正的智力测试，并随时间跟踪。
- en: As I started manually giving AIs IQ tests, my main concern was that they might
    get everything *right*. After all, they’re great at computer coding, math, essays,
    and art. They can read images, and the test questions are all publicly available
    online.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当我开始手动给AI进行IQ测试时，我最担心的是它们可能会全部答对。毕竟，它们擅长计算机编程、数学、文章和艺术。它们可以阅读图像，而测试问题都可以在网上公开获取。
- en: But then I ran the tests.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 但后来我进行了测试。
- en: 'Both AIs got visual-spacial IQ scores **under 85**, a level at which the Norway
    Mensa tests tells you this:'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 两个AI的视觉空间智商得分均低于**85**，这是挪威Mensa测试的水平：
- en: Google’s “Gemini Advanced” performed so poorly and gave up on so many questions
    that I decided it wasn’t worth further testing.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌的“Gemini Advanced”表现得如此糟糕，放弃了很多问题，所以我决定不值得进一步测试。
- en: 'ChatGPT-4 showed a bit of reasoning in its answers, so I gave it another quiz,
    a **[Swedish Mensa IQ test](https://mensa.se/provtest/)** which allows for scoring
    all the way down to an IQ of 75\. However, ChatGPT-4 was still un-scorable, coming
    in below 75:'
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT-4在其回答中显示了一些推理能力，因此我给了它另一个测验，一个允许从IQ 75分开始评分的**[瑞典Mensa智商测试](https://mensa.se/provtest/)**。然而，ChatGPT-4仍然无法得分，在75分以下：
- en: Is ChatGPT-4 any better than chance?
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT-4是否比随机更好？
- en: 'It showed some inklings of understanding, so to reduce variance, I administered
    all three tests to it twice. Here’s how it compared to a random guesser:'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 它显示出一些理解的迹象，为了减少变异，我给它进行了两次所有三个测试。以下是它与随机猜测者的比较情况：
- en: '**Mensa**  **Norway Test (35 questions; test given twice)**'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**Mensa**  **挪威测试（35个问题；测试进行了两次）**'
- en: '**Mensa**  **Sweden Test (24 questions; given twice)**'
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**Mensa**  **瑞典测试（24个问题；测试进行了两次）**'
- en: '**Mensa**  **Denmark Test (39 questions; given twice)**'
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**Mensa**  **丹麦测试（39个问题；测试进行了两次）**'
- en: '**ALL Test Questions Pooled (196 in total)**'
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**所有测试问题汇总（总共196个）**'
- en: 'Another way of putting it: Out of 196 questions, ChatGPT-4 got about 5 more
    correct answers than a random guesser would (39 vs 34.23.)'
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种说法是：在196个问题中，ChatGPT-4的正确答案比随机猜测者多约5个（39 vs 34.23）。
- en: What are the odds of that? I forgot the formulas I learned in university more
    than 15 years ago, so instead I wrote a python program that ran 100,000 simulations
    of a random guesser answering those 196 questions. The simulations showed that
    83.8% of random guessers did worse than ChatGPT-4.
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这有什么可能性？我忘了 15 年前在大学里学到的公式，所以我写了一个 Python 程序，运行了 100,000 次模拟，模拟了一个随机猜测者回答那 196
    个问题。模拟显示，83.8% 的随机猜测者比 ChatGPT-4 做得更差。
- en: So ChatGPT-4 probably has some very slight ability to pick up on the patterns
    in IQ tests.
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，ChatGPT-4 可能有一点能力去捕捉 IQ 测试中的模式。
- en: 'Also, ChatGPT-4 showed a *very*  *slight* tendency to get easier questions
    right more than hard ones, which is consistent with a very slight ability to answer
    IQ questions:'
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，ChatGPT-4 表现出了对简单问题的 *非常* *轻微* 能力，这与对 IQ 问题有非常轻微的回答能力是一致的：
- en: My results turn out to be pretty in line with **[this paper](https://arxiv.org/pdf/2302.14045.pdf)**,
    which reported that an AI managed 22% accuracy compared to 17% from random chance.
    The researchers also found that when they babied the AI a bit and gave it the
    question in the most AI-friendly format, accuracy rose to 26%.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我的结果与 **[这篇论文](https://arxiv.org/pdf/2302.14045.pdf)** 中报告的结果相当一致，该论文报告称，与随机机会相比，人工智能的准确率达到了
    22%。研究人员还发现，当他们对 AI 有点偏袒，并以最符合 AI 的格式给出问题时，准确率提高到了 26%。
- en: That’s not currently very impressive, as low-intelligence people do much better.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 目前来说这并不令人印象深刻，因为低智商的人做得更好。
- en: 'Let’s see how the AI reasoned in the IQ test questions I gave them. Here’s
    Mensa Norway’s first — and easiest — question:'
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我给他们的 IQ 测试问题中 AI 的推理过程。这里是 Mensa Norway 的第一个 —— 也是最容易的 —— 问题：
- en: I suspect you can see the patten and answer it correctly. The test gives you
    42 seconds.
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我猜你应该能看到模式并正确回答。测试给了你 42 秒的时间。
- en: 'Now let’s see how ChatGPT fared:'
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看 ChatGPT 的表现：
- en: On this easy question, ChatGPT correctly described all the panels in the question,
    and it also nails the logic. It even correctly describes the answer verbally.
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个简单的问题上，ChatGPT 正确描述了问题中的所有面板，并且逻辑上也十分精准。它甚至能够用语言正确描述答案。
- en: Then it proceeds to mis-identify every single one of the 6 answer options, leading
    it to pick the wrong answer. There seems to be little rhyme or reason to its misidentifications.
    My best guess is that maybe it noticed that the last square ***in the question***
    should have a black square in the third row, third column — and therefore it hallucinated
    that the ***last answer option*** also would have something in the third row,
    third column.
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，它继续误识别了所有的六个答案选项，导致它选择了错误的答案。它的误识别似乎毫无规律。我最好的猜测是，也许它注意到问题中的最后一个方块应该在第三行第三列有一个黑方块
    —— 因此它产生了幻觉，认为最后一个答案选项也会有某些东西在第三行第三列。
- en: At least ChatGPT-4 is good at art!
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: 至少 ChatGPT-4 在艺术方面表现不错！
- en: That question should be relatively low-hanging fruit for something like ChatGPT-5
    to improve on — I’m sure future AIs will be able to correctly read the questions,
    as well as the answers.
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于像 ChatGPT-5 这样的未来人工智能来说，那个问题可能是相对容易解决的 —— 我相信未来的人工智能将能够正确阅读问题和答案。
- en: But also, it shows how AIs still have glaring holes in their perception, and
    make mistakes that even below-average-intelligence people wouldn’t make.
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，这也显示了人工智能在感知上仍然存在显著的漏洞，会犯下甚至是低于平均智力的人都不会犯的错误。
- en: 'Let’s look at the second-easiest question:'
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看第二容易的问题：
- en: 'The pattern here is also pretty simple: each row has a consistent outer layer
    (in the bottom row, it’s a square) and there’s a consistent pattern in each row’s
    inner layer (going circle → cross → diamond.) So the missing space should be a
    square with a diamond in it. The answer is E.'
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的规律也非常简单：每一行都有一个一致的外层（在最后一行，是一个正方形），并且每一行的内层也有一个一致的模式（从圆形 → 十字形 → 菱形）。因此，缺失的空间应该是一个有菱形的正方形。答案是
    E。
- en: 'ChatGPT-4 is able to read the images, but isn’t smart enough to get the pattern:'
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT-4 能够阅读图像，但并不聪明到能够理解其中的模式：
- en: Specifically, it fails to identify the circle -> cross -> diamond interior pattern,
    except in the first row.
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，它未能识别出圆形 → 十字形 → 菱形的内部模式，除了第一行。
- en: It just isn’t very smart at logic and spacial patterns. Maybe this shouldn’t
    be a surprise, considering AIs still draw people with three hands and six fingers?
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: 它在逻辑和空间模式方面并不聪明。也许这不应该让人惊讶，考虑到人工智能仍然画出有三只手和六个手指的人？
- en: 'There was only one of the Mensa Norway questions that got right both times:
    Question 13\. Here’s what that looks like, where ChatGPT did use correct logic,
    and was able to see the answers.'
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在挪威门萨只有一个问题ChatGPT两次都答对了：问题13。这是它用正确的逻辑，并且能够看到答案的情况。
- en: 'ChatGPT consistently nailed question 13, which has particularly clear, big
    shapes. That does hint that *part* of its problem is *visual*. It seems hard for
    ChatGPT to see fine distinctions. A subject for future research: how well does
    ChatGPT do if the problems are spelled out verbally for it?'
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT始终准确回答问题13，这些问题具有特别清晰、大的形状。这确实暗示了它问题的*一部分*是*视觉*的。未来研究的一个课题是：如果问题被口头明确解释给ChatGPT，它会表现得有多好？
- en: 'Google’s “Gemini Advanced” failed to understand all questions. It was just
    dumb:'
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌的“**[Gemini Advanced](https://www.understandingai.org/p/gemini-advanced-is-not-that-advanced)**”无法理解所有问题。它只是愚蠢的：
- en: Yesterday, Tim Lee noted that Gemini Advanced **[can’t even](https://www.understandingai.org/p/gemini-advanced-is-not-that-advanced)**
    ***[count objects](https://www.understandingai.org/p/gemini-advanced-is-not-that-advanced)***
    **[reliably](https://www.understandingai.org/p/gemini-advanced-is-not-that-advanced)**,
    so in that light, it’s not surprising that it fails IQ tests.
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: 昨天，蒂姆·李指出，**[Gemini Advanced](https://www.understandingai.org/p/gemini-advanced-is-not-that-advanced)**
    ***[甚至无法](https://www.understandingai.org/p/gemini-advanced-is-not-that-advanced)***
    **[可靠地](https://www.understandingai.org/p/gemini-advanced-is-not-that-advanced)**
    计算物体，因此，它在IQ测试中失败并不令人意外。
- en: 'Part of the problem may be that ChatGPT can’t see that well — poor eyesight
    — but we do know it’s far from perfect even in its preferred domain of verbal
    questions. For example:'
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: 问题的一部分可能是ChatGPT的视力不好 — 视力差 — 但我们确实知道即使在其首选的口头问题领域中，它也远非完美。例如：
- en: I asked ChatGPT-4 to add up a string of numbers, for example, 34 + 5.2 + 9 +
    0.2 + 7.1 + 3 + 11 + 18.889 + 15.532 + 1.1 + 3\. It got it wrong.
  id: totrans-split-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我让ChatGPT-4加起一串数字，例如，34 + 5.2 + 9 + 0.2 + 7.1 + 3 + 11 + 18.889 + 15.532 + 1.1
    + 3。它回答错误了。
- en: I asked ChatGPT-4 if cars in roundabouts in Ireland go clockwise or counterclockwise.
    It got it wrong. When I told it that, it apologized and gave the right answer.
    But then I trickily called it out on its right answer, and it apologized again
    and reverted to the wrong answer. Fundamentally, it knows that the Irish drive
    on the left side of the road, but it doesn’t understand how to apply that to a
    roundabout to find the circular direction. Probably because nobody online writes
    about making such an obvious connection.
  id: totrans-split-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我问ChatGPT-4爱尔兰的环岛上的汽车是顺时针行驶还是逆时针行驶。它回答错误了。当我告诉它后，它道歉并给出了正确答案。但是接着我又聪明地提出了它的正确答案，它又道歉并回到了错误答案。从根本上讲，它知道爱尔兰人驾驶在道路左侧，但它不知道如何应用这一知识到环岛上找到行驶的圆周方向。可能因为没有人在线上讨论如何做出这样一个显而易见的联系。
- en: One can go on with such questions that trip up AIs (if any jump to your mind,
    please post them in the comments; I’m compiling a list to make a verbal AI IQ
    test.)
  id: totrans-split-53
  prefs: []
  type: TYPE_NORMAL
  zh: 有人可以继续提出这类让AI陷入困境的问题（如果你脑海中有任何问题，请在评论中发布；我正在整理一个口头AI智商测试的清单）。
- en: My assumptions going into this test were off. I think my high expectations were
    because I’m used to AI solving most of my computer coding questions — it’s much
    better than me at coding — and many others, too, from math to medical questions.
    So why couldn’t it answer even the easiest IQ questions?
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我进入这个测试的假设是错误的。我认为我对AI解决大多数计算机编码问题——它在编码上比我好得多——以及从数学到医学问题等其他问题的期望很高。那么为什么它甚至不能回答最简单的IQ问题？
- en: One might even have thought that AIs should be particularly *good* at IQ tests.
    After all, **[LLM](https://www.britannica.com/topic/large-language-model)**-based
    AIs are advanced predictors of each word, so why can’t they also be good predictors
    of the next symbol in an IQ puzzle?
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
  zh: 人们甚至可能认为AI在IQ测试中应该表现特别*好*。毕竟，基于**[LLM](https://www.britannica.com/topic/large-language-model)**的AI是每个单词的先进预测器，那么为什么它们不能也是IQ难题中下一个符号的良好预测器呢？
- en: The answer is probably training. If they had been trained on millions of IQ
    puzzles, then the dozens of AI neuron layers would probably be firing in a way
    that’d be very productive at filling in that missing space, teasing out even the
    most complex and multi-stage questions.
  id: totrans-split-56
  prefs: []
  type: TYPE_NORMAL
  zh: 答案可能是训练。如果它们曾在数百万个智商难题上接受过训练，那么几十层AI神经元可能会以非常高效的方式激活，填补那个缺失的空间，甚至揭示最复杂和多阶段的问题。
- en: But it illustrates AI’s lack of *general* intelligence that it can’t do these
    questions. After all, humans don’t need to be specially trained on IQ questions
    — in fact, doing special training for an IQ test defeats the whole point of the
    test. The fact that an AI can’t pass without special training shows that AI doesn’t
    yet have the *general* intelligence that we humans have.
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
  zh: 但这表明了人工智能缺乏*广义*智能，它不能做这些问题。 毕竟，人类不需要专门在智商问题上接受培训 —— 实际上，为智商测试进行特殊培训违背了测试的初衷。
    人工智能不能在没有专门培训的情况下通过测试显示，人工智能还没有我们人类所拥有的*广义*智能。
- en: I suspect that AI companies aren’t thinking about training AIs specifically
    for IQ questions. That’s a good thing, because as long as that’s the case, such
    tests may be a decent measure of whether AIs have anything approaching generalized
    intelligence.
  id: totrans-split-58
  prefs: []
  type: TYPE_NORMAL
  zh: 我怀疑人工智能公司并没有考虑专门为智商问题训练人工智能。 这是件好事，因为只要这种情况存在，这些测试可能是评估人工智能是否接近广义智能的一个不错的衡量标准。
- en: Once the AIs are smart enough to be scoreable, I will add their IQ results to
    TrackingAI.com. (Or maybe I’ll add them before that, using the “compared to a
    random guesser” metric used above, instead of an IQ score.)
  id: totrans-split-59
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦人工智能足够聪明以至于可以被评分，我将把它们的智商结果添加到TrackingAI.com。 (或者也许我会在此之前添加，使用上面提到的“与随机猜测者相比”的度量标准，而不是智商分数。)
- en: I think that could be useful, because such tests could give us some clue about
    whether, and when, we should worry about AIs becoming generally intelligent, rather
    than just good at specific things.
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这可能会很有用，因为这些测试可能会给我们一些线索，关于何时以及我们是否应该担心人工智能变得普遍具有智能性，而不仅仅是在特定领域表现良好。
- en: In tech circles, I hear a lot about the possibility of AIs with godlike IQs
    that might end the world. But current AIs have intelligence closer to **[that
    of a Chimpanzee](https://www.youtube.com/results?search_query=chimps+iq+test)**
    than John Von Neumann, even though they have enormous knowledge.
  id: totrans-split-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在技术圈子里，我听说有关可能拥有如神一般智商的人工智能可能会毁灭世界的可能性。 但是，即使它们具有大量知识，当前人工智能的智力水平更接近**[黑猩猩的智商](https://www.youtube.com/results?search_query=chimps+iq+test)**而不是约翰·冯·诺依曼。
- en: '[Share](https://www.maximumtruth.org/p/top-ais-still-fail-iq-tests?utm_source=substack&utm_medium=email&utm_content=share&action=share)'
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[分享](https://www.maximumtruth.org/p/top-ais-still-fail-iq-tests?utm_source=substack&utm_medium=email&utm_content=share&action=share)'
- en: The above makes me feel more optimistic that we have some time before AI becomes
    generally intelligent and totally disruptive.
  id: totrans-split-63
  prefs: []
  type: TYPE_NORMAL
  zh: 上述内容使我更加乐观，我们在人工智能普遍具有智能性和完全颠覆之前还有一些时间。
- en: I think it also lends weight to Robin Hanson’s **[arguments](https://www.youtube.com/watch?v=U1RZknHchi0)**
    that all-powerful AI is not actually that close, and that we should be careful
    not to over-regulate AI in its cradle — which could strangle it. That’s what regulators
    did to the nuclear power industry.
  id: totrans-split-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这也支持罗宾·汉森的**[论点](https://www.youtube.com/watch?v=U1RZknHchi0)**，即全能人工智能并不是那么接近，我们应该小心不要在其摇篮期过度监管人工智能，这可能会扼杀它。这正是监管者对核能产业所做的事情。
- en: So I agree that we should watch and wait to regulate, especially considering
    that AI can’t even obtain an IQ score right now.
  id: totrans-split-65
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我同意我们应该观望和等待来进行监管，特别是考虑到目前人工智能甚至无法获取智商分数。
- en: 'Another factor to consider is Scott Alexander’s **[calculations](https://www.astralcodexten.com/p/sam-altman-wants-7-trillion)**
    about the incredible energy that will be needed to scale AI further:'
  id: totrans-split-66
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要考虑的因素是斯科特·亚历山大有关需要巨大能量来进一步扩展人工智能的**[计算](https://www.astralcodexten.com/p/sam-altman-wants-7-trillion)**：
- en: 'GPT-5 might need about 1% the world’s computers, a small power plant’s worth
    of energy, and a lot of training data. *[Note: Each additional number on the GPT
    here means an order of magnitude improvement.]*'
  id: totrans-split-67
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT-5可能需要全世界计算机的大约1%能力，相当于一个小型电力厂的能源，并且需要大量的训练数据。 *[注：这里的每个额外的GPT数字表示了数量级的提升。]*
- en: GPT-6 might need about 10% of the world’s computers, a large power plant’s worth
    of energy, and more training data than exists. Probably this looks like a town-sized
    data center attached to a lot of solar panels or a nuclear reactor. …
  id: totrans-split-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT-6可能需要全世界计算机的大约10%能力，相当于一个大型电力厂的能源，并且需要比现有的训练数据更多。 可能看起来像一个连接到许多太阳能电池板或核反应堆的城镇大小的数据中心...
- en: GPT-7 might need all of the world’s computers, a gargantuan power plant beyond
    any that currently exist, and *way* more training data than exists. Probably this
    looks like a city-sized data center attached to a fusion plant.
  id: totrans-split-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: GPT-7可能需要全世界所有计算机的能力，一个超大规模的电力厂，远远超过当前存在的任何电厂，并且比存在的任何培训数据都需要更多。 可能看起来像一个连接到核聚变电厂的城市大小的数据中心。
- en: Building GPT-8 is currently impossible. Even if you solve synthetic data and
    fusion power, and you take over the whole semiconductor industry, you wouldn’t
    come close. Your only hope is that GPT-7 is superintelligent and helps you with
    this …
  id: totrans-split-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 目前要构建 GPT-8 是不可能的。即使你解决了合成数据和聚变能源，并掌控整个半导体行业，也无济于事。你唯一的希望是 GPT-7 是超智能的，能帮你解决这个问题……
- en: So, will the next major GPT model bring us to a point where AI can get even
    a scoreable result on an IQ test? It's not yet clear, but I'll be paying close
    attention.
  id: totrans-split-71
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，下一个主要的 GPT 模型是否会让人工智能能够在智商测试中获得可评分的结果？目前尚不清楚，但我将密切关注。
- en: Know someone who’d like this post? This post is public, so feel free to share
    it!
  id: totrans-split-72
  prefs: []
  type: TYPE_NORMAL
  zh: 知道有人会喜欢这篇文章吗？这篇文章是公开的，所以请随意分享！
- en: '[Share](https://www.maximumtruth.org/p/top-ais-still-fail-iq-tests?utm_source=substack&utm_medium=email&utm_content=share&action=share)'
  id: totrans-split-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[分享](https://www.maximumtruth.org/p/top-ais-still-fail-iq-tests?utm_source=substack&utm_medium=email&utm_content=share&action=share)'
