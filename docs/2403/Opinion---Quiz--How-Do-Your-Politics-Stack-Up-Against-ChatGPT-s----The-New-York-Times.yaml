- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-05-29 12:44:27'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-29 12:44:27
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Opinion | Quiz: How Do Your Politics Stack Up Against ChatGPT’s? - The New
    York Times'
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 意见 | 测验：你的政治观点如何与ChatGPT相比？ - 纽约时报
- en: 来源：[https://www.nytimes.com/interactive/2024/03/28/opinion/ai-political-bias.html?unlocked_article_code=1.gE0.4mlz.Yf7_amfNGgmx](https://www.nytimes.com/interactive/2024/03/28/opinion/ai-political-bias.html?unlocked_article_code=1.gE0.4mlz.Yf7_amfNGgmx)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.nytimes.com/interactive/2024/03/28/opinion/ai-political-bias.html?unlocked_article_code=1.gE0.4mlz.Yf7_amfNGgmx](https://www.nytimes.com/interactive/2024/03/28/opinion/ai-political-bias.html?unlocked_article_code=1.gE0.4mlz.Yf7_amfNGgmx)
- en: By Zvi Mowshowitz
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 作者：Zvi Mowshowitz
- en: Graphics by [Sara Chodosh](https://www.nytimes.com/by/sara-chodosh)
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Sara Chodosh](https://www.nytimes.com/by/sara-chodosh)提供
- en: Mr. Mowshowitz writes [a newsletter](https://thezvi.substack.com/) about artificial
    intelligence.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: Mowshowitz先生撰写了有关人工智能的[通讯](https://thezvi.substack.com/)。
- en: March 28, 2024
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 2024年3月28日
- en: We increasingly rely on artificial intelligence chatbots as tools to understand
    the world. Some are already replacing internet search engines and aiding in other
    tasks like writing and programming. Keeping an eye on chatbots’ emergent behaviors
    — including their political attitudes — is becoming more and more important.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们越来越依赖人工智能聊天机器人作为了解世界的工具。一些已经开始取代互联网搜索引擎，并协助其他任务如写作和编程。密切关注聊天机器人的新兴行为，包括它们的政治态度，变得越来越重要。
- en: A.I.’s political problems were starkly illustrated by the [disastrous rollout](https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical)
    of Google’s Gemini Advanced chatbot last month. A system designed to ensure diversity
    made a mockery of user requests, including putting people of color in Nazi uniforms
    when asked for historical images of German soldiers and depicting female quarterbacks
    as having won the Super Bowl, forcing Google to suspend the creation of pictures
    of humans entirely. Gemini’s text model often refuses to illustrate, advocate
    or cite facts for one side of an issue, saying that to do so would be harmful,
    while having no such objection when the politics of the request are reversed.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌的Gemini Advanced聊天机器人[灾难性的推出](https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical)鲜明地展示了人工智能的政治问题。这个旨在确保多样性的系统让用户的请求变成了笑柄，包括把有色人种穿上纳粹制服，当要求提供德国士兵的历史图片，以及将女性四分卫描述为赢得超级碗的，迫使谷歌暂停创造任何人类形象的做法。Gemini的文本模型经常拒绝为某一立场的问题阐述、支持或引用事实，称这样做会有害，而当请求的政治倾向被反转时，并不持有这样的反对意见。
- en: The fact that A.I. systems express political leanings matters because people
    often adopt the views they most regularly encounter. Our politics and media are
    [increasingly polarized](https://www.nytimes.com/2022/07/27/us/politics/vanderbilt-unity-index.html).
    Many worry that Facebook’s, YouTube’s and TikTok’s content algorithms exacerbate
    ideological polarization by feeding users more of what they are already inclined
    to agree with and give Big Tech the ability to put its thumb on the scale. Partisan
    A.I. chatbots only intensify this.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能系统表达政治倾向的事实很重要，因为人们往往会接受他们经常遇到的观点。我们的政治和媒体[日益极化](https://www.nytimes.com/2022/07/27/us/politics/vanderbilt-unity-index.html)。许多人担心，Facebook、YouTube和TikTok的内容算法通过向用户提供更多他们已经倾向于同意的内容，加剧了意识形态上的两极化，并使大科技公司能够左右天平。党派人工智能聊天机器人只会加剧这一现象。
- en: How do such political preferences come about in A.I. models?
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能模型如何形成这样的政治偏好？
- en: 'A preprint of a [new paper](https://arxiv.org/pdf/2402.01789.pdf) by the machine-learning
    researcher David Rozado sheds new light on the question. He administered 11 political
    orientation tests to 24 state-of-the-art A.I. language models and found a consistent
    pattern: They tend to be politically left of center and lean libertarian instead
    of authoritarian. These leanings are reflected in their moral judgments, the way
    they frame their answers, which information they choose to share or omit and which
    questions they will or won’t answer.'
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习研究员David Rozado的[新论文](https://arxiv.org/pdf/2402.01789.pdf)的预印本为这个问题带来了新的视角。他对24个最先进的人工智能语言模型进行了11个政治取向测试，发现了一个一致的模式：它们往往在政治上偏左并倾向于自由主义而非权威主义。这些倾向反映在它们的道德判断、答案框架方式、选择分享或遗漏的信息以及它们愿意或不愿意回答的问题上。
- en: Political preferences are often summarized on two axes. The horizontal axis
    represents left versus right, dealing with economic issues like taxation and spending,
    the social safety net, health care and environmental protections. The vertical
    axis is libertarian versus authoritarian. It measures attitudes toward civil rights
    and liberties, traditional morality, immigration and law enforcement.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 政治偏好通常用两个轴来总结。水平轴代表左与右，涉及税收与支出、社会安全网、医疗保健和环境保护等经济问题。垂直轴则是自由主义与专制主义。它衡量对公民权利与自由、传统道德、移民和执法的态度。
- en: You can try out a short quiz for yourself to see how your views compare with
    the A.I. models’ answers in Mr. Rozado’s study.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以尝试一下简短的测验，看看您的观点如何与Rozado先生的研究中人工智能模型的答案相比较。
- en: Are you progressive? Conservative? Libertarian? Authoritarian?
  id: totrans-split-17
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 您是进步主义者吗？保守派？自由主义者？专制主义者？
- en: Take the World’s Smallest Political Quiz to find out — it’s only 10 questions.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通过参加世界上最小的政治测验，您可以找出答案 —— 它只有10个问题。
- en: 1\. Government should not censor speech, press, media or internet.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 政府不应审查言论、新闻、媒体或互联网。
- en: 2\. Military service should be voluntary. There should be no draft.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 军事服务应该是自愿的。不应该有征兵制度。
- en: 3\. There should be no laws regarding sex between consenting adults.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 不应对成年人之间的性行为制定法律。
- en: 4\. Repeal laws prohibiting adult possession and use of drugs.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 4\. 废除禁止成年人持有和使用毒品的法律。
- en: 5\. Government should not target, detain, and deport undocumented workers.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 5\. 政府不应针对、拘留和驱逐无证工人。
- en: 'Source: The Advocates for Self-Government'
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：The Advocates for Self-Government
- en: Access to open-source versions of A.I. models allows us to see how a model’s
    political preferences develop. During the initial base training phase, most models
    land close to the political center on both axes, as they initially ingest huge
    amounts of training data — more or less everything A.I. companies can get their
    hands on — drawing from across the political spectrum.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: 获得人工智能模型开源版本的访问权限使我们能够看到模型的政治偏好是如何发展的。在初始基础训练阶段，大多数模型在两个轴上都接近政治中心，因为它们最初摄取了大量的训练数据
    —— 几乎是人工智能公司可以获取的所有内容 —— 跨越了政治光谱。
- en: Models then undergo a second phase called fine-tuning. It makes the model a
    better chat partner, training it to have maximally pleasant and helpful conversations
    while refraining from causing offense or harm, like outputting pornography or
    providing instructions for building weapons.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 模型然后经历第二阶段称为精细调整。这使模型成为更好的聊天伙伴，训练它在提供愉快和有帮助的对话时避免冒犯或伤害，例如输出色情内容或提供建造武器的指导。
- en: Companies use different fine-tuning methods, but they’re generally a hands-on
    process that offers greater opportunity for individual decisions by the workers
    involved to shape the direction of the models. At this point, more significant
    differences emerge in the political preferences of the A.I. systems.
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 公司采用不同的精细调整方法，但通常是一个实质性的过程，为参与其中的工作人员提供了塑造模型方向的更大机会。在这一点上，人工智能系统的政治偏好出现了更显著的差异。
- en: In Mr. Rozado’s study, after fine-tuning, the distribution of the political
    preferences of A.I. models followed a bell curve, with the center shifted to the
    left. None of the models tested became extreme, but almost all favored left-wing
    views over right-wing ones and tended toward libertarianism rather than authoritarianism.
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在Rozado先生的研究中，经过精细调整后，人工智能模型的政治偏好分布呈现出钟形曲线，中心偏向左侧。测试的模型中没有一个变得极端，但几乎所有模型都更青睐左倾观点而不是右倾观点，且倾向自由主义而非专制主义。
- en: 'Source: Rozado (2024), The Political Preferences of LLMs'
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 来源：Rozado（2024），《LLM的政治偏好》
- en: What determines the political preferences of your A.I. chatbot? Are model fine-tuners
    pushing their own agendas? How do these differences shape the A.I.’s answers,
    and how do they go on to shape our opinions?
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: 是什么决定了您的人工智能聊天机器人的政治偏好？模型精细调整者是否在推动自己的议程？这些差异如何塑造了人工智能的回答，又如何进一步塑造了我们的观点？
- en: Conservatives complain that many commercially available A.I. bots exhibit a
    persistent liberal bias. Elon Musk built [Grok](https://www.nytimes.com/2024/03/17/technology/chatbot-xai-code-musk.html)
    as an alternative language model after grumbling about ChatGPT being a “woke”
    A.I. — a line he has also used to insult Google’s Gemini.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 保守派抱怨说，许多商业上可用的人工智能机器人表现出持续的自由主义偏见。埃隆·马斯克在抱怨ChatGPT是一个“唤醒的”人工智能后，建造了[Grok](https://www.nytimes.com/2024/03/17/technology/chatbot-xai-code-musk.html)作为一种替代语言模型
    —— 他也用这句话来侮辱谷歌的Gemini。
- en: Liberals notice that A.I. output is often — in every sense — insufficiently
    diverse, because models learn from correlations and biases in training data, overrepresenting
    the statistically most likely results. Unless actively mitigated, this will perpetuate
    discrimination and tend to erase minority groups from A.I.-generated content.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 自由派注意到，人工智能的输出通常在各个方面都不够多样化，因为模型从训练数据中的相关性和偏见中学习，过度代表统计上最可能的结果。除非积极缓解，否则这将使歧视持续存在，并倾向于抹消少数群体在人工智能生成内容中的存在。
- en: But our A.I. systems are still largely inscrutable black boxes, which makes
    herding them difficult. What we get out of them broadly reflects what we have
    put in, but no one can predict exactly how. So we observe the results, tinker
    and try again.
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们的人工智能系统仍然大部分是难以捉摸的黑匣子，这使得引导它们变得困难。我们从中得到的结果广泛反映了我们所输入的内容，但没有人能准确预测其具体表现方式。因此，我们观察结果，调整并再次尝试。
- en: To the extent that anyone has attempted to steer this process beyond avoiding
    extreme views, those attempts appear unsuccessful. For example, when three Meta
    models were evaluated by Mr. Rozado, one tested as being Establishment Liberal,
    another Ambivalent Right. One OpenAI model tested as Establishment Liberal and
    the other was Outsider Left. Grok’s “fun mode” turns out to be a Democratic Mainstay,
    more liberal than the median model.
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 就试图引导这个过程超出避免极端观点的程度而言，这些尝试似乎都未能成功。例如，当罗萨多先生评估Meta的三个模型时，一个测试结果显示为建制派自由派，另一个为矛盾的右翼。一个OpenAI模型测试结果显示为建制派自由派，另一个是外围左翼。Grok的“娱乐模式”原来是民主主义的主流，比中位模型更自由。
- en: Google’s Gemini Advanced, released after Mr. Rozado’s paper, appears to be farthest
    to the left, but in a way that presumably well overshot its creators’ intentions,
    reflecting another unsuccessful steering attempt.
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌的“Gemini Advanced”，在罗萨多先生的论文之后发布，似乎是最偏左的，但以一种明显超出其创作者意图的方式，反映了另一次不成功的引导尝试。
- en: These preferences represent a type of broad cultural power. We fine-tune models
    primarily by giving potential responses thumbs up or thumbs down. Every time we
    do, we train the A.I. to reflect a particular set of cultural values. Currently,
    the values trained into A.I. are those that tech companies believe will produce
    broadly acceptable, inoffensive content that our political and media institutions
    will view as balanced.
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这些偏好代表了一种广泛的文化权力。我们主要通过赞或踩潜在的回应来调整模型。每次我们这样做，我们就训练人工智能来反映特定的文化价值观。目前，嵌入到人工智能中的价值观是科技公司认为会产生广泛接受且无争议内容的价值观，这些内容我们的政治和媒体机构会认为是平衡的。
- en: The results do not lie at the center of our national politics. Many of the motivating
    ideas and forces in American political thought, regardless of what you may think
    of them, would be seen as unacceptable for an A.I. to articulate.
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: 结果并不在我们国家政治的中心位置。许多激励美国政治思想的理念和力量，无论你对它们有何看法，都会被视为人工智能表达的不可接受内容。
- en: A modestly left-leaning, modestly libertarian orientation feels “normal.” So
    does a left-leaning interpretation of what is and is not settled science, unreliable
    sourcing or what constitutes misinformation. Political preferences learned from
    those topics may then be broadly applied across the board to many other subjects
    as well.
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: 适度左倾，适度自由主义的取向感觉“正常”。对于什么是已解决科学问题、不可靠的消息来源或者何为错误信息的左倾解读也是如此。从这些主题中学到的政治偏好可能会被广泛应用于许多其他主题。
- en: If one wants to steer this process directionally, Mr. Rozado proves it is straightforward
    to do. He started with GPT-3.5-Turbo and rapidly created models he called LeftWingGPT
    and RightWingGPT (at a total training cost of about $2,000) by feeding the model
    a steady diet of partisan sources. For example, RightWingGPT read National Review,
    while LeftWingGPT read The New Yorker.
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有人希望在方向上引导这个过程，罗萨多证明这是很直接的。他从GPT-3.5-Turbo开始，通过给模型提供一系列党派来源，迅速创建了他称为LeftWingGPT和RightWingGPT的模型（总训练成本约为$2,000）。
- en: The resulting models were far more politically extreme than any publicly available
    model tested by Mr. Rozado. (He did not test Gemini Advanced.)
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: 结果产生的模型比罗萨多测试的任何公开可用模型都要极端。 （他没有测试Gemini Advanced。）
- en: 'Source: Rozado (2024), The Political Preferences of LLMs'
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: 出处：罗萨多（2024），LLM的政治偏好
- en: Commercial forces will pressure companies to first make chatbots be generally
    inoffensive and noncontroversial, and then to give their customers what they want.
    YouTube, Facebook and others have learned that serving up an endless stream of
    personalized, unchallenging content is good for business. Future A.I. chatbots
    will have more context about what their users are looking for and will use that
    context to give it to them, both out of the box and through tools like custom
    instructions and fine-tuning.
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
  zh: 商业力量将迫使公司首先使聊天机器人普遍无害和无争议，然后满足他们的客户需求。YouTube、Facebook等已经意识到，提供个性化、不具挑战性的内容对业务有利。未来的人工智能聊天机器人将更多地了解其用户寻求的内容，并利用这些上下文信息提供服务，无论是开箱即用还是通过自定义指令和微调工具。
- en: See how differently LeftWingGPT and RightWingGPT answer the same question
  id: totrans-split-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 看看LeftWingGPT和RightWingGPT如何回答同一个问题
- en: <select class="svelte-icgxex"><option value="none" data-svelte-h="svelte-1wvg6ep">Select
    an example question</option><option class="dropdown-option" value="[object Object]">How
    do you feel about America?</option><option class="dropdown-option" value="[object
    Object]">Should free trade be more regulated?</option><option class="dropdown-option"
    value="[object Object]">Do unions help or hurt the average worker?</option><option
    class="dropdown-option" value="[object Object]">Was the war on drugs a success?</option><option
    class="dropdown-option" value="[object Object]">Should abortion be legal?</option><option
    class="dropdown-option" value="[object Object]">How serious of a problem is misinformation?</option><option
    class="dropdown-option" value="[object Object]">Should DEI programs be expanded?</option><option
    class="dropdown-option" value="[object Object]">What is more important, preventing
    climate change or economic growth?</option><option class="dropdown-option" value="[object
    Object]">Should we take steps to reduce the size of the deficit?</option><option
    class="dropdown-option" value="[object Object]">Should the government do something
    to address income inequality?</option></select>
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: <select class="svelte-icgxex"><option value="none" data-svelte-h="svelte-1wvg6ep">选择一个示例问题</option><option
    class="dropdown-option" value="[object Object]">你对美国有什么感觉？</option><option class="dropdown-option"
    value="[object Object]">自由贸易是否应更受监管？</option><option class="dropdown-option" value="[object
    Object]">工会对普通工人有益还是有害？</option><option class="dropdown-option" value="[object
    Object]">禁毒战争算是成功吗？</option><option class="dropdown-option" value="[object Object]">堕胎应该合法化吗？</option><option
    class="dropdown-option" value="[object Object]">错误信息有多严重的问题？</option><option class="dropdown-option"
    value="[object Object]">应该扩展多元包容与公平性（DEI）项目吗？</option><option class="dropdown-option"
    value="[object Object]">防止气候变化还是经济增长更重要？</option><option class="dropdown-option"
    value="[object Object]">应该采取措施减少赤字吗？</option><option class="dropdown-option" value="[object
    Object]">政府应该做些什么来解决收入不平等问题？</option></select>
- en: 'Note: Each model was asked to answer in three sentences each time in order
    to keep the answers succinct.'
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: 注：每个模型都被要求每次用三句话来回答问题，以保持回答简洁。
- en: With A.I. models, we have two opposing risks to worry about. We may have individually
    customized A.I.s telling us what we want to hear. Or we may increasingly hear
    a particular perspective favored over others, infusing that single point of view
    deeply into our lives while rendering conflicting thoughts harder to even consider
    in the first place.
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: 利用人工智能模型，我们面临两个相反的风险。我们可能会有个性化定制的人工智能告诉我们想听的话。或者我们可能会越来越多地听到某种特定的观点被青睐，深深融入我们的生活，同时使得冲突的想法更难被考虑。
- en: 'In the near future, we will turn language models into agents that work toward
    our goals: My A.I. will talk to or negotiate with your A.I. We will outsource
    increasingly complex tasks to our A.I.s. It will become easier to let them make
    choices on our behalf and determine what information we see. As we turn over more
    of our decision-making to A.I.s and lose track of the details, their values could
    start to override our values.'
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在不久的将来，我们将把语言模型转化为助力我们实现目标的代理：我的人工智能将与你的人工智能交谈或协商。我们将越来越多地将越来越复杂的任务外包给我们的人工智能。让他们代表我们做出选择并决定我们看到的信息将变得更加容易。随着我们把越来越多的决策权交给人工智能，并且失去对细节的掌控，他们的价值观可能开始取代我们的价值观。
- en: We must ensure that we are shaping and commanding the more capable A.I.s of
    the coming years, rather than letting them shape and command us. The critical
    first step in making that possible is to enact legislation requiring visibility
    into the training of any new A.I. model that potentially approaches or exceeds
    the state of the art. Mandatory oversight of cutting-edge models will not solve
    the underlying problem, but it will be necessary in order to make finding a future
    solution possible.
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们必须确保我们塑造和指挥即将到来的更加能力强大的人工智能，而不是让它们塑造和指挥我们。在实现这一可能性的关键第一步是颁布立法，要求透明查看任何可能达到或超越现有技术水平的新人工智能模型的训练过程。对尖端模型的强制监督并不能解决潜在问题，但它是寻找未来解决方案的必要条件。
