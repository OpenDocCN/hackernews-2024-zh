- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-29 12:44:53'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-29 12:44:53'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Large language models use a surprisingly simple mechanism to retrieve some stored
    knowledge | MIT News | Massachusetts Institute of Technology
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大型语言模型使用了一个令人惊讶地简单的机制来检索一些存储的知识 | MIT News | 麻省理工学院
- en: 来源：[https://news.mit.edu/2024/large-language-models-use-surprisingly-simple-mechanism-retrieve-stored-knowledge-0325](https://news.mit.edu/2024/large-language-models-use-surprisingly-simple-mechanism-retrieve-stored-knowledge-0325)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://news.mit.edu/2024/large-language-models-use-surprisingly-simple-mechanism-retrieve-stored-knowledge-0325](https://news.mit.edu/2024/large-language-models-use-surprisingly-simple-mechanism-retrieve-stored-knowledge-0325)
- en: Large language models, such as those that power popular artificial intelligence
    chatbots like ChatGPT, are incredibly complex. Even though these models are being
    used as tools in many areas, such as customer support, code generation, and language
    translation, scientists still don’t fully grasp how they work.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型，如驱动流行的人工智能聊天机器人（如ChatGPT）的模型，非常复杂。尽管这些模型被用作许多领域的工具，如客户支持、代码生成和语言翻译，但科学家仍未完全理解它们的工作原理。
- en: In an effort to better understand what is going on under the hood, researchers
    at MIT and elsewhere studied the mechanisms at work when these enormous machine-learning
    models retrieve stored knowledge.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解这些庞大的机器学习模型检索存储知识时的工作机制，MIT和其他地方的研究人员进行了研究。
- en: 'They found a surprising result: Large language models (LLMs) often use a very
    simple linear function to recover and decode stored facts. Moreover, the model
    uses the same decoding function for similar types of facts. Linear functions,
    equations with only two variables and no exponents, capture the straightforward,
    straight-line relationship between two variables.'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 他们发现了一个令人惊讶的结果：大型语言模型（LLMs）通常使用非常简单的线性函数来恢复和解码存储的事实。此外，该模型对于类似类型的事实使用相同的解码函数。线性函数，即只有两个变量且没有指数的方程式，捕捉了两个变量之间直接、直线关系。
- en: The researchers showed that, by identifying linear functions for different facts,
    they can probe the model to see what it knows about new subjects, and where within
    the model that knowledge is stored.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员表明，通过识别不同事实的线性函数，他们可以探索模型看它对新主题的了解情况，并确定模型内知识的存储位置。
- en: Using a technique they developed to estimate these simple functions, the researchers
    found that even when a model answers a prompt incorrectly, it has often stored
    the correct information. In the future, scientists could use such an approach
    to find and correct falsehoods inside the model, which could reduce a model’s
    tendency to sometimes give incorrect or nonsensical answers.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 使用他们开发的技术来估计这些简单函数，研究人员发现，即使模型错误地回答提示，它通常已经存储了正确的信息。将来，科学家可以使用这种方法来查找和纠正模型内的虚假信息，这可以减少模型偶尔给出错误或荒谬答案的倾向。
- en: “Even though these models are really complicated, nonlinear functions that are
    trained on lots of data and are very hard to understand, there are sometimes really
    simple mechanisms working inside them. This is one instance of that,” says Evan
    Hernandez, an electrical engineering and computer science (EECS) graduate student
    and co-lead author of a [paper detailing these findings](https://arxiv.org/pdf/2308.09124.pdf).
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: “尽管这些模型非常复杂，是训练在大量数据上的非线性函数，并且非常难以理解，但有时候它们内部确实存在非常简单的机制。这就是其中一个实例，” 电气工程和计算机科学（EECS）研究生，以及详细阐述这些发现的论文的共同第一作者Evan
    Hernandez说。
- en: Hernandez wrote the paper with co-lead author Arnab Sharma, a computer science
    graduate student at Northeastern University; his advisor, Jacob Andreas, an associate
    professor in EECS and a member of the Computer Science and Artificial Intelligence
    Laboratory (CSAIL); senior author David Bau, an assistant professor of computer
    science at Northeastern; and others at MIT, Harvard University, and the Israeli
    Institute of Technology. The research will be presented at the International Conference
    on Learning Representations.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: Hernandez与共同第一作者Arnab Sharma合作撰写了这篇论文，Arnab Sharma是东北大学的计算机科学研究生；他的导师Jacob Andreas是EECS的副教授，也是计算机科学与人工智能实验室（CSAIL）的成员；资深作者David
    Bau是东北大学的计算机科学助理教授，还有其他来自MIT、哈佛大学和以色列理工学院的研究人员。这项研究将在国际学习表征会议上进行展示。
- en: '**Finding facts**'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: '**查找事实**'
- en: Most large language models, also called transformer models, are [neural networks](https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414).
    Loosely based on the human brain, neural networks contain billions of interconnected
    nodes, or neurons, that are grouped into many layers, and which encode and process
    data.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数大型语言模型，也称为变压器模型，是[神经网络](https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414)。神经网络基于人脑，包含数十亿个互连的节点或神经元，分组成许多层，用于编码和处理数据。
- en: Much of the knowledge stored in a transformer can be represented as relations
    that connect subjects and objects. For instance, “Miles Davis plays the trumpet”
    is a relation that connects the subject, Miles Davis, to the object, trumpet.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 变压器中存储的大部分知识可以表示为连接主题和对象的关系。例如，“迈尔斯·戴维斯演奏小号”是一个连接主题迈尔斯·戴维斯和对象小号的关系。
- en: As a transformer gains more knowledge, it stores additional facts about a certain
    subject across multiple layers. If a user asks about that subject, the model must
    decode the most relevant fact to respond to the query.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当变压器获取更多知识时，它会在多个层次上存储关于某个主题的附加事实。如果用户询问有关该主题的信息，模型必须解码最相关的事实以回应查询。
- en: If someone prompts a transformer by saying “Miles Davis plays the. . .” the
    model should respond with “trumpet” and not “Illinois” (the state where Miles
    Davis was born).
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有人通过说“迈尔斯·戴维斯演奏的是…”来提示变压器，模型应该回答“小号”，而不是“伊利诺伊州”（迈尔斯·戴维斯的出生地）。
- en: “Somewhere in the network’s computation, there has to be a mechanism that goes
    and looks for the fact that Miles Davis plays the trumpet, and then pulls that
    information out and helps generate the next word. We wanted to understand what
    that mechanism was,” Hernandez says.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: “在网络的计算中，必须有一个机制去查找迈尔斯·戴维斯演奏小号的事实，并从中提取这些信息来帮助生成下一个词。我们想要理解那个机制是什么，”赫尔南德斯说道。
- en: The researchers set up a series of experiments to probe LLMs, and found that,
    even though they are extremely complex, the models decode relational information
    using a simple linear function. Each function is specific to the type of fact
    being retrieved.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员设置了一系列实验来探索LLMs，并发现，尽管它们非常复杂，但模型使用简单的线性函数解码关系信息。每个函数都特定于正在检索的事实类型。
- en: For example, the transformer would use one decoding function any time it wants
    to output the instrument a person plays and a different function each time it
    wants to output the state where a person was born.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，变压器在想要输出一个人所演奏的乐器时会使用一种解码函数，而在想要输出一个人出生的州时会使用另一种函数。
- en: The researchers developed a method to estimate these simple functions, and then
    computed functions for 47 different relations, such as “capital city of a country”
    and “lead singer of a band.”
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员开发了一种估计这些简单函数的方法，然后为47种不同的关系计算了函数，例如“一个国家的首都”和“一个乐队的主唱”。
- en: While there could be an infinite number of possible relations, the researchers
    chose to study this specific subset because they are representative of the kinds
    of facts that can be written in this way.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可能存在无限数量的可能关系，但研究人员选择研究这个特定的子集，因为它们代表了可以用这种方式写入的事实类型。
- en: They tested each function by changing the subject to see if it could recover
    the correct object information. For instance, the function for “capital city of
    a country” should retrieve Oslo if the subject is Norway and London if the subject
    is England.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 他们通过改变主题来测试每个函数，以查看它是否能恢复正确的对象信息。例如，“一个国家的首都”的函数应该在主题是挪威时检索奥斯陆，而在主题是英格兰时检索伦敦。
- en: Functions retrieved the correct information more than 60 percent of the time,
    showing that some information in a transformer is encoded and retrieved in this
    way.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: 函数超过60%的时间检索到正确的信息，表明变压器中的一些信息是以这种方式编码和检索的。
- en: “But not everything is linearly encoded. For some facts, even though the model
    knows them and will predict text that is consistent with these facts, we can’t
    find linear functions for them. This suggests that the model is doing something
    more intricate to store that information,” he says.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: “但并不是所有事实都是线性编码的。对于一些事实，尽管模型知道它们并将预测与这些事实一致的文本，我们却无法找到线性函数。这表明模型在存储这些信息时正在进行更复杂的操作，”他说道。
- en: '**Visualizing a model’s knowledge**'
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**可视化模型的知识**'
- en: They also used the functions to determine what a model believes is true about
    different subjects.
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 他们还使用这些函数来确定模型对不同主题的信仰。
- en: In one experiment, they started with the prompt “Bill Bradley was a” and used
    the decoding functions for “plays sports” and “attended university” to see if
    the model knows that Sen. Bradley was a basketball player who attended Princeton.
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个实验中，他们以提示“比尔·布拉德利是”开始，并使用“从事运动”和“上大学”的解码功能，以查看模型是否知道参议员布拉德利是一个参加了普林斯顿大学的篮球运动员。
- en: “We can show that, even though the model may choose to focus on different information
    when it produces text, it does encode all that information,” Hernandez says.
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: “我们可以展示，即使模型在生成文本时可能选择关注不同的信息，它确实对所有信息进行了编码，” 赫尔南德斯说。
- en: They used this probing technique to produce what they call an “attribute lens,”
    a grid that visualizes where specific information about a particular relation
    is stored within the transformer’s many layers.
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: 他们利用这种探索技术制作了所谓的“属性镜头”，这是一种网格，可以显示变压器的许多层中存储有关特定关系的具体信息的位置。
- en: Attribute lenses can be generated automatically, providing a streamlined method
    to help researchers understand more about a model. This visualization tool could
    enable scientists and engineers to correct stored knowledge and help prevent an
    AI chatbot from giving false information.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 可以自动生成属性镜头，提供一种简化的方法，帮助研究人员更好地理解模型。这种可视化工具可以使科学家和工程师更正存储的知识，并帮助防止AI聊天机器人提供错误信息。
- en: In the future, Hernandez and his collaborators want to better understand what
    happens in cases where facts are not stored linearly. They would also like to
    run experiments with larger models, as well as study the precision of linear decoding
    functions.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来，赫尔南德斯和他的合作者们希望更好地理解在事实不是线性存储的情况下会发生什么。他们还希望运行更大的模型实验，并研究线性解码函数的精度。
- en: “This is an exciting work that reveals a missing piece in our understanding
    of how large language models recall factual knowledge during inference. Previous
    work showed that LLMs build information-rich representations of given subjects,
    from which specific attributes are being extracted during inference. This work
    shows that the complex nonlinear computation of LLMs for attribute extraction
    can be well-approximated with a simple linear function,” says Mor Geva Pipek,
    an assistant professor in the School of Computer Science at Tel Aviv University,
    who was not involved with this work.
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: “这是一项令人兴奋的工作，揭示了我们在推理过程中大语言模型如何回忆事实知识中的一个缺失部分。先前的研究表明，大语言模型在给定主题中构建了信息丰富的表示，推理过程中从中提取了特定属性。这项工作表明，大语言模型复杂的非线性计算用于属性提取可以很好地近似为简单的线性函数，”
    未参与此项工作的特拉维夫大学计算机科学学院助理教授 Mor Geva Pipek 说。
- en: This research was supported, in part, by Open Philanthropy, the Israeli Science
    Foundation, and an Azrieli Foundation Early Career Faculty Fellowship.
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这项研究在一定程度上得到了开放慈善、以色列科学基金会和阿兹里埃利基金会早期职业教职员工奖助金的支持。
