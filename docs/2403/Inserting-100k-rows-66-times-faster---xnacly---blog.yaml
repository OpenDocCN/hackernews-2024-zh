- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-29 12:31:43'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Inserting 100k rows 66 times faster | xnacly - blog
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://xnacly.me/posts/2024/faster-inserts/](https://xnacly.me/posts/2024/faster-inserts/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In the process of implementing the initial data syncing logic for a mostly offline
    application I noticed my database abstraction taking a solid 2 minutes for inserting
    short of 750k rows into a single database table.
  prefs: []
  type: TYPE_NORMAL
- en: I set out to fix this bottleneck.
  prefs: []
  type: TYPE_NORMAL
- en: Problems and Issues [##](#problems-and-issues)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A new issue arose before i could even tackle the aforementioned performance
    problems: At first I used the spread syntax for a variadic amount of function
    parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This polluted the call stack and promptly caused a stack overflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Believe me this seems obvious in retrospect, but it took me a solid day of combing
    trough typescript source maps to find the cause.
  prefs: []
  type: TYPE_NORMAL
- en: Takeaway
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: I will never use the spread operator again - looking at you react.js
  prefs: []
  type: TYPE_NORMAL
- en: First Estimates and Benchmarking [##](#first-estimates-and-benchmarking)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Fixing this issue allowed me to call my `create` function and pass the rows
    to insert in. The first tests were nothing short of disappointing: 57 seconds
    for inserting 500k rows, 1min 10 seconds for inserting 750k rows - this was too
    slow.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'My next idea was to get specific and reproducible numbers, thus i created a
    benchmark, for the simplified `create` implementation above, with differing loads,
    starting with 10 rows and stopping at a million rows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Measured times:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | `create` |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 10 rows | 2ms |'
  prefs: []
  type: TYPE_TB
- en: '| 100 rows | 1ms |'
  prefs: []
  type: TYPE_TB
- en: '| 1,000 rows | 13ms |'
  prefs: []
  type: TYPE_TB
- en: '| 10,000 rows | 100ms |'
  prefs: []
  type: TYPE_TB
- en: '| 100,000 rows | 1089ms |'
  prefs: []
  type: TYPE_TB
- en: '| 1,000,000 rows | 11795ms |'
  prefs: []
  type: TYPE_TB
- en: Approaches [##](#approaches)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: My first idea was to omit calls in the hot paths that obviously are contained
    in the create methods loop for inserting every row passed into it. After taking
    a look, i notice there are no heavy or even many operations here. How could I
    improve the database interaction itself? This was the moment I stumbled upon bulk
    inserts.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The naive example implementation makes a database call for every row it wants
    to insert. Bulk inserting reduces this to a single call to the database layer
    by appending more value tuples to the above statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Using the above to implement a faster `create` method as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Extending our tests for `createFast`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '|  | `create` | `createFast` | Improvement |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 10 rows | 2ms | 1ms | 2x |'
  prefs: []
  type: TYPE_TB
- en: '| 100 rows | 1ms | 1ms | / |'
  prefs: []
  type: TYPE_TB
- en: '| 1,000 rows | 13ms | 3ms | 4.3x |'
  prefs: []
  type: TYPE_TB
- en: '| 10,000 rows | 100ms | 22ms | 4.5x |'
  prefs: []
  type: TYPE_TB
- en: '| 100,000 rows | 1089ms | 215ms | 5.1x |'
  prefs: []
  type: TYPE_TB
- en: '| 1,000,000 rows | 11795ms | 1997ms | 5.9x |'
  prefs: []
  type: TYPE_TB
- en: Info
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The before benchmarks were done on the following system:'
  prefs: []
  type: TYPE_NORMAL
- en: 'CPU: Intel(R) Core(TM) i5-6200U CPU @ 2.30GHz 4 cores'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RAM: 8,0 GB DDR3 1600 MHz'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The system was under heavy load while benchmarking, thus the recorded times
    are still pretty slow.
  prefs: []
  type: TYPE_NORMAL
- en: Escaping from micro benchmarks into the real world [##](#escaping-from-micro-benchmarks-into-the-real-world)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Applying the results from the micro benchmarks to my real world projects database
    layer resulted in significant runtime improvements, up to 66x faster.
  prefs: []
  type: TYPE_NORMAL
- en: '|  | `create` | `createFast` | Improvement |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 10 rows | 7ms | 2ms | 3.5x |'
  prefs: []
  type: TYPE_TB
- en: '| 100 rows | 48ms | 1ms | 48x |'
  prefs: []
  type: TYPE_TB
- en: '| 1000 rows | 335ms | 9ms | 37.2x |'
  prefs: []
  type: TYPE_TB
- en: '| 10000 rows | 2681ms | 80ms | 33.5x |'
  prefs: []
  type: TYPE_TB
- en: '| 100000 rows | 25347ms | 390ms | 66x |'
  prefs: []
  type: TYPE_TB
