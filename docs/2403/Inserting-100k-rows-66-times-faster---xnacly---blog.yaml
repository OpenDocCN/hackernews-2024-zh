- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-05-29 12:31:43'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-29 12:31:43
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Inserting 100k rows 66 times faster | xnacly - blog
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 插入100k行速度提升66倍 | xnacly - 博客
- en: 来源：[https://xnacly.me/posts/2024/faster-inserts/](https://xnacly.me/posts/2024/faster-inserts/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://xnacly.me/posts/2024/faster-inserts/](https://xnacly.me/posts/2024/faster-inserts/)
- en: In the process of implementing the initial data syncing logic for a mostly offline
    application I noticed my database abstraction taking a solid 2 minutes for inserting
    short of 750k rows into a single database table.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现大部分离线应用的初始数据同步逻辑过程中，我注意到我的数据库抽象化在将近75万行插入单个数据库表时需要花费长达2分钟的时间。
- en: I set out to fix this bottleneck.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我开始解决这个瓶颈。
- en: Problems and Issues [##](#problems-and-issues)
  id: totrans-split-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 问题和挑战 [##](#problems-and-issues)
- en: 'A new issue arose before i could even tackle the aforementioned performance
    problems: At first I used the spread syntax for a variadic amount of function
    parameters.'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在我甚至能够解决上述性能问题之前，出现了一个新问题：起初，我使用了散布语法来变化函数参数的可变数量。
- en: '[PRE0]'
  id: totrans-split-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This polluted the call stack and promptly caused a stack overflow:'
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这污染了调用堆栈，并迅速导致堆栈溢出：
- en: '[PRE1]'
  id: totrans-split-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Believe me this seems obvious in retrospect, but it took me a solid day of combing
    trough typescript source maps to find the cause.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 相信我，这在回顾中似乎很明显，但我花了一整天的时间来梳理TypeScript源映射以找到原因。
- en: Takeaway
  id: totrans-split-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结论
- en: I will never use the spread operator again - looking at you react.js
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我永远不会再使用散布操作符了 - 瞧你，React.js
- en: First Estimates and Benchmarking [##](#first-estimates-and-benchmarking)
  id: totrans-split-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 首次估计和基准测试 [##](#first-estimates-and-benchmarking)
- en: 'Fixing this issue allowed me to call my `create` function and pass the rows
    to insert in. The first tests were nothing short of disappointing: 57 seconds
    for inserting 500k rows, 1min 10 seconds for inserting 750k rows - this was too
    slow.'
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 解决这个问题使我能够调用我的 `create` 函数，并将要插入的行传递给它。最初的测试结果令人失望：插入50万行需要57秒，插入75万行需要1分10秒
    - 这太慢了。
- en: '[PRE2]'
  id: totrans-split-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'My next idea was to get specific and reproducible numbers, thus i created a
    benchmark, for the simplified `create` implementation above, with differing loads,
    starting with 10 rows and stopping at a million rows:'
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我的下一个想法是获取具体和可重复的数字，因此我创建了一个基准测试，用于上述简化的 `create` 实现，负载不同，从10行开始到一百万行结束：
- en: '[PRE3]'
  id: totrans-split-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Measured times:'
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 测量时间：
- en: '|  | `create` |'
  id: totrans-split-22
  prefs: []
  type: TYPE_TB
  zh: '|  | `create` |'
- en: '| --- | --- |'
  id: totrans-split-23
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 10 rows | 2ms |'
  id: totrans-split-24
  prefs: []
  type: TYPE_TB
  zh: '| 10 行 | 2ms |'
- en: '| 100 rows | 1ms |'
  id: totrans-split-25
  prefs: []
  type: TYPE_TB
  zh: '| 100 行 | 1ms |'
- en: '| 1,000 rows | 13ms |'
  id: totrans-split-26
  prefs: []
  type: TYPE_TB
  zh: '| 1,000 行 | 13ms |'
- en: '| 10,000 rows | 100ms |'
  id: totrans-split-27
  prefs: []
  type: TYPE_TB
  zh: '| 10,000 行 | 100ms |'
- en: '| 100,000 rows | 1089ms |'
  id: totrans-split-28
  prefs: []
  type: TYPE_TB
  zh: '| 100,000 行 | 1089ms |'
- en: '| 1,000,000 rows | 11795ms |'
  id: totrans-split-29
  prefs: []
  type: TYPE_TB
  zh: '| 1,000,000 行 | 11795ms |'
- en: Approaches [##](#approaches)
  id: totrans-split-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方法 [##](#approaches)
- en: My first idea was to omit calls in the hot paths that obviously are contained
    in the create methods loop for inserting every row passed into it. After taking
    a look, i notice there are no heavy or even many operations here. How could I
    improve the database interaction itself? This was the moment I stumbled upon bulk
    inserts.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我的第一个想法是在明显包含在创建方法循环中的热路径中省略调用。仔细一看，我注意到这里没有重的或者很多操作。我该如何改进数据库交互本身？这是我偶然发现批量插入的时刻。
- en: '[PRE4]'
  id: totrans-split-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The naive example implementation makes a database call for every row it wants
    to insert. Bulk inserting reduces this to a single call to the database layer
    by appending more value tuples to the above statement:'
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: 天真的示例实现为每行插入都进行一次数据库调用。通过将更多值元组附加到上述语句，批量插入可将其减少为对数据库层的单一调用：
- en: '[PRE5]'
  id: totrans-split-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Using the above to implement a faster `create` method as follows:'
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用上述内容实现更快的 `create` 方法如下：
- en: '[PRE6]'
  id: totrans-split-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Extending our tests for `createFast`:'
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展我们对 `createFast` 的测试：
- en: '[PRE7]'
  id: totrans-split-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '|  | `create` | `createFast` | Improvement |'
  id: totrans-split-39
  prefs: []
  type: TYPE_TB
  zh: '|  | `create` | `createFast` | 改进 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-split-40
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 10 rows | 2ms | 1ms | 2x |'
  id: totrans-split-41
  prefs: []
  type: TYPE_TB
  zh: '| 10 行 | 2ms | 1ms | 2x |'
- en: '| 100 rows | 1ms | 1ms | / |'
  id: totrans-split-42
  prefs: []
  type: TYPE_TB
  zh: '| 100 行 | 1ms | 1ms | / |'
- en: '| 1,000 rows | 13ms | 3ms | 4.3x |'
  id: totrans-split-43
  prefs: []
  type: TYPE_TB
  zh: '| 1,000 行 | 13ms | 3ms | 4.3x |'
- en: '| 10,000 rows | 100ms | 22ms | 4.5x |'
  id: totrans-split-44
  prefs: []
  type: TYPE_TB
  zh: '| 10,000 行 | 100ms | 22ms | 4.5x |'
- en: '| 100,000 rows | 1089ms | 215ms | 5.1x |'
  id: totrans-split-45
  prefs: []
  type: TYPE_TB
  zh: '| 100,000 行 | 1089ms | 215ms | 5.1x |'
- en: '| 1,000,000 rows | 11795ms | 1997ms | 5.9x |'
  id: totrans-split-46
  prefs: []
  type: TYPE_TB
  zh: '| 1,000,000 行 | 11795ms | 1997ms | 5.9x |'
- en: Info
  id: totrans-split-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 信息
- en: 'The before benchmarks were done on the following system:'
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的基准测试是在以下系统上完成的：
- en: 'CPU: Intel(R) Core(TM) i5-6200U CPU @ 2.30GHz 4 cores'
  id: totrans-split-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU：Intel(R) Core(TM) i5-6200U CPU @ 2.30GHz 4 cores
- en: 'RAM: 8,0 GB DDR3 1600 MHz'
  id: totrans-split-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAM：8.0 GB DDR3 1600 MHz
- en: The system was under heavy load while benchmarking, thus the recorded times
    are still pretty slow.
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在基准测试时系统负载较重，因此记录的时间仍然相当慢。
- en: Escaping from micro benchmarks into the real world [##](#escaping-from-micro-benchmarks-into-the-real-world)
  id: totrans-split-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从微基准测试中走出来 [##](#escaping-from-micro-benchmarks-into-the-real-world)
- en: Applying the results from the micro benchmarks to my real world projects database
    layer resulted in significant runtime improvements, up to 66x faster.
  id: totrans-split-53
  prefs: []
  type: TYPE_NORMAL
  zh: 将微基准测试结果应用到我的真实项目数据库层，导致显著的运行时改进，最高提速达到66倍。
- en: '|  | `create` | `createFast` | Improvement |'
  id: totrans-split-54
  prefs: []
  type: TYPE_TB
  zh: '|  | `create` | `createFast` | 改进 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-split-55
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 10 rows | 7ms | 2ms | 3.5x |'
  id: totrans-split-56
  prefs: []
  type: TYPE_TB
  zh: '| 10 行 | 7ms | 2ms | 3.5倍 |'
- en: '| 100 rows | 48ms | 1ms | 48x |'
  id: totrans-split-57
  prefs: []
  type: TYPE_TB
  zh: '| 100 行 | 48ms | 1ms | 48倍 |'
- en: '| 1000 rows | 335ms | 9ms | 37.2x |'
  id: totrans-split-58
  prefs: []
  type: TYPE_TB
  zh: '| 1000 行 | 335ms | 9ms | 37.2倍 |'
- en: '| 10000 rows | 2681ms | 80ms | 33.5x |'
  id: totrans-split-59
  prefs: []
  type: TYPE_TB
  zh: '| 10000 行 | 2681ms | 80ms | 33.5倍 |'
- en: '| 100000 rows | 25347ms | 390ms | 66x |'
  id: totrans-split-60
  prefs: []
  type: TYPE_TB
  zh: '| 100000 行 | 25347ms | 390ms | 66倍 |'
