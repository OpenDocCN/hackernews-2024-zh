- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 14:36:42'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 14:36:42'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Motion Blur All the Way Down
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Motion Blur All the Way Down
- en: 来源：[https://www.osar.fr/notes/motionblur/](https://www.osar.fr/notes/motionblur/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.osar.fr/notes/motionblur/](https://www.osar.fr/notes/motionblur/)
- en: Motion Blur All the Way Down
  id: totrans-split-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Motion Blur All the Way Down
- en: Pierre Cusa <pierre@osar.fr>
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: Pierre Cusa <pierre@osar.fr>
- en: November 2022
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 2022年11月
- en: '[(history)](https://github.com/pac-dev/notes/commits/master/content/motionblur.md)'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[(历史)](https://github.com/pac-dev/notes/commits/master/content/motionblur.md)'
- en: '"Torusphere Accelerator", the animation that motivated this article.'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: '"环球空间加速器"，启发了本文的动画。'
- en: What happens if you take motion blur past its logical extreme? Here are some
    fun observations and ideas I encountered while trying to answer this question,
    with an attempt to apply the results in a procedural animation.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你把运动模糊推向它的逻辑极限会发生什么？以下是在试图回答这个问题时遇到的一些有趣的观察和想法，试图在程序化动画中应用结果。
- en: What is motion blur supposed to look like?
  id: totrans-split-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运动模糊应该是什么样子？
- en: Motion blur started out purely as a film artifact, the result of a subject moving
    while the camera's shutter is open. This artifact turned out to be desirable,
    especially for videos, because it improves the perceptual similarity between a
    video and a natural scene, something I'll dive into in this section.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 运动模糊最初纯粹是一种电影的产物，是在主体移动时摄像机快门打开的结果。这种产物被认为是可取的，特别是对于视频，因为它提高了视频和自然场景之间的感知相似性，我将在本节中深入探讨。
- en: 'In a 3D and animation context, it''s interesting to note that those two goals
    - looking natural, and simulating a camera, might not be in agreement, and might
    result in different motion blurs. I''ll keep the simulation aspect as a side note,
    and ask what the most natural possible motion blur should look like. This can
    be broken down into a few questions:'
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在3D和动画的背景下，有趣的是注意到这两个目标 - 看起来自然，以及模拟相机，可能并不一致，并可能导致不同的运动模糊效果。我将把模拟方面作为一个侧面说明，并探讨最自然的运动模糊应该是什么样子。这可以细分为几个问题：
- en: How do we perceive a natural moving scene?
  id: totrans-split-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自然移动场景是如何被我们感知的？
- en: How do we perceive this scene reproduced in a video?
  id: totrans-split-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何感知视频中再现的这一场景？
- en: What is the perceptual difference between those two cases?
  id: totrans-split-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这两种情况之间的感知差异是什么？
- en: How can video motion blur minimize this difference?
  id: totrans-split-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 视频运动模糊如何最小化这种差异？
- en: Perception of motion in a natural scene
  id: totrans-split-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在自然场景中感知运动
- en: For the purpose of crafting motion blur, we can start by analyzing the very
    first steps of human vision, where the light hits our retina and [phototransduction](https://en.wikipedia.org/wiki/Visual_phototransduction)
    takes place. Under well-lit conditions, this is handled by cone-type cells. Phototransduction
    is not immediate, and we can model this lag by smoothing out the light stimulus
    over time.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 为了制作运动模糊，我们可以从人类视觉的最初几步开始分析，即光线照射到我们的视网膜上，以及[光转导](https://en.wikipedia.org/wiki/Visual_phototransduction)的过程。在光照充足的条件下，这由锥细胞处理。光转导并不是即时的，我们可以通过随时间平滑光刺激来模拟这种滞后。
- en: '**1\. Example of temporal integration in goldfish cones**'
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**1\. 金鱼锥体中的时间积分示例**'
- en: ', taken directly from'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: ，直接引用自
- en: '[Howlett et al. (2017)](https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2001210)'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[Howlett et al. (2017)](https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2001210)'
- en: . Raw stimulus is the number of photons entering the photoreceptor, in this
    case, a realistic example. The weighting function is derived from the cone's response
    in different conditions, and can be used to simulate the cone's average temporal
    integration. The resulting "effective stimulus", while not a measurable response,
    is a successful first step in modeling the cone's actual photocurrent response.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: . 原始刺激是进入光感受器的光子数量，在这种情况下是一个现实的例子。加权函数源自不同条件下锥体的反应，并可用于模拟锥体的平均时间积分。结果的“有效刺激”，虽然不是可测量的响应，但是成功地模拟了锥体的实际光电流响应的第一步。
- en: Combining the above weighting function's shape with known human cone response
    times, we can create a detailed simulation of a *perceived image* based on any
    input scene. This concept has been [used before](https://pubmed.ncbi.nlm.nih.gov/26357212/),
    but without the shape of the time response.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: 结合上述加权函数的形状和已知的人类锥体反应时间，我们可以基于任何输入场景创建一个*感知图像*的详细模拟。这个概念以前已经被[使用过](https://pubmed.ncbi.nlm.nih.gov/26357212/)，但没有时间响应形状。
- en: '**2\. Motion Smearing**. Left: Example scene, assumed to be natural and continuous.
    Right: simulated perceived image. This assumes the viewer is looking at a fixed
    point, and not tracking the object with their eyes.'
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**2\. 运动模糊**。左：假设为自然连续的示例场景。右：模拟的感知图像。这假设观众正盯着一个固定点，并且没有用眼睛追踪物体。'
- en: What this shows is that there already exists a natural blur at the photoreceptor
    level, a phenomenon often called motion smear. So why do we add artificial motion
    blur in videos, and what is the link between motion smear and motion blur?
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明，在光感受器级别已经存在自然模糊，这种现象通常称为运动模糊。那么为什么在视频中添加人为的运动模糊，运动模糊与运动模糊之间有什么联系呢？
- en: Perception of a scene on a screen
  id: totrans-split-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 屏幕上场景的感知
- en: Let's see what this perceived image looks like when viewing a screen with limited
    frames per second.
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看当观看每秒帧数有限的屏幕时，这种感知图像会是什么样子。
- en: '**3\. Perception of a video**. Left: Example scene as it would appear on a
    screen. Right: perceived image.'
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**3\. 视频的感知**。左：在屏幕上显示的示例场景。右：感知到的图像。'
- en: This finally gives us a way of visualizing the usefulness of motion blur. When
    viewing a video without motion blur, the resulting perceived image looks like
    overlaid frames instead of the expected motion smear. This situation is improved
    with a motion blurred video, where each frame no longer shows a moment in time,
    but an average of all the moments within the time interval covered by this frame.
    This is analogous to a video made with a camera whose shutter is open for the
    duration of each frame's timespan. The resulting perceived image looks a lot more
    similar to the natural case.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，这给我们提供了一种可视化运动模糊有用性的方式。在观看没有运动模糊的视频时，结果的感知图像看起来像是叠加的帧，而不是预期的运动模糊。使用运动模糊的视频改善了这种情况，其中每个帧不再显示某一时刻，而是显示该帧时间间隔内所有时刻的平均值。这类似于使用快门开放每帧持续时间的相机制作的视频。结果的感知图像看起来更加类似于自然情况。
- en: Making the screen natural with a shutter function
  id: totrans-split-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用快门功能使屏幕更加自然
- en: 'Something still looks off in the perceived image for traditional motion blur.
    At some object speeds, artifacts still appear as discontinuities in the motion
    smear. This can be almost eliminated by applying a shutter function: instead of
    averaging all the moments within a frame, we weight them by a function so that
    the start and end moments have less weight than the central moment of a frame.
    The name "shutter function" comes from the analogy to shutter efficiency in a
    [diaphragm camera](https://en.wikipedia.org/wiki/Diaphragm_%28optics%29), where
    the shutter takes time to transition between open and closed states. But instead
    of simulating cameras, the shutter function can be chosen in a way that minimizes
    the perceptual difference between the screen and a natural scene. The problem
    then becomes very similar to crafting [window functions](https://en.wikipedia.org/wiki/Window_function)
    in signal processing, and indeed the most popular window functions give very good
    results.'
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的运动模糊在感知图像上仍然有些问题。在某些物体速度下，伪影仍然表现为运动模糊中的不连续性。通过应用快门功能，这几乎可以消除：不再是对帧内所有时刻进行平均，而是通过函数进行加权，使得帧的起始和结束时刻的权重小于帧中心的时刻。
    "快门功能" 这个名字来自于类比到[光圈相机](https://en.wikipedia.org/wiki/Diaphragm_%28optics%29)，在那里快门需要在开启和关闭状态之间进行过渡。但是，与模拟相机不同，快门功能可以选择为最小化屏幕和自然场景之间的感知差异。这个问题然后变得非常类似于在信号处理中制作[窗口函数](https://en.wikipedia.org/wiki/Window_function)，事实上最受欢迎的窗口函数提供非常好的结果。
- en: '**4\. Applying a shutter function**.'
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**4\. 应用快门功能**。'
- en: How well does this work? You can get a rough idea in the following demo, which
    can be switched between motion blur with and without a shutter function. My impression
    is that the shutter function is not necessary at low speeds, but is noticeably
    more natural for fast-moving objects^(. This makes it highly relevant to the "past
    the logical extreme" experiment I'm aiming for. It also looks smoother in still
    frames, which is incidental but sometimes relevant.)
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这项工作效果如何？您可以在以下演示中大致了解，可以在带有和不带有快门功能的运动模糊之间切换。我个人的印象是，低速情况下快门功能不是必需的，但对于快速移动的物体来说显然更加自然^(。这使得它与我正在追求的“超越逻辑极限”的实验高度相关。它在静止画面中看起来更加平滑，这是偶然的，但有时也很重要。
- en: '**5\. Live comparison** of motion blur with and without a shutter function.'
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**5\. 运动模糊的实时比较**，带有和不带有快门功能的比较。'
- en: I'll emphasize that this perceptual approach to motion blur is not conventional
    and could be misguided in some way. The common approach is to simulate cameras,
    which results in zero time overlap between frames, and often entirely discards
    moments that fall between frames. Meanwhile, the method I'm describing results
    in overlapping time-ranges for successive frames. With that out of the way, let's
    try applying this technique.
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我要强调这种对运动模糊的感知方法并不传统，可能在某些方面是误导的。常见的方法是模拟相机，导致帧之间没有时间重叠，并且通常完全丢弃在帧之间落入的时刻。与此同时，我描述的方法导致连续帧之间存在时间重叠的时间范围。说了这么多，让我们尝试应用这种技术。
- en: Getting irrational with the torusphere
  id: totrans-split-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与环面球感到愉悦
- en: To make things both difficult and interesting, I decided to make this infinite
    motion blur animation as a realtime [shader](https://thebookofshaders.com/01/).
    Because I like hardship and misery, yes, but mostly because I'd like the end product
    to be interactive, and in this case, a shader might be the simplest way.
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使事情既困难又有趣，我决定将这个无限运动模糊动画制作成一个实时[着色器](https://thebookofshaders.com/01/)。因为我喜欢挑战和痛苦，是的，但主要是因为我希望最终产品是互动的，而在这种情况下，着色器可能是最简单的方法。
- en: First, how does one render motion blur in realtime? After ruling out multisampling
    ^(and analytic ray-traced motion blur^(, I settled on a terrible hack best described
    as "integrated volume motion blur". Represent the moving object as a function
    that takes coordinates (including time) and returns density (the inside is 1,
    the rest is 0). Integrate this density function over time, and the result should
    give you a "motion-blurred density" over any time interval. The result can be
    rendered by [volume ray casting](https://en.wikipedia.org/wiki/Volume_ray_casting).
    This method is not photorealistic, but can handle extremely long trails with realtime
    performance.))
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如何实时渲染运动模糊？在排除了多重采样和解析射线追踪的运动模糊后，我采用了一个可怕的方法，最好被描述为“综合体积运动模糊”。将运动物体表示为一个函数，该函数接受坐标（包括时间）并返回密度（内部为1，其他为0）。对这个密度函数在时间上进行积分，结果应该在任何时间间隔内给出一个“运动模糊密度”。结果可以通过[体积光线投射](https://en.wikipedia.org/wiki/Volume_ray_casting)来渲染。这种方法并不逼真，但可以处理极长的轨迹并实时性能良好。
- en: The intended animation combines an **orbiting sphere** and a **rotating torus**,
    both of which need to be motion-blurred up to essentially infinite speed.
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: 所期望的动画结合了**轨道球体**和**旋转环面**，这两者都需要达到几乎无限速度的运动模糊效果。
- en: Motion-blurred sphere
  id: totrans-split-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运动模糊的球体
- en: 'Taking a 2D slice of the orbiting sphere, the problem is reduced to finding
    the motion-blurred density for an orbiting circle. Let''s assume an orbital radius
    $R$, and a circle of radius $a$. The circle''s center is always at a distance
    of $R$ from the origin, so it can start at the point $(R, 0)$. This means that
    initially, all points $(x, y)$ on the circle are defined by:'
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: 取轨道球的二维切片，问题简化为找到轨道圆的运动模糊密度。假设轨道半径为$R$，圆的半径为$a$。圆的中心始终与原点距离为$R$，因此可以从点$(R, 0)$开始。这意味着最初，圆上的所有点$(x,
    y)$由以下定义：
- en: $$ (x - R)^2 + y^2 = a^2 $$
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: $$ (x - R)^2 + y^2 = a^2 $$
- en: 'In order to work with the orbit, this should be expressed in polar coordinates
    $(r,\theta)$, which can be done by substitution:'
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: 要处理轨道问题，应该使用极坐标$(r,\theta)$来表示，可以通过以下替换实现：
- en: $$ r^2 - 2 r R \cos\theta + R^2 = a^2 $$
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: $$ r^2 - 2 r R \cos\theta + R^2 = a^2 $$
- en: 'Finding the density function means taking any point, and answering the question:
    When does this point enter the orbiting circle? When does it exit? The answer
    lies in the angle coordinate coordinate $\theta$ of the initial object''s surface,
    with the same radial coordinate $r$ as the given point. Because the object is
    orbiting, this angle is directly related to the time when the object will hit
    the point. So let''s find $\theta$ based on the above definition of the surface:'
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: 找到密度函数意味着取任意点，并回答这个问题：这个点何时进入轨道圆？何时退出？答案在于初始对象表面的角度坐标$\theta$，其径向坐标$r$与给定点相同。因为对象正在轨道运动，所以这个角度直接与对象击中该点的时间相关。因此，让我们根据上述表面的定义找到$\theta$：
- en: $$ \theta = \pm\arccos\frac{R^2 + r^2 - a^2}{2 r R}, \theta\in[-\pi,\pi] $$
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \theta = \pm\arccos\frac{R^2 + r^2 - a^2}{2 r R}, \theta\in[-\pi,\pi] $$
- en: 'The $\pm$ sign comes from the inversion of $\cos$. This $\pm$ is useful, since
    it determines which half-circle is defined: positive or negative $\theta$. The
    two halves can be combined to get a polar expression of the density $\rho$ of
    the corresponding disk:'
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: $\pm$符号来自于$\cos$的反转。这个$\pm$很有用，因为它决定了哪一半圆被定义为正或负的$\theta$。这两个半部分可以结合起来得到相应圆盘密度$\rho$的极坐标表达式：
- en: $$ \rho(r,\theta) = \begin{cases} 1 & \text{if }-h(r)\lt\theta\lt h(r) \cr 0
    & \text{otherwise} \end{cases}\\[2ex] \text{where}\ \ h(r) = \arccos\frac{R^2
    + r^2 - a^2}{2 r R} $$
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \rho(r,\theta) = \begin{cases} 1 & \text{如果 }-h(r)\lt\theta\lt h(r) \cr 0
    & \text{否则} \end{cases}\\[2ex] \text{其中}\ \ h(r) = \arccos\frac{R^2 + r^2 - a^2}{2
    r R} $$
- en: 'From this starting position, the disk is orbiting around the origin. This is
    equivalent to removing the time $t$ times the speed $v$ from the angle coordinate:'
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个起始位置，圆盘围绕原点运动。这相当于从角度坐标中减去时间$t$乘以速度$v$：
- en: $$ \rho(\colorbox{yellow}{t,}r,\theta) = \begin{cases} 1 & \text{if }-h(r)\lt\theta\colorbox{yellow}{-
    v t}\lt h(r) \cr 0 & \text{otherwise} \end{cases} $$
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \rho(\colorbox{yellow}{t,}r,\theta) = \begin{cases} 1 & \text{如果 }-h(r)\lt\theta\colorbox{yellow}{-
    v t}\lt h(r) \cr 0 & \text{否则} \end{cases} $$
- en: 'We can separate $t$ from the time interval $I$ during which the object is present
    at a point $(r,\theta)$:'
  id: totrans-split-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将时间间隔$I$内的时间$t$与物体在点$(r,\theta)$的位置分开：
- en: $$ \rho(t, r,\theta) = \begin{cases} 1 & \text{if }t\in I \cr 0 & \text{otherwise}
    \end{cases}\\[2ex] I=\left[\cfrac{\theta-h(r)}{v}, \cfrac{\theta+h(r)}{v}\right]
    $$
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \rho(t, r,\theta) = \begin{cases} 1 & \text{如果 }t\in I \cr 0 & \text{否则}
    \end{cases}\\[2ex] I=\left[\cfrac{\theta-h(r)}{v}, \cfrac{\theta+h(r)}{v}\right]
    $$
- en: 'The motion-blurred density is the integral of the density $\rho$ over the current
    frame''s time interval $F$. This works out to be the length of the intersection
    between $I$ and $F$. This can also be described intuitively: we''re measuring
    how much of the frame''s time is occupied by the object at a given point in space.'
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
  zh: 运动模糊密度是在当前帧时间间隔$F$内密度$\rho$的积分。这等于$I$和$F$的交集的长度。这也可以直观地描述：我们测量的是物体在空间中给定点上占用了帧时间的多少。
- en: $$\int_F\rho(t,r,\theta) d t = \int_{F\cap I}1\ d t = |F\cap I|$$
  id: totrans-split-56
  prefs: []
  type: TYPE_NORMAL
  zh: $$\int_F\rho(t,r,\theta) d t = \int_{F\cap I}1\ d t = |F\cap I|$$
- en: 'Let''s apply a shutter function $s$. For simplicity, assume $s$ is already
    centered on the current frame''s time span. We can apply it by multiplying the
    density with $s(t)$ before integrating, replacing the need for any bounds of integration
    of the density. If $s$ has an antiderivative $S$, then the motion-blurred density
    becomes:'
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们应用一个快门函数$s$。为了简单起见，假设$s$已经居中在当前帧的时间跨度上。我们可以在积分之前通过将密度乘以$s(t)$来应用它，从而替换密度的任何积分边界。如果$s$有一个反导数$S$，那么运动模糊密度变为：
- en: $$ \int\rho(t,r,\theta) s(t) d t = \int_I s(t) d t = S(\max I)-S(\min I) $$
  id: totrans-split-58
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \int\rho(t,r,\theta) s(t) d t = \int_I s(t) d t = S(\max I)-S(\min I) $$
- en: 'This can be implemented in a shader and works with any shutter function, however,
    based on the goals from the first part of this article, shutter functions should
    have an integral of 1 and should overlap in such a way that the sum of all shutter
    functions at any timepoint is always 1\. This can be satisfied with a trapezoid
    function, or with a sinusoid function such as this one, used in the animation:'
  id: totrans-split-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以在着色器中实现，并且适用于任何快门函数，然而，根据本文第一部分的目标，快门函数应该有一个积分为1，并且应该以一种使得任何时间点的所有快门函数的和总是1的方式重叠。这可以通过梯形函数或像动画中使用的这种正弦函数来实现：
- en: $$ s(t)=\begin{cases} \cfrac{1-\cos\frac{(t-A)2\pi}{B-A}}{B-A} & \text{if }A\lt
    t\lt B \cr 0 & \text{otherwise} \end{cases}\\[2ex] A=\min F-\frac{|F|}{2},B=\max
    F+\frac{|F|}{2} $$
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
  zh: $$ s(t)=\begin{cases} \cfrac{1-\cos\frac{(t-A)2\pi}{B-A}}{B-A} & \text{如果 }A\lt
    t\lt B \cr 0 & \text{否则} \end{cases}\\[2ex] A=\min F-\frac{|F|}{2},B=\max F+\frac{|F|}{2}
    $$
- en: Motion-blurred torus
  id: totrans-split-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运动模糊的圆环
- en: 'The same process can be followed for the torus. A 2D vertical slice of a torus
    is called a [spiric section](https://en.wikipedia.org/wiki/Spiric_section), or
    Spiric of Perseus. Aside from sounding like an **epic videogame weapon**, it also
    has a convenient formulation in polar coordinates. Take a torus of minor radius
    $a$ and major radius $b$. Take a section at position $c$, and within this section
    in polar coordinates $(r,\theta)$, all torus points are defined by:'
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于圆环，可以采用同样的过程。圆环的二维垂直切片称为[斯皮尔科截面](https://en.wikipedia.org/wiki/Spiric_section)，或者称为Perseus的斯皮尔科。除了听起来像是一个**史诗般的视频游戏武器**外，在极坐标中还有一个方便的表述。取小半径为$a$，大半径为$b$的圆环。在位置$c$处取一个切片，在该切片中的极坐标$(r,\theta)$中，所有的圆环点由以下公式定义：
- en: $$ (r^2-a^2+b^2+c^2)^2 = 4b^2(r^2\cos^2\theta+c^2) $$
  id: totrans-split-63
  prefs: []
  type: TYPE_NORMAL
  zh: $$ (r^2-a^2+b^2+c^2)^2 = 4b^2(r^2\cos^2\theta+c^2) $$
- en: 'Solving for $\theta$, assuming $\theta\in[-\pi/2,\pi/2]$, this becomes:'
  id: totrans-split-64
  prefs: []
  type: TYPE_NORMAL
  zh: 求解$\theta$，假设$\theta\in[-\pi/2,\pi/2]$，则变为：
- en: $$ \theta = \pm\arccos\frac{\sqrt{(a^2 - b^2 - c^2 - r^2 - 2 b c) (a^2 - b^2
    - c^2 - r^2 + 2 b c)}}{2 b r} $$
  id: totrans-split-65
  prefs: []
  type: TYPE_NORMAL
  zh: $$ \theta = \pm\arccos\frac{\sqrt{(a^2 - b^2 - c^2 - r^2 - 2 b c) (a^2 - b^2
    - c^2 - r^2 + 2 b c)}}{2 b r} $$
- en: Once again, the inside of the torus is enclosed between the positive and negative
    cases of the $\pm$ sign, giving us a polar expression of the density of the solid
    torus. The remaining steps to get the motion-blurred rotating torus are exactly
    the same as for the sphere above.
  id: totrans-split-66
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，环面的内部在正负$\pm$符号之间被包围，给我们一个实体环面密度的极坐标表达式。获取运动模糊旋转环面的剩余步骤与上面的球体完全相同。
- en: '**6\. Motion-blurred spiric section**.'
  id: totrans-split-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**6\. 运动模糊螺旋截面**。'
- en: Putting it together
  id: totrans-split-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 把它组合在一起
- en: All that's left is to "draw the rest of the owl" by combining elements in a
    convincing way, and by using standard volume ray casting on the result. [Surface
    normals](https://en.wikipedia.org/wiki/Normal_%28geometry%29) need extra care
    because there's no such thing as "motion-blurred surface normals", so they're
    just blended together here.
  id: totrans-split-69
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一需要做的是通过以令人信服的方式组合元素，并在结果上使用标准体积光线投射来"画出猫头鹰的剩余部分"。[表面法线](https://en.wikipedia.org/wiki/Normal_%28geometry%29)需要额外注意，因为"运动模糊表面法线"这种东西不存在，所以它们在这里只是混合在一起。
- en: The animation should run below with basic mouse/touch interaction. It might
    not work well on all devices, so there's also a pre-rendered video at the top
    of the page. You can also find [this shader on Shadertoy](https://www.shadertoy.com/view/cdXSRn).
  id: totrans-split-70
  prefs: []
  type: TYPE_NORMAL
  zh: 动画应在下方以基本的鼠标/触摸交互方式运行。在所有设备上可能运行效果不佳，因此页面顶部还有预渲染的视频。你也可以在[Shadertoy上找到这个着色器](https://www.shadertoy.com/view/cdXSRn)。
- en: Torusphere accelerator (live)
  id: totrans-split-71
  prefs: []
  type: TYPE_NORMAL
  zh: 环面加速器（现场）
- en: '* * *'
  id: totrans-split-72
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
