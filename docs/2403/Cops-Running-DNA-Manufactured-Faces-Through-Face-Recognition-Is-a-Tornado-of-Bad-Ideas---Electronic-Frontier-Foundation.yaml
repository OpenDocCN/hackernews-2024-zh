- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-29 12:44:59'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: Cops Running DNA-Manufactured Faces Through Face Recognition Is a Tornado of
    Bad Ideas | Electronic Frontier Foundation
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://www.eff.org/deeplinks/2024/03/cops-running-dna-manufactured-faces-through-face-recognition-tornado-bad-ideas](https://www.eff.org/deeplinks/2024/03/cops-running-dna-manufactured-faces-through-face-recognition-tornado-bad-ideas)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In keeping with law enforcement’s grand tradition of taking [antiquated, invasive,
    and oppressive technologies, making them digital, and then calling it innovation](https://slate.com/technology/2020/02/rogues-gallery-facial-recognition-technology-history.html),
    police in the U.S. recently combined two existing dystopian technologies in a
    brand new way to violate civil liberties. A police force in California recently
    employed the new practice of taking a [DNA sample](https://www.fsigenetics.com/article/S1872-4973(23)00045-5/fulltext)
    from a crime scene, running this through a service provided by US company [Parabon
    NanoLabs](https://parabon-nanolabs.com/) that guesses what the perpetrators face
    looked like, and plugging [this rendered image into face recognition software](https://www.wired.com/story/parabon-nanolabs-dna-face-models-police-facial-recognition/#:~:text=Parabon%20NanoLabs%20ran%20the%20suspect's,using%20only%20crime%20scene%20evidence)
    to build a suspect list.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: Parts of this process aren't [entirely new](https://www.vice.com/en/article/xwngn3/police-are-feeding-celebrity-photos-into-facial-recognition-software-to-solve-crimes).
    On more than one occasion, police forces have been found to have fed [images of
    celebrities](https://www.vice.com/en/article/xwngn3/police-are-feeding-celebrity-photos-into-facial-recognition-software-to-solve-crimes)
    into face recognition software to generate suspect lists. In one case from 2017,
    the New York Police Department decided its suspect looked like Woody Harrelson
    and ran the actor’s image through the software to generate hits. Further, software
    provided by US company [Vigilant Solutions](https://www.motorolasolutions.com/en_us/products/command-center-software/public-safety-software/analysis-and-investigation.html?utm_source=vigilantsolutions.com&utm_medium=referral&utm_campaign=vigilantsolutions_redirect)
    enables law enforcement to create “a proxy image from a sketch artist or artist
    rendering” to enhance images of potential suspects so that face recognition software
    can match these more accurately.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: Since 2014, law enforcement have also sought the assistance of [Parabon NanoLabs](https://parabon-nanolabs.com/)—a
    company that alleges it can create an image of the suspect’s face from their DNA.
    Parabon NanoLabs [claim](https://www.wired.com/story/parabon-nanolabs-dna-face-models-police-facial-recognition/#:~:text=Parabon%20NanoLabs%20ran%20the%20suspect's,using%20only%20crime%20scene%20evidence)
    to have built this system by training machine learning models on the DNA data
    of thousands of volunteers with 3D scans of their faces. It is currently the only
    company offering phenotyping and only in concert with a [forensic genetic genealogy
    investigation](https://www.eff.org/wp/forensic-genetic-genealogy-searches-what-defense-attorneys-need-know).
    The process is yet to be independently audited, and [scientists have affirmed](https://senseaboutscience.org/activities/making-sense-of-forensic-genetics/)
    that predicting face shapes—particularly from DNA samples—is not possible. But
    this has not stopped law enforcement officers from seeking to use it, or from
    running these fabricated images through face recognition software.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 自2014年以来，执法部门还寻求[Parabon NanoLabs](https://parabon-nanolabs.com/)的帮助，这家公司声称能够根据嫌疑人的DNA创建他们的面孔图像。Parabon
    NanoLabs [声称](https://www.wired.com/story/parabon-nanolabs-dna-face-models-police-facial-recognition/#:~:text=Parabon%20NanoLabs%20ran%20the%20suspect's,using%20only%20crime%20scene%20evidence)是通过对成千上万志愿者的DNA数据和他们面孔的3D扫描训练机器学习模型来构建该系统的。目前，这是唯一一家提供表型信息的公司，并且只能与[法医遗传家谱调查](https://www.eff.org/wp/forensic-genetic-genealogy-searches-what-defense-attorneys-need-know)一起使用。该流程尚未得到独立审计，[科学家已经确认](https://senseaboutscience.org/activities/making-sense-of-forensic-genetics/)，尤其是从DNA样本预测面部形状是不可能的。但这并没有阻止执法官员寻求使用它，或者将这些虚构图像通过面部识别软件。
- en: 'Simply put: police are using DNA to create a hypothetical and not at all accurate
    face, then using that face as a clue on which to base investigations into crimes.
    Not only is this full dice-roll policing, it also threatens the rights, freedom,
    or even the life of whoever is unlucky enough to look a little bit like that artificial
    face.'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之：警方利用DNA创建一个假设的、一点也不准确的面孔，然后将这张面孔作为调查犯罪的线索。这不仅是盲目的警务，而且威胁着任何不幸看起来有点像那张人工面孔的人的权利、自由，甚至生命。
- en: But it gets worse.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 但情况更糟。
- en: In 2020, a detective from the East Bay Regional Park District Police Department
    in California [asked](https://www.wired.com/story/parabon-nanolabs-dna-face-models-police-facial-recognition/#:~:text=Parabon%20NanoLabs%20ran%20the%20suspect's,using%20only%20crime%20scene%20evidence)
    to have a rendered image from Parabon NanoLabs run through face recognition software.
    This 3D rendering, called a [Snapshot Phenotype Report](https://snapshot.parabon-nanolabs.com/),
    predicted that—among other attributes—the suspect was male, had brown eyes, and
    fair skin. Found in police records published by [Distributed Denial of Secrets](https://ddosecrets.com/wiki/Distributed_Denial_of_Secrets),
    this appears to be the first reporting of a detective running an algorithmically-generated
    rendering based on crime-scene DNA through face recognition software. This puts
    a second layer of speculation between the actual face of the suspect and the product
    the police are using to guide investigations and make arrests. Not only is the
    artificial face a guess, now face recognition ([a technology known to misidentify
    people](https://www.cbsnews.com/sacramento/news/texas-macys-sunglass-hut-facial-recognition-software-wrongful-arrest-sacramento-alibi/)) 
    will create a “most likely match” for that face.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 2020年，加州东湾地区区域公园警察局的一位侦探[要求](https://www.wired.com/story/parabon-nanolabs-dna-face-models-police-facial-recognition/#:~:text=Parabon%20NanoLabs%20ran%20the%20suspect's,using%20only%20crime%20scene%20evidence)通过Parabon
    NanoLabs的渲染图像运行面部识别软件。这张3D渲染图称为[快照表型报告](https://snapshot.parabon-nanolabs.com/)，预测出嫌疑人是男性，有棕色眼睛和白皙的皮肤等属性。根据[分布式否认秘密](https://ddosecrets.com/wiki/Distributed_Denial_of_Secrets)发布的警方记录，这似乎是侦探首次运行基于犯罪现场DNA的算法生成的渲染图像通过面部识别软件。这使得警方在调查和逮捕中使用的产品与嫌疑人的实际面孔之间增加了第二层猜测。人工面孔不仅仅是一个猜测，现在面部识别（一个众所周知的[容易误认人的技术](https://www.cbsnews.com/sacramento/news/texas-macys-sunglass-hut-facial-recognition-software-wrongful-arrest-sacramento-alibi/)）将为这张脸创建一个“最有可能的匹配”。
- en: These technologies, and their reckless use by police forces, are an inherent
    threat to our individual privacy, free expression, information security, and social
    justice. Face recognition tech alone has an [egregious history](https://www.eff.org/aboutface)
    of misidentifying [people of color](https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf),
    especially [Black women](https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf),
    as well as failing to correctly identify [trans and nonbinary people](https://qz.com/1726806/facial-recognition-ai-from-amazon-microsoft-and-ibm-misidentifies-trans-and-non-binary-people/).
    The algorithms are [not always reliable](https://www.sciencedirect.com/science/article/abs/pii/S0364021302000848),
    and even if the technology somehow had 100% accuracy, it would still be an [unacceptable
    tool](https://www.eff.org/aboutface) of invasive surveillance capable of identifying
    and tracking people on a massive scale. Combining this with fabricated 3D renderings
    from crime-scene DNA exponentially increases the likelihood of false arrests,
    and exacerbates [existing harms](https://www.cbc.ca/news/canada/edmonton/edmonton-police-issue-apology-for-controversial-use-of-dna-phenotyping-1.6608457)
    on communities that are already disproportionately over-surveilled by face recognition
    technology and discriminatory policing.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这些技术及其被警方滥用，对我们的个人隐私、自由表达、信息安全和社会公正构成了固有威胁。单单面部识别技术就有一段[严重的历史](https://www.eff.org/aboutface)，频繁误认[有色人种](https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf)，特别是[黑人女性](https://proceedings.mlr.press/v81/buolamwini18a/buolamwini18a.pdf)，以及未能正确识别[跨性别和非二元性别的人](https://qz.com/1726806/facial-recognition-ai-from-amazon-microsoft-and-ibm-misidentifies-trans-and-non-binary-people/)。这些算法并[非总是可靠](https://www.sciencedirect.com/science/article/abs/pii/S0364021302000848)，即使技术以某种方式达到了100%的准确率，它仍然是一个[无法接受的工具](https://www.eff.org/aboutface)，具备大规模识别和跟踪人群的侵入性监视能力。结合此技术与从犯罪现场DNA制作的虚构三维渲染，极大地增加了虚假逮捕的可能性，并加剧了已经由面部识别技术和歧视性执法过度监控的社区上的[现存伤害](https://www.cbc.ca/news/canada/edmonton/edmonton-police-issue-apology-for-controversial-use-of-dna-phenotyping-1.6608457)。
- en: There are no federal rules that prohibit police forces from undertaking these
    actions. And despite the detective’s request violating Parabon NanoLabs’ [terms
    of service](https://web.archive.org/web/20160507204509/https://snapshot.parabon-nanolabs.com/terms),
    there is seemingly no way to ensure compliance. Pulling together criteria like
    skin tone, hair color, and gender does not give an accurate face of a suspect,
    and deploying these untested algorithms without any oversight places people at
    risk of being a suspect for a crime they didn’t commit. In one case from Canada,
    Edmonton Police Service [issued an apology](https://www.cbc.ca/news/canada/edmonton/edmonton-police-issue-apology-for-controversial-use-of-dna-phenotyping-1.6608457)
    over its failure to balance the harms to the Black community with the potential
    investigative value after [using](https://globalnews.ca/news/9175041/edmonton-police-dna-phenotyping-sexual-assault-suspect/)
    Parabon’s DNA phenotyping services to identify a suspect.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 没有联邦规定禁止警方采取这些行动。尽管侦探的请求违反了Parabon NanoLabs的[服务条款](https://web.archive.org/web/20160507204509/https://snapshot.parabon-nanolabs.com/terms)，似乎并没有确保其遵守的方式。根据肤色、头发颜色和性别等标准组合并不能准确描绘出嫌疑犯的面孔，而在没有任何监督的情况下部署这些未经测试的算法，使人们面临被错误指控的风险。在加拿大的一个案例中，埃德蒙顿警察局因在使用Parabon的DNA表型服务识别嫌疑人后，未能在[使用](https://globalnews.ca/news/9175041/edmonton-police-dna-phenotyping-sexual-assault-suspect/)时平衡对黑人社区的伤害和潜在调查价值后[道歉](https://www.cbc.ca/news/canada/edmonton/edmonton-police-issue-apology-for-controversial-use-of-dna-phenotyping-1.6608457)。
- en: EFF continues to call for a complete ban on government use of face recognition—because
    otherwise these are the results. How much more evidence do law markers need that
    police cannot be trusted with this dangerous technology? How many more people
    need to be falsely arrested and how many more reckless schemes like this one need
    to be perpetrated before legislators realize this is not a sustainable method
    of law enforcement? [Cities across the United States](https://www.eff.org/deeplinks/2022/05/movement-ban-government-use-face-recognition)
    have already taken the step to ban government use of this technology, and [Montana](https://www.eff.org/deeplinks/2023/08/montanas-new-genetic-privacy-law-caps-ten-years-innovative-state-privacy)
    has specifically recognized a privacy interest in phenotype data. Other cities
    and states need to catch up or Congress needs to act before more people are hurt
    and our rights are trampled.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: EFF 继续呼吁完全禁止政府使用面部识别技术 — 因为否则就会出现这些结果。立法者需要多少证据证明警方不能信任这种危险技术？还需要多少人被错误逮捕，还需要多少类似这种鲁莽计划才能让立法者意识到，这并非可持续的执法方法？[美国各地的城市](https://www.eff.org/deeplinks/2022/05/movement-ban-government-use-face-recognition)已经迈出了禁止政府使用这一技术的步伐，而[蒙大拿州](https://www.eff.org/deeplinks/2023/08/montanas-new-genetic-privacy-law-caps-ten-years-innovative-state-privacy)则特别认识到对表型数据的隐私利益。其他城市和州需要赶上，或者国会在更多人受伤和我们的权利受损之前采取行动。
