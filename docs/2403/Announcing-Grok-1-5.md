<!--yml

category: 未分类

date: 2024-05-29 12:47:19

-->

# 宣布Grok-1.5

> 来源：[https://x.ai/blog/grok-1.5](https://x.ai/blog/grok-1.5)

## 长上下文理解

Grok-1.5 的新功能是能够在其上下文窗口内处理长达128K令牌的长上下文。这使得Grok的记忆能力比先前的上下文长度增加了16倍，使其能够利用来自极长文档的信息。

此外，该模型可以处理更长、更复杂的提示，同时随着其上下文窗口的扩展，仍保持其遵循指令的能力。在“大海捞针”（NIAH）评估中，Grok-1.5 展示了在长达128K令牌长度的上下文中的强大检索能力，实现了完美的检索结果。

## Grok-1.5 Infra

运行在大规模GPU集群上的前沿大语言模型（LLMs）研究需要强大而灵活的基础设施。Grok-1.5基于JAX、Rust和Kubernetes构建了自定义分布式训练框架。这种训练堆栈使我们的团队能够在大规模上原型化想法，并训练新的架构，几乎不费吹灰之力。在大型计算集群上训练LLMs的一个主要挑战是最大化训练作业的可靠性和正常运行时间。我们的自定义训练协调器确保自动检测到问题节点，并将其从训练作业中剔除。我们还优化了检查点、数据加载和训练作业重启，以最小化在故障发生时的停机时间。如果您对我们的训练堆栈感兴趣，请[申请加入我们的团队](https://x.ai/careers)。

## 展望未来

Grok-1.5 将很快提供给早期测试者，我们期待收到您的反馈，以帮助我们改进Grok。随着我们逐步向更广泛的受众推出Grok-1.5，我们很高兴在未来几天介绍几个新功能。

*请注意，GPT-4分数来自2023年3月的发布。对于MATH和GSM8K，我们展示maj@1的结果。对于HumanEval，我们报告pass@1的基准分数。*
