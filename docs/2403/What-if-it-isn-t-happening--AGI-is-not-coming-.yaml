- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:42:54'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: What if it isn't happening, AGI is not coming?
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://www.mindprison.cc/p/what-if-agi-is-not-coming](https://www.mindprison.cc/p/what-if-agi-is-not-coming)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '***[Notes From the Desk](https://www.mindprison.cc/s/notes-from-the-desk)**
    are periodic posts that summarize recent topics of interest or other brief notable
    commentary that might otherwise be a tweet or note.*'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: No matter what appears to be happening, we always have to consider what if it
    isn't. What If LLMs fail to turn into AGIs? Has our quest for intelligence simply
    unveiled our demonstrable lack thereof? Will trillions of dollars turn unpredictable
    hallucination machines into reliable universal productivity tools that can do
    anything?
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to hard problems the herd is almost universally always wrong.
    There is an enormous amount of institutional money flowing into AI development
    on the premise that LLM architecture is going to manifest something we call AGI
    that will solve all the world’s problems.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
- en: So what are some of the counter perspectives?
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
- en: 'These are the primary arguments that are expanded below:'
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
- en: We will soon be **reaching the limits of hardware scaling** for larger AI models.
  id: totrans-split-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There have been **no major AI technology breakthroughs in decades**. Everything
    we are seeing is larger compute scaling.
  id: totrans-split-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Scaling alone is not going to create AGI**, need other novel discoveries.'
  id: totrans-split-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The release of ChatGPT to the public made people think that generative AI was
    just getting started on an exponentially improving curve.
  id: totrans-split-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Yet, generative AI itself had been around for a while before that & **what we
    are seeing is probably the best it will ever be**.
  id: totrans-split-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Of course improving past what GPT-4 is now is going to require more & more resources
    to the point that no company, however big, will have the incentive to improve
    the technology any further.
  id: totrans-split-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Until a new breakthrough comes along, generative AI is almost at its peak
    now**.'
  id: totrans-split-18
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If Google struggled hard to make a model based on performance in the class of
    GPT-4, do you honestly think there is more juice in generative pretrained transformer
    (GPT) models to keep pumping out more improvements?
  id: totrans-split-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I don't think so, **these models are already too big**.
  id: totrans-split-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: …
  id: totrans-split-21
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Therefore GPT-4 is right at the elbow of the S-curve given the sort of diminishing
    returns already being observed - language models, both closed & open source, **aren't
    improving as much as they are demanding more & more resources** such as compute
    & data.
  id: totrans-split-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'See also:'
  id: totrans-split-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: …
  id: totrans-split-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: — Chomba Bupe, [X post](https://twitter.com/ChombaBupe/status/1763617694023033226)
  id: totrans-split-25
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A deep neural net (DNN) is just an arrangement of simple nodes - the perceptrons
    from the 40s, with various nonlinearities - in layers one atop the other.
  id: totrans-split-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: AI companies are **hoping that if they can mega size these DNNs by using lots
    of compute & data they can solve intelligence**.
  id: totrans-split-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The foundation for DNNs was **layed out in the 80s**.
  id: totrans-split-28
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Gradient descent (GD) was around even much earlier than that, stochastic gradient
    descent (SGD) is a variant of GD. For GD, the gradients are computed by passing
    through the entire training set before taking a step. SGD uses one sample - drawn
    randomly from the training set hence the term stochastic. Batch GD uses a greater
    than 1 sample but not all samples to compute gradients.
  id: totrans-split-29
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: There are variants to help convergence faster to a solution. **But nothing much
    has changed**.
  id: totrans-split-30
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: …
  id: totrans-split-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Thus if you look at it, there hasn't been enough innovation other than **just
    mega sizing old 80s techniques using modern hardware**. The success of today's
    systems are more attributed to breakthroughs in hardware computing like GPUs,
    TPUs etc than actual AI algorithms.
  id: totrans-split-32
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: That's why you expect AI to hit a plateau soon because **mega sizing these models
    has limits**. Physical limitations will come into effect to prevent further scaling
    up. **No matter how much compute or data they through into these, they won't solve
    intelligence**.
  id: totrans-split-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: …
  id: totrans-split-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Chomba Bupe, [X post](https://twitter.com/ChombaBupe/status/1763982592351629767)
  id: totrans-split-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A short perspective from Gary Marcus on why we haven’t seen hints of GPT5 as
    of yet. This aligns with the view of reaching limits on scaling.
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a theory: [Why OpenAI has not already released GPT5 to compete with
    Gemini and Claude]'
  id: totrans-split-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: • OpenAI tried already[creating GPT5], but what they came up with wasn’t impressive
    enough, so they called it GPT 4.5 Turbo.
  id: totrans-split-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: • They are still trying, but nothing they have come up with comes close to living
    up to expectations.
  id: totrans-split-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: • They aren’t really sure what to do next.
  id: totrans-split-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: • They aren’t sure they can do a lot better without a LOT of money, maybe even
    $7T worth of infrastructure.
  id: totrans-split-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: • So we will have to wait a while longer, maybe a lot longer.
  id: totrans-split-42
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Gary Marcus, [X post](https://twitter.com/GaryMarcus/status/1765198638182256780)
  id: totrans-split-43
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
- en: This suite of tests from [Maximum Truth](https://www.maximumtruth.org/p/ais-ranked-by-iq-ai-passes-100-iq)
    demonstrates the trouble of measuring the “IQ” of LLM intelligence.
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
- en: The new Claude-3 scores 101 the highest of any LLM so far. However, Claude is
    still a strange mix of capabilities in that IQ measurements give us no hint as
    to how Claude performs. It still fails to answer basic questions and hallucinates,
    but at the same time has proven to solve far more complex problems than other
    models.
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is Claude-3 failing to answer correctly the relative weight of feathers
    and bricks: How many more billions of dollars of compute will solve this one?'
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
- en: 'And here is Claude-3 solving novel problems:'
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
- en: IQ tests don’t predict this type of divergence in expected capability and it
    is exactly this that continues to create such divergence in opinion as to whether
    we are getting closer to AGI or making very expensive and unreliable Dr. Jekylls
    and Mr. Hydes.
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
- en: Billions to trillions of dollars will be poured into research over the next
    decade. More humans than ever are looking for breakthroughs. We have exponentially
    increased the parallel efforts. LLM architecture might be unable to deliver in
    its current state, but it has ignited monumental investments into research that
    might find other paths.
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
- en: However, expectations have been set extremely high. AI is the perfect technology
    that is currently just good enough to excite the imagination of what it could
    do making it seemingly within grasp but potentially still far away. It is the
    problem of being almost there seemingly indefinitely. Despite the real utility
    of current LLMs, the promises are far greater and if not delivered will result
    in significant market collapse in due time.
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
- en: Without AGI we are still exponentially improving, just not vertically with intelligence,
    but horizontally as new applications and methods are discovered for its use. Refinement
    in training, data, inferencing and application are all still advancing.
  id: totrans-split-53
  prefs: []
  type: TYPE_NORMAL
- en: If we are not intelligent enough to know what is intelligence, then just how
    intelligent are we? And are we intelligent enough to build more of something that
    we don't know what it is?
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
- en: '*No compass through the dark exists without hope of reaching the other side
    and the belief that it matters …*'
  id: totrans-split-56
  prefs: []
  type: TYPE_NORMAL
- en: Mind Prison is a reader-supported publication. You can also assist by sharing.
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
- en: '[Share](https://www.mindprison.cc/p/what-if-agi-is-not-coming?utm_source=substack&utm_medium=email&utm_content=share&action=share)'
  id: totrans-split-58
  prefs: []
  type: TYPE_NORMAL
