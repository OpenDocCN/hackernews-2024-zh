- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:54:56'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: 'Artificial Intelligence Act: MEPs adopt landmark law | News | European Parliament'
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law](https://www.europarl.europa.eu/news/en/press-room/20240308IPR19015/artificial-intelligence-act-meps-adopt-landmark-law)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The regulation, [agreed in negotiations with member states in December](https://www.europarl.europa.eu/news/en/press-room/20231206IPR15699/artificial-intelligence-act-deal-on-comprehensive-rules-for-trustworthy-ai)
    2023, was endorsed by MEPs with 523 votes in favour, 46 against and 49 abstentions.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: It aims to protect fundamental rights, democracy, the rule of law and environmental
    sustainability from high-risk AI, while boosting innovation and establishing Europe
    as a leader in the field. The regulation establishes obligations for AI based
    on its potential risks and level of impact.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: '**Banned applications**'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: The new rules ban certain AI applications that threaten citizens’ rights, including
    biometric categorisation systems based on sensitive characteristics and untargeted
    scraping of facial images from the internet or CCTV footage to create facial recognition
    databases. Emotion recognition in the workplace and schools, social scoring, predictive
    policing (when it is based solely on profiling a person or assessing their characteristics),
    and AI that manipulates human behaviour or exploits people’s vulnerabilities will
    also be forbidden.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
- en: '**Law enforcement exemptions**'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
- en: The use of biometric identification systems (RBI) by law enforcement is prohibited
    in principle, except in exhaustively listed and narrowly defined situations. “Real-time”
    RBI can only be deployed if strict safeguards are met, e.g. its use is limited
    in time and geographic scope and subject to specific prior judicial or administrative
    authorisation. Such uses may include, for example, a targeted search of a missing
    person or preventing a terrorist attack. Using such systems post-facto (“post-remote
    RBI”) is considered a high-risk use case, requiring judicial authorisation being
    linked to a criminal offence.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
- en: '**Obligations for high-risk systems**'
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
- en: Clear obligations are also foreseen for other high-risk AI systems (due to their
    significant potential harm to health, safety, fundamental rights, environment,
    democracy and the rule of law). Examples of high-risk AI uses include critical
    infrastructure, education and vocational training, employment, essential private
    and public services (e.g. healthcare, banking), certain systems in law enforcement,
    migration and border management, justice and democratic processes (e.g. influencing
    elections). Such systems must assess and reduce risks, maintain use logs, be transparent
    and accurate, and ensure human oversight. Citizens will have a right to submit
    complaints about AI systems and receive explanations about decisions based on
    high-risk AI systems that affect their rights.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
- en: '**Transparency requirements**'
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
- en: General-purpose AI (GPAI) systems, and the GPAI models they are based on, must
    meet certain transparency requirements, including compliance with EU copyright
    law and publishing detailed summaries of the content used for training. The more
    powerful GPAI models that could pose systemic risks will face additional requirements,
    including performing model evaluations, assessing and mitigating systemic risks,
    and reporting on incidents.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, artificial or manipulated images, audio or video content (“deepfakes”)
    need to be clearly labelled as such.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
- en: '**Measures to support innovation and SMEs**'
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
- en: Regulatory sandboxes and real-world testing will have to be established at the
    national level, and made accessible to SMEs and start-ups, to develop and train
    innovative AI before its placement on the market.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
- en: '**Quotes**'
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
- en: 'During the plenary debate on Tuesday, the Internal Market Committee co-rapporteur
    [Brando Benifei (S&D, Italy)](https://www.europarl.europa.eu/meps/en/124867/BRANDO_BENIFEI/home)
    said: “We finally have the world’s first binding law on artificial intelligence,
    to reduce risks, create opportunities, combat discrimination, and bring transparency.
    Thanks to Parliament, unacceptable AI practices will be banned in Europe and the
    rights of workers and citizens will be protected. The AI Office will now be set
    up to support companies to start complying with the rules before they enter into
    force. We ensured that human beings and European values are at the very centre
    of AI’s development”.'
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
- en: 'Civil Liberties Committee co-rapporteur [Dragos Tudorache (Renew, Romania)](https://www.europarl.europa.eu/meps/en/197665/DRAGOS_TUDORACHE/home)
    said: “The EU has delivered. We have linked the concept of artificial intelligence
    to the fundamental values that form the basis of our societies. However, much
    work lies ahead that goes beyond the AI Act itself. AI will push us to rethink
    the social contract at the heart of our democracies, our education models, labour
    markets, and the way we conduct warfare. The AI Act is a starting point for a
    new model of governance built around technology. We must now focus on putting
    this law into practice”.'
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
- en: '**Next steps**'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
- en: The regulation is still subject to a final lawyer-linguist check and is expected
    to be finally adopted before the end of the legislature (through the so-called
    [corrigendum](https://www.europarl.europa.eu/doceo/document/RULES-9-2023-11-01-RULE-241_EN.html)
    procedure). The law also needs to be formally endorsed by the Council.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
- en: 'It will enter into force twenty days after its publication in the official
    Journal, and be fully applicable 24 months after its entry into force, except
    for: bans on prohibited practises, which will apply six months after the entry
    into force date; codes of practise (nine months after entry into force); general-purpose
    AI rules including governance (12 months after entry into force); and obligations
    for high-risk systems (36 months).'
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
- en: '**Background**'
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
- en: The Artificial Intelligence Act responds directly to citizens’ proposals from
    the Conference on the Future of Europe (COFE), most concretely to [proposal 12(10)](https://conference-followup.europarl.europa.eu/cmsdata/267078/Report_EN.pdf#page=55)
    on enhancing EU’s competitiveness in strategic sectors, [proposal 33(5)](https://conference-followup.europarl.europa.eu/cmsdata/267078/Report_EN.pdf#page=76)
    on a safe and trustworthy society, including countering disinformation and ensuring
    humans are ultimately in control, [proposal 35](https://conference-followup.europarl.europa.eu/cmsdata/267078/Report_EN.pdf#page=77)
    on promoting digital innovation, (3) while ensuring human oversight and [(8)](https://conference-followup.europarl.europa.eu/cmsdata/267078/Report_EN.pdf#page=77)
    trustworthy and responsible use of AI, setting safeguards and ensuring transparency,
    and [proposal 37 (3)](https://conference-followup.europarl.europa.eu/cmsdata/267078/Report_EN.pdf#page=80)
    on using AI and digital tools to improve citizens’ access to information, including
    persons with disabilities.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
