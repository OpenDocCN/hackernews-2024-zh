- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:29:47'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: A story of a very large loop with a long instruction dependency chain - Johnny's
    Software Lab
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://johnnysswlab.com/a-story-of-a-very-large-loop-with-a-long-instruction-dependency-chain/](https://johnnysswlab.com/a-story-of-a-very-large-loop-with-a-long-instruction-dependency-chain/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*We at **Johnny’s Software Lab LLC** are experts in performance. If performance
    is in any way concern in your software project, feel free to [contact us](https://johnnysswlab.com/contact/).*'
  prefs: []
  type: TYPE_NORMAL
- en: Some time ago we had to investigate a performance problem for a customer. The
    problematic piece of code was a loop. The loop was very long, about 1000 lines
    of vector intrinsics. The vectorization was done efficiently so there were no
    more efficient intrinsics that we could use to make it faster. Just by looking
    at it, it seemed that it everything was fine and we reached peak performance.
  prefs: []
  type: TYPE_NORMAL
- en: Nevertheless, we measured CPI (cycles per instructions) number to find out it
    was quite bad. The most common reasons for low CPI are (1) stalls because data
    couldn’t be fetched from the memory subsystem and (2) instruction dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: Since all memory accesses were sequential, we investigated the loop for instruction
    dependencies. And behold, inside the loop, the input data for each intrinsic depended
    on the output data of the previous intrinsic. There was a long chain of dependencies
    starting from the first line in the loop body and going to the last line. There
    were no loop-carried dependencies – each iteration was independent of all the
    other iterations.
  prefs: []
  type: TYPE_NORMAL
- en: The experiment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For the purposes of this post, we recreated a similar loop – a loop with a
    long dependency chain going from the first instruction to the last instruction
    but without loop-carried dependency ([full source code](https://github.com/ibogosavljevic/johnysswlab/blob/master/2024-02-ilp-loopfission/cos_test.cpp)).
    First let’s declare a `cos_vector` function which takes a vector of four double
    values and calculates four cosines. The function looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Don’t spend too much time analyzing what the function does, since it is not
    important. What is important is to notice the instruction dependency chain. For
    many intrinsics in this function, the input data used by intrinsic X is produced
    by the intrinsic that comes immediately before it. So there is an instruction
    dependency chain that starts at the beginning of the function and ends at the
    end of the function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we use this function to calculate nested cosines, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: For this experiment. we added nested cosines here intentionally, to make the
    instruction dependency chain arbitrary long!
  prefs: []
  type: TYPE_NORMAL
- en: 'When we measured CPI (cycles per instruction metric, smaller number is better,
    0.25 is the best possible) as a function of number of nested cosines, we got following
    values:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Number of nested cosines | CPI |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0.65 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 1.47 |'
  prefs: []
  type: TYPE_TB
- en: '| 10 | 2.14 |'
  prefs: []
  type: TYPE_TB
- en: '| 15 | 2.46 |'
  prefs: []
  type: TYPE_TB
- en: '| 20 | 2.63 |'
  prefs: []
  type: TYPE_TB
- en: When there is only one cosine, the CPU can start executing instructions from
    the next iteration of the loop if it doesn’t have enough work. But as the dependency
    chain becomes longer with the growing number of nested cosines, the CPU has less
    and less work to do and the CPI metric gets worse.
  prefs: []
  type: TYPE_NORMAL
- en: Interleaving
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One solution to increasing ILP is interleaving: we create a new version of
    `cos_vector` that instead of one takes two double vectors for inputs and calculate
    two results. So, inside our new [`cos_vector_interleaved`](https://github.com/ibogosavljevic/johnysswlab/blob/master/2024-02-ilp-loopfission/cos_test.cpp#L133)
    we have two dependency chains running in parallel. This increases available ILP
    and consequently increases performance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We already covered [interleaving in earlier post](https://johnnysswlab.com/when-an-instruction-depends-on-the-previous-instruction-depends-on-the-previous-instructions-long-instruction-dependency-chains-and-performance/).
    Interleaving would be fine for this specific example, but it wasn’t a good approach
    with our customer: the loop body was already quite complex and interleaving makes
    it even more complex. Also, there was fear of register spilling and possible loss
    of performance because the loop body was already using a lot of constants and
    needed a lot of registers.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Like what you are reading? Follow us on [LinkedIn](https://www.linkedin.com/company/johnysswlab)
    , [Twitter](https://twitter.com/johnnysswlab) or [Mastodon](https://mastodon.online/@johnnysswlab)
    and get notified as soon as new content becomes available.'
  prefs: []
  type: TYPE_NORMAL
- en: Need help with software performance? [Contact us](https://johnnysswlab.com/contact/)!*
  prefs: []
  type: TYPE_NORMAL
- en: A different approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Are there other approaches? Let’s limit the analysis for simplicity to three
    nested cosines. Our original loop looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We took our original loop and split it into three smaller loops, as you can
    see bellow. Each loop calculates one cosine. This approach is called *loop fission*.
    Since each loop produces a result that is consumed by the next loop, we need a
    temporary array to store the intermediate result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The original big loop got split into three smaller loops. The newly introduced
    `tmp_vec` holds the intermediate results for the second and the third loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'Does this approach work? Here are the runtimes for the original loop, interleaved
    loop and fissioned loop for various numbers of nested cosines, from 1 to 49 and
    1 M:'
  prefs: []
  type: TYPE_NORMAL
- en: Our new version is better than the original version, but not than the interleaved
    version. Interleaved version is still better. But notice the outlier for the really
    long dependency chain of 1 M nested cosines. This requires some additional investigation.
  prefs: []
  type: TYPE_NORMAL
- en: Because of the way we wrote our test, the size of the input array depends on
    the number of nested cosines. For one nested cosine, the size of the input array
    is 60 M elements, for two nested cosines the size of the input array is 30 M elements,
    for N nested cosines the size of the input array is 60 M divided by N. So, for
    1 M nested cosines, the size of the input array is only 60.
  prefs: []
  type: TYPE_NORMAL
- en: The memory subsystem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since the size of our temporary buffer is the size of the input array, and we
    read from the buffer and write to it many times, this makes a lot of data moving
    in and out of the memory subsystem. And the performance depends on the which part
    of the memory subsystem the data is coming from. If it is from L1 cache, the loop
    will be fast, if it is from memory, the loop will be slow.
  prefs: []
  type: TYPE_NORMAL
- en: We can easily check where the data is coming from using LIKWID measurement group
    L2CACHE. There is a measurement called *L2 Request Rate* which is number of L2
    requests made per executed instruction. For 10 nested cosines, this number is
    0.011 for the original and interleaved versions and 0.3 for our version. Ouch!
  prefs: []
  type: TYPE_NORMAL
- en: A smaller temporary buffer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The solution is to make our temporary buffer smaller, so it fits L1 cache. The
    size of L1 cache is about 16 kB, so we need to keep our temporary buffer smaller
    than this number.
  prefs: []
  type: TYPE_NORMAL
- en: 'If our input buffer was smaller, we would need a smaller temporary buffer.
    And we can make our input buffer smaller! We just need to process our input data
    in blocks. The first block is e.g. first 128 values from the input, second block
    is next 128 values in the input, etc. This technique is called *loop blocking*,
    because data is processed in blocks. After blocking, our processing loop looks
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The outer loop works on a block level, and the inner loops process data within
    blocks. Here are the performance numbers with loop fission + loop blocking:'
  prefs: []
  type: TYPE_NORMAL
- en: Now this looks better! The last version, with fission and blocking is the fastest!
  prefs: []
  type: TYPE_NORMAL
- en: '*Like what you are reading? Follow us on [LinkedIn](https://www.linkedin.com/company/johnysswlab)
    , [Twitter](https://twitter.com/johnnysswlab) or [Mastodon](https://mastodon.online/@johnnysswlab)
    and get notified as soon as new content becomes available.'
  prefs: []
  type: TYPE_NORMAL
- en: Need help with software performance? [Contact us](https://johnnysswlab.com/contact/)!*
  prefs: []
  type: TYPE_NORMAL
