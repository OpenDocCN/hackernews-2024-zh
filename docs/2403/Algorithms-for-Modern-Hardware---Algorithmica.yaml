- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 15:01:34'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Algorithms for Modern Hardware - Algorithmica
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://en.algorithmica.org/hpc/](https://en.algorithmica.org/hpc/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is an upcoming high performance computing book titled “Algorithms for Modern
    Hardware” by [Sergey Slotin](http://sereja.me/).
  prefs: []
  type: TYPE_NORMAL
- en: Its intended audience is everyone from performance engineers and practical algorithm
    researchers to undergraduate computer science students who have just finished
    an advanced algorithms course and want to learn more practical ways to speed up
    a program than by going from $O(n \log n)$ to $O(n \log \log n)$.
  prefs: []
  type: TYPE_NORMAL
- en: All book materials are [hosted on GitHub](https://github.com/algorithmica-org/algorithmica),
    with code in a [separate repository](https://github.com/sslotin/scmm-code). This
    isn’t a collaborative project, but any contributions and feedback are very much
    welcome.
  prefs: []
  type: TYPE_NORMAL
- en: FAQ
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Bug/typo fixes.** If you spot an error on any page, please do one of these
    — in the order of preference:'
  prefs: []
  type: TYPE_NORMAL
- en: fix it right away by either clicking on the pencil icon on the top right on
    any page (opens the [Prose](https://prose.io/) editor) or, more traditionally,
    by modifying the page directly on GitHub (the link to the source is also on the
    top right);
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: create [an issue on GitHub](https://github.com/algorithmica-org/algorithmica/issues);
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[tell me](http://sereja.me/) about it directly;'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: or leave a comment on some other website where it is being discussed — I read
    most of [HackerNews](https://news.ycombinator.com/from?site=algorithmica.org),
    [CodeForces](https://codeforces.com/profile/sslotin), and [Twitter](https://twitter.com/sergey_slotin)
    threads where I’m tagged.
  prefs: []
  type: TYPE_NORMAL
- en: '**Release date.** The book is split into several parts that I plan to finish
    sequentially with long breaks in-between. Part I, Performance Engineering, is
    ~75% complete as of March 2022 and will hopefully be >95% complete by this summer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A “release” for an open-source book like this essentially means:'
  prefs: []
  type: TYPE_NORMAL
- en: finishing all essential sections and filling all the TODOs,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: mostly freezing the table of contents (except for the case studies),
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: doing one final round of heavy copyediting (hopefully, with the help of a professional
    editor — I still haven’t figured out how commas work in English),
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: drawing illustrations (I stole a lot of those that are currently displayed),
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: making a print-optimized PDF and figuring out the best way to distribute it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: After that, I will mostly be fixing errors and only doing some minor edits reflecting
    the changes in technology or new algorithm advancements. The e-book/printed editions
    will most likely be sold on a “pay what you want” basis, and in any case, the
    web version will always be fully available online.
  prefs: []
  type: TYPE_NORMAL
- en: '**Pre-ordering / financially supporting the book.** Due to my unfortunate citizenship
    and place of birth, you can’t — that is, until I find a way that at the same time
    complies with international sanctions, doesn’t sponsor [the war](https://en.wikipedia.org/wiki/2022_Russian_invasion_of_Ukraine),
    and won’t put me in prison for tax evasion.'
  prefs: []
  type: TYPE_NORMAL
- en: So, don’t bother. If you want to support this book, just share it and help fix
    typos — that would be enough.
  prefs: []
  type: TYPE_NORMAL
- en: '**Translations.** The website has a separate functionality for creating and
    managing translations — and I’ve already been contacted by some nice people willing
    to translate the book into Italian and Chinese (and I will personally translate
    at least some of it into my native Russian).'
  prefs: []
  type: TYPE_NORMAL
- en: However, as the book is still evolving, it is probably not the best idea to
    start translating it at least until Part I is finished. That said, you are very
    much encouraged to make translations of any articles and publish them in your
    blogs — just send me the link so that we can merge it back when centralized translation
    starts.
  prefs: []
  type: TYPE_NORMAL
- en: '**“Translating” the Russian version.** The articles hosted at [ru.algorithmica.org/cs/](https://ru.algorithmica.org/cs/)
    are not about advanced performance engineering but mostly about classical computer
    science algorithms — without discussing how to speed them up beyond asymptotic
    complexity. Most of the information there is not unique and already exists in
    English on some other places on the internet: for example, the similar-spirited
    [cp-algorithms.com](https://cp-algorithms.com/).'
  prefs: []
  type: TYPE_NORMAL
- en: '**Teaching performance engineering in colleges.** One of my goals for writing
    this book is to change the way computer science — algorithm design, to be more
    precise — is taught in colleges. Let me elaborate on that.'
  prefs: []
  type: TYPE_NORMAL
- en: There are two highly impactful textbooks on which most computer science courses
    are built. Both are undoubtedly outstanding, but [one of them](https://en.wikipedia.org/wiki/The_Art_of_Computer_Programming)
    is 50 years old, and [the other](https://en.wikipedia.org/wiki/Introduction_to_Algorithms)
    is 30 years old, and [computers have changed a lot](/hpc/complexity/hardware)
    since then. Asymptotic complexity is not the sole deciding factor anymore. In
    modern practical algorithm design, you choose the approach that makes better use
    of different types of parallelism available in the hardware over the one that
    theoretically does fewer raw operations on galaxy-scale inputs.
  prefs: []
  type: TYPE_NORMAL
- en: And yet, the computer science curricula in most colleges completely ignore this
    shift. Although there are some great courses that aim to correct that — such as
    “[Performance Engineering of Software Systems](https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-172-performance-engineering-of-software-systems-fall-2018/)”
    from MIT, “[Programming Parallel Computers](https://ppc.cs.aalto.fi/)” from Aalto
    University, and some non-academic ones like Denis Bakhvalov’s “[Performance Ninja](https://github.com/dendibakh/perf-ninja)”
    — most computer science graduates still treat modern hardware like something from
    the 1990s.
  prefs: []
  type: TYPE_NORMAL
- en: 'What I really want to achieve is that performance engineering becomes taught
    right after introduction to algorithms. Writing the first comprehensive textbook
    on the subject is a large part of it, and this is why I rush to finish it by the
    summer so that the colleges can pick it up in the next academic year. But creating
    a new course requires more than that: you need a balanced curriculum, course infrastructure,
    lecture slides, lab assignments… so for some time after finishing the main book,
    I will be working on course materials and tools for *teaching* performance engineering
    — and I’m looking forward to collaborating with other people who want to make
    it a reality as well.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Part I: Performance Engineering'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first part covers the basics of computer architecture and optimization of
    single-threaded algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: It walks through the main CPU optimization topics such as caching, SIMD, and
    pipelining, and provides brief examples in C++, followed by large case studies
    where we usually achieve a significant speedup over some STL algorithm or data
    structure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Planned table of contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Among the cool things that we will speed up:'
  prefs: []
  type: TYPE_NORMAL
- en: 2x faster GCD (compared to `std::gcd`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 8-15x faster binary search (compared to `std::lower_bound`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 5-10x faster segment trees (compared to Fenwick trees)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 5x faster hash tables (compared to `std::unordered_map`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2x faster popcount (compared to repeatedly calling `popcnt`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 35x faster parsing series of integers (compared to `scanf`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ?x faster sorting (compared to `std::sort`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2x faster sum (compared to `std::accumulate`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 2-3x faster prefix sum (compared to naive implementation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10x faster argmin (compared to naive implementation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 10x faster array searching (compared to `std::find`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 15x faster search tree (compared to `std::set`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 100x faster matrix multiplication (compared to “for-for-for”)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: optimal word-size integer factorization (~0.4ms per 60-bit integer)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: optimal Karatsuba Algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: optimal FFT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Volume: 450-600 pages'
  prefs: []
  type: TYPE_NORMAL
- en: 'Release date: Q3 2022'
  prefs: []
  type: TYPE_NORMAL
- en: 'Part II: Parallel Algorithms'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Concurrency, models of parallelism, context switching, green threads, concurrent
    runtimes, cache coherence, synchronization primitives, OpenMP, reductions, scans,
    list ranking, graph algorithms, lock-free data structures, heterogeneous computing,
    CUDA, kernels, warps, blocks, matrix multiplication, sorting.
  prefs: []
  type: TYPE_NORMAL
- en: 'Volume: 150-200 pages'
  prefs: []
  type: TYPE_NORMAL
- en: 'Release date: 2023-2024?'
  prefs: []
  type: TYPE_NORMAL
- en: 'Part III: Distributed Computing'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Metworking, message passing, actor model, communication-constrained algorithms,
    distributed primitives, all-reduce, MapReduce, stream processing, query planning,
    storage, sharding, compression, distributed databases, consistency, reliability,
    scheduling, workflow engines, cloud computing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Release date: ??? (more likely to be completed than not)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Part IV: Software & Hardware'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LLVM IR, compiler optimizations & back-end, interpreters, JIT-compilation, Cython,
    JAX, Numba, Julia, OpenCL, DPC++, oneAPI, XLA, (basic) Verilog, FPGAs, ASICs,
    TPUs and other AI accelerators.
  prefs: []
  type: TYPE_NORMAL
- en: 'Release date: ??? (less likely to be completed than not)'
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The book is largely based on blog posts, research papers, conference talks,
    and other work authored by a lot of people:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Disclaimer: Technology Choices'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The examples in this book use C++, GCC, x86-64, CUDA, and Spark, although the
    underlying principles conveyed are not specific to them.
  prefs: []
  type: TYPE_NORMAL
- en: 'To clear my conscience, I’m not happy with any of these choices: these technologies
    just happen to be the most widespread and stable at the moment and thus more helpful
    to the reader. I would have respectively picked C / Rust / [Carbon?](https://github.com/carbon-language/carbon-lang),
    LLVM, arm, OpenCL, and Dask; maybe there will be a 2nd edition in which some of
    the tech stack is changed.'
  prefs: []
  type: TYPE_NORMAL
