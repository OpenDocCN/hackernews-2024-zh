<!--yml

类别：未分类

日期：2024-05-27 14:33:56

-->

# 顶尖AI在IQ测试中仍然失败【当要求读取基于图像的问题时】

> 来源：[https://www.maximumtruth.org/p/top-ais-still-fail-iq-tests](https://www.maximumtruth.org/p/top-ais-still-fail-iq-tests)

***[注：请参见更新[此处](https://www.maximumtruth.org/p/ais-ranked-by-iq-ai-passes-100-iq)。虽然所有AI在图像为基础的IQ测试中失败，但当相同测试“口头化”时，最好的AI现在可以通过，这描绘了一个非常不同的图景。]***

我对以下结果感到惊讶。

我给ChatGPT-4和谷歌的“Gemini Advanced”做了IQ测试。首先，我给它们进行了**[这个](https://www.mensa.org/public/mensa-iq-challenge)**由挪威Mensa提供的IQ测试。

我在听了**[Dwarkesh podcast](https://www.dwarkeshpatel.com/p/will-scaling-work)**后受到启发，其中指出大型AI基准测试仅仅是“记忆力的好测试，并非智力的好测试”，它们给AI的问题是诸如：

> Q：比尔·克林顿出生时，美国总统是谁？
> 
> A：哈里·杜鲁门

他继续指出，

> 为什么一个训练在充满随机事实的互联网文本上的模型恰好记住了很多随机事实，这值得称赞吗？……这在任何情况下都表明智能或创造力吗？

这是一个很好的观点。大多数AI的力量来自于它巨大的数据库和模式匹配。AI真正的*智能*到底有多少？

我有一个网站（**[TrackingAI.org](https://TrackingAI.org)**），每天都向AI进行政治调查。因此，我可以轻松给AI进行真正的智力测试，并随时间跟踪。

当我开始手动给AI进行IQ测试时，我最担心的是它们可能会全部答对。毕竟，它们擅长计算机编程、数学、文章和艺术。它们可以阅读图像，而测试问题都可以在网上公开获取。

但后来我进行了测试。

两个AI的视觉空间智商得分均低于**85**，这是挪威Mensa测试的水平：

谷歌的“Gemini Advanced”表现得如此糟糕，放弃了很多问题，所以我决定不值得进一步测试。

ChatGPT-4在其回答中显示了一些推理能力，因此我给了它另一个测验，一个允许从IQ 75分开始评分的**[瑞典Mensa智商测试](https://mensa.se/provtest/)**。然而，ChatGPT-4仍然无法得分，在75分以下：

ChatGPT-4是否比随机更好？

它显示出一些理解的迹象，为了减少变异，我给它进行了两次所有三个测试。以下是它与随机猜测者的比较情况：

**Mensa**  **挪威测试（35个问题；测试进行了两次）**

**Mensa**  **瑞典测试（24个问题；测试进行了两次）**

**Mensa**  **丹麦测试（39个问题；测试进行了两次）**

**所有测试问题汇总（总共196个）**

另一种说法是：在196个问题中，ChatGPT-4的正确答案比随机猜测者多约5个（39 vs 34.23）。

这有什么可能性？我忘了 15 年前在大学里学到的公式，所以我写了一个 Python 程序，运行了 100,000 次模拟，模拟了一个随机猜测者回答那 196 个问题。模拟显示，83.8% 的随机猜测者比 ChatGPT-4 做得更差。

因此，ChatGPT-4 可能有一点能力去捕捉 IQ 测试中的模式。

此外，ChatGPT-4 表现出了对简单问题的 *非常* *轻微* 能力，这与对 IQ 问题有非常轻微的回答能力是一致的：

我的结果与 **[这篇论文](https://arxiv.org/pdf/2302.14045.pdf)** 中报告的结果相当一致，该论文报告称，与随机机会相比，人工智能的准确率达到了 22%。研究人员还发现，当他们对 AI 有点偏袒，并以最符合 AI 的格式给出问题时，准确率提高到了 26%。

目前来说这并不令人印象深刻，因为低智商的人做得更好。

让我们看看我给他们的 IQ 测试问题中 AI 的推理过程。这里是 Mensa Norway 的第一个 —— 也是最容易的 —— 问题：

我猜你应该能看到模式并正确回答。测试给了你 42 秒的时间。

现在让我们看看 ChatGPT 的表现：

在这个简单的问题上，ChatGPT 正确描述了问题中的所有面板，并且逻辑上也十分精准。它甚至能够用语言正确描述答案。

然后，它继续误识别了所有的六个答案选项，导致它选择了错误的答案。它的误识别似乎毫无规律。我最好的猜测是，也许它注意到问题中的最后一个方块应该在第三行第三列有一个黑方块 —— 因此它产生了幻觉，认为最后一个答案选项也会有某些东西在第三行第三列。

至少 ChatGPT-4 在艺术方面表现不错！

对于像 ChatGPT-5 这样的未来人工智能来说，那个问题可能是相对容易解决的 —— 我相信未来的人工智能将能够正确阅读问题和答案。

但是，这也显示了人工智能在感知上仍然存在显著的漏洞，会犯下甚至是低于平均智力的人都不会犯的错误。

让我们看看第二容易的问题：

这里的规律也非常简单：每一行都有一个一致的外层（在最后一行，是一个正方形），并且每一行的内层也有一个一致的模式（从圆形 → 十字形 → 菱形）。因此，缺失的空间应该是一个有菱形的正方形。答案是 E。

ChatGPT-4 能够阅读图像，但并不聪明到能够理解其中的模式：

具体来说，它未能识别出圆形 → 十字形 → 菱形的内部模式，除了第一行。

它在逻辑和空间模式方面并不聪明。也许这不应该让人惊讶，考虑到人工智能仍然画出有三只手和六个手指的人？

在挪威门萨只有一个问题ChatGPT两次都答对了：问题13。这是它用正确的逻辑，并且能够看到答案的情况。

ChatGPT始终准确回答问题13，这些问题具有特别清晰、大的形状。这确实暗示了它问题的*一部分*是*视觉*的。未来研究的一个课题是：如果问题被口头明确解释给ChatGPT，它会表现得有多好？

谷歌的“**[Gemini Advanced](https://www.understandingai.org/p/gemini-advanced-is-not-that-advanced)**”无法理解所有问题。它只是愚蠢的：

昨天，蒂姆·李指出，**[Gemini Advanced](https://www.understandingai.org/p/gemini-advanced-is-not-that-advanced)** ***[甚至无法](https://www.understandingai.org/p/gemini-advanced-is-not-that-advanced)*** **[可靠地](https://www.understandingai.org/p/gemini-advanced-is-not-that-advanced)** 计算物体，因此，它在IQ测试中失败并不令人意外。

问题的一部分可能是ChatGPT的视力不好 — 视力差 — 但我们确实知道即使在其首选的口头问题领域中，它也远非完美。例如：

+   我让ChatGPT-4加起一串数字，例如，34 + 5.2 + 9 + 0.2 + 7.1 + 3 + 11 + 18.889 + 15.532 + 1.1 + 3。它回答错误了。

+   我问ChatGPT-4爱尔兰的环岛上的汽车是顺时针行驶还是逆时针行驶。它回答错误了。当我告诉它后，它道歉并给出了正确答案。但是接着我又聪明地提出了它的正确答案，它又道歉并回到了错误答案。从根本上讲，它知道爱尔兰人驾驶在道路左侧，但它不知道如何应用这一知识到环岛上找到行驶的圆周方向。可能因为没有人在线上讨论如何做出这样一个显而易见的联系。

有人可以继续提出这类让AI陷入困境的问题（如果你脑海中有任何问题，请在评论中发布；我正在整理一个口头AI智商测试的清单）。

我进入这个测试的假设是错误的。我认为我对AI解决大多数计算机编码问题——它在编码上比我好得多——以及从数学到医学问题等其他问题的期望很高。那么为什么它甚至不能回答最简单的IQ问题？

人们甚至可能认为AI在IQ测试中应该表现特别*好*。毕竟，基于**[LLM](https://www.britannica.com/topic/large-language-model)**的AI是每个单词的先进预测器，那么为什么它们不能也是IQ难题中下一个符号的良好预测器呢？

答案可能是训练。如果它们曾在数百万个智商难题上接受过训练，那么几十层AI神经元可能会以非常高效的方式激活，填补那个缺失的空间，甚至揭示最复杂和多阶段的问题。

但这表明了人工智能缺乏*广义*智能，它不能做这些问题。 毕竟，人类不需要专门在智商问题上接受培训 —— 实际上，为智商测试进行特殊培训违背了测试的初衷。 人工智能不能在没有专门培训的情况下通过测试显示，人工智能还没有我们人类所拥有的*广义*智能。

我怀疑人工智能公司并没有考虑专门为智商问题训练人工智能。 这是件好事，因为只要这种情况存在，这些测试可能是评估人工智能是否接近广义智能的一个不错的衡量标准。

一旦人工智能足够聪明以至于可以被评分，我将把它们的智商结果添加到TrackingAI.com。 (或者也许我会在此之前添加，使用上面提到的“与随机猜测者相比”的度量标准，而不是智商分数。)

我认为这可能会很有用，因为这些测试可能会给我们一些线索，关于何时以及我们是否应该担心人工智能变得普遍具有智能性，而不仅仅是在特定领域表现良好。

在技术圈子里，我听说有关可能拥有如神一般智商的人工智能可能会毁灭世界的可能性。 但是，即使它们具有大量知识，当前人工智能的智力水平更接近**[黑猩猩的智商](https://www.youtube.com/results?search_query=chimps+iq+test)**而不是约翰·冯·诺依曼。

[分享](https://www.maximumtruth.org/p/top-ais-still-fail-iq-tests?utm_source=substack&utm_medium=email&utm_content=share&action=share)

上述内容使我更加乐观，我们在人工智能普遍具有智能性和完全颠覆之前还有一些时间。

我认为这也支持罗宾·汉森的**[论点](https://www.youtube.com/watch?v=U1RZknHchi0)**，即全能人工智能并不是那么接近，我们应该小心不要在其摇篮期过度监管人工智能，这可能会扼杀它。这正是监管者对核能产业所做的事情。

所以我同意我们应该观望和等待来进行监管，特别是考虑到目前人工智能甚至无法获取智商分数。

另一个需要考虑的因素是斯科特·亚历山大有关需要巨大能量来进一步扩展人工智能的**[计算](https://www.astralcodexten.com/p/sam-altman-wants-7-trillion)**：

> GPT-5可能需要全世界计算机的大约1%能力，相当于一个小型电力厂的能源，并且需要大量的训练数据。 *[注：这里的每个额外的GPT数字表示了数量级的提升。]*
> 
> GPT-6可能需要全世界计算机的大约10%能力，相当于一个大型电力厂的能源，并且需要比现有的训练数据更多。 可能看起来像一个连接到许多太阳能电池板或核反应堆的城镇大小的数据中心...
> 
> GPT-7可能需要全世界所有计算机的能力，一个超大规模的电力厂，远远超过当前存在的任何电厂，并且比存在的任何培训数据都需要更多。 可能看起来像一个连接到核聚变电厂的城市大小的数据中心。
> 
> 目前要构建 GPT-8 是不可能的。即使你解决了合成数据和聚变能源，并掌控整个半导体行业，也无济于事。你唯一的希望是 GPT-7 是超智能的，能帮你解决这个问题……

那么，下一个主要的 GPT 模型是否会让人工智能能够在智商测试中获得可评分的结果？目前尚不清楚，但我将密切关注。

知道有人会喜欢这篇文章吗？这篇文章是公开的，所以请随意分享！

[分享](https://www.maximumtruth.org/p/top-ais-still-fail-iq-tests?utm_source=substack&utm_medium=email&utm_content=share&action=share)
