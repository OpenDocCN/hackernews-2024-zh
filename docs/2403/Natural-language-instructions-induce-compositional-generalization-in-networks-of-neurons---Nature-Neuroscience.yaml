- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-29 12:29:31'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-29 12:29:31'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Natural language instructions induce compositional generalization in networks
    of neurons | Nature Neuroscience
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自然语言指令诱导神经网络中的组合泛化 | 自然神经科学
- en: 来源：[https://www.nature.com/articles/s41593-024-01607-5](https://www.nature.com/articles/s41593-024-01607-5)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.nature.com/articles/s41593-024-01607-5](https://www.nature.com/articles/s41593-024-01607-5)
- en: Model architecture
  id: totrans-split-6
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型架构
- en: Sensorimotor-RNN
  id: totrans-split-7
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 感觉运动-RNN
- en: 'The base model architecture and task structure used in this paper follows^([18](/articles/s41593-024-01607-5#ref-CR18
    "Yang, G. R., Joglekar, M. R., Song, H. F., Newsome, W. T. & Wang, X.-J. Task
    representations in neural networks trained to perform many cognitive tasks. Nat.
    Neurosci. 22, 297–306 (2019).")). All networks of sensorimotor units denoted sensorimotor-RNN
    are gated recurrent units (GRU)^([49](/articles/s41593-024-01607-5#ref-CR49 "Chung,
    J., Gulcehre, C., Cho, K. & Bengio, Y. Empirical evaluation of gated recurrent
    neural networks on sequence modeling. Preprint at                    https://arxiv.org/abs/1412.3555                                     (2014)."))
    using rectified linear unit (ReLU) nonlinearities with 256 hidden units each.
    Inputs to the networks consist of (1) sensory inputs, *X*[*t*] and (2) task-identifying
    information, *I*[*t*]. We initialize hidden activity in the GRU as \({h}^{0}\in
    {{\mathbb{R}}}^{256}\) with values set to 0.1\. All networks of sensorimotor units
    use the same hidden state initialization, so we omit *h*⁰ in network equations.
    At each time step, a readout layer Linear[out] decodes motor activity, \(\hat{{y}_{t}}\),
    from the activity of recurrent hidden units, *h*[*t*], according to:'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中使用的基础模型架构和任务结构遵循^([18](/articles/s41593-024-01607-5#ref-CR18 "Yang, G. R.,
    Joglekar, M. R., Song, H. F., Newsome, W. T. & Wang, X.-J. Task representations
    in neural networks trained to perform many cognitive tasks. Nat. Neurosci. 22,
    297–306 (2019)."))。所有传感运动单元网络均为门控循环单元（GRU）^([49](/articles/s41593-024-01607-5#ref-CR49
    "Chung, J., Gulcehre, C., Cho, K. & Bengio, Y. Empirical evaluation of gated recurrent
    neural networks on sequence modeling. Preprint at                    https://arxiv.org/abs/1412.3555                                     (2014)."))，使用具有256个隐藏单元的修正线性单元（ReLU）非线性。网络的输入包括（1）感觉输入*X*[t]和（2）任务标识信息*I*[t]。我们将GRU中的隐藏活动初始化为\({h}^{0}\in
    {{\mathbb{R}}}^{256}\)，其值设置为0.1。所有传感运动单元网络使用相同的隐藏状态初始化，因此我们在网络方程中省略*h*⁰。在每个时间步，一个读出层Linear[out]根据循环隐藏单元*h*[*t*]的活动解码运动活动\(\hat{{y}_{t}}\)如下：
- en: $$\begin{array}{ll}{h}_{t}={{{\rm{SensorimotorRNN}}}}\Big({X}_{t},{I}_{t};{h}_{t-1}\Big)\qquad\qquad{h}_{t}\in
    {{\mathbb{R}}}^{256}\\ {\hat{y}}_{t}=\sigma \Big({{{{\rm{Linear}}}}}_{{{{\rm{out}}}}}({h}_{t})\Big)\qquad\qquad\qquad\qquad\qquad\quad{\hat{y}}_{t}\in
    {{\mathbb{R}}}^{33}\end{array}$$
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: $$\begin{array}{ll}{h}_{t}={{{\rm{SensorimotorRNN}}}}\Big({X}_{t},{I}_{t};{h}_{t-1}\Big)\qquad\qquad{h}_{t}\in
    {{\mathbb{R}}}^{256}\\ {\hat{y}}_{t}=\sigma \Big({{{{\rm{Linear}}}}}_{{{{\rm{out}}}}}({h}_{t})\Big)\qquad\qquad\qquad\qquad\qquad\quad{\hat{y}}_{t}\in
    {{\mathbb{R}}}^{33}\end{array}$$
- en: where *σ* denotes the sigmoid function. Sensory inputs *X*[*t*] are made up
    of three channels, two sensory modalities \({x}_{{{\mathrm{mod}}}\,1,t}\) and
    \({x}_{{{\mathrm{mod}}}\,2,t}\), and a fixation channel *x*[fix,*t*]. Both \({x}_{{{\mathrm{mod}}}\,1,t},{x}_{{{\mathrm{mod}}}\,2,t}\in
    {{\mathbb{R}}}^{32}\) and stimuli in these modalities are represented as hills
    of activity with peaks determined by units’ preferred directions around a one-dimensional
    circular variable. For an input at direction *θ*, the activity of a given input
    unit *u*[*i*] with preferred direction *θ*[*i*] is
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*σ*表示sigmoid函数。感觉输入*X*[t]由三个通道组成，两个感觉模态\({x}_{{{\mathrm{mod}}}\,1,t}\)和\({x}_{{{\mathrm{mod}}}\,2,t}\)，以及一个固定通道*x*[fix,*t*]。这两个模态\({x}_{{{\mathrm{mod}}}\,1,t}\)和\({x}_{{{\mathrm{mod}}}\,2,t}\in
    {{\mathbb{R}}}^{32}\)，这些模态的刺激被表示为在一个一维圆形变量周围的单位偏好方向的活动山峰。对于方向*θ*的输入，给定输入单元*u*[i]的活动与其偏好方向*θ*[i]为
- en: $${u}_{i}=str \times 0.8\exp \left[-0.5 \times {\left(\frac{8| \theta -{\theta
    }_{i}| }{\pi }\right)}^{2}\right]$$
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: $${u}_{i}=str \times 0.8\exp \left[-0.5 \times {\left(\frac{8| \theta -{\theta
    }_{i}| }{\pi }\right)}^{2}\right]$$
- en: where *s**t**r* is the coefficient describing stimulus strength. The fixation
    channel \({x}_{{{{\rm{fix}}}},t}\in {{\mathbb{R}}}^{1}\) is a single unit simulating
    a fixation cue for the network. In all, sensory input \({X}_{t}=({x}_{mod1,t},{x}_{mod2,t},{x}_{fix,t})\in
    {{\mathbb{R}}}^{65}\). Motor output, \({\hat{{y}}_{t}}\) consists of both a 32-dimensional
    ring representing directional responses to the input stimulus as well as a single
    unit representing model fixation, so that \({\hat{{y}}_{t}}\in {{\mathbb{R}}}^{33}\).
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 *s**t**r* 是描述刺激强度的系数。定位通道 \({x}_{{{{\rm{fix}}}},t}\in {{\mathbb{R}}}^{1}\)
    是一个单一单元，模拟网络的注视提示。总体而言，感觉输入 \({X}_{t}=({x}_{mod1,t},{x}_{mod2,t},{x}_{fix,t})\in
    {{\mathbb{R}}}^{65}\)。运动输出 \({\hat{{y}}_{t}}\) 包括一个32维环，表示对输入刺激的方向响应，以及一个单元表示模型的注视，因此
    \({\hat{{y}}_{t}}\in {{\mathbb{R}}}^{33}\)。
- en: For all models, task-identifying information \({I}_{t}\in {{\mathbb{R}}}^{64}\).
    Task-identifying information is presented throughout the duration of a trial and
    remains constant such that \({I}_{t}={I}_{t{\prime} }\forall t,t{\prime}\). For
    all models, task-identifying info *I*[*t*] and sensory input *X*[*t*] are concatenated
    as inputs to the sensorimotor-RNN.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有模型，任务识别信息\({I}_{t}\in {{\mathbb{R}}}^{64}\)。任务识别信息在试验持续时间内一直存在，并保持不变，即\({I}_{t}={I}_{t{\prime}
    }\forall t,t{\prime}\)。对于所有模型，任务识别信息 *I*[*t*] 和感觉输入 *X*[*t*] 被连接作为传感运动-RNN的输入。
- en: Nonlinguistic models
  id: totrans-split-14
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 非语言模型
- en: For SIMPLENET, we generate a set of 64-dimensional orthogonal task rules by
    constructing an orthogonal matrix using the Python package scipy.stats.ortho_group,
    and assign rows of this matrix to each task type. For STRUCTURENET, we generate
    a set of ten orthogonal, 64-dimensional vectors in the same manner, and each of
    these represents a dimension of the task set (that is, respond weakest versus
    strongest direction, respond in the same versus opposite direction, pay attention
    only to stimuli in the first modality, and so on). Rule vectors for tasks are
    then simple combinations of each of these ten basis vectors. For a full description
    of structure rule vectors, see Supplementary Note [3](/articles/s41593-024-01607-5#MOESM1).
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 对于SIMPLENET，我们通过使用Python包scipy.stats.ortho_group构造正交矩阵生成一组64维正交任务规则，并将该矩阵的行分配给每种任务类型。对于STRUCTURENET，我们以相同方式生成十个正交的64维向量，每个向量代表任务集的一个维度（即，对输入最弱与最强方向的响应，以相同或相反方向响应，在第一模态中仅关注刺激等）。任务的规则向量然后是这十个基向量的简单组合。有关结构规则向量的完整描述，请参阅附注[3](/articles/s41593-024-01607-5#MOESM1)。
- en: We also test SIMPLENETPLUS and STRUCTURENETPLUS, which use an additional hidden
    layer with 128 units and ReLU nonlinearities to process orthogonal tasks rules
    *I*[*t*] into a vector \(\bar{{I}_{t}}\) which is used by sensorimotor-RNN as
    task-identifying information.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还测试了SIMPLENETPLUS和STRUCTURENETPLUS，它们使用具有128个单元和ReLU非线性的额外隐藏层来处理正交任务规则 *I*[*t*]，生成一个向量
    \(\bar{{I}_{t}}\)，该向量作为传感运动-RNN的任务识别信息。
- en: $$\begin{array}{ll}{\bar{{I}_{t}}}^{{\prime} }=\rm{ReLU}({{{{\rm{Linear}}}}}_{{{{\rm{RuleEmb}}}}1}({I}_{t}))&{\bar{{I}_{t}}}^{{\prime}
    }\in {{\mathbb{R}}}^{128}\\ {\bar{{I}_{t}}}^{{\prime} }=\rm{ReLU}({{{{\rm{Linear}}}}}_{{{{\rm{RuleEmb}}}}2}({I}_{t}^{{\prime}
    }))&{\bar{{I}_{t}}}^{{\prime} }\in {{\mathbb{R}}}^{128}\\ \bar{{I}_{t}}=\rm{ReLU}({{{{\rm{Linear}}}}}_{{{{\rm{RuleEmb}}}}3}({\bar{{I}_{t}}}^{{\prime}
    }))&\bar{{I}_{t}}\in {{\mathbb{R}}}^{64}\end{array}$$
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: $$\begin{array}{ll}{\bar{{I}_{t}}}^{{\prime} }=\rm{ReLU}({{{{\rm{Linear}}}}}_{{{{\rm{RuleEmb}}}}1}({I}_{t}))&{\bar{{I}_{t}}}^{{\prime}
    }\in {{\mathbb{R}}}^{128}\\ {\bar{{I}_{t}}}^{{\prime} }=\rm{ReLU}({{{{\rm{Linear}}}}}_{{{{\rm{RuleEmb}}}}2}({I}_{t}^{{\prime}
    }))&{\bar{{I}_{t}}}^{{\prime} }\in {{\mathbb{R}}}^{128}\\ \bar{{I}_{t}}=\rm{ReLU}({{{{\rm{Linear}}}}}_{{{{\rm{RuleEmb}}}}3}({\bar{{I}_{t}}}^{{\prime}
    }))&\bar{{I}_{t}}\in {{\mathbb{R}}}^{64}\end{array}$$
- en: Full results for these models are included in Supplementary Fig. [4](/articles/s41593-024-01607-5#MOESM1).
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型的完整结果包含在附图[4](/articles/s41593-024-01607-5#MOESM1)中。
- en: Pretrained transformers
  id: totrans-split-19
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 预训练变换器
- en: 'The main language models we test use pretrained transformer architectures to
    produce *I*. Importantly, transformers differ in the type of pretraining objective
    used to tune the model parameters. GPT is trained to predict the next word given
    a context of words^([9](/articles/s41593-024-01607-5#ref-CR9 "Radford, A. et al.
    Language models are unsupervised multitask learners. OpenAI 1, 9 (2019).")). GPT
    (XL) follows the same objective but trains for longer on a larger dataset^([50](/articles/s41593-024-01607-5#ref-CR50
    "Radford, A. et al. Better language models and their implications.                    https://openai.com/blog/better-language-models/                                     (2019).")).
    Both models are fully autoregressive. BERT, by contrast, takes bidirectional language
    inputs and is tasked with predicting masked words that appear in the middle of
    input phrases. Additionally, BERT is trained on a simple sentence prediction task
    where the model must determine if input sentence 1 is followed by input sentence
    2 in the training corpus. Extending this principle, SBERT is explicitly trained
    to produce fixed-length embeddings of whole sentences^([21](/articles/s41593-024-01607-5#ref-CR21
    "Reimers, N. & Gurevych, I. Sentence-bert: Sentence embeddings using siamese bert-networks.
    Preprint at                    https://arxiv.org/abs/1908.10084                                     (2019).")).
    It takes pretrained BERT networks and uses them in a siamese architecture^([51](/articles/s41593-024-01607-5#ref-CR51
    "Bromley, J. et al. Signature verification using a ‘siamese’ time delay neural
    network. Int. J. Pattern Recognit. Artif. Intell. 7, 669–688 (1993).")), which
    allows the weights of the model to be tuned in a supervised fashion according
    to the Stanford Natural Language Inference dataset^([22](/articles/s41593-024-01607-5#ref-CR22
    "Bowman, S. R., Angeli, G., Potts, C. & Manning, C. D. A large annotated corpus
    for learning natural language inference. Preprint at                    http://arxiv.org/abs/1508.05326                                     (2015).")).
    Natural language inference is a three-way categorization task where the network
    must infer the logical relationship between sentences: whether a premise sentence
    implies, contradicts or is unrelated to a hypothesis sentence. Finally, CLIP is
    trained to jointly embed images and language^([23](/articles/s41593-024-01607-5#ref-CR23
    "Radford, A. et al. "Learning transferable visual models from natural language
    supervision. In Proc. 38th International Conference on Machine Learning (eds Marina,
    M. & Tong, Z.) 8748–8763 (PMLR, 2021).")). It uses data from captioned images
    and is asked to properly categorize which text and images pairs match or are mismatched
    in the dataset via a contrastive loss.'
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: '我们测试的主要语言模型使用预训练的变压器架构来生成*I*。变压器的预训练目标类型不同，用于调整模型参数。GPT被训练为根据单词上下文预测下一个单词^([9](/articles/s41593-024-01607-5#ref-CR9
    "Radford, A. et al. 语言模型是无监督的多任务学习者。OpenAI 1, 9 (2019)."))。GPT (XL)遵循相同的目标，但在更大的数据集上进行更长时间的训练^([50](/articles/s41593-024-01607-5#ref-CR50
    "Radford, A. et al. 更好的语言模型及其影响。https://openai.com/blog/better-language-models/
    (2019)."))。这两种模型都是完全自回归的。相比之下，BERT接受双向语言输入，并任务是预测出现在输入短语中间的屏蔽单词。此外，BERT还在一个简单的句子预测任务上进行训练，其中模型必须确定训练语料库中输入句子1是否跟在输入句子2后面。基于这个原理，SBERT明确地训练以生成整个句子的固定长度嵌入^([21](/articles/s41593-024-01607-5#ref-CR21
    "Reimers, N. & Gurevych, I. Sentence-bert: 使用siamese bert-networks生成句子嵌入。预印本https://arxiv.org/abs/1908.10084
    (2019)."))。它采用预训练的BERT网络，并在一个孪生结构中使用它们^([51](/articles/s41593-024-01607-5#ref-CR51
    "Bromley, J. et al. 使用“孪生”时延神经网络进行签名验证。Int. J. Pattern Recognit. Artif. Intell.
    7, 669–688 (1993)."))，这允许模型的权重按照斯坦福自然语言推理数据集的监督方式进行调整。自然语言推理是一个三分类任务，网络必须推断句子之间的逻辑关系：前提句是否暗示、与假设句矛盾或无关。最后，CLIP被训练以联合嵌入图像和语言^([23](/articles/s41593-024-01607-5#ref-CR23
    "Radford, A. et al. 从自然语言监督中学习可传递的视觉模型。在Proc.第38届国际机器学习会议上（eds Marina, M. & Tong,
    Z.）8748–8763（PMLR，2021年）。"))。它使用来自带标题的图像数据，并要求通过对比损失适当地分类数据集中哪些文本和图像配对是匹配或不匹配的。'
- en: Importantly, the natural output of a transformer is a matrix of size \({\dim
    }_{{{{\rm{trans}}}}.}\times {{{\mathcal{T}}}}\), the inherent dimensionality of
    the transformer by the length of the input sequence. To create an embedding space
    for sentences it is standard practice to apply a pooling method to the transformer
    output, which produces a fixed-length representation for each instruction.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，变压器的自然输出是一个大小为\({\dim }_{{{{\rm{trans}}}}.}\times {{{\mathcal{T}}}}\)的矩阵，这反映了输入序列长度对变压器的固有维度。为了为句子创建嵌入空间，通常会对变压器输出应用池化方法，从而为每个指令生成固定长度的表示。
- en: 'For GPT, GPT (XL), BERT and SBERT, we use an average pooling method. Suppose
    we have an input instruction \({w}_{1}\ldots {w}_{{{{\mathcal{T}}}}}\). Following
    standard practice with pretrained language models, the input to our transformers
    is tokenized with special ‘cls’ and ‘eos’ tokens at the beginning and end of the
    input sequence. We then compute *I* as follows:'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 对于GPT、GPT (XL)、BERT和SBERT，我们使用平均池化方法。假设我们有一个输入指令\({w}_{1}\ldots {w}_{{{{\mathcal{T}}}}}\)。按照预训练语言模型的标准做法，我们的变压器输入在序列的开头和结尾处使用特殊的‘cls’和‘eos’标记进行标记。然后我们计算
    *I* 如下：
- en: $$\begin{array}{ll}{h}^{\rm{tran.}}={{{\rm{transformer}}}}\Big({{\mbox{[cls]}}}\,,{w}_{1}\ldots
    {w}_{{{{\mathcal{T}}}}},\,{{\mbox{[eos]}}}\Big),\qquad{h}^{\rm{tran.}}\in {{\mathbb{R}}}^{{\dim
    }_{{{{\rm{trans}}}}.}\times {{{\mathcal{T}}}}+2}\\ {h}^{I}={{{\rm{mean}}}}({h}^{\rm{tran.}}),\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad{h}^{I}\in
    {{\mathbb{R}}}^{{\dim }_{{{{{\rm{trans}}}}}.}}\\ I={{{{\rm{Linear}}}}}_{{{{\rm{embed}}}}}({h}^{I})\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\quad
    I\in {{\mathbb{R}}}^{64}\end{array}$$
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: $$\begin{array}{ll}{h}^{\rm{tran.}}={{{\rm{transformer}}}}\Big({{\mbox{[cls]}}}\,,{w}_{1}\ldots
    {w}_{{{{\mathcal{T}}}}},\,{{\mbox{[eos]}}}\Big),\qquad{h}^{\rm{tran.}}\in {{\mathbb{R}}}^{{\dim
    }_{{{{\rm{trans}}}}.}\times {{{\mathcal{T}}}}+2}\\ {h}^{I}={{{\rm{mean}}}}({h}^{\rm{tran.}}),\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad{h}^{I}\in
    {{\mathbb{R}}}^{{\dim }_{{{{{\rm{trans}}}}}.}}\\ I={{{{\rm{Linear}}}}}_{{{{\rm{embed}}}}}({h}^{I})\qquad\qquad\qquad\qquad\qquad\qquad\qquad\qquad\quad
    I\in {{\mathbb{R}}}^{64}\end{array}$$
- en: 'We chose this average pooling method primarily because a previous study^([21](/articles/s41593-024-01607-5#ref-CR21
    "Reimers, N. & Gurevych, I. Sentence-bert: Sentence embeddings using siamese bert-networks.
    Preprint at                    https://arxiv.org/abs/1908.10084                                     (2019)."))
    found that this resulted in the highest-performing SBERT embeddings. Another alternative
    would be to simply use the final hidden representation of the ‘cls’ token as a
    summary of the information in the entire sequence (given that BERT architectures
    are bidirectional, this token will have access to the whole sequence).'
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: '我们选择这种平均池化方法主要是因为一项先前的研究^([21](/articles/s41593-024-01607-5#ref-CR21 "Reimers,
    N. & Gurevych, I. Sentence-bert: Sentence embeddings using siamese bert-networks.
    Preprint at                    https://arxiv.org/abs/1908.10084                                     (2019)."))
    发现这种方法产生了性能最佳的SBERT嵌入。另一种选择是简单地使用‘cls’标记的最终隐藏表示作为整个序列信息的摘要（考虑到BERT架构是双向的，该标记将能够访问整个序列）。'
- en: $$\begin{array}{ll}{h}^{\rm{tran.}}={{{\rm{transformer}}}}\Big(\,{{\mbox{[cls]}}}\,,{w}_{1}\ldots
    {w}_{{{{\mathcal{T}}}}},\,{{\mbox{[eos]}}}\,\Big),\qquad{h}^{\rm{tran.}}\in {{\mathbb{R}}}^{{\dim
    }_{{{{{\rm{trans}}}}}.}\times {{\,{\mathcal{T}}}}+2}\\ {h}^{I}=({h}_{{{{\rm{cls}}}}}^{\rm{tran.}})\qquad\qquad\qquad\qquad\qquad\qquad\quad\qquad\quad\;\;{h}^{I}\in
    {{\mathbb{R}}}^{{\dim }_{{{{{\rm{trans}}}}}.}}\end{array}$$
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: $$\begin{array}{ll}{h}^{\rm{tran.}}={{{\rm{transformer}}}}\Big(\,{{\mbox{[cls]}}}\,,{w}_{1}\ldots
    {w}_{{{{\mathcal{T}}}}},\,{{\mbox{[eos]}}}\,\Big),\qquad{h}^{\rm{tran.}}\in {{\mathbb{R}}}^{{\dim
    }_{{{{{\rm{trans}}}}}.}\times {{\,{\mathcal{T}}}}+2}\\ {h}^{I}=({h}_{{{{\rm{cls}}}}}^{\rm{tran.}})\qquad\qquad\qquad\qquad\qquad\qquad\quad\qquad\quad\;\;{h}^{I}\in
    {{\mathbb{R}}}^{{\dim }_{{{{{\rm{trans}}}}}.}}\end{array}$$
- en: 'Where \({h}_{{{{\rm{cls}}}}}^{\rm{tran.}}\) denote the last hidden representation
    for the ‘cls’ token. Ref. ^([21](/articles/s41593-024-01607-5#ref-CR21 "Reimers,
    N. & Gurevych, I. Sentence-bert: Sentence embeddings using siamese bert-networks.
    Preprint at                    https://arxiv.org/abs/1908.10084                                     (2019)."))
    found this pooling method performed worse than average pooling, so we don’t include
    these alternatives in our results. For GPT and GPT (XL), we also tested a pooling
    method where the fixed-length representation for a sequence was taken from the
    transformer output of the ‘eos’ token. In this case:'
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 \({h}_{{{{\rm{cls}}}}}^{\rm{tran.}}\) 表示 ''cls'' 标记的最后隐藏表示。参考 ^([21](/articles/s41593-024-01607-5#ref-CR21
    "Reimers, N. & Gurevych, I. Sentence-bert: Sentence embeddings using siamese bert-networks.
    Preprint at                    https://arxiv.org/abs/1908.10084                                     (2019)."))
    的研究发现，这种汇聚方法的表现低于平均汇聚，因此我们在结果中不包括这些替代方案。对于 GPT 和 GPT (XL)，我们还测试了一种汇聚方法，其中序列的固定长度表示取自
    ''eos'' 标记的变压器输出。在这种情况下：'
- en: $$\begin{array}{ll}{h}^{\rm{tran.}}={{{\rm{transformer}}}}\Big(\,{{\mbox{[cls]}}}\,,{w}_{1}\ldots
    {w}_{{{{\mathcal{T}}}}},\,{{\mbox{[eos]}}}\,\Big),\qquad{h}^{\rm{tran.}}\in {{\mathbb{R}}}^{{\dim
    }_{{{{\rm{trans}}}}.}\times {{\;{\mathcal{T}}}}+2}\\ {h}^{I}=({h}_{{{{\rm{eos}}}}}^{\rm{tran.}}),\qquad\qquad\qquad\qquad\qquad\qquad\qquad\quad\quad{h}^{I}\in
    {{\mathbb{R}}}^{{\dim }_{{{{\rm{trans}}}}.}}\\ I={{{{\rm{Linear}}}}}_{{{{\rm{embed}}}}}({h}^{I}),\qquad\qquad\qquad\qquad\qquad\qquad\quad
    I\in {{\mathbb{R}}}^{64}\end{array}$$
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: $$\begin{array}{ll}{h}^{\rm{tran.}}={{{\rm{transformer}}}}\Big(\,{{\mbox{[cls]}}}\,,{w}_{1}\ldots
    {w}_{{{{\mathcal{T}}}}},\,{{\mbox{[eos]}}}\,\Big),\qquad{h}^{\rm{tran.}}\in {{\mathbb{R}}}^{{\dim
    }_{{{{\rm{trans}}}}.}\times {{\;{\mathcal{T}}}}+2}\\ {h}^{I}=({h}_{{{{\rm{eos}}}}}^{\rm{tran.}}),\qquad\qquad\qquad\qquad\qquad\qquad\qquad\quad\quad{h}^{I}\in
    {{\mathbb{R}}}^{{\dim }_{{{{\rm{trans}}}}.}}\\ I={{{{\rm{Linear}}}}}_{{{{\rm{embed}}}}}({h}^{I}),\qquad\qquad\qquad\qquad\qquad\qquad\quad
    I\in {{\mathbb{R}}}^{64}\end{array}$$
- en: We found that GPT failed to achieve even a relaxed performance criterion of
    85% across tasks using this pooling method, and GPT (XL) performed worse than
    with average pooling, so we omitted these models from the main results (Supplementary
    Fig. [11](/articles/s41593-024-01607-5#MOESM1)). For CLIP models we use the same
    pooling method as in the original multiModal training procedure, which takes the
    outputs of the [cls] token as described above.
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，使用此汇聚方法，GPT 未能达到85%的宽松性能标准，而 GPT (XL) 的表现甚至低于平均汇聚，因此我们在主要结果中省略了这些模型（见附图
    [11](/articles/s41593-024-01607-5#MOESM1)）。对于 CLIP 模型，我们使用与原始多模态训练过程相同的汇聚方法，即使用
    [cls] 标记的输出，如上所述。
- en: For all the above models, we also tested a version where the information from
    the pretrained transformers is passed through a multilayer perceptron with a single
    hidden layer of 256 hidden units and ReLU nonlinearities. We found that this manipulation
    reduced performance across all models, verifying that a simple linear embedding
    is beneficial to generalization performance.
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有上述模型，我们还测试了一个版本，其中来自预训练变压器的信息通过具有256个隐藏单元和ReLU非线性的单隐藏层多层感知机传递。我们发现这种操作降低了所有模型的性能，验证了简单的线性嵌入对泛化性能的益处。
- en: 'For GPT, BERT and SBERT, \({\dim }_{{{{\rm{trans}}}}.}=768\) and each model
    uses a total of ~100 million parameters; for SBERT (L) \({\dim }_{{{{\rm{trans}}}}.}=1,024\)
    and the model uses ~300 million parameters; GPT (XL) \({\dim }_{{{{\rm{trans}}}}.}=1,600\)
    and the model uses ~1.5 billion parameters; for CLIP, \({\dim }_{{{{\rm{trans}}}}.}=512\)
    and the model uses ~60 million parameters. Full PyTorch implementations, including
    all pretrained weights and model hyperparameters, can be accessed at the Huggingface
    library ([https://huggingface.co/docs/transformers/](https://huggingface.co/docs/transformers/))^([52](/articles/s41593-024-01607-5#ref-CR52
    "Wolf, T. et al. Transformers: state-of-the-art natural language processing. In
    Proc. 2020 Conference on Empirical Methods in Natural Language Processing: System
    Demonstrations (eds Liu, Q. & Schlangen, D.) 38–45 (Association for Computational
    Linguistics, 2020).")).'
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: '对于 GPT、BERT 和 SBERT，\({\dim }_{{{{\rm{trans}}}}.}=768\)，每个模型使用约1亿个参数；对于 SBERT
    (L)，\({\dim }_{{{{\rm{trans}}}}.}=1,024\)，模型使用约3亿个参数；对于 GPT (XL)，\({\dim }_{{{{\rm{trans}}}}.}=1,600\)，模型使用约15亿个参数；对于
    CLIP，\({\dim }_{{{{\rm{trans}}}}.}=512\)，模型使用约6千万个参数。可以在 Huggingface 库中访问完整的 PyTorch
    实现，包括所有预训练权重和模型超参数信息（[https://huggingface.co/docs/transformers/](https://huggingface.co/docs/transformers/)）^([52](/articles/s41593-024-01607-5#ref-CR52
    "Wolf, T. et al. Transformers: state-of-the-art natural language processing. In
    Proc. 2020 Conference on Empirical Methods in Natural Language Processing: System
    Demonstrations (eds Liu, Q. & Schlangen, D.) 38–45 (Association for Computational
    Linguistics, 2020).")).'
- en: BoW model
  id: totrans-split-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: BoW 模型
- en: For our BoW model, instructions are represented as a vector of binary activations
    the size of the instruction vocabulary, where each unit indicates the inclusion
    or exclusion of the associated word in the current instruction. For our instruction
    set, ∣vocab∣ = 181\. This vector is then projected through a linear layer into
    64-dimensional space.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的 Bag-of-Words 模型，指令被表示为二进制激活向量，其大小与指令词汇表相同，其中每个单元表示当前指令中相应单词的包含或排除。对于我们的指令集，∣vocab∣ = 181。然后将此向量通过一个线性层投影到64维空间。
- en: $$\begin{array}{ll}{h}_{i}^{{{{\rm{BoW}}}}}=\left\{\begin{array}{ll}1\quad\,{{\mbox{if}}}\,\,{w}_{i}\in
    ({w}_{1}\ldots {w}_{{{{\mathcal{T}}}}})\\ 0\quad\,{{\mbox{otherwise}}}\,\end{array}\right.\qquad\qquad{h}^{{{{\rm{BoW}}}}}\in
    {{\mathbb{R}}}^{| \rm{vocab}| }\\ I={{{{\rm{Linear}}}}}_{{{{\rm{embed}}}}}({h}^{{{{\rm{BoW}}}}}),\qquad\qquad\qquad\qquad\qquad\quad
    I\in {{\mathbb{R}}}^{64}\end{array}$$
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: $$\begin{array}{ll}{h}_{i}^{{{{\rm{BoW}}}}}=\left\{\begin{array}{ll}1\quad\,{{\mbox{如果}}}\,\,{w}_{i}\in
    ({w}_{1}\ldots {w}_{{{{\mathcal{T}}}}})\\ 0\quad\,{{\mbox{否则}}}\,\end{array}\right.\qquad\qquad{h}^{{{{\rm{BoW}}}}}\in
    {{\mathbb{R}}}^{| \rm{vocab}| }\\ I={{{{\rm{Linear}}}}}_{{{{\rm{embed}}}}}({h}^{{{{\rm{BoW}}}}}),\qquad\qquad\qquad\qquad\qquad\quad
    I\in {{\mathbb{R}}}^{64}\end{array}$$
- en: Blank slate language models
  id: totrans-split-34
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 空白版语言模型
- en: Given that tuning the last layers of language models resulted in improved performance
    (Fig. [2e](/articles/s41593-024-01607-5#Fig2)), we tested two additional models
    to determine if training a blank slate language model trained exclusively on the
    loss from sensorimotor tasks would improve performance. These models consist of
    passing BoW representations through a multilayer perceptron and passing pretrained
    BERT word embeddings through one layer of a randomly initialized BERT encoder.
    Both models performed poorly compared to pretrained models (Supplementary Fig.
    [4.5](/articles/s41593-024-01607-5#MOESM1)), confirming that language pretraining
    is essential to generalization.
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 调整语言模型的最后几层结果表明性能有所提高（图 [2e](/articles/s41593-024-01607-5#Fig2)）。我们测试了另外两个模型，以确定仅训练从感觉运动任务中损失的空白版语言模型是否会改善性能。这些模型包括通过多层感知器传递
    BoW 表示和通过随机初始化的 BERT 编码器的一层传递预训练的 BERT 词嵌入。与预训练模型相比，这两个模型的表现较差（附图 [4.5](/articles/s41593-024-01607-5#MOESM1)），证实语言预训练对泛化至关重要。
- en: Tasks sets
  id: totrans-split-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 任务集
- en: 'Tasks were divided into five interrelated subgroups: ‘go’, ‘decision-making’,
    ‘matching’, and ‘comparison’ and ‘duration’. Depending on the task, multiple stimuli
    may appear during the stimulus epoch. Also, depending on the task, models may
    be required to respond in a particular direction or repress response altogether.
    Unless otherwise specified, zero-mean Gaussian noise is added independently at
    each time step and to each input unit and the variance of this noise is drawn
    randomly from \({\mathbb{U}}[0.1,0.15]\). The timing of stimuli differs among
    the tasks type. However, for all tasks, trials can be divided into preparatory,
    stimulus and response epochs. The stimulus epoch can be subdivided into three
    parts—stim1, delay and stim23—although these distinct parts aren’t used by all
    tasks. A trial lasts for a total of *T* = 150 time steps. Let *d**u**r*[epoch]
    denote the duration in simulated time steps of a given epoch. Then'
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: 任务被分为五个相关子组：‘go’、‘decision-making’、‘matching’、‘comparison’和‘duration’。根据任务不同，刺激时段内可能出现多个刺激物。此外，根据任务不同，模型可能需要朝特定方向响应或完全抑制响应。除非另有说明，每个时间步骤独立地向每个输入单元添加均值为零的高斯噪声，并且此噪声的方差从
    \({\mathbb{U}}[0.1,0.15]\) 中随机抽取。刺激的时间安排在任务类型之间有所不同。然而，对于所有任务，试验可以分为准备、刺激和响应时段。刺激时段可以细分为三个部分—stim1、delay和stim23—尽管并非所有任务都使用这些明确的部分。每次试验总共持续*T* = 150个时间步骤。设*d**u**r*[epoch]表示给定时期模拟时间步长的持续时间。那么
- en: $$\begin{array}{rcl}&&du{r}_{{{{\rm{response}}}}} \sim\Big\{i| 20 < i\le 25;i\in
    {\mathbb{N}}\Big\}\\ &&du{r}_{{{{\rm{stim}}}}1},du{r}_{{{{\rm{stim}}}}2} \sim\Big\{i|
    37 < i\le 50;i\in {\mathbb{N}}\Big\}\\ &&du{r}_{{{{\rm{delay}}}}} \sim\Big\{i|
    15 < i\le 25;i\in {\mathbb{N}}\Big\}\\ &&du{r}_{{{{\rm{prep}}}}.}=150-\Big(du{r}_{{{{\rm{response}}}}}+du{r}_{{{{\rm{stim}}}}1}+du{r}_{{{{\rm{stim}}}}2}+du{r}_{{{{\rm{delay}}}}}\Big)\end{array}$$
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: $$\begin{array}{rcl}&&du{r}_{{{{\rm{response}}}}} \sim\Big\{i| 20 < i\le 25;i\in
    {\mathbb{N}}\Big\}\\ &&du{r}_{{{{\rm{stim}}}}1},du{r}_{{{{\rm{stim}}}}2} \sim\Big\{i|
    37 < i\le 50;i\in {\mathbb{N}}\Big\}\\ &&du{r}_{{{{\rm{delay}}}}} \sim\Big\{i|
    15 < i\le 25;i\in {\mathbb{N}}\Big\}\\ &&du{r}_{{{{\rm{prep}}}}.}=150-\Big(du{r}_{{{{\rm{response}}}}}+du{r}_{{{{\rm{stim}}}}1}+du{r}_{{{{\rm{stim}}}}2}+du{r}_{{{{\rm{delay}}}}}\Big)\end{array}$$
- en: For tasks that don’t utilize a delay structure, stim1, stim2 and delay epochs
    are grouped together in a single stimulus epoch where \(du{r}_{{{{\rm{stimulus}}}}}=du{r}_{{{{\rm{stim}}}}1}+du{r}_{{{{\rm{stim}}}}2}+du{r}_{{{{\rm{delay}}}}}\).
    Unless otherwise specified, a fixation cue with a constant strength *s**t**r*[fix] = 1
    is activated throughout the preparatory and stimulus epochs. For example trials
    of each task, see Supplementary Fig. [13](/articles/s41593-024-01607-5#MOESM1).
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不使用延迟结构的任务，stim1、stim2 和 delay 时期被组合在一个单一的刺激时期内，其中 \(du{r}_{{{{\rm{stimulus}}}}}=du{r}_{{{{\rm{stim}}}}1}+du{r}_{{{{\rm{stim}}}}2}+du{r}_{{{{\rm{delay}}}}}\)。除非另有说明，在准备和刺激时期内会激活具有恒定强度
    *s**t**r*[fix] = 1 的注视提示。例如每个任务的示例试验，请参阅补充图 [13](/articles/s41593-024-01607-5#MOESM1)。
- en: ‘Go’ tasks
  id: totrans-split-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ‘Go’ 任务
- en: The ‘Go’ family of tasks includes ‘Go’, ‘RTGo’, ‘AntiGo’, ‘AntiRTGo’ and modality-specific
    versions of each task denoted with either ‘Mod1’ and ‘Mod2’. In both the ‘Go’
    and ‘AntiGo’ tasks, a single stimulus is presented at the beginning of the stimulus
    epoch. The direction of the presented stimulus is generated by drawing from a
    uniform distribution between 0 and 2*π*, that is, \({\theta }_{{{{\rm{stim}}}}}
    \sim {\mathbb{U}}[0,2\pi ]\). The stimulus will appear in either modality 1 or
    modality 2 with equal probability. The strength of the stimulus is given by \(st{r}_{{{{\rm{stim}}}}}
    \sim {\mathbb{U}}[1.0,1.2]\). In the ‘Go’ task, the target response is in the
    same direction as the presented stimulus, that is, \({\theta }_{{{{\rm{stim}}}}}={\theta
    }_{{{{\rm{target}}}}}\), while in the ‘AntiGo’ task the direction of the response
    should be in the opposite of the stimulus direction, \({\theta }_{{{{\rm{stim}}}}}+\pi
    ={\theta }_{{{{\rm{target}}}}}\). For modality-specific versions of each task,
    a stimulus direction is drawn in each modality \({\theta }_{{{{\rm{stim}}}},{{{\rm{mod}}}}1}
    \sim {\mathbb{U}}[0,2\pi ]\) and \({\theta }_{{{{\rm{stim}}}},{{{\rm{mod}}}}2}
    \sim {\mathbb{U}}[0,2\pi ]\) and for modality-specific Go-type tasks
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: ‘Go’ 任务族包括 ‘Go’、‘RTGo’、‘AntiGo’、‘AntiRTGo’ 和每个任务的特定模态版本，用 ‘Mod1’ 和 ‘Mod2’ 表示。在
    ‘Go’ 和 ‘AntiGo’ 任务中，刺激在刺激时期开始时呈现。所呈现刺激的方向是从均匀分布 \([0, 2*π]\) 中随机抽取的，即 \({\theta
    }_{{{{\rm{stim}}}}} \sim {\mathbb{U}}[0,2\pi ]\)。刺激将以等概率出现在模态 1 或模态 2 中。刺激的强度由
    \(st{r}_{{{{\rm{stim}}}}} \sim {\mathbb{U}}[1.0,1.2]\) 给出。在 ‘Go’ 任务中，目标反应与呈现刺激的方向相同，即
    \({\theta }_{{{{\rm{stim}}}}}={\theta }_{{{{\rm{target}}}}}\)，而在 ‘AntiGo’ 任务中，响应方向应与刺激方向相反，即
    \({\theta }_{{{{\rm{stim}}}}}+\pi ={\theta }_{{{{\rm{target}}}}}\)。对于每个任务的特定模态版本，分别在每个模态中抽取一个刺激方向
    \({\theta }_{{{{\rm{stim}}}},{{{\rm{mod}}}}1} \sim {\mathbb{U}}[0,2\pi ]\) 和 \({\theta
    }_{{{{\rm{stim}}}},{{{\rm{mod}}}}2} \sim {\mathbb{U}}[0,2\pi ]\)，以及特定模态的 Go 类型任务
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}},{{{\rm{mod}}}}1}
    &{{\mbox{if}}}\,\,\,{{\mbox{Mod1 task}}}\\ {\theta }_{{{{\rm{stim}}}},{{{\rm{mod}}}}2}
    &{{\mbox{if}}}\,\,\,{{\mbox{Mod2 task}}}\end{array}\right.$$
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}},{{{\rm{mod}}}}1}
    &{{\mbox{如果}}}\,\,\,{{\mbox{Mod1 任务}}}\\ {\theta }_{{{{\rm{stim}}}},{{{\rm{mod}}}}2}
    &{{\mbox{如果}}}\,\,\,{{\mbox{Mod2 任务}}}\end{array}\right.$$
- en: while for modality-specific AntiGo-type tasks
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: 而对于特定模态的 AntiGo 类型任务
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}},{{{\rm{mod}}}}1}+\pi
    &{{\mbox{if}}}\,\,\,{{\mbox{Mod1 task}}}\,\\ {\theta }_{{{{\rm{stim}}}},{{{\rm{mod}}}}2}+\pi
    &{{\mbox{if}}}\,\,\,{{\mbox{Mod2 task}}}\end{array}\right.$$
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}},{{{\rm{mod}}}}1}+\pi
    &{{\mbox{如果}}}\,\,\,{{\mbox{Mod1 任务}}}\,\\ {\theta }_{{{{\rm{stim}}}},{{{\rm{mod}}}}2}+\pi
    &{{\mbox{如果}}}\,\,\,{{\mbox{Mod2 任务}}}\end{array}\right.$$
- en: For ‘RT’ versions of the ‘Go’ tasks, stimuli are only presented during the response
    epoch and the fixation cue is never extinguished. Thus, the presence of the stimulus
    itself serves as the response cue and the model must respond as quickly as possible.
    Otherwise, stimuli persist through the duration of the stimulus epoch.
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 ‘Go’ 任务的 ‘RT’ 版本，刺激仅在响应时期呈现，注视提示从未熄灭。因此，刺激本身的存在即作为响应提示，模型必须尽快做出响应。否则，刺激会持续整个刺激时期。
- en: ‘Decision-making’ tasks
  id: totrans-split-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ‘决策制定’任务
- en: The ‘decision-making’ family of tasks includes ‘DM’ (decision-making), ‘AntiDM’,
    ‘MultiDM’ (multisensory decision-making), ‘AntiMultiDM,’ modality-specific versions
    of each of these tasks and, finally, confidence-based versions of ‘DM’ and ‘AntiDM.’
    For all tasks in this group, two stimuli are presented simultaneously and persist
    throughout the duration of the stimulus epoch. They are drawn according to \({\theta
    }_{{{{\rm{stim}}}}1} \sim {\mathbb{U}}[0,2\pi ]\) and \({\theta }_{{{{\rm{stim}}}}2}
    \sim {\mathbb{U}}\)\([({\theta }_{{{{\rm{stim}}}}1}-0.2\pi ,{\theta }_{{{{\rm{stim}}}}1}-0.6\pi
    )\cup ({\theta }_{{{{\rm{stim}}}}1}+0.2\pi ,{\theta }_{{{{\rm{stim}}}}1}+0.6\pi
    )]\). A base strength applied to both stimuli is drawn such that \(st{r}_{\rm{base}}
    \sim {\mathbb{U}}[1.0,1.2]\). A contrast is drawn from a discrete distribution
    such that *c* ~ {−0.175, −0.15, −0.1, 0.1, 0.15, 0.175} so the stimulus strength
    associated with each direction in a trial are given by \(st{r}_{{{{\rm{stim}}}}1}=st{r}_{\rm{base}}+c\)
    and \(st{r}_{{{{\rm{stim}}}}2}=\) \({str}_{\rm{base}}-c\).
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: ‘决策’类任务包括‘DM’（决策制定）、‘AntiDM’、‘MultiDM’（多感官决策制定）、‘AntiMultiDM’、每个任务的特定模态版本，以及‘DM’和‘AntiDM’的基于置信度的版本。对于这组所有任务，同时呈现两个刺激，并在刺激期内持续存在。它们根据
    \({\theta }_{{{{\rm{stim}}}}1} \sim {\mathbb{U}}[0,2\pi ]\) 和 \({\theta }_{{{{\rm{stim}}}}2}
    \sim {\mathbb{U}}\)\([({\theta }_{{{{\rm{stim}}}}1}-0.2\pi ,{\theta }_{{{{\rm{stim}}}}1}-0.6\pi
    )\cup ({\theta }_{{{{\rm{stim}}}}1}+0.2\pi ,{\theta }_{{{{\rm{stim}}}}1}+0.6\pi
    )]\) 进行抽取。应用于两个刺激的基础强度由 \(st{r}_{\rm{base}} \sim {\mathbb{U}}[1.0,1.2]\) 抽取。对比度从离散分布中抽取，使得每个试验中每个方向的刺激强度为
    \(st{r}_{{{{\rm{stim}}}}1}=st{r}_{\rm{base}}+c\) 和 \(st{r}_{{{{\rm{stim}}}}2}={str}_{\rm{base}}-c\)。
- en: For the ‘DM’ task,
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于‘DM’任务，
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{if}}}\,\,st{r}_{{{{\rm{stim}}}}1} > st{r}_{{{{\rm{stim}}}}2}\\ {\theta
    }_{{{{\rm{stim}}}}2}\quad &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{若}}}\,\,st{r}_{{{{\rm{stim}}}}1} > st{r}_{{{{\rm{stim}}}}2}\\ {\theta
    }_{{{{\rm{stim}}}}2}\quad &\,{{\mbox{否则}}}\,\end{array}\right.$$
- en: and for the the ‘AntiDM’ task,
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以及对于‘AntiDM’任务，
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{if}}}\,\,st{r}_{{{{\rm{stim}}}}1} < st{r}_{{{{\rm{stim}}}}2}\\ {\theta
    }_{{{{\rm{stim}}}}2}\quad &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{若}}}\,\,st{r}_{{{{\rm{stim}}}}1} < st{r}_{{{{\rm{stim}}}}2}\\ {\theta
    }_{{{{\rm{stim}}}}2}\quad &\,{{\mbox{否则}}}\,\end{array}\right.$$
- en: For these versions of the tasks, the stimuli are presented in either modality
    1 or modality 2 with equal probability. For the multisensory versions of each
    task, stimuli directions are drawn in the same manner and presented across both
    modalities so that \({\theta }_{{{{\rm{stim}}}}1,{{{\rm{mod}}}}1}={\theta }_{{{{\rm{stim}}}}1,{{{\rm{mod}}}}2}\)
    and \({\theta }_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}1}={\theta }_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}2}\).
    Base strengths are drawn independently for each modality. Contrasts for both modalities
    are drawn from a discrete distribution such that \({c}_{{{\mathrm{mod}}}\,1},{c}_{{{\mathrm{mod}}}\,2}
    \sim \left\{0.2,0.175,\right.\)\(\left.0.15,0.125,-0.125,-0.15,-0.175,-0.2\right\}\).
    If both \(| {c}_{{{\mathrm{mod}}}\,1}| -| {c}_{{{\mathrm{mod}}}\,2}| =0\) then
    contrasts are redrawn to avoid zero-contrast trials during training. If both \({c}_{{{\mathrm{mod}}}\,1}\)
    and \({c}_{{{\mathrm{mod}}}\,2}\) have the same sign, then contrasts are redrawn
    to ensure that the trial requires integrating over both modalities as opposed
    to simply performing a ‘DM’ task in a single modality. Criteria for target responses
    are measured as the strength of a given direction summed over both modalities.
    So, for ‘MultiDM’
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些任务版本，刺激以相等概率呈现在模态 1 或模态 2 中。对于每个任务的多感官版本，刺激方向以相同方式抽取并在两个模态中呈现，使得 \({\theta
    }_{{{{\rm{stim}}}}1,{{{\rm{mod}}}}1}={\theta }_{{{{\rm{stim}}}}1,{{{\rm{mod}}}}2}\)
    和 \({\theta }_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}1}={\theta }_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}2}\)。每个模态的基础强度独立抽取。两个模态的对比度从离散分布中抽取，使得
    \({c}_{{{\mathrm{mod}}}\,1},{c}_{{{\mathrm{mod}}}\,2} \sim \left\{0.2,0.175,0.15,0.125,-0.125,-0.15,-0.175,-0.2\right\}\)。若
    \(| {c}_{{{\mathrm{mod}}}\,1}| -| {c}_{{{\mathrm{mod}}}\,2}| =0\)，则重新抽取对比度以避免零对比度的试验。若
    \({c}_{{{\mathrm{mod}}}\,1}\) 和 \({c}_{{{\mathrm{mod}}}\,2}\) 同号，则重新抽取对比度以确保试验需要在两个模态上进行整合，而不仅仅在单一模态中执行‘DM’任务。目标响应的标准被测量为在两个模态上给定方向的强度之和。因此，对于‘MultiDM’任务，
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1,{{\mathrm{mod}}}\,1}\quad
    &\,{{\mbox{if}}}\,\,st{r}_{{{{\rm{stim}}}}1,{{{\rm{mod}}}}1}+st{r}_{{{{\rm{stim}}}}1,{{{\rm{mod}}}}2}
    > st{r}_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}1}\\&+st{r}_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}2}\\
    {\theta }_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}1}\quad &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-53
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1,{{\mathrm{mod}}}\,1}\quad
    &\,{{\mbox{if}}}\,\,st{r}_{{{{\rm{stim}}}}1,{{{\rm{mod}}}}1}+st{r}_{{{{\rm{stim}}}}1,{{{\rm{mod}}}}2}
    > st{r}_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}1}\\&+st{r}_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}2}\\
    {\theta }_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}1}\quad &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
- en: and for ‘AntiMultiDM’
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: 对于‘AntiMultiDM’
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1,{{\mathrm{mod}}}\,1}\quad
    &\,{{\mbox{if}}}\,\,st{r}_{{{{\rm{stim}}}}1,{{{\rm{mod}}}}1}+st{r}_{{{{\rm{stim}}}}1,{{{\rm{mod}}}}2}
    < st{r}_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}1}\\&+st{r}_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}2}\\
    {\theta }_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}1}\quad &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1,{{\mathrm{mod}}}\,1}\quad
    &\,{{\mbox{if}}}\,\,st{r}_{{{{\rm{stim}}}}1,{{{\rm{mod}}}}1}+st{r}_{{{{\rm{stim}}}}1,{{{\rm{mod}}}}2}
    < st{r}_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}1}\\&+st{r}_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}2}\\
    {\theta }_{{{{\rm{stim}}}}2,{{{\rm{mod}}}}1}\quad &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
- en: Stimuli for modality-specific versions of each task are generated in the same
    way as multisensory versions of the task. Criteria for target response are the
    same as standard versions of ‘DM’ and ‘AntiDM’ tasks applied only to stimuli in
    the relevant modality.
  id: totrans-split-56
  prefs: []
  type: TYPE_NORMAL
  zh: 任务的模态特定版本的刺激生成方式与任务的多感官版本相同。目标响应的标准与相关模态中的标准‘DM’和‘AntiDM’任务相同。
- en: In confidence-based decision-making tasks (‘ConDM’ and ‘ConAntiDM’), the stimuli
    directions are drawn in the same way as above. Stimuli are shown in either modality
    1 or modality 2 with equal probability. In each trial, *s**t**r*[base] = 1\. The
    contrast and noise for each trial is based on the thresholded performance of a
    SIMPLENET model trained on all tasks except ‘ConDM’ and ‘ConAntiDM’. Once this
    model has been trained, we establish a threshold across levels of noise and contrasts
    for which the model can perform a ‘DM’ or an ‘AntiDM’ task at 95% correct. We
    then draw contrasts and noises for trials from above and below this threshold
    with equal probability during training. In trials where the noise and contrast
    levels fell below the 95% correct threshold, the model must repress response,
    and otherwise perform the decision-making task (either ‘DM’ or ‘AntiDM’).
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于信心的决策任务（‘ConDM’和‘ConAntiDM’）中，刺激的方向与上述方式相同。刺激以相等的概率显示在模态1或模态2中。每次试验中，*s**t**r*[base] = 1\.
    每个试验的对比度和噪声基于在除‘ConDM’和‘ConAntiDM’之外所有任务上训练的SIMPLENET模型的阈值性能。一旦这个模型被训练好，我们会在噪声和对比度水平上建立一个阈值，以便模型在95%正确率下执行‘DM’或‘AntiDM’任务。在训练期间，我们以相等的概率从超过和低于该阈值的对比度和噪声水平中抽取试验。在噪声和对比度水平低于95%正确阈值的试验中，模型必须抑制响应，否则执行决策任务（‘DM’或‘AntiDM’）。
- en: ‘Comparison’ tasks
  id: totrans-split-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ‘比较’任务
- en: Our comparison task group includes ‘COMP1’, ‘COMP2’, ‘MultiCOMP1’, ‘MultiCOMP2’,
    ‘Anti’ versions of each of these tasks, as well as modality-specific versions
    of ‘COMP1’ and ‘COMP2’ tasks. This group of tasks is designed to extend the basic
    decision-making framework into a setting with more complex control demands. These
    tasks utilize the delay structure in the stimulus epoch so that stim1 appears
    only during the stim1 epoch, followed by a delay, and finally stim2\. This provides
    a temporal ordering on the stimuli. In ‘COMP1’, the model must respond to the
    first stimulus only if it has greater strength than the second and otherwise repress
    a response that is
  id: totrans-split-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的比较任务组包括‘COMP1’，‘COMP2’，‘MultiCOMP1’，‘MultiCOMP2’，每个任务的‘Anti’版本，以及‘COMP1’和‘COMP2’任务的模态特定版本。这组任务旨在将基本决策框架扩展到具有更复杂控制需求的环境中。这些任务利用刺激时期中的延迟结构，使得stim1仅在stim1时期出现，随后是一个延迟，最后是stim2\.
    这为刺激提供了时间顺序。在‘COMP1’中，模型必须仅在第一个刺激的强度大于第二个刺激时才响应，否则抑制响应
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{if}}}\,\,st{r}_{{{{\rm{stim}}}}1} > st{r}_{{{{\rm{stim}}}}2}\\ {{{\rm{repress}}}}\quad
    &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{if}}}\,\,st{r}_{{{{\rm{stim}}}}1} > st{r}_{{{{\rm{stim}}}}2}\\ {{{\rm{repress}}}}\quad
    &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
- en: Likewise, in ‘COMP2’, the model must respond to the second direction if it presented
    with greater strength than the first otherwise repress response that is
  id: totrans-split-61
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在 ‘COMP2’ 中，如果第二个方向的强度大于第一个方向，模型必须响应第二个方向，否则抑制响应，即
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}2}\quad
    &\,{{\mbox{if}}}\,\,st{r}_{{{{\rm{stim}}}}2} > {{{{\rm{str}}}}}_{{{{\rm{stim}}}}1}\\
    {{{\rm{repress}}}}\quad &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}2}\quad
    &\,{{\mbox{如果}}}\,\,st{r}_{{{{\rm{stim}}}}2} > {{{{\rm{str}}}}}_{{{{\rm{stim}}}}1}\\
    {{{\rm{抑制}}}}\quad &\,{{\mbox{否则}}}\,\end{array}\right.$$
- en: In ‘Anti’ versions of the task the ordering criteria is the same except for
    stimuli with least strength, that is, for ‘AntiCOMP1’
  id: totrans-split-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在任务的 ‘Anti’ 版本中，排序标准相同，除了具有最小强度的刺激，即对于 ‘AntiCOMP1’
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{if}}}\,\,{{{{\rm{str}}}}}_{{{{\rm{stim}}}}1} < {{{{\rm{str}}}}}_{{{{\rm{stim}}}}2}\\
    {{{\rm{repress}}}}\quad &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-64
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{如果}}}\,\,{{{{\rm{str}}}}}_{{{{\rm{stim}}}}1} < {{{{\rm{str}}}}}_{{{{\rm{stim}}}}2}\\
    {{{\rm{抑制}}}}\quad &\,{{\mbox{否则}}}\,\end{array}\right.$$
- en: and for ‘AntiCOMP2’
  id: totrans-split-65
  prefs: []
  type: TYPE_NORMAL
  zh: 以及对于‘AntiCOMP2’
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}2}\quad
    &\,{{\mbox{if}}}\,\,{{{{\rm{str}}}}}_{{{{\rm{stim}}}}2} < {{{{\rm{str}}}}}_{{{{\rm{stim}}}}1}\\
    {{{\rm{repress}}}}\quad &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-66
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}2}\quad
    &\,{{\mbox{如果}}}\,\,{{{{\rm{str}}}}}_{{{{\rm{stim}}}}2} < {{{{\rm{str}}}}}_{{{{\rm{stim}}}}1}\\
    {{{\rm{抑制}}}}\quad &\,{{\mbox{否则}}}\,\end{array}\right.$$
- en: In multisensory settings, the criteria for target direction are analogous to
    the multisensory decision-making tasks where strength is integrated across modalities.
    Likewise, for modality-specific versions, the criteria are only applied to stimuli
    in the relevant modality. Stimuli directions and strength for each of these tasks
    are drawn from the same distributions as the analogous task in the ‘decision-making’
    family. However, during training, we make sure to balance trials where responses
    are required and trials where models must repress response.
  id: totrans-split-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在多感官设置中，目标方向的标准类似于多感官决策任务，其中强度跨越各个模态。同样，在特定模态版本中，标准仅适用于相关模态中的刺激。这些任务的刺激方向和强度与“决策”系列中类似任务的分布相同。然而，在训练期间，我们确保平衡需要响应的试验和模型必须抑制响应的试验。
- en: ‘Duration’ tasks
  id: totrans-split-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '''Duration'' 任务'
- en: The ‘duration’ family of tasks includes ‘Dur1’, ‘Dur2’, ‘MultiDur1’, ‘MultiDur2’,
    ‘Anti’ versions of each of these tasks and modality-specific versions of ‘Dur1’
    and ‘Dur2’ tasks. These tasks require models to perform a time estimation task
    with the added demand or stimuli ordering determining relevance for response.
    Like in ‘comparison’ tasks, stim1 is presented followed by a delay and then stim2\.
    For ‘Dur1’ trials
  id: totrans-split-69
  prefs: []
  type: TYPE_NORMAL
  zh: ‘duration’ 任务系列包括 ‘Dur1’、‘Dur2’、‘MultiDur1’、‘MultiDur2’，每个任务的 ‘Anti’ 版本和 ‘Dur1’
    和 ‘Dur2’ 任务的特定模态版本。这些任务要求模型执行具有额外需求或刺激排序决定响应相关性的时间估计任务。与 ‘comparison’ 任务类似，首先呈现
    stim1，然后是延迟，然后是 stim2。对于 ‘Dur1’ 试验
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{if}}}\,\,du{r}_{{{{\rm{stim}}}}1} > du{r}_{{{{\rm{stim}}}}2}\\ {{{\rm{repress}}}}\quad
    &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-70
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{如果}}}\,\,du{r}_{{{{\rm{stim}}}}1} > du{r}_{{{{\rm{stim}}}}2}\\ {{{\rm{抑制}}}}\quad
    &\,{{\mbox{否则}}}\,\end{array}\right.$$
- en: Likewise, for ‘Dur2’
  id: totrans-split-71
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在 ‘Dur2’ 中
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}2}\quad
    &\,{{\mbox{if}}}\,\,du{r}_{{{{\rm{stim}}}}2} > du{r}_{{{{\rm{stim}}}}1}\\ {{{\rm{repress}}}}\quad
    &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-72
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}2}\quad
    &\,{{\mbox{如果}}}\,\,du{r}_{{{{\rm{stim}}}}2} > du{r}_{{{{\rm{stim}}}}1}\\ {{{\rm{抑制}}}}\quad
    &\,{{\mbox{否则}}}\,\end{array}\right.$$
- en: In ‘Anti’ versions of these tasks, the correct response is in the direction
    of the stimulus with the shortest duration given the ordering criteria is met.
    Hence, for ‘AntiDur1’
  id: totrans-split-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些任务的 ‘Anti’ 版本中，正确的响应是在满足排序标准的情况下以刺激最短持续时间的方向。因此，对于 ‘AntiDur1’
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{if}}}\,\,du{r}_{{{{\rm{stim}}}}1} < du{r}_{{{{\rm{stim}}}}2}\\ {{{\rm{repress}}}}\quad
    &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-74
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{如果}}}\,\,du{r}_{{{{\rm{stim}}}}1} < du{r}_{{{{\rm{stim}}}}2}\\ {{{\rm{抑制}}}}\quad
    &\,{{\mbox{否则}}}\,\end{array}\right.$$
- en: and for ‘AntiDur2’
  id: totrans-split-75
  prefs: []
  type: TYPE_NORMAL
  zh: 以及对于 ‘AntiDur2’
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}2}\quad
    &\,{{\mbox{if}}}\,\,du{r}_{{{{\rm{stim}}}}2} < du{r}_{{{{\rm{stim}}}}1}\\ {{{\rm{repress}}}}\quad
    &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-76
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}2}\quad
    &\,{{\mbox{如果}}}\,\,du{r}_{{{{\rm{stim}}}}2} < du{r}_{{{{\rm{stim}}}}1}\\ {{{\rm{抑制}}}}\quad
    &\,{{\mbox{否则}}}\,\end{array}\right.$$
- en: Across these tasks directions are drawn according to \({\theta }_{{{{\rm{stim}}}}1}
    \sim {\mathbb{U}}[0,2\pi ]\) and \({\theta }_{{{{\rm{stim}}}}2} \sim {\mathbb{U}}[({\theta
    }_{{{{\rm{stim}}}}1}-0.2\pi ,{\theta }_{{{{\rm{stim}}}}1}-0.6\pi )\cup ({\theta
    }_{{{{\rm{stim}}}}1}+0.2\pi ,{\theta }_{{{{\rm{stim}}}}1}+0.6\pi )]\). Stimulus
    strengths are drawn according to \(st{r}_{{{{\rm{stim}}}}1},st{r}_{{{{\rm{stim}}}}2}
    \sim {\mathbb{U}}[0.8,1.2]\). To set the duration of each stimulus, we first draw
    \(du{r}_{{{{\rm{long}}}}} \sim\) \(\{i| 35 < i\le 50,i\in {\mathbb{N}}\}\) and
    \(du{r}_{{{{\rm{short}}}}} \sim \{i| 25 < i\le (du{r}_{{{{\rm{long}}}}}-8),i\in
    {\mathbb{N}}\}\). During training, we determine which trials for a given task
    should and should not require a response in order to evenly balance repress and
    respond trials. We then assign *d**u**r*[long] and *d**u**r*[short] to either
    stim1 or stim2 so that the trial requires the appropriate response given the particular
    task type.
  id: totrans-split-77
  prefs: []
  type: TYPE_NORMAL
  zh: 跨越这些任务方向是根据 \({\theta }_{{{{\rm{stim}}}}1} \sim {\mathbb{U}}[0,2\pi ]\) 和 \({\theta
    }_{{{{\rm{stim}}}}2} \sim {\mathbb{U}}[({\theta }_{{{{\rm{stim}}}}1}-0.2\pi ,{\theta
    }_{{{{\rm{stim}}}}1}-0.6\pi )\cup ({\theta }_{{{{\rm{stim}}}}1}+0.2\pi ,{\theta
    }_{{{{\rm{stim}}}}1}+0.6\pi )]\) 绘制的。刺激强度根据 \(st{r}_{{{{\rm{stim}}}}1},st{r}_{{{{\rm{stim}}}}2}
    \sim {\mathbb{U}}[0.8,1.2]\) 绘制。为了设置每个刺激的持续时间，我们首先绘制 \(du{r}_{{{{\rm{long}}}}}
    \sim\) \(\{i| 35 < i\le 50,i\in {\mathbb{N}}\}\) 和 \(du{r}_{{{{\rm{short}}}}}
    \sim \{i| 25 < i\le (du{r}_{{{{\rm{long}}}}}-8),i\in {\mathbb{N}}\}\)。在训练过程中，我们确定对于给定任务，哪些试验需要响应，哪些不需要，以平衡抑制和响应试验。然后，我们将
    *d**u**r*[long] 和 *d**u**r*[short] 分配给 stim1 或 stim2，以便根据特定的任务类型需要适当的响应。
- en: Again, criteria for correct response in the multisensory and modality-specific
    versions of each tasks follow analogous tasks in the ‘decision-making’ and ‘comparison’
    groups where multisensory versions of the task require integrating total duration
    over each modality, and modality-specific tasks require only considering durations
    in the given task modality. For multisensory tasks, we draw duration value \(du{r}_{{{{\rm{long}}}}}
    \sim \{i| 75 < i\le 100,i\in {\mathbb{N}}\}\) and then split this value *d**u**r*[long0] = *d**u**r*[long ]× 0.55
    and *d**u**r*[long1] = *d**u**r*[long ]× 0.45\. We also draw a value *d**u**r*[short] = *d**u**r*[long] − Δ*d**u**r*
    where \(\Delta dur \sim \{i| 15 < i\le 25,i\in {\mathbb{N}}\}\). This value is
    then subdivided further into *d**u**r*[short0] = *d**u**r*[long1] + Δ*d**u**r*[short]
    where \(\Delta du{r}_{{{{\rm{short}}}}} \sim\) \(\{i| 19 < i\le 15,i\in {\mathbb{N}}\}\)
    and *d**u**r*[short1] = *d**u**r*[Short] − *d**u**r*[short0]. Short and long durations
    can then be allocated to the ordered stimuli according to task type. Drawing durations
    in this manner ensures that, like in ‘decision-making’ and ‘comparison’ groups,
    correct answers truly require models to integrate durations over both modalities,
    rather than simply performing the task in a given modality to achieve correct
    responses.
  id: totrans-split-78
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，多感官和特定模态版本的每个任务的正确响应标准遵循类似于“决策制定”和“比较”组中的类似任务，其中多感官版本的任务要求整合每种模态的总持续时间，而特定模态的任务仅需要考虑给定任务模态中的持续时间。对于多感官任务，我们绘制持续时间值
    \(du{r}_{{{{\rm{long}}}}} \sim \{i| 75 < i\le 100,i\in {\mathbb{N}}\}\)，然后将这个值分成
    *d**u**r*[long0] = *d**u**r*[long ]× 0.55 和 *d**u**r*[long1] = *d**u**r*[long ]× 0.45。我们还绘制一个值
    *d**u**r*[short] = *d**u**r*[long] − Δ*d**u**r*，其中 \(\Delta dur \sim \{i| 15 <
    i\le 25,i\in {\mathbb{N}}\}\)。然后将此值进一步细分为 *d**u**r*[short0] = *d**u**r*[long1] + Δ*d**u**r*[short]，其中
    \(\Delta du{r}_{{{{\rm{short}}}}} \sim\) \(\{i| 19 < i\le 15,i\in {\mathbb{N}}\}\)，以及
    *d**u**r*[short1] = *d**u**r*[Short] − *d**u**r*[short0]。然后根据任务类型将短时和长时持续时间分配给有序刺激。通过这种方式绘制持续时间，确保像“决策制定”和“比较”组中一样，正确的答案确实要求模型整合两种模态的持续时间，而不仅仅是在给定模态中执行任务以实现正确的响应。
- en: ‘Matching’ tasks
  id: totrans-split-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ‘匹配’任务
- en: The ‘matching’ family of tasks consists of ‘DMS’ (delay match to stimulus),
    ‘DNMS’ (delay non-match to stimulus), ‘DMC’ (delay match to category) and ‘DMNC’
    (delay non-match to category) tasks. For all tasks, stim1 is presented at the
    beginning of the stimulus epoch, followed by a delay, and the presentation of
    stim2\. The stimulus strength is drawn according to \(st{r}_{{{{\rm{stim}}}}1},st{r}_{{{{\rm{stim}}}}2}
    \sim {\mathbb{U}}[0.8,1.2]\). The input modality for any given trial is chosen
    at random with equal probability. In both ‘DMS’ and ‘DNMS’ tasks, trials are constructed
    as ‘matching stim’ trials or ‘mismatching stim’ trials with equal probability.
    In ‘matching stim’ trials \({\theta }_{{{{\rm{stim}}}}1} \sim {\mathbb{U}}[0,2\pi
    ]\) and \({\theta }_{{{{\rm{stim}}}}2}={\theta }_{{{{\rm{stim}}}}1}\). In ‘mismatch
    stim’ trials, \({\theta }_{{{{\rm{stim}}}}1} \sim {\mathbb{U}}[0,2\pi ]\) and
  id: totrans-split-80
  prefs: []
  type: TYPE_NORMAL
  zh: ‘matching’ 任务系列包括 ‘DMS’（延迟匹配到刺激物）、‘DNMS’（延迟不匹配到刺激物）、‘DMC’（延迟匹配到类别）和 ‘DMNC’（延迟不匹配到类别）任务。对于所有任务，stim1
    在刺激时期开始时呈现，随后是一个延迟，然后是 stim2 的呈现。刺激强度根据 \(st{r}_{{{{\rm{stim}}}}1},st{r}_{{{{\rm{stim}}}}2}
    \sim {\mathbb{U}}[0.8,1.2]\) 进行抽取。任意给定试验的输入模态以相等概率随机选择。在 ‘DMS’ 和 ‘DNMS’ 任务中，试验分为
    ‘matching stim’ 试验或 ‘mismatching stim’ 试验，概率相等。在 ‘matching stim’ 试验中，\({\theta
    }_{{{{\rm{stim}}}}1} \sim {\mathbb{U}}[0,2\pi ]\) 和 \({\theta }_{{{{\rm{stim}}}}2}={\theta
    }_{{{{\rm{stim}}}}1}\)。在 ‘mismatch stim’ 试验中，\({\theta }_{{{{\rm{stim}}}}1} \sim
    {\mathbb{U}}[0,2\pi ]\) 和
- en: $${\theta }_{{{{\rm{stim}}}}2} \sim {\mathbb{U}}[({\theta }_{{{{\rm{stim}}}}1}-0.2\pi
    ,{\theta }_{{{{\rm{stim}}}}1}-0.6\pi )\cup ({\theta }_{{{{\rm{stim}}}}1}+0.2\pi
    ,{\theta }_{{{{\rm{stim}}}}1}+0.6\pi )].$$
  id: totrans-split-81
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{stim}}}}2} \sim {\mathbb{U}}[({\theta }_{{{{\rm{stim}}}}1}-0.2\pi
    ,{\theta }_{{{{\rm{stim}}}}1}-0.6\pi )\cup ({\theta }_{{{{\rm{stim}}}}1}+0.2\pi
    ,{\theta }_{{{{\rm{stim}}}}1}+0.6\pi )]。$$
- en: For ‘DMS’, models must respond in the displayed direction if the stimuli match,
    otherwise repress response,
  id: totrans-split-82
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 ‘DMS’，如果刺激物匹配，模型必须在显示的方向作出响应，否则抑制响应，
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{if}}}\,\,{\theta }_{{{{\rm{stim}}}}1}={\theta }_{{{{\rm{stim}}}}2}\\
    {{{\rm{repress}}}}\quad &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-83
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{if}}}\,\,{\theta }_{{{{\rm{stim}}}}1}={\theta }_{{{{\rm{stim}}}}2}\\
    {{{\rm{repress}}}}\quad &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
- en: and for ‘DNMS’, models must respond to the second direction if both directions
    are mismatched,
  id: totrans-split-84
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 ‘DNMS’，如果两个方向不匹配，模型必须响应于第二个方向，
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}2}\quad
    &\,{{\mbox{if}}}\,\,{\theta }_{{{{\rm{stim}}}}1}\ne {\theta }_{{{{\rm{stim}}}}2}\\
    {{{\rm{repress}}}}\quad &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-85
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}2}\quad
    &\,{{\mbox{if}}}\,\,{\theta }_{{{{\rm{stim}}}}1}\ne {\theta }_{{{{\rm{stim}}}}2}\\
    {{{\rm{repress}}}}\quad &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
- en: ‘DMC’ and ‘DNMC’ tasks are organized in a similar manner. The stimulus input
    space is divided evenly into two categories such that cat1 = {*θ*: 0 < *θ*≤*π*}
    and cat2 = {*θ*: *π* < *θ*≤2*π*}. For ‘DMC’ and ‘DNMC’ tasks, trials are constructed
    as ‘matching cat.’ trials or ‘mismatching cat.’ trials with equal probability.
    In ‘matching cat.’ trials \({\theta }_{{{{\rm{stim}}}}1} \sim {\mathbb{U}}[0,2\pi
    ]\) and \({\theta }_{{{{\rm{stim}}}}2} \sim {\mathbb{U}}({{{\mbox{cat}}}}_{{{{\rm{stim}}}}1})\),
    where \({\mathbb{U}}({{{\mbox{cat}}}}_{{{{\rm{stim}}}}1})\) is a uniform draw
    from the category of stim1\. In ‘mismatch stim’ trials, \({\theta }_{{{{\rm{stim}}}}1}
    \sim {\mathbb{U}}[0,2\pi ]\) and \({\theta }_{{{{\rm{stim}}}}2} \sim {\mathbb{U}}(-{{{\mbox{cat}}}}_{{{{\rm{stim}}}}1})\)
    where \(-{{{\mbox{cat}}}}_{{{{\rm{stim}}}}1}\) is the opposite category as stim1\.
    For ‘DMC’, the model must respond in the first direction if both stimuli are presented
    in the same category otherwise repress response,
  id: totrans-split-86
  prefs: []
  type: TYPE_NORMAL
  zh: ‘DMC’ 和 ‘DNMC’ 任务以类似方式组织。刺激输入空间均匀分为两类，即 cat1 = {*θ*: 0 < *θ*≤*π*} 和 cat2 = {*θ*: *π* < *θ*≤2*π*}。对于
    ‘DMC’ 和 ‘DNMC’ 任务，试验分为 ‘matching cat.’ 试验或 ‘mismatching cat.’ 试验，概率相等。在 ‘matching
    cat.’ 试验中，\({\theta }_{{{{\rm{stim}}}}1} \sim {\mathbb{U}}[0,2\pi ]\) 和 \({\theta
    }_{{{{\rm{stim}}}}2} \sim {\mathbb{U}}({{{\mbox{cat}}}}_{{{{\rm{stim}}}}1})\)，其中
    \({\mathbb{U}}({{{\mbox{cat}}}}_{{{{\rm{stim}}}}1})\) 是从 stim1 的类别中均匀抽取的。在 ‘mismatch
    stim’ 试验中，\({\theta }_{{{{\rm{stim}}}}1} \sim {\mathbb{U}}[0,2\pi ]\) 和 \({\theta
    }_{{{{\rm{stim}}}}2} \sim {\mathbb{U}}(-{{{\mbox{cat}}}}_{{{{\rm{stim}}}}1})\)，其中
    \(-{{{\mbox{cat}}}}_{{{{\rm{stim}}}}1}\) 是与 stim1 相反的类别。对于 ‘DMC’，如果两个刺激物呈现在相同的类别中，模型必须在第一个方向作出响应，否则抑制响应，
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{if}}}\,\,{{{\mbox{cat}}}}_{{{{\rm{stim}}}}1}={{{\mbox{cat}}}}_{{{{\rm{stim}}}}2}\\
    {{{\rm{repress}}}}\quad &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-87
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}1}\quad
    &\,{{\mbox{如果}}}\,\,{{{\mbox{cat}}}}_{{{{\rm{stim}}}}1}={{{\mbox{cat}}}}_{{{{\rm{stim}}}}2}\\
    {{{\rm{抑制}}}}\quad &\,{{\mbox{否则}}}\,\end{array}\right.$$
- en: and for ‘DNMC’, the model should respond to the second direction if both stimuli
    are presented in opposite categories otherwise repress response,
  id: totrans-split-88
  prefs: []
  type: TYPE_NORMAL
  zh: '-   对于''DNMC''，如果两个刺激出现在相反的类别中，则模型应对第二个方向作出响应，否则抑制响应。'
- en: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}2}\quad
    &\,{{\mbox{if}}}\,\,{{{\mbox{cat}}}}_{{{{\rm{stim}}}}1}\ne {{{\mbox{cat}}}}_{{{{\rm{stim}}}}2}\\
    {{{\rm{repress}}}}\quad &\,{{\mbox{otherwise}}}\,\end{array}\right.$$
  id: totrans-split-89
  prefs: []
  type: TYPE_NORMAL
  zh: $${\theta }_{{{{\rm{target}}}}}=\left\{\begin{array}{ll}{\theta }_{{{{\rm{stim}}}}2}\quad
    &\,{{\mbox{如果}}}\,\,{{{\mbox{cat}}}}_{{{{\rm{stim}}}}1}\ne {{{\mbox{cat}}}}_{{{{\rm{stim}}}}2}\\
    {{{\rm{抑制}}}}\quad &\,{{\mbox{否则}}}\,\end{array}\right.$$
- en: Target output and correct criteria
  id: totrans-split-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '-   目标输出和正确标准'
- en: The target output \(y\in {{\mathbb{R}}}^{33\times T}\) for a trial entails maintaining
    fixation in *y*[1] = *y*[fix] during the stimulus epoch, and then either responding
    in the correct direction or repressing activity in the remaining target response
    units *y*[2…33] in the response epoch. Since the model should maintain fixation
    until response, target for fixation is set at *y*[fix] = 0.85 during preparatory
    and stimulus epochs and *y*[fix] = 0.05 in the response epoch. When a response
    is not required, as in the preparatory and stimulus epochs and with repressed
    activity in the response epoch, unit *i* takes on a target activity of *y*[*i*] = 0.05\.
    Alternatively, when there is a target direction for response,
  id: totrans-split-91
  prefs: []
  type: TYPE_NORMAL
  zh: '-   试验的目标输出\(y\in {{\mathbb{R}}}^{33\times T}\)要求在刺激时期保持注视在*y*[1] = *y*[fix]，然后在响应时期要么朝着正确方向响应，要么在其余的目标响应单位*y*[2…33]中抑制活动。由于模型应保持注视直至响应，因此注视的目标设置为*y*[fix] = 0.85在准备和刺激时期和*y*[fix] = 0.05在响应时期。当不需要响应时，如在准备和刺激时期以及响应时期的抑制活动中，单位*i*的目标活动为*y*[*i*] = 0.05。或者，当存在响应方向目标时，'
- en: $${y}_{i}=0.8\exp \left[-0.5 \times {\left(\frac{8| {\theta }_{{{{\rm{target}}}}}-{\theta
    }_{i}| }{\pi }\right)}^{2}\right]+0.05$$
  id: totrans-split-92
  prefs: []
  type: TYPE_NORMAL
  zh: $${y}_{i}=0.8\exp \left[-0.5 \times {\left(\frac{8| {\theta }_{{{{\rm{target}}}}}-{\theta
    }_{i}| }{\pi }\right)}^{2}\right]+0.05$$
- en: where *θ*[*i*] is the preferred direction for unit *i*. Like in sensory stimuli,
    preferred directions for target units are evenly spaced values from [0, 2*π*]
    allocated to the 32 response units.
  id: totrans-split-93
  prefs: []
  type: TYPE_NORMAL
  zh: '-   其中*θ*[*i*]是单位*i*的首选方向。类似于感觉刺激，目标单位的首选方向是从[0, 2*π*]分配给32个响应单元的均匀分布值。'
- en: For a model response to count as correct, it must maintain fixation, that is,
    \({\hat{y}}_{{{{\rm{fix}}}}} > 0.5\) during preparatory and stimulus epochs. When
    no response is required \({\hat{y}}_{i} < 0.15\). When a response is required,
    response activity is decoded using a population vector method and \({\theta }_{{{{\rm{resp}}}}.}\in
    ({\theta }_{{{{\rm{target}}}}}-\frac{\pi }{10},{\theta }_{{{{\rm{target}}}}}+\frac{\pi
    }{10})\). If the model fails to meet any of these criteria, the trial response
    is incorrect.
  id: totrans-split-94
  prefs: []
  type: TYPE_NORMAL
  zh: '-   模型的正确响应必须在准备和刺激时期维持凝视，即\({\hat{y}}_{{{{\rm{fix}}}}} > 0.5\)。当不需要响应时\({\hat{y}}_{i}
    < 0.15\)。需要响应时，使用种群矢量方法解码响应活动，并且\({\theta }_{{{{\rm{resp}}}}.}\in ({\theta }_{{{{\rm{target}}}}}-\frac{\pi
    }{10},{\theta }_{{{{\rm{target}}}}}+\frac{\pi }{10})\)。如果模型未达到任何这些标准，则试验响应为错误。'
- en: Model training
  id: totrans-split-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '-   模型训练'
- en: Again following ref. ^([18](/articles/s41593-024-01607-5#ref-CR18 "Yang, G.
    R., Joglekar, M. R., Song, H. F., Newsome, W. T. & Wang, X.-J. Task representations
    in neural networks trained to perform many cognitive tasks. Nat. Neurosci. 22,
    297–306 (2019).")), model parameters are updated in a supervised fashion according
    to a masked mean squared error loss (mMSE) computed between the model motor response,
    \({\hat{y}}_{1\ldots T}=\hat{y}\), and the target, *y*[1…*T*] = *y*, for each
    trial.
  id: totrans-split-96
  prefs: []
  type: TYPE_NORMAL
  zh: '-   再次根据参考文献^([18](/articles/s41593-024-01607-5#ref-CR18 "Yang, G. R., Joglekar,
    M. R., Song, H. F., Newsome, W. T. & Wang, X.-J. Task representations in neural
    networks trained to perform many cognitive tasks. Nat. Neurosci. 22, 297–306 (2019)."))^，模型参数按照掩码均方误差损失（mMSE）进行监督式更新，计算模型的运动响应\({\hat{y}}_{1\ldots
    T}=\hat{y}\)和目标*y*[1…*T*] = *y*每个试验。'
- en: $$L={{{\rm{mMSE}}}}(\,y,\hat{y})={\rm{mask}} \times {\Big\langle {\left({\,y}_{t}-{{\hat{y}_{t}}}\right)}^{2}\Big\rangle
    }_{t}$$
  id: totrans-split-97
  prefs: []
  type: TYPE_NORMAL
  zh: $$L={{{\rm{mMSE}}}}(\,y,\hat{y})={\rm{mask}} \times {\Big\langle {\left({\,y}_{t}-{{\hat{y}_{t}}}\right)}^{2}\Big\rangle
    }_{t}$$
- en: Here, the multiplication sign denotes element-wise multiplication. Masks weigh
    the importance of different trial epochs. During preparatory and stimulus epochs,
    mask weights are set to 1; during the first five time steps of the response epoch,
    the mask value is set to 0; and during the remainder of the response epoch, the
    mask weight is set to 5\. The mask value for the fixation is twice that of other
    values at all time steps.
  id: totrans-split-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，乘法符号表示逐元素乘法。掩码权重衡量不同试验时期的重要性。在准备和刺激时期，掩码权重设置为 1；在响应时期的前五个时间步中，掩码值设为 0；在响应时期的其余时间步中，掩码权重设为
    5。在所有时间步中，固定的掩码值是其他值的两倍。
- en: For all models, we update Θ = {sensorimotor-RNN, Linear[out]} during training
    on our task set. For instructed models, we additionally update Linear[embed] in
    the process of normal training. We train models using standard PyTorch machinery
    and an Adam optimizer. An epoch consists of 2,400 mini-batches, with each mini-batch
    consisting of 64 trials. For all models, we use the same initial learning rate
    as in ref. ^([18](/articles/s41593-024-01607-5#ref-CR18 "Yang, G. R., Joglekar,
    M. R., Song, H. F., Newsome, W. T. & Wang, X.-J. Task representations in neural
    networks trained to perform many cognitive tasks. Nat. Neurosci. 22, 297–306 (2019).")),
    *l**r* = 0.001\. We found that in the later phases of training, model performance
    oscillated based on which latest task presented during training, so we decayed
    the learning rate for each epoch by a factor of *γ* = 0.95, which allowed performance
    to converge smoothly. Following ref. ^([18](/articles/s41593-024-01607-5#ref-CR18
    "Yang, G. R., Joglekar, M. R., Song, H. F., Newsome, W. T. & Wang, X.-J. Task
    representations in neural networks trained to perform many cognitive tasks. Nat.
    Neurosci. 22, 297–306 (2019).")), models train until they reach a threshold performance
    of 95% across all tasks (and train for a minimum of 35 epochs). We found that
    training for GPTNET tended to asymptote below performance threshold for multisensory
    versions of comparison tasks. This held true over a variety of training hyperparameters
    and learning rate scheduler regimes. Hence, we relax the performance threshold
    of GPTNET to 85%. For each model type, we train five models that start from five
    different random initializations. Where applicable, results are averaged over
    these initializations.
  id: totrans-split-99
  prefs: []
  type: TYPE_NORMAL
  zh: 对于所有模型，在我们的任务集上训练时，我们更新 Θ = {sensorimotor-RNN, Linear[out]}。对于指导模型，在正常训练过程中，我们还会更新
    Linear[embed]。我们使用标准的PyTorch工具和Adam优化器进行模型训练。一个时代包括 2,400 个小批次，每个小批次包含 64 个试验。对于所有模型，我们使用与参考文献
    ^([18](/articles/s41593-024-01607-5#ref-CR18 "Yang, G. R., Joglekar, M. R., Song,
    H. F., Newsome, W. T. & Wang, X.-J. Task representations in neural networks trained
    to perform many cognitive tasks. Nat. Neurosci. 22, 297–306 (2019).")) 相同的初始学习率，*l**r* = 0.001。我们发现，在训练的后期阶段，模型的表现会根据训练过程中呈现的最新任务而振荡，因此我们通过
    *γ* = 0.95 的因子将每个时代的学习率衰减，这使得性能能够平稳收敛。根据参考文献 ^([18](/articles/s41593-024-01607-5#ref-CR18
    "Yang, G. R., Joglekar, M. R., Song, H. F., Newsome, W. T. & Wang, X.-J. Task
    representations in neural networks trained to perform many cognitive tasks. Nat.
    Neurosci. 22, 297–306 (2019)."))，模型训练直到达到所有任务的 95% 阈值（并且至少训练 35 个时代）。我们发现，对于 GPTNET
    的训练往往在多感官版本比较任务的性能阈值以下趋于渐近。这一点在各种训练超参数和学习率调度器制度下都成立。因此，我们将 GPTNET 的性能阈值放宽到 85%。对于每种模型类型，我们从五种不同的随机初始化开始训练五个模型。在适用的情况下，结果是这些初始化的平均值。
- en: Language model fine-tuning
  id: totrans-split-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 语言模型微调
- en: When fine-tuning models, we allow the gradient from the motor loss experienced
    during sensorimotor training to fine-tune the weights in the final layers of the
    transformer language models. During normal training, we checkpoint a copy of our
    instructed models after training for 30 epochs. We then add the last three transformer
    layers to the set of trainable parameters, and reset the learning rates to *l**r* = 1 × 10^−⁴
    for Θ = {sensorimotor-RNN, Linear[out]} and *l**r*^(lang) = 3 × 10^(−4) for Θ^(lang) = {Linear[embed], transformer[−3,−2,−1]}
    where transformer[−3,−2,−1] denotes the parameters of the last three layers of
    the relevant transformer architecture. We used these reduced learning rates to
    avoid completely erasing preexisting linguistic knowledge. Similarly for RNN parameters,
    we found the above learning rate avoided catastrophic forgetting of sensorimotor
    knowledge while also allowing the RNN to adapt to updated language embeddings
    across all models. Autoregressive models were much more sensitive to this procedure,
    often collapsing at the beginning of fine-tuning. Hence, for GPTNETXL and GPTNET,
    we used *l**r*^(lang) = 5 × 10^(−5), which resulted in robust learning. Models
    train until they reach a threshold performance of 95% across training tasks or
    85% correct for GPTNET.
  id: totrans-split-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调模型时，我们允许来自传感器运动训练期间体验到的电机损失梯度，微调变压器语言模型的最终层的权重。在正常训练期间，我们在训练30个周期后对我们指导的模型进行检查点处理。然后，我们将最后三个变压器层添加到可训练参数集中，并将学习率重置为
    *l**r* = 1 × 10^−⁴，对于 Θ = {sensorimotor-RNN, Linear[out]} 和 *l**r*^(lang) = 3 × 10^(−4)，对于
    Θ^(lang) = {Linear[embed], transformer[−3,−2,−1]} 其中 transformer[−3,−2,−1] 表示相关变压器体系结构的最后三层的参数。我们使用这些降低的学习率来避免完全擦除现有的语言知识。同样对于
    RNN 参数，我们发现上述学习率避免了对传感器运动知识的灾难性遗忘，同时也允许 RNN 适应所有模型中更新的语言嵌入。自回归模型对这一过程更为敏感，通常在微调开始时就崩溃。因此，对于
    GPTNETXL 和 GPTNET，我们使用 *l**r*^(lang) = 5 × 10^(−5)，这导致了稳健的学习。模型训练直到达到 95% 的训练任务阈值或对于
    GPTNET，正确率为 85%。
- en: Hold-out testing
  id: totrans-split-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 留出测试
- en: During hold-out testing, we present models with 100 batches of one of the tasks
    that had been held out of training. For the instructed model, the only weights
    allowed to update during this phase are Θ = {sensorimotor-RNN, Linear[out], Linear[embed]}.
    All weights of SIMPLENET and STRUCTURENET are trainable in this context. In this
    hold-out setting, we found that in more difficult tasks for some of our more poorly
    performing models, the standard hyperparameters we used during training resulted
    in unstable learning curves for novel tasks. To stabilize performance and thereby
    create fair comparisons across models, we used an increased batch size of 256\.
    We then began with the standard learning rate of 0.001 and decreased this by increments
    of 0.0005 until all models showed robust learning curves. This resulted in a learning
    rate of 8 × 10^(−4). All additional results shown in the [Supplementary Information](/articles/s41593-024-01607-5#Sec36)
    section 4 follow this procedure.
  id: totrans-split-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在留出测试期间，我们向模型展示了一个被留出训练的任务的 100 批次。对于指导模型，在这个阶段允许更新的唯一权重是 Θ = {sensorimotor-RNN, Linear[out], Linear[embed]}。在此上下文中，SIMPLENET
    和 STRUCTURENET 的所有权重都是可训练的。在这种留出设置中，我们发现对于一些表现较差的模型中更困难的任务，我们在训练期间使用的标准超参数导致了新任务的不稳定学习曲线。为了稳定性能并因此在模型之间进行公平比较，我们增加了批量大小至
    256。然后，我们从标准学习率 0.001 开始，逐步减少 0.0005，直到所有模型显示出稳健的学习曲线。这导致了一个学习率为 8 × 10^(−4)。所有额外的结果在
    [补充信息](/articles/s41593-024-01607-5#Sec36) 第 4 节中都遵循这一过程。
- en: CCGP calculation
  id: totrans-split-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CCGP 计算
- en: 'To calculate CCGP, we trained a linear decoder on a pair of tasks and then
    tested that decoder on alternative pairs of tasks that have an analogous relationship.
    We grouped tasks into eight dichotomies: ‘Go’ versus ‘Anti’, ‘Standard’ versus
    ‘RT’, ‘Weakest’ versus ‘Strongest’, ‘Longest’ versus ‘Shortest’, ‘First Stim.’
    versus ‘Second Stim’, ‘Stim Match’ versus ‘Category Match’, ‘Matching’ versus
    ‘Non-Matching’ and ‘Mod1’ versus ‘Mod2’. As an example, the ‘Go’ versus ‘Anti’
    dichotomy includes (‘Go’, ‘AntiGo’), (‘GoMod1’, ‘AntiGoMod1’), (‘GoMod2’, ‘AntiGoMod2’),
    (‘RTGo’, ‘AntiRTGo’), (‘RTGoMod1’, ‘AntiRTGoMod1’) and (‘RTGoMod2’, ‘AntiRTGoMod2’)
    task pairs. For ‘RNN’ task representations, we extracted activity at the time
    of stimulus onset for 250 example trials. For language representations, we input
    the instruction sets for relevant tasks to our language model and directly analyze
    activity in the ‘embedding’ layer or take the sequence-averaged activity in each
    transformer layer. For nonlinguistic models, we simply analyze the space of rule
    vectors. Train and test conditions for decoders were determined by dichotomies
    identified across the task set (Supplementary Note [1](/articles/s41593-024-01607-5#MOESM1)).
    To train and test decoders, we used sklearn.svm.LinearSVC Python package. The
    CCGP score for a given task is the average decoding score achieved across all
    dichotomies where the task in question was part of either the train set or the
    test set. For model scores reported in the main text, we only calculate CCGP scores
    for models where the task in question has been held out of training. In Supplementary
    Fig. [9](/articles/s41593-024-01607-5#MOESM1), we report scores on tasks where
    models have been trained on all tasks, and for models where instructions have
    been switched for the hold-out task.'
  id: totrans-split-105
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算CCGP，我们在一对任务上训练了一个线性解码器，然后在具有类似关系的替代任务对上测试了该解码器。我们将任务分成了八个二分法：‘Go’ versus
    ‘Anti’，‘Standard’ versus ‘RT’，‘Weakest’ versus ‘Strongest’，‘Longest’ versus ‘Shortest’，‘First
    Stim.’ versus ‘Second Stim’，‘Stim Match’ versus ‘Category Match’，‘Matching’ versus
    ‘Non-Matching’ 和 ‘Mod1’ versus ‘Mod2’。例如，‘Go’ versus ‘Anti’ 二分法包括（‘Go’，‘AntiGo’），（‘GoMod1’，‘AntiGoMod1’），（‘GoMod2’，‘AntiGoMod2’），（‘RTGo’，‘AntiRTGo’），（‘RTGoMod1’，‘AntiRTGoMod1’）和（‘RTGoMod2’，‘AntiRTGoMod2’）任务对。对于‘RNN’任务表示，我们提取了250个示例试验的刺激开始时的活动。对于语言表示，我们向我们的语言模型输入相关任务的指令集，并直接分析‘嵌入’层中的活动或在每个变压器层中进行序列平均活动。对于非语言模型，我们简单地分析规则向量空间。解码器的训练和测试条件由跨任务集识别的二分法确定（补充说明
    [1](/articles/s41593-024-01607-5#MOESM1)）。为了训练和测试解码器，我们使用了sklearn.svm.LinearSVC
    Python包。给定任务的CCGP分数是在任务被训练集或测试集中的二分法中获得的平均解码分数。对于主文中报告的模型分数，我们仅计算了对于任务已被从训练中排除的模型的CCGP分数。在补充图
    [9](/articles/s41593-024-01607-5#MOESM1) 中，我们报告了在模型已对所有任务进行训练并且对保留任务进行了指令切换的任务上的分数。
- en: For Fig. [3e](/articles/s41593-024-01607-5#Fig3), we calculated Pearson’s *r*
    correlation coefficient between performance on held-out tasks and CCGP scores
    per task, as well as a *P*-value testing against the null hypothesis that these
    metrics are uncorrelated and normally distributed (using the scipy.stats.pearsonr
    function). Full statistical tests for CCGP scores of both RNN and embedding layers
    from Fig. [3f](/articles/s41593-024-01607-5#Fig3) can be found in Supplementary
    Fig. [9](/articles/s41593-024-01607-5#MOESM1). Note that transformer language
    models use the same set of pretrained weights among random initialization of Sensorimotor-RNNs,
    thus for language model layers, the Fig. [3f](/articles/s41593-024-01607-5#Fig3)
    plots show the absolute scores of those language models.
  id: totrans-split-106
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图 [3e](/articles/s41593-024-01607-5#Fig3)，我们计算了持有任务表现与每个任务的CCGP分数之间的Pearson's
    *r*相关系数，以及一个*P*-值，检验这些指标是否不相关且正态分布（使用scipy.stats.pearsonr函数）。关于图 [3f](/articles/s41593-024-01607-5#Fig3)
    中RNN和嵌入层的完整统计测试可以在补充图 [9](/articles/s41593-024-01607-5#MOESM1) 中找到。请注意，变压器语言模型在随机初始化Sensorimotor-RNNs时使用相同的预训练权重集，因此对于语言模型层，图
    [3f](/articles/s41593-024-01607-5#Fig3) 中显示了这些语言模型的绝对分数。
- en: Conditional clause/deduction task analysis
  id: totrans-split-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 条件从句/推断任务分析
- en: 'We first split our task set into two groups (listed below): tasks that included
    conditional clauses and simple deductive reasoning components (30 tasks) and those
    where instructions include simple imperatives (20 tasks). We computed the difference
    in performance across the mean of generalization performance for each group across
    random initialization for each model (Fig. [2f](/articles/s41593-024-01607-5#Fig2)).
    We compared these differences to a null distribution constructed by performing
    a set of 50 random shuffles of the task set into groups of 30 and 20 tasks and
    computing differences in the same way, again using two-sided unequal-variance
    *t*-tests. Because STRUCUTRENET is a nonlinguistic model, we then compared performance
    of STRUCUTRENET to our instructed models to disassociate the effects of performing
    tasks with a deductive reasoning component versus processing instructions with
    more complicated conditional clause structure. Results of all statistical tests
    are reported in Supplementary Fig. [6](/articles/s41593-024-01607-5#MOESM1)).'
  id: totrans-split-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先将我们的任务集分成两组（如下所列）：包括条件子句和简单演绎推理组成部分的任务（30个任务）以及那些指令包括简单祈使句的任务（20个任务）。我们计算了每组在每个模型的随机初始化下的泛化性能均值之间的性能差异（图[2f](/articles/s41593-024-01607-5#Fig2)）。我们将这些差异与一个由对任务集进行50次随机洗牌并以相同方式计算差异的空分布进行比较，再次使用双侧异方差*t*检验。因为STRUCUTRENET是一个非语言模型，我们随后比较了STRUCUTRENET与我们指导模型的性能，以分离具有演绎推理成分的任务执行效果与处理具有更复杂条件子句结构指令的效果。所有统计检验结果见补充图[6](/articles/s41593-024-01607-5#MOESM1)。
- en: 'Simple imperative tasks include: ‘Go’, ‘AntiGo’, ‘RTGo’, ‘AntiRTGo’, ‘GoMod1’,
    ‘GoMod2’, ‘AntiGoMod1’, ‘AntiGoMod2’, ‘RTGoMod1’, ‘AntiRTGoMod2’, ‘RTGoMod2’,
    ‘AntiRTGoMod2’, ‘DM’, ‘AntiDM’, ‘MultiDM’, ‘AntiMultiDM’, ‘DMMod1’, ‘DMMod2’,
    ‘AntiDMMod1’ and ‘AntiDMMod2’.'
  id: totrans-split-109
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的祈使句任务包括：‘Go’, ‘AntiGo’, ‘RTGo’, ‘AntiRTGo’, ‘GoMod1’, ‘GoMod2’, ‘AntiGoMod1’,
    ‘AntiGoMod2’, ‘RTGoMod1’, ‘AntiRTGoMod2’, ‘RTGoMod2’, ‘AntiRTGoMod2’, ‘DM’, ‘AntiDM’,
    ‘MultiDM’, ‘AntiMultiDM’, ‘DMMod1’, ‘DMMod2’, ‘AntiDMMod1’和‘AntiDMMod2’。
- en: 'Conditional clause/deduction tasks include: ‘ConDM’, ‘ConAntiDM’, ‘Dur1’, ‘Dur2’,
    ‘MultiDur1’, ‘MultiDur2’, ‘AntiDur1’, ‘AntiDur2’, ‘AntiMultiDur1’, ‘AntiMultiDur2’,
    ‘Dur1Mod1’, ‘Dur1Mod2’, ‘Dur2Mod1’, ‘Dur2Mod2’, ‘COMP1’, ‘COMP2’, ‘MultiCOMP1’,
    ‘MultiCOMP2’, ‘AntiCOMP1’, ‘AntiCOMP2’, ‘AntiMultiCOMP1’, ‘AntiMultiCOMP2’, ‘COMP1Mod1’,
    ‘COMP1Mod2’, ‘COMP2Mod1’, ‘COMP2Mod2’, ‘DMS’, ‘DNMS’, ‘DMC’ and ‘DMNC’.'
  id: totrans-split-110
  prefs: []
  type: TYPE_NORMAL
  zh: 条件子句/演绎任务包括：‘ConDM’, ‘ConAntiDM’, ‘Dur1’, ‘Dur2’, ‘MultiDur1’, ‘MultiDur2’,
    ‘AntiDur1’, ‘AntiDur2’, ‘AntiMultiDur1’, ‘AntiMultiDur2’, ‘Dur1Mod1’, ‘Dur1Mod2’,
    ‘Dur2Mod1’, ‘Dur2Mod2’, ‘COMP1’, ‘COMP2’, ‘MultiCOMP1’, ‘MultiCOMP2’, ‘AntiCOMP1’,
    ‘AntiCOMP2’, ‘AntiMultiCOMP1’, ‘AntiMultiCOMP2’, ‘COMP1Mod1’, ‘COMP1Mod2’, ‘COMP2Mod1’,
    ‘COMP2Mod2’, ‘DMS’, ‘DNMS’, ‘DMC’和‘DMNC’。
- en: Language production training
  id: totrans-split-111
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语言生成训练
- en: Self-supervised language production network training
  id: totrans-split-112
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自监督语言生成网络训练
- en: Our language production framework is inspired by classic sequence-to-sequence
    modeling using RNNs^([53](/articles/s41593-024-01607-5#ref-CR53 "Sutskever, I.,
    Vinyals, O. & Le., Q. V. Sequence to sequence learning with neural networks. In
    Proc. 27th International Conference on Neural Information Processing Systems 3104–3112
    (MIT Press, 2014).")). Our Production-RNN is a GRU with 256 hidden units using
    ReLU nonlinearities. At each step in the sequence, a set of decoder weights, Linear[words],
    attempts to decode the next token, *w*[*τ*+1], from the hidden state of the recurrent
    units. The hidden state of the Production-RNN is initialized by concatenating
    the time average and maximum sensorimotor activity of a SBERTNET (L) and passing
    that through weights Linear[sm]. The linguistic instruction used to drive the
    initializing sensorimotor activity is in turn used as the target set of tokens
    for the Production-RNN outputs. The first input to the Production-RNN is always
    a special start-of-sentence token, and the decoder runs until an end-of-sentence
    token is decoded or until input reaches a length of 30 tokens. Suppose \({w}_{1,k}\ldots
    {w}_{{{{\mathcal{T}}}},k}\in {\rm{Instruc{t}}}_{k}^{i}\) is the sequence of tokens
    in instruction *k* where *k* is in the instruction set for task *i* and *X*^(*i*)
    is sensory input for a trial of task *i*. For brevity, we denote the process by
    which language models embed instructions as Embed() (see ‘Pretrained transformers’).
    The decoded token at the *τ*^(th) position, \({\hat{w}}_{\tau ,k}\), is then given
    by
  id: totrans-split-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的语言生成框架灵感来自经典的序列到序列建模，使用具有256隐藏单元的GRU及ReLU非线性函数。在序列的每一步中，一组解码器权重 Linear[words]
    尝试从递归单元的隐藏状态中解码下一个标记 *w*[*τ*+1]。Production-RNN 的隐藏状态通过将SBERTNET (L)的时间平均和最大感觉运动活动串联，然后通过权重
    Linear[sm] 进行初始化。驱动初始化感觉运动活动的语言指令，反过来成为Production-RNN输出的目标标记集。Production-RNN 的第一个输入始终是一个特殊的句子开头标记，解码器运行直到解码到句子结束标记或输入达到30个标记长度。假设
    \({w}_{1,k}\ldots {w}_{{{{\mathcal{T}}}},k}\in {\rm{Instruc{t}}}_{k}^{i}\) 是指令
    *k* 中的标记序列，其中 *k* 属于任务 *i* 的指令集，而 *X*^(*i*) 是任务 *i* 的试验感觉输入。为简洁起见，我们用Embed()表示语言模型嵌入指令的过程（见“预训练转换器”）。在第
    *τ*^(th) 位置的解码标记 \({\hat{w}}_{\tau ,k}\) 如下确定
- en: $$\begin{array}{ll}{h}_{T}^{sm}={{{\rm{SensorimotorRNN}}}}\left({X}^{i},Embed\left({w}_{1,k}\ldots
    {w}_{{{{\mathcal{T}}}},k}\right)\right)\quad\quad{h}_{T}^{sm}\in {{\mathbb{R}}}^{T\times
    256}\\ sm\_out=\left.\right({{{{\rm{mean}}}}}_{T}\left({h}_{T}^{sm}\right),\mathop{\max
    }\limits_{T}\left({h}_{T}^{sm}\right)\quad\quad\quad\quad\quad\quad\quad\quad\quad\;\;{sm}\_{out}\in
    {{\mathbb{R}}}^{512}\\ \overline{{h}_{0}^{{{{\rm{decoder}}}}}}={{{\rm{relu}}}}\left({{{{\rm{Linear}}}}}_{{{{\rm{sm}}}}}(sm\_out)\right)\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\;\overline{{h}_{0}^{{{{\rm{decoder}}}}}}\in
    {{\mathbb{R}}}^{256}\\ {h}_{0}^{{{{\rm{decoder}}}}}={{{\rm{Dropout}}}}\left(\overline{{h}_{0}^{{{{\rm{decoder}}}}}}\right)\;\;\;\quad\quad\quad\quad\quad\quad\quad\quad\quad\qquad\quad{h}_{0}^{{{{\rm{decoder}}}}}\in
    {{\mathbb{R}}}^{256}\\ {h}_{\tau }^{{{{\rm{decoder}}}}}={{{\rm{ProductionRNN}}}}\left({\hat{w}}_{1,k}\ldots
    {\hat{w}}_{\tau -1,k};{h}_{0}^{{{{\rm{decoder}}}}}\right),\quad\quad\quad{h}_{\tau
    }^{{{{\rm{decoder}}}}}\in {{\mathbb{R}}}^{256}\\ {p}_{{\hat{w}}_{\tau ,k}}={{{\rm{softmax}}}}\left({{{{\rm{Linear}}}}}_{{{{\rm{words}}}}}\left({h}_{\tau
    ,k}^{{{{\rm{decoder}}}}}\right)\right)\quad\quad\quad\quad\quad\quad\quad\quad\quad{p}_{{\hat{w}}_{\tau
    ,k}}\in {{\mathbb{R}}}^{| vocab| },\\ {\hat{w}}_{\tau ,k}={{{\rm{argmax}}}}\left({p}_{{\hat{w}}_{\tau
    ,k}}\right)\end{array}$$
  id: totrans-split-114
  prefs: []
  type: TYPE_NORMAL
  zh: $$\begin{array}{ll}{h}_{T}^{sm}={{{\rm{SensorimotorRNN}}}}\left({X}^{i},Embed\left({w}_{1,k}\ldots
    {w}_{{{{\mathcal{T}}}},k}\right)\right)\quad\quad{h}_{T}^{sm}\in {{\mathbb{R}}}^{T\times
    256}\\ sm\_out=\left.\right({{{{\rm{mean}}}}}_{T}\left({h}_{T}^{sm}\right),\mathop{\max
    }\limits_{T}\left({h}_{T}^{sm}\right)\quad\quad{sm}\_{out}\in {{\mathbb{R}}}^{512}\\
    \overline{{h}_{0}^{{{{\rm{decoder}}}}}}={{{\rm{relu}}}}\left({{{{\rm{Linear}}}}}_{{{{\rm{sm}}}}}(sm\_out)\right)\quad\quad\overline{{h}_{0}^{{{{\rm{decoder}}}}}}\in
    {{\mathbb{R}}}^{256}\\ {h}_{0}^{{{{\rm{decoder}}}}}={{{\rm{Dropout}}}}\left(\overline{{h}_{0}^{{{{\rm{decoder}}}}}}\right)\;\;\;\quad\quad\quad\quad\quad\quad{h}_{0}^{{{{\rm{decoder}}}}}\in
    {{\mathbb{R}}}^{256}\\ {h}_{\tau }^{{{{\rm{decoder}}}}}={{{\rm{ProductionRNN}}}}\left({\hat{w}}_{1,k}\ldots
    {\hat{w}}_{\tau -1,k};{h}_{0}^{{{{\rm{decoder}}}}}\right),\quad\quad{h}_{\tau
    }^{{{{\rm{decoder}}}}}\in {{\mathbb{R}}}^{256}\\ {p}_{{\hat{w}}_{\tau ,k}}={{{\rm{softmax}}}}\left({{{{\rm{Linear}}}}}_{{{{\rm{words}}}}}\left({h}_{\tau
    ,k}^{{{{\rm{decoder}}}}}\right)\right)\quad\quad{p}_{{\hat{w}}_{\tau ,k}}\in {{\mathbb{R}}}^{|
    vocab| },\\ {\hat{w}}_{\tau ,k}={{{\rm{argmax}}}}\left({p}_{{\hat{w}}_{\tau ,k}}\right)\end{array}$$
- en: The model parameters Θ^(production) = {Linear[sm], Linear[words], Production-RNN}
    are trained using cross-entropy loss between the \({p}_{{\hat{w}}_{\tau ,i}}\)
    and the instruction token *w*[*τ*,*k*] provided to the sensorimotor-RNN as input.
    We train for 80 epochs of 2,400 batches with 64 trials per batch and with task
    type randomly interleaved. We found that using an initial learning rate of 0.001
    sometimes caused models to diverge in early phases of training, so we opted for
    a learning rate of 1× 10^(−4), which led to stable early training. To alleviate
    similar oscillation problems detected in sensorimotor training, we also decayed
    the learning rate by *γ* = 0.99 per epoch. Additionally, the use of a dropout
    layer with a dropout rate of 0.05 improved performance. We also used a teacher
    forcing curriculum, where for some ratio of training batches, we input the ground
    truth instruction token *w*[*τ*,*k*] at each time step instead of the models decoded
    word \({\hat{w}}_{\tau ,k}\). At each epoch, \({\rm{teacher}}\,{{\mbox{\_}}}{\rm{forcing}}{{\mbox{\_}}}\)
    \({\rm{ratio}}=0.5 \times \frac{80-{{{\rm{epoch}}}}}{80}\).
  id: totrans-split-115
  prefs: []
  type: TYPE_NORMAL
  zh: 模型参数 Θ^(production) = {Linear[sm], Linear[words], Production-RNN} 使用了传感运动-RNN
    的输入 *w*[*τ*,*k*] 和 \({p}_{{\hat{w}}_{\tau ,i}}\) 之间的交叉熵损失进行训练。我们训练了 80 个 epoch，每个
    epoch 包含 2,400 个批次，每个批次包含 64 个试验，并且任务类型被随机交错。我们发现，使用初始学习率 0.001 有时会导致模型在训练早期发散，因此我们选择了学习率为
    1× 10^(−4)，这样可以保持稳定的早期训练。为了减轻在传感运动训练中检测到的类似振荡问题，我们还按每个 epoch 将学习率衰减 *γ* = 0.99。此外，使用了一个
    dropout 层，dropout 率为 0.05，改善了性能。我们还使用了一种教师强迫课程，其中在某些比例的训练批次中，我们在每个时间步输入地面真实的指令标记
    *w*[*τ*,*k*]，而不是模型解码的词 \({\hat{w}}_{\tau ,k}\)。每个 epoch，教师强迫比例 \({\rm{teacher}}\,{{\mbox{\_}}}{\rm{forcing}}{{\mbox{\_}}}\)
    \({\rm{ratio}}=0.5 \times \frac{80-{{{\rm{epoch}}}}}{80}\)。
- en: Obtaining embedding layer activity using motor feedback
  id: totrans-split-116
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用运动反馈获取嵌入层活动
- en: For a task, *i*, we seek to optimize a set of embedding activity vectors \({E}^{i}\in
    {{\mathbb{R}}}^{64}\) such that when they are input as task-identifying information,
    the model will perform the task in question. Crucially, we freeze all model weights
    Θ = {sensorimotor-RNN, Linear[out], Linear[embedding]} and only update *E*^(*i*)
    according to the standard supervised loss on the motor output. For notional clarity,
    GRU dependence on the previous hidden state *h*[*t*−1] has been made implicit
    in the following equations.
  id: totrans-split-117
  prefs: []
  type: TYPE_NORMAL
  zh: 对于任务*i*，我们寻求优化一组嵌入活动向量\({E}^{i}\in {{\mathbb{R}}}^{64}\)，使得当它们作为任务识别信息输入时，模型能够执行所需的任务。关键在于，我们冻结所有模型权重
    Θ = {sensorimotor-RNN, Linear[out], Linear[embedding]}，只根据运动输出上的标准监督损失更新 *E*^(*i*)。为了概念上的清晰，GRU
    对先前隐藏状态 *h*[*t*−1] 的依赖在下面的方程中被隐含地表示。
- en: $$\begin{array}{rcl}{\hat{y}}{\,}^{i}&=&\sigma \Big({{{{\rm{Linear}}}}}_{{{{\rm{out}}}}}\left({{{\rm{SensorimotorRNN}}}}({X}^{\,i},{E}^{i})\right)\Big)\\
    L&=&{\rm{mMSE}}(\;y,\hat{y})\end{array}$$
  id: totrans-split-118
  prefs: []
  type: TYPE_NORMAL
  zh: $$\begin{array}{rcl}{\hat{y}}{\,}^{i}&=&\sigma \Big({{{{\rm{Linear}}}}}_{{{{\rm{out}}}}}\left({{{\rm{SensorimotorRNN}}}}({X}^{\,i},{E}^{i})\right)\Big)\\
    L&=&{\rm{mMSE}}(\;y,\hat{y})\end{array}$$
- en: We optimized a set of 25 embedding vectors for each task, again using an Adam
    optimizer. Here the optimization space has many suboptimal local minimums corresponding
    to embeddings for related tasks. Hence, we used a high initial learning rate of
    *l**r* = 0.05, which we decayed by *γ* = 0.8 for each epoch. This resulted in
    more robust learning than lower learning rates. An epoch lasts for 800 batches
    with a batch length of 64, and we train for a minimum of 1 epoch or until we reach
    a threshold performance of 90% or 85% on ‘DMC’ and ‘DNMC’ tasks.
  id: totrans-split-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为每个任务优化了一组包含 25 个嵌入向量，同样使用了 Adam 优化器。在这里，优化空间中有许多对应于相关任务嵌入的次优局部最小值。因此，我们使用了初始学习率
    *l**r* = 0.05，并且每个 epoch 时将其衰减 *γ* = 0.8。这比较高的学习率导致了比较健壮的学习。一个 epoch 包含 800 个批次，每个批次包含
    64 个数据点，我们最少训练 1 个 epoch 或者直到在‘DMC’和‘DNMC’任务上达到 90% 或 85% 的阈值性能为止。
- en: Producing task instructions
  id: totrans-split-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 生成任务指令
- en: To produce task instructions, we simply use the set *E*^(*i*) as task-identifying
    information in the input of the sensorimotor-RNN and use the Production-RNN to
    output instructions based on the sensorimotor activity driven by *E*^(*i*). For
    each task, we use the set of embedding vectors to produce 50 instructions per
    task. We repeat this process for each of the 5 initializations of sensorimotor-RNN,
    resulting in 5 distinct language production networks, and 5 distinct sets of learned
    embedding vectors. Reported results for each task are averaged over these 5 networks.
    For the confusion matrix (Fig. [5d](/articles/s41593-024-01607-5#Fig5)), we report
    the average percentage that decoded instructions are in the training instruction
    set for a given task or a novel instruction. Partner model performance (Fig. [5e](/articles/s41593-024-01607-5#Fig5))
    for each network initialization is computed by testing each of the 4 possible
    partner networks and averaging over these results.
  id: totrans-split-121
  prefs: []
  type: TYPE_NORMAL
  zh: 要生成任务说明，我们只需在传感运动-RNN的输入中使用集合 *E*^(*i*) 作为任务识别信息，并使用Production-RNN基于由 *E*^(*i*)
    驱动的感觉运动活动输出说明。对于每个任务，我们使用嵌入向量集合为每个任务生成50条说明。我们对传感运动-RNN的5个初始化重复此过程，从而产生5个不同的语言生成网络和5个不同的学习嵌入向量集。每个任务的报告结果是在这5个网络上进行平均。对于混淆矩阵（图[5d](/articles/s41593-024-01607-5#Fig5)），我们报告了解码说明在给定任务或新说明的训练说明集中的平均百分比。合作模型性能（图[5e](/articles/s41593-024-01607-5#Fig5)）针对每个网络初始化通过测试每个可能的4个合作网络并对这些结果进行平均来计算。
- en: Sample sizes/randomization
  id: totrans-split-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 样本大小/随机化
- en: No statistical methods were used to predetermine sample sizes but following
    ref. ^([18](/articles/s41593-024-01607-5#ref-CR18 "Yang, G. R., Joglekar, M. R.,
    Song, H. F., Newsome, W. T. & Wang, X.-J. Task representations in neural networks
    trained to perform many cognitive tasks. Nat. Neurosci. 22, 297–306 (2019)."))
    we used five different random weight initializations per language model tested.
    Randomization of weights was carried out automatically in Python and PyTorch software
    packages. Given this automated randomization of weights, we did not use any blinding
    procedures in our study. No data were excluded from analyses.
  id: totrans-split-123
  prefs: []
  type: TYPE_NORMAL
  zh: 没有使用统计方法来预设样本大小，但根据参考文献 ^([18](/articles/s41593-024-01607-5#ref-CR18 "Yang,
    G. R., Joglekar, M. R., Song, H. F., Newsome, W. T. & Wang, X.-J. Task representations
    in neural networks trained to perform many cognitive tasks. Nat. Neurosci. 22,
    297–306 (2019)."))，我们对每个测试的语言模型使用了五种不同的随机权重初始化。权重的随机化是在Python和PyTorch软件包中自动进行的。鉴于这种自动化的权重随机化，我们在研究中没有使用任何蒙眼程序。没有从分析中排除任何数据。
- en: Software
  id: totrans-split-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 软件
- en: All simulation and data analysis was performed in Python 3.7.11\. PyTorch 1.10
    was used to implement and train models (this includes Adam optimizer implementation).
    Transformers 4.16.2 was used to implement language models and all pretrained weights
    for language models were taken from the Huggingface repository ([https://huggingface.co/docs/transformers/](https://huggingface.co/docs/transformers/)).
    We also used scikit-learn 0.24.1 and scipy 1.7.3 to perform analyses.
  id: totrans-split-125
  prefs: []
  type: TYPE_NORMAL
  zh: 所有模拟和数据分析均在Python 3.7.11中完成。使用PyTorch 1.10实现和训练模型（包括Adam优化器实现）。使用Transformers
    4.16.2实现语言模型，所有预训练语言模型权重均来自Huggingface库（[https://huggingface.co/docs/transformers/](https://huggingface.co/docs/transformers/)）。我们还使用了scikit-learn
    0.24.1和scipy 1.7.3执行分析。
- en: Reporting summary
  id: totrans-split-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 汇报摘要
- en: Further information on research design is available in the [Nature Portfolio
    Reporting Summary](/articles/s41593-024-01607-5#MOESM2) linked to this article.
  id: totrans-split-127
  prefs: []
  type: TYPE_NORMAL
  zh: 关于研究设计的进一步信息，请参阅与本文相关的[自然出版物报告摘要](/articles/s41593-024-01607-5#MOESM2)。
