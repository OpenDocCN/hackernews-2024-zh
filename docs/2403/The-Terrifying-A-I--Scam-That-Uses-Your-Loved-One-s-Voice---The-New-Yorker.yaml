- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 14:44:46'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 14:44:46'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: The Terrifying A.I. Scam That Uses Your Loved One’s Voice | The New Yorker
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用你亲人的声音进行恐怖人工智能骗局 | 纽约客
- en: 来源：[https://www.newyorker.com/science/annals-of-artificial-intelligence/the-terrifying-ai-scam-that-uses-your-loved-ones-voice](https://www.newyorker.com/science/annals-of-artificial-intelligence/the-terrifying-ai-scam-that-uses-your-loved-ones-voice)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.newyorker.com/science/annals-of-artificial-intelligence/the-terrifying-ai-scam-that-uses-your-loved-ones-voice](https://www.newyorker.com/science/annals-of-artificial-intelligence/the-terrifying-ai-scam-that-uses-your-loved-ones-voice)
- en: On a recent night, a woman named Robin was asleep next to her husband, Steve,
    in their Brooklyn home, when her phone buzzed on the bedside table. Robin is in
    her mid-thirties with long, dirty-blond hair. She works as an interior designer,
    specializing in luxury homes. The couple had gone out to a natural-wine bar in
    Cobble Hill that evening, and had come home a few hours earlier and gone to bed.
    Their two young children were asleep in bedrooms down the hall. “I’m always, like,
    kind of one ear awake,” Robin told me, recently. When her phone rang, she opened
    her eyes and looked at the caller I.D. It was her mother-in-law, Mona, who never
    called after midnight. “I’m, like, maybe it’s a butt-dial,” Robin said. “So I
    ignore it, and I try to roll over and go back to bed. But then I see it pop up
    again.”
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的一个晚上，一位名叫罗宾的女士在布鲁克林的家中与丈夫史蒂夫一同入睡，她的手机在床头柜上震动。罗宾是一个三十多岁、长着长而脏兮兮的金发的女性，从事室内设计工作，专注于豪华住宅。这对夫妇当晚在科布尔山的一家天然葡萄酒酒吧喝过酒后回家，几个小时前就已经回到家并上床休息。他们的两个小孩则在走廊尽头的卧室里熟睡。“我总是有点像半夜听着一耳朵的感觉，”罗宾最近告诉我说。当她的手机响了，她睁开眼睛看了看来电显示。是她的岳母莫娜，通常不会在午夜后打电话。“我想，也许是个臀部拨号，”罗宾说。“所以我忽略了，试图翻身回去睡觉。但然后我看到它又弹了出来。”
- en: She picked up the phone, and, on the other end, she heard Mona’s voice wailing
    and repeating the words “I can’t do it, I can’t do it.” “I thought she was trying
    to tell me that some horrible tragic thing had happened,” Robin told me. Mona
    and her husband, Bob, are in their seventies. She’s a retired party planner, and
    he’s a dentist. They spend the warm months in Bethesda, Maryland, and winters
    in Boca Raton, where they play pickleball and canasta. Robin’s first thought was
    that there had been an accident. Robin’s parents also winter in Florida, and she
    pictured the four of them in a car wreck. “Your brain does weird things in the
    middle of the night,” she said. Robin then heard what sounded like Bob’s voice
    on the phone. (The family members requested that their names be changed to protect
    their privacy.) “Mona, pass me the phone,” Bob’s voice said, then, “Get Steve.
    Get Steve.” Robin took this—that they didn’t want to tell her while she was alone—as
    another sign of their seriousness. She shook Steve awake. “I think it’s your mom,”
    she told him. “I think she’s telling me something terrible happened.”
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 她接起电话，听到另一端的莫娜的声音哀号并重复着“我做不到，我做不到”。“我以为她试图告诉我发生了什么可怕的事情，”罗宾告诉我。莫娜和她的丈夫鲍勃都已经七十多岁了。她是一名退休的派对策划师，而他是一名牙医。他们在马里兰州贝塞斯达度过温暖的月份，并在博卡拉顿度过冬季，他们会打排球和玩卡纳斯塔。罗宾的第一个想法是发生了意外。罗宾的父母也在佛罗里达过冬，她想象他们四个人在一起发生了车祸。“你的大脑在半夜会做出奇怪的事情，”她说。接着罗宾听到了像是鲍勃的声音从电话那头传来。（出于隐私保护，家庭成员要求更改姓名。）“莫娜，把电话递给我，”鲍勃的声音说，然后，“叫史蒂夫。叫史蒂夫过来。”罗宾将这当作他们不想让她一个人时告诉她的另一个证据。她摇醒史蒂夫。“我觉得是你妈，”她告诉他。“我觉得她在告诉我发生了可怕的事情。”
- en: Steve, who has close-cropped hair and an athletic build, works in law enforcement.
    When he opened his eyes, he found Robin in a state of panic. “She was screaming,”
    he recalled. “I thought her whole family was dead.” When he took the phone, he
    heard a relaxed male voice—possibly Southern—on the other end of the line. “You’re
    not gonna call the police,” the man said. “You’re not gonna tell anybody. I’ve
    got a gun to your mom’s head, and I’m gonna blow her brains out if you don’t do
    exactly what I say.”
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 史蒂夫，一个头发修剪整齐、体格健壮的人，从事执法工作。当他睁开眼睛时，他发现罗宾处于恐慌状态。“她在尖叫，”他回忆说。“我以为她整个家庭都死了。”当他拿起电话时，他听到一位轻松的男声——可能是南方口音——从电话那端传来。“你不会打电话给警察，”那人说。“你也不会告诉任何人。我拿枪顶着你妈的头，如果你不完全按照我说的做，我就把她脑袋给崩了。”
- en: Steve used his own phone to call a colleague with experience in hostage negotiations.
    The colleague was muted, so that he could hear the call but wouldn’t be heard.
    “You hear this???” Steve texted him. “What should I do?” The colleague wrote back,
    “Taking notes. Keep talking.” The idea, Steve said, was to continue the conversation,
    delaying violence and trying to learn any useful information.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 史蒂夫用自己的手机打电话给一个有劫持谈判经验的同事。这位同事被静音，以便他能听到电话，但不会被听到。“你听到了吗？？”史蒂夫发短信给他。“我该怎么办？”同事回复说：“记录下来，继续谈。”史蒂夫解释说，目的是继续对话，延迟暴力，并试图获取任何有用的信息。
- en: “I want to hear her voice,” Steve said to the man on the phone.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: “我想听她的声音，”史蒂夫对电话那头的男人说。
- en: The man refused. “If you ask me that again, I’m gonna kill her,” he said. “Are
    you fucking crazy?”
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 那人拒绝了。“如果你再问我一次，我就要杀了她，”他说。“你疯了吗？”
- en: “O.K.,” Steve said. “What do you want?”
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: “好的，”史蒂夫说。“你想要什么？”
- en: 'The man demanded money for travel; he wanted five hundred dollars, sent through
    Venmo. “It was such an insanely small amount of money for a human being,” Steve
    recalled. “But also: I’m obviously gonna pay this.” Robin, listening in, reasoned
    that someone had broken into Steve’s parents’ home to hold them up for a little
    cash. On the phone, the man gave Steve a Venmo account to send the money to. It
    didn’t work, so he tried a few more, and eventually found one that did. The app
    asked what the transaction was for.'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 那人要求旅行费用；他想要五百美元，通过Venmo发送。“对一个人来说，这是如此微不足道的金额，”史蒂夫回忆说。“但显然我得付。”在旁听的罗宾推断，有人闯进史蒂夫父母的家里，只是为了抢点现金。在电话里，那人告诉史蒂夫一个用于发送钱的Venmo账户。但没有成功，所以他试了几个，最终找到一个有效的。应用程序询问交易是什么。
- en: “Put in a pizza emoji,” the man said.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: “加一个披萨表情符号，”那人说。
- en: After Steve sent the five hundred dollars, the man patched in a female voice—a
    girlfriend, it seemed—who said that the money had come through, but that it wasn’t
    enough. Steve asked if his mother would be released, and the man got upset that
    he was bringing this up with the woman listening. “Whoa, whoa, whoa,” he said.
    “Baby, I’ll call you later.” The implication, to Steve, was that the woman didn’t
    know about the hostage situation. “That made it even more real,” Steve told me.
    The man then asked for an additional two hundred and fifty dollars to get a ticket
    for his girlfriend. “I’ve gotta get my baby mama down here to me,” he said. Steve
    sent the additional sum, and, when it processed, the man hung up.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 史蒂夫发送了五百美元后，那人接入了一个女声——似乎是女友——说钱已经到账，但不够。史蒂夫问他的母亲是否会被释放，那人因为他在女人面前提起这件事而感到不悦。“喔，喔，喔，”他说。“宝贝，我待会再打给你。”对史蒂夫来说，暗示是女人并不知道人质情况。“这使得情况更加真实，”史蒂夫告诉我。然后那人要求额外的两百五十美元以购买一张票给他的女友。“我得让我的孩子妈过来见我，”他说。史蒂夫发送了额外的金额，在处理后，那人挂断了电话。
- en: By this time, about twenty-five minutes had elapsed. Robin cried and Steve spoke
    to his colleague. “You guys did great,” the colleague said. He told them to call
    Bob, since Mona’s phone was clearly compromised, to make sure that he and Mona
    were now safe. After a few tries, Bob picked up the phone and handed it to Mona.
    “Are you at home?” Steve and Robin asked her. “Are you O.K.?”
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 到这时，大约已经过去了二十五分钟。罗宾哭了，史蒂夫和同事交谈。“你们做得很好，”同事说。他建议他们打电话给鲍勃，因为莫娜的手机显然已经被入侵，以确保他们现在安全了。经过几次尝试，鲍勃接起电话并把它递给了莫娜。“你在家吗？”史蒂夫和罗宾问她。“你还好吗？”
- en: Mona sounded fine, but she was unsure of what they were talking about. “Yeah,
    I’m in bed,” she replied. “Why?”
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 莫娜听起来挺好的，但她不确定他们在谈论什么。“是的，我在床上，”她回答。“为什么？”
- en: '[Artificial intelligence](https://www.newyorker.com/tag/artificial-intelligence-ai)
    is revolutionizing seemingly every aspect of our lives: medical diagnosis, weather
    forecasting, space exploration, and even mundane tasks like writing e-mails and
    searching the Internet. But with increased efficiencies and computational accuracy
    has come a Pandora’s box of trouble. Deepfake video content is proliferating across
    the Internet. The month after Russia invaded Ukraine, a video surfaced on social
    media in which Ukraine’s President, Volodymyr Zelensky, appeared to tell his troops
    to surrender. (He had not done so.) In early February of this year, Hong Kong
    police announced that a finance worker had been tricked into paying out twenty-five
    million dollars after taking part in a video conference with who he thought were
    members of his firm’s senior staff. (They were not.) Thanks to large language
    models like ChatGPT, phishing e-mails have grown increasingly sophisticated, too.
    Steve and Robin, meanwhile, fell victim to another new scam, which uses A.I. to
    replicate a loved one’s voice. “We’ve now passed through the uncanny valley,”
    Hany Farid, who studies generative A.I. and manipulated media at the University
    of California, Berkeley, told me. “I can now clone the voice of just about anybody
    and get them to say just about anything. And what you think would happen is exactly
    what’s happening.”'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[人工智能](https://www.newyorker.com/tag/artificial-intelligence-ai)正在彻底改变我们生活中看似每一个方面：医学诊断、天气预报、太空探索，甚至是像写电子邮件和搜索互联网这样的日常任务。但随着效率提升和计算准确性的增加，也带来了一系列麻烦的潘多拉魔盒。深度伪造视频内容在互联网上蔓延。俄罗斯入侵乌克兰后的一个月，社交媒体上出现了一个视频，乌克兰总统沃洛迪米尔·泽连斯基似乎在视频中告诉他的部队投降（实际上并没有）。今年二月初，香港警方宣布，一名金融工作者在参加视频会议时被骗支付了两千五百万美元，因为他认为对方是公司高级人员（实际上并非如此）。多亏了像ChatGPT这样的大语言模型，钓鱼邮件也变得越来越复杂。与此同时，史蒂夫和罗宾成为另一种新骗局的受害者，该骗局利用人工智能复制所爱之人的声音。“我们现在已经越过了诡异谷，”加州大学伯克利分校研究生成A.I.和操纵媒体的汉尼·法里德告诉我说。“我现在可以克隆几乎任何人的声音，并让他们说几乎任何话。你想象中会发生的事情正是正在发生的事情。”'
- en: 'Robots aping human voices are not new, of course. In 1984, an Apple computer
    became one of the first that could read a text file in a tinny robotic voice of
    its own. “Hello, I’m Macintosh,” a squat machine announced to a live audience,
    at an unveiling with Steve Jobs. “It sure is great to get out of that bag.” The
    computer took potshots at Apple’s main competitor at the time, saying, “I’d like
    to share with you a maxim I thought of the first time I met an I.B.M. mainframe:
    never trust a computer you can’t lift.” In 2011, Apple released Siri; inspired
    by “Star Trek” ’s talking computers, the program could interpret precise commands—“Play
    Steely Dan,” say, or, “Call Mom”—and respond with a limited vocabulary. Three
    years later, Amazon released Alexa. Synthesized voices were cohabiting with us.'
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 机器人模仿人类声音并非新鲜事物。当然了，1984年，一台苹果电脑成为首批能够用自己尖锐的机械声读取文本文件的设备之一。“你好，我是麦金塔，”一个矮胖的机器在与史蒂夫·乔布斯一同揭幕时向现场观众宣布，“能够走出那个包袋确实很棒。”
    该电脑抨击当时苹果的主要竞争对手，说：“我想和你分享一条箴言，那是我第一次见到IBM大型机时想到的：永远不要相信你不能抬起的电脑。” 2011年，苹果发布了Siri；受到《星际迷航》中的对话电脑的启发，该程序能够解释精确的指令——比如，“播放史提利·丹”，或者“打电话给妈妈”——并以有限的词汇作出回应。三年后，亚马逊发布了Alexa。合成声音与我们共同生活。
- en: 'Still, until a few years ago, advances in synthetic voices had plateaued. They
    weren’t entirely convincing. “If I’m trying to create a better version of Siri
    or G.P.S., what I care about is naturalness,” Farid explained. “Does this sound
    like a human being and not like this creepy half-human, half-robot thing?” Replicating
    a specific voice is even harder. “Not only do I have to sound *human*,” Farid
    went on. “I have to sound like *you*.” In recent years, though, the problem began
    to benefit from more money, more data—importantly, troves of voice recordings
    online—and breakthroughs in the underlying software used for generating speech.
    In 2019, this bore fruit: a Toronto-based A.I. company called Dessa cloned the
    podcaster Joe Rogan’s voice. (Rogan responded with “awe” and acceptance on Instagram,
    at the time, adding, “The future is gonna be really fucking weird, kids.”) But
    Dessa needed a lot of money and hundreds of hours of Rogan’s very available voice
    to make their product. Their success was a one-off.'
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，直到几年前，合成语音的进展曾经停滞不前。它们并不完全令人信服。“如果我试图创建一个更好的Siri或GPS，我关心的是自然度，”法里德解释道。“这听起来像一个人类，而不是这种令人毛骨悚然的半人半机器的东西吗？”复制特定的声音更难。“我不仅仅需要听起来*像人类*，”法里德继续说。“我还要听起来*像你*。”然而，近年来，这个问题开始受益于更多的资金、更多的数据——重要的是，在生成语音所用的底层软件的突破中也有所帮助。2019年，一个名为Dessa的多伦多人工智能公司克隆了播客主持人乔·罗根的声音。（当时，罗根在Instagram上回应说：“未来将会非常奇怪，孩子们。”）但Dessa需要大量资金和数百小时的罗根的可用声音才能制作出他们的产品。他们的成功是个特例。
- en: In 2022, though, a New York-based company called ElevenLabs unveiled a service
    that produced impressive clones of virtually any voice quickly; breathing sounds
    had been incorporated, and more than two dozen languages could be cloned. ElevenLabs’s
    technology is now widely available. “You can just navigate to an app, pay five
    dollars a month, feed it forty-five seconds of someone’s voice, and then clone
    that voice,” Farid told me. The company is now valued at more than a billion dollars,
    and the rest of Big Tech is chasing closely behind. The designers of Microsoft’s
    Vall-E cloning program, which débuted last year, used sixty thousand hours of
    English-language audiobook narration from more than seven thousand speakers. Vall-E,
    which is not available to the public, can reportedly replicate the voice and “acoustic
    environment” of a speaker with just a three-second sample.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在2022年，一家名为ElevenLabs的纽约公司推出了一项服务，能够快速生成几乎任何语音的印象深刻的克隆；呼吸声音已经被整合进去，而且能够克隆二十多种语言。ElevenLabs的技术现在已经广泛应用。“你只需打开一个应用程序，每月支付五美元，输入某人的四十五秒声音片段，然后就能克隆出那个声音，”法里德告诉我。该公司现在估值超过十亿美元，其他大科技公司紧随其后。微软的Vall-E克隆程序的设计师去年推出，使用了超过六万小时的英语有声读物叙述，来自七千多位讲述者。据报道，Vall-E能够仅凭三秒的样本复制说话者的声音和“声学环境”，但目前不对公众开放。
- en: 'Voice-cloning technology has undoubtedly improved some lives. The Voice Keeper
    is among a handful of companies that are now “banking” the voices of those suffering
    from voice-depriving diseases like A.L.S., Parkinson’s, and throat cancer, so
    that, later, they can continue speaking with their own voice through text-to-speech
    software. A South Korean company recently launched what it describes as the first
    “AI memorial service,” which allows people to “live in the cloud” after their
    deaths and “speak” to future generations. The company suggests that this can “alleviate
    the pain of the death of your loved ones.” The technology has other legal, if
    less altruistic, applications. Celebrities can use voice-cloning programs to “loan”
    their voices to record advertisements and other content: the College Football
    Hall of Famer Keith Byars, for example, recently let a chicken chain in Ohio use
    a clone of his voice to take orders. The film industry has also benefitted. Actors
    in films can now “speak” other languages—English, say, when a foreign movie is
    released in the U.S. “That means no more subtitles, and no more dubbing,” Farid
    said. “Everybody can speak whatever language you want.” Multiple publications,
    including *The New Yorker*, use ElevenLabs to offer audio narrations of stories.
    Last year, New York’s mayor, Eric Adams, sent out A.I.-enabled robocalls in Mandarin
    and Yiddish—languages he does not speak. (Privacy advocates called this a “creepy
    vanity project.”)'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 语音克隆技术无疑改善了一些人的生活。Voice Keeper 是少数几家公司之一，现在“银行化”了那些患有失语症疾病（如肌萎缩侧索硬化症、帕金森病和喉癌）的人的声音，以便以后他们可以通过文本转语音软件继续用自己的声音说话。一家韩国公司最近推出了他们称为第一个“人工智能纪念服务”，允许人们在他们去世后“活在云端”，并且能够与未来的世代“交流”。该公司表示，这可以“减轻亲人去世的痛苦”。该技术还有其他合法的、尽管不那么利他的应用。名人可以使用语音克隆程序将他们的声音“借”给录制广告和其他内容：例如，前大学橄榄球名人堂成员基思·拜尔斯最近允许俄亥俄州的一个鸡肉连锁店使用他的声音克隆来接单。电影行业也受益匪浅。电影中的演员现在可以在外语电影在美国上映时“说”其他语言，比如英语。“这意味着不再需要字幕，也不再需要配音，”Farid
    说道。“每个人都可以说他想说的任何语言。”多家出版物，包括 *纽约客* 在内，都使用 ElevenLabs 提供故事的音频叙述。去年，纽约市市长埃里克·亚当斯以智能语音电话用普通话和意第绪语向人们发出了电话。（隐私倡导者称之为“令人毛骨悚然的虚荣项目”。）
- en: 'But, more often, the technology seems to be used for nefarious purposes, like
    fraud. This has become easier now that TikTok, YouTube, and Instagram store endless
    videos of regular people talking. “It’s simple,” Farid explained. “You take thirty
    or sixty seconds of a kid’s voice and log in to ElevenLabs, and pretty soon Grandma’s
    getting a call in Grandson’s voice saying, ‘Grandma, I’m in trouble, I’ve been
    in an accident.’ ” A financial request is almost always the end game. Farid went
    on, “And here’s the thing: the bad guy can fail ninety-nine per cent of the time,
    and they will still become very, very rich. It’s a numbers game.” The prevalence
    of these illegal efforts is difficult to measure, but, anecdotally, they’ve been
    on the rise for a few years. In 2020, a corporate attorney in Philadelphia took
    a call from what he thought was his son, who said he had been injured in a car
    wreck involving a pregnant woman and needed nine thousand dollars to post bail.
    (He found out it was a scam when his daughter-in-law called his son’s office,
    where he was safely at work.) In January, voters in New Hampshire received a robocall
    call from Joe Biden’s voice telling them not to vote in the primary. (The man
    who admitted to generating the call said that he had used ElevenLabs software.)
    “I didn’t think about it at the time that it wasn’t his real voice,” an elderly
    Democrat in New Hampshire told the Associated Press. “That’s how convincing it
    was.”'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 但更多时候，技术似乎被用于不良目的，比如欺诈。现在使用起来更加容易，像 TikTok、YouTube 和 Instagram 存储了无数普通人说话的视频。Farid
    解释道：“很简单，你录下孩子说话的三十或六十秒钟，登录 ElevenLabs，不久奶奶就会接到一个声称‘奶奶，我出事了，我出了车祸’的电话，这几乎总是为了达到金融要求。”坏人即使失败百分之九十九，仍然会变得非常非常富有。“这是一个数字游戏。”这些非法活动的普及程度很难衡量，但据传，它们在过去几年里有所增加。2020
    年，费城的一位公司律师接到了一个电话，声称是他儿子，说他在涉及一名怀孕女子的车祸中受伤，需要九千美元保释金。（当他的儿媳妇打电话到他儿子的办公室时，他才发现这是一场诈骗，他儿子安全地在工作中。）一月份，新罕布什尔州的选民接到了乔·拜登的语音自动电话，告诉他们不要在初选中投票。（承认生成该电话的人称他使用了
    ElevenLabs 软件。）“当时我没有想到那不是他真正的声音，”新罕布什尔州的一位年长的民主党人告诉美联社。“这就是它是多么令人信服。”
