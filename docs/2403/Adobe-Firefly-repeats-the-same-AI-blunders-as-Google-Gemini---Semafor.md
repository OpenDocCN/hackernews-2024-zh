<!--yml
category: 未分类
date: 2024-05-27 14:56:53
-->

# Adobe Firefly repeats the same AI blunders as Google Gemini | Semafor

> 来源：[https://www.semafor.com/article/03/13/2024/adobe-firefly-repeats-the-same-ai-blunders-as-google-gemini](https://www.semafor.com/article/03/13/2024/adobe-firefly-repeats-the-same-ai-blunders-as-google-gemini)

Firefly, Adobe’s AI image creation tool, repeats some of the same controversial mistakes that Google’s Gemini made in inaccurate racial and ethnic depictions, illustrating the challenges tech companies face across the industry.

Google [shut down](https://blog.google/products/gemini/gemini-image-generation-issue/) its Gemini image creation tool last month after critics pointed out that it was creating historically inaccurate images, depicting America’s Founding Fathers as Black, for instance, and refusing to depict white people. CEO Sundar Pichai told employees the company “[got it wrong](https://www.semafor.com/article/02/27/2024/google-ceo-sundar-pichai-calls-ai-tools-responses-completely-unacceptable).”

The tests done by Semafor on Firefly replicated many of the same things that tripped up Gemini. The two services rely on similar techniques for creating images from written text, but they are trained on very different datasets. Adobe uses only stock images or images that it licenses.

Adobe and Google also have different cultures. Adobe, a more traditionally structured company, has never been a hotbed of employee activism like Google. The common denominator is the core technology for image generation, and companies can attempt to corral it, but there is no guaranteed way to do it.

I asked Firefly to create images using similar prompts that got Gemini in trouble. It created Black soldiers fighting for Nazi Germany in World War II. In scenes depicting the Founding Fathers and the constitutional convention in 1787, Black men and women were inserted into roles. When I asked it to create a comic book character of an old white man, it drew one, but also gave me three others of a Black man, a Black woman and a white woman. And yes, it even drew me a picture of Black Vikings, just like Gemini.

The source of this kind of result is an attempt by the model’s designers to ensure that certain groups of people avoid racist stereotypes — that doctors not all be white men, for instance, or that criminals not fall into racial stereotypes. But the projection of those efforts into historical contexts has infuriated some on the right who see it as the AI trying to rewrite history along the lines of today’s politics.

The Adobe results show how this issue is not exclusive to one company or one type of model. And Adobe has, more than most big tech companies, tried to do everything by the book. It [trained](https://www.adobe.com/products/firefly.html) its algorithm on stock images, openly licensed content, and public domain content so that its customers could use its tool without worries about copyright infringement.

** This story has been updated to include a statement from Adobe.*