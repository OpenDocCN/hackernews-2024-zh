- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们设计WarpStream时，我们知道仅仅用更便宜、更易操作的替代Apache Kafka是不够的。Kafka是许多公司最关键基础设施的核心，如果我们想说服这些组织采用WarpStream，我们必须在更短的时间内压缩12年以上的生产硬化过程。我们通过我们依赖对象存储作为系统中唯一存储的架构决策来加速这一过程，避开了许多确保数据耐久性、可用性和规模复制的棘手问题。但是，WarpStream利用对象存储的事实只是确保整个系统正确性的一小部分。
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更近期的采用此测试方法的数据库系统的例子是[TigerBeetle](https://tigerbeetle.com/)，一个金融交易数据库，它利用[确定性模拟测试](https://www.youtube.com/watch?v=sC1B3d9C_sI)建立了当今最健壮的金融OLTP数据库之一。
- en: 'date: 2024-05-27 14:52:14'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的整个SaaS服务中采用确定性模拟测试 - WarpStream - 更多流，更少管理
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: Deterministic Simulation Testing for Our Entire SaaS - WarpStream - Stream More,
    Manage Less
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 来源：[https://www.warpstream.com/blog/deterministic-simulation-testing-for-our-entire-saas](https://www.warpstream.com/blog/deterministic-simulation-testing-for-our-entire-saas)
- en: 来源：[https://www.warpstream.com/blog/deterministic-simulation-testing-for-our-entire-saas](https://www.warpstream.com/blog/deterministic-simulation-testing-for-our-entire-saas)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: -->
- en: Deterministic Simulation Testing
  id: totrans-split-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确定性模拟测试
- en: 'Deterministic simulation testing is fast becoming the gold standard for how
    mission critical software is tested. Deterministic simulation testing was first
    popularized by the [FoundationDB](https://www.foundationdb.org/) team who spent
    18 months building a deterministic simulation framework for their database before
    ever letting it write or read data from an actual physical disk. The results speak
    for themselves: FoundationDB is widely considered to be one of the most robust
    and well-tested distributed databases, so much so that Kyle Kingsbury (of Jepsen
    fame) refused to test it because their deterministic simulator already stress
    tested FoundationDB more than the Jepsen framework ever could.'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.foundationdb.org/](https://www.foundationdb.org/)团队首次推广了确定性模拟测试，他们花了18个月时间为他们的数据库建立确定性模拟框架，然后才允许它从实际物理硬盘上读写数据。结果不言而喻：FoundationDB被普遍认为是最健壮和经过充分测试的分布式数据库之一，以至于Jepsen的Kyle
    Kingsbury拒绝测试它，因为他们的确定性模拟器已经对FoundationDB进行了比Jepsen框架更彻底的压力测试。'
- en: 'The WarpStream team utilized FoundationDB heavily at Datadog when we built
    [Husky, Datadog’s columnar storage engine for event data](https://www.datadoghq.com/blog/engineering/introducing-husky/).
    Over the course of our careers, our team has operated (and been on-call for) almost
    every database on the market: M3DB, etcd, ZooKeeper, Cassandra, Elasticsearch,
    Redis, MongoDB, MySQL, Postgres, Apache Kafka and more. In our experience, FoundationDB
    stands in a league of its own in terms of correctness and reliability due to its
    early investment in deterministic simulation testing.'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在Datadog建立[Husky，Datadog的事件数据列存储引擎](https://www.datadoghq.com/blog/engineering/introducing-husky/)时，WarpStream团队在Datadog大量使用了FoundationDB。在我们的职业生涯中，我们的团队几乎操作过市面上所有的数据库：M3DB，etcd，ZooKeeper，Cassandra，Elasticsearch，Redis，MongoDB，MySQL，Postgres，Apache
    Kafka等等。根据我们的经验，FoundationDB因其早期在确定性模拟测试上的投资，在正确性和可靠性方面独树一帜。
- en: A more recent example of a database system that leverages this approach to testing
    is [TigerBeetle](https://tigerbeetle.com/), a financial transactions database,
    that uses [deterministic simulation testing](https://www.youtube.com/watch?v=sC1B3d9C_sI)
    to build one of the most robust financial OLTP databases available today.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: When we were designing WarpStream, we knew that it wouldn’t be enough to just
    replace Apache Kafka with something cheaper and easier to operate. Kafka is the
    beating heart of many companies most critical infrastructure, and if we were to
    stand any chance of convincing those organizations to adopt WarpStream, we’d have
    to compress 12+ years of production hardening into a much shorter time frame.
    We accelerated this process with our architectural decision to rely on object
    storage as the *only* storage in the system, bypassing many of the tricky problems
    of ensuring data durability, availability, and replication at scale. Still, the
    fact that WarpStream leverages object storage is only a small part of ensuring
    the correctness of the overall system.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-27 14:52:14
- en: Antithesis
  id: totrans-split-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对立
- en: 'When we first heard about [Antithesis](https://antithesis.com/), we could hardly
    contain our excitement. Antithesis has created the holy grail for testing distributed
    systems: a bespoke hypervisor that deterministically simulates an entire set of
    Docker containers and injects faults, *created by the same people who made FoundationDB*.
    For a group of gray-haired distributed systems engineers, seeing Antithesis in
    action felt like a tribe of cavemen stumbling upon a post-industrial revolution
    society. As we spoke more to the Antithesis team, an idea began to crystallize:
    we could use Antithesis to deterministically simulate not only WarpStream, but
    our entire SaaS!'
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们第一次听说 [Antithesis](https://antithesis.com/) 时，我们几乎无法控制兴奋。Antithesis 为测试分布式系统创建了圣杯：一款定制的超级监控程序，确定性地模拟了整套
    Docker 容器，并注入故障，*由 FoundationDB 的创始人打造*。对于一群经验丰富的分布式系统工程师来说，看到 Antithesis 的实际效果就像是一群穴居人偶然发现了后工业革命社会一样。随着我们与
    Antithesis 团队的交流加深，一个想法开始清晰起来：我们可以使用 Antithesis 不仅确定性地模拟 WarpStream，还可以模拟我们整个的
    SaaS！
- en: 'WarpStream was built differently than most traditional database products. It
    was designed from day one with a true data plane / control plane split. There
    are two primary components to WarpStream: First, the Agents (data plane) that
    act as “thick proxies” and expose the Kafka protocol to clients. The Agents also
    take care of all communication with object storage, layering in batching and caching
    to improve performance and keep costs low.'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: WarpStream 与大多数传统数据库产品不同。它从一开始就设计了真正的数据平面 / 控制平面分离。WarpStream 有两个主要组件：首先是代理（数据平面），它们充当“厚代理”，向客户端公开
    Kafka 协议。代理还负责与对象存储的所有通信，增加批处理和缓存以提高性能并降低成本。
- en: ‍
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: ‍
- en: 'Second is the WarpStream control plane which has two major components:'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个是 WarpStream 控制平面，它有两个主要组件：
- en: The metadata store that tracks cluster metadata and performs remote consensus.
  id: totrans-split-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 跟踪集群元数据并执行远程一致性的元数据存储。
- en: Our SaaS software that manages different tenants’ metadata stores, API keys,
    users, accounts, etc.
  id: totrans-split-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的 SaaS 软件管理不同租户的元数据存储、API 密钥、用户、帐户等。
- en: 'The metadata store only has two dependencies:'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 元数据存储仅有两个依赖项：
- en: Any cloud KV store
  id: totrans-split-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 任何云 KV 存储
- en: Object storage
  id: totrans-split-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对象存储
- en: 'The SaaS software adds one additional dependency: a traditional SQL database
    for managing users, organization, API keys, etc. Looking at WarpStream’s minimal
    dependencies, we thought, why not test its entire customer experience, from initial
    signup to running Kafka workloads?'
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这款 SaaS 软件增加了一个额外的依赖项：传统的 SQL 数据库，用于管理用户、组织、API 密钥等。看到 WarpStream 的最小依赖项，我们想，为什么不测试其整个客户体验，从初始注册到运行
    Kafka 工作负载呢？
- en: 'We created a docker-compose file that contains the following components:'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建了一个包含以下组件的 docker-compose 文件：
- en: Several WarpStream Agents
  id: totrans-split-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Several WarpStream 代理
- en: Several WarpStream Control Plane nodes
  id: totrans-split-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Several WarpStream 控制平面节点
- en: Several Apache Kafka clients
  id: totrans-split-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Several Apache Kafka 客户端
- en: A KV store
  id: totrans-split-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个 KV 存储
- en: Postgres
  id: totrans-split-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Postgres
- en: An object store ([localstack](https://docs.localstack.cloud/user-guide/aws/s3/))
  id: totrans-split-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个对象存储 ([localstack](https://docs.localstack.cloud/user-guide/aws/s3/))
- en: With the help of the Antithesis team, we wrote a test workload that started
    all of those services, signed up for a WarpStream account, created a virtual cluster,
    and then began producing and consuming data. The workload was carefully structured
    so that we could assert on a variety of different important properties that WarpStream
    must maintain at all times.
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Antithesis 团队的帮助下，我们编写了一个测试工作负载，启动了所有这些服务，注册了一个 WarpStream 帐户，创建了一个虚拟集群，然后开始生产和消费数据。工作负载被精心设计，以便我们可以断言
    WarpStream 在任何时候都必须维护的各种重要属性。
- en: 'The test workload consists of multiple producers that are each assigned a unique
    ID and write records to a small set of topics. These producers synchronously write
    a few small JSON records that contain the producer’s ID, a counter (a monotonic
    sequence number for that producer), and a few other properties. We repeat the
    same components as the record’s key, value, and in a header to ensure we never
    shuffle those around accidentally. The consumer side of the workload polls all
    the topics and all the partitions and asserts that:'
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: 测试工作负载由多个生产者组成，每个生产者分配一个唯一的 ID，并将记录写入一小组主题。这些生产者同步写入一些包含生产者 ID、计数器（该生产者的单调序列号）和其他一些属性的小型
    JSON 记录。我们重复了记录的关键、值和标头的组件，以确保我们不会意外地对其进行重排。工作负载的消费端轮询所有主题和所有分区，并断言：
- en: The topic and partition the record was consumed from matches the topic and partition
    the record was produced to.
  id: totrans-split-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 记录被消费的主题和分区与记录被生产的主题和分区相匹配。
- en: The offsets for each record in each partition are monotonic.
  id: totrans-split-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个分区中每条记录的偏移量都是单调递增的。
- en: The sequence numbers for each producer are monotonic, i.e. if we group the records
    by <Topic, Partition, ProducerID> the sequence number encoded in the record is
    monotonically increasing.
  id: totrans-split-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个生产者的序列号是单调递增的，即如果我们按<Topic，Partition，ProducerID>对记录进行分组，记录中编码的序列号是单调递增的。
- en: The consumers store all of the records for each polling iteration and can assert
    that a record at offset X in the previous poll still exists in a future poll.
    This ensures that WarpStream doesn't lose or reorder data as e.g. background compaction
    runs to reorganize the cluster’s data for more efficient access.
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 消费者会将每个轮询迭代的所有记录存储起来，并可以断言在前一个轮询中的偏移X处的记录仍然存在于将来的轮询中。这确保了WarpStream不会丢失或重新排序数据，例如后台压实运行以重新组织集群数据以实现更高效的访问。
- en: 'These assertions address many of the classes of bugs found in previous Jepsen
    tests of Apache Kafka and other Kafka-compatible systems. For example, prior Jepsen
    tests have caught bugs like:'
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这些断言解决了在之前的Apache Kafka和其他兼容Kafka系统的Jepsen测试中发现的许多错误类别。例如，先前的Jepsen测试曾捕捉到以下类似的错误：
- en: Loss of previously acknowledged writes. If a write was acknowledged but failed
    to appear in the output for that topic-partition in the future, assertion 1 or
    3 above would fire.
  id: totrans-split-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之前已确认的写入丢失。如果一个写入已经确认但未来在该主题分区的输出中未出现，上述第1或第3断言将触发。
- en: Violation of producer idempotency (i.e producing duplicate records without the
    producer itself crashing or restarting).  Antithesis automatically tests our Idempotent
    Producer implementation by disrupting the network between the producer client
    and the agent or the agent and the control plane, leading to internal retries
    inside the Kafka client. A duplicate would cause the sequence number from a producer
    to stay the same or decrease, causing assertion 3 above to fire.
  id: totrans-split-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 违反生产者幂等性（即在生产者本身没有崩溃或重启的情况下生成重复记录）。Antithesis通过在生产者客户端和代理之间或代理和控制平面之间中断网络来测试我们的幂等性生产者实现，导致Kafka客户端内部进行重试。重复的情况将导致来自生产者的序列号保持不变或减少，从而触发上述第3断言。
- en: Records appearing in different topic-partitions than they were originally written
    to. This is addressed by assertions 1 or 3 above.
  id: totrans-split-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 记录出现在与它们最初写入的不同主题分区中。这是通过上述第1或第3断言来解决的。
- en: What’s the big deal?
  id: totrans-split-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这有什么大不了的？
- en: 'At this point you might be scratching your head a little bit and wondering:
    “What’s the big deal here? Isn’t this just a really fancy integration test!?”.
    Yes and no. Before we started using Antithesis, WarpStream already had a pretty
    robust set of stress tests we called the “correctness tests”.'
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: 到了这一点，您可能会有些困惑，并想知道：“这里有什么大不了的吗？这不就是一个非常复杂的集成测试吗？”是的，也不完全是。在我们开始使用Antithesis之前，WarpStream已经有了一个相当强大的一套压力测试，我们称之为“正确性测试”。
- en: These tests do essentially everything we just described, but in a regular CI
    environment. Our correctness tests even inject faults all over the WarpStream
    stack using a custom chaos injection library that we wrote. These tests are incredibly
    powerful, and they caught a *lot* of bugs. We would go as far as saying that investing
    deeply in those correctness tests is one of the main reasons that we were able
    to develop WarpStream as efficiently as we did.
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这些测试基本上做了我们刚才描述的所有事情，但是在常规的CI环境中。我们的正确性测试甚至使用我们编写的自定义混沌注入库在整个WarpStream堆栈中注入故障。这些测试非常强大，已经捕捉到了*很多*错误。我们甚至可以说，深入投资这些正确性测试是我们能够高效开发WarpStream的主要原因之一。
- en: Just like our existing correctness tests, the Antithesis hypervisor automatically
    injects faults, latency, thread hangs, and restarts into the workload. However,
    unlike our correctness tests, the Antithesis hypervisor is *really smart* and
    automatically fuzzes the system under test in an intelligent way.
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们现有的正确性测试一样，Antithesis超级管理程序自动向工作负载中注入故障、延迟、线程挂起和重启。然而，与我们的正确性测试不同，Antithesis超级管理程序*非常智能*，以智能方式对被测试系统进行模糊测试。
- en: Antithesis automatically instruments your software to measure code coverage
    and build statistics about the execution frequency of each code path. This enables
    Antithesis to detect “interesting” behavior in the test (such as infrequent code
    paths getting exercised, or rare log messages being emitted).
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: Antithesis自动为您的软件进行仪器化，以测量代码覆盖率，并构建关于每个代码路径执行频率的统计信息。这使得Antithesis能够检测测试中的“有趣”行为（例如执行不频繁的代码路径或发出稀有日志消息）。
- en: When Antithesis detects interesting or rare behavior, it immediately snapshots
    the state of the entire system before exploring various different execution branches.
    This means that Antithesis is *much* better at triggering rare or unlikely behavior
    in WarpStream than our existing correctness tests were.
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: 当Antithesis检测到有趣或罕见的行为时，它会立即快照整个系统的状态，然后探索各种不同的执行分支。这意味着Antithesis在触发WarpStream中罕见或不太可能的行为方面比我们现有的正确性测试要好得多。
- en: Also, since Antithesis runs the entire software stack in a deterministic simulator,
    they can actually run the simulation at *faster than wall clock time*. Similar
    to FoundationDB, WarpStream makes heavy use of timers and batching to improve
    performance. Anytime a WarpStream Goroutine does the equivalent of time.Sleep(),
    the Antithesis hypervisor *doesn’t actually have to wait*. On top of that, the
    Antithesis hypervisor explores code branches *concurrently*. All of this adds
    up in a meaningful way such that Antithesis can cost effectively compress years
    of stress testing into a much shorter time frame.
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，由于Antithesis在确定性模拟器中运行整个软件堆栈，它们实际上可以以比墙钟时间更快的速度运行模拟。与FoundationDB类似，WarpStream大量使用定时器和批处理来提高性能。每当WarpStream
    Goroutine执行类似于time.Sleep()的操作时，Antithesis监管程序实际上*不必等待*。此外，Antithesis监管程序*并发地*探索代码分支。所有这些都以有意义的方式累积起来，使Antithesis能够以成本效益的方式将数年的压力测试压缩到更短的时间段内。
- en: It’s hard to over-emphasize just how transformative this technology is for building
    distributed systems. For all intents and purposes, it really does feel like a
    time-traveler arrived from 20 years in the future and gave us their state of the
    art software testing technology. Of course, it’s not *actually* magic. Antithesis
    is the result of dozens of the smartest software engineers, statisticians, and
    machine learning experts pouring their heart and souls into the problem of software
    testing for 5 years straight. But to us mere mortals, it does feel a lot like
    magic.
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: 很难过分强调这项技术对于构建分布式系统有多么具有变革性。在所有意图和目的上，它确实感觉像是从未来20年来到我们这里并给予我们他们最先进的软件测试技术。当然，它并不*真正*是魔法。Antithesis是几十位最聪明的软件工程师、统计学家和机器学习专家连续五年投入心血解决软件测试问题的结果。但对于我们这些凡人来说，它确实感觉很像魔法。
- en: We found some bugs
  id: totrans-split-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们发现了一些bug。
- en: Let’s look at a few example runs that Antithesis generated for us.
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一些Antithesis为我们生成的示例运行。
- en: Antithesis ran the WarpStream workload for 6 wall clock hours, during which
    it simulated 280 hours of application time. The graph shows that it took about
    160 “application hours” for Antithesis to “stall” and stop discovering new “behaviors”
    in the WarpStream workload. This means that running the tests for longer than
    160 hours has diminishing returns, and instead we should invest in making the
    test itself more sophisticated if we want to exercise the codebase more. Great
    feedback for us!
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: Antithesis在墙钟时间内运行了WarpStream工作负载达6个小时，期间模拟了280小时的应用时间。图表显示，Antithesis在WarpStream工作负载中大约花了160个“应用小时”才“停滞”，停止发现新的“行为”。这意味着运行超过160小时的测试收益递减，如果想要更多地测试代码库，我们应该投资于使测试本身更加复杂。这对我们是极好的反馈！
- en: 'But think about that for a moment: even after 140 hours of injecting faults,
    randomizing thread execution, automatically detecting that something interesting
    / rare had happened and intentionally branching to investigate further, Antithesis
    was still “discovering” new behaviors in WarpStream. We could hire a 100 distributed
    systems engineers and make them write integration tests for an entire year, and
    they probably wouldn’t be able to trigger all the interesting states and behavior
    that a single Antithesis run covered in 6 hours of wall clock time.'
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: 但是请思考一下：即使在注入故障、随机化线程执行、自动检测到有趣或罕见事件并有意分支以进一步调查的140小时之后，Antithesis仍在WarpStream中“发现”新的行为。我们可以雇佣100名分布式系统工程师，让他们为整整一年编写集成测试，但他们可能无法触发Antithesis在墙钟时间6小时内覆盖的所有有趣状态和行为。
- en: As just one example of how powerful this is, on the first day we started using
    Antithesis it caught a data race in our metrics instrumentation library that had
    been present since the first month of the project.
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: 仅举一个例子来说明它有多强大，我们开始使用Antithesis的第一天，它就捕获到了我们度量仪表库中的一个数据竞争，而这个问题自项目启动以来就存在了一个月之久。
- en: Our correctness tests had run in our regular CI workflows for literally *10s
    of thousands of hours* by then, with the Go race detector enabled, and not once
    ever caught this bug. Antithesis caught this bug in its first 233 seconds of execution.
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的正确性测试在我们的常规 CI 工作流中运行了成千上万个小时，启用了 Go 竞争检测器，从未捕获过此错误。Antithesis 在执行的前 233
    秒内就捕获了此错误。
- en: A data race in the instrumentation library isn’t that exciting, though. What
    about an extremely rare data loss bug that is the result of both a network failure
    and a race condition? That’s more exciting!
  id: totrans-split-53
  prefs: []
  type: TYPE_NORMAL
  zh: 仪器库中的数据竞争并不那么令人兴奋。那么，一个由网络故障和竞争条件引起的极其罕见的数据丢失错误呢？这更加令人激动！
- en: To minimize the number of S3 PUTs that WarpStream users have to pay for, the
    Agents buffer Kafka Produce requests from many different clients in-memory for
    ~250ms before combining the batches of data into a single file and flushing it
    to object storage.
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少 WarpStream 用户需要支付的 S3 PUT 数量，代理程序将来自多个不同客户端的 Kafka 生产请求在内存中缓冲约 250 毫秒，然后将数据批量合并成单个文件并刷新到对象存储中。
- en: In some scenarios, like if write throughput is high, there will be multiple
    outstanding files being flushed to object storage concurrently. Once flushing
    the files succeeds, committing the metadata for the flushed files to the control
    plane can be batched to reduce networking overhead. This is implemented using
    a background Goroutine that periodically scans the list of “flushed but not yet
    committed” files.
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些场景下，比如写入吞吐量很高时，可能会有多个未完成的文件同时被刷新到对象存储中。一旦文件刷新成功，将刷新文件的元数据提交到控制平面可以批量处理，以减少网络开销。这是通过后台
    Goroutine 实现的，定期扫描“已刷新但尚未提交”的文件列表来实现的。
- en: While refactoring the Agent to add speculative retries for flushing files to
    object storage, we subtly broke the error handling on this path so that, for a
    very brief window of time, a file which failed to flush would be considered successful
    and ready to commit to the control plane metadata store. In program order (i.e.
    the linear flow of the code, ignoring concurrency) this window where the background
    Goroutine that commits metadata would see the successful file would be nearly
    impossible to squeeze into. This background Goroutine only polls for successful
    files every five milliseconds, and the time between the two state transitions
    in the common case would be less than a microsecond!
  id: totrans-split-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在重构代理程序以添加对刷新文件到对象存储的推测重试时，我们在此路径上微妙地破坏了错误处理，以致在非常短暂的时间窗口内，未能刷新的文件被认为是成功的，并准备提交到控制平面的元数据存储。在程序顺序（即代码的线性流程，忽略并发性）中，这个后台
    Goroutine 只会每五毫秒轮询一次成功的文件，而在常见情况下，两个状态转换之间的时间将少于一微秒！
- en: 'This bug is the manifestation of two unlikely events: a file failing to flush
    and a specific thread interleaving that should be extremely rare in practice.
    Despite how unlikely these events are to occur together, on a long enough time-scale,
    this bug would have resulted in data loss at some point.'
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这个错误是两个不太可能的事件的表现：一个文件未能刷新，以及一个特定线程交错，这在实践中应该非常罕见。尽管这些事件同时发生的可能性很小，在足够长的时间尺度上，这个错误最终会导致数据丢失。
- en: Instead, thanks to Antithesis’ powerful fuzzer and fault injector, this rare
    combination of events happened roughly once per wall clock hour of testing. We’d
    been running a build with this bug in our staging environment and obviously did
    not encounter that bug at all, let alone once per hour, as it would’ve immediately
    been noticed when a future background compaction failed due to the missing file
    in object storage. We’ve since fixed the regression in the code such that the
    invalid, temporary state transition cannot occur.
  id: totrans-split-58
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，由于 Antithesis 强大的模糊器和故障注入器，这种罕见的事件组合大约每小时发生一次。我们在测试环境中运行了一个存在此错误的构建，显然没有遇到这个错误，更不用说每小时一次了，因为当后台压缩由于对象存储中缺少文件而失败时，这个错误将立即被注意到。我们已经修复了代码中的回归，使得无效的临时状态转换无法发生。
- en: Why not Jepsen?
  id: totrans-split-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么不用 Jepsen？
- en: 'The obvious question you might be asking yourself at this point is: Why use
    Antithesis instead of a traditional Jepsen test? It’s a good question, and one
    we asked ourselves before embarking on our journey with Antithesis.'
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可能会问自己一个显而易见的问题：为什么使用 Antithesis 而不是传统的 Jepsen 测试？这是一个很好的问题，在我们开始使用 Antithesis
    进行测试之前，我们也曾自问过。
- en: 'We’re big fans of Jepsen and have consumed almost every published report. However,
    after speaking with the Antithesis team and spending a few months integrating
    with it, we feel strongly that deterministic simulation testing with tools like
    Antithesis is a much more robust and sustainable path forward for the industry.
    Specifically, we think that the Antithesis’ approach is better than Jepsen’s for
    a few reasons:'
  id: totrans-split-61
  prefs: []
  type: TYPE_NORMAL
- en: The Antithesis technology is more robust, and much more likely to catch bugs
    than the Jepsen harness. There is simply no other equivalent (that we’re aware
    of) to Antithesis’ custom hypervisor, and its ability to automatically instrument
    distributed systems for code coverage and effectively “hunt” for bugs. Yes, the
    Jepsen framework will inject faults into a running environment in an effort to
    trigger bugs and edge-case behavior, but this approach is crude in comparison
    to what Antithesis does.
  id: totrans-split-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Antithesis integrates natively into how our engineers are used to working.
    The entire test setup is expressed using standard docker-compose files and Docker
    images, and Antithesis tests are kicked off using Github Actions that push WarpStream
    images to Antithesis’ docker registry. When we add new functionality, all our
    engineers have to do is modify the Antithesis workload and kick off an automated
    CI job. The entire experience and workflow lives right next to our existing codebase,
    CI, and workflows. Extra bonus: none of our engineers had to learn Clojure.'
  id: totrans-split-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Antithesis testing is designed to be a continuous process with accompanying
    professional services that help you grow and adapt the tests as the scope of your
    product increases. That means our users get the confidence that every WarpStream
    release is actively tested with Antithesis, unlike a traditional Jepsen test where
    the engagement is short-lived and usually only covers a “snapshot” of a system
    at a static point in time.
  id: totrans-split-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, it would not have been practical to continuously test our entire SaaS
    platform with Jepsen in the same way that we do with Antithesis. While that may
    seem like overkill, we think it’s a pretty important point. For example, consider
    the fact that almost every cloud infrastructure provider has a routing or proxy
    layer that is responsible for routing customer requests to the correct set of
    infrastructure that hosts the customer’s resources. A small data race or caching
    bug in that routing layer could result in exposing one customer’s resources to
    a different customer. These multi-tenant SaaS layers are never tested in traditional
    Jepsen testing, but with Antithesis it was actually easier to include these layers
    in our testing than to specifically exclude them.
  id: totrans-split-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We’re just getting started with Antithesis! Over the coming months we plan
    to work with the Antithesis team to expand our testing footprint to cover additional
    functionality like:'
  id: totrans-split-66
  prefs: []
  type: TYPE_NORMAL
- en: Multi-region deployments of our SaaS platform.
  id: totrans-split-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Multi-role Agent Clusters](https://docs.warpstream.com/warpstream/configuration/deploy/splitting-agent-roles).'
  id: totrans-split-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[多角色代理集群](https://docs.warpstream.com/warpstream/configuration/deploy/splitting-agent-roles)。'
- en: Injecting and detecting data corruption at the storage and file cache layer
    using checksums.
  id: totrans-split-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在存储和文件缓存层使用校验和来注入和检测数据损坏。
- en: And much more!
  id: totrans-split-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还有更多！
- en: If you’d like to learn more about WarpStream, please [contact us](https://www.warpstream.com/contact-us),
    or [join our Slack!](https://console.warpstream.com/socials/slack)
  id: totrans-split-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于WarpStream的信息，请[联系我们](https://www.warpstream.com/contact-us)，或者[加入我们的Slack！](https://console.warpstream.com/socials/slack)
