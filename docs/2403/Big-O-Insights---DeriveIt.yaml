- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:54:34'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Big O Insights - DeriveIt
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://deriveit.org/coding/cheat-sheets/big-o-insights-106?h=t](https://deriveit.org/coding/cheat-sheets/big-o-insights-106?h=t)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Imagine you''re asked to evaluate how fast an algorithm is. Think for a second
    about how you might do this. One idea is to just count the total number of simple
    operations it does (read, writes, comparisons) given an input of size <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation
    encoding="application/x-tex">n</annotation></semantics></math>n. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: The thing is, it's hard to come up with a formula like above, and the coefficients
    will vary a lot based on what processor you run your program on.
  prefs: []
  type: TYPE_NORMAL
- en: 'To simplify this, computer scientists only talk about how the algorithm''s
    speed *scales* when <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation
    encoding="application/x-tex">n</annotation></semantics></math>n gets very large.
    The biggest-order term always kills the other terms when <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation
    encoding="application/x-tex">n</annotation></semantics></math>n gets very large
    (plug in n=1,000,000). This happens no matter what coefficients you have. You
    can see that when n=1,000,000, the <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>n</mi><mn>2</mn></msup></mrow><annotation
    encoding="application/x-tex">n^2</annotation></semantics></math>n2 term dominates
    even though it has a much smaller coefficient:'
  prefs: []
  type: TYPE_NORMAL
- en: 'So computer scientists only talk about the biggest term, without any coefficients.
    The above algorithm has <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>n</mi><mn>2</mn></msup></mrow><annotation
    encoding="application/x-tex">n^2</annotation></semantics></math>n2 as the biggest
    term, so we say that:'
  prefs: []
  type: TYPE_NORMAL
- en: This is called Big O notation. Verbally, you say that the algorithm takes "on
    the order of <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>n</mi><mn>2</mn></msup></mrow><annotation
    encoding="application/x-tex">n^2</annotation></semantics></math>n2 operations".
    In other words, the amount of time the algorithm takes to run scales with the
    term <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>n</mi><mn>2</mn></msup></mrow><annotation
    encoding="application/x-tex">n^2</annotation></semantics></math>n2.
  prefs: []
  type: TYPE_NORMAL
- en: Computer scientists describe memory based on how it scales too. If your program
    needs <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>200</mn><mi>n</mi><mo>+</mo><mn>5</mn></mrow><annotation
    encoding="application/x-tex">200n + 5</annotation></semantics></math>200n+5 units
    of storage, then computer scientists say <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Space Complexity</mtext><mo>=</mo><mi>O</mi><mo
    stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation
    encoding="application/x-tex">\text{Space Complexity} = O(n)</annotation></semantics></math>Space Complexity=O(n).
  prefs: []
  type: TYPE_NORMAL
- en: There's a common confusion people have. People will intuitively know that something
    that takes <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation
    encoding="application/x-tex">n</annotation></semantics></math>n operations is
    <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation
    encoding="application/x-tex">O(n)</annotation></semantics></math>O(n). But many
    people get confused that something that takes, say, <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>n</mi></mrow><annotation
    encoding="application/x-tex">2n</annotation></semantics></math>2n operations is
    still <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation
    encoding="application/x-tex">O(n)</annotation></semantics></math>O(n), or something
    that takes 26 operations is <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation
    encoding="application/x-tex">O(1)</annotation></semantics></math>O(1).
  prefs: []
  type: TYPE_NORMAL
- en: The answer is that Big O is just a ballpark estimate of how your function grows.
    Which power of <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation
    encoding="application/x-tex">n</annotation></semantics></math>n does it grow with?
    If it doesn't grow at all, then grows just like the number 1 grows (not at all),
    so it's <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation
    encoding="application/x-tex">O(1)</annotation></semantics></math>O(1), the 0th
    power of n.
  prefs: []
  type: TYPE_NORMAL
- en: If it grows as some percent of <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation
    encoding="application/x-tex">n</annotation></semantics></math>n, it grows as <math
    xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mo
    stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(n)</annotation></semantics></math>O(n).
    Some square and it's <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo
    stretchy="false">(</mo><msup><mi>n</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation
    encoding="application/x-tex">O(n^2)</annotation></semantics></math>O(n2). If it
    grows with <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo><mi>n</mi></mrow><annotation
    encoding="application/x-tex">\log n</annotation></semantics></math>logn, it's
    <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo
    stretchy="false">(</mo><mi>log</mi><mo>⁡</mo><mi>n</mi><mo stretchy="false">)</mo></mrow><annotation
    encoding="application/x-tex">O(\log n)</annotation></semantics></math>O(logn).
    And so on. It's just a ballpark estimate, a big mistake is to try and overly formalize
    it or overcomplicate it. It should be intuitive.
  prefs: []
  type: TYPE_NORMAL
- en: If you build a size 10,000 array, you must have done at least 10,000 operations.
    But if you did 10,000 operations, you might not have used 10,000 slots of memory.
    Your <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Time Complexity</mtext></mrow><annotation
    encoding="application/x-tex">\text{Time Complexity}</annotation></semantics></math>Time Complexity
    will *always* be greater than or equal to your <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Space Complexity</mtext></mrow><annotation
    encoding="application/x-tex">\text{Space Complexity}</annotation></semantics></math>Space Complexity.
  prefs: []
  type: TYPE_NORMAL
- en: This picture might give you an intuitive sense of this. You can reuse space,
    but not time. This is ultimately because in our universe, you can go back in space,
    but you can't go back in time.
  prefs: []
  type: TYPE_NORMAL
- en: It will *always* be true that <math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Total Time</mtext><mo>≥</mo><mtext>Total Space</mtext></mrow><annotation
    encoding="application/x-tex">\text{Total Time} \ge \text{Total Space}</annotation></semantics></math>Total Time≥Total Space,
    even if you're writing parallel algorithms (which don't show up in interviews),
    because a parallel algorithm is just made of many single-processor algorithms.
    This is why you usually assume infinite memory in most problems, and why limited
    memory problems like in-place sorting are arguably not very interesting. Time
    limits space, so time is more interesting.
  prefs: []
  type: TYPE_NORMAL
