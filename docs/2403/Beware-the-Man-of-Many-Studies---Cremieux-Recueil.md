<!--yml

category: 未分类

date: 2024-05-27 14:46:48

-->

# Beware the Man of Many Studies - Cremieux Recueil

> 来源：[https://www.cremieux.xyz/p/beware-the-man-of-many-studies](https://www.cremieux.xyz/p/beware-the-man-of-many-studies)

在2014年，斯科特·亚历山大撰写了[一篇文章](https://web.archive.org/web/20230604231635/https://slatestarcodex.com/2014/12/12/beware-the-man-of-one-study/)，此后广为引用。他描述了一个大家都认为是问题的事情：过于信任单一研究而不是文献结果。

他强调需要做一些事情。首先，寻找关于特定主题的所有证据的综合总结，如高质量的漏斗图。其次，思考结果可能需要进行限定的方式。以他关于最低工资的例子来说，不同研究中估计的影响可能由于研究背后经济学家的意识形态之外的原因而有所不同。它们可能取决于最低工资变化的大小、受影响的地区或行业，或者变化发生的时间。最后，对结果要保持谨慎，警惕那些明显偏见的人的结论，并警惕那些看似提出非常强有力案例的人，直到你自己做了一些研究。

但这还不够。有时文献是被扭曲的。斯科特并不对此无知；他确实提到了欺诈和出版偏倚。但问题更为严重。本文简要讨论了为什么往往更好地信任单一研究而不是整个文献的结果。

* * *

发表偏倚发生在某些结果更可能被出版的文献中。这可能由于编辑偏好闪光的结果，而闪光的结果有共同之处，如非常大的效应或使用多样化样本等原因。

这种情况比较常见的一种发生方式是通过寻找显著性来实现的。作者知道公众和期刊编辑不希望没有产生显著结果的研究，因此有动机只在*p-*值低于0.05时提交研究。这也导致了对不满足*p* < 0.05的结果进行调整，无论是通过残差化足够的协变量、筛选样本观察，还是在子集中检查结果。关键是找到一些数据的排列组合，使得*p* < 0.05，从而被认为值得出版。

有一个特定的效应，是在给定样本大小下可以检测到的最小效应。因此，如果你的样本足够小，你的效应必须非常大。

显著性选择和*p*-值、样本大小和效应大小之间的依赖关系结合在一起，产生了出版偏见模式，即在许多文献中，效应大小越大，估计越不精确。如果你以前读过我的东西，你可能知道这是什么样子，但如果你不知道，这里是[安德烈亚斯·施内克提供的例子](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5712469/)。

在这样的漏斗图中，出版偏见模式是很容易看到的。对元分析估计值的影响也非常明显：由于有大量的研究估计值过大，因为它们不够精确，所以在存在偏见时，效果似乎比实际上更大！

许多文献实际上看起来就像右边的图表。考虑两个例子：[空气污染对各种结果的影响](https://web.archive.org/web/20230526233206/https://www.econstor.eu/bitstream/10419/266386/1/I4R-DP011.pdf) 和 [正念对学生结果的影响](https://www.frontiersin.org/articles/10.3389/fpsyg.2014.00603/full)。

[修剪和填充方法](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.0006-341X.2000.00455.x) 是一种现成的方法，通过添加反映元分析估计值另一侧绘图中观察到的不对称的数据点来纠正这种偏差。原始例子很清楚地说明了这是如何运作的。在这些图表中，“填充”估计值是空白的白点，黑点是在元分析中观察到的估计值。在添加白点并有效限制不准确的、异常的结果夸大元分析估计的能力之后，新的估计大大减少。在许多更严重的情况下，估计值在校正后变得完全为零。

还有其他出版偏见校正方法，如PET、PEESE、PET-PEESE、*p*-曲线和三部分选择模型。这些方法的唯一问题是，它们仅在研究数量较大、出版偏见模式由于对显著性的过滤而观察到，以及模式较弱但算法校正偏见不认为需要校正的情况下才有效。

我们知道这是真的，因为我们可以模拟它，而且已经进行了实证测试。实证测试结果非常糟糕：每种方法都倾向于未能正确校正元分析估计值。在左边，你有元分析效应大小，紧邻其旁，你有来自大型、预注册复制研究的效应大小。黄色的柱代表通过PET-PEESE（许多人认为过于保守的校正），3PSM和修剪填充调整元分析估计值时获得的效应大小。

[这一点并不独特](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01365/full)。我最喜欢的复制研究显示，货币启动文献中存在着非常显著的出版偏见效应。注意已发表和未发表研究的结果。一个明显比另一个更大且更有偏见。交互作用效应比主效应更难检测，也受到非常显著的出版偏见的影响。由于检测它们的能力较低，预注册研究可能根本没有尝试去寻找它们。最后，预注册的效应正好集中在0周围。货币启动并不真实。像许多建立广泛文献的效应一样，它是出版偏见所造成的一种发明。

一些出版偏见模式的发生是由于对显著性的最小过滤，简单地追求小于0.05的 *p-* 值，并且 *刚好* 在0.05以下。[正如我在其他地方写过的](https://cremieux.substack.com/p/ranking-fields-by-p-value-suspiciousness)，这导致 *p-* 值分布中的一个峰值，在显著性阈值下方有过多的存在。但这并非必然如此，这削弱了出版偏见的纠正作用。这发生在人们进行他们的 *p-* 操纵时，无论是否故意，都会创造一个 *极其* 显著而不是 *仅仅* 显著的效果。

有时，类似于出版偏见模式的东西出现的原因并不是出版偏见。这就是 [干预措施未能扩展时](https://web.archive.org/web/20230118032728/https://www.nber.org/papers/w30850) 的情况。因为扩展失败可能导致对未来效果的期望降低，如果这导致更为保守的功效分析并建议需要更大的样本或更多的资金每人。但如果由于扩展问题导致更大样本的结果更小，这可能会成为一个自我强化的问题。因此，区分出版偏见和扩展失败可能会很困难，并需要大规模、预注册的复制实验来提供可靠的裁定或不同解释的限定。

然而有一点是肯定的，那就是扩展失败 *不应该* 产生 *仅仅* 显著或者看起来产生显著性阈值下方的峰值的结果。没有出版偏见的扩展失败应该导致结果不显著而不是 *仅仅* 显著。它们可能增加 *p-* 操纵发生的风险，但这意味着扩展失败应被视为出版偏见的促进者，而不是完全的替代品。

预注册的复制实验经常证明了大部分或完全是出版偏见的解释，我倾向于认为它解释结果的频率远远超过扩展失败。

有时候既不是缩放，也不是出版偏见导致了一开始看起来与它们一致的模式。这种情况发生在需要报告、预注册和外部分析作为获得资金条件的教育干预项目中。你可以在由教育基金会（EEF）和国家教育评估及地区协助中心（NCEE）资助的研究图表中看到这一点。

这个图表值得仔细检查。虚线表示特定试验的最小可检测效应大小。你可以看到有一种出版偏见的模式，如果你点击进入研究，你会在图2中看到更典型的表现。

那么究竟发生了什么？这看起来与通常理解的出版偏见不同，因为构成模式基础的研究中很少有实际产生显著结果的。它们并不是*p*-挖掘过的；它们只是不显著，并且看起来很大，因为不精确的零效应在逻辑上更有可能是极端大的，而不是精确估计的零效应。

这项研究发现，出版年份、试验质量、每位学生的成本以及试验的总成本都不是这些试验效果大小的调节变量。唯一重要的调节变量是理论上预期的效力和有效性试验之间的差异。前者是在理想条件下进行的试验，而后者是在现实条件下进行的试验。差异非常小，但方向是符合预期的：效力试验的平均效果为0.05，有效性试验为0.01。

这些试验都非常大，资金充足，并在其领域内表现出色。出现出版偏见的类似模式是因为在不精确的研究中极端估计的固有可能性与资金资助研究的选择相结合。为了获得资金支持，研究人员必须提交证据表明他们的方法有效，因此有偏向于资助至少不会造成伤害的干预措施。尽管如此，[所有研究中任何效果的证据基本为零](https://twitter.com/cremieuxrecueil/status/1663721847194615808)；动力也很低，中位数仅为17%，这表明动力和出版偏见模式之间的关系是由于*p*-值挖掘，因为这在这些研究中并未实际观察到。

所以我们有一个问题：元分析有时可以提出建议，但通常无法解决出版偏见的问题。如果你相信未经校正的元分析估计，你将会被误导。如果你相信校正后的元分析估计，*你通常仍然会被误导*。

* * *

研究在质量上存在差异，但在进行调节分析之前，你的元分析估计将研究视为质量相同。只需要你的估计和标准误差，得到的结果就是跨越各种可信度不同的研究效应的加权估计。

对于功效为10%的研究，其权重将基于一个标准误差，就像功效为80%的研究一样。如果大多数研究功效低，它们的个体权重可能比更有力的研究少，但它们仍然倾向于将估计拉向它们所在的位置，而不是向有力估计的位置。如果它们处于同一位置，那就没问题；如果它们系统性地有所区别，低功效研究产生更大效应，正如它们倾向于的那样，那么问题可能就会出现。

低功效几乎是所有领域的常态，包括[神经科学](https://www.nature.com/articles/nrn3475)，[政治科学](https://web.archive.org/web/20220815075738/https://osf.io/hsgkp/)，[环境科学](https://web.archive.org/web/20230125190958/https://ecoevorxiv.org/repository/view/4966/)，[医学](https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.2000797)，或[乳腺癌、青光眼、类风湿性关节炎、阿尔茨海默病、癫痫、多发性硬化和帕金森病研究](https://royalsocietypublishing.org/doi/10.1098/rsos.160254/)。进行元分析时，几乎肯定是在使用功效不足的研究，元分析结果也会反映这一点。元分析和校正出版偏倚只能在提供的数据范围内进行，如果质量不够好，可能只能得到一个有偏差且不现实的结果。

如上所述，任何修正都不能解决这些问题。“垃圾进，垃圾出”是元分析无法解决的问题；要避开这个问题，需要进行新的研究，而不是对垃圾数据的疲惫重新分析。但如果有人决定检查研究质量对元分析效果的调节作用，他们可能会认为能够处理质量问题。他们能做得多好取决于他们如何编码研究质量，以及研究质量的各个维度如何随着用于元分析的估计变化而变化。

编码研究质量的典型方法是制作一个检查表，列出高质量和低质量的特征，然后为每个研究分配一个反映其质量的分数。但是假设研究质量在质量检查表的项目内部变化，某些项目比其他项目更重要，而一些被认为与质量相关的项目根本不重要。预先无法知道如何对研究质量维度进行加权，编码是否充分考虑了这些维度对估计的影响，甚至结果估计是否存在偏差。

因此，研究人员可能决定评估研究质量各个维度的调节力量。再次，质量评分的有效性可能不足，评分可能不够精细，编码可能不足，维度的单独分析可能会掩盖需要更全面同时建模研究质量的细节。在典型元分析中包括的样本量较少，加之编码过程中出现的任何系统性误差，会加剧这一问题。研究人员必须依靠运气使调节分析有效。特殊维度是显然独立影响研究质量的事物，比如实验中是否有被动或主动对照。当调节因素是由抽样（比如年龄）而不是研究设计（比如对安慰剂效应的控制）引起时，更可能导致或促进内生性问题。

我可以继续探讨其他做法，但它们都会得出同样令人厌倦的结论：元分析估计只能通过修正和调节移动这么多，而且对估计的任何变化通常都具有不确定的实用性。这不能取代复制的必要性。

* * *

Scott提到了最低工资效应的例子。关于最低工资的文献并不容易进行元分析，因为其效应大小依赖于重要的调节变量。一项发现所有研究结果为零的元分析可能忽略了重要的细节，比如在存在大量单买方市场力量时，最低工资效应通常是广泛有益的，或者当最低工资微幅提高时，其不良影响较少。

因为这些重要的限定条件可能不像最低工资研究那样频繁发布，零效应可能是典型研究结果，而没有这些调节变量的重要影响更普遍。将典型研究和特殊研究视为同等可能会掩盖重要的、政策相关的识别差异。如果研究人员有意识形态倾向，元分析中的零效应可能只是研究人员典型情感的表达。即使每一项分析都完全内部可信，只需少数偏倚人员即可证明这一点为真。

对于像最低工资研究这样更自然、不那么标准化的元分析，总会有争议的地方。在最低工资问题上，你不能只看一项研究，也不能看所有研究，因为尽管属于更广泛的“最低工资研究”范畴，但太多研究提出了重要的不同观点。

当异质性问题重要时，你应该关注几项（但可能不是所有）研究，或者一个可信地汇编它们并展示对所有研究理解的细微差别的综述。

那么对于产生影响的东西相对一致，而受影响的东西也相对一致的文献呢？在这种情况下，你可能仍需要成为一项研究的人，而不是所有研究的人。作为例子，我将使用收入或财富对心理健康的影响，并使用彩票来辨识不受混淆的影响，因为玩彩票的人是随机的。

[Lindqvist, Östling & Cesarini](https://academic.oup.com/restud/article/87/6/2703/5734654)（LÖC）最近发表了一项比他们之前的研究更好的关于彩票财富对心理幸福感的影响的估计。他们的研究比以往的大部分文献具有更大的样本，变数大小更多，因此有更多的识别变数，得奖者的样本更具代表性，并且在已发表研究中具有最多的年份覆盖。简而言之，这是迄今为止对彩票中奖对心理幸福感影响最好的研究。

让我们将其与以往的文献进行对比。在LÖC之前有四项研究。我们来看看它们的结果与LÖC的结果：

这些影响相对于普通人口的定位权衡和收入的影响是如此极端，以至于它们混淆了这两种估计的标准错误。在普通人口中，10万美元与更好的心理幸福感相关联，标准差为0.068（SE = 0.009）。在我进行元分析的以往文献中，10万美元的影响与更好的心理幸福感一致，标准差为0.873（0.443）。相比之下，LÖC的估计值为0.013（0.016）。

10万美元对心理幸福感的影响似乎显然被混淆，基于非常好识别的设计，不太可能是因果的。但如果你使用以往文献，你会得出不同的结果：彩票收入的重大影响，同时，与普通人口的关系没有差异。使用所有可用的研究，你将被误导。

可用的研究数量很少，但这一点通常适用，因为它代表了充满大量研究的文献中的情况。

* * *

有时研究是虚假的，虚假的研究会污染元分析估计。有时所有的研究可能无法幸存欺诈。如果他认为一项欺诈研究能代表他感兴趣的效应的更广泛文献，他将被误导。

你可以从动机和智商测试之间的关系中看出这一点。在最新的关于动机是否能增强智商测试结果的元分析中，[Duckworth et al. (2011)](https://www.pnas.org/doi/10.1073/pnas.1018601108)，三项研究由被定罪的骗子Stephen E. Breuning进行。这三项可能是欺诈的研究在文献中是最大的，它们产生了最大的效果，并且估计的精确性也比其他研究更高。它们使得似乎没有任何出版偏见，但是如果将它们移除，每一个标准的出版偏见校正突然将元分析估计变为零。

有多少研究是欺诈的？大量研究是完全欺诈的可能性不大，但许多研究都涉及某种程度的欺诈，即使是由于 [不正确地四舍五入](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4830257/) *[p](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4830257/)*[-value](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4830257/)、效应大小或标准误差的微小变化，这些变化可能会导致错误的元分析结果。

浏览几个小时 [Elisabeth Bik 的 Twitter](https://twitter.com/MicrobiomDigest)，你可能会认为 *一切* 都是欺诈的。 [谁知道呢](https://twitter.com/cremieuxrecueil/status/1652469608442482689)？

* * *

Scott提到了“魔法词汇‘同行评审的实验研究’”。

同行评审并不神奇。如果你曾参与过或成为它的主题，你可能知道它有多糟糕。正如许多人最近从预印本革命中学到的那样，它似乎也不会影响出版质量。我在前一节关于欺诈的研究中提到的研究都通过了同行评审，几乎可以肯定，你曾阅读过的每一篇糟糕的研究或元研究也都通过了同行评审。

同行评审赢得的声誉是不应得的。它不能解决问题，也不清楚在保持研究可信方面是否有任何好处。因为同行评审在个别研究中的影响是异质的，它几乎也无法在保持元分析可信度方面起到作用。元分析者必须相信同行评审使得他们分析中的每项研究都受益，但如果说，某个评审人对显著结果的偏好影响了文献，它可能是出版偏见的 *来源* 。同行评审中的任何评审人对任何已出版或未发表的文献中的任何特征的偏好也可能同样有害。显著性只是一个常见的偏好特征。

当涉及审查元分析时，同行评审理论上可以阅读每一篇引用在元分析中的研究，并建议如何编码研究质量或哪些研究应该保留和移除。理想情况下，他们会这样做；现实情况是，当研究很多时，这要求太多了。而且你通常不会知道在任何个别情况或元分析中它是否有帮助，因为大多数同行评审并不公开报道。同行评审是一个黑匣子。如果你不轻信专家的话，为什么要相信它呢？

同行评审对于广泛研究的人来说根本不起作用。最好的情况是，当元分析做得不够好以至于评审员注意到并采取行动，例如告诉正在被评审的研究人员改变他们的估计器时，它可以保护他们。如果他们告诉他们在其他地方寻找出版物，研究人员可以继续进行，直到他们遇到足够轻信的评审员并发表他们的垃圾。

由于几乎没有证据表明同行评审很重要，我怀疑它对于研究者经常被赋予任何思考的一或多个研究人员是有帮助的。

* * *

像Scott一样，我不想宣扬激进的怀疑主义。我想宣扬科学推理。如果你对$topic_x的研究感兴趣，你应该熟悉该领域的方法，特别是该领域最关键的声音。你应该知道什么是对的，什么是错的，并能够识别出领域研究者足够经常以侧目看到的所有问题。

大多数人没有能力做到这一点。当他们有能力时，他们可能不知道他们有能力；当他们没有能力时，他们可能错误地认为他们有能力。Scott建议减少对主张的信心是好的，避免有偏见的人的结论也是好的，尽管我想补充一点，有偏见的人很适合阅读，以理解他们反对的人的论点中的缺陷，并且有必要查看所有的证据仍然是相当明显的。

我想补充一点，通过关注设计来思考因果推断对于建立对科学的正确理解是必要的。一个设计良好、功率强大的研究通常比大量较差识别和低功率的研究更有价值。这是如此真实，以至于只知道自己是一项研究的人，*因为其他都是垃圾*，通常比他的同行研究人员错得少得多。因为很难传达他是一个只知道自己是一项研究的人，*知道*他是一项研究的人，这可能很难看到。
