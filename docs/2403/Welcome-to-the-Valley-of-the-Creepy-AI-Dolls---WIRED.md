<!--yml

类别：未分类

日期：2024年5月27日14:46:11

-->

# 欢迎来到怪异AI娃娃的谷 | WIRED

> 来源：[https://www.wired.com/story/ai-dolls-for-older-adults/](https://www.wired.com/story/ai-dolls-for-older-adults/)

但这些都是当公司要求人们在他们最脆弱的时刻转向他们的产品时所带来的固有风险。莫伊尔说她在这个问题上有两种看法。

“如果我们让某人有机会与AI交谈，是否会排除其他所有的社交机会？”莫伊尔说。“这是否意味着家人停止访问？员工是否停止与人交流？”这是一个风险，但她说，根据她的经验，许多养老设施中的老年人大部分时间都是独自一人度过的。“如果能给他们一些东西让他们开心，比起什么都不给要好得多。”

当然，这些设备并不等同于人类。大型语言模型并不理解与它们互动的人；它们只是非常擅长预测什么样的回应听起来会很好。它们当然也不知道如何完全理解一个人的情感或心理状态。

“人们可能表现出相当具有挑战性的情绪，但AI却无法捕捉到。”莫伊尔说。“随着AI变得更加复杂，这种情况可能会变得更好，但目前显然不是这样。”她顿了一下，然后笑着补充道：“但很多人类也不能很好地评估情绪，所以……”

对于许多人来说，一个机器人是否能回报爱并不重要。这就是为什么我们仍然为我们的机器人哀悼它们的“缓慢、忧郁的死亡”，并为机器狗举行[葬礼](https://www.theguardian.com/world/2018/may/03/japan-robot-dogs-get-solemn-buddhist-send-off-at-funerals)。这就是为什么我们在我们的性机器人中想要[个性](https://www.wired.com/story/henry-the-sexbot-wants-to-know-all-your-hopes-and-dreams/)，并信任它们了解我们的[深层愿望](https://www.wired.com/story/replika-chatbot-sexuality-ai/)。当一个人与机器人互动时，这与机器人是否能回报你的爱意无关，而更关乎人们如何从向某人（或某物）倾注自己的感情中获得价值。

“猫咪和婴儿带给我们的感觉是，它们需要我们的爱，这也是我们作为人类所渴望的。”洪说。如果有人希望与一只可爱而亲密的机器人互动，通常也是为了满足同样的需求。“我们购买这些机器人是因为我们想要向它们表达爱意——所以我们觉得机器人需要我们的爱，这样我们就感觉到有某种东西需要我们。这就是人类的本性。”

*2024年3月20日更新：本故事已更新，包括Hyodol在本故事初始发布后发送的声明。*
