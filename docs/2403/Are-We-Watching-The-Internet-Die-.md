<!--yml

category: 未分类

date: 2024-05-27 14:49:39

-->

# Are We Watching The Internet Die?

> 来源：[https://www.wheresyoured.at/are-we-watching-the-internet-die/](https://www.wheresyoured.at/are-we-watching-the-internet-die/)

Sometime this month, [Reddit将以65亿美元的估值上市](https://www.cnbc.com/2024/03/01/reddit-seeking-a-valuation-of-up-to-6point5-billion-in-ipo.html?ref=wheresyoured.at)。[选择的Reddit用户有机会以首次上市价格购买股票](https://www.cnn.com/2024/02/26/tech/reddit-ipo-users-can-buy-shares/index.html?ref=wheresyoured.at)，尽管目前尚未公布，但预计在每股31-34美元之间](https://www.ft.com/content/b3199303-d419-482d-96c7-e73c0b0ee8ed?ref=wheresyoured.at)。不论实际价格如何，Reddit的股价很可能迅速跌破IPO价格，因为Reddit是一家非常糟糕的公司，[2023年收入8.04亿美元，亏损9,080万美元](https://www.reuters.com/technology/reddit-makes-us-ipo-filing-public-2024-02-22/?ref=wheresyoured.at)，[从未盈利](https://www.cnn.com/2024/02/23/tech/reddit-ipo-filing-business-plan/index.html?ref=wheresyoured.at)。[Reddit的S1](https://www.sec.gov/Archives/edgar/data/1713445/000162828024006294/reddits-1q423.htm?ref=wheresyoured.at)(公司公开上市的初始注册表格)荒谬地声称，该网站上的广告“快速发展”，并且“仍处于发展初期”，[指的是Reddit 15年前推出的业务](https://techcrunch.com/2009/11/12/reddit-advertising/?ref=wheresyoured.at)。

Reddit 的 IPO 是企业历史上最大的欺诈之一，数百万未付报酬的贡献者发布了数十亿篇帖子，以便于 [CEO Steve Huffman 在 2023 年赚取 1.93 亿美元](https://www.bizjournals.com/sanfrancisco/inno/stories/news/2024/02/23/reddit-ceo-steve-huffman-total-compensation-2023.html?ref=wheresyoured.at#:~:text=Bay%20Area%20Inno%20-%20Reddit%20CEO,exceeded%20%24193M%20last%20year)，同时裁员 90 人并 [有效地](https://www.reuters.com/technology/reddit-lay-off-about-5-workforce-wsj-2023-06-06/?ref=wheresyoured.at) [通过高额的 API 访问费用将第三方应用程序](https://www.theverge.com/2023/6/15/23762501/reddit-ceo-steve-huffman-interview-protests-blackout?ref=wheresyoured.at) [从平台上赶走](https://www.theverge.com/2023/6/12/23755974/reddit-subreddits-going-dark-private-protest-api-changes?ref=wheresyoured.at)，这些行动引发了用户的多次长时间“罢工”。 Reddit 随后有效地“政变”了这些子版块，用 [其自选的](https://www.theverge.com/2023/7/20/23802370/reddit-over-reopens-subreddit-protest-male-fashion-advice?ref=wheresyoured.at) 版主取代了长期的版主 — 这些人愿意 [遵循党的路线并重新向公众开放](https://arstechnica.com/gadgets/2023/07/reddit-calls-for-a-few-new-mods-after-axing-polarizing-some-of-its-best/?ref=wheresyoured.at)。

为 Subreddit 奉献了数小时生命或执行了重要但不被感谢的审查工作的人都不会从 Reddit 的上市中获利，但 [Sam Altman 在 2014 年的 5000 万美元投资将使其获得数亿美元](https://www.cnbc.com/2024/02/22/openai-ceo-sam-altman-stands-to-net-millions-as-reddit-goes-public.html?ref=wheresyoured.at)。 [Reddit 还宣布达成了 6000 万美元的协议，允许 Google 在 Reddit 的帖子上进行模型训练](https://www.reuters.com/technology/reddit-ai-content-licensing-deal-with-google-sources-say-2024-02-22/?ref=wheresyoured.at)，再次对用户的辛勤工作不提供任何回报。

[赫夫曼写给投资者的信](https://www.sec.gov/Archives/edgar/data/1713445/000162828024006294/reddits-1q423.htm?ref=wheresyoured.at#:~:text=As%20a%20way,enjoyable%20as%20possible.) 对Reddit用户的“对他们创建的社区拥有深刻的所有权感”进行了诗意的描绘，并通过声称他希望“这种所有权感在实际所有权中得到反映”，来为公司上市辩护，提供给他们购买非投票股票的机会，这些股票会增值。赫夫曼在信末称Reddit是“互联网上最大的真实和不断更新的人类生成经验库之一”，然后将其称为公司的“数据优势和知识产权”，将Reddit用户的帖子描述为“[数据，这些数据随用户对话不断增长和再生](https://futurism.com/ai-trained-ai-generated-data-interview?ref=wheresyoured.at)”。

我们正处于互联网用户的一场广泛而多方面的骗局的尾声，超级富豪技术人员愚弄他们的客户，让他们免费为他们的公司建设。而虽然交易曾经看起来是公平的，但显然这些高管们看待用户不是作为某种公平交换中的自愿参与者，而是作为可以无限次利用的数据来源，除了获得或不获得正常运行的平台访问权限外，什么也不给予。

当然，这正是科里·多克托罗（Cory Doctorow）的[恶化理论](https://en.wikipedia.org/wiki/Enshittification?ref=wheresyoured.at)的关键所在，Reddit已经从取悦用户转向取悦其商业客户，现在则是取悦股东，这必然会以平台质量为代价。

然而，正在发生在网络上的事情比简单的*贪婪*更为阴险，而是用户生成的互联网的毁灭，高管们认为他们已经找到了一种方法，可以用由万亿美元公司控制和货币化的数据集训练的生成怪物来取代人类创造出的酷东西。

他们理想的情况不是你访问由人类创造内容的不同网站，而是回到互联网黑暗时代，其中大多数流量通过由少数几家精心策划的门户网站运行，其结果基于越来越多地受到生成内容污染的数据集构建，这些内容只是填充空间而不是为用户消费。

算法容易被欺骗，用来欺骗它们的工具变得越来越容易使用和扩展。

而且它正在慢慢摧毁互联网。

## **退化人工智能**

在世界各国政府于20世纪40年代中期开始进行地上核武器测试后，放射性粒子进入大气层，永久污染了所有现代钢铁生产，这使得建造某些机器（如测量放射性的机器）变得具有挑战性（或不可能）。因此，我们有限的供应来自称为"[低背景金属](https://qz.com/emails/quartz-obsession/1849564217/low-background-metal-pure-unadulterated-treasure?ref=wheresyoured.at)"的东西，通常必须从第一次核武器爆炸前沉没的船只中收集，包括[一些可以追溯到罗马帝国时期的船只](https://www.theatlantic.com/science/archive/2019/10/search-dark-matter-depends-ancient-shipwrecks/600718/?ref=wheresyoured.at)。

生成AI模型通过大量从互联网上抓取的文本进行训练，这意味着生成AI的消费采用给自己的数据集带来了一定程度的放射性。随着越来越多的互联网内容部分或完全通过生成AI创建，这些模型本身将发现它们越来越多地依赖自己模型生成的内容，这些内容在某种程度上是在[永久锁定在2023年](https://lowbackgroundsteel.ai/?ref=wheresyoured.at)之前，这是一个专门用于替换人类创建内容的工具的到来之前。

这是Jathan Sadowski所称的"[哈布斯堡AI](https://twitter.com/jathansadowski/status/1625245803211272194?lang=en&ref=wheresyoured.at)"现象，其中"一个系统如此严重地依赖其他生成AI的输出，以至于它变成了一个近亲突变体，可能具有夸张、怪诞的特征。"实际上，哈布斯堡AI将会越来越*普通*和*空洞*，标准化为一堆平庸的商业用语，因为它的模型越来越多地基于越来越相似的内容训练。

LinkedIn已经是一个空洞企业胡言乱语的库，[已经允许用户使用AI撰写消息、档案和职位描述](https://techcrunch.com/2023/03/15/linkedin-expands-its-generative-ai-assistant-to-recruitment-ads-and-writing-profiles/?ref=wheresyoured.at)，而[使用这些生成功能创建的任何内容立即反馈到其母公司Microsoft旗下的Azure OpenAI模型中](https://www.linkedin.com/help/linkedin/answer/a5538339?ref=wheresyoured.at#:~:text=For%20example%2C%20some%20of%20our,data%20from%20the%20training%20dataset.)，该公司在2023年初向OpenAI投资了100亿美元。虽然LinkedIn尚未推出完全自动化的回复，[Chrome扩展程序已经存在，用于向平台发送泛泛的响应](https://twitter.com/nilansaha/status/1762390930550927823?ref=wheresyoured.at)，这为Microsoft和OpenAI的模型输入了更多的通用化内容。

生成式AI也自然地与最大平台创造的有毒激励机制相吻合。谷歌的算法满足搜索引擎优化行业自然而然地使那些能够生成大量“相关”内容而不是人类创建的内容受益。[虽然谷歌声称他们即将推出的“核心”更新将有助于推广“为人们而不是为了在搜索引擎中排名的内容”，](https://searchengineland.com/google-released-massive-search-quality-improvements-with-march-2024-core-update-and-multiple-spam-updates-438144?ref=wheresyoured.at) [它此前也做出过这种承诺，](https://www.theregister.com/2022/08/19/google_search_algorithm/?ref=wheresyoured.at) 我严重怀疑是否会有任何有意义的改变。毕竟，谷歌占据了超过85%的所有搜索流量，并且[每年向苹果支付数十亿美元，使谷歌搜索成为Apple设备上的默认选项。](https://www.theverge.com/2023/10/26/23933206/google-apple-search-deal-safari-18-billion?ref=wheresyoured.at)

因为这些平台更多地奖励规模和数量而不是质量，AI自然而然地奖励那些能够找到最具垃圾特征的方法来操纵算法的人。[404 Media报告称，](https://www.404media.co/inside-the-world-of-tiktok-spammers-and-the-ai-tools-that-enable-them/?ref=wheresyoured.at) [垃圾邮件制作者通过制作“无面重拍”来利用TikTok的创作者计划赚取数千美元，其中AI生成的声音在从YouTube剪辑拼接而成的视频上发言](https://www.404media.co/inside-the-world-of-tiktok-spammers-and-the-ai-tools-that-enable-them/?ref=wheresyoured.at)，并且[自动化大师的小作坊](https://www.instagram.com/reel/C1ZidLAuksO/?ref=404media.co)通过帮助其他人用低质量视频淹没Facebook、TikTok和Instagram来赚钱。

亚马逊的Kindle电子书平台被AI生成的内容淹没，[曾一度主导畅销书榜单，](https://www.wired.com/story/scammy-ai-generated-books-flooding-amazon/?ref=wheresyoured.at) [迫使亚马逊限制作者每天只能发布三本书。](https://arstechnica.com/information-technology/2023/09/ai-generated-books-force-amazon-to-cap-ebook-publications-to-3-per-day/?ref=wheresyoured.at) [这并未阻止垃圾邮件制作者发布笨拙的重写和他人书籍的摘要，](https://www.wired.com/story/scammy-ai-generated-books-flooding-amazon/?ref=wheresyoured.at) 由于亚马逊的政策并未明确禁止AI生成的内容，ChatGPT已经成为出版行业身上不可操作的癌症。

“手工制作”的商品商店Etsy自己也有AI问题，[据《大西洋月刊》去年的报道](https://www.theatlantic.com/technology/archive/2023/06/ai-chatgpt-side-hustle/674415/?ref=wheresyoured.at)，该平台现在充斥着AI生成的艺术品、T恤和马克杯，这些商品又利用ChatGPT优化列表以在Google搜索中排名靠前。作为一家盈利的上市公司，Etsy几乎没有动力改变现状，即使平台上的手工艺品正被AI生成的艺术品挤压出市场。[而eBay则正在推广垃圾信息，提供工具基于单一图像使用生成式AI生成整个商品列表](https://www.pymnts.com/artificial-intelligence-2/2023/ebay-to-add-ai-powered-image-based-listing-tool/?ref=wheresyoured.at)。

去年，《华尔街日报》报道称，[杂志现在被AI生成的文章提案淹没](https://www.wsj.com/articles/chatgpt-already-floods-some-corners-of-the-internet-with-spam-its-just-the-beginning-9c86ea25?ref=wheresyoured.at)，并且[著名的科幻出版社Clarkesworld在收到大量AI生成的故事后不得不停止接受投稿](https://www.theguardian.com/technology/2023/feb/21/sci-fi-publisher-clarkesworld-halts-pitches-amid-deluge-of-ai-generated-stories?ref=wheresyoured.at)。Help A Reporter Out曾经是记者寻找潜在来源和引用的途径，但现在请求却被大量AI生成的垃圾信息所淹没。

当然，这些故事都反映了一个共同的问题：生成式人工智能对依赖算法的互联网构成了毒害。

现在，有太多用户、太多网站和太多内容提供者，手动组织和筛选互联网内容已经不可行，这使得平台必须依赖算法提供服务。生成式人工智能是一个完美的工具，可以无情地按照特定的指令——比如算法遵循的指令——生产内容，虽然理论上算法可以被调整以评估内容的“人性化”，但生成的内容也可以被调整使其*看起来*更像人类创作。

当你意识到互联网内容的纯粹*数量*使得算法推荐成为必要来筛选日益增长的一堆废物时，情况变得更糟。生成式AI [使创作者能够武装算法的弱点](https://twitter.com/sugarsmorecake/status/1763941484653343056?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1763941484653343056%7Ctwgr%5Ea872ae864382ff6ce94a7bc72d711eaacb954876%7Ctwcon%5Es1_&ref_url=https%3A%2F%2Fwww.404media.co%2Finside-the-world-of-tiktok-spammers-and-the-ai-tools-that-enable-them%2F&ref=wheresyoured.at)来赚钱和推广低效的废物，最终，平台该如何处理？禁止使用AI生成内容的所有内容？调整算法以惩罚没有人脸的视频？平台如何判断受欢迎视频和平台推广的视频之间的差异？如果这些视频是由人类制作并受人类喜爱的，为什么*应该*阻止它们？

Google可能会*假装*关心搜索结果的质量，但是搜索在过去十年里的衰退并没有表明它真的打算采取任何行动。[Google的垃圾邮件政策](https://developers.google.com/search/docs/essentials/spam-policies?hl=en&ref=wheresyoured.at)多年来一直声称[*多年来*](https://web.archive.org/web/20221207161654/https://developers.google.com/search/docs/essentials/spam-policies?hl=en)，剽窃内容（直接复制另一个网站的内容）是从Google中删除的理由，但是即使是最粗略的一瞥任何新闻搜索也会显示网站多么频繁地浅显地重写或者直接窃取其他人的内容。而我无法表达出存在[$400亿美元的搜索引擎优化行业](https://www.acumenresearchandconsulting.com/search-engine-optimization-services-market?ref=wheresyoured.at#:~:text=The%20market%20size%20of%20search,USD%2046.7%20Billion%20in%202021.)有多糟糕（然而也是不可避免的），以及如何半自动化地创作和优化内容符合[Google已经详细解释过的算法标准](https://developers.google.com/search/docs/essentials?ref=wheresyoured.at)是多么的有利。尽管Google有可能真正尝试打击SEO生成的文章的涌入，但人们不禁要思考为什么在花费几十年迎合这个行业之后现在才尝试。

正如我们所看到的，平台正在与*生成式垃圾邮件*进行搏斗，这是一种荒谬而显而易见的毫无意义的东西，这种毫无意义的东西应该（也很可能会）被制止。然而在这个过程中，他们未能看到这不是一场对*垃圾邮件*的战争，而是一场对*糟糕东西*的战争，以及当内容被制作来取悦算法并为消费者提供最低限度的可行产品时所带来的整体正常化和智力麻木化。谷歌的“无用”结果问题不是来自没有意义的内容，而是来自内容只能在一定程度上帮助的内容，它是“正确”的结果，但实际上并没有真正的思考在其中，就像无数的“如何修复错误代码X”的结果充满了怀着良好愿望、可能有所帮助的内容，但实际上并没有起到任何实际的帮助。

相同的情况也发生在Etsy和亚马逊身上。尽管Etsy的“垃圾邮件”对于真正用手工制作东西的工匠来说是一个存在性威胁，但它并不是真正的垃圾邮件 — 它是廉价而劣质的产品，尽管如此它却满足了一定的需求，并*在一定程度上*符合Etsy的使命。亚马逊没有任何动机去摆脱那些低质量的书籍，因为它们销售得很好，销售的原因和它不清除其他低质量物品的原因相同。人们不是在寻找最好的，他们是在满足一种需求，即使这种需求是通过劣质商品来满足的。

平台很可能将定位与受欢迎混为一谈，未能看到算法的自我实现预言，因为算法使得某些东西受欢迎，因为这些东西是为了取悦算法而制作的，从而创造了更多为了取悦算法的内容需求。 “病毒式”内容不再是很多人决定他们觉得某些东西有趣的结果 — 而是由生成式AI使之成为可能的力量，正在变得更加强大和细致。

我们正在看到互联网的联合超扩展和超正常化，所有受欢迎的内容都开始变得相似，以吸引那些着迷于增长的公司运行的算法。AI模型中的质量控制只是为了阻止人们通过毫无疑义的恶意意图裸露地利用网络，而不是为了阻止人们制作那些很糟糕但因为算法喜欢而受欢迎的东西。

这并不是自动化工具为艺术或新概念注入生命的情况，而是对日益缺乏独特性的互联网进行的复述，*因为这些模型是基于从互联网上获取的数据进行训练的*。就像植物转向捕捉阳光一样，[互联网的某些部分已经扭曲成为算法的满足点](https://www.wheresyoured.at/the-anti-economy/)，随着其他人依赖生成式AI（[例如Quora，现在在搜索结果顶部推广ChatGPT生成的答案](https://slate.com/technology/2024/02/quora-what-happened-ai-decline.html?ref=wheresyoured.at)），网页将变得更加依赖和由自动化系统主导。

最终问题在于，这种无用的混乱将导致像谷歌这样的公司强迫他们的生成式AI来“修复”问题，通过生成答案来筛选掉无用信息。[亚马逊现在使用生成式AI总结评论](https://www.theverge.com/2023/8/14/23831391/amazon-review-summaries-generative-ai?ref=wheresyoured.at)，将[平台上成千上万的虚假和付费评论](https://www.wired.com/story/fake-amazon-reviews-underground-market/?ref=wheresyoured.at)合法化，并将其呈现为来自亚马逊自身的验证和信任的信息。[谷歌已经在iOS和Chrome上实验其“搜索生成体验”](https://blog.google/products/search/google-search-generative-ai-international-expansion/?ref=wheresyoured.at)，[总结整篇文章](https://www.theverge.com/2023/8/15/23833045/google-artificial-intelligence-summary-chrome-sge?ref=wheresyoured.at)，微软的必应搜索已经集成了Copilot的摘要，两者都基于搜索和训练数据生成答案。

然而，这样做的同时，这些平台获得了对世界信息的危险控制。[谷歌与Reddit的交易也给予了谷歌对Reddit内容的实时访问权限](https://www.searchenginejournal.com/google-announces-deal-to-show-more-reddit-content/509132/?ref=wheresyoured.at)，使其能够在搜索中原生显示Reddit帖子（并直接访问Reddit帖子数据用于训练目的）。但在某些时候，这些门户将根据它们拥有的数据（或者像Tumblr和Wordpress的情况中，[出售用户数据以训练AI工具](https://www.404media.co/tumblr-and-wordpress-to-sell-users-data-to-train-ai-tools/?ref=wheresyoured.at)）生成答案，而不是将您引导到其他人创造的信息来源。可能会有未来，大多数网民通过一系列门户体验网络，[例如Arc Search的“为我浏览”功能，该功能代表您访问网站并使用AI总结其信息](https://www.theverge.com/2024/1/28/24053882/arc-search-browser-web-app-ios?ref=wheresyoured.at)。

现在，互联网受到少数几个不同平台的控制，每个平台都致力于打断曾经使网络伟大的探索和创造力量。我相信，它们的目标是侵犯我们浏览互联网的能力，进一步混淆信息来源，同时向平台支付用户免费制造的内容。在我看来，它们的最终目标是尽可能地减少与更大互联网的互动，总结和复述尽可能多的内容，以便尽可能地控制和商业化结果。

在某种程度上，我担心当前的平台意图利用AI变成类似于互联网服务提供商，提供对已经因这些平台行动而变得混乱和不可靠的网络的“清洁”访问，最终找到将你的信息显著性商业化的方式，包括它们的门户网站、模型和聊天机器人。随着这一情况的发生，它将开始腐蚀互联网的其他部分，剥夺媒体实体和社交网络的流量，就像史蒂夫·哈夫曼这样的高管进一步达成协议，通过平台来商业化自由劳动，这些平台将尽其所能将所有互联网流量集中到两到三个网站上。

随着互联网被这些集中平台和它们为内容而搜寻的网站所主导，Habsburg AI的恶性循环开始了。OpenAI的ChatGPT和Anthropic的Claude依赖于持续的训练数据流以改进它们的模型，甚至到了[事实上不可能在不侵犯版权的情况下运作](https://www.theguardian.com/technology/2024/jan/08/ai-tools-chatgpt-copyrighted-material-openai?ref=wheresyoured.at)的地步。因此，当它们选择信息时，它们不能太挑剔，这意味着它们很可能依赖于互联网上公开可用的内容，正如我之前所暗示的那样，这将越来越受算法的需求和自动化生产满足它们的通用内容的影响。

我并不是说用户生成的内容会*消失*，而是人类无法像自动化那样大规模创建内容，当[互联网的大部分内容都是给机器人的内容](https://www.theverge.com/23753963/google-seo-shopify-small-business-ai?ref=wheresyoured.at)时，*那*将成为明天模型的内容。真正能让它们变得更好的唯一事物就是*更多的东西*，但是当被创建的大多数东西不好、无趣，甚至不是为人类写的时，ChatGPT或Claude的模型将学习到腐烂内容的腐烂习惯。这就是为什么这么多模型的回应听起来如此相似——它们在很大程度上依赖于它们所输入的东西，因此它们的“智能”大部分来自相同的训练数据。

这是同一个问题的不同表现方式——这些模型实际上并不“知道”任何东西。它们只是在抄袭别人的作业。

> 顺便说一句，我也担心像GitHub Co-pilot这样的生成AI产品创建的软件代码。[安全公司Snyk的一项研究](https://www.infoworld.com/article/3713141/github-copilot-makes-insecure-code-even-less-secure-snyk-says.html?ref=wheresyoured.at)发现，GitHub Copilot和其他基于AI的编码平台是通过公开可用的代码进行训练的（并基于用户自己的代码库），可能复制现有的安全问题，从而扩散问题而非修复它们。[纽约大学网络安全中心在2023年的研究中也发现，CoPilot生成的代码存在40%的安全漏洞](https://cyber.nyu.edu/2021/10/15/ccs-researchers-find-github-copilot-generates-vulnerable-code-40-of-the-time/?ref=wheresyoured.at)。

这些也是你将在生成图像和视频中看到的严格限制。虽然互联网是一个可以轻松和廉价地用于训练的内容巨大的洞穴，但视觉媒体需要更复杂的数据，而且明显存在版权问题。ChatGPT的DALL-E（图像）和Sora（视频）产品 [如我所指出的](https://www.wheresyoured.at/sam-altman-fried/)，受到了教授它们的方式以及生成AI本身的限制，这意味着视频可能会继续主导互联网，因为文本内容被AI生成的内容挤出了市场。[这可能是为什么Sam Altman试图声称巨型AI模型不是未来的原因](https://finance.yahoo.com/news/openai-sam-altman-says-giant-164924270.html?ref=wheresyoured.at) — 因为可能没有足够的燃料来进一步发展它们。毕竟，[Altman声称任何一个数据来源“都不能改变OpenAI的局面”](https://cnbc.com/2024/01/18/openai-ceo-on-nyt-lawsuit-ai-models-dont-need-publishers-data-.html?ref=wheresyoured.at)。

无法逃避这一事实，这些饥渴的机器人需要进行法律剽窃，任何数量的版权侵犯都可能极大地减缓它们的进展。[让模型忘记信息是极其困难的](https://www.axios.com/2024/01/12/ai-forget-unlearn-data-privacy?ref=wheresyoured.at)，这意味着如果数据集必须回到删除版权材料的早期版本，模型的发展可能会出现*倒退*。

[众多](https://www.vox.com/technology/2024/1/18/24041598/openai-new-york-times-copyright-lawsuit-napster-google-sony?ref=wheresyoured.at) [诉讼](https://www.nytimes.com/2024/02/28/technology/openai-copyright-suit-media.html?ref=wheresyoured.at) [针对](https://www.cnbc.com/2024/01/05/microsoft-openai-sued-over-copyright-infringement-by-authors.html?ref=wheresyoured.at) OpenAI 可能会摧毁该公司，虽然Altman和其他AI幻想家可能会假装这些模型是社会未来不可改变的道路，但任何控制（或让他们为此付费的）数据的力量都将削弱这家公司，并迫使他们找出一种道德方式来运作。

然而，我担心的世界是这些人被允许肆意妄为的世界，将独特内容转化为一个丑陋、近亲繁殖的网络怪物的食物，这个网络将每个人的信息源都变成了半个性化版本的相同内容。这些人有名字 —— OpenAI 的 Sam Altman，Google 的 Sundar Pichai，Meta 的 Mark Zuckerberg（其公司有自己的模型称为LLaMA），Anthropic 的 Dario Amodei，以及 Microsoft 的 Satya Nadella —— 他们负责试图标准化互联网，并将其变成通向同一地方的一系列收费高速公路。

他们将乐意误导和使数十亿人陷入不利境地。他们的未来将变得缺乏色彩、缺乏激情，迎合特权阶层并抑制创造力。那些依赖生成式AI进行创作的人与委托画像的人一样，并不是真正的创作者。Altman及其同类认为自己是新的列奥纳多·达·芬奇，但他们仅仅是企图窃取世界魔力的小人物和寻租者。

然而，我们可以抗争。不要相信他们的谎言。生成式AI可能深深植根于高幻想的语言之中，但它只是一个工具，他们不会承认这是一种极其有缺陷且无利可图的方式，用来满足以增长为一切代价的科技引擎。质疑他们所说的一切。不要接受AI "可能有一天" 会变得伟大的说法。要求它今天就应该完美无缺，并且拒绝接受那些以数十亿美元售卖一堆半成品给你的人们的任何不完美之处。拒绝他们的营销说辞和空洞的幻想，并审视他们摆在你面前的工具，在他们试图告诉你平庸是未来时，成为他们的眼中钉。

你并不愚蠢。你没有"错过任何东西"。这些工具不是魔法 —— 它们只是自动补全的幻想版本，它们无法避免从其他人窃取的千兆字节信息中学到的同样错误。
