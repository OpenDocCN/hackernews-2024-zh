<!--yml

类别：未分类

日期：2024-05-27 15:04:35

-->

# 我们已经达到了AI的巅峰吗？

> 来源：[https://www.wheresyoured.at/peakai/](https://www.wheresyoured.at/peakai/)

上周，[《华尔街日报》刊登了一场时长10分钟的采访，主角是OpenAI的首席技术官米拉·穆拉蒂](https://www.youtube.com/watch?v=mAUpxN-EIgU&ref=wheresyoured.at)，记者乔安娜·斯特恩提出了一系列深思熟虑但又直截了当的问题，穆拉蒂未能令人满意地回答。当被问及训练OpenAI视频生成应用Sora所使用的数据时，[穆拉蒂声称使用了公开可用的数据](https://youtu.be/mAUpxN-EIgU?t=263&ref=wheresyoured.at)，而当[斯特恩问她是否使用了YouTube上的视频时](https://youtu.be/mAUpxN-EIgU?t=272&ref=wheresyoured.at)，[穆拉蒂的脸上露出了一种混合着困惑和痛苦的表情](https://twitter.com/edzitron/status/1768367582137249844/photo/1?ref=wheresyoured.at)，然后她说她“其实不太确定”。[当斯特恩第三次追问时](https://youtu.be/mAUpxN-EIgU?t=278&ref=wheresyoured.at)，询问是否使用了来自Facebook或Instagram的视频时，穆拉蒂摇了摇头，说如果视频是“公开可用的……可以使用，也许有这些数据，我不确定，我对此不太有信心。”

斯特恩做得很好，迫使穆拉蒂回答问题，但令人深感担忧的是，这个全球最“重要”的AI公司的首席技术官竟然无法回答一个关于训练数据的非常基础的问题。[即使被问及是否使用Shutterstock的数据进行训练](https://youtu.be/mAUpxN-EIgU?t=297&ref=wheresyoured.at)，这是OpenAI与之合作的公司，穆拉蒂结结巴巴地摇头说，她不会“详细讨论使用的数据，但这些数据是公开可用的**或者**有许可的”（我加粗了重点）。采访后不久，斯特恩补充说，OpenAI分享了Shutterstock的数据被用于训练Sora的模型。

> **旁注：** 斯特恩在这次采访中做的一件非常有用的事情是[详细解释了*Sora如何运作*](https://youtu.be/mAUpxN-EIgU?t=81&ref=wheresyoured.at)，为大众定义了这个“AI模型分析大量视频并学习识别物体和动作”。这看起来可能是一个小小的举动，但报道生成AI的一个问题是不愿意清楚地描述这些东西是如何运作的，而是将其行为描述为在一个大型、可怕的计算机上完成的某种神秘过程。

这次采访因几个原因而重要，但让我们从最明显的地方开始：OpenAI的首席技术官要么不能要么不愿意解释其视频生成生成AI是在什么材料上进行训练的。在整个采访中，她似乎迷失、不安，无法提供关于她正在工作的产品的许多具体细节，描述一切都在“很快”和“最终”的最广泛的术语中。如果不是这次采访围绕训练数据展开了如此有用的对话，Murati将对世界讲得很少。尽管Murati的含糊可能是公共关系和法律顾问的要求，但我实际上认为更可能的是她实时意识到她要么不知道这些答案，要么真相远比世界想象的要平淡（或令人不安）。

当被问及是否可能在生成Sora视频后修复它们时，Murati说“最终”，然后解释说“我们正试图弄清楚……如何将这项技术用作人们可以编辑和创造的工具。”她承诺最终会有“更多的控制、准确性……和反映你想要的意图。”

你最终可以将音频添加到Sora视频中，并且当被问及Sora的生成视频何时会向公众开放时，她再次说“最终”，并在推动时表示Sora的发布“肯定会在今年，但可能还要几个月”。

Murati生活在“最终”的世界中，没有提供技术见解，没有具体细节，也没有很多细节。

这些是只有最受欢迎的科技公司才会进行的访谈——相对表面的来回对话，似乎没有人能够说“嘿，那实际上是什么意思？”Murati在回答有关其技术背后的具体问题时毫无准备，似乎每当她需要扩展超出最一般化的谈论时都感到不安。

尽管我通常喜欢Stern如何处理这次采访，但当她未能反驳[Murati的说法](https://youtu.be/mAUpxN-EIgU?t=504&ref=wheresyoured.at)，即她将Sora视为“扩展创造力的工具，并且OpenAI希望“电影行业的人士以及各地的创作者参与”OpenAI如何开发和部署Sora时，我感到非常沮丧。这正是你应该说“这到底是什么意思？”和“在过去，当涉及图像生成时，你是如何做到的？”

当然，答案是 OpenAI 对与任何电影行业或任何创作者进行交流毫无兴趣，穆拉提因此提出这种建议本该受到口头上的严厉斥责。[虽然 OpenAI 已经为社区专家这类岗位招聘广告](https://qz.com/is-openai-extending-an-olive-branch-to-creators-and-wri-1851156896?ref=wheresyoured.at)，但我几乎看不到 OpenAI 有任何帮助创作者的计划，除了试图说服他们使用其工具。

当然，这一切都是 OpenAI 华丽空洞的套路。[2022 年 10 月的《每日秀》采访中（ChatGPT 发布一个月之前），](https://www.youtube.com/watch?v=Ba_C-C6UwlI&ref=wheresyoured.at) 穆拉提告诉特雷弗·诺亚，OpenAI 视 ChatGPT 和 DALL-E 2 这类工具为 "[扩展我们创造力的延伸](https://youtu.be/Ba_C-C6UwlI?t=121&ref=wheresyoured.at)"，[直接复制粘贴了 OpenAI 在 DALL-E 网站上使用的消息](https://openai.com/blog/dall-e-2-extending-creativity?ref=wheresyoured.at)。穆拉提在七分钟的采访中首次提出了支撑 OpenAI 整个消息战略的谈话要点 —— 虚假信息不好，OpenAI 好，会有一些工作岗位流失，但这是好事，因为这种情况以前也发生过。在 2023 年 7 月接受彭博的艾米丽·张采访时，穆拉提描述她的工作为 "[指导基层团队，思考长期战略，找出我们的不足之处，并确保团队得到良好支持以取得成功](https://youtu.be/p9Q5a1Vn-Hk?t=123&ref=wheresyoured.at)"，并且[她最担心的问题之一是幻觉](https://youtu.be/p9Q5a1Vn-Hk?t=324&ref=wheresyoured.at)（当一个模型权威地说错事情），这个问题张没有追问“所以，您是如何解决这个问题的？”。

[从他被撤销 OpenAI 董事会成员资格之后就变得不那么合理的原因](https://www.semafor.com/article/11/19/2023/reid-hoffman-was-privately-unhappy-about-leaving-openais-board?ref=wheresyoured.at)，张也采访了亿万富翁投资者里德·霍夫曼，他建议[AI 将被"比 iPhone 更快地"采用，并且每个职业将有"一个副驾驶"](https://youtu.be/p9Q5a1Vn-Hk?t=694&ref=wheresyoured.at)。张弱弱地以她的孩子们使用 ChatGPT 写论文为例做了反驳，霍夫曼反驳道他自己的"扩展创造力"版本，表示希望与 AI 的互动将教育学生"创作更有趣的论文"，这时张本该问他“那到底是什么意思”。

While writing this piece, I took the time to watch several more interviews with Murati (and, indeed, OpenAI CEO Sam Altman), and for the most important company in Silicon Valley, there is very little fundamental explanation of why this technology matters, and what it actually does. In an interview with Joanna Stern at the Wall Street Journal's "Tech Live" event in October 2023, Sam Altman said that the thing that people really like about ChatGPT isn't that it "[knows particular knowledge](https://youtu.be/byYlC2cagLw?t=870&ref=wheresyoured.at)," but that it has this "larval reasoning capacity that's going to get better and better," and continues to mumble out an answer about how models will "set up all sorts of economic arrangements" that will have them explain *how* it will answer a question (?), before adding that "the fundamental thing about these models is not that they memorize a lot of data." Stern fails to push back here on numerous fronts — that "larval reasoning" is a completely meaningless term, and that, in general, Altman has failed to actually explain what he means.

This is the problem with powerful people in tech. If you allow them to speak and fill in the gaps for them, they will happily do so. Murati and Altman continuously obfuscate how ChatGPT works, what it can do, what it *could* do, and profit handsomely from a complete lack of pushback from a press that routinely accepts AI executives' vague explanations at face value. OpenAI's messaging and explanations of what its technology can (or will) do have barely changed in the last few years, returning repeatedly to "eventually" and "in the future" and speaking in the vaguest ways about how businesses make money off of — let alone *profit* from — integrating generative AI.

Sam Altman repeatedly given the ability to wax lyrical about the futuristic capabilities of artificial intelligence in a way that lets him paint a picture of a technology he is not actually building. Altman's fanciful claims include his kids "[having more AI friends than human friends](https://www.youtube.com/watch?v=PWBzXe0KAGo&ref=wheresyoured.at)," [that human-level AI is "coming" without ever specifying when](https://www.cnbc.com/2024/01/16/openais-sam-altman-agi-coming-but-is-less-impactful-than-we-think.html?ref=wheresyoured.at), [that AI will replace 95% of tasks performed by marketing agencies](https://www.cmswire.com/digital-marketing/sam-altman-ai-will-replace-95-of-creative-marketing-work/?ref=wheresyoured.at), [that ChatGPT will evolve in "uncomfortable ways,"](https://www.axios.com/2024/01/17/sam-altman-davos-ai-future-interview?ref=wheresyoured.at) [that AI will kill us all](https://www.cnn.com/2023/10/31/tech/sam-altman-ai-risk-taker/index.html?ref=wheresyoured.at), and that human beings are only separated from artificial intelligence because they "[really care what others think](https://futurism.com/altman-stumped-humans-better-ai?ref=wheresyoured.at)."

每次 Sam Altman 发言几乎立即陷入幻想世界，谈论“AI”可能做的一般性事情，以及 ChatGPT 在其中可能或可能不适合的地方，却从未描述过一个真实世界的用例。多年来，他一直以完全相同的方式做到这一点，未能描述任何工业或社会对人工智能的*需求*，只是模糊地承诺自动化和“模型”将能够完成人类可以做的事情，尽管 OpenAI 的模型始终证明自己甚至无法匹敌最愚蠢的活人的智能。

Altman 想要谈论普通人工智能可以取代人类工作的大而性感的故事，因为 OpenAI 的现实 — 以及生成AI的延伸 — 比他想让你知道的要无聊、有限和昂贵得多。

我并不认为情况可能会有所改善。

## **有限的智能**

上周，[The Information 发布了一篇关于亚马逊和谷歌“抑制生成AI期望”的报道](https://www.theinformation.com/articles/generative-ai-providers-quietly-tamp-down-expectations?rc=kz8jh3&ref=wheresyoured.at)，其中提到这些公司正在降低销售人员对其技术能力的兴奋情绪。文章中引述一位科技高管称客户开始遇到诸如“AI是否提供价值？”和“我如何评估AI的表现？”等问题，而一位Gartner分析师告诉亚马逊网络服务销售人员，AI行业正处于“大语言模型和其他生成AI周围的炒作周期的顶峰”。

该文章证实了我对很多怀疑的肯定 — 正如 The Information 所写的那样，“其他软件公司宣称生成AI对企业是一大利好，但仍在等待收入的涌现”，并举例说明专业服务公司毕马威以显著折扣购买了 Microsoft 的共同驾驶AI 的 47,000 个订阅，“这个订阅价格为每个席位每月 $30”，尽管毕马威购买这些订阅并没有衡量其员工实际从软件中获得多少价值，而是为了“熟悉客户可能提出的任何与AI相关的问题”。

Salesforce首席财务官Amy Weaver在其最近的盈利电话会议上表示，在其2025财年指导方针中，“不考虑Salesforce众多AI产品的实质性贡献”。软件公司Adobe的股票因未能从其AI产品中产生有意义的收入而下跌（[链接](https://www.marketwatch.com/story/adobes-stock-slides-toward-worst-day-in-18-months-as-ai-story-will-take-time-270668be?ref=wheresyoured.at)），[分析师对其实际如何赚钱担忧不已](https://www.investors.com/news/technology/adobe-stock-adbe-weak-forecast-ai-software/?ref=wheresyoured.at)。ServiceNow声称其盈利表现中生成AI的贡献是有意义的（[链接](https://siliconangle.com/2024/01/24/servicenow-beats-guidance-metrics-generative-ai-powers-strong-growth/?ref=wheresyoured.at)），然而《The Information》的报道援引其首席财务官Gina Mastantuono的话称“从收入贡献的角度来看，这并不会是很大的”。

我认为人工智能繁荣的很大一部分是热气，通过高管胡扯和愿意写关于*想象*人工智能能做什么的媒体来推动。《华尔街日报》著名的老板倡导者Chip Cutter上周撰写了一篇关于如何在办公室中整合AI的文章（[链接](https://www.wsj.com/tech/ai/office-workers-artificial-intelligence-changes-86d8d4ab?mod=ai_more_article_pos7&ref=wheresyoured.at)），在文章的大部分内容中讨论公司在实验性地使用这些工具，并且他们一直在犯错误。《纽约时报》在与Salesforce的AI负责人Clara Shih的采访中未能让她多谈一些关于其AI产品实际做了什么的内容（[链接](https://www.nytimes.com/2024/03/07/business/clara-shih-salesforce-artificial-intelligence.html?ref=wheresyoured.at)），只谈到了其“爱因斯坦信任层”如何处理数据，Shih补充道AI将“对职位产生变革，就像互联网一样”。

媒体被愚弄了，就像他们被虚拟现实愚弄一样，被AI和支持它的高管们的虚假承诺愚弄了。半真半假的宣传和神奇的想法因AI的实际存在而迅速传播开来，人们更容易想象它可能如何改变我们的生活，即使它可能在不太可能和不可能之间。很容易认为像数据输入或者“无聊”的工作这样的任务可以轻松自动化，当你使用ChatGPT时，你几乎可以有点儿看到它可能会发生的方式，即使ChatGPT实际上无法做到这些事情，仅仅因为ChatGPT在推出时能够做一些看起来几乎有用的事情的印象。

当我们在谈论的时候，基于去年的人工智能繁荣，我们的生活并没有多少实质性的改善。我刚刚删除了一句话，谈到“我认识的使用ChatGPT的人”，意识到在过去的一年里，我只遇到了一个人——一位作家，他用它来找同义词。

我找不到任何一家公司真正通过集成生成式AI而显著改善其底线的例子，除了Klarna，后者声称其AI支持机器人在2024年将带来“4亿美元的利润改善”（https://www.klarna.com/international/press/klarna-ai-assistant-handles-two-thirds-of-customer-service-chats-in-its-first-month/?ref=wheresyoured.at），尽管许多人错误地认为这意味着它已经“让Klarna赚了4000万美元”（https://www.inc.com/ben-sherry/klarna-says-its-new-ai-assistant-is-outperforming-customer-service-representatives.html?ref=wheresyoured.at）。尽管存在相反的担忧，AI似乎并未取代大量工人，[即使有时候](https://www.theverge.com/2020/5/30/21275524/microsoft-news-msn-layoffs-artificial-intelligence-ai-replacements?ref=wheresyoured.at)，[结果也相当糟糕](https://www.cnn.com/2023/11/02/tech/microsoft-ai-news/index.html?ref=wheresyoured.at)。[波士顿咨询集团的一项研究](https://www.bcg.com/publications/2023/how-people-create-and-destroy-value-with-gen-ai?ref=wheresyoured.at)发现，那些“用OpenAI的GPT-4解决业务问题”的顾问的表现比那些没有使用它的顾问要*差23%*，即使事先警告过顾问有关生成式AI的局限性和幻觉风险。

明确地说，我并不主张用AI替代工人。然而，我确实在说，如果AI实际上能够替代人类的产出——即使它只是*接近*这样做——任何数量的大规模、诽谤性的公司都会在规模上这样做，并且会在模型改进时计划做得更多。

当然，*除非根本不可能*。如果今天我们所见到的不是未来的一个片段，而是当下的新常态呢？如果人工智能实际上并没有能力比我们今天所见到的更多，那又该怎么办？如果没有明确的时间表，它什么时候才能做更多呢？整个炒作周期是否都是建立在一个顺从的媒体之上，他们愿意相信职业炫耀者的话？

每当我读到人工智能可以做出“惊人”的事情时，我都会看到有人试图为即将熄灭的火添加燃料。尽管乔安娜·斯特恩可能已经说过，索拉的生成视频片段“让她感到恐惧”，但让人感到恐怖的大部分原因是OpenAI将修复幻觉的假设，而这家公司已经明确未能做到。人工智能的炒作建立在解决越来越糟糕的AI模型问题的基础上，而OpenAI的唯一答案是“我们最终会解决的，请相信我”和“我们需要在[芯片](https://www.wsj.com/tech/ai/sam-altman-seeks-trillions-of-dollars-to-reshape-business-of-chips-and-ai-89ab3db0?ref=wheresyoured.at)和[能源](https://www.popsci.com/technology/sam-altman-age-of-ai-will-require-an-energy-breakthrough/?ref=wheresyoured.at)技术上有所突破。”

生成式AI的核心问题——它的幻觉，其[巨大能耗](https://www.theverge.com/2023/10/10/23911059/ai-climate-impact-google-openai-chatgpt-energy?ref=wheresyoured.at)和[无利可图的计算需求](https://www.washingtonpost.com/technology/2023/06/05/chatgpt-hidden-cost-gpu-compute/?ref=wheresyoured.at)——尚未接近解决。我现在已经阅读和听了很多穆拉蒂和阿尔特曼的访谈，我几乎找不到一个案例，他们在这些问题上甚至被*问到*，更不用说他们提供了一个合理的答案。

我相信这是因为根本就没有一种解决方法。

生成式AI模型在不提供明显、具体的大众市场应用案例的情况下，成本高昂且计算密集。穆拉蒂和阿尔特曼的未来在很大程度上取决于让世界相信，他们的模型能力的发展和改进将继续保持急迫的进展步伐，而这一步伐显然已经放缓，[OpenAI承认GPT-4在某些任务上可能更糟。](https://www.businessinsider.com/openai-gpt4-worse-on-some-tasks-chatgpt-2023-7?ref=wheresyoured.at)

[正如我之前所写的](https://www.wheresyoured.at/sam-altman-fried/)，幻觉不是bug而是一种特性。这些模型并不“知道”任何东西。它们是基于训练数据和标记生成的数学巨人，因此无法“知道”你要求它做什么。你根本无法修复它们。幻觉不会消失。

对这项技术的每一丝激动都建立在它*可能*会做的事情的想法上，这很快就与它*能够*做的事情混为一谈，使得更多是营销人员而不是工程师的奥尔特曼能够基于最不具体的承诺来推销开放AI的梦想，就像马克·扎克伯格曾说过我们会生活在他们的Oculus头盔中一样。

## **奥尔特曼，弗里德**

我相信萨姆·奥尔特曼这段时间以来一直在跳脚舞，希望他能积累足够的权力和收入，以至于他的成功是不可避免的。然而，他极其成功的炒作活动却是深深的虚假，他和整个AI行业都突然发现自己必须提供一个他们甚至都没有接近开发的未来。

我担心的不是自动化夺走我们的工作，而是生成式AI的基础崩溃，因为公司们意识到他们最好能看到的只是少数几位数字的利润增长。像Nvidia、Google、Amazon、Snowflake和Microsoft这样的公司，它们的市值高达数千亿美元，以及预期的收入增长，都与这样一个理念紧密相关：每个人都将把AI整合到一切中，并且他们会比今天做得更*多*。

如果AI泡沫破裂，整个科技行业将遭受重创，因为风险投资家们再次通过追逐一种不盈利、几乎无根据的趋势而被淘汰。再次，整个行业受到影响，因为人们不想建立新事物或尝试新想法，而是愿意资助那些做着类似事情的同类人，因为成为共识的一部分感觉很好，即使你是错误的。直到硅谷再次学会构建真正的东西——人们因为这些东西确实有所作为而使用的东西——它才能在规模上实现创新。

奥尔特曼需要我们构建更高效的芯片和“能源突破”，因为他深知，从本质上讲，生成式AI既无法解决自身的问题，也无法在没有（也许永远也不会有）这样的技术的情况下进一步发展。穆拉蒂在“公开数据”的含糊回答明显表明，OpenAI的模型是在YouTube和Facebook视频上进行训练的，这意味着Sora的任何公开发布都将立即引发一场末日般的法律斗争。多么末日呢？嗯，[上周的一项研究](https://www.cnbc.com/2024/03/06/gpt-4-researchers-tested-leading-ai-models-for-copyright-infringement.html?ref=wheresyoured.at)显示，每个模型都生成了受版权保护的材料，OpenAI的GPT-4在研究构建的44%提示中生成了这些材料，而[Nvidia因作者声称其NeMo语言模型侵犯版权而被起诉](https://www.engadget.com/now-its-nvidia-being-sued-over-ai-copyright-infringement-083407300.html?ref=wheresyoured.at)。

最终，这些公司中的一家将输掉一场版权诉讼，导致所有整合了AI的行业都将面临残酷的使用模型审查。这些模型实际上无法真正"忘记"，可能需要进行昂贵的全行业重新培训和许可协议，[这将使权力集中在那些有能力承担这些成本的大型AI公司手中](https://hunterwalk.com/2024/02/23/every-time-openai-cuts-a-check-for-training-data-an-unlaunched-competitive-startup-dies-without-a-safe-harbor-ai-will-be-ruled-by-incumbents/?ref=wheresyoured.at)。而且，如果Sora和其他视频模型实际上是在YouTube和Instagram上的受版权保护的材料上训练的，从法律上讲，没有办法解决这个问题而不重新启动训练模型。

## 人工炒作

山姆·阿特曼迫切需要你相信生成式AI将是必不可少、不可避免且棘手的，因为如果你不这样做，你会突然意识到数万亿美元的市场资本化和收入正在被浪费在一些相当平庸的东西上。如果你专注于现在——OpenAI的技术今天能做什么，以及在相当长一段时间内可能会做什么——你会清楚地看到，生成式AI并不是一种改变社会的技术，而是另一种效率驱动的云计算软件，主要惠及相对较小的人群。

如果你停止说"AI可以做"或者"AI将会做"这样的话，你就必须开始问AI*能*做什么，答案是……不是很多，未来也不会多。Sora不会生成电影。它将继续制作类似于《星球大战》中AT-AT步行器那样的令人毛骨悚然的人类相似生物，以及看起来非常像YouTube上的受版权保护材料的卡通片。

我相信人工智能有三个季度的时间来证明自己，然后末日将降临，那时情况将更加糟糕，严重影响科技巨头的收入。一旦使用率下降，大科技公司注入的大量收入也将减少，数据中心的面积将无人使用，这相当于疫后硅谷的大规模过度招聘。

我担心的结果可能会比我们在2023年看到的对科技行业的痛苦更严重，其中大部分痛苦会影响到工人，而不是那些吹大这个危险泡沫的鬼怪。
