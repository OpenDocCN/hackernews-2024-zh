<!--yml

category: 未分类

date: 2024-05-27 14:42:54

-->

# What if it isn't happening, AGI is not coming?

> 来源：[https://www.mindprison.cc/p/what-if-agi-is-not-coming](https://www.mindprison.cc/p/what-if-agi-is-not-coming)

***[Notes From the Desk](https://www.mindprison.cc/s/notes-from-the-desk)** 是定期发布的帖子，总结了最近的感兴趣的主题或其他简短的值得注意的评论，这些评论原本可能是推文或便签。*

* * *

不管看起来发生了什么，我们始终要考虑如果事情不是那样。如果大语言模型（LLMs）不能演变成AGI，那么我们对智能的追求是否揭示了我们明显的不足？将数万亿美元转化为能做任何事情的可靠通用生产工具的无法预测幻觉机器？

当涉及到困难问题时，群体几乎总是错误的。大量机构资金涌入AI开发，基于LLM架构将演变出我们称之为AGI的东西，可以解决世界上的所有问题。

那么，有哪些相反的观点呢？

这些是下文详细展开的主要论点：

1.  我们很快将**达到硬件扩展的极限**，以支持更大的AI模型。

1.  几十年来**没有发生过重大的AI技术突破**。我们所看到的一切都是基于更大的计算资源的扩展。

1.  **单靠扩展规模并不能创造通用人工智能（AGI）**，需要其他新颖的发现。

> ChatGPT向公众发布使人们认为生成式人工智能正处于指数改进的起步阶段。
> 
> 然而，生成式人工智能本身在此之前已经存在了一段时间，而**我们所看到的可能是它能达到的最好的水平**。
> 
> 当然，要超越目前的GPT-4需要更多和更多的资源，到了这一步，无论多么庞大的公司都没有动力进一步改进这项技术。
> 
> **在新的突破出现之前，生成式人工智能几乎已经达到了其巅峰**。
> 
> 如果谷歌为了制作一个性能与GPT-4相当的模型而苦苦挣扎，你真的认为生成预训练变换器（GPT）模型还能继续产生更多改进吗？
> 
> 我不这么认为，**这些模型已经太大了**。
> 
> …
> 
> 因此，GPT-4正处于S型曲线的拐点处，由于语言模型，无论是封闭还是开放源代码，**都不是在大幅改进，而是在需求更多和更多的资源**，如计算资源和数据。
> 
> 另见：
> 
> …
> 
> — Chomba Bupe, [X post](https://twitter.com/ChombaBupe/status/1763617694023033226)
> 
> 深度神经网络（DNN）只是一种简单节点的排列 - 从40年代的感知器开始，带有各种非线性，叠加在一起的层。
> 
> AI公司**希望通过大量使用计算资源和数据来扩展这些深度神经网络（DNNs），以解决智能问题**。
> 
> 深度神经网络（DNNs）的基础**在80年代已经奠定**。
> 
> 梯度下降（GD）甚至早于此，随机梯度下降（SGD）是GD的一种变体。对于GD，在采取步骤之前需要通过整个训练集计算梯度。SGD使用一个随机抽取的样本，因此称为随机。批量GD使用大于1的样本但不使用所有样本来计算梯度。
> 
> 有些变体可以帮助更快地收敛到解决方案。**但是并没有太多改变**。
> 
> …
> 
> 因此，如果你仔细观察，除了**仅仅是利用现代硬件将80年代的技术规模化**之外，并没有足够的创新。今天系统的成功更多归因于像GPU、TPU等硬件计算的突破，而非实际的AI算法。
> 
> 这就是为什么你预期AI很快会达到一个平台，因为**这些模型的规模化有其极限**。物理限制将会生效，阻止进一步的规模化。**无论他们投入多少计算资源或数据，它们都无法解决智能**。
> 
> …
> 
> Chomba Bupe，[转帖](https://twitter.com/ChombaBupe/status/1763982592351629767)

Gary Marcus对为什么我们还没有看到GPT5的迹象进行了简短的阐述。这与认为达到了规模化的极限的观点是一致的。

> 这里有一个理论：[为什么OpenAI还没有发布与Gemini和Claude竞争的GPT5]
> 
> • OpenAI已经尝试过[创造GPT5]，但他们所提出的方案并不令人印象深刻，因此他们将其称为GPT 4.5 Turbo。
> 
> • 他们仍在努力，但他们提出的方案都没有达到预期水平。
> 
> • 他们并不确定接下来该做什么。
> 
> • 他们不确定是否没有大量资金，甚至是价值7万亿美元的基础设施就能取得更大的进展。
> 
> • 因此，我们可能还需要等待更长一段时间，甚至可能更久。
> 
> Gary Marcus，[转帖](https://twitter.com/GaryMarcus/status/1765198638182256780)

* * *

这套来自[Maximum Truth](https://www.maximumtruth.org/p/ais-ranked-by-iq-ai-passes-100-iq)的测试展示了衡量LLM智能“智商”所遇到的问题。

新的Claude-3得分为101，迄今为止所有LLM中最高。然而，Claude仍然是一种能力混合体，智商测量并不能告诉我们Claude的表现如何。它依然无法回答基本问题，有幻觉，但同时已经证明能够解决比其他模型更复杂的问题。

Claude-3未能正确回答羽毛和砖头的相对重量：还需要多少十亿美元的计算资源来解决这个问题？

而这里是Claude-3解决新问题的例子：

智商测试并不预测这种预期能力上的分歧，而正是这种分歧导致人们对是否接近AGI或者只是在制造非常昂贵且不可靠的化身犹豫不决。

* * *

在未来十年内，将有数十亿到数万亿美元投入研究。比以往任何时候更多的人类都在寻找突破。我们已经指数级增加了并行的努力。尽管当前的LLM架构可能无法在其当前状态下交付，但它已经点燃了可能找到其他途径的研究的巨大投资。

然而，期望值已经被设置得非常高。人工智能是一种完美技术，目前只是足够好以激发想象力，看似可以触手可及，但实际上可能仍然遥远。这是几乎无限期地接近的问题。尽管当前的LLM在现实中具有实际效用，但承诺远远超过现实，如果不能兑现，将在适当的时机导致市场的显著崩溃。

没有通用人工智能（AGI），我们仍在指数级改进，只是不是在智能垂直方面，而是在发现其使用新应用和方法的水平方面。在训练、数据、推理和应用的精炼方面，一切仍在进步。

如果我们不够聪明以知道什么是智能，那我们到底有多聪明？我们是否足够聪明来建造更多我们不知道是什么的东西？

* * *

*没有希望到达另一边的罗盘也没有意义......*

Mind Prison 是一份由读者支持的出版物。你也可以通过分享来提供帮助。

[分享](https://www.mindprison.cc/p/what-if-agi-is-not-coming?utm_source=substack&utm_medium=email&utm_content=share&action=share)
