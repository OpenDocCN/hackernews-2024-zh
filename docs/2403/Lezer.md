<!--yml

category: 未分类

date: 2024-05-29 12:37:49

-->

# Lezer

> 来源：[https://marijnhaverbeke.nl/blog/lezer.html](https://marijnhaverbeke.nl/blog/lezer.html)

我经常遇到一些认为解析技术是一门令人生畏的编程领域的人。这是无稽之谈——一个小小的解析器可以是[非常简单的](http://eloquentjavascript.net/12_language.html#h_cpTTNxAWkQ)，并且可以提供一个很好的递归思维练习。同时，事实上确实可以让解析变得非常复杂。大多数情况下，这种情况发生在你将解析技术泛化到不同语法上时。由于编译器教材通常描述了解析的通用方法，他们可能是为人们对解析感到畏惧负责的原因。

这篇文章描述了我为[CodeMirror](https://codemirror.net)写的一个[新的解析系统](https://lezer.codemirror.net)，它用一些历史背景框定了系统，并深入探讨了一些精彩的架构细节。

编辑器功能，如语法高亮、括号匹配、代码折叠和自动完成，都涉及一定程度的解析。不幸的是，由于编辑器必须处理许多不同的语言，它们需要一种通用的解析方法。

CodeMirror正在被重写，我希望改进它解析内容的方式。在编辑器内部进行解析带来了自己独特的一套约束条件，这些条件很难满足。虽然多年来我一直在计划新的方法，但到目前为止，我所能展示的仅仅是一堆死胡同。

让代码编辑器中的解析问题变得困难的约束条件大致如下：

+   文件在不断变化。

+   你不能做什么昂贵的事情。如果解析过程太耗时，将会导致编辑感觉[迟缓](https://input-delay.glitch.me/)和无响应。

+   输入通常不是最终的、语法正确的形式。但你仍然需要对其进行一些处理——没有人希望在文档中存在语法错误时，大多数功能都无法正常工作的编辑器。

+   你经常希望能够在单个文档中混合多种语言/语法（比如在HTML中嵌入JavaScript和CSS）。

记住这些，让我们来看看我尝试过的方法。

## CodeMirror解析简史

现在的CodeMirror 5系统（基本上从一开始就在使用的系统）是一个[简单的系统](http://marijnhaverbeke.nl/blog/codemirror-mode-system.html)。对于每种语言，你编写一个分词器，将输入分成片段，并为每个片段打上一些语法类别的标签（如`variable`、`keyword`或`number`）。分词器可以是有状态的，这使它们可以偷偷地成为完整的解析器，如果它们愿意的话。

这种状态必须是可复制的，以便编辑器可以策略性地存储前一次运行的标记器状态，并在更改后，恢复到接近该更改的状态，以避免重新对整个文档进行标记化。因为我们通常只对可见视口中的代码感兴趣，所以这意味着重新标记的复杂性受限于更改与视口末端之间的距离。由于大多数更改发生在该视口内部，这在实践中效果很好。

* * *

这样的标记器直接编写起来很麻烦，因此多年来已经有几次尝试建立对它们的抽象。第一次尝试是由Mozilla Skywriter的作者（之前称为Bespin，后来合并为[ACE](https://ace.c9.io/)）提出的[Common JavaScript Syntax Highlighting Specification](https://github.com/mozilla/skywriter/wiki/Common-JavaScript-Syntax-Highlighting-Specification)，旨在定义一个声明性格式，用于描述将标记器作为带有正则表达式的状态机（描述标记）的边。ACE项目最终采用了一种不兼容但相似的格式（与其内部过于交织，不幸地无法在CodeMirror中使用）。我为CodeMirror实现了原始规范，并实现了另一个不兼容的[扩展](http://cm/demo/simplemode.html)，因为基础规范过于局限。仍有一些基于该代码的CodeMirror模式，但并没有真正取得成功。

我认为这样的状态机（以及在桌面编辑器中广泛使用的略有关联的[TextMate grammars](https://macromates.com/manual/en/language_grammars)），从来没有感觉像是一个很好的解决方案，原因是一旦超越了简单的语法（在那里它们的声明简单确实看起来很好），它们在抽象方面并没有真正帮助。手动设计复杂的状态机是一项苦差事。正则表达式本身已经很糟糕，当你不得不将所有边都构建成它们时，它们变得十分可怕，经常将多个标记塞入单个表达式中，以避免创建中间状态。这种“抽象”倾向于产生比将标记器编写为纯代码时更丑陋、难以维护的代码。

* * *

因此，2017年，我开始了一个雄心勃勃的项目，创建一种更好的抽象定义增量标记器的方法。我得出结论，基于上下文无关文法的经典解析器生成器永远不会在这种情况下起作用（我稍后会回到原因）。但我一直在接触到[parsing expression grammars](https://en.wikipedia.org/wiki/Parsing_expression_grammar)，它们不基于上下文无关文法，并且具有一些有趣的属性，例如能够组合多个语法以创建新的语法（对于混合语言文档非常有用）。

因此，我花了几个月的时间构建一个解析系统，它采用类似 PEG 的语法，将其编译为状态机，并使其能够作为 CodeMirror 语言模式运行。

这个 [系统](https://github.com/codemirror/grammar-mode) 是一种奇迹。它使用了一种相当复杂的 [优化编译器](https://www.youtube.com/watch?v=1qIee0aHOhY) 来生成状态机。结果运行相当顺利，并且今天在几个实际系统中使用。但不幸的是，如果我真诚地说，这是一个可悲地走得太远的坏主意。

解析表达式语法通过回溯进行解析。因此，它们非常不适合实现具有状态的标记器。在回溯系统中，您永远不知道何时*绝对*解析了一段内容——后续的输入可能要求您再次回溯。因此，我最终得到的实际上根本不是 PEG，而是一种需要显式注释解析器应该向前查看的系统。尽管以这种方式编写的语法相对可读，但它们涉及大量琐碎、容易出错的修补程序以解决局部歧义。

此外，解析 PEG 实际上非常低效。这样的语法是“无扫描器”的，意味着它们不区分标记和解析。在这种天真的解析方式中，您基本上必须为每个输入字符运行整个解析逻辑。由于回溯，可能要多次运行。编译器中的许多魔法旨在恢复语法中隐含的标记，以提高一些效率。但从速度上讲，该系统从未接近手写语言模式。

## Tree-sitter

所以，尽管我知道我需要一个新的方法，但在 CodeMirror 6 重写中，我没有任何具体的想法会是什么样子。

然后我发现了 [tree-sitter](http://tree-sitter.github.io/tree-sitter/)，并得到了启发。

Tree-sitter 是一种专为代码编辑器设计的解析器系统，正在被集成到 [Atom 编辑器](https://atom.io/) 中。它对编辑器内的解析器应该做的事情采取了更加雄心勃勃的方法：为内容构建完整准确的语法树。

用实际的语法树比用一系列标记能做的事情多得多。而标记，可能还加上一些存储在标记器状态中的信息，允许您大致理解代码结构的某些方面，而树通常会精确地给出您需要的信息。

Tree-sitter 使用的大多数想法并不新鲜，实际上，[2000 年的一篇论文](https://www.researchgate.net/profile/SL_Graham/publication/2377179_Efficient_and_Flexible_Incremental_Parsing/links/004635294e13f23ef1000000/Efficient-and-Flexible-Incremental-Parsing.pdf) 描述了一个类似的系统。但据我所知，tree-sitter 是第一个将它们集成到一个实用软件中的系统。

不幸的是，tree-sitter是用C编写的，在浏览器中运行起来仍然很笨拙（而CodeMirror针对非WASM浏览器）。它还生成非常庞大的语法文件，因为它以一种不同于Web系统的方式进行大小/速度权衡。

但好的想法可以移植。[Lezer](https://lezer.codemirror.net)是一个受树-sitter启发的基于JavaScript的系统。

## LR解析与无上下文语法

长时间以来，我坚信基于无上下文语法和[LL](https://en.wikipedia.org/wiki/LL_parser)或[LR](https://en.wikipedia.org/wiki/LR_parser)解析算法的经典解析器系统对编辑器用例并不适用。我之前的论点是...

*无上下文语法是一种有限制的抽象，只要语言做一些奇怪的事情，它就会崩溃。需要语法是LR或LL以满足解析器生成器的需求，会进一步将你钉在角落里。*

这并不是错的。在纯无上下文语法中表达操作符优先级需要为每个优先级级别编写一个愚蠢的公式规则。当你需要实现类似于自动分号插入或对空格敏感的功能时，在手写语法中可能只需要几行代码，但在这里无法直接表达，必须以某种方式逃脱无上下文抽象。

使这样的语法适合LR解析器生成器甚至更加棘手，通常需要你对解析器生成器的工作原理有相当深入的理解。

但就像很多事情一样，一旦你了解它们，它们并不那么糟糕。解析器生成器可以支持优先级声明，这使得操作符解析不再那么可怕。它们甚至可以输出不错的错误信息。

通过像[GLR解析](https://en.wikipedia.org/wiki/GLR_parser)这样的动态解决歧义的支持，可以提供传统上解析器生成器处理不好的情况的实际解决方案。

与我之前提到的一些抽象相反，这个实际上确实给了我们一些东西。与适当的解析器生成器结合使用时，无上下文语法确实可以从可读性强、紧凑的语法声明中快速生成解析器。

*令人困扰的是，分词器和解析器之间的严格分离。*

在许多语言中（比如JavaScript在正则表达式和除号运算符之间的模糊性）。它还倾向于使混合语言解析更加困难。

但仅仅因为这种类型的解析器传统上与完全独立的分词器一起运行并不意味着它必须这样。让解析状态驱动分词器在很大程度上并不成问题。你甚至可以让解析器生成器[自动设置](#contextual-tokens)，无需用户参与。

*生成的解析器太大了。*

一个天真生成的LR解析器是*庞大*的，许多工具生成的文件令人尴尬地大。但通过精心的解析器状态去重和表压缩，可以使这样的解析器几乎与手写的解析器一样紧凑。

*使这样的解析器具有误差容忍性非常麻烦*。

如果你在学术文献中搜索LR解析器系统的错误容忍方法，你会得到大量结果，有许多不同的方法，但没有一个是非常实用的。大多数方法要求语法编写者显式地使用错误恢复策略注释语法，这使得语法变得臃肿，并将正确性的责任放在每个语法作者身上。

Tree-sitter巧妙地滥用[GLR解析](https://en.wikipedia.org/wiki/GLR_parser)，其中解析器可以同时尝试多个解释，以集成自动错误修正而不需要额外的复杂性。Lezer复制了[这种方法](#error-recovery)。

## Lezer

我将我的树坐者克隆项目命名为[Lezer](https://lezer.codemirror.net)，这是荷兰语中的*阅读者*（而且发音很像*laser*）。在某些方面，它比tree-sitter不那么先进，在其他方面则更为先进，并且在很多点上完全不同，这些差异源于不同的优先级和口味设定。

CodeMirror 6将保留运行经典的有状态分词器的能力，但定义语言模式的推荐方式是编写一个Lezer语法，并将其包装在添加了一些编辑器相关元数据的CodeMirror特定包中。

Lezer是一个[LR](https://en.wikipedia.org/wiki/LR_parser)（具有选择性使用[GLR](https://en.wikipedia.org/wiki/GLR_parser)）解析器生成器。它支持增量解析，您可以便宜地在局部更改后重新解析文档，方法是重复使用旧解析树的部分。当解析器遇到语法错误时，它会自动尝试恢复并继续解析，并在输出树中留下标记，指示恢复发生的位置。

Lezer包括一个离线解析器生成工具，它接受语法描述并输出包含该语法解析器的JavaScript模块，以及一个解析器运行时系统（依赖于这些输出文件），用于实际解析。编辑器只需加载运行时系统和生成的解析器。

解析器输出非抽象语法树，意味着它只创建一个原始树结构，其中包含它解析的构造（以及它们的位置信息），而不是将它们组织成一个干净、易于使用的数据结构。

该系统针对紧凑性进行了优化，无论是解析表大小还是语法树大小。必须可以将一堆解析器实际传送到Web用户，而不会产生大量网络流量，并且可以保持大型文档的语法树在内存中而不会耗尽内存。

[Lezer指南](https://lezer.codemirror.net/docs/guide/)提供了更全面的介绍，以及其语法符号的描述。在本博客文章中，我想深入介绍一些在用户文档中不相关的精彩实现细节。

## 错误恢复

当我理解到它的错误恢复策略时，我确信我绝对需要使用或复制tree-sitter。

假设你达到了一个无法正常进行的点，因为有语法错误。错误之后的输入可能充满了仍然可以解析的有意义结构。我们希望将这些结构放入我们的语法树中。但是我们的常规解析过程卡住了——它不知道如何从错误中恢复到可以继续解析的状态。

我绝对不想要求语法作者在他们的语法中添加错误恢复提示。这些倾向于混乱语法并且很容易写错。编写语法已经很难了，不需要这样的干扰。

您可以将错误恢复视为一个搜索问题。可能存在一个解析状态和输入位置（超出错误）可以有意义地继续解析。我们只需找到它。

解析表中编码的动作，以及解析器通常不会采取的一些特定恢复动作，提供了一种搜索树。您从错误发生的状态开始，并从那里继续探索新的状态。

但是接受条件是什么样子呢？您如何知道已经找到了可接受的解决方案？您可以精确定义它，例如作为可以处理下N个标记而不再出现错误的状态。但我们也可以模棱两可地定义。

在tree-sitter中，[Max Brunsfeld](https://github.com/maxbrunsfeld)发现的解决方案是使用解析模棱两可语法所使用的相同机制。GLR解析器可以将其解析栈分割并在一段时间内并行运行两侧，直到清楚哪一侧有效。

这几乎正是搜索算法所做的——它跟踪它仍然必须探索的一些分支，并继续探索它们，可能使用一些启发式方法修剪不太有希望的分支，直到找到解决方案。

为了能够在混乱的情况下，如较长的无效输入串中获得良好或至少*一些*结果，每个分支都与一个坏度分数相关联，每次采取恢复操作时线性增加，并在能够正常消耗一个标记时渐近减少。

我们想要做的是，在出现错误后，尝试所有可能的恢复技巧，这些技巧会递归地分支出大量的状态。但是，在进行了一段时间之后，我们应该再次合并到一个或者最多几个解析状态，因为以多种方式解析输入是昂贵的。

为了达到这种效果，Lezer禁止具有比最佳状态的坏度的给定倍数更高（或某个最大阈值）的状态继续应用恢复动作，从而有效地丢弃那些无法正常进行的分支。在一个分支找到继续的良好方法的情况下，该分支的坏度将会收敛到零，并最终停止所有更糟糕的分支。在输入继续毫无意义的情况下，所有分支最终将获得超过最大值的坏度分数，解析器将仅继续其中一个。

使用的恢复策略包括：

+   跳过下一个令牌，然后在此之后再试一次。

+   发明一个令牌——使用此状态中有效的任何令牌，并继续到将消耗它们的状态。这是分支的主要来源，因为许多状态允许许多令牌。

+   强制结束当前正在解析的最内部产生式。

有些情况下，这种方法的结果并非完全理想，但通常表现良好。重要的是它始终保持解析，并以一种保持可控的方式进行（指数搜索迅速减弱）。系统有点倾向于跳过令牌规则，因此如果一切都失败了，它将继续跳过令牌，直到碰巧遇到可以继续解析的情况。

## 后序解析器输出

当您有一个可能多次分割其状态并多次构建树的解析器时，这种重复的树构建及其所涉及的簿记工作可能会导致大量不必要的工作。

LR解析器创建节点的顺序是从内向外。例如，它首先创建操作数节点，然后稍后创建操作符表达式节点。这提出了一种方法：如果不立即构建树结构，而是让解析器仅保持所创建的节点的平面日志，那么这可以是一个数组，在其中节点按[后序顺序](https://en.wikipedia.org/wiki/Tree_traversal#Post-order_(LRN))排列，子节点在父节点之前。

解析器只是将内容附加到此数组中。在分割状态时，一个状态保留现有的数组，另一个状态获得一个新的空数组，以及指向具有其余数组的状态的指针，以及分割时数组的长度。

现在分割根本不涉及任何节点复制。您确实需要复制状态栈，LR解析器用于跟踪上下文，但通常这是浅层的。

此外，节点分配变得像将几个数字附加到数组一样便宜。对于不产生树节点的操作（Lezer允许您将规则标记为不感兴趣，以保持树的小型化），您根本不必执行任何操作。控制栈在每个规则开始时存储输出数组位置，并可以使用它来发出足够的数据以后重建父子关系。

在成功完成解析之后，最终状态的父数组指针可以用来找到组成树的所有节点，并根据它们构造出实际的树结构。

当跳过的内容（空格和注释）产生节点时，会出现一个棘手的问题。如果您的代码像这样...

```
if (true) something()
// Comment
otherStatement() 
```

...注释*不应*成为if语句节点的一部分。然而，解析器只有在看到下一条语句后才确定可以完成该节点（可能还有一个`else`语句即将到来）。

在这种情况下，输出数组包含在减少节点的前面立即跳过的节点，解析器必须将它们向前移动，并将节点的末尾*存储在*它们之前。幸运的是，这种情况相对较少发生（除非您添加了空格节点，否则每个具有可能继续的规则的末尾都会发生这种情况）。

## 缓冲树

平面后序树表示法的一个好处是它很紧凑。通常构建的树结构，作为单独分配的节点，会因指针和分配头部的额外开销而增加很多开销。它们还可能具有可怕的局部性，因为谁知道内存分配器会将节点放在彼此多远的地方。

不幸的是，我们不能仅仅使用平面表示法来表示我们的语法树。增量解析器必须能够重复使用其部分，而不是将这些部分复制到不同的缓冲区中。

但是我们*可以*将它用于树的部分。将粗略结构存储为经典树，但较小节点的内容（比如少于几千个字符长）存储为平面数组，可以兼顾两者的优点。由于大多数节点（按数量计算）存在于细微结构中，这样可以节省大量的开销（并有助于提高局部性）。

这意味着我们不能重用小节点。但由于它们的大小有限，重新解析它们涉及的工作量也有限。通过将它们排除在外，增量解析器可以避免为了准备和扫描树结构以重用而进行的大量工作。

一个小节点将其内容存储在16位无符号整数的类型数组中。每个节点使用4个这样的数字（64位），存储类型、开始位置、结束位置和每个节点的子节点计数。与解析器创建的数组相反，这些数组是按[前序](https://en.wikipedia.org/wiki/Tree_traversal#Pre-order_(NLR))排列的，因为这使得前向迭代（比后向迭代更常见）更便宜。子节点计数几乎已经过时（结束位置可以告诉您哪些节点是子节点），但Lezer支持零长度节点，这可能会落在其父节点的末尾，使得它们是否属于它们变得模棱两可。

当然，客户端代码不希望处理这种表示。Lezer提供了一个抽象接口，用于搜索和遍历树结构，隐藏了缓冲结构，使您可以概念化地处理节点的统一树。

与 tree-sitter 类似，Lezer 将语法中重复的结果（由 `*` 和 `+` 操作符生成）存储为平衡的子树。这意味着，除非您的输入是病态的（例如连续一千次应用单个二进制运算符），否则您往往会得到浅层、平衡的语法树，这样的树在搜索时成本低廉且允许有效重用。

## 上下文 token

根据语法的复杂性，LR 解析器生成器为您的语法创建了十几到几千个解析状态。这些状态表示语法位置，比如“在参数列表的开括号后”或“在表达式之后，可能期望一些表达式后缀”。

解析生成器可以找出在给定状态下哪些 token 是有效的。它还可以自动确定作为语法一部分指定的 token 中哪些 token 冲突（匹配相同的输入或彼此的某些前缀）。

冲突 token 的一个著名例子是 JavaScript 中的除法运算符与正则表达式语法。但其他例子还包括关键字也可能出现为属性名称，以及位右移操作符 (`>>`) 与 C++ 中两个闭角括号的冲突。

Lezer 如果 token 在不同的解析状态下出现，就不会抱怨重叠的 token。这种隐含地解决了正则表达式和属性名称的问题，而不需要用户进行任何交互。

当冲突的 token 出现在同一位置时，比如除法操作符和 C 风格的注释，您必须指定一个显式的优先顺序（注释优先），以告诉工具您知道自己在做什么。

上下文的标记化通过称为 token 组的概念来实现。具有与其他 token 冲突的未解决冲突的 token 被分配到一个或多个组中，每个组仅包含非冲突的 token。每个状态被分配一个单一的组（如果它期望冲突的 token 那是一个错误）。分词器传递该组，然后仅返回属于该组或不与任何其他 token 冲突的 token。通过将组成员资格存储在位集中并查看是否使用二进制 *和* 设置了正确的位，这种检查得到了优化。

token 被编译为单个确定性状态机，该状态机在输入字符流上运行。在像正则表达式与除法之间的问题中，您不希望该机器在仅允许除法的情况下通过正则表达式特定的状态，因为那样会很浪费。因此，每个分词器状态还标记有一个位集，告诉您从该状态可达的 token 属于哪些组，并且当遇到一个与解析状态的允许 token 没有重叠的状态时，分词器会停止运行。

## 跳过表达式

几乎所有编程语言都有特殊的语法元素，比如空白和注释，可以出现在任何 token 之间。对大多数语言来说，直接在语法中对其进行编码是极其乏味的。

传统上，标记器在读取下一个标记时会跳过这样的元素。这在大多数情况下效果很好，但在将这些元素包含在解析树中时会显得有些别扭。

Lezer 将跳过的元素视为语法的一部分（尽管以优化的方式以避免增加解析表的大小）。可以跳过不是单个标记的元素（例如实现类似可嵌套注释的内容，或确保您的块注释节点由较小的节点组成，以便可以逐步解析巨大的块注释）。

每个规则或规则组可能有其自己的跳过表达式集，这样您就可以在语法中表达不同的子语言，例如插值字符串的内容，而不允许语言不允许的地方插入空格。

每个解析状态都有一个指向（共享的）跳过动作集的指针，用于跳过标记或开始复合跳过表达式的标记的动作。对于单个标记跳过元素，该动作只告诉解析器跳过标记并保持在相同状态。对于复合元素，则会将处理其余元素的状态推送到控制栈上。

## 树节点标记

Lezer 需要处理的语言类型差异很大，从 JavaScript 到 Haskell 再到 CSS 和 YAML。因此，很难找到一个跨语言的词汇来描述它们的构造。事实上，这似乎需要一个单独的多年项目，并且引入了大量复杂性。

不过，如果解析器输出带有一些信息，而无需知道您正在使用的语言，那将是很好的。

在几次迭代后，我决定采用一种系统，其中节点具有*名称*（仅在语言内有意义），以及*props*，这些是与外部代码定义的标签相关联的值。将语言语法集成到 CodeMirror 中涉及为语言使用的节点类型分配某些 props 的值，例如语法高亮样式信息以及如何进行 [缩进](indent-from-tree.html) 这些节点。

由于语言中节点类型的数量有限，我们可以为每种节点类型分配一个对象以保存这些信息，并且所有该类型的节点都指向同一个对象。

为了允许语法外的代码在不变更全局状态的情况下添加 props，可以通过扩展解析器实例来创建附加 props 的副本，从而输出带有附加 props 的节点。在混合语言树的上下文中，这是特别有用的。

Lezer 支持有限形式的语法嵌套。如果语言 A 可以出现在语言 B 的文档中，并且可以通过扫描特定标记明确找到 A 覆盖的区域的末端，Lezer 可以在解析这样的区域时暂时切换到另一组解析表。

语法树将包含来自两种语法的节点。直接附加到节点的属性使得处理这样的树变得更加容易（而不是使用将节点名称与元数据关联的特定于语言的表格）。
