<!--yml

category: 未分类

date: 2024-05-27 14:43:52

-->

# GPT-4 障碍终于被打破了。

> 来源：[https://simonwillison.net/2024/Mar/8/gpt-4-barrier/](https://simonwillison.net/2024/Mar/8/gpt-4-barrier/)

## GPT-4 障碍终于被打破了。

2024 年 3 月 8 日

四周前，GPT-4 仍然是无可争议的冠军：在每个关键性能基准上保持领先，但更重要的是在“氛围”方面是明显的赢家。几乎所有认真研究大语言模型的人都同意，它是大多数任务的最佳默认模型——并且已经如此超过一年了。

今天这个障碍终于被打破了。我们有四个新模型，所有这些模型都在过去四周内向公众发布，其性能基准接近甚至超过了 GPT-4。而且所有重要的反馈也是积极的！

这些模型来自四个不同的供应商。

+   [谷歌 Gemini 1.5](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/)，2 月 15 日。我在[前几周](https://simonwillison.net/2024/Feb/21/gemini-pro-video/)写过这个：其标志性功能是一个不可思议的一百万个标记的上下文，几乎是 GPT-4 Turbo 长度的 8 倍。它还可以处理视频，方法是将视频每秒拆分成一帧，但你可以在一百万个标记中放入大量帧（每帧 258 个标记）。

+   [Mistral Large](https://mistral.ai/news/mistral-large/)，2 月 26 日。我对 Mistral 有很大的好感，因为他们开放授权的模型异常出色——Mistral 7B 在我的 iPhone 上运行，Mixtral-8x7B 是我在笔记本上成功运行过的最佳模型。Medium 和 Large 是他们两个托管但封闭的模型，虽然 Large 可能并不完全超越 GPT-4，但明显处于同一类别。我迫不及待想看看他们接下来会发布什么。

+   [克劳德 3 音韵](https://www.anthropic.com/news/claude-3-family)，3 月 4 日。这才过去几天，哇，这个的氛围*真的*很强。我认识的那些密切评估大语言模型的人士认为这是首个明显超越 GPT-4 的模型。我已经把它作为默认模型用在了很多事情上，尤其是在代码方面——最近有几次，复杂的 GPT-4 提示在经过 Opus 处理后，曾经导致 JavaScript 错误的问题，结果却给我了一个完美的工作答案（[最近的例子](https://fedi.simonwillison.net/@simon/112057299607427949)）。我还喜欢 Anthropi

+   [Inflection-2.5](https://inflection.ai/inflection-2-5)，3月7日。对我来说，这真是个出乎意料的消息：Inflection 制作了[Pi](https://hello.pi.ai/)，一个以对话为重点的聊天界面，当我第一次尝试它时，感觉有点花哨。然后就在几天前，他们宣布他们全新的2.5模型在基准测试中比GPT-4表现良好，而我最喜欢的[LLM酒侍](https://interconnected.org/home/2023/03/22/tuning)之一Ethan Mollick指出，它[值得更多关注](https://twitter.com/emollick/status/1765801629788647468)。

并非所有这些模型都是明确的GPT-4挑战者，但它们每一个都是有竞争力的。就像我说的，一个月前我们根本没有。

这里有几个令人失望的地方。

首先，这些模型中没有一个是公开授权或提供权重的。我想象它们运行所需的资源会使它们对大多数人来说不实用，但在过去一年中，开放授权模型类别取得了巨大的进步，看到最好的模型仍然严格专有感到遗憾。

除非我漏掉了什么，否则这些模型都没有透明地公开它们的训练数据。这也不足为奇：现在开始起诉使用非许可版权数据进行训练，公众对这些模型建立在不明确伦理基础上的负面情绪继续增长。

对我来说，这仍然令人失望。虽然我很希望看到完全基于公共领域或有许可内容训练的模型，并且感觉我们很快应该能看到一些强有力的例子，但我不清楚是否可能在没有深入非许可内容训练的情况下建立与 GPT-4 竞争的东西。我很乐意在这方面被证明是错的！

在缺少这样的[纯素模型](https://simonwillison.net/2022/Aug/29/stable-diffusion/#ai-vegan)的情况下，我更看重训练透明度，而不是我们今天看到的东西。我经常使用这些模型，了解一个模型的训练方式对于帮助决定一个模型可能适用的问题和任务是一个强有力的因素。缺乏训练透明度让我们都在揣测，分享阴谋论，拼命尝试弄清楚背后的真实动机。
