- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 14:35:39'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 14:35:39'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Large language models can do jaw-dropping things. But nobody knows exactly why.
    | MIT Technology Review
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大语言模型可以做出令人瞠目结舌的事情。但没人确切知道为什么。| MIT Technology Review
- en: 来源：[https://www.technologyreview.com/2024/03/04/1089403/large-language-models-amazing-but-nobody-knows-why/](https://www.technologyreview.com/2024/03/04/1089403/large-language-models-amazing-but-nobody-knows-why/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.technologyreview.com/2024/03/04/1089403/large-language-models-amazing-but-nobody-knows-why/](https://www.technologyreview.com/2024/03/04/1089403/large-language-models-amazing-but-nobody-knows-why/)
- en: “These are exciting times,” says Boaz Barak, a computer scientist at Harvard
    University who is on secondment to [OpenAI’s superalignment team](https://www.technologyreview.com/2023/12/14/1085344/openai-super-alignment-rogue-agi-gpt-4/)
    for a year. “Many people in the field often compare it to physics at the beginning
    of the 20th century. We have a lot of experimental results that we don’t completely
    understand, and often when you do an experiment it surprises you.”
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: “这是令人兴奋的时代，” 哈佛大学计算机科学家 Boaz Barak 说道，他正在[OpenAI 超对齐团队](https://www.technologyreview.com/2023/12/14/1085344/openai-super-alignment-rogue-agi-gpt-4/)实习一年。“该领域的许多人经常将其比作20世纪初的物理学。我们有许多实验结果，我们并不完全理解，而且通常在进行实验时会让人感到惊讶。”
- en: '**Old code, new tricks**'
  id: totrans-split-7
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**旧代码，新技巧**'
- en: Most of the surprises concern the way models can learn to do things that they
    have not been shown how to do. Known as generalization, this is one of the most
    fundamental ideas in machine learning—and its greatest puzzle. Models learn to
    do a task—spot faces, translate sentences, avoid pedestrians—by training with
    a specific set of examples. Yet they can generalize, learning to do that task
    with examples they have not seen before. Somehow, models do not just memorize
    patterns they have seen but come up with rules that let them apply those patterns
    to new cases. And sometimes, as with grokking, generalization happens when we
    don’t expect it to.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数惊喜涉及模型如何学会做它们没有被展示过的事情。被称为泛化，这是机器学习中最基本的理念之一，也是最大的难题之一。模型通过训练特定的示例来学会执行任务——如识别面孔、翻译句子、避开行人等等。然而，它们可以泛化，学会在以前未见过的示例中执行该任务。模型不仅仅是记住它们见过的模式，而是能够制定规则，让它们将这些模式应用到新情况中去。有时，就像领悟一样，泛化发生在我们没有预料到的时候。
- en: Large language models in particular, such as OpenAI’s GPT-4 and Google DeepMind’s
    Gemini, have an astonishing ability to generalize. “The magic is not that the
    model can learn math problems in English and then generalize to new math problems
    in English,” says Barak, “but that the model can learn math problems in English,
    then see some French literature, and from that generalize to solving math problems
    in French. That’s something beyond what statistics can tell you about.”
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是像 OpenAI 的 GPT-4 和 Google DeepMind 的 Gemini 这样的大语言模型，具有惊人的泛化能力。“魔法不在于模型能够学习英语中的数学问题，然后泛化到解决英语中的新数学问题，”
    Barak 说，“而在于模型可以学习英语中的数学问题，然后看到一些法语文学作品，从而泛化到解决法语中的数学问题。这是超出统计学所能告诉你的事情。”
- en: 'When Zhou started studying AI a few years ago, she was struck by the way her
    teachers focused on the how but not the why. “It was like, here is how you train
    these models and then here’s the result,” she says. “But it wasn’t clear why this
    process leads to models that are capable of doing these amazing things.” She wanted
    to know more, but she was told there weren’t good answers: “My assumption was
    that scientists know what they’re doing. Like, they’d get the theories and then
    they’d build the models. That wasn’t the case at all.”'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 几年前，周开始学习人工智能时，她被她的老师们注重“如何”而非“为什么”的方式所震撼。“就像，这是如何训练这些模型，然后这是结果，” 她说。“但是并不清楚为什么这个过程会导致能够做这些惊人事物的模型。”
    她想了解更多，但她被告知没有好的答案：“我的假设是科学家知道他们在做什么。就像，他们会得到理论然后建立模型。但实际情况并非如此。”
- en: The rapid advances in deep learning over the last 10-plus years came more from
    trial and error than from understanding. Researchers copied what worked for others
    and tacked on innovations of their own. There are now many different ingredients
    that can be added to models and a growing cookbook filled with recipes for using
    them. “People try this thing, that thing, all these tricks,” says Belkin. “Some
    are important. Some are probably not.”
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的10多年里，深度学习的快速进展更多来自于试错而非理解。研究人员复制了他人的成功方法，并添加了自己的创新。现在有许多不同的成分可以添加到模型中，并且有一个日益增长的食谱书，充满了使用它们的方法。“人们尝试这个东西，那个东西，所有这些技巧，”
    Belkin 说。“有些很重要，有些可能并不重要。”
- en: '“It works, which is amazing. Our minds are blown by how powerful these things
    are,” he says. And yet for all their success, the recipes are more alchemy than
    chemistry: “We figured out certain incantations at midnight after mixing up some
    ingredients,” he says.'
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: “这个方法很有效，真是令人惊讶。这些东西的强大程度让我们感到震惊，”他说道。然而，尽管它们如此成功，但这些配方更像是炼金术而非化学：“我们在午夜后混合了一些成分后，找到了某些咒语，”他说道。
- en: '**Overfitting**'
  id: totrans-split-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**过拟合**'
- en: The problem is that AI in the era of large language models appears to defy textbook
    statistics. The most powerful models today are vast, with up to a trillion parameters
    (the values in a model that get adjusted during training). But statistics says
    that as models get bigger, they should first improve in performance but then get
    worse. This is because of something called overfitting.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于，在大语言模型时代，人工智能似乎违背了传统的统计学规律。今天最强大的模型非常庞大，具有高达一万亿的参数（在训练过程中调整的模型值）。但统计学告诉我们，随着模型变得更大，它们应该首先在性能上有所改善，然后再恶化。这是因为一种叫做过拟合的问题。
- en: When a model gets trained on a data set, it tries to fit that data to a pattern.
    Picture a bunch of data points plotted on a chart. A pattern that fits the data
    can be represented on that chart as a line running through the points. The process
    of training a model can be thought of as getting it to find a line that fits the
    training data (the dots already on the chart) but also fits new data (new dots).
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个模型在数据集上训练时，它试图将数据拟合成一个模式。想象一下一堆数据点在图表上绘制的情况。一个适合数据的模式可以在图表上表示为一条穿过这些点的线。训练模型的过程可以被认为是让它找到一个既适合训练数据（已经在图表上的点），又适合新数据（新点）的线。
