- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-27 14:34:24'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-27 14:34:24
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Megaparsec tutorial
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Megaparsec 教程
- en: 来源：[https://markkarpov.com/tutorial/megaparsec.html](https://markkarpov.com/tutorial/megaparsec.html)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://markkarpov.com/tutorial/megaparsec.html](https://markkarpov.com/tutorial/megaparsec.html)
- en: Megaparsec tutorial
  id: totrans-split-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Megaparsec 教程
- en: '*Published on February 23, 2019, last updated October 30, 2021*'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*发布于2019年2月23日，最后更新于2021年10月30日*'
- en: '*This is the Megaparsec tutorial which originally was written as a chapter
    for the [Intermediate Haskell](https://intermediatehaskell.com) book. Due to lack
    of progress with the book in the last year, other authors agreed to let me publish
    the text as a standalone tutorial so that people can benefit at least from this
    part of our work.*'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*这是最初作为《Intermediate Haskell》书中的一章写成的Megaparsec教程。由于过去一年该书没有进展，其他作者同意我将这部分文本发布为独立教程，以便人们至少可以从我们的这部分工作中受益。*'
- en: '[Japanese translation](https://haskell.e-bigmoon.com/posts/2019/07-14-megaparsec-tutorial.html),
    [Chinese translation](https://blog.yzyzsun.me/megaparsec/).'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[日语翻译](https://haskell.e-bigmoon.com/posts/2019/07-14-megaparsec-tutorial.html)，[中文翻译](https://blog.yzyzsun.me/megaparsec/)。'
- en: 'The toy parser combinators developed in chapter “An Example: Writing Your Own
    Parser Combinators” are not suitable for real-world use, so let’s continue by
    taking a look at the libraries in the Haskell ecosystem that solve the same problem,
    and note various trade-offs they make:'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在章节“一个例子：编写自己的解析器组合子”中开发的玩具解析器组合子不适合实际使用，所以让我们继续看看Haskell生态系统中解决同一问题的库，并注意它们的各种权衡：
- en: '[`parsec`](https://hackage.haskell.org/package/parsec) has been the “default”
    parsing library in Haskell for a long time. The library is said to be focused
    on quality of error messages. It however does not have good test coverage and
    is currently in maintenance mode.'
  id: totrans-split-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`parsec`](https://hackage.haskell.org/package/parsec) 长期以来一直是Haskell中的“默认”解析库。据说该库专注于错误消息的质量。然而，它没有良好的测试覆盖率，目前处于维护模式。'
- en: '[`attoparsec`](https://hackage.haskell.org/package/attoparsec) is a robust,
    fast parsing library with focus on performance. It is the only library from this
    list that has full support for incremental parsing. Its downsides are poor quality
    of error messages, inability to be used as a monad transformer, and limited set
    of types that can be used as input stream.'
  id: totrans-split-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`attoparsec`](https://hackage.haskell.org/package/attoparsec) 是一个强大且快速的解析库，专注于性能。它是这个列表中唯一支持增量解析的库。其缺点是错误消息质量较差，无法用作单子变换器，并且输入流类型受限。'
- en: '[`trifecta`](https://hackage.haskell.org/package/trifecta) features good error
    messages but is under-documented and hard to figure out. It can parse `String`
    and `ByteString` out-of-the-box, but not `Text`.'
  id: totrans-split-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`trifecta`](https://hackage.haskell.org/package/trifecta) 具有良好的错误消息特性，但文档不足且难以理解。它可以直接解析`String`和`ByteString`，但不能解析`Text`。'
- en: '[`megaparsec`](https://hackage.haskell.org/package/megaparsec) is a fork of
    `parsec` that has been actively developed in the last few years. The current version
    tries to find a nice balance between speed, flexibility, and quality of parse
    errors. As an unofficial successor of `parsec`, it stays conventional and immediately
    familiar for users who have used that library or who have read `parsec` tutorials.'
  id: totrans-split-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`megaparsec`](https://hackage.haskell.org/package/megaparsec) 是`parsec`的一个分支，最近几年一直在积极开发中。当前版本尝试在速度、灵活性和解析错误质量之间找到一个良好的平衡点。作为`parsec`的非官方继承者，它保持传统且对于那些曾经使用过该库或阅读过`parsec`教程的用户来说是立即熟悉的。'
- en: It would be impractical to try to cover all these libraries, and so we will
    focus on `megaparsec`. More precisely, we are going to cover the version 9, which
    by the time this book is published will probably have replaced the older versions
    almost everywhere.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试覆盖所有这些库是不切实际的，因此我们将专注于`megaparsec`。更准确地说，我们将覆盖版本9，在本书出版时，这个版本可能已经几乎在所有地方取代了旧版本。
- en: '`ParsecT` and `Parsec` monads'
  id: totrans-split-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`ParsecT` 和 `Parsec` 单子'
- en: '`ParsecT` is the main parser monad transformer and the central data type in
    `megaparsec`. `ParsecT e s m a` is parametrized like this:'
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: '`ParsecT` 是主要的解析器单子变换器，也是`megaparsec`中的核心数据类型。`ParsecT e s m a` 的参数化如下：'
- en: '`e` is the type of custom component of error messages. If we do not want anything
    custom (and for now we do not), we just use `Void` from the `Data.Void` module.'
  id: totrans-split-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`e` 是自定义错误消息组件的类型。如果我们暂时不需要任何自定义（现在确实不需要），我们只需使用`Data.Void`模块中的`Void`。'
- en: '`s` is the type of input stream. `megaparsec` works out-of-the-box with `String`,
    strict and lazy `Text`, and strict and lazy `ByteString`s. It is also possible
    to work with custom input streams.'
  id: totrans-split-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s` 是输入流的类型。`megaparsec` 可以直接使用 `String`、严格和惰性的 `Text`，以及严格和惰性的 `ByteString`。也可以使用自定义输入流。'
- en: '`m` is the inner monad of the `ParsecT` monad transformer.'
  id: totrans-split-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`m` 是 `ParsecT` 单子变换器的内部单子。'
- en: '`a` is the monadic value, result of parsing.'
  id: totrans-split-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`a` 是解析结果的单子值。'
- en: 'Since most of the time `m` is nothing but `Identity`, the `Parsec` type synonym
    is quite useful:'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大多数情况下 `m` 只是 `Identity`，`Parsec` 类型同义词非常有用：
- en: '[PRE0]'
  id: totrans-split-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`Parsec` is simply the non-transformer version of `ParsecT`.'
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: '`Parsec` 简单地是 `ParsecT` 的非变换器版本。'
- en: We can also draw an analogy between the monad transformers in `megaparsec` and
    MTL monad transformers and classes. Indeed, there is also the `MonadParsec` type
    class which is similar in its purpose to type classes such as `MonadState` and
    `MonadReader`. We will return to `MonadParsec` [later](#the-monadparsec-type-class)
    and discuss it in more details.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以在 `megaparsec` 和 MTL 单子变换器及类之间进行类比。事实上，还有 `MonadParsec` 类型类，其目的类似于 `MonadState`
    和 `MonadReader` 等类型类。我们将稍后回到 `MonadParsec`，在[后文](#the-monadparsec-type-class)中更详细地讨论它。
- en: 'Speaking of type synonyms, the best way to start writing parser with `megaparsec`
    is to define a custom type synonym for your parser. This is a good idea for two
    reasons:'
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 谈到类型同义词，使用 `megaparsec` 开始编写解析器的最佳方法是为您的解析器定义一个自定义类型同义词。有两个原因支持这个想法：
- en: It will be easier to add top level signatures like `Parser Int` where `Parser`
    is your parsing monad. Without the signatures, things like `e` will often be ambiguous—it
    is the flip side of the polymorphic API of the library.
  id: totrans-split-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加顶级签名（如 `Parser Int`）将更容易。在没有签名的情况下，像 `e` 这样的事物通常是模棱两可的——这是库的多态 API 的反面。
- en: Working with concrete types with all type variables fixed helps GHC optimize
    a lot better. GHC cannot do much in terms of optimization if your parsers stay
    polymorphic. Although `megaparsec` API is polymorphic, it is expected that end
    user will stick to a concrete type of parsing monad, so inlining and the fact
    that most functions have their definition dumped into so-called *interface files*
    will allow GHC produce very efficient non-polymorphic code.
  id: totrans-split-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用所有类型变量固定的具体类型可以帮助 GHC 进行更好的优化。如果您的解析器保持多态，GHC 将无法进行太多优化。虽然 `megaparsec` 的
    API 是多态的，但预期最终用户将坚持使用具体类型的解析单子，因此内联和大多数函数将其定义倒入所谓的*接口文件*，使 GHC 能够生成非常有效的非多态代码。
- en: 'Let’s define a type synonym (typically called `Parser`) like this:'
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们定义一个类型同义词（通常称为 `Parser`），如下所示：
- en: '[PRE1]'
  id: totrans-split-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Until we start dealing with custom parsing errors, when you see `Parser` in
    the chapter, assume this type.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始处理自定义解析错误之前，当您在本章中看到 `Parser` 时，请假定这个类型。
- en: Character and binary streams
  id: totrans-split-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 字符和二进制流
- en: 'It has been said that `megaparsec` can work with five types of input stream
    out-of-the-box: `String`, strict and lazy `Text`, and strict and lazy `ByteString`s.
    This is possible because the library makes these types instances of the `Stream`
    type class which abstracts the functionality that every data type should support
    to be used as input to a `megaparsec` parser.'
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: 有人说 `megaparsec` 可以与五种类型的输入流直接配合使用：`String`、严格和惰性的 `Text`，以及严格和惰性的 `ByteString`。这是可能的，因为该库将这些类型作为
    `Stream` 类型类的实例，该类型类抽象了每个数据类型应支持以用作 `megaparsec` 解析器输入的功能。
- en: 'A simplified version of `Stream` could look like this:'
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream` 的简化版本可能如下所示：'
- en: '[PRE2]'
  id: totrans-split-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The real definition of `Stream` has more methods, but knowing about them is
    not necessary for using the library.
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`Stream` 的真正定义有更多方法，但了解它们对使用该库并不是必要的。'
- en: 'Note that the type class has two type functions associated with it:'
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: 注意该类型类有两个与之关联的类型函数：
- en: '`Token s` for stream `s` is the type of single token. Common examples are `Char`
    and `Word8`, although it may be something else for custom streams.'
  id: totrans-split-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于流 `s` 的 `Token s` 是单个令牌的类型。常见的例子有 `Char` 和 `Word8`，尽管对于自定义流可能会有其他类型。
- en: '`Tokens s` for stream `s` is the type of a “chunk” of stream. The concept of
    *chunk* was only introduced for performance reasons. Indeed, it is often possible
    to have a more efficient representation of part of a stream which is isomorphic
    to list of tokens `[Token s]`. For example, input stream of the type `Text` has
    `Tokens s ~ Text`: chunk of `Text` is just `Text`. Although the type equality
    `Tokens s ~ s` often holds, `Tokens s` and `s` may differ for custom streams,
    and thus we separate these types in `megaparsec`.'
  id: totrans-split-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can put all the default input streams into a single table like this:'
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
- en: '| `s` | `Token s` | `Tokens s` |'
  id: totrans-split-41
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-split-42
  prefs: []
  type: TYPE_TB
- en: '| `String` | `Char` | `String` |'
  id: totrans-split-43
  prefs: []
  type: TYPE_TB
- en: '| strict `Text` | `Char` | strict `Text` |'
  id: totrans-split-44
  prefs: []
  type: TYPE_TB
- en: '| lazy `Text` | `Char` | lazy `Text` |'
  id: totrans-split-45
  prefs: []
  type: TYPE_TB
- en: '| strict `ByteString` | `Word8` | strict `ByteString` |'
  id: totrans-split-46
  prefs: []
  type: TYPE_TB
- en: '| lazy `ByteString` | `Word8` | lazy `ByteString` |'
  id: totrans-split-47
  prefs: []
  type: TYPE_TB
- en: It is important to get used to the `Token` and `Tokens` type functions because
    they are ubiquitous in the types of `megaparsec` API.
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
- en: 'You may have noticed that if we group all default input streams by token type,
    we will get two groups:'
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
- en: 'character streams, for which `Token s ~ Char`: `String` and strict/lazy `Text`,'
  id: totrans-split-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'binary streams, for which `Token s ~ Word8`: strict and lazy `ByteString`s.'
  id: totrans-split-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It turns out that with `megaparsec` it is not necessary to code the same parsers
    for every type of input stream (this is the case, for example, with the `attoparsec`
    library), but still we must have different code for different token types:'
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
- en: to get common combinators for character streams, import the `Text.Megaparsec.Char`
    module;
  id: totrans-split-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: to get the same for binary streams, import `Text.Megaparsec.Byte`.
  id: totrans-split-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These modules contain two similar sets of helper parsers such as:'
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | `Text.Megaparsec.Char` | `Text.Megaparsec.Byte` |'
  id: totrans-split-56
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-split-57
  prefs: []
  type: TYPE_TB
- en: '| `newline` | `(MonadParsec e s m, Token s ~ Char) => m (Token s)` | `(MonadParsec
    e s m, Token s ~ Word8) => m (Token s)` |'
  id: totrans-split-58
  prefs: []
  type: TYPE_TB
- en: '| `eol` | `(MonadParsec e s m, Token s ~ Char) => m (Tokens s)` | `(MonadParsec
    e s m, Token s ~ Word8) => m (Tokens s)` |'
  id: totrans-split-59
  prefs: []
  type: TYPE_TB
- en: Let’s introduce a couple of primitives on which the modules are built, so we
    understand the tools we are going to use.
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
- en: 'The first primitive is called `token`, and correspondingly it allows us to
    parse a `Token s`:'
  id: totrans-split-61
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-split-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The first argument of `token` is the matching function for the token to parse.
    If the function returns something in `Just`, that value becomes the result of
    parsing. `Nothing` indicates that the parser does not accept this token and so
    the primitive fails.
  id: totrans-split-63
  prefs: []
  type: TYPE_NORMAL
- en: The second argument is a `Set` (from the `containers` package) that contains
    all expected `ErrorItem`s to be displayed to the user in case of failure. We will
    explore the `ErrorItem` type in details when we will be discussing parse errors.
  id: totrans-split-64
  prefs: []
  type: TYPE_NORMAL
- en: 'To better understand how `token` works, let’s see some definitions from the
    `Text.Megaparsec` module which contains, among other things, some combinators
    that work with all types of input stream. `satisfy` is a fairly common combinator,
    we give it a predicate that returns `True` for tokens we want to match and it
    gives us a parser back:'
  id: totrans-split-65
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-split-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The job of `testToken` is to turn the `f` function which returns `Bool` into
    a function that returns `Maybe (Token s)` that `token` expects. With `satisfy`
    we do not know exact sequence of tokens that we expect to match, thus we pass
    `Set.empty` as the second argument.
  id: totrans-split-67
  prefs: []
  type: TYPE_NORMAL
- en: '`satisfy` should look understandable, let’s see how it works. To play with
    a parser we need a helper function that would run it. For testing in GHCi `megaparsec`
    provides `parseTest`.'
  id: totrans-split-68
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s start GHCi and import some modules:'
  id: totrans-split-69
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-split-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We add the `Parser` type synonym that we will use to resolve ambiguity in the
    type of the parsers:'
  id: totrans-split-71
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-split-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We also need to enable the `OverloadedStrings` language extension so we can
    use string literals as `Text` values:'
  id: totrans-split-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-split-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '*The `:: Parser Char` annotation is necessary because `satisfy` by itself is
    polymorphic, so `parseTest` cannot know what to use in place of `e` and `s` in
    `MonadParsec e s m` (`m` is assumed to be `Identity` with these helpers). If we
    worked with a pre-existing parser which had a type signature, the explicit clarification
    of parser type would be unnecessary.*'
  id: totrans-split-75
  prefs: []
  type: TYPE_NORMAL
- en: 'That seems to work all right. The problem with `satisfy` is that it does not
    say what is expected when it fails, because we cannot analyze the function which
    the caller of `satisfy` provides. There are other combinators that are less general,
    but they can generate more helpful error messages. For example `single` (with
    type-constrained synonyms called `char` in `Text.Megaparsec.Byte` and `Text.Megaparsec.Char`)
    which matches a specific token value:'
  id: totrans-split-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-split-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `Tokens` data type constructor has nothing in common with the type function
    `Tokens` that we have discussed previously. In fact, `Tokens` is one of constructors
    of `ErrorItem` and it is used to specify concrete sequence of tokens we expected
    to match.
  id: totrans-split-78
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-split-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can now define `newline` from the table above:'
  id: totrans-split-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-split-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The second primitive is called `tokens` and it allows us to parse `Tokens s`,
    that is, it can be used to match a fixed chunk of input:'
  id: totrans-split-82
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-split-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'There are also two parsers defined in terms of `tokens`:'
  id: totrans-split-84
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-split-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: They match fixed chunks of input, `chunk` (which has type-constrained synonyms
    called `string` in `Text.Megaparsec.Byte` and `Text.Megaparsec.Char`) case-sensitively,
    while `string'` case-insensitively. For case-insensitive matching the `case-insensitive`
    package is used, thus the `FoldCase` constraint.
  id: totrans-split-86
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try to use the new combinators:'
  id: totrans-split-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-split-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: OK, we can match a single token and a chunk of input. The next step is to learn
    how to combine the building blocks to write more interesting parsers.
  id: totrans-split-89
  prefs: []
  type: TYPE_NORMAL
- en: Monadic and applicative syntax
  id: totrans-split-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The simplest way to combine parsers is to execute them in succession. `ParsecT`
    and `Parsec` are monads, and monadic bind is exactly what we use for sequencing
    our parsers:'
  id: totrans-split-91
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的组合解析器的方式是依次执行它们。`ParsecT` 和 `Parsec` 都是单子，而单子绑定正是我们用来顺序执行解析器的方法：
- en: '[PRE14]'
  id: totrans-split-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can run it to check that everything works as expected:'
  id: totrans-split-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以运行它来检查一切是否按预期工作：
- en: '[PRE15]'
  id: totrans-split-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'An alternative syntax for sequential execution is possible if we remember that
    every monad is also an applicative functor, and so we can use applicative syntax:'
  id: totrans-split-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们记得每个单子也是一个应用函子，那么我们可以使用应用语法来实现一种可能的顺序执行：
- en: '[PRE16]'
  id: totrans-split-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The second version works just like the first. Which style to use is often a
    matter of taste. Monadic style is arguably more verbose and sometimes clearer,
    while applicative style is often more concise. That said, monadic style is of
    course more powerful because monads are more powerful than applicative functors.
  id: totrans-split-97
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个版本的工作方式与第一个版本完全相同。使用哪种风格通常是一种品味问题。单子风格可能更冗长但有时更清晰，而应用风格通常更简洁。话虽如此，单子风格当然更强大，因为单子比应用函子更强大。
- en: Forcing consumption of input with `eof`
  id: totrans-split-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 `eof` 强制消耗输入。
- en: '`Applicative` is often powerful enough to allow doing quite interesting things.
    Equipped with an associative operator which has identity, we get a monoid on applicative
    functors expressed in Haskell via the `Alternative` type class. The [`parser-combinators`](https://hackage.haskell.org/package/parser-combinators)
    package provides quite a few abstract combinators built on the concepts of `Applicative`
    and `Alternative`. The `Text.Megaparsec` module re-exports them from `Control.Applicative.Combinators`.'
  id: totrans-split-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`Applicative` 往往足够强大，可以做一些非常有趣的事情。配备有具有单位元的结合运算符后，我们通过 `Alternative` 类型类在 Haskell
    中得到了应用函子的幺半群。[`parser-combinators`](https://hackage.haskell.org/package/parser-combinators)
    包基于 `Applicative` 和 `Alternative` 的概念提供了相当多的抽象组合子。`Text.Megaparsec` 模块从 `Control.Applicative.Combinators`
    中重新导出它们。'
- en: 'One of the most common combinators is called `many`. It allows us to run a
    given parser *zero* or more times:'
  id: totrans-split-100
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的组合子之一称为 `many`。它允许我们运行给定的解析器*零*次或更多次：
- en: '[PRE17]'
  id: totrans-split-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The second result may be a bit surprising. The parser consumed `a`s that matched,
    but stopped after that. Well, we did not say what we want to do after `many (char
    'a')`!
  id: totrans-split-102
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个结果可能有点令人惊讶。解析器消耗了匹配的 `a`，但之后停止了。好吧，我们并没有说明在 `many (char 'a')` 之后要做什么！
- en: 'Most of the time we want to actually force parser to consume entire input,
    and report parse errors instead of being shy and stopping silently. This is done
    by demanding that we reach the end of input. Happily, although the end of input
    is nothing but a concept, there is a primitive called `eof :: MonadParsec e s
    m => m ()` that does not ever consume anything and only succeeds at the end of
    input. Let’s add it to our parser and try again:'
  id: totrans-split-103
  prefs: []
  type: TYPE_NORMAL
  zh: '大多数情况下，我们实际上希望强制解析器消耗整个输入，并报告解析错误，而不是悄悄地停止。这通过要求达到输入的结尾来完成。幸运的是，虽然输入的结尾只是一个概念，但有一个叫做
    `eof :: MonadParsec e s m => m ()` 的原始操作，它不消耗任何东西，只在输入的结尾成功。让我们把它加入我们的解析器并再试一次：'
- en: '[PRE18]'
  id: totrans-split-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We did not say anything about `b`s in our parser, and they are certainly unexpected.
  id: totrans-split-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的解析器中并未提及 `b`，而它们显然是意料之外的。
- en: Working with alternatives
  id: totrans-split-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用替代方案
- en: 'From now on we will be developing a real, useful parser that can parse URIs
    of the following form:'
  id: totrans-split-107
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，我们将开发一个真正有用的解析器，可以解析以下形式的 URI：
- en: '[PRE19]'
  id: totrans-split-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: We should remember that things in square brackets `[]` are optional, they may
    or may not appear in a valid URI. `[]` may be even nested to express a possibility
    inside another possibility. We will handle all of this [¹](#fn1).
  id: totrans-split-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该记住方括号 `[]` 中的内容是可选的，它们可能出现也可能不出现在有效的 URI 中。`[]` 甚至可以嵌套以表达另一种可能性。我们将处理所有这些
    [¹](#fn1)。
- en: 'Let’s start with `scheme`. We will accept only schemes that are known to us,
    such as: `data`, `file`, `ftp`, `http`, `https`, `irc`, and `mailto`.'
  id: totrans-split-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从 `scheme` 开始。我们只接受我们已知的 scheme，例如：`data`、`file`、`ftp`、`http`、`https`、`irc`
    和 `mailto`。
- en: 'To match a fixed sequence of characters we use `string`. To express a choice,
    we use the `(<|>)` method from the `Alternative` type class. So we can write:'
  id: totrans-split-111
  prefs: []
  type: TYPE_NORMAL
  zh: 要匹配固定的字符序列，我们使用 `string`。要表达选择，我们使用 `Alternative` 类型类中的 `(<|>)` 方法。所以我们可以这样写：
- en: '[PRE20]'
  id: totrans-split-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let’s try it:'
  id: totrans-split-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们试试它：
- en: '[PRE21]'
  id: totrans-split-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Looks good, but the defintion of `pScheme` is a bit repetitive. There is a
    way to write `pScheme` with the `choice` combinator:'
  id: totrans-split-115
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来不错，但 `pScheme` 的定义有点重复。有一种方法可以使用 `choice` 组合子来编写 `pScheme`：
- en: '[PRE22]'
  id: totrans-split-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '*`choice` is just a synonym for `asum`—an operation that folds a list putting
    `(<|>)` between its elements, so the two definitions of `pScheme` are actually
    the same, although the one which uses `choice` may look a bit nicer.*'
  id: totrans-split-117
  prefs: []
  type: TYPE_NORMAL
  zh: '*`choice`只是`asum`的一个同义词——一个将`(<|>)`放在其元素之间折叠列表的操作，因此使用`choice`的这两个`pScheme`定义实际上是相同的，尽管使用`choice`的看起来可能更好一些。*'
- en: 'After the scheme, there should be a colon `:`. Recall that to require something
    to go after something else, we use monadic bind or `do`-notation:'
  id: totrans-split-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在方案之后，应该有一个冒号`:`。请记住，要求在某事物之后还要有另一件事物，我们使用单子绑定或`do`-notation：
- en: '[PRE23]'
  id: totrans-split-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'If we try to run `pUri`, we will see that it requires `:` to follow the scheme
    name now:'
  id: totrans-split-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们尝试运行`pUri`，我们会看到现在它需要跟在方案名称后面的`:`：
- en: '[PRE24]'
  id: totrans-split-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'We are not done with the scheme parsing though. A good Haskell programmer tries
    to define types in such a way so that incorrect data cannot be represented. Not
    every `Text` value is a valid scheme. Let’s define a data type to represent schemes
    and make our `pScheme` parser return value of that type:'
  id: totrans-split-122
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们还没有完成方案解析。一个优秀的 Haskell 程序员会尝试以这样的方式定义类型，以确保不会表示不正确的数据。并非每个`Text`值都是有效的方案。让我们定义一个数据类型来表示方案，并让我们的`pScheme`解析器返回该类型的值：
- en: '[PRE25]'
  id: totrans-split-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '*The `(<$)` operator just puts the value on its left-hand side into a functorial
    context replacing whatever is there at the moment. `a <$ f` is the same as `const
    a <$> f`, but can be more efficient for some functors.*'
  id: totrans-split-124
  prefs: []
  type: TYPE_NORMAL
  zh: '*`(<$)`操作符只是将其左侧的值放入一个函子上下文中，替换当前的任何值。`a <$ f`与`const a <$> f`相同，但对于某些函子可能更有效率。*'
- en: 'Let’s continue playing with our parser:'
  id: totrans-split-125
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续玩耍我们的解析器：
- en: '[PRE26]'
  id: totrans-split-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Hmm, `https` should be a valid scheme. Can you figure out what went wrong?
    The parser tries the alternatives one by one, and `http` matches, so it does not
    go further to try `https`. The solution is to put the `SchemeHttps <$ string "https"`
    line before the `SchemeHttp <$ string "http"` line. Remember: *with alternatives,
    order matters!*'
  id: totrans-split-127
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，`https`应该是一个有效的方案。你能找出问题出在哪吗？解析器逐个尝试备选项，而`http`匹配成功，因此它不再继续尝试`https`。解决方案是在`SchemeHttp
    <$ string "http"`行之前放置`SchemeHttps <$ string "https"`行。记住：*在备选项中，顺序很重要！*
- en: 'Now `pUri` works correctly:'
  id: totrans-split-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在`pUri`正常工作了：
- en: '[PRE27]'
  id: totrans-split-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Controlling backtracking with `try`
  id: totrans-split-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用`try`控制回溯
- en: 'The next part to handle is `[//[user:password@]host[:port]]`—the authority.
    Here we have nested optional parts, let us update the `Uri` type to reflect this:'
  id: totrans-split-131
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来处理的是`//[user:password@]host[:port]`——权威部分。这里我们有嵌套的可选部分，让我们更新`Uri`类型以反映这一点：
- en: '[PRE28]'
  id: totrans-split-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now we need to discuss an important concept called *backtracking*. Backtracking
    is a way to travel back in time “un-consuming” input in the process. This is important
    primarily with branching. Here is an example:'
  id: totrans-split-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要讨论一个重要的概念，叫做*回溯*。回溯是一种在过程中“取消消耗”输入并返回的方式。这在分支中尤为重要。以下是一个例子：
- en: '[PRE29]'
  id: totrans-split-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Looks reasonable, let’s try it:'
  id: totrans-split-135
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来合理，让我们试一试：
- en: '[PRE30]'
  id: totrans-split-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: What happens here is that `char 'a'` part of `foo` (which is tried first) succeeded
    and consumed an `a` from the input stream. `char 'b'` then failed to match against
    `'c'` and so we ended up with this error. An important detail here is that `(<|>)`
    did not even try `bar` because `foo` has consumed some input!
  id: totrans-split-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这里发生的是，`foo`的`char 'a'`部分（首先尝试）成功匹配并从输入流中消耗了`a`。然后`char 'b'`未能匹配`'c'`，所以我们得到了这个错误。这里的一个重要细节是，`(<|>)`甚至没有尝试`bar`，因为`foo`已经消耗了一些输入！
- en: 'This is done for performance reasons and because it would make no sense to
    run `bar` feeding it leftovers of `foo` anyway. `bar` wants to be run from the
    same point in the input stream as `foo`. `megaparsec` does not go back automatically,
    unlike for example `attoparsec` or the toy combinators from the previous chapter,
    so we must use a primitive called `try` to express our wish to backtrack explicitly.
    `try p` makes it so that if `p` fails consuming input, `try p` fails as if no
    input has been consumed (in fact, it backtracks the entire parser state). This
    allows `(<|>)` to try its right-hand alternative:'
  id: totrans-split-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这是出于性能原因并且因为从`foo`的剩余部分运行`bar`是毫无意义的原因。`bar`希望从与`foo`相同的输入流位置运行。与例如`attoparsec`或前一章中的玩具组合子不同，`megaparsec`不会自动回溯，因此我们必须使用一个称为`try`的原语来显式表达我们回溯的意愿。如果`p`在消耗输入后失败，`try
    p`会失败，就好像没有消耗任何输入一样（实际上，它会回溯整个解析器状态）。这允许`(<|>)`尝试其右侧的备用选项：
- en: '[PRE31]'
  id: totrans-split-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-split-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'All primitives that actually consume input (there are also primitives that
    alter behavior of existing parsers, such as `try` itself) are “atomic” in terms
    of input consumption. This means that if they fail, they backtrack automatically,
    so there is no way they can consume some input and then fail halfway through.
    This is why `pScheme` with its list of alternatives works: `string` is defined
    on top of `tokens` and `tokens` is a primitive. We either match the entire string
    with `string` or we fail without consuming input stream at all.'
  id: totrans-split-141
  prefs: []
  type: TYPE_NORMAL
- en: 'Back to parsing URIs, `(<|>)` can be used to build a handy combinator called
    `optional`:'
  id: totrans-split-142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-split-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'If `p` in `optional p` matches, we get its result in `Just`, otherwise `Nothing`
    is returned. Just what we want! There is no need to define `optional`, `Text.Megaparsec`
    re-exports this combinator for us. We can now use it in `pUri`:'
  id: totrans-split-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-split-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '*I took the liberty of accepting any alpha-numeric sequences of characters
    as username and password, and made similarly arbitrary simplifications in the
    format of the host.*'
  id: totrans-split-146
  prefs: []
  type: TYPE_NORMAL
- en: 'Some important points here:'
  id: totrans-split-147
  prefs: []
  type: TYPE_NORMAL
- en: In (1) and (2) we need to wrap the argument of `optional` with `try` because
    it is a composite parser, not a primitive.
  id: totrans-split-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(3) `some` is just like `many`, but demands that its argument parser matches
    at least once: `some p = (:) <$> p <*> many p`.'
  id: totrans-split-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (4) Do not use `try` unless necessary! Here if `char ':'` succeeds (which is
    by itself built on top of `token`, so it does not need a `try`), we know for sure
    that port must follow after it, so we just demand a decimal number with `L.decimal`.
    After matching `:`, we are committed and do not need a way to go back.
  id: totrans-split-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In (5) and (6) we assemble `Authority` and `Uri` values using the `RecordWildCards`
    language extension.
  id: totrans-split-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void :: Functor f => f a -> f ()` is used to explicitly discard the result
    to parsing, without it we would get warnings about unused values from GHC.'
  id: totrans-split-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Play with `pUri` in GHCi and see for yourself that it works:'
  id: totrans-split-153
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-split-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Debugging parsers
  id: totrans-split-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'However, you may find that there is a problem:'
  id: totrans-split-156
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-split-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The parse error could be better! What to do? The easiest way to figure out
    what is going on is to use the built-in `dbg` helper from the `Text.Megaparsec.Debug`
    module:'
  id: totrans-split-158
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-split-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The `VisualStream` type class is defined for input streams that can be printed
    out on the screen in readable form. We will not dwell on it here.
  id: totrans-split-160
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use it in `pUri`:'
  id: totrans-split-161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-split-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Then let’s try running `pUri` on that unfortunate input again:'
  id: totrans-split-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-split-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'We can see what exactly is going on inside `megaparsec` now:'
  id: totrans-split-165
  prefs: []
  type: TYPE_NORMAL
- en: '`scheme` matches successfully.'
  id: totrans-split-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`user` fails: although there is a username in place `mark`, there is no password
    after the column `:` (we demand that the password is not empty here). We fail
    and thanks to `try`, backtrack.'
  id: totrans-split-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`host` starts from the same point as `user` and tries now to interpret input
    as hostname. We can see that it succeeds and returns `mark` as host name.'
  id: totrans-split-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There may be a port number after host, so `port` gets its chance now. It sees
    `:`, but after that there is no integer, so `port` fails as well.
  id: totrans-split-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The whole `auth` parser thus fails (`port` is inside of `auth` and it has failed).
  id: totrans-split-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `auth` parser returns `Nothing` because it could not parse anything. Now
    `eof` demands that we have reached the end of input, but it is not the case, so
    we get the final error message.
  id: totrans-split-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'What to do? This is an example of a situation when using `try` enclosing large
    portions of code may make parse errors worse. Let us take another look at the
    syntax we want to parse:'
  id: totrans-split-172
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-split-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'What are we looking for? Something that would allow us to commit to certain
    branch of parsing. Just like with port where when we see column `:` we are sure
    port number must follow. If you look carefully, you will see that the double slash
    `//` is the sign that we have the authority part in our URI. Since we match `//`
    with an “atomic” parser (`string`), matching on it backtracks automatically, and
    after we have matched `//`, we can be sure to demand the authority part. Let us
    remove the first `try` from `pUri`:'
  id: totrans-split-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-split-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now we get a nicer parse error:'
  id: totrans-split-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-split-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Although it is still a bit misleading, but well, that is a tricky example I
    have picked. Lots of `optional`s.
  id: totrans-split-178
  prefs: []
  type: TYPE_NORMAL
- en: Labeling and hiding things
  id: totrans-split-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes the list of expected items may get rather long. Remember what we get
    when we try to use a non-recognized scheme?
  id: totrans-split-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-split-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '`megaparsec` provides a way to override expected items with something custom,
    typically called a *label*. This is done with the help of the `label` primitive
    (which has a synonym in the form of the `(<?>)` operator):'
  id: totrans-split-182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-split-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-split-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We can go on and add more labels to make errors messages more human-readable:'
  id: totrans-split-185
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-split-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'For example:'
  id: totrans-split-187
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-split-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Another primitive is called `hidden`. If `label` renames things, `hidden` just
    removes them altogether. Compare:'
  id: totrans-split-189
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-split-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '`hidden` is useful when it is desirable to make error messages less noisy.
    For example, when parsing a programming language it is a good idea to drop “expecting
    white space” messages because usually there may be white space after each token
    anyway.'
  id: totrans-split-191
  prefs: []
  type: TYPE_NORMAL
- en: '*EXERCISE: Finishing the `pUri` parser is left as an exercise for the reader,
    now that all the tools that are necessary for this have been explained.*'
  id: totrans-split-192
  prefs: []
  type: TYPE_NORMAL
- en: Running a parser
  id: totrans-split-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We explored in details how to construct parsers, but we haven’t inspected the
    functions that allow us to run them, except for `parseTest`.
  id: totrans-split-194
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditionally, the “default” function to run a parser from your program has
    been `parse`. But `parse` is actually a synonym for `runParser`:'
  id: totrans-split-195
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-split-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The second argument is just a file name which will be included in the generated
    parse errors, `megaparsec` is not going to read anything from that file, because
    the actual input comes as the third argument of the function.
  id: totrans-split-197
  prefs: []
  type: TYPE_NORMAL
- en: '`runParser` allows us to run the `Parsec` monad which, as we already know,
    is the non-transformer version of `ParsecT`:'
  id: totrans-split-198
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-split-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '`runParser` has 3 siblings: `runParser''`, `runParserT`, and `runParserT''`.
    The versions with the `T` suffix run `ParsecT` monad transformer, and the “prime”
    versions take and return parser state. Let’s put all the functions into a table:'
  id: totrans-split-200
  prefs: []
  type: TYPE_NORMAL
- en: '| Arguments | Runs `Parsec` | Runs `ParsecT` |'
  id: totrans-split-201
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-split-202
  prefs: []
  type: TYPE_TB
- en: '| Input and file name | `runParser` | `runParserT` |'
  id: totrans-split-203
  prefs: []
  type: TYPE_TB
- en: '| Custom initial state | `runParser''` | `runParserT''` |'
  id: totrans-split-204
  prefs: []
  type: TYPE_TB
- en: 'Custom initial state may be necessary if you e.g. want to set tab width to
    some non-standard value (the default value is `8`). As an example, here is the
    type signature of `runParser''`:'
  id: totrans-split-205
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-split-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Modifying `State` manually is advanced usage of the library, and we are not
    going to describe it here.
  id: totrans-split-207
  prefs: []
  type: TYPE_NORMAL
- en: If you wonder what is `ParseErrorBundle`, we’ll discuss it in [one of the following
    sections](#parse-errors).
  id: totrans-split-208
  prefs: []
  type: TYPE_NORMAL
- en: The `MonadParsec` type class
  id: totrans-split-209
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All tools in `megaparsec` work with any instance of the `MonadParsec` type class.
    The type class abstracts *primitive combinators*—the elementary building blocks
    of all `megaparsec` parsers, combinators that cannot be expressed via other combinators.
  id: totrans-split-210
  prefs: []
  type: TYPE_NORMAL
- en: 'Having primitive combinators in a type class allows the principal concrete
    monad transformer of `megaparsec` `ParsecT` to be wrapped in the familiar transformers
    of the MTL family achieving different interactions between layers of a monadic
    stack. To better understand the motivation, recall that the order of layers in
    a monadic stack matters. If we combine `ReaderT` and `State` like this:'
  id: totrans-split-211
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-split-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'the outer layer, `ReaderT` cannot inspect the internal structure of the underlying
    `m` layer. The `Monad` instance for `ReaderT` describes the binding strategy:'
  id: totrans-split-213
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-split-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: In fact, the only thing that we know about `m` is that it is an instance of
    `Monad` and so the state of `m` can only be passed to `k` via monadic bind. That
    is what we typically want from `(>>=)` of `ReaderT` anyway.
  id: totrans-split-215
  prefs: []
  type: TYPE_NORMAL
- en: The `(<|>)` method of the `Alternative` type class works differently—it “splits”
    state and the two branches of parsing do not contact anymore, so we get *backtracking
    state* in the sense that if the first branch is discarded changes to its state
    are also discarded and cannot influence the second branch (we “backtrack” the
    state when the first branch fails).
  id: totrans-split-216
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate, let us see the definition of `Alternative` for `ReaderT`:'
  id: totrans-split-217
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-split-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: This all is very nice, because `ReaderT` is a “stateless” monad transformer
    and it is easy to delegate the actual work to the inner monad (the `Alternative`
    instance of `m` comes in handy here) without needing to combine monadic state
    associated with `ReaderT` itself (it has none).
  id: totrans-split-219
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s take a look at `State`. Since `State s a` is just a type synonym
    for `StateT s Identity a`, we should look at the `Alternative` instance for `StateT
    s m` itself:'
  id: totrans-split-220
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-split-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Here we can see the splitting of state `s`, just like we saw sharing of the
    reader context `r`. There is a difference though, because the expressions `m s`
    and `n s` produce stateful results: together with monadic value, they return the
    new state in a tuple. Here we either go with `m s` or with `n s`, naturally achieving
    backtracking.'
  id: totrans-split-222
  prefs: []
  type: TYPE_NORMAL
- en: 'What about `ParsecT`? Let us consider now putting `State` inside `ParsecT`
    like this:'
  id: totrans-split-223
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-split-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '`ParsecT` is more complex than `ReaderT` and its implementation of `(<|>)`
    has to do more:'
  id: totrans-split-225
  prefs: []
  type: TYPE_NORMAL
- en: managing of the state of the parser itself;
  id: totrans-split-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: merging of parse errors (when appropriate), should they happen.
  id: totrans-split-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation of `(<|>)` in `ParsecT`‘s instance of `Alternative` thus cannot
    delegate its work to the `Alternative` instance of the underlying monad `State
    MyState` and so no splitting of `MyState` happens—we have no backtracking.
  id: totrans-split-228
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us demonstrate this with an example:'
  id: totrans-split-229
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-split-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Here is the result of running the program:'
  id: totrans-split-231
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-split-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: With `parser0` we can see that the branch `b` is not tried. With `parser1` however
    it is obvious that the final result—the value returned by `get` —comes from the
    branch `a` even though it fails because of `empty` and it is the branch `b` that
    succeeds (`empty` in the context of parsing means “fail instantly and without
    any information about what has happened”). No backtracking happens.
  id: totrans-split-233
  prefs: []
  type: TYPE_NORMAL
- en: 'What to do if we want backtracking custom state in our parser? We can provide
    that if we allow to wrap `ParsecT` *inside* `StateT`:'
  id: totrans-split-234
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-split-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Now if we use `(<|>)` in `MyStack` the instance used is that of `StateT`:'
  id: totrans-split-236
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-split-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Which gives us backtracking state and then delegates the rest of the work to
    `Alternative` instance of its inner monad—`ParsecT`. This behavior is exactly
    what we want:'
  id: totrans-split-238
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-split-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'The program prints:'
  id: totrans-split-240
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-split-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'To make this approach feasible, `StateT` should support the whole set of primitive
    parsers, so we can work with it just like with `ParsecT`. In other words, it should
    be an instance of `MonadParsec`, just like it is an instance of not only `MonadState`,
    but also e.g. `MonadWriter` if its inner monad is an instance of `MonadWriter`
    (in MTL):'
  id: totrans-split-242
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-split-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Indeed, we can lift primitives from inner instance of `MonadParsec` into `StateT`:'
  id: totrans-split-244
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  id: totrans-split-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '`megaparsec` defines instances of `MonadParsec` for all MTL monad transformers
    so that the user is free to insert the transformers inside of `ParsecT` or wrap
    `ParsecT` in those transformers achieving different kinds of interactions between
    the layers of monadic stack.'
  id: totrans-split-246
  prefs: []
  type: TYPE_NORMAL
- en: Lexing
  id: totrans-split-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Lexing* is the process of transforming the input stream into a stream of tokens:
    integers, keywords, symbols, etc. which are easier to parse than the raw input
    directly, or are expected as input to parsers created with parser generators.
    Lexing can be performed in a separate pass with an external tool such as `alex`,
    but `megaparsec` also provides functions that should simplify writing a lexer
    in a seamless fashion, as part of your parser.'
  id: totrans-split-248
  prefs: []
  type: TYPE_NORMAL
- en: There are two lexer modules `Text.Megaparsec.Char.Lexer` for character streams
    and `Text.Megaparsec.Byte.Lexer` for byte streams. We will be using `Text.Megaparsec.Char.Lexer`
    because we work with a strict `Text` as the input stream, but most functions are
    mirrored in `Text.Megaparsec.Byte.Lexer` as well if you wish to work with `ByteString`s.
  id: totrans-split-249
  prefs: []
  type: TYPE_NORMAL
- en: White space
  id: totrans-split-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first topic we need to cover is dealing with white space. It is helpful
    to consume white space in a consistent manner either before every token or after
    every token. Megaparsec’s lexer modules follow the strategy “assume no white space
    before token and consume all white space after token”.
  id: totrans-split-251
  prefs: []
  type: TYPE_NORMAL
- en: 'To consume white space we need a special parser that we will refer to as *space
    consumer*. The `Text.Megaparsec.Char.Lexer` module provides a helper allowing
    to build a general space consumer:'
  id: totrans-split-252
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  id: totrans-split-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'The documentation for the `space` function is quite comprehensive by itself,
    but let us complement it with an example:'
  id: totrans-split-254
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  id: totrans-split-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Some notes:'
  id: totrans-split-256
  prefs: []
  type: TYPE_NORMAL
- en: The `Text.Megaparsec.Char.Lexer` is intended to be imported qualified because
    it contains names that collide with names from e.g. `Text.Megaparsec.Char`, for
    example `space`.
  id: totrans-split-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first argument of `L.space` should be a parser that is to be used to pick
    up white space. An important detail is that it should not accept empty input because
    then `L.space` would go into an infinite loop. `space1` is a parser from `Text.Megaparsec.Char`
    that meets the requirements perfectly.
  id: totrans-split-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second argument of `L.space` defines how to skip line comments, that is,
    comments that start with a given sequence of tokens and end with the end of line.
    The `skipLineComment` helper allows us to craft an auxiliary parser for line comments
    easily.
  id: totrans-split-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The third argument of `L.space` in turn defines how to pick up block comments:
    everything between starting and ending sequences of tokens. The `skipBlockComment`
    helper allows us to deal with non-nested block comments. If supporting nested
    block comments is desirable, `skipBlockCommentNested` should be used instead.'
  id: totrans-split-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operationally, `L.space` tries all three parsers in turn as many times as it
    can till all of them cannot be applied anymore meaning that we have consumed all
    white space there is. Knowing this, it should make sense that if your grammar
    does not include block or line comments, you can just pass `empty` as the second
    and/or third argument of `L.space`. `empty`, being the identity of `(<|>)`, will
    just cause `L.space` to try the parser for the next white space component—exactly
    what is desirable.
  id: totrans-split-261
  prefs: []
  type: TYPE_NORMAL
- en: 'Having the space consumer `sc`, we can then define various white space-related
    helpers:'
  id: totrans-split-262
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-split-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '`lexeme` is a wrapper for lexemes that picks up all trailing white space using
    the supplied space consumer.'
  id: totrans-split-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`symbol` is a parser that matches given text using `string` internally and
    then similarly picks up all trailing white space.'
  id: totrans-split-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will see how it all works together in a moment, but first we need to introduce
    a couple more helpers from `Text.Megaparsec.Char.Lexer`.
  id: totrans-split-266
  prefs: []
  type: TYPE_NORMAL
- en: Char and string literals
  id: totrans-split-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Parsing character and string literals can be tricky because of various escaping
    rules. To make life easier, `megaparsec` provides the `charLiteral` parser:'
  id: totrans-split-268
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-split-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The job of `charLiteral` is to parse a single character that may be escaped
    according to the syntax for character literals described in the Haskell report.
    Note that it does not parse quotes around the literal though for two reasons:'
  id: totrans-split-270
  prefs: []
  type: TYPE_NORMAL
- en: so the user can control how character literals are quoted,
  id: totrans-split-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: so `charLiteral` can be used to parse string literals as well.
  id: totrans-split-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are some example parsers built on top of `charLiteral`:'
  id: totrans-split-273
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  id: totrans-split-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'To turn `L.charLiteral` into a parser for char literals we only need to add
    the enclosing quotes. Here we follow Haskell syntax and use single quotes. The
    `between` combinator is defined simply as: `between open close p = open *> p <*
    close`.'
  id: totrans-split-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stringLiteral` uses `L.charLiteral` to parse individual characters inside
    a string literal enclosed in double quotes.'
  id: totrans-split-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The second function is also interesting because of its use of the `manyTill`
    combinator:'
  id: totrans-split-277
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  id: totrans-split-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: '`manyTill` tries to apply the `end` parser on every iteration and if it fails,
    it then runs the `p` parser and accumulates results of `p` in a list.'
  id: totrans-split-279
  prefs: []
  type: TYPE_NORMAL
- en: There is also `someTill` for when you want to demand that at least one item
    is present.
  id: totrans-split-280
  prefs: []
  type: TYPE_NORMAL
- en: Numbers
  id: totrans-split-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, a very common need is to parse numbers. For integral numbers, there
    are three helpers that can parse values in decimal, octal, and hexadecimal representations:'
  id: totrans-split-282
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  id: totrans-split-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Using them is easy:'
  id: totrans-split-284
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  id: totrans-split-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: '[PRE73]'
  id: totrans-split-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: '`scientific` accepts integer and fractional grammars, while `float` accepts
    only fractional grammars. `scientific` returns the `Scientific` type from the
    `scientific` package, while `float` is polymorphic in its result type and can
    return any instance of `RealFloat`:'
  id: totrans-split-287
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  id: totrans-split-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'For example:'
  id: totrans-split-289
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  id: totrans-split-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: '[PRE76]'
  id: totrans-split-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'Note that all these parsers do not parse signed numbers. To make a parser for
    signed numbers, we need to wrap an existing parser with the `signed` combinator:'
  id: totrans-split-292
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  id: totrans-split-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: The first argument of `signed`—the space consumer—controls how white space is
    consumed between the sign and actual numeral. If you do not want to allow space
    in there, just pass `return ()` instead.
  id: totrans-split-294
  prefs: []
  type: TYPE_NORMAL
- en: '`notFollowedBy` and `lookAhead`'
  id: totrans-split-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are two more primitives (in addition to `try`) that can perform look ahead
    in the input stream without actually advancing the parsing position in it.
  id: totrans-split-296
  prefs: []
  type: TYPE_NORMAL
- en: 'The first one is called `notFollowedBy`:'
  id: totrans-split-297
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  id: totrans-split-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: It succeeds only when its argument parser fails and never consumes any input
    or modifies the parser state.
  id: totrans-split-299
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example when you may want to use `notFollowedBy`, consider parsing of
    keywords:'
  id: totrans-split-300
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  id: totrans-split-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'This parser has a problem: what if the keyword we are matching against is just
    a prefix of an identifier? In that case it is definitely not a keyword. Thus we
    must eliminate that case by using `notFollowedBy`:'
  id: totrans-split-302
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  id: totrans-split-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Another primitive is `lookAhead`:'
  id: totrans-split-304
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  id: totrans-split-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: If the argument `p` of `lookAhead` succeeds, the whole construct `lookAhead
    p` also succeeds but the input stream (and the entire parser state) stays untouched,
    i.e. nothing is consumed.
  id: totrans-split-306
  prefs: []
  type: TYPE_NORMAL
- en: 'One example of where this may be useful is performing a check on an already
    parsed value and then either failing or continuing successfully. The idiom can
    be expressed in code like this:'
  id: totrans-split-307
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  id: totrans-split-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'This demonstrates a use of `lookAhead`, but we also should note that when the
    check if successful we perform the parsing twice, which is not good. Here is an
    alternative solution using the `getOffset` function:'
  id: totrans-split-309
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  id: totrans-split-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: This way we just set offset in the input stream to what if was before running
    `p` and then fail. There is a mismatch now in what remains unconsumed vs offset
    position, but it does not matter in this case because we end parsing immediately
    by calling `fail`. It may matter in other cases. We will see how to do better
    in situations like this later in this chapter.
  id: totrans-split-311
  prefs: []
  type: TYPE_NORMAL
- en: Parsing expressions
  id: totrans-split-312
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By “expression” we mean a structure formed from terms and operators applied
    to those terms. Operators can be prefix, infix, and postfix, left and right-associative,
    with different precedence. An example of such a construct would be arithmetic
    expressions familiar from school:'
  id: totrans-split-313
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  id: totrans-split-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Here we can see two kinds of terms: variables (`a` and `b`) and integers (`2`).
    There are also two operators: `*` and `+`.'
  id: totrans-split-315
  prefs: []
  type: TYPE_NORMAL
- en: 'Writing an expression parser may take a while to get right. To help with that,
    the [`parser-combinators`](https://hackage.haskell.org/package/parser-combinators)
    package comes with the `Control.Monad.Combinators.Expr` module which exports only
    two things: the `Operator` data type and the `makeExprParser` helper. Both are
    well documented, so in this section we will not repeat the documentation, instead
    we are going to write a simple but fully functional expression parser.'
  id: totrans-split-316
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by defining a data type representing an expression as [AST](https://en.wikipedia.org/wiki/Abstract_syntax_tree):'
  id: totrans-split-317
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  id: totrans-split-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'To use `makeExprParser` we need to provide it with a term parser and an operator
    table:'
  id: totrans-split-319
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  id: totrans-split-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Let’s start with the term parser. It is helpful to think about term as a box
    that that is to be considered as an indivisible whole by the expression parsing
    algorithm when it works with things like associativity and precedence. In our
    case there are three things that fall into this category: variables, integers,
    and entire expressions in parentheses. Using the definitions from previous chapters
    we can define the term parser as:'
  id: totrans-split-321
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  id: totrans-split-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'The definitions of `pVariable`, `pInteger`, and `parens` should go without
    questions by now. We are also quite lucky here in that we do not need `try`s in
    `pTerm` because the grammars do not overlap:'
  id: totrans-split-323
  prefs: []
  type: TYPE_NORMAL
- en: if we see an opening parenthesis `(`, we know that an expression in parentheses
    is to follow, so we commit to that branch;
  id: totrans-split-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: if we see a letter, we know that it is the start of an identifier;
  id: totrans-split-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: if we see a digit, we know that it is the start of an integer.
  id: totrans-split-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, to finish `pExpr` we need to define the `operatorTable`. We can see
    from the type that it is a nested list. Every inner list is a list of operators
    we want to support, they all have equal precedence. The outer list is ordered
    in descending precedence, so the higher we place a group of operators in it, the
    tighter they bind:'
  id: totrans-split-327
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  id: totrans-split-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: Note how we place `Parser (Expr -> Expr -> Expr)` inside `InfixL` in `binary`
    and similarly `Parser (Expr -> Expr)` in `prefix` and `postfix`. That is, we run
    `symbol name` and return a function to apply to the terms in order to get the
    final result of the type `Expr`.
  id: totrans-split-329
  prefs: []
  type: TYPE_NORMAL
- en: We can now try our parser, it is ready!
  id: totrans-split-330
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  id: totrans-split-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: Documentation for the `Control.Monad.Combinators.Expr` module contains some
    hints that are useful in certain less-standard situations, so it is a good idea
    to read it as well.
  id: totrans-split-332
  prefs: []
  type: TYPE_NORMAL
- en: Indentation-sensitive parsing
  id: totrans-split-333
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `Text.Megaparsec.Char.Lexer` module contains tools that should be helpful
    when parsing indentation-sensitive grammars. We are going to review the available
    combinators first, then put them into use by writing an indentation-sensitive
    parser.
  id: totrans-split-334
  prefs: []
  type: TYPE_NORMAL
- en: '`nonIndented` and `indentBlock`'
  id: totrans-split-335
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s start with the simplest thing—`nonIndented`:'
  id: totrans-split-336
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  id: totrans-split-337
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: It allows us to make sure that its inner parser consumes input that is *not*
    indented. It is a part of a model behind high-level parsing of indentation-sensitive
    input. We state that there are top-level items that are not indented and that
    all indented tokens are directly or indirectly children of those top-level definitions.
    In `megaparsec`, we do not need any additional state to express this. Since indentation
    is always relative, our idea is to explicitly tie parsers for reference tokens
    and indented tokens, thus defining indentation-sensitive grammar via pure combination
    of parsers.
  id: totrans-split-338
  prefs: []
  type: TYPE_NORMAL
- en: 'So, how do we define a parser for indented block? Let’s take a look at the
    signature of `indentBlock`:'
  id: totrans-split-339
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  id: totrans-split-340
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: First, we specify how to consume indentation. An important thing to note here
    is that this space-consuming parser *must* consume newlines as well, while tokens
    (reference token and indented tokens) should not normally consume newlines after
    them.
  id: totrans-split-341
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the second argument allows us to parse reference token and
    return a data structure that tells `indentBlock` what to do next. There are several
    options:'
  id: totrans-split-342
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  id: totrans-split-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: We can change our mind and parse no indented tokens, we can parse *many* (that
    is, possibly zero) indented tokens or require *at least one* such token. We can
    either allow `indentBlock` to detect the indentation level of the first indented
    token and use that, or manually specify the indentation level.
  id: totrans-split-344
  prefs: []
  type: TYPE_NORMAL
- en: Parsing a simple indented list
  id: totrans-split-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s parse a simple indented list of some items. We begin with the import
    section:'
  id: totrans-split-346
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  id: totrans-split-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: 'We will need two kinds of space-consumers: one that consumes new lines `scn`
    and one that does not `sc` (actually it only parses spaces and tabs here):'
  id: totrans-split-348
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  id: totrans-split-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: Just for fun, we allow line comments that start with `#`.
  id: totrans-split-350
  prefs: []
  type: TYPE_NORMAL
- en: '`pItemList` is a top-level form that itself is a combination of reference token
    (header of list) and indented tokens (list items), so:'
  id: totrans-split-351
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  id: totrans-split-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'For our purposes, an item is a sequence of alpha-numeric characters and dashes:'
  id: totrans-split-353
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  id: totrans-split-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'Let’s load the code into GHCi and try it with the help of `parseTest` built-in:'
  id: totrans-split-355
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  id: totrans-split-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: Remember that we are using the `IndentMany` option, so empty lists are OK, on
    the other hand the built-in combinator `space` has hidden the phrase “expecting
    more space” from error messages, so this error message is perfectly reasonable.
  id: totrans-split-357
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s continue:'
  id: totrans-split-358
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  id: totrans-split-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'Let’s replace `IndentMany` with `IndentSome` and `Nothing` with `Just (mkPos
    5)` (indentation levels are counted from 1, so it will require 4 spaces before
    indented items):'
  id: totrans-split-360
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  id: totrans-split-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: 'Now:'
  id: totrans-split-362
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  id: totrans-split-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: The first message may be a bit surprising, but `megaparsec` knows that there
    must be at least one item in the list, so it checks the indentation level and
    it is 1, which is incorrect, so it reports it.
  id: totrans-split-364
  prefs: []
  type: TYPE_NORMAL
- en: Nested indented list
  id: totrans-split-365
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s allow list items to have sub-items. For this we will need a new parser,
    `pComplexItem`:'
  id: totrans-split-366
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  id: totrans-split-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'If we feed something like this:'
  id: totrans-split-368
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  id: totrans-split-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'into our parser, we will get:'
  id: totrans-split-370
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  id: totrans-split-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: This demonstrates how this approach scales for nested indented construts without
    requiring additional state.
  id: totrans-split-372
  prefs: []
  type: TYPE_NORMAL
- en: Adding line folds
  id: totrans-split-373
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *line fold* consists of several elements that can be put on one line or on
    several lines as long as the indentation level of the subsequent items is greater
    than the indentation level of the first item.
  id: totrans-split-374
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s make use of another helper called `lineFold`:'
  id: totrans-split-375
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  id: totrans-split-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE104]'
- en: '`lineFold` works like this: we give it a space consumer that accepts newlines
    `scn` and it gives back a special space consumer `sc''` that we can use in the
    callback to consume space between elements of line fold.'
  id: totrans-split-377
  prefs: []
  type: TYPE_NORMAL
- en: 'Why use `try sc''` and `scn` on the line (1)? The situation is the following:'
  id: totrans-split-378
  prefs: []
  type: TYPE_NORMAL
- en: Components of a line fold can only be more indented than its start.
  id: totrans-split-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sc''` consumes whitespace with newlines in such a way that after consuming
    whitespace the column number is greater than initial column.'
  id: totrans-split-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To stop, `sc'` should encounter the opposite situation, that is, the column
    number after consumption should be less than or equal to the initial column. At
    that point it fails without consuming input (thanks to `try`) and `scn` is used
    to pick up whitespace before that new thing that will start at that column.
  id: totrans-split-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Previously used `sc'` already probed whitespace with space consumer which consumes
    newlines. So, it is only logical to also consume newlines when picking up trailing
    whitespace. This is why `scn` is used on the line (1) and not `sc`.
  id: totrans-split-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*EXERCISE: Playing with the final version of our parser is left as an exercise
    for the reader. You can create “items” that consist of multiple words and as long
    as they are line-folded they will be parsed and concatenated with single space
    between them.*'
  id: totrans-split-383
  prefs: []
  type: TYPE_NORMAL
- en: Writing efficient parsers
  id: totrans-split-384
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s discuss what to attempt in order to improve performance of a `megaparsec`
    parser. It should be noted right away that one should always check if there is
    any improvement through profiling and benchmarking. That is the only way to understand
    if we are doing the right thing when tuning performance.
  id: totrans-split-385
  prefs: []
  type: TYPE_NORMAL
- en: 'Common pieces of advice:'
  id: totrans-split-386
  prefs: []
  type: TYPE_NORMAL
- en: If your parser uses a monad stack instead of the plain `Parsec` monad (recall
    that it is the `ParsecT` monad transformer over `Identity`, which is quite lightweight),
    make sure you use at least version 0.5 of `transformers` library, and at least
    version 7.0 of `megaparsec`. Both libraries have critical performance improvements
    in these versions, so you can just get better performance for free.
  id: totrans-split-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Parsec` monad will be always faster then `ParsecT`-based monad transformers.
    Avoid using `StateT`, `WriterT`, and other monad transformers unless absolutely
    necessary. The more you add to the monadic stack, the slower your parser will
    be.'
  id: totrans-split-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backtracking is an expensive operation. Avoid building long chains of alternatives
    where every alternative can go deep into input before failing.
  id: totrans-split-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do not keep your parsers polymorphic unless you really have a reason to do so.
    It is best to fix the types of parsers specifying concrete types, such as `type
    Parser = Parsec Void Text` for every top-level definition. This way GHC will be
    able to optimize better.
  id: totrans-split-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inline generously (when it makes sense, of course). You may not believe your
    eyes when you see how much of a difference inlining can do, especially for short
    functions. This is especially true for parsers that are defined in one module
    and used in another one, because `INLINE` and `INLINEABLE` pragmas make GHC dump
    function definitions into interface files and this facilitates specializing.
  id: totrans-split-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the fast primitives such as `takeWhileP`, `takeWhile1P`, and `takeP` whenever
    you can. [This blog post](https://markkarpov.com/post/megaparsec-more-speed-more-power#there-is-hope)
    explains why they are so fast.
  id: totrans-split-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid `oneOf` and `noneOf` preferring `satisfy` and `anySingleBut` whenever
    possible.
  id: totrans-split-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While most of the points above do not require additional comment, I think it
    would be beneficial to get into the habit of using the newer fast primitives:
    `takeWhileP`, `takeWhile1P`, and `takeP`. The first two are especially common
    as they allow us to replace `many` and `some`-based constructs making them faster
    and changing the type of returned data to chunk of input stream, i.e. the `Tokens
    s` type we have discussed previously.'
  id: totrans-split-394
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, recall that when we parsed URIs, we had this code for parsing
    username in the authority component:'
  id: totrans-split-395
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  id: totrans-split-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE105]'
- en: 'We can replace it by `takeWhile1P`:'
  id: totrans-split-397
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  id: totrans-split-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE106]'
- en: When we parse `ByteString`s and `Text`, this will be a lot faster than the original
    approach. Also note that `T.pack` is not necessary anymore as we get `Text` directly
    from `takeWhile1P`.
  id: totrans-split-399
  prefs: []
  type: TYPE_NORMAL
- en: 'These equations may be helpful for understanding the meaning of the `Maybe
    String` argument of `takeWhileP` and `takeWhile1P`:'
  id: totrans-split-400
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  id: totrans-split-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE107]'
- en: Parse errors
  id: totrans-split-402
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have explored how to use most features of `megaparsec`, it is time
    to learn more about parse errors: how they are defined, how to signal them, and
    how to process them inside a running parser.'
  id: totrans-split-403
  prefs: []
  type: TYPE_NORMAL
- en: Parse error definitions
  id: totrans-split-404
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `ParseError` type is defined like this:'
  id: totrans-split-405
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  id: totrans-split-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE108]'
- en: 'In English: a `ParseError` is either a `TrivialError` with at most one unexpected
    item and a (possibly empty) collection of expected items or a `FancyError`.'
  id: totrans-split-407
  prefs: []
  type: TYPE_NORMAL
- en: '`ParseError s e` is parametrized over two type variables:'
  id: totrans-split-408
  prefs: []
  type: TYPE_NORMAL
- en: '`s` is the type of input stream.'
  id: totrans-split-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`e` is the type of custom component of parse error.'
  id: totrans-split-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ErrorItem` is defined as:'
  id: totrans-split-411
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  id: totrans-split-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE109]'
- en: '`NonEmpty` is a type for non-empty lists, it comes from `Data.List.NonEmpty`.
    And here is `ErrorFancy`:'
  id: totrans-split-413
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  id: totrans-split-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE110]'
- en: '`ErrorFancy` includes data constructors for two common cases `megaparsec` supports
    out-of-the-box:'
  id: totrans-split-415
  prefs: []
  type: TYPE_NORMAL
- en: Use of the `fail` function that causes parser to fail reporting an arbitrary
    `String`.
  id: totrans-split-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indentation-related issues which we have seen in a previous section. Since we
    provide tools for working with indentation-sensitive grammars out-of-the-box,
    we need a way to store well-typed information about problems with indentation.
  id: totrans-split-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, `ErrorCustom` is a sort of an “extension slot” which allows to embed
    arbitrary data into the `ErrorFancy` type. When we do not need any custom data
    in our parse errors, we parametrize `ErrorFancy` by `Void`. Since `Void` is not
    inhabited by non-bottom values, `ErrorCustom` becomes “cancelled out” or, if we
    follow the analogy between algebraic data types and numbers, “multiplied by zero”.
  id: totrans-split-418
  prefs: []
  type: TYPE_NORMAL
- en: In older version of the library, `ParseError`s were returned directly by functions
    like `parse`, but version 7 delays calculation of line and column for each error,
    as well as fetching of the relevant line on input for displaying in case of an
    error. This is done to be make parsing faster, because all this information is
    usually useful only when a parser fails. Another problem of older versions of
    the library is that displaying several parse errors at once required re-traversal
    of input each time to fetch the right line.
  id: totrans-split-419
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem is solved with the `ParseErrorBundle` data type:'
  id: totrans-split-420
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  id: totrans-split-421
  prefs: []
  type: TYPE_PRE
  zh: '[PRE111]'
- en: All parser-running functions return `ParseErrorBundle` with a correctly set
    `bundlePosState` and a collection `ParseError`s inside.
  id: totrans-split-422
  prefs: []
  type: TYPE_NORMAL
- en: How to signal a parse error
  id: totrans-split-423
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s discuss different ways to signal a parse error. The simplest function
    for that is `fail`:'
  id: totrans-split-424
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  id: totrans-split-425
  prefs: []
  type: TYPE_PRE
  zh: '[PRE112]'
- en: For many people who are familiar with simpler parsing libraries such as `parsec`
    this is often enough. However, displaying a parse error to the user is not everything,
    we may have a need to analyze and/or manipulate it. This is where `String`s are
    not very convenient.
  id: totrans-split-426
  prefs: []
  type: TYPE_NORMAL
- en: 'Trivial parse errors are usually generated by `megaparsec`, but we can signal
    any such an error ourselves using the `failure` combinator:'
  id: totrans-split-427
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  id: totrans-split-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE113]'
- en: '[PRE114]'
  id: totrans-split-429
  prefs: []
  type: TYPE_PRE
  zh: '[PRE114]'
- en: '[PRE115]'
  id: totrans-split-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE115]'
- en: Unlike the `fail`-based approach, trivial parse errors are easy to pattern-match
    on, inspect, and modify.
  id: totrans-split-431
  prefs: []
  type: TYPE_NORMAL
- en: 'For fancy errors we correspondingly have the `fancyFaliure` combinator:'
  id: totrans-split-432
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  id: totrans-split-433
  prefs: []
  type: TYPE_PRE
  zh: '[PRE116]'
- en: 'With `fancyFailure`, it is often desirable to define a helper like the one
    we have in the lexer modules instead of calling `fancyFailure` directly:'
  id: totrans-split-434
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  id: totrans-split-435
  prefs: []
  type: TYPE_PRE
  zh: '[PRE117]'
- en: As an example of adding a custom parse error component to your parser, let’s
    go through defining a special parse error that says that given `Text` value is
    not a keyword.
  id: totrans-split-436
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to define the data type with constructors representing scenarios
    we want to support:'
  id: totrans-split-437
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  id: totrans-split-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE118]'
- en: 'And tell `megaparsec` how to display it in parse errors:'
  id: totrans-split-439
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  id: totrans-split-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE119]'
- en: 'Next we update our `Parser` type synonym:'
  id: totrans-split-441
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  id: totrans-split-442
  prefs: []
  type: TYPE_PRE
  zh: '[PRE120]'
- en: 'After that we can define the `notKeyword` helper:'
  id: totrans-split-443
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  id: totrans-split-444
  prefs: []
  type: TYPE_PRE
  zh: '[PRE121]'
- en: 'Where `customFailure` is a useful helper that comes from the `Text.Megaparsec`
    module:'
  id: totrans-split-445
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  id: totrans-split-446
  prefs: []
  type: TYPE_PRE
  zh: '[PRE122]'
- en: 'Finally, let us try it:'
  id: totrans-split-447
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE123]'
  id: totrans-split-448
  prefs: []
  type: TYPE_PRE
  zh: '[PRE123]'
- en: Displaying parse errors
  id: totrans-split-449
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Displaying of `ParseErrorBundle`s is done with the `errorBundlePretty` function:'
  id: totrans-split-450
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  id: totrans-split-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE124]'
- en: In 99% of cases you will only need this one function.
  id: totrans-split-452
  prefs: []
  type: TYPE_NORMAL
- en: Catching parse errors in a running parser
  id: totrans-split-453
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another useful feature of `megaparsec` is that it is possible to “catch” a
    parse error, alter it in some way, and then re-throw, [just like with exceptions](/tutorial/exceptions).
    This is enabled by the `observing` primitive:'
  id: totrans-split-454
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE125]'
  id: totrans-split-455
  prefs: []
  type: TYPE_PRE
  zh: '[PRE125]'
- en: 'Here is a complete program demonstrating typical usage of `observing`:'
  id: totrans-split-456
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE126]'
  id: totrans-split-457
  prefs: []
  type: TYPE_PRE
  zh: '[PRE126]'
- en: '*EXERCISE: Understand in details how this program works.*'
  id: totrans-split-458
  prefs: []
  type: TYPE_NORMAL
- en: 'If I run this program, I see the following output:'
  id: totrans-split-459
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE127]'
  id: totrans-split-460
  prefs: []
  type: TYPE_PRE
  zh: '[PRE127]'
- en: 'Thus, the feature can be used to attach location labels to parse errors, or
    indeed define *regions* in which parse errors are processed in some way. The idiom
    is quite useful, so there is even a non-primitive helper called `region` defined
    in terms of the `observing` primitive:'
  id: totrans-split-461
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE128]'
  id: totrans-split-462
  prefs: []
  type: TYPE_PRE
  zh: '[PRE128]'
- en: '*EXERCISE: Rewrite the `inside` function in the program above using `region`.*'
  id: totrans-split-463
  prefs: []
  type: TYPE_NORMAL
- en: Controlling location of parse errors
  id: totrans-split-464
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The definition of `region` uses the `parseError` primitive:'
  id: totrans-split-465
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE129]'
  id: totrans-split-466
  prefs: []
  type: TYPE_PRE
  zh: '[PRE129]'
- en: 'It is the fundamental primitive for error reporting and all other functions
    we have seen so far are defined in terms of `parseError`:'
  id: totrans-split-467
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE130]'
  id: totrans-split-468
  prefs: []
  type: TYPE_PRE
  zh: '[PRE130]'
- en: 'One thing `parseError` allows you to do is to set error offset (that is, position)
    to something else than current position in input stream. Let’s return to the example
    with rejecting results of parsing retroactively:'
  id: totrans-split-469
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE131]'
  id: totrans-split-470
  prefs: []
  type: TYPE_PRE
  zh: '[PRE131]'
- en: We noted that `setOffset o` will make the error to be located correctly, but
    it will also invalidate the parser state as a side effect—the offset will not
    reflect reality anymore. This may be a real problem in more complex parsers. For
    example, imagine that you enclose `withPredicate2` with `observing` so that there
    will be some code running after `fail`.
  id: totrans-split-471
  prefs: []
  type: TYPE_NORMAL
- en: 'With `parseError` and `region` we finally have proper solution to the problem—either
    use `region` to reset the parse error location, or use `parseError` in the first
    place:'
  id: totrans-split-472
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE132]'
  id: totrans-split-473
  prefs: []
  type: TYPE_PRE
  zh: '[PRE132]'
- en: Reporting multiple parse errors
  id: totrans-split-474
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Finally, `megaparsec` allows us to signal several parse errors in a single run.
    This may be helpful for the end users because they will be able to fix several
    issues at once and so they will need to run your parser fewer times.
  id: totrans-split-475
  prefs: []
  type: TYPE_NORMAL
- en: 'One prerequisite for having a multi-error parser is that it should be possible
    to skip over a problematic part of input and resume parsing from a position that
    is known to be good. This part is accomplished by using the `withRecovery` primitive:'
  id: totrans-split-476
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE133]'
  id: totrans-split-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE133]'
- en: Before Megaparsec 8 users had to pick the type `a` to be a sum type including
    the possibilities for success and failure. For example, it could be `Either (ParseError
    s e) Result`. The parse errors had to be collected and later manually added to
    the `ParseErrorBundle` before displaying. Needless to say, all of this was an
    example of advanced usage that was not user friendly.
  id: totrans-split-478
  prefs: []
  type: TYPE_NORMAL
- en: 'Megaparsec 8 supports *delayed parse errors*:'
  id: totrans-split-479
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE134]'
  id: totrans-split-480
  prefs: []
  type: TYPE_PRE
  zh: '[PRE134]'
- en: These errors can be registered in the error-processing callback of `withRecovery`
    making the resulting type `Maybe Result`. This takes care of including the delayed
    errors in the final `ParseErrorBundle` as well as making the parser fail in the
    end if the collection of delayed errors in not empty.
  id: totrans-split-481
  prefs: []
  type: TYPE_NORMAL
- en: With all this, we hope that the practice of writing multi-error parsers will
    become more common among the users.
  id: totrans-split-482
  prefs: []
  type: TYPE_NORMAL
- en: Testing Megaparsec parsers
  id: totrans-split-483
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Testing a parser is a practical task most people face sooner or later, so we
    are bound to cover it. The recommended way to test `megaparsec` parsers is by
    using the [`hspec-megaparsec`](https://hackage.haskell.org/package/hspec-megaparsec)
    package. The package adds utility expectations such as `shouldParse`, `parseSatisfies`,
    etc. which work with the `hspec` testing framework.
  id: totrans-split-484
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with an example:'
  id: totrans-split-485
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE135]'
  id: totrans-split-486
  prefs: []
  type: TYPE_PRE
  zh: '[PRE135]'
- en: '`shouldParse` accepts `Either (ParseErrorBundle s e) a`—the result of parsing
    and a thing of the type `a` to compare with. It is probably the most common helper.
    `parseSatisfies` is quite similar, but instead of comparing for equality with
    the expected result, it allows to check the result by applying an arbitrary predicate.'
  id: totrans-split-487
  prefs: []
  type: TYPE_NORMAL
- en: 'Other simple expectations are `shouldSucceedOn` and `shouldFailOn` (although
    they are rarely used):'
  id: totrans-split-488
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE136]'
  id: totrans-split-489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE136]'
- en: 'With `megaparsec` we want to be precise about parse errors our parsers produce.
    To test parse errors there is `shouldFailWith`, which can be used like this:'
  id: totrans-split-490
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE137]'
  id: totrans-split-491
  prefs: []
  type: TYPE_PRE
  zh: '[PRE137]'
- en: 'Writing out a `TrivialError` like this is tiresome. The definition of `ParseError`
    contains “inconvenient” types like `Set` and `NonEmpty` which are not handy to
    enter directly as we have just seen. Fortunately, `Test.Hspec.Megaparsec` also
    re-exports the `Text.Megaparsec.Error.Builder` module which provides an API for
    easier construction of `ParserError`s. Let us instead use the `err` helper:'
  id: totrans-split-492
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE138]'
  id: totrans-split-493
  prefs: []
  type: TYPE_PRE
  zh: '[PRE138]'
- en: The first argument of `err` is offset of the parse error (the number of tokens
    that had been consumed before we got the error). In this example it is simply
    0.
  id: totrans-split-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`utok` stands for “unexpected token”, similarly `etok` means “expected token”.'
  id: totrans-split-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*EXERCISE: Familiarize yourself with `errFancy`, which is used to construct
    fancy parse errors.*'
  id: totrans-split-496
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, it is possible to test what part of input remains unconsumed after
    parsing using `failsLeaving` and `succeedsLeaving`:'
  id: totrans-split-497
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE139]'
  id: totrans-split-498
  prefs: []
  type: TYPE_PRE
  zh: '[PRE139]'
- en: 'These should by used with `runParser''` or `runParserT''` which accept custom
    initial state of parser and return its final state (this is what allows us to
    check the leftover of the input stream after parsing):'
  id: totrans-split-499
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE140]'
  id: totrans-split-500
  prefs: []
  type: TYPE_PRE
  zh: '[PRE140]'
- en: The `initialState` function takes the input stream and returns the initial state
    with that input stream and other record fields filled with their default values.
  id: totrans-split-501
  prefs: []
  type: TYPE_NORMAL
- en: 'Other sources of inspiration for using `hspec-megaparsec` are:'
  id: totrans-split-502
  prefs: []
  type: TYPE_NORMAL
- en: Working with custom input streams
  id: totrans-split-503
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`megaparsec` can be used to parse any input that is an instance of the `Stream`
    type class. This means that it may be used in conjunction with a lexing tool such
    as `alex`.'
  id: totrans-split-504
  prefs: []
  type: TYPE_NORMAL
- en: 'Not to digress from our main topic by presenting how a stream of tokens could
    be generated with `alex`, we will assume it in the following form:'
  id: totrans-split-505
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE141]'
  id: totrans-split-506
  prefs: []
  type: TYPE_PRE
  zh: '[PRE141]'
- en: 'To report parse errors though we need a way to know the token’s starting position,
    ending position, and length, so let’s add `WithPos`:'
  id: totrans-split-507
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE142]'
  id: totrans-split-508
  prefs: []
  type: TYPE_PRE
  zh: '[PRE142]'
- en: 'Then we can have a data type for our stream:'
  id: totrans-split-509
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE143]'
  id: totrans-split-510
  prefs: []
  type: TYPE_PRE
  zh: '[PRE143]'
- en: 'Next, we need to make `MyStream` an instance of the `Stream` type class. This
    requires the `TypeFamilies` language extension because we want to define the associated
    type functions `Token` and `Tokens`:'
  id: totrans-split-511
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE144]'
  id: totrans-split-512
  prefs: []
  type: TYPE_PRE
  zh: '[PRE144]'
- en: '`Stream`, `VisualStream`, and `TraversableStream` are documented in the `Text.Megaparsec.Stream`
    module. Here we go straight to defining the methods:'
  id: totrans-split-513
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE145]'
  id: totrans-split-514
  prefs: []
  type: TYPE_PRE
  zh: '[PRE145]'
- en: More background information about the `Stream` type class (and why it looks
    like this) can be found in [this blog post](https://markkarpov.com/post/megaparsec-more-speed-more-power).
    Note that in the version 9 of `megaparsec` certain methods of `Stream` were moved
    to the classes `VisualStream` and `TraversableStream` to make it easier to define
    instances of `Stream` for certain custom input streams.
  id: totrans-split-515
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can define `Parser` for our custom stream:'
  id: totrans-split-516
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE146]'
  id: totrans-split-517
  prefs: []
  type: TYPE_PRE
  zh: '[PRE146]'
- en: The next step is to define basic parsers on top of `token` and (if it makes
    sense) `tokens` primitives. For the streams that are supported out-of-the-box
    we have `Text.Megaparsec.Byte` and `Text.Megaparsec.Char` modules, but if we are
    to work with custom tokens, we need custom helpers.
  id: totrans-split-518
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE147]'
  id: totrans-split-519
  prefs: []
  type: TYPE_PRE
  zh: '[PRE147]'
- en: 'Finally let us have a test parser which parses a sum:'
  id: totrans-split-520
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE148]'
  id: totrans-split-521
  prefs: []
  type: TYPE_PRE
  zh: '[PRE148]'
- en: 'And an example input for it:'
  id: totrans-split-522
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE149]'
  id: totrans-split-523
  prefs: []
  type: TYPE_PRE
  zh: '[PRE149]'
- en: 'Let’s try it:'
  id: totrans-split-524
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE150]'
  id: totrans-split-525
  prefs: []
  type: TYPE_PRE
  zh: '[PRE150]'
- en: 'If we change `Plus` on the line (1) to `Div`, we will get the correct parse
    error:'
  id: totrans-split-526
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE151]'
  id: totrans-split-527
  prefs: []
  type: TYPE_PRE
  zh: '[PRE151]'
- en: In other words, we have now a fully functional parser that parses a custom stream.
  id: totrans-split-528
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  id: totrans-split-529
  prefs: []
  type: TYPE_NORMAL
- en: There is actually the [`modern-uri`](https://hackage.haskell.org/package/modern-uri)
    package which contains a real-world Megaparsec parser which can parse URIs according
    to RFC 3986\. The parser from the package is much more complex than the one we
    describe here, though. [↩](#fnref1)
  id: totrans-split-530
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
