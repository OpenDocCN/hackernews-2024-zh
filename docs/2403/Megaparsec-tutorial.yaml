- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:34:24'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Megaparsec tutorial
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://markkarpov.com/tutorial/megaparsec.html](https://markkarpov.com/tutorial/megaparsec.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Megaparsec tutorial
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Published on February 23, 2019, last updated October 30, 2021*'
  prefs: []
  type: TYPE_NORMAL
- en: '*This is the Megaparsec tutorial which originally was written as a chapter
    for the [Intermediate Haskell](https://intermediatehaskell.com) book. Due to lack
    of progress with the book in the last year, other authors agreed to let me publish
    the text as a standalone tutorial so that people can benefit at least from this
    part of our work.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Japanese translation](https://haskell.e-bigmoon.com/posts/2019/07-14-megaparsec-tutorial.html),
    [Chinese translation](https://blog.yzyzsun.me/megaparsec/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The toy parser combinators developed in chapter “An Example: Writing Your Own
    Parser Combinators” are not suitable for real-world use, so let’s continue by
    taking a look at the libraries in the Haskell ecosystem that solve the same problem,
    and note various trade-offs they make:'
  prefs: []
  type: TYPE_NORMAL
- en: '[`parsec`](https://hackage.haskell.org/package/parsec) has been the “default”
    parsing library in Haskell for a long time. The library is said to be focused
    on quality of error messages. It however does not have good test coverage and
    is currently in maintenance mode.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`attoparsec`](https://hackage.haskell.org/package/attoparsec) is a robust,
    fast parsing library with focus on performance. It is the only library from this
    list that has full support for incremental parsing. Its downsides are poor quality
    of error messages, inability to be used as a monad transformer, and limited set
    of types that can be used as input stream.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`trifecta`](https://hackage.haskell.org/package/trifecta) features good error
    messages but is under-documented and hard to figure out. It can parse `String`
    and `ByteString` out-of-the-box, but not `Text`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[`megaparsec`](https://hackage.haskell.org/package/megaparsec) is a fork of
    `parsec` that has been actively developed in the last few years. The current version
    tries to find a nice balance between speed, flexibility, and quality of parse
    errors. As an unofficial successor of `parsec`, it stays conventional and immediately
    familiar for users who have used that library or who have read `parsec` tutorials.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It would be impractical to try to cover all these libraries, and so we will
    focus on `megaparsec`. More precisely, we are going to cover the version 9, which
    by the time this book is published will probably have replaced the older versions
    almost everywhere.
  prefs: []
  type: TYPE_NORMAL
- en: '`ParsecT` and `Parsec` monads'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`ParsecT` is the main parser monad transformer and the central data type in
    `megaparsec`. `ParsecT e s m a` is parametrized like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '`e` is the type of custom component of error messages. If we do not want anything
    custom (and for now we do not), we just use `Void` from the `Data.Void` module.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`s` is the type of input stream. `megaparsec` works out-of-the-box with `String`,
    strict and lazy `Text`, and strict and lazy `ByteString`s. It is also possible
    to work with custom input streams.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`m` is the inner monad of the `ParsecT` monad transformer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`a` is the monadic value, result of parsing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Since most of the time `m` is nothing but `Identity`, the `Parsec` type synonym
    is quite useful:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`Parsec` is simply the non-transformer version of `ParsecT`.'
  prefs: []
  type: TYPE_NORMAL
- en: We can also draw an analogy between the monad transformers in `megaparsec` and
    MTL monad transformers and classes. Indeed, there is also the `MonadParsec` type
    class which is similar in its purpose to type classes such as `MonadState` and
    `MonadReader`. We will return to `MonadParsec` [later](#the-monadparsec-type-class)
    and discuss it in more details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Speaking of type synonyms, the best way to start writing parser with `megaparsec`
    is to define a custom type synonym for your parser. This is a good idea for two
    reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: It will be easier to add top level signatures like `Parser Int` where `Parser`
    is your parsing monad. Without the signatures, things like `e` will often be ambiguous—it
    is the flip side of the polymorphic API of the library.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with concrete types with all type variables fixed helps GHC optimize
    a lot better. GHC cannot do much in terms of optimization if your parsers stay
    polymorphic. Although `megaparsec` API is polymorphic, it is expected that end
    user will stick to a concrete type of parsing monad, so inlining and the fact
    that most functions have their definition dumped into so-called *interface files*
    will allow GHC produce very efficient non-polymorphic code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s define a type synonym (typically called `Parser`) like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Until we start dealing with custom parsing errors, when you see `Parser` in
    the chapter, assume this type.
  prefs: []
  type: TYPE_NORMAL
- en: Character and binary streams
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It has been said that `megaparsec` can work with five types of input stream
    out-of-the-box: `String`, strict and lazy `Text`, and strict and lazy `ByteString`s.
    This is possible because the library makes these types instances of the `Stream`
    type class which abstracts the functionality that every data type should support
    to be used as input to a `megaparsec` parser.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A simplified version of `Stream` could look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The real definition of `Stream` has more methods, but knowing about them is
    not necessary for using the library.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the type class has two type functions associated with it:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Token s` for stream `s` is the type of single token. Common examples are `Char`
    and `Word8`, although it may be something else for custom streams.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Tokens s` for stream `s` is the type of a “chunk” of stream. The concept of
    *chunk* was only introduced for performance reasons. Indeed, it is often possible
    to have a more efficient representation of part of a stream which is isomorphic
    to list of tokens `[Token s]`. For example, input stream of the type `Text` has
    `Tokens s ~ Text`: chunk of `Text` is just `Text`. Although the type equality
    `Tokens s ~ s` often holds, `Tokens s` and `s` may differ for custom streams,
    and thus we separate these types in `megaparsec`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We can put all the default input streams into a single table like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '| `s` | `Token s` | `Tokens s` |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `String` | `Char` | `String` |'
  prefs: []
  type: TYPE_TB
- en: '| strict `Text` | `Char` | strict `Text` |'
  prefs: []
  type: TYPE_TB
- en: '| lazy `Text` | `Char` | lazy `Text` |'
  prefs: []
  type: TYPE_TB
- en: '| strict `ByteString` | `Word8` | strict `ByteString` |'
  prefs: []
  type: TYPE_TB
- en: '| lazy `ByteString` | `Word8` | lazy `ByteString` |'
  prefs: []
  type: TYPE_TB
- en: It is important to get used to the `Token` and `Tokens` type functions because
    they are ubiquitous in the types of `megaparsec` API.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may have noticed that if we group all default input streams by token type,
    we will get two groups:'
  prefs: []
  type: TYPE_NORMAL
- en: 'character streams, for which `Token s ~ Char`: `String` and strict/lazy `Text`,'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'binary streams, for which `Token s ~ Word8`: strict and lazy `ByteString`s.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It turns out that with `megaparsec` it is not necessary to code the same parsers
    for every type of input stream (this is the case, for example, with the `attoparsec`
    library), but still we must have different code for different token types:'
  prefs: []
  type: TYPE_NORMAL
- en: to get common combinators for character streams, import the `Text.Megaparsec.Char`
    module;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: to get the same for binary streams, import `Text.Megaparsec.Byte`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These modules contain two similar sets of helper parsers such as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Name | `Text.Megaparsec.Char` | `Text.Megaparsec.Byte` |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `newline` | `(MonadParsec e s m, Token s ~ Char) => m (Token s)` | `(MonadParsec
    e s m, Token s ~ Word8) => m (Token s)` |'
  prefs: []
  type: TYPE_TB
- en: '| `eol` | `(MonadParsec e s m, Token s ~ Char) => m (Tokens s)` | `(MonadParsec
    e s m, Token s ~ Word8) => m (Tokens s)` |'
  prefs: []
  type: TYPE_TB
- en: Let’s introduce a couple of primitives on which the modules are built, so we
    understand the tools we are going to use.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first primitive is called `token`, and correspondingly it allows us to
    parse a `Token s`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The first argument of `token` is the matching function for the token to parse.
    If the function returns something in `Just`, that value becomes the result of
    parsing. `Nothing` indicates that the parser does not accept this token and so
    the primitive fails.
  prefs: []
  type: TYPE_NORMAL
- en: The second argument is a `Set` (from the `containers` package) that contains
    all expected `ErrorItem`s to be displayed to the user in case of failure. We will
    explore the `ErrorItem` type in details when we will be discussing parse errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'To better understand how `token` works, let’s see some definitions from the
    `Text.Megaparsec` module which contains, among other things, some combinators
    that work with all types of input stream. `satisfy` is a fairly common combinator,
    we give it a predicate that returns `True` for tokens we want to match and it
    gives us a parser back:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The job of `testToken` is to turn the `f` function which returns `Bool` into
    a function that returns `Maybe (Token s)` that `token` expects. With `satisfy`
    we do not know exact sequence of tokens that we expect to match, thus we pass
    `Set.empty` as the second argument.
  prefs: []
  type: TYPE_NORMAL
- en: '`satisfy` should look understandable, let’s see how it works. To play with
    a parser we need a helper function that would run it. For testing in GHCi `megaparsec`
    provides `parseTest`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s start GHCi and import some modules:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We add the `Parser` type synonym that we will use to resolve ambiguity in the
    type of the parsers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We also need to enable the `OverloadedStrings` language extension so we can
    use string literals as `Text` values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '*The `:: Parser Char` annotation is necessary because `satisfy` by itself is
    polymorphic, so `parseTest` cannot know what to use in place of `e` and `s` in
    `MonadParsec e s m` (`m` is assumed to be `Identity` with these helpers). If we
    worked with a pre-existing parser which had a type signature, the explicit clarification
    of parser type would be unnecessary.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'That seems to work all right. The problem with `satisfy` is that it does not
    say what is expected when it fails, because we cannot analyze the function which
    the caller of `satisfy` provides. There are other combinators that are less general,
    but they can generate more helpful error messages. For example `single` (with
    type-constrained synonyms called `char` in `Text.Megaparsec.Byte` and `Text.Megaparsec.Char`)
    which matches a specific token value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `Tokens` data type constructor has nothing in common with the type function
    `Tokens` that we have discussed previously. In fact, `Tokens` is one of constructors
    of `ErrorItem` and it is used to specify concrete sequence of tokens we expected
    to match.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now define `newline` from the table above:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The second primitive is called `tokens` and it allows us to parse `Tokens s`,
    that is, it can be used to match a fixed chunk of input:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'There are also two parsers defined in terms of `tokens`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: They match fixed chunks of input, `chunk` (which has type-constrained synonyms
    called `string` in `Text.Megaparsec.Byte` and `Text.Megaparsec.Char`) case-sensitively,
    while `string'` case-insensitively. For case-insensitive matching the `case-insensitive`
    package is used, thus the `FoldCase` constraint.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try to use the new combinators:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: OK, we can match a single token and a chunk of input. The next step is to learn
    how to combine the building blocks to write more interesting parsers.
  prefs: []
  type: TYPE_NORMAL
- en: Monadic and applicative syntax
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The simplest way to combine parsers is to execute them in succession. `ParsecT`
    and `Parsec` are monads, and monadic bind is exactly what we use for sequencing
    our parsers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'We can run it to check that everything works as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'An alternative syntax for sequential execution is possible if we remember that
    every monad is also an applicative functor, and so we can use applicative syntax:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The second version works just like the first. Which style to use is often a
    matter of taste. Monadic style is arguably more verbose and sometimes clearer,
    while applicative style is often more concise. That said, monadic style is of
    course more powerful because monads are more powerful than applicative functors.
  prefs: []
  type: TYPE_NORMAL
- en: Forcing consumption of input with `eof`
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`Applicative` is often powerful enough to allow doing quite interesting things.
    Equipped with an associative operator which has identity, we get a monoid on applicative
    functors expressed in Haskell via the `Alternative` type class. The [`parser-combinators`](https://hackage.haskell.org/package/parser-combinators)
    package provides quite a few abstract combinators built on the concepts of `Applicative`
    and `Alternative`. The `Text.Megaparsec` module re-exports them from `Control.Applicative.Combinators`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the most common combinators is called `many`. It allows us to run a
    given parser *zero* or more times:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: The second result may be a bit surprising. The parser consumed `a`s that matched,
    but stopped after that. Well, we did not say what we want to do after `many (char
    'a')`!
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of the time we want to actually force parser to consume entire input,
    and report parse errors instead of being shy and stopping silently. This is done
    by demanding that we reach the end of input. Happily, although the end of input
    is nothing but a concept, there is a primitive called `eof :: MonadParsec e s
    m => m ()` that does not ever consume anything and only succeeds at the end of
    input. Let’s add it to our parser and try again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We did not say anything about `b`s in our parser, and they are certainly unexpected.
  prefs: []
  type: TYPE_NORMAL
- en: Working with alternatives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'From now on we will be developing a real, useful parser that can parse URIs
    of the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: We should remember that things in square brackets `[]` are optional, they may
    or may not appear in a valid URI. `[]` may be even nested to express a possibility
    inside another possibility. We will handle all of this [¹](#fn1).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with `scheme`. We will accept only schemes that are known to us,
    such as: `data`, `file`, `ftp`, `http`, `https`, `irc`, and `mailto`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To match a fixed sequence of characters we use `string`. To express a choice,
    we use the `(<|>)` method from the `Alternative` type class. So we can write:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s try it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Looks good, but the defintion of `pScheme` is a bit repetitive. There is a
    way to write `pScheme` with the `choice` combinator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '*`choice` is just a synonym for `asum`—an operation that folds a list putting
    `(<|>)` between its elements, so the two definitions of `pScheme` are actually
    the same, although the one which uses `choice` may look a bit nicer.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'After the scheme, there should be a colon `:`. Recall that to require something
    to go after something else, we use monadic bind or `do`-notation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'If we try to run `pUri`, we will see that it requires `:` to follow the scheme
    name now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We are not done with the scheme parsing though. A good Haskell programmer tries
    to define types in such a way so that incorrect data cannot be represented. Not
    every `Text` value is a valid scheme. Let’s define a data type to represent schemes
    and make our `pScheme` parser return value of that type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '*The `(<$)` operator just puts the value on its left-hand side into a functorial
    context replacing whatever is there at the moment. `a <$ f` is the same as `const
    a <$> f`, but can be more efficient for some functors.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s continue playing with our parser:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Hmm, `https` should be a valid scheme. Can you figure out what went wrong?
    The parser tries the alternatives one by one, and `http` matches, so it does not
    go further to try `https`. The solution is to put the `SchemeHttps <$ string "https"`
    line before the `SchemeHttp <$ string "http"` line. Remember: *with alternatives,
    order matters!*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now `pUri` works correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Controlling backtracking with `try`
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The next part to handle is `[//[user:password@]host[:port]]`—the authority.
    Here we have nested optional parts, let us update the `Uri` type to reflect this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we need to discuss an important concept called *backtracking*. Backtracking
    is a way to travel back in time “un-consuming” input in the process. This is important
    primarily with branching. Here is an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Looks reasonable, let’s try it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: What happens here is that `char 'a'` part of `foo` (which is tried first) succeeded
    and consumed an `a` from the input stream. `char 'b'` then failed to match against
    `'c'` and so we ended up with this error. An important detail here is that `(<|>)`
    did not even try `bar` because `foo` has consumed some input!
  prefs: []
  type: TYPE_NORMAL
- en: 'This is done for performance reasons and because it would make no sense to
    run `bar` feeding it leftovers of `foo` anyway. `bar` wants to be run from the
    same point in the input stream as `foo`. `megaparsec` does not go back automatically,
    unlike for example `attoparsec` or the toy combinators from the previous chapter,
    so we must use a primitive called `try` to express our wish to backtrack explicitly.
    `try p` makes it so that if `p` fails consuming input, `try p` fails as if no
    input has been consumed (in fact, it backtracks the entire parser state). This
    allows `(<|>)` to try its right-hand alternative:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'All primitives that actually consume input (there are also primitives that
    alter behavior of existing parsers, such as `try` itself) are “atomic” in terms
    of input consumption. This means that if they fail, they backtrack automatically,
    so there is no way they can consume some input and then fail halfway through.
    This is why `pScheme` with its list of alternatives works: `string` is defined
    on top of `tokens` and `tokens` is a primitive. We either match the entire string
    with `string` or we fail without consuming input stream at all.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Back to parsing URIs, `(<|>)` can be used to build a handy combinator called
    `optional`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'If `p` in `optional p` matches, we get its result in `Just`, otherwise `Nothing`
    is returned. Just what we want! There is no need to define `optional`, `Text.Megaparsec`
    re-exports this combinator for us. We can now use it in `pUri`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '*I took the liberty of accepting any alpha-numeric sequences of characters
    as username and password, and made similarly arbitrary simplifications in the
    format of the host.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Some important points here:'
  prefs: []
  type: TYPE_NORMAL
- en: In (1) and (2) we need to wrap the argument of `optional` with `try` because
    it is a composite parser, not a primitive.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(3) `some` is just like `many`, but demands that its argument parser matches
    at least once: `some p = (:) <$> p <*> many p`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (4) Do not use `try` unless necessary! Here if `char ':'` succeeds (which is
    by itself built on top of `token`, so it does not need a `try`), we know for sure
    that port must follow after it, so we just demand a decimal number with `L.decimal`.
    After matching `:`, we are committed and do not need a way to go back.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In (5) and (6) we assemble `Authority` and `Uri` values using the `RecordWildCards`
    language extension.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`void :: Functor f => f a -> f ()` is used to explicitly discard the result
    to parsing, without it we would get warnings about unused values from GHC.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Play with `pUri` in GHCi and see for yourself that it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Debugging parsers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'However, you may find that there is a problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'The parse error could be better! What to do? The easiest way to figure out
    what is going on is to use the built-in `dbg` helper from the `Text.Megaparsec.Debug`
    module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The `VisualStream` type class is defined for input streams that can be printed
    out on the screen in readable form. We will not dwell on it here.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s use it in `pUri`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Then let’s try running `pUri` on that unfortunate input again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see what exactly is going on inside `megaparsec` now:'
  prefs: []
  type: TYPE_NORMAL
- en: '`scheme` matches successfully.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`user` fails: although there is a username in place `mark`, there is no password
    after the column `:` (we demand that the password is not empty here). We fail
    and thanks to `try`, backtrack.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`host` starts from the same point as `user` and tries now to interpret input
    as hostname. We can see that it succeeds and returns `mark` as host name.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There may be a port number after host, so `port` gets its chance now. It sees
    `:`, but after that there is no integer, so `port` fails as well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The whole `auth` parser thus fails (`port` is inside of `auth` and it has failed).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `auth` parser returns `Nothing` because it could not parse anything. Now
    `eof` demands that we have reached the end of input, but it is not the case, so
    we get the final error message.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'What to do? This is an example of a situation when using `try` enclosing large
    portions of code may make parse errors worse. Let us take another look at the
    syntax we want to parse:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'What are we looking for? Something that would allow us to commit to certain
    branch of parsing. Just like with port where when we see column `:` we are sure
    port number must follow. If you look carefully, you will see that the double slash
    `//` is the sign that we have the authority part in our URI. Since we match `//`
    with an “atomic” parser (`string`), matching on it backtracks automatically, and
    after we have matched `//`, we can be sure to demand the authority part. Let us
    remove the first `try` from `pUri`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we get a nicer parse error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: Although it is still a bit misleading, but well, that is a tricky example I
    have picked. Lots of `optional`s.
  prefs: []
  type: TYPE_NORMAL
- en: Labeling and hiding things
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sometimes the list of expected items may get rather long. Remember what we get
    when we try to use a non-recognized scheme?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '`megaparsec` provides a way to override expected items with something custom,
    typically called a *label*. This is done with the help of the `label` primitive
    (which has a synonym in the form of the `(<?>)` operator):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'We can go on and add more labels to make errors messages more human-readable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Another primitive is called `hidden`. If `label` renames things, `hidden` just
    removes them altogether. Compare:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '`hidden` is useful when it is desirable to make error messages less noisy.
    For example, when parsing a programming language it is a good idea to drop “expecting
    white space” messages because usually there may be white space after each token
    anyway.'
  prefs: []
  type: TYPE_NORMAL
- en: '*EXERCISE: Finishing the `pUri` parser is left as an exercise for the reader,
    now that all the tools that are necessary for this have been explained.*'
  prefs: []
  type: TYPE_NORMAL
- en: Running a parser
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We explored in details how to construct parsers, but we haven’t inspected the
    functions that allow us to run them, except for `parseTest`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditionally, the “default” function to run a parser from your program has
    been `parse`. But `parse` is actually a synonym for `runParser`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: The second argument is just a file name which will be included in the generated
    parse errors, `megaparsec` is not going to read anything from that file, because
    the actual input comes as the third argument of the function.
  prefs: []
  type: TYPE_NORMAL
- en: '`runParser` allows us to run the `Parsec` monad which, as we already know,
    is the non-transformer version of `ParsecT`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '`runParser` has 3 siblings: `runParser''`, `runParserT`, and `runParserT''`.
    The versions with the `T` suffix run `ParsecT` monad transformer, and the “prime”
    versions take and return parser state. Let’s put all the functions into a table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Arguments | Runs `Parsec` | Runs `ParsecT` |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Input and file name | `runParser` | `runParserT` |'
  prefs: []
  type: TYPE_TB
- en: '| Custom initial state | `runParser''` | `runParserT''` |'
  prefs: []
  type: TYPE_TB
- en: 'Custom initial state may be necessary if you e.g. want to set tab width to
    some non-standard value (the default value is `8`). As an example, here is the
    type signature of `runParser''`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Modifying `State` manually is advanced usage of the library, and we are not
    going to describe it here.
  prefs: []
  type: TYPE_NORMAL
- en: If you wonder what is `ParseErrorBundle`, we’ll discuss it in [one of the following
    sections](#parse-errors).
  prefs: []
  type: TYPE_NORMAL
- en: The `MonadParsec` type class
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: All tools in `megaparsec` work with any instance of the `MonadParsec` type class.
    The type class abstracts *primitive combinators*—the elementary building blocks
    of all `megaparsec` parsers, combinators that cannot be expressed via other combinators.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having primitive combinators in a type class allows the principal concrete
    monad transformer of `megaparsec` `ParsecT` to be wrapped in the familiar transformers
    of the MTL family achieving different interactions between layers of a monadic
    stack. To better understand the motivation, recall that the order of layers in
    a monadic stack matters. If we combine `ReaderT` and `State` like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'the outer layer, `ReaderT` cannot inspect the internal structure of the underlying
    `m` layer. The `Monad` instance for `ReaderT` describes the binding strategy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: In fact, the only thing that we know about `m` is that it is an instance of
    `Monad` and so the state of `m` can only be passed to `k` via monadic bind. That
    is what we typically want from `(>>=)` of `ReaderT` anyway.
  prefs: []
  type: TYPE_NORMAL
- en: The `(<|>)` method of the `Alternative` type class works differently—it “splits”
    state and the two branches of parsing do not contact anymore, so we get *backtracking
    state* in the sense that if the first branch is discarded changes to its state
    are also discarded and cannot influence the second branch (we “backtrack” the
    state when the first branch fails).
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate, let us see the definition of `Alternative` for `ReaderT`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: This all is very nice, because `ReaderT` is a “stateless” monad transformer
    and it is easy to delegate the actual work to the inner monad (the `Alternative`
    instance of `m` comes in handy here) without needing to combine monadic state
    associated with `ReaderT` itself (it has none).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s take a look at `State`. Since `State s a` is just a type synonym
    for `StateT s Identity a`, we should look at the `Alternative` instance for `StateT
    s m` itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we can see the splitting of state `s`, just like we saw sharing of the
    reader context `r`. There is a difference though, because the expressions `m s`
    and `n s` produce stateful results: together with monadic value, they return the
    new state in a tuple. Here we either go with `m s` or with `n s`, naturally achieving
    backtracking.'
  prefs: []
  type: TYPE_NORMAL
- en: 'What about `ParsecT`? Let us consider now putting `State` inside `ParsecT`
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '`ParsecT` is more complex than `ReaderT` and its implementation of `(<|>)`
    has to do more:'
  prefs: []
  type: TYPE_NORMAL
- en: managing of the state of the parser itself;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: merging of parse errors (when appropriate), should they happen.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementation of `(<|>)` in `ParsecT`‘s instance of `Alternative` thus cannot
    delegate its work to the `Alternative` instance of the underlying monad `State
    MyState` and so no splitting of `MyState` happens—we have no backtracking.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us demonstrate this with an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the result of running the program:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: With `parser0` we can see that the branch `b` is not tried. With `parser1` however
    it is obvious that the final result—the value returned by `get` —comes from the
    branch `a` even though it fails because of `empty` and it is the branch `b` that
    succeeds (`empty` in the context of parsing means “fail instantly and without
    any information about what has happened”). No backtracking happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'What to do if we want backtracking custom state in our parser? We can provide
    that if we allow to wrap `ParsecT` *inside* `StateT`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Now if we use `(<|>)` in `MyStack` the instance used is that of `StateT`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Which gives us backtracking state and then delegates the rest of the work to
    `Alternative` instance of its inner monad—`ParsecT`. This behavior is exactly
    what we want:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'The program prints:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'To make this approach feasible, `StateT` should support the whole set of primitive
    parsers, so we can work with it just like with `ParsecT`. In other words, it should
    be an instance of `MonadParsec`, just like it is an instance of not only `MonadState`,
    but also e.g. `MonadWriter` if its inner monad is an instance of `MonadWriter`
    (in MTL):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'Indeed, we can lift primitives from inner instance of `MonadParsec` into `StateT`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: '`megaparsec` defines instances of `MonadParsec` for all MTL monad transformers
    so that the user is free to insert the transformers inside of `ParsecT` or wrap
    `ParsecT` in those transformers achieving different kinds of interactions between
    the layers of monadic stack.'
  prefs: []
  type: TYPE_NORMAL
- en: Lexing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Lexing* is the process of transforming the input stream into a stream of tokens:
    integers, keywords, symbols, etc. which are easier to parse than the raw input
    directly, or are expected as input to parsers created with parser generators.
    Lexing can be performed in a separate pass with an external tool such as `alex`,
    but `megaparsec` also provides functions that should simplify writing a lexer
    in a seamless fashion, as part of your parser.'
  prefs: []
  type: TYPE_NORMAL
- en: There are two lexer modules `Text.Megaparsec.Char.Lexer` for character streams
    and `Text.Megaparsec.Byte.Lexer` for byte streams. We will be using `Text.Megaparsec.Char.Lexer`
    because we work with a strict `Text` as the input stream, but most functions are
    mirrored in `Text.Megaparsec.Byte.Lexer` as well if you wish to work with `ByteString`s.
  prefs: []
  type: TYPE_NORMAL
- en: White space
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first topic we need to cover is dealing with white space. It is helpful
    to consume white space in a consistent manner either before every token or after
    every token. Megaparsec’s lexer modules follow the strategy “assume no white space
    before token and consume all white space after token”.
  prefs: []
  type: TYPE_NORMAL
- en: 'To consume white space we need a special parser that we will refer to as *space
    consumer*. The `Text.Megaparsec.Char.Lexer` module provides a helper allowing
    to build a general space consumer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'The documentation for the `space` function is quite comprehensive by itself,
    but let us complement it with an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Some notes:'
  prefs: []
  type: TYPE_NORMAL
- en: The `Text.Megaparsec.Char.Lexer` is intended to be imported qualified because
    it contains names that collide with names from e.g. `Text.Megaparsec.Char`, for
    example `space`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first argument of `L.space` should be a parser that is to be used to pick
    up white space. An important detail is that it should not accept empty input because
    then `L.space` would go into an infinite loop. `space1` is a parser from `Text.Megaparsec.Char`
    that meets the requirements perfectly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second argument of `L.space` defines how to skip line comments, that is,
    comments that start with a given sequence of tokens and end with the end of line.
    The `skipLineComment` helper allows us to craft an auxiliary parser for line comments
    easily.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The third argument of `L.space` in turn defines how to pick up block comments:
    everything between starting and ending sequences of tokens. The `skipBlockComment`
    helper allows us to deal with non-nested block comments. If supporting nested
    block comments is desirable, `skipBlockCommentNested` should be used instead.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operationally, `L.space` tries all three parsers in turn as many times as it
    can till all of them cannot be applied anymore meaning that we have consumed all
    white space there is. Knowing this, it should make sense that if your grammar
    does not include block or line comments, you can just pass `empty` as the second
    and/or third argument of `L.space`. `empty`, being the identity of `(<|>)`, will
    just cause `L.space` to try the parser for the next white space component—exactly
    what is desirable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Having the space consumer `sc`, we can then define various white space-related
    helpers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '`lexeme` is a wrapper for lexemes that picks up all trailing white space using
    the supplied space consumer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`symbol` is a parser that matches given text using `string` internally and
    then similarly picks up all trailing white space.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will see how it all works together in a moment, but first we need to introduce
    a couple more helpers from `Text.Megaparsec.Char.Lexer`.
  prefs: []
  type: TYPE_NORMAL
- en: Char and string literals
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Parsing character and string literals can be tricky because of various escaping
    rules. To make life easier, `megaparsec` provides the `charLiteral` parser:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'The job of `charLiteral` is to parse a single character that may be escaped
    according to the syntax for character literals described in the Haskell report.
    Note that it does not parse quotes around the literal though for two reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: so the user can control how character literals are quoted,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: so `charLiteral` can be used to parse string literals as well.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are some example parsers built on top of `charLiteral`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'To turn `L.charLiteral` into a parser for char literals we only need to add
    the enclosing quotes. Here we follow Haskell syntax and use single quotes. The
    `between` combinator is defined simply as: `between open close p = open *> p <*
    close`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`stringLiteral` uses `L.charLiteral` to parse individual characters inside
    a string literal enclosed in double quotes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The second function is also interesting because of its use of the `manyTill`
    combinator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '`manyTill` tries to apply the `end` parser on every iteration and if it fails,
    it then runs the `p` parser and accumulates results of `p` in a list.'
  prefs: []
  type: TYPE_NORMAL
- en: There is also `someTill` for when you want to demand that at least one item
    is present.
  prefs: []
  type: TYPE_NORMAL
- en: Numbers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Finally, a very common need is to parse numbers. For integral numbers, there
    are three helpers that can parse values in decimal, octal, and hexadecimal representations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Using them is easy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '`scientific` accepts integer and fractional grammars, while `float` accepts
    only fractional grammars. `scientific` returns the `Scientific` type from the
    `scientific` package, while `float` is polymorphic in its result type and can
    return any instance of `RealFloat`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that all these parsers do not parse signed numbers. To make a parser for
    signed numbers, we need to wrap an existing parser with the `signed` combinator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: The first argument of `signed`—the space consumer—controls how white space is
    consumed between the sign and actual numeral. If you do not want to allow space
    in there, just pass `return ()` instead.
  prefs: []
  type: TYPE_NORMAL
- en: '`notFollowedBy` and `lookAhead`'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are two more primitives (in addition to `try`) that can perform look ahead
    in the input stream without actually advancing the parsing position in it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first one is called `notFollowedBy`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: It succeeds only when its argument parser fails and never consumes any input
    or modifies the parser state.
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example when you may want to use `notFollowedBy`, consider parsing of
    keywords:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: 'This parser has a problem: what if the keyword we are matching against is just
    a prefix of an identifier? In that case it is definitely not a keyword. Thus we
    must eliminate that case by using `notFollowedBy`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'Another primitive is `lookAhead`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: If the argument `p` of `lookAhead` succeeds, the whole construct `lookAhead
    p` also succeeds but the input stream (and the entire parser state) stays untouched,
    i.e. nothing is consumed.
  prefs: []
  type: TYPE_NORMAL
- en: 'One example of where this may be useful is performing a check on an already
    parsed value and then either failing or continuing successfully. The idiom can
    be expressed in code like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 'This demonstrates a use of `lookAhead`, but we also should note that when the
    check if successful we perform the parsing twice, which is not good. Here is an
    alternative solution using the `getOffset` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: This way we just set offset in the input stream to what if was before running
    `p` and then fail. There is a mismatch now in what remains unconsumed vs offset
    position, but it does not matter in this case because we end parsing immediately
    by calling `fail`. It may matter in other cases. We will see how to do better
    in situations like this later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing expressions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'By “expression” we mean a structure formed from terms and operators applied
    to those terms. Operators can be prefix, infix, and postfix, left and right-associative,
    with different precedence. An example of such a construct would be arithmetic
    expressions familiar from school:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we can see two kinds of terms: variables (`a` and `b`) and integers (`2`).
    There are also two operators: `*` and `+`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Writing an expression parser may take a while to get right. To help with that,
    the [`parser-combinators`](https://hackage.haskell.org/package/parser-combinators)
    package comes with the `Control.Monad.Combinators.Expr` module which exports only
    two things: the `Operator` data type and the `makeExprParser` helper. Both are
    well documented, so in this section we will not repeat the documentation, instead
    we are going to write a simple but fully functional expression parser.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start by defining a data type representing an expression as [AST](https://en.wikipedia.org/wiki/Abstract_syntax_tree):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'To use `makeExprParser` we need to provide it with a term parser and an operator
    table:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s start with the term parser. It is helpful to think about term as a box
    that that is to be considered as an indivisible whole by the expression parsing
    algorithm when it works with things like associativity and precedence. In our
    case there are three things that fall into this category: variables, integers,
    and entire expressions in parentheses. Using the definitions from previous chapters
    we can define the term parser as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'The definitions of `pVariable`, `pInteger`, and `parens` should go without
    questions by now. We are also quite lucky here in that we do not need `try`s in
    `pTerm` because the grammars do not overlap:'
  prefs: []
  type: TYPE_NORMAL
- en: if we see an opening parenthesis `(`, we know that an expression in parentheses
    is to follow, so we commit to that branch;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: if we see a letter, we know that it is the start of an identifier;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: if we see a digit, we know that it is the start of an integer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, to finish `pExpr` we need to define the `operatorTable`. We can see
    from the type that it is a nested list. Every inner list is a list of operators
    we want to support, they all have equal precedence. The outer list is ordered
    in descending precedence, so the higher we place a group of operators in it, the
    tighter they bind:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: Note how we place `Parser (Expr -> Expr -> Expr)` inside `InfixL` in `binary`
    and similarly `Parser (Expr -> Expr)` in `prefix` and `postfix`. That is, we run
    `symbol name` and return a function to apply to the terms in order to get the
    final result of the type `Expr`.
  prefs: []
  type: TYPE_NORMAL
- en: We can now try our parser, it is ready!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: Documentation for the `Control.Monad.Combinators.Expr` module contains some
    hints that are useful in certain less-standard situations, so it is a good idea
    to read it as well.
  prefs: []
  type: TYPE_NORMAL
- en: Indentation-sensitive parsing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The `Text.Megaparsec.Char.Lexer` module contains tools that should be helpful
    when parsing indentation-sensitive grammars. We are going to review the available
    combinators first, then put them into use by writing an indentation-sensitive
    parser.
  prefs: []
  type: TYPE_NORMAL
- en: '`nonIndented` and `indentBlock`'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s start with the simplest thing—`nonIndented`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: It allows us to make sure that its inner parser consumes input that is *not*
    indented. It is a part of a model behind high-level parsing of indentation-sensitive
    input. We state that there are top-level items that are not indented and that
    all indented tokens are directly or indirectly children of those top-level definitions.
    In `megaparsec`, we do not need any additional state to express this. Since indentation
    is always relative, our idea is to explicitly tie parsers for reference tokens
    and indented tokens, thus defining indentation-sensitive grammar via pure combination
    of parsers.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, how do we define a parser for indented block? Let’s take a look at the
    signature of `indentBlock`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: First, we specify how to consume indentation. An important thing to note here
    is that this space-consuming parser *must* consume newlines as well, while tokens
    (reference token and indented tokens) should not normally consume newlines after
    them.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the second argument allows us to parse reference token and
    return a data structure that tells `indentBlock` what to do next. There are several
    options:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: We can change our mind and parse no indented tokens, we can parse *many* (that
    is, possibly zero) indented tokens or require *at least one* such token. We can
    either allow `indentBlock` to detect the indentation level of the first indented
    token and use that, or manually specify the indentation level.
  prefs: []
  type: TYPE_NORMAL
- en: Parsing a simple indented list
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s parse a simple indented list of some items. We begin with the import
    section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'We will need two kinds of space-consumers: one that consumes new lines `scn`
    and one that does not `sc` (actually it only parses spaces and tabs here):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: Just for fun, we allow line comments that start with `#`.
  prefs: []
  type: TYPE_NORMAL
- en: '`pItemList` is a top-level form that itself is a combination of reference token
    (header of list) and indented tokens (list items), so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'For our purposes, an item is a sequence of alpha-numeric characters and dashes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s load the code into GHCi and try it with the help of `parseTest` built-in:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: Remember that we are using the `IndentMany` option, so empty lists are OK, on
    the other hand the built-in combinator `space` has hidden the phrase “expecting
    more space” from error messages, so this error message is perfectly reasonable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s continue:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s replace `IndentMany` with `IndentSome` and `Nothing` with `Just (mkPos
    5)` (indentation levels are counted from 1, so it will require 4 spaces before
    indented items):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'Now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: The first message may be a bit surprising, but `megaparsec` knows that there
    must be at least one item in the list, so it checks the indentation level and
    it is 1, which is incorrect, so it reports it.
  prefs: []
  type: TYPE_NORMAL
- en: Nested indented list
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s allow list items to have sub-items. For this we will need a new parser,
    `pComplexItem`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'If we feed something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'into our parser, we will get:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: This demonstrates how this approach scales for nested indented construts without
    requiring additional state.
  prefs: []
  type: TYPE_NORMAL
- en: Adding line folds
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *line fold* consists of several elements that can be put on one line or on
    several lines as long as the indentation level of the subsequent items is greater
    than the indentation level of the first item.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s make use of another helper called `lineFold`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: '`lineFold` works like this: we give it a space consumer that accepts newlines
    `scn` and it gives back a special space consumer `sc''` that we can use in the
    callback to consume space between elements of line fold.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Why use `try sc''` and `scn` on the line (1)? The situation is the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Components of a line fold can only be more indented than its start.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sc''` consumes whitespace with newlines in such a way that after consuming
    whitespace the column number is greater than initial column.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To stop, `sc'` should encounter the opposite situation, that is, the column
    number after consumption should be less than or equal to the initial column. At
    that point it fails without consuming input (thanks to `try`) and `scn` is used
    to pick up whitespace before that new thing that will start at that column.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Previously used `sc'` already probed whitespace with space consumer which consumes
    newlines. So, it is only logical to also consume newlines when picking up trailing
    whitespace. This is why `scn` is used on the line (1) and not `sc`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*EXERCISE: Playing with the final version of our parser is left as an exercise
    for the reader. You can create “items” that consist of multiple words and as long
    as they are line-folded they will be parsed and concatenated with single space
    between them.*'
  prefs: []
  type: TYPE_NORMAL
- en: Writing efficient parsers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s discuss what to attempt in order to improve performance of a `megaparsec`
    parser. It should be noted right away that one should always check if there is
    any improvement through profiling and benchmarking. That is the only way to understand
    if we are doing the right thing when tuning performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Common pieces of advice:'
  prefs: []
  type: TYPE_NORMAL
- en: If your parser uses a monad stack instead of the plain `Parsec` monad (recall
    that it is the `ParsecT` monad transformer over `Identity`, which is quite lightweight),
    make sure you use at least version 0.5 of `transformers` library, and at least
    version 7.0 of `megaparsec`. Both libraries have critical performance improvements
    in these versions, so you can just get better performance for free.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Parsec` monad will be always faster then `ParsecT`-based monad transformers.
    Avoid using `StateT`, `WriterT`, and other monad transformers unless absolutely
    necessary. The more you add to the monadic stack, the slower your parser will
    be.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backtracking is an expensive operation. Avoid building long chains of alternatives
    where every alternative can go deep into input before failing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do not keep your parsers polymorphic unless you really have a reason to do so.
    It is best to fix the types of parsers specifying concrete types, such as `type
    Parser = Parsec Void Text` for every top-level definition. This way GHC will be
    able to optimize better.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inline generously (when it makes sense, of course). You may not believe your
    eyes when you see how much of a difference inlining can do, especially for short
    functions. This is especially true for parsers that are defined in one module
    and used in another one, because `INLINE` and `INLINEABLE` pragmas make GHC dump
    function definitions into interface files and this facilitates specializing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the fast primitives such as `takeWhileP`, `takeWhile1P`, and `takeP` whenever
    you can. [This blog post](https://markkarpov.com/post/megaparsec-more-speed-more-power#there-is-hope)
    explains why they are so fast.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid `oneOf` and `noneOf` preferring `satisfy` and `anySingleBut` whenever
    possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While most of the points above do not require additional comment, I think it
    would be beneficial to get into the habit of using the newer fast primitives:
    `takeWhileP`, `takeWhile1P`, and `takeP`. The first two are especially common
    as they allow us to replace `many` and `some`-based constructs making them faster
    and changing the type of returned data to chunk of input stream, i.e. the `Tokens
    s` type we have discussed previously.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, recall that when we parsed URIs, we had this code for parsing
    username in the authority component:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'We can replace it by `takeWhile1P`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: When we parse `ByteString`s and `Text`, this will be a lot faster than the original
    approach. Also note that `T.pack` is not necessary anymore as we get `Text` directly
    from `takeWhile1P`.
  prefs: []
  type: TYPE_NORMAL
- en: 'These equations may be helpful for understanding the meaning of the `Maybe
    String` argument of `takeWhileP` and `takeWhile1P`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: Parse errors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have explored how to use most features of `megaparsec`, it is time
    to learn more about parse errors: how they are defined, how to signal them, and
    how to process them inside a running parser.'
  prefs: []
  type: TYPE_NORMAL
- en: Parse error definitions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `ParseError` type is defined like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: 'In English: a `ParseError` is either a `TrivialError` with at most one unexpected
    item and a (possibly empty) collection of expected items or a `FancyError`.'
  prefs: []
  type: TYPE_NORMAL
- en: '`ParseError s e` is parametrized over two type variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '`s` is the type of input stream.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`e` is the type of custom component of parse error.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ErrorItem` is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: '`NonEmpty` is a type for non-empty lists, it comes from `Data.List.NonEmpty`.
    And here is `ErrorFancy`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: '`ErrorFancy` includes data constructors for two common cases `megaparsec` supports
    out-of-the-box:'
  prefs: []
  type: TYPE_NORMAL
- en: Use of the `fail` function that causes parser to fail reporting an arbitrary
    `String`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Indentation-related issues which we have seen in a previous section. Since we
    provide tools for working with indentation-sensitive grammars out-of-the-box,
    we need a way to store well-typed information about problems with indentation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, `ErrorCustom` is a sort of an “extension slot” which allows to embed
    arbitrary data into the `ErrorFancy` type. When we do not need any custom data
    in our parse errors, we parametrize `ErrorFancy` by `Void`. Since `Void` is not
    inhabited by non-bottom values, `ErrorCustom` becomes “cancelled out” or, if we
    follow the analogy between algebraic data types and numbers, “multiplied by zero”.
  prefs: []
  type: TYPE_NORMAL
- en: In older version of the library, `ParseError`s were returned directly by functions
    like `parse`, but version 7 delays calculation of line and column for each error,
    as well as fetching of the relevant line on input for displaying in case of an
    error. This is done to be make parsing faster, because all this information is
    usually useful only when a parser fails. Another problem of older versions of
    the library is that displaying several parse errors at once required re-traversal
    of input each time to fetch the right line.
  prefs: []
  type: TYPE_NORMAL
- en: 'The problem is solved with the `ParseErrorBundle` data type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: All parser-running functions return `ParseErrorBundle` with a correctly set
    `bundlePosState` and a collection `ParseError`s inside.
  prefs: []
  type: TYPE_NORMAL
- en: How to signal a parse error
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let’s discuss different ways to signal a parse error. The simplest function
    for that is `fail`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: For many people who are familiar with simpler parsing libraries such as `parsec`
    this is often enough. However, displaying a parse error to the user is not everything,
    we may have a need to analyze and/or manipulate it. This is where `String`s are
    not very convenient.
  prefs: []
  type: TYPE_NORMAL
- en: 'Trivial parse errors are usually generated by `megaparsec`, but we can signal
    any such an error ourselves using the `failure` combinator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: Unlike the `fail`-based approach, trivial parse errors are easy to pattern-match
    on, inspect, and modify.
  prefs: []
  type: TYPE_NORMAL
- en: 'For fancy errors we correspondingly have the `fancyFaliure` combinator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: 'With `fancyFailure`, it is often desirable to define a helper like the one
    we have in the lexer modules instead of calling `fancyFailure` directly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: As an example of adding a custom parse error component to your parser, let’s
    go through defining a special parse error that says that given `Text` value is
    not a keyword.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to define the data type with constructors representing scenarios
    we want to support:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: 'And tell `megaparsec` how to display it in parse errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: 'Next we update our `Parser` type synonym:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: 'After that we can define the `notKeyword` helper:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: 'Where `customFailure` is a useful helper that comes from the `Text.Megaparsec`
    module:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let us try it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: Displaying parse errors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Displaying of `ParseErrorBundle`s is done with the `errorBundlePretty` function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: In 99% of cases you will only need this one function.
  prefs: []
  type: TYPE_NORMAL
- en: Catching parse errors in a running parser
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another useful feature of `megaparsec` is that it is possible to “catch” a
    parse error, alter it in some way, and then re-throw, [just like with exceptions](/tutorial/exceptions).
    This is enabled by the `observing` primitive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a complete program demonstrating typical usage of `observing`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: '*EXERCISE: Understand in details how this program works.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'If I run this program, I see the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: 'Thus, the feature can be used to attach location labels to parse errors, or
    indeed define *regions* in which parse errors are processed in some way. The idiom
    is quite useful, so there is even a non-primitive helper called `region` defined
    in terms of the `observing` primitive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: '*EXERCISE: Rewrite the `inside` function in the program above using `region`.*'
  prefs: []
  type: TYPE_NORMAL
- en: Controlling location of parse errors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The definition of `region` uses the `parseError` primitive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: 'It is the fundamental primitive for error reporting and all other functions
    we have seen so far are defined in terms of `parseError`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: 'One thing `parseError` allows you to do is to set error offset (that is, position)
    to something else than current position in input stream. Let’s return to the example
    with rejecting results of parsing retroactively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: We noted that `setOffset o` will make the error to be located correctly, but
    it will also invalidate the parser state as a side effect—the offset will not
    reflect reality anymore. This may be a real problem in more complex parsers. For
    example, imagine that you enclose `withPredicate2` with `observing` so that there
    will be some code running after `fail`.
  prefs: []
  type: TYPE_NORMAL
- en: 'With `parseError` and `region` we finally have proper solution to the problem—either
    use `region` to reset the parse error location, or use `parseError` in the first
    place:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: Reporting multiple parse errors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Finally, `megaparsec` allows us to signal several parse errors in a single run.
    This may be helpful for the end users because they will be able to fix several
    issues at once and so they will need to run your parser fewer times.
  prefs: []
  type: TYPE_NORMAL
- en: 'One prerequisite for having a multi-error parser is that it should be possible
    to skip over a problematic part of input and resume parsing from a position that
    is known to be good. This part is accomplished by using the `withRecovery` primitive:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: Before Megaparsec 8 users had to pick the type `a` to be a sum type including
    the possibilities for success and failure. For example, it could be `Either (ParseError
    s e) Result`. The parse errors had to be collected and later manually added to
    the `ParseErrorBundle` before displaying. Needless to say, all of this was an
    example of advanced usage that was not user friendly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Megaparsec 8 supports *delayed parse errors*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: These errors can be registered in the error-processing callback of `withRecovery`
    making the resulting type `Maybe Result`. This takes care of including the delayed
    errors in the final `ParseErrorBundle` as well as making the parser fail in the
    end if the collection of delayed errors in not empty.
  prefs: []
  type: TYPE_NORMAL
- en: With all this, we hope that the practice of writing multi-error parsers will
    become more common among the users.
  prefs: []
  type: TYPE_NORMAL
- en: Testing Megaparsec parsers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Testing a parser is a practical task most people face sooner or later, so we
    are bound to cover it. The recommended way to test `megaparsec` parsers is by
    using the [`hspec-megaparsec`](https://hackage.haskell.org/package/hspec-megaparsec)
    package. The package adds utility expectations such as `shouldParse`, `parseSatisfies`,
    etc. which work with the `hspec` testing framework.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: '`shouldParse` accepts `Either (ParseErrorBundle s e) a`—the result of parsing
    and a thing of the type `a` to compare with. It is probably the most common helper.
    `parseSatisfies` is quite similar, but instead of comparing for equality with
    the expected result, it allows to check the result by applying an arbitrary predicate.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Other simple expectations are `shouldSucceedOn` and `shouldFailOn` (although
    they are rarely used):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: 'With `megaparsec` we want to be precise about parse errors our parsers produce.
    To test parse errors there is `shouldFailWith`, which can be used like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: 'Writing out a `TrivialError` like this is tiresome. The definition of `ParseError`
    contains “inconvenient” types like `Set` and `NonEmpty` which are not handy to
    enter directly as we have just seen. Fortunately, `Test.Hspec.Megaparsec` also
    re-exports the `Text.Megaparsec.Error.Builder` module which provides an API for
    easier construction of `ParserError`s. Let us instead use the `err` helper:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: The first argument of `err` is offset of the parse error (the number of tokens
    that had been consumed before we got the error). In this example it is simply
    0.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`utok` stands for “unexpected token”, similarly `etok` means “expected token”.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*EXERCISE: Familiarize yourself with `errFancy`, which is used to construct
    fancy parse errors.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, it is possible to test what part of input remains unconsumed after
    parsing using `failsLeaving` and `succeedsLeaving`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: 'These should by used with `runParser''` or `runParserT''` which accept custom
    initial state of parser and return its final state (this is what allows us to
    check the leftover of the input stream after parsing):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: The `initialState` function takes the input stream and returns the initial state
    with that input stream and other record fields filled with their default values.
  prefs: []
  type: TYPE_NORMAL
- en: 'Other sources of inspiration for using `hspec-megaparsec` are:'
  prefs: []
  type: TYPE_NORMAL
- en: Working with custom input streams
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`megaparsec` can be used to parse any input that is an instance of the `Stream`
    type class. This means that it may be used in conjunction with a lexing tool such
    as `alex`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Not to digress from our main topic by presenting how a stream of tokens could
    be generated with `alex`, we will assume it in the following form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: 'To report parse errors though we need a way to know the token’s starting position,
    ending position, and length, so let’s add `WithPos`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can have a data type for our stream:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we need to make `MyStream` an instance of the `Stream` type class. This
    requires the `TypeFamilies` language extension because we want to define the associated
    type functions `Token` and `Tokens`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: '`Stream`, `VisualStream`, and `TraversableStream` are documented in the `Text.Megaparsec.Stream`
    module. Here we go straight to defining the methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: More background information about the `Stream` type class (and why it looks
    like this) can be found in [this blog post](https://markkarpov.com/post/megaparsec-more-speed-more-power).
    Note that in the version 9 of `megaparsec` certain methods of `Stream` were moved
    to the classes `VisualStream` and `TraversableStream` to make it easier to define
    instances of `Stream` for certain custom input streams.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can define `Parser` for our custom stream:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: The next step is to define basic parsers on top of `token` and (if it makes
    sense) `tokens` primitives. For the streams that are supported out-of-the-box
    we have `Text.Megaparsec.Byte` and `Text.Megaparsec.Char` modules, but if we are
    to work with custom tokens, we need custom helpers.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally let us have a test parser which parses a sum:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: 'And an example input for it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s try it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: 'If we change `Plus` on the line (1) to `Div`, we will get the correct parse
    error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: In other words, we have now a fully functional parser that parses a custom stream.
  prefs: []
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: There is actually the [`modern-uri`](https://hackage.haskell.org/package/modern-uri)
    package which contains a real-world Megaparsec parser which can parse URIs according
    to RFC 3986\. The parser from the package is much more complex than the one we
    describe here, though. [↩](#fnref1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
