<!--yml

category: 未分类

date: 2024-05-27 14:30:31

-->

# 分布式SQL流式数据库的案例

> 来源：[https://risingwave.com/blog/the-case-for-distributed-sql-streaming-databases/](https://risingwave.com/blog/the-case-for-distributed-sql-streaming-databases/)

## 介绍

上述声明可能显得挑衅，但其中确实有一定的真实性。随着企业努力利用数据来实施新的业务模式，显然现有的数据堆栈存在不足之处。传统的数据堆栈并未设计用于今天的超低延迟需求。在深入探讨新应用的新兴需求之前，重要的是退后一步，了解数据驱动型组织的期望。同样重要的是识别推动这些新需求的数据特征的共同趋势。

让我们回顾大约十年前的那段时光。那个时候，数据和分析领域的主要趋势无疑是“大数据”运动。思想领袖们将“大数据”定义为三个V：体量（Volume）、速度（Velocity）和多样性（Variety）。

简单来说，大数据指的是来自新源的大型复杂数据集。这些数据集对于传统软件来说太大，但它们可以用来解决以前无法解决的业务问题。

企业可以从大量数据中提取有意义的信息的潜力巨大。然而，由于缺乏处理如此大型数据集的工具，这一潜力仍然未被开发。像Hadoop这样的技术的引入预期能够释放这一潜力。然而，很显然，这些大数据技术主要集中在解决***体积***方面。因此，企业的广泛采用并不可行，因为大多数用户没有看到这些工具的需求或价值。

原因有多种，但主要原因之一是数据的有限生命周期。数据从业者面临的挑战是在数据的内在价值高时精确地实时访问数据。简单地将原始数据存储在数据湖中更像是一个数据转储，而不是利用宝贵资源。

另一个重要原因是数据工程实践的状态。即使数据可以访问，通常也难以以其原始形式进行分析。因此，复杂的提取-转换-加载（ETL）过程变得必要，以从数据中提取有价值的信息。数据仍然隔离在称为“数据孤岛”的单独系统中，并且与特定应用程序紧密相关联。数据源的集成最近通过消息队列和CDC连接器等机制得到改善。

数据特征的演变

在传统上，所有的数据从业者都关心以下特征：

这些特征已在关系数据库系统中得到处理。数据库系统的事务管理功能支持ACID属性以处理这些特征。

+   Atomicity: 通过全或无的语义确保**完整性**。

+   Consistency: 通过约束确保**数据准确性**。

+   Isolation: 为**数据完整性**和**正确性**提供保证。

+   Durability: 基于不可变写入确保**数据的可靠性**。

这些特性已经有效地解决了各种业务需求。当前的数据处理系统已经在任何数据堆栈中为这些特性提供了强大的支持。因此，企业已经能够执行依赖于静态数据快照的工作负载。虽然已经在通过各种优化来增强这些工作负载的速度和实时能力，但这些改进已不再足够。

在业界观察者中，越来越多的人一致认为将数据视为连续的无界流，而不是快照，具有重要价值。企业不再满足于了解过去发生了什么；相反，它们专注于预测未来结果，这需要在“实时”中分析数据。在这种情况下，“实时”是由数据延迟定义的，而不是查询延迟。为了更好地理解，我们需要建立一组新的特性来定义数据。

为了解决这些特性，需要一种新的数据处理范式。这种范式将：

+   处理离散粒度的事件数据。

+   连续处理实时数据。

+   集成多个数据流进行有状态处理。

早期流处理解决方案

需要一种新的数据处理堆栈来支持前文讨论的新范式。此数据堆栈应具备以下功能：

+   事件数据语义以维护事件数据的一致性。

+   用于连续更新实时数据的增量计算模型。

+   一种熟悉的关系数据模型，将流视为表，实现各种数据源的无缝集成。

**第一代流处理系统**：流处理系统长期以来一直在努力满足这些要求。第一代流处理系统，如Spark Streaming、Apache Heron和Flink的早期版本，在某些方面证明了它们的价值。例如，它们在微批处理方面表现突出，并且非常适合特定的使用案例。例如，对于希望将流处理纳入其现有工作负载的Spark用户来说，Spark Streaming是一个有价值的补充。总的来说，这些系统从成熟的批处理模型中继承了许多优势。

然而，它们也继承了遗留批处理模型的调度和协调问题。它们不支持真正的事件时间语义，这在构建事件驱动架构应用程序中至关重要。此外，这些技术只专注于数据处理方面。缺乏数据存储意味着需要单独的数据存储用于持久化，导致应用程序性能较慢且操作开销增加。此外，这些系统主要为早期采用者设计，他们习惯使用低级API和接口。因此，这些技术并未显著推动快速和轻松构建实时应用程序的能力。

新一代流处理解决方案

早期流处理系统传统上采用先代码后API的方法设计。为了使流处理更广泛被采纳，将SQL作为标准API至关重要。此外，新系统应包括内置存储层，以有效处理数据检索。

**引入流数据库**：它们旨在结合流处理引擎的增量处理能力与传统数据库的基于SQL的分析和持久化能力。新一代流数据库的出现可能改善与依赖于分离平台进行流和批处理的方法相比的操作效率。流数据库，例如[RisingWave](https://www.risingwave.com/)和[Materialize](https://materialize.com/)，旨在使用SQL查询和实时物化视图连续处理事件数据流。它们还为进一步分析持久化历史事件数据。

不同于将数据存储在外部数据库的流处理引擎，流数据库专门设计为具备内置处理和持久化能力。这意味着单个流数据库可以作为使用诸如Apache Flink和Apache Cassandra组合工具的可行替代方案。通过这种方式，简化了部署、配置、集成和管理任务。有了流数据库，数据库功能的移动向上游发生了范式转变，使得能够实时处理数据，并便捷地提供数据服务。

展望未来

通过将早期流处理系统的优势与传统数据库系统结合，我们使流处理更加易于广泛用户使用。这种创新的方法彻底改变了实时数据处理，并使更多人能够利用它。通过弥合流处理灵活性与传统数据库可靠性之间的差距，我们创建了一个更加包容和用户友好的数据处理环境。

这种趋同的影响深远。企业可以利用实时数据分析做出明智决策，预测结果，并获得竞争优势。持续的实时数据处理和多个数据流的集成使得各种用例成为可能，包括欺诈检测、实时个性化、供应链优化和物联网分析。此外，流处理的民主化使得数据工程师、科学家和分析师可以在不需要广泛技术专业知识的情况下利用实时数据处理。

总之，这种整合解决了限制，并赋予企业实时数据分析的能力。流处理正在变得更加可访问、高效，并且对跨行业组织具有转型性影响。流处理的民主化现在变得触手可及，为创新和增长开辟了新的可能性。
