- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 14:52:49'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 14:52:49'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Robots Dream of Root Shells
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Robots Dream of Root Shells
- en: 来源：[https://blog.isosceles.com/robots-dream-of-root-shells/](https://blog.isosceles.com/robots-dream-of-root-shells/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://blog.isosceles.com/robots-dream-of-root-shells/](https://blog.isosceles.com/robots-dream-of-root-shells/)
- en: It's been an incredible year for AI. Back in the early 2000s, there were AI
    posters up all over my local computer science department, and it was all genetic
    algorithms, genetic programming, and particle swarm optimization as far as you
    could see. They could figure out if a circle was centered on an image, but it
    didn't work very well. It was the tail-end of a long [AI winter](https://en.wikipedia.org/wiki/AI_winter?ref=blog.isosceles.com).
    Fast forward to today and we're seeing all sorts of emergent *stuff*, the rate
    of progress is off the charts, and there's not a genetic algorithm in sight.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 今年对于人工智能来说是不可思议的一年。回到21世纪初，我的当地计算机科学系到处都是人工智能的海报，充斥着遗传算法、遗传编程和粒子群优化。它们可以判断一个图像中的圆是否居中，但效果并不好。那时正值长达数年的[人工智能冬季](https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%86%AC%E5%AD%A3?ref=blog.isosceles.com)的尾声。快进到今天，我们看到各种新兴的*事物*，进展速度快得令人难以置信，而遗传算法已经不复存在。
- en: Recently I've been following the new DARPA competition, the [Artificial Intelligence
    Cyber Challenge (AIxCC)](https://aicyberchallenge.com/?ref=blog.isosceles.com).
    The basic idea is to discover if we can use AI to find security vulnerabilities,
    and then use AI to fix them as well. The net result would be an autonomous system
    that can make software more secure with no humans in the loop, and that could
    have big implications for... well, *all the software in the world*.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，我一直在关注新的DARPA竞赛，即[人工智能网络挑战（AIxCC）](https://aicyberchallenge.com/?ref=blog.isosceles.com)。基本思想是探索是否能够利用人工智能发现安全漏洞，然后利用人工智能修复这些漏洞。最终结果将是一个能够在没有人类参与的情况下使软件更加安全的自主系统，这可能对...
    嗯，*全球所有软件*都具有重大影响。
- en: If that sounds familiar, the goal of AIxCC is somewhat similar to a previous
    DARPA competition, the Cyber Grand Challenge (CGC) in 2016\. The original hope
    for CGC was that we could take the thought processes used by capture the flag
    (CTF) players and turn them into automated systems, and overall it was quite successful.
    I suspect the organizers were expecting more in the way of novel program analysis
    techniques, but in practice most competitors converged on using [fuzzing](https://en.wikipedia.org/wiki/Fuzzing?ref=blog.isosceles.com).
    Perhaps the inadvertent success of CGC was in highlighting how much more effective
    fuzzing is than other automated bug discovery methodologies, because there's been
    a huge amount of energy and attention around fuzzing in the past 8 years, and
    not so much on all the other stuff.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这听起来很熟悉，AIxCC的目标与之前的DARPA竞赛——2016年的网络大挑战（CGC）有些相似。最初CGC的希望是将捉旗（CTF）选手使用的思维过程转化为自动化系统，总体来说取得了相当大的成功。我怀疑组织者原本期望有更多新颖的程序分析技术，但实际上大多数竞争者最终都集中在使用[fuzzing](https://zh.wikipedia.org/wiki/Fuzzing?ref=blog.isosceles.com)。也许CGC的意外成功在于突显出在过去的8年中，fuzzing比其他自动化漏洞发现方法更加有效，因此围绕fuzzing产生了大量的能量和关注，而其他方面却没有那么多。
- en: For better or worse, the CGC was designed around a highly contrived execution
    environment and relatively simple challenge binaries. This made the problem tractable,
    but it did raise some questions about real-world applicability, particularly around
    the exploit generation and binary patching parts. The idea of AIxCC is to set
    up a similar competition structure, but to drop the contrivances. Challenges will
    be based on real software like the Linux kernel and Jenkins, and all of the source
    code will be available. Find the bugs, fix the bugs, but you don't need to solve
    the exploit generation problem.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是好是坏，CGC都是围绕一个高度刻意的执行环境和相对简单的挑战二进制程序设计的。这使得问题变得可行，但也提出了一些关于实际应用性的问题，特别是在漏洞生成和二进制修补部分。AIxCC的理念是建立一个类似的竞赛结构，但取消刻意性。挑战将基于像Linux内核和Jenkins这样的真实软件，并且所有源代码都将可用。找到漏洞，修复漏洞，但无需解决漏洞生成问题。
- en: Overall, AIxCC is probably a harder challenge than CGC, if only because performing
    automated reasoning on such vastly different types of software is so hard, and
    you can't get much more vastly different than a modern operating system kernel
    and a Java-based CI/CD server. If you think about it, the Venn diagram intersection
    of people who even know how to get both of these things set up and running is
    going to be fairly tiny.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，AIxCC可能比CGC更具挑战性，至少因为在如此大不相同的软件类型上执行自动推理是如此困难，而现代操作系统内核和基于Java的CI/CD服务器就属于这种极大不同的类型。如果仔细思考一下，即使知道如何设置和运行这两种东西的人在交集上也会非常小。
- en: But maybe that's the point? We have AI now, and AI is in that intersection.
    AI is in the intersection of ***every*** Venn diagram.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 但也许这就是问题的关键？我们现在有了AI，而AI就在这个交集中。AI在每个Venn图的交集中都存在。
- en: The problem is that AI doesn't seem to be very good at finding security bugs
    yet, even when the model is [specifically designed](https://arxiv.org/pdf/2306.17193.pdf?ref=blog.isosceles.com)
    to analyze code. There's some [promising results](https://arxiv.org/pdf/2402.11814.pdf?ref=blog.isosceles.com)
    around using AI to solve CTF challenges, but so far that hasn't translated to
    real world software very well. To get a sense for how quickly this space is moving
    though, a few days ago it looked like we had a [potential leap forward](https://twitter.com/JasonDClinton/status/1766233772805288006?ref=blog.isosceles.com)
    on AI-automated bug-discovery for the Linux kernel, only for it it to quickly
    fizzle out once the [details were checked](https://github.com/SeanHeelan/claude_opus_cve_2023_0266?ref=blog.isosceles.com).
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 问题在于，AI似乎还不擅长找到安全漏洞，即使该模型专门设计用于分析代码。使用AI解决CTF挑战似乎取得了一些**有希望的结果**，但迄今为止，在实际软件中尚未很好地体现出来。然而，要了解这个领域的发展速度，就在几天前，我们看起来在Linux内核的AI自动化漏洞发现上有了**潜在的飞跃**，但在**详细检查之后**，它很快就消失了。
- en: 'It turns out that finding security bugs in real software is hard – impossibly,
    stupidly hard – at least from the perspective of computational complexity. The
    basic problem is state explosion, where each system interaction leads to an exponential
    number of new possibilities, which in turn leads to an exponential number of new
    possibilities, and so on. If you see "find a bug in this source code" as a search
    optimization problem, then the search space is mind boggling. One way to make
    it tractable is to simplify the problem: CTF problems, CGC challenge binaries,
    looking at a single file/function at a time. But real world security bugs don''t
    work like that, they involve huge codebases with all sorts of cross-function,
    cross-library, and cross-process interactions that blow up the search space immediately.'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在现实软件中找到安全漏洞是困难的——从计算复杂性的角度来看，这几乎是不可能的、愚蠢的难题。基本问题是状态爆炸，每个系统交互导致指数增长的新可能性，进而导致指数增长的新可能性，依此类推。如果将“在这段源代码中找到一个漏洞”视为一个搜索优化问题，那么搜索空间令人震惊。使其可处理的一种方法是简化问题：CTF问题、CGC挑战二进制文件、一次查看单个文件/函数。但真实世界的安全漏洞并不像这样，它们涉及庞大的代码库，具有各种跨函数、跨库和跨进程的交互，这立即使搜索空间扩大。
- en: This is why fuzzing has been winning the methodology wars. When the search space
    is this big, all of the fancy program analysis stuff breaks down, and you're left
    with some fairly primitive tools – random mutations with a code-coverage/compare-value
    feedback loop, and a bunch of clever trimming of the search space (like enabling
    compiler sanitizers to make bugs easier to trigger). But maybe AI can change that?
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么模糊测试一直处于方法论之战的前沿。当搜索空间如此之大时，所有的高级程序分析都会崩溃，你只能用一些相当原始的工具——带有代码覆盖率/比较值反馈循环的随机突变，以及一些巧妙的搜索空间修剪（例如启用编译器检查器使漏洞更容易触发）。但也许AI可以改变这一切？
- en: 'At the moment there''s a minor practical problem: the LLM tech of 2024 has
    a relatively small context window, and so it''s usually not possible (or cost-effective)
    to reason on the entire system at once, unless the system is [very basic](https://twitter.com/moyix/status/1765967602982027550?ref=blog.isosceles.com).
    That means splitting the work up into smaller chunks, which is tricky to do in
    a way that doesn''t introduce ambiguity or incorrectness into the analysis, and
    that will also fundamentally limit the ability to find bugs that are "spread out"
    across a larger codebase (like use-after-free bugs, which tend not to be localized
    to a single function). I don''t think this is going to be a big problem in the
    future, because there are already models coming down the pipeline with context
    windows large enough to handle 100k lines-of-code (LOC), and that number keeps
    growing. To put this in context though (excuse the pun), the entire Linux kernel
    is about 27 million LOC – so there''s still a long way to go, and there''s definitely
    some uncertainty about how well the transformer architecture will continue to
    scale.'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 目前存在一个小的实际问题：2024 年的 LLM 技术具有相对较小的上下文窗口，因此通常不可能（或经济上不可行）一次推理整个系统，除非系统非常基础。这意味着将工作分成较小的块是有技巧要求的，这样做不会在分析中引入歧义或错误，并且从根本上限制了查找“分散”在更大代码库中的漏洞的能力（例如
    use-after-free 漏洞，这些漏洞倾向于不局限于单个函数）。我认为这在未来不会成为一个大问题，因为已经有一些模型正在开发中，其上下文窗口足够大，可以处理
    10 万行代码（LOC），而且这个数字还在增长。不过，为了理解清楚（请原谅双关语），整个 Linux 内核约有 2700 万行代码（LOC）- 因此还有很长的路要走，而且对于
    transformer 架构能否继续扩展，还存在一些不确定性。
- en: The bigger problem is that AI can't just magically erase the state explosion
    involved in this type of analysis, and it still has to find a way to navigate
    the same search space that a fuzzer or a human code reviewer does. We know that
    humans can navigate this search space with some degree of success, and that sometimes
    humans can even find bugs that fuzzers can't. With that said, the reason we want
    to automate this task is that human code auditors are excruciatingly slow and
    generally pretty unreliable.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 更大的问题是，AI 不能魔法般地消除这种类型分析中涉及的状态爆炸，它仍然必须找到一种方法来导航与模糊器或人类代码审查者相同的搜索空间。我们知道人类可以在一定程度上成功地导航这个搜索空间，有时甚至可以找到模糊器无法找到的漏洞。话虽如此，我们希望自动化这项任务的原因是人类代码审计员非常慢且通常相当不可靠。
- en: So how will the AI navigate this search space? I've spent years talking to security
    researchers about their techniques and approaches for finding security bugs, and
    when it comes to code review, we're really quite bad at explaining how we do it.
    The notion of "show your working" never caught on in our scene, and so you'll
    find hundreds of blog posts that intricately explain how to trigger a bug and
    what happens next, but very few that succinctly explain the steps that led to
    that discovery, and even fewer that explain why those exact steps were chosen
    in the first place.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 所以 AI 将如何导航这个搜索空间？多年来，我与安全研究人员讨论了他们在寻找安全漏洞时的技术和方法，当涉及到代码审查时，我们在解释我们的方法时确实表现得很差。在我们的领域里，“展示你的工作过程”这个概念从未流行起来，因此你会发现数百篇博文详细解释如何触发一个漏洞以及接下来会发生什么，但很少有简明扼要地解释导致发现的步骤，甚至更少的是解释为什么最初选择了这些确切的步骤。
- en: All of this is to say that the training corpus for AI-driven bug hunting seems
    to have some problematic gaps. We can still expect some amount of emergent behavior,
    but it's too much to expect these systems to match or surpass a human reviewer
    if we can't even begin to describe what the "bug hunter's mind palace" really
    looks like. The promising news here is that AI is getting really good at in-context
    learning, so if you can find a way to describe the thought process of a human
    code review, then good prompt engineering should be able to transfer some of those
    insights, even if the training corpus is bad.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都是为了说明，AI 驱动的漏洞猎手的训练语料库似乎存在一些问题性的空白。我们仍然可以期待某些新兴行为的出现，但期望这些系统能与或超过人类审查者匹敌还为时过早，因为我们甚至无法开始描述“漏洞猎手的心理宫殿”真正的样子。这里的有希望的消息是，AI
    在上下文学习方面表现得非常出色，因此如果能找到一种描述人类代码审查思维过程的方法，良好的提示工程应该能够转移部分这些见解，即使训练语料库很糟糕。
- en: As an aside, I suspect the public training corpus is only going to get worse
    – I've talked about this in the past, but recently there's been a steady divergence
    between the public and private state-of-the-art in security research. Attackers
    are highly incentivized to keep their knowledge hidden and to share it with as
    few people as possible, and they're also investing in exploit development at a
    much higher rate than defenders are, so the net effect is that the security research
    you see in public presentations and blog posts is often on a completely different
    wavelength to the stuff that's happening in private. That's a big opportunity
    if you're one of the handful of groups that have access to enough relevant R&D
    to build a training dataset that has modern exploit development included, but
    not such good news for defenders.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，我怀疑公共训练语料库只会变得更糟——我过去曾谈论过这个问题，但最近公共和私人安全研究的最新状态有稳定的分歧。攻击者有很强的动机保持他们的知识不公开，并尽可能少地分享给他人，他们还在比较高的速度上投入到利用开发中，而防御者的投入远远不及。因此，你在公开演示和博客文章中看到的安全研究，往往与私人领域中的研究完全不在一个频率上。如果你是少数几个能够获取足够相关研发数据集的团队之一，这就是一个巨大的机会，但对于防御者来说这并不是什么好消息。
- en: So what does this all mean for AIxCC? There's some chatter about some of the
    early work being competitive with traditional fuzzers, but nobody seems to be
    willing to show their hand before the big event. It looks like there might be
    two potential strategies emerging though. The first, AI-focused, will try to use
    the analytical ability of LLMs to directly point out where vulnerabilities in
    the source code lie. The second, fuzzing-focused, will use AI to assist in setting
    up a more traditional fuzzing environment.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 那么这一切对AIXCC意味着什么呢？关于早期工作在与传统模糊测试相竞争的传言不绝于耳，但在大事件之前没有人愿意透露他们的底牌。看起来可能会出现两种潜在的策略。第一种是以人工智能为重点，将尝试利用LLM的分析能力直接指出源代码中的漏洞位置。第二种是以模糊测试为重点，将利用人工智能来协助建立更传统的模糊测试环境。
- en: Interestingly the winners of the previous CGC competition, [Mayhem](https://www.mayhem.security/blog/mayhem-wins-darpa-cgc?ref=blog.isosceles.com),
    weren't included in the funded track for AIxCC. Perhaps the organizers thought
    that Mayhem's proposal was too fuzzing-heavy? I don't know for sure, but I hope
    that Mayhem competes in the open track so that we can get a comparison of AI-focused
    and fuzzing-focused approaches to this problem, and it would be nice to have that
    historic link back to CGC.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，前一届CGC竞赛的获胜者[Mayhem](https://www.mayhem.security/blog/mayhem-wins-darpa-cgc?ref=blog.isosceles.com)，并未被包括在AIXCC的资助轨道中。也许组织者认为Mayhem的提案过于侧重于模糊测试？我不能确定，但我希望Mayhem能参加公开赛轨道，这样我们可以比较以人工智能为重点和以模糊测试为重点方法在解决这个问题上的差异，而且能够回溯到CGC的历史联系也是件好事。
- en: If I were designing an entry, I would be leaning toward a fuzzing-focused approach,
    particularly given the short timelines and the current code analysis limitations
    of LLMs in 2024\. The counter-argument to this is that the organizers would probably
    prefer an AI-focused winner, so there's a decent chance that challenges will be
    designed in a way that's highly amenable to that approach.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我设计一个参赛项目，我会倾向于采用以模糊测试为重点的方法，特别是考虑到2024年LLM在当前代码分析方面的限制和时间紧迫的情况。这种方法的反对意见是，组织者可能更倾向于选择一个以人工智能为重点的获胜者，因此挑战很可能会以这种方法为基础进行设计。
- en: My intuition would still be to use LLMs to 1) help with building the target
    projects with coverage instrumentation and sanitizers enabled, 2) finding a good
    seed corpus (or a good way to generate one), and 3) generating the actual fuzzing
    harness. Creating fuzzing harnesses is a lot of manual work, and it looks like
    Google has had some good success with [LLM-generated harnesses](https://security.googleblog.com/2023/08/ai-powered-fuzzing-breaking-bug-hunting.html?ref=blog.isosceles.com).
    Then I'd let a target-appropriate fuzzer (syzkaller, afl++, ffuf, domato, etc)
    do the heavy lifting on the actual bug discovery part. Once you have an interesting
    test-case in hand, I think you could bring the LLM back into the picture for the
    source code patching process. LLMs seem to be able to handle well-scoped debugging
    tasks, and you can narrow the problem space down significantly once you have a
    test case that triggers something interesting (like a crash). Based on that I
    think you should be able to get some quite good results on the automated patching
    side, and hopefully this is the area where we will see a lasting impact from AIxCC.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我的直觉仍然是使用LLMs来：1）帮助构建具有覆盖仪器和启用消毒剂的目标项目，2）找到一个好的种子语料库（或生成的好方法），和3）生成实际的模糊测试韧性。创建模糊测试韧性需要大量的手工工作，看起来谷歌在[LLM生成的韧性](https://security.googleblog.com/2023/08/ai-powered-fuzzing-breaking-bug-hunting.html?ref=blog.isosceles.com)方面取得了一些良好的成功。然后我会让一个适合目标的模糊器（如syzkaller、afl++、ffuf、domato等）在实际的漏洞发现部分进行大量的工作。一旦你手头有一个有趣的测试用例，我认为你可以将LLM重新引入图像进行源代码修补过程。LLMs似乎能够很好地处理范围明确的调试任务，一旦有一个触发有趣情况（如崩溃）的测试用例，你可以显著地缩小问题空间。基于此，我认为你应该能够在自动修补方面取得一些相当不错的结果，希望这是我们能从AIxCC中看到持久影响的领域。
- en: The AIxCC semi-finals are due to take place in Las Vegas later this year, with
    the final being held a year later in August 2025\. It looks like we're going to
    find out soon if AI can find and fix bugs in real world software. If it can, then
    things are going to get exciting very quickly.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: AIxCC半决赛定于今年晚些时候在拉斯维加斯举行，最终将于2025年8月举行。看起来我们很快就会知道AI是否能在真实世界的软件中找到并修复错误。如果可以的话，事情将会变得非常令人兴奋。
- en: Good luck to all of the competitors, I'll be watching from afar!
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: 祝所有参赛者好运，我会远远地关注着！
- en: '- Ben Hawkes'
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: '- 本·霍克斯'
