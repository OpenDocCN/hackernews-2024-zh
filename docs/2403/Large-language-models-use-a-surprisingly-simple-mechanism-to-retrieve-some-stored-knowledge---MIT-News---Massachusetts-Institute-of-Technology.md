<!--yml

category: 未分类

date: 2024-05-29 12:44:53

-->

# 大型语言模型使用了一个令人惊讶地简单的机制来检索一些存储的知识 | MIT News | 麻省理工学院

> 来源：[https://news.mit.edu/2024/large-language-models-use-surprisingly-simple-mechanism-retrieve-stored-knowledge-0325](https://news.mit.edu/2024/large-language-models-use-surprisingly-simple-mechanism-retrieve-stored-knowledge-0325)

大型语言模型，如驱动流行的人工智能聊天机器人（如ChatGPT）的模型，非常复杂。尽管这些模型被用作许多领域的工具，如客户支持、代码生成和语言翻译，但科学家仍未完全理解它们的工作原理。

为了更好地理解这些庞大的机器学习模型检索存储知识时的工作机制，MIT和其他地方的研究人员进行了研究。

他们发现了一个令人惊讶的结果：大型语言模型（LLMs）通常使用非常简单的线性函数来恢复和解码存储的事实。此外，该模型对于类似类型的事实使用相同的解码函数。线性函数，即只有两个变量且没有指数的方程式，捕捉了两个变量之间直接、直线关系。

研究人员表明，通过识别不同事实的线性函数，他们可以探索模型看它对新主题的了解情况，并确定模型内知识的存储位置。

使用他们开发的技术来估计这些简单函数，研究人员发现，即使模型错误地回答提示，它通常已经存储了正确的信息。将来，科学家可以使用这种方法来查找和纠正模型内的虚假信息，这可以减少模型偶尔给出错误或荒谬答案的倾向。

“尽管这些模型非常复杂，是训练在大量数据上的非线性函数，并且非常难以理解，但有时候它们内部确实存在非常简单的机制。这就是其中一个实例，” 电气工程和计算机科学（EECS）研究生，以及详细阐述这些发现的论文的共同第一作者Evan Hernandez说。

Hernandez与共同第一作者Arnab Sharma合作撰写了这篇论文，Arnab Sharma是东北大学的计算机科学研究生；他的导师Jacob Andreas是EECS的副教授，也是计算机科学与人工智能实验室（CSAIL）的成员；资深作者David Bau是东北大学的计算机科学助理教授，还有其他来自MIT、哈佛大学和以色列理工学院的研究人员。这项研究将在国际学习表征会议上进行展示。

**查找事实**

大多数大型语言模型，也称为变压器模型，是[神经网络](https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414)。神经网络基于人脑，包含数十亿个互连的节点或神经元，分组成许多层，用于编码和处理数据。

变压器中存储的大部分知识可以表示为连接主题和对象的关系。例如，“迈尔斯·戴维斯演奏小号”是一个连接主题迈尔斯·戴维斯和对象小号的关系。

当变压器获取更多知识时，它会在多个层次上存储关于某个主题的附加事实。如果用户询问有关该主题的信息，模型必须解码最相关的事实以回应查询。

如果有人通过说“迈尔斯·戴维斯演奏的是…”来提示变压器，模型应该回答“小号”，而不是“伊利诺伊州”（迈尔斯·戴维斯的出生地）。

“在网络的计算中，必须有一个机制去查找迈尔斯·戴维斯演奏小号的事实，并从中提取这些信息来帮助生成下一个词。我们想要理解那个机制是什么，”赫尔南德斯说道。

研究人员设置了一系列实验来探索LLMs，并发现，尽管它们非常复杂，但模型使用简单的线性函数解码关系信息。每个函数都特定于正在检索的事实类型。

例如，变压器在想要输出一个人所演奏的乐器时会使用一种解码函数，而在想要输出一个人出生的州时会使用另一种函数。

研究人员开发了一种估计这些简单函数的方法，然后为47种不同的关系计算了函数，例如“一个国家的首都”和“一个乐队的主唱”。

虽然可能存在无限数量的可能关系，但研究人员选择研究这个特定的子集，因为它们代表了可以用这种方式写入的事实类型。

他们通过改变主题来测试每个函数，以查看它是否能恢复正确的对象信息。例如，“一个国家的首都”的函数应该在主题是挪威时检索奥斯陆，而在主题是英格兰时检索伦敦。

函数超过60%的时间检索到正确的信息，表明变压器中的一些信息是以这种方式编码和检索的。

“但并不是所有事实都是线性编码的。对于一些事实，尽管模型知道它们并将预测与这些事实一致的文本，我们却无法找到线性函数。这表明模型在存储这些信息时正在进行更复杂的操作，”他说道。

**可视化模型的知识**

他们还使用这些函数来确定模型对不同主题的信仰。

在一个实验中，他们以提示“比尔·布拉德利是”开始，并使用“从事运动”和“上大学”的解码功能，以查看模型是否知道参议员布拉德利是一个参加了普林斯顿大学的篮球运动员。

“我们可以展示，即使模型在生成文本时可能选择关注不同的信息，它确实对所有信息进行了编码，” 赫尔南德斯说。

他们利用这种探索技术制作了所谓的“属性镜头”，这是一种网格，可以显示变压器的许多层中存储有关特定关系的具体信息的位置。

可以自动生成属性镜头，提供一种简化的方法，帮助研究人员更好地理解模型。这种可视化工具可以使科学家和工程师更正存储的知识，并帮助防止AI聊天机器人提供错误信息。

在未来，赫尔南德斯和他的合作者们希望更好地理解在事实不是线性存储的情况下会发生什么。他们还希望运行更大的模型实验，并研究线性解码函数的精度。

“这是一项令人兴奋的工作，揭示了我们在推理过程中大语言模型如何回忆事实知识中的一个缺失部分。先前的研究表明，大语言模型在给定主题中构建了信息丰富的表示，推理过程中从中提取了特定属性。这项工作表明，大语言模型复杂的非线性计算用于属性提取可以很好地近似为简单的线性函数，” 未参与此项工作的特拉维夫大学计算机科学学院助理教授 Mor Geva Pipek 说。

这项研究在一定程度上得到了开放慈善、以色列科学基金会和阿兹里埃利基金会早期职业教职员工奖助金的支持。
