- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-29 12:32:42'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: DuckDB as the New jq - Paul Gross’s Blog
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://www.pgrs.net/2024/03/21/duckdb-as-the-new-jq/](https://www.pgrs.net/2024/03/21/duckdb-as-the-new-jq/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Recently, I’ve been interested in the [DuckDB](https://duckdb.org/) project
    (like a [SQLite](https://www.sqlite.org/) geared towards data applications). And
    one of the amazing features is that it has many data importers included without
    requiring extra dependencies. This means it can natively read and parse JSON as
    a database table, among many other formats.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: I work extensively with JSON day to day, and I often reach for [jq](https://jqlang.github.io/jq/)
    when exploring documents. I love `jq`, but I find it hard to use. The syntax is
    super powerful, but I have to study the docs anytime I want to do anything beyond
    just selecting fields.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: Once I learned DuckDB could read JSON files directly into memory, I realized
    that I could use it for many of the things where I’m currently using `jq`. In
    contrast to the complicated and custom `jq` syntax, I’m very familiar with SQL
    and use it almost daily.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an example:'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we fetch some sample JSON to play around with. I used the GitHub API
    to grab the repository information from the golang org:'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-split-11
  prefs: []
  type: TYPE_PRE
- en: Now, as a sample question to answer, let’s get some stats on the types of open
    source licenses used.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
- en: 'The JSON structure looks like this:'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-split-14
  prefs: []
  type: TYPE_PRE
- en: 'This might not be the best way, but here is what I cobbled together after searching
    and reading some docs for how to do this in `jq`:'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-split-16
  prefs: []
  type: TYPE_PRE
- en: 'And here is what it looks like in DuckDB using SQL:'
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-split-18
  prefs: []
  type: TYPE_PRE
- en: For me, this SQL is much simpler and I was able to write it without looking
    at any docs. The only tricky part is querying nested JSON with the `->>` operator.
    The syntax is the same as the [PostgreSQL JSON Functions](https://www.postgresql.org/docs/current/functions-json.html),
    however, so I was familiar with it.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
- en: 'And if we do need the output in JSON, there’s a DuckDB flag for that:'
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-split-21
  prefs: []
  type: TYPE_PRE
- en: 'We can still even pretty print with `jq` at the end, after using DuckDB to
    do the heavy lifting:'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-split-23
  prefs: []
  type: TYPE_PRE
- en: JSON is just one of the many ways of importing data into DuckDB. This same approach
    would work for CSVs, parquet, Excel files, etc.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
- en: And I could choose to create tables and persist locally, but often I’m just
    interrogating data and don’t need the persistence.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
- en: 'Read more about DuckDB’s great JSON support in this blog post: [Shredding Deeply
    Nested JSON, One Vector at a Time](https://duckdb.org/2023/03/03/json.html)'
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
- en: '**Update:**'
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
- en: 'I also learned that DuckDB can read the JSON directly from a URL, not just
    a local file:'
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-split-29
  prefs: []
  type: TYPE_PRE
