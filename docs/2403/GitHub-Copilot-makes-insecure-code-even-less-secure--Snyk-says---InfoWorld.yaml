- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:49:32'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Copilot makes insecure code even less secure, Snyk says | InfoWorld
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://www.infoworld.com/article/3713141/github-copilot-makes-insecure-code-even-less-secure-snyk-says.html](https://www.infoworld.com/article/3713141/github-copilot-makes-insecure-code-even-less-secure-snyk-says.html)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: GitHub’s AI-powered coding assistant, [GitHub Copilot](https://github.blog/2022-06-21-github-copilot-is-generally-available-to-all-developers/),
    may suggest insecure code when the user’s existing codebase contains security
    issues, according to developer security company Snyk.
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Copilot can replicate existing security issues in code, Snyk said in
    a blog post published February 22\. “This means that existing security debt in
    a project can make insecure developers using Copilot even less secure,” the company
    said. However, GitHub Copilot is less likely to suggest insecure code in projects
    without security issues, as it has a less insecure code context to draw from.
  prefs: []
  type: TYPE_NORMAL
- en: '[Generative AI](https://www.infoworld.com/article/3689973/what-is-generative-ai-artificial-intelligence-that-creates.html)
    coding assistants such as [GitHub Copilot](https://www.infoworld.com/article/3699140/review-codewhisperer-bard-and-copilot.html),
    [Amazon CodeWhisperer](https://www.infoworld.com/article/3699140/review-codewhisperer-bard-and-copilot.html),
    and [ChatGPT](https://www.infoworld.com/article/3689172/chatgpt-and-software-development.html)
    offer a significant leap forward in productivity and code efficiency, Snyk said.
    But these tools do not understand code semantics and thus cannot judge it.'
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Copilot generates code snippets based on patterns and structures it has
    learned from a vast repository of existing code. While this approach has advantages,
    it also can have a glaring drawback in the context of security, Snyk said. Copilot’s
    code suggestions may inadvertently replicate existing security vulnerabilities
    and bad practices present in neighbor files.
  prefs: []
  type: TYPE_NORMAL
- en: 'To mitigate duplication of existing security issues in code generated by AI
    assistants, Snyk advises the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Developers should conduct manual reviews of code.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security teams should put a SAST (security application security testing) guardrail
    in place, including policies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developers should adhere to secure coding guidelines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security teams should provide training and awareness to development teams and
    prioritize and triage the backlog of issues per team.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executive teams should mandate security guardrails.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snyk data says the average commercial software project has an average of 40
    vulnerabilities in first-party code, and almost a third of those are high-severity
    issues. “This is the playground in which AI generation tools can duplicate code
    by using these vulnerabilities as their context,” Snyk said. The most common issues
    Snyk sees in commercial projects are cross-site scripting, path traversal, SQL
    injection, and hard-coded secrets and credentials.
  prefs: []
  type: TYPE_NORMAL
- en: GitHub could not be reached late-Wednesday afternoon to respond to Snyk’s comments
    about GitHub Copilot.
  prefs: []
  type: TYPE_NORMAL
- en: Copyright © 2024 IDG Communications, Inc.
  prefs: []
  type: TYPE_NORMAL
