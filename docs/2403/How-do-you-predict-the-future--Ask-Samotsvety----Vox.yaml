- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:51:27'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: How do you predict the future? Ask Samotsvety. - Vox
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://www.vox.com/future-perfect/2024/2/13/24070864/samotsvety-forecasting-superforecasters-tetlock](https://www.vox.com/future-perfect/2024/2/13/24070864/samotsvety-forecasting-superforecasters-tetlock)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The question before a group made up of some of the best forecasters of world
    events: What are the odds that [China](/china) will control at least half of Taiwan’s
    territory by 2030?'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: Everyone on the chat gives their answer, and in each case it’s a number. Chinmay
    Ingalagavi, an economics fellow at Yale, says 8 percent. Nuño Sempere, the 25-year-old
    Spanish independent researcher and consultant leading our session, agrees. Greg
    Justice, an MBA student at the University of Chicago, pegs it at 17 percent. Lisa
    Murillo, who holds a PhD in [neuroscience](/neuroscience), says 15-20 percent.
    One member of the group, who asked not to be named in this context because they
    have family in China who could be targeted by the government there, posits the
    highest figure: 24 percent.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: Sempere asks me for my number. Based on a quick analysis of past military clashes
    between the countries, I came up with 5 percent. That might not seem too far away
    from the others, but it feels embarrassingly low in this context. Why am I so
    out of step?
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: This is a meeting of Samotsvety. The name comes from a 50-year-old Soviet rock
    band — more on that later — but the modern Samotsvety specializes in predicting
    the future. And they are very, very good at it. At [Infer](https://www.infer-pub.com/),
    a major forecasting platform [operated by Rand](https://www.infer-pub.com/the-pub/rand-program-update),
    the [four most accurate forecasters in the site’s history](https://capture.dropbox.com/qENgJOuZgsTPZy3c)
    are all members of Samotsvety, and there is a wide gap between them and fifth
    place. In fact, the gap between them and fifth place is bigger than between fifth
    and 10th places. They’re waaaaay out ahead.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
- en: While Samotsvety members converse on Slack regularly, the Saturday meetings
    are the heart of the group, and I was sitting in to get a sense of why, exactly,
    the group was so good. What were these folks doing differently that made them
    able to see the future when the rest of us can’t?
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
- en: I knew a bit about forecasting going into the meeting. I’ve [written about it](/future-perfect/23785731/human-extinction-forecasting-superforecasters);
    I’ve read *Superforecasting*, the bestseller by Philip Tetlock and Dan Gardner
    describing the research behind forecasting. The whole [Future Perfect](/future-perfect)
    team here at Vox [puts together predictions](/future-perfect/2024/1/1/24011179/2024-predictions-trump-politics-ohtani-oppenheimer-elections)
    at the start of each year, hoping not just to lay down markers on how we think
    the next year will go, but to get better at forecasting in the process.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
- en: Part of the appeal of forecasting is not just that it seems to work, but that
    you don’t seem to need specialized expertise to succeed at it. The aggregated
    opinions of non-experts doing forecasting have [proven to be a better guide to
    the future](https://arbresearch.com/files/comparing_forecasters.pdf) than the
    aggregated opinions of experts. One [frequently cited study](https://goodjudgment.io/docs/Goldstein-et-al-2015.pdf)
    found that accurate forecasters’ predictions of geopolitical events, when aggregated
    using standard scientific methods, were more accurate than the forecasts of members
    of the US intelligence community who answered the same questions in a confidential
    prediction market. This was true even though the latter had access to classified
    intelligence.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
- en: But I felt a bit stuck. After years of doing my annual predictions, I didn’t
    sense they were improving much at all, but I wasn’t predicting enough things to
    tell for sure. Events kept happening that I didn’t see coming, like the [Gaza
    war](/2023/10/7/23907683/israel-hamas-war-news-updates-october-2023) in recent
    months or the [Wagner mutiny](/2023/6/26/23774184/putin-wagner-group-mutiny-prigozhin)
    a few months before that. I wanted to hang out with Samotsvety for a bit because
    they were the best of the best, and thus a good crew to learn from.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
- en: They count among their fans Jason Matheny, now CEO of the RAND Corporation,
    a think tank that’s long worked on developing better predictive methods. Before
    he was at RAND, Matheny funded foundational work on forecasting as an official
    at the Intelligence Advanced Research Projects Activity (IARPA), a government
    organization that invests in technologies that might help the US intelligence
    community. “I’ve admired their work,” Matheny said of Samotsvety. “Not only their
    impressive accuracy, but also their commitment to scoring their own accuracy”
    — meaning they grade themselves so they can know when they fail and need to do
    better. That, he said, “is really rare institutionally.”
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
- en: What I discovered was that Samotsvety’s record of success wasn’t because its
    members knew things others didn’t. The factors its members brought up that Saturday
    to explain their probabilities sounded like the points you’d hear at a think tank
    event or an academic lecture on China-Taiwan relations. The anonymous member emphasized
    how ideologically important capturing the island was to Xi Jinping, and how few
    political constraints he faces. Greg Justice countered that the CCP has depended
    on economic growth that a war would jeopardize. Murrillo put a higher probability
    on an attack because of a projection that the US will not be likely to back up
    Taiwan once the latter’s chip production monopoly has waned due to other [nations](https://www.theverge.com/2023/7/25/23806813/eu-chips-act-approved-semiconductor-manufacturing)
    investing in [fabrication plants](https://www.nytimes.com/2023/01/16/opinion/america-biden-semiconductor-tsmc.html).
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
- en: 'But if the factors being listed reminded me of a normal think tank discussion,
    the numbers being raised didn’t. Near the end of the session, I asked: If some
    of you think there are such strong reasons for China to capture Taiwan, why is
    the highest odds anyone has proposed 24 percent, meaning even the most bullish
    member thinks such an event is nearly 75 percent likely *not* to happen? Why does
    no one here think Chinese control by 2030 is more likely than not?'
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
- en: The team had an answer, and it’s an answer that goes some way toward explaining
    why this group has managed to get so good at predicting the future.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
- en: 'The name Samotsvety, co-founder Misha Yagudin says, is a multifaceted pun.
    “It’s Russian for semi-precious stones, or more directly ‘self-lighting/coloring’
    stones,” he writes in an email. “It’s a few puns on what forecasting might be:
    finding nuggets of good info; even if we are not diamonds, together in aggregate
    we are great; self-lighting is kinda about shedding light on the future.”'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
- en: It began because he and Nuño Sempere needed a name for a Slack they started
    around 2020 on which they and friends could shoot the shit about forecasting.
    The two met at a summer fellowship at Oxford’s Future of Humanity Institute, a
    hotbed of the rationalist subculture where forecasting is a favored activity.
    Before long, they were competing together in contests like Infer and on platforms
    like [Good Judgment Open](https://www.gjopen.com/).
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
- en: The latter site is part of the [Good Judgment Project](https://goodjudgment.com/),
    led by Penn psychologists Philip Tetlock and Barbara Mellers. Those researchers
    have studied the process of forecasting intensely in recent decades. One of their
    main findings is that [forecasting ability is not evenly distributed](https://michaelmbishop.github.io/superforecasters.pdf).
    Some people are consistently much better at it than others, and strong past performance
    indicates better predictions going forward. These high performers are known as
    “superforecasters,” a term Tetlock and Gardner would later borrow for their [book](https://www.amazon.com/Superforecasting-Science-Prediction-Philip-Tetlock/dp/0804136718).
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
- en: Superforecaster® is now a [registered trademark of Good Judgment](https://goodjudgment.com/how-to-become-a-superforecaster/),
    and not every member of Samotsvety has been through that exact process, although
    more than half of them (8 of 15) have. I won’t call the group as a whole “superforecasters”
    here for fear of stealing superforecaster valor. But their team’s track record
    is strong.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
- en: A common measure of forecasting ability is the [relative Brier score](https://www.cultivatelabs.com/crowdsourced-forecasting-guide/what-are-relative-brier-scores-and-how-are-they-calculated),
    a number that aggregates the result of every prediction for which an outcome is
    now known, and then compares each forecaster to the median forecaster. A score
    of 0 means you’re average; a positive score means worse than average while negative
    means better than average. In 2021, the last full year Samotsvety participated,
    their score in the Infer tournament was -2.43, compared to -1.039 for the next-best
    team. They were more than twice as good as the nearest competition.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
- en: “If the point of forecasting tournaments is to figure out who you can trust,”
    the [writer Scott Alexander](https://www.astralcodexten.com/p/mantic-monday-31422?s=r)
    once quipped. “the science has spoken, and the answer is ‘these guys.’”
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
- en: 'So, why these guys? Part of the answer is selection. Members’ stories of how
    they joined the Samotsvety were usually some variation of: I started forecasting,
    I turned out to be pretty good at it, and the group noticed me. It’s a bit like
    how a youth soccer prodigy might eventually find themselves on Manchester City.'
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
- en: Molly Hickman came to forecasting by way of the government. Taking a contracting
    job out of college, she was assigned to IARPA, the intelligence research agency
    where Jason Matheny and others were running forecasting tournaments. The idea
    intrigued her, and when she went back to grad school for computer science, she
    signed up at Infer to try forecasting herself. She put together a team with her
    dad and some friends, and while the team as a whole didn’t do great, she did amazing.
    The Samotsvety group saw her scores and invited her to join.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
- en: 'Eli Lifland, a 2020 economics and computer science grad at UVA now [attempting
    to forecast AI progress](https://www.elilifland.com/), got his start predicting
    Covid-19\. 2020 was in some ways a banner year for forecasting: Superforecasters
    were [predicting that Covid would reach hundreds of thousands of cases](https://time.com/5848271/superforecasters-covid-19/)
    in February of that year, a time when government officials were still [calling
    the risk “minuscule.”](https://www.usatoday.com/story/news/health/2020/02/17/nih-disease-official-anthony-fauci-risk-of-coronavirus-in-u-s-is-minuscule-skip-mask-and-wash-hands/4787209002/)
    Users of the forecasting platform [Metaculus outperformed a panel of epidemiologists](https://www.metaculus.com/news/2020/06/02/LRT/)
    when predicting case numbers. Even in that company, Lifland did unusually well.
    The fast-moving nature of the pandemic made it easy to learn quickly because you
    could predict cases on a near-weekly basis and quickly realize what you got right
    or wrong. Before long, Misha and Nuño from Samotsvety came calling.'
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
- en: But “select people already good at forecasting” doesn’t explain why Samotsvety
    is so good. What made these forecasters good enough to win Samotsvety’s attention?
    What are these people, specifically, doing differently that makes their predictions
    better than almost everyone else’s?
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
- en: The habits of highly effective forecasters
  id: totrans-split-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The literature on superforecasting, from Tetlock, Mellers, and others, finds
    some commonalities between good predictors. One is a tendency to think in numbers.
    Quantitative reasoning sharpens thinking in this context. “Somewhat likely,” “pretty
    unlikely,” “I’d be surprised.” These kinds of phrases, on their own, convey some
    useful information about someone’s confidence in a prediction, but they’re impossible
    to compare to each other — is “pretty unlikely” more or less doubtful than “I’d
    be surprised”? Numbers, by contrast, are easy to compare, and they provide a means
    of accountability. Unsurprisingly, many great forecasters, in Samotsvety and elsewhere,
    have backgrounds in computer science, economics, math, and other quantitative
    disciplines.
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
- en: 'Hickman recalls telling her coworkers in intelligence that she was working
    on forecasting and being frustrated by their skeptical responses: that it’s impossible
    to put numbers on such things, that the true probabilities are inherently unknowable.
    Of course, the true probabilities aren’t known, but that isn’t the point. Even
    if they weren’t using numbers, her peers were “actually doing these calculations
    implicitly all the time,” she recalls.'
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
- en: You might not tell yourself “the odds of China invading Taiwan this year is
    10 percent,” but how much time a deputy assistant Secretary of Defense spends
    studying, say, Taiwan’s naval strategy is probably a reflection of their concept
    of the underlying probability. They wouldn’t spend any time if their probability
    was 0.1 percent; they would be losing their mind if their probability was 90 percent.
    In reality, it’s somewhere in between. They’re just not making that assessment
    explicit or putting it in a form that makes it possible to judge their accuracy
    and from which they can learn in the future. Numeric predictions can be graded;
    they let you know when you’re wrong and how wrong you are. That’s exactly why
    they’re so scary to make.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
- en: 'That leads to another commonality: practice. Forecasting is a lot like any
    other skill — you get better with practice — so good forecasters forecast a lot,
    and that in turn makes them better at it. They also update their forecasts a lot.
    The Taiwan numbers I heard from the team at the start of our meeting? They weren’t
    the same by the end. Part of practicing is adjusting and tweaking constantly.'
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
- en: But not everyone who practices, and uses numbers to do so, succeeds. In *Superforecasting*,
    Tetlock and Gardner come up with an array of “commandments” to help us mere mortals
    do better, but I often find myself struggling to implement them. One is “strike
    the right balance between under- and overreacting to evidence”; another is “strike
    the right balance between under- and overconfidence.” Great, I will simply strike
    correct balances in all things. I will become Ty Cobb by always striking the right
    balance between swinging too early and swinging too late.
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
- en: However, another commandment — to pay attention to “base rates” — came up a
    lot when talking to the Samotsvety team. In forecasting lingo, a “base rate” is
    the rate at which some event tends to happen. If I want to project the odds that
    the New York Yankees win the World Series, I might note that out of 119 World
    Series to date, the Yankees [have won 27](https://www.foxsports.com/stories/mlb/world-series-winners-complete-list-by-year),
    for a base rate of 22.7 percent. If I knew nothing else about baseball, that would
    incline me to give the Yankees better odds than any other team to win the next
    World Series.
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
- en: Of course, you’d be a fool to depend on that alone — in baseball, you have a
    lot more information than base rates to go on, like stats on every player, years
    of modeling telling you which stats are most predictive of team performance, etc.
    But when projecting other kinds of events where far less data exists, you often
    don’t have any more to go on than the base rate.
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
- en: This was the whole explanation, it turns out, for why everyone in the group
    put a relatively low probability on the odds of a successful Chinese attempt to
    retake Taiwan by 2030\. Members argued over just how strong the reasons for China
    to attempt such an effort was, but there was broad agreement that the base rate
    of war — between China and Taiwan or just between countries in general — is [not
    very high](https://ourworldindata.org/grapher/number-of-wars-project-mars). “I
    think that’s why we were all so far below 50 percent, because we were all starting
    really low,” Justice explained when I asked.
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
- en: That kind of attention to base rates can be surprisingly powerful. Among other
    things, it gives you a starting point for questions that might seem otherwise
    intractable. Say you wanted to predict whether [India](/india) will go into a
    recession next year. Starting by counting up the number of years in which India
    has had a recession since independence and calculating a probability is a simple
    way to begin a guess without requiring huge amounts of research. One of my first
    [successful predictions](/future-perfect/2020/1/7/21051910/predictions-trump-brexit-recession-2019-2020)
    was that neither India nor China would go into a recession in 2019\. I got it
    right not because I’m an expert on either, but because I paid attention to the
    base rates.
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
- en: But there’s more to successful forecasting than just base rates. For one thing,
    knowing what base rate to use is itself a bit of an art. Going into the China/Taiwan
    discussion, I [counted](https://en.wikipedia.org/wiki/First_Taiwan_Strait_Crisis)
    that there have been four [lethal](https://en.wikipedia.org/wiki/Kashmir_Princess)
    exchanges [between](https://en.wikipedia.org/wiki/Battle_of_Dong-Yin) China and
    [Taiwan](https://en.wikipedia.org/wiki/Second_Taiwan_Strait_Crisis) since the
    end of the Chinese Civil War in 1949\. That’s four incidents over 75 years, implying
    that there’s a 5 percent chance of a lethal exchange in a given year. There are
    six years between now and 2030, so I got a 26.5 percent chance that there’d be
    a lethal exchange in at least one of them. After adjusting down for the odds that
    the exchange is just a skirmish versus a full invasion, and compensating for the
    chances that Taiwan beats China, I got my 5 percent number.
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
- en: But in our discussion, the participants brought up all kinds of other base rates
    I hadn’t thought of. Sempere alone brought up three. One was the rate at which
    provinces claimed by China (like Hong Kong, Macau, and Tibet) have eventually
    been absorbed, peacefully or by force; another was how often control of Taiwan
    has changed over the last few hundred years (twice; once when Japan took over
    from the Qing Empire in 1895 and once when the Chinese Nationalists did in 1945);
    the third base rate used [Laplace’s rule](https://www.lesswrong.com/posts/Tg5pQCjpefFiqaKjw/limitations-of-laplace-s-rule-of-succession).
    Laplace’s rule states that the probability of something that hasn’t happened before
    happening is 1 divided by N+2, where N is the number of times it hasn’t happened
    in the past. So the odds of the People’s Republic of China invading Taiwan this
    year is 1 divided by 75 (the number of years since 1949 when this has not happened)
    plus 2, or 1/77, or 1.3 percent.
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
- en: 'Sempere averaged his three base rates to get his initial prediction: 8 percent.
    Is that the best method? Should he have added even more? How should he have adjusted
    his guess after our discussion? (He nudged up to 12 percent.) There’s no firm
    rule about these questions. It’s ultimately something that can only be judged
    by your track record.'
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
- en: What if knowing the future is knowing the world?
  id: totrans-split-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Justice, the MBA student, tells me that quantitative skill is one reason why
    the Samotsvety crew is so good at prediction. Another reason is more abstract,
    maybe even grandiose: that as you forecast, you develop “a better model of the
    world ... you start to see patterns in how the world works, and then that makes
    you better at forecasting.”'
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
- en: “It’s helpful to think of learning forecasting as having two steps,” he wrote
    in a follow-up email to me. “The first (and most important) step is the recognition
    that the future and past will look mostly the same. The second step is isolating
    that small bundle of cases where the two are different.” And it’s in that second
    step that developing a clear model of how the world works, and being willing to
    update that model frequently, is most helpful.
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
- en: A lot of Justice’s “updates” to his world model have been toward assuming more
    continuity. In recent years, he says, he learned a lot from facts like, “Putin
    didn’t die of cancer, use nukes, or get removed from office; bird flu didn’t jump
    to and spread among humans (so far); Viktor Orban (very recently) dropped his
    objection to Ukraine aid.” What these have in common is “they’re predominantly
    about major events that *didn’t* happen, implying the future will look a lot like
    the past.”
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
- en: 'The hardest part of the job is predicting those rare exceptions where everything
    changes. Samotsvety’s big coming-out party happened in early 2022 when they published
    an [estimate of the odds that London would be hit by nuclear weapons](https://samotsvety.org/blog/2022/03/10/samotsvety-nuclear-risk-forecasts-march-2022/)
    as a result of the Ukraine conflict. Their estimated odds of a reasonably prepared
    Londoner dying from a nuclear warhead in the next month were 0.00241 percent:
    very, very low, all things considered. The prediction got some [press attention](https://www.wired.com/story/micromorts-nuclear-war/)
    and earned rejoinders from nuclear experts like Peter Scoblic, who argued it significantly
    [understated the risk of a nuclear exchange](https://forum.effectivealtruism.org/posts/W8dpCJGkwrwn7BfLk/nuclear-expert-comment-on-samotsvety-nuclear-risk-forecast-2).
    It was a big moment for the group — but also an example of a prediction that’s
    very, very difficult to get right. The further you’re straying from the ordinary
    course of history (and a nuclear bomb going off in London would be straying very
    far), the harder this is.'
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
- en: The tight connection between forecasting and building a model of the world helps
    explain why so much of the early interest in the idea came from the intelligence
    community. Matheny and colleagues wanted to develop a tool that could give policymakers
    real-time numerical probabilities, something that intelligence reports have historically
    not done, much to policymakers’ consternation. As early as 1973, [Secretary of
    State Henry Kissinger was telling colleagues](https://drive.google.com/file/d/1e_9pEYgRPsF0R1EMXUQIb6TSXw9fIZNM/view)
    he wished “intelligence would supply him with estimates of the relevant betting
    odds.”
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
- en: Matheny’s experiment ran through 2020\. It included both the aggregative contingent
    estimation (ACE), which used members of the public and grew into the Good Judgment
    Project, and the IC Prediction Market (ICPM), which was available to intelligence
    analysts with access to classified information. The two sources of information
    were [about equally accurate](https://goodjudgment.io/docs/Goldstein-et-al-2015.pdf),
    despite the outsiders’ lack of classified access. The experiment was exciting
    enough to spawn a [UK offshoot](https://www.economist.com/science-and-technology/2021/04/15/how-spooks-are-turning-to-superforecasting-in-the-cosmic-bazaar).
    But funding on the US side of the Atlantic ran out, and the culture of forecasting
    in intelligence died off.
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
- en: To Matheny, it’s a crying shame, and he wishes that government institutions
    and think tanks like his would get back into the habit and act a bit more like
    Samotsvety. “People might assume that the methods that we use in most institutions
    that are responsible for analysis have been well-evaluated. And in fact, they
    haven’t. Even when there are organizations whose decisions cost billions of dollars
    or even trillions, billions of dollars in the case of key national security decisions,”
    he told me. Forecasting, by contrast, works. So what are we waiting for?
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
