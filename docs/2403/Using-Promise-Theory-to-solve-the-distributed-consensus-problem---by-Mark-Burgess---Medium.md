<!--yml

category: 未分类

date: 2024-05-27 14:52:45

-->

# 使用承诺理论解决分布式共识问题 | 作者：Mark Burgess | Medium

> 来源：[https://mark-burgess-oslo-mb.medium.com/using-promise-theory-to-solve-the-distributed-consensus-problem-4cc2116f24e1](https://mark-burgess-oslo-mb.medium.com/using-promise-theory-to-solve-the-distributed-consensus-problem-4cc2116f24e1)

# 使用承诺理论解决分布式共识问题

## 安全工具用于在微客户端之间共享细粒度数据

每当我们试图在IT的一个角落修复问题时，似乎总是在搬弄其它角落，制造新问题——用一个难题换另一个难题。微服务就是一个典型例子：数据的去规范化和流程的集中化使得团队的相互依赖性降低（解决了一个人为问题），但也带来了管理共享状态的挑战。将单一数据存储分解为（并非完全）独立的部分很容易破坏算法、数据、用户体验的完整性，从而影响到[业务连续性](https://en.wikipedia.org/wiki/Business_continuity_planning)。随着这些事务逐渐受到法律法规的监管（如[GDPR](https://gdpr-info.eu/)、[DORA](https://www.digital-operational-resilience-act.com/)等），这些头疼的问题变得更加明显。其中最突出的问题是所谓的*一致性*问题，因为它涵盖了如此多的内容，涉及到工程师能够理解的技术问题。

# 我们敢不敢问？

[数据一致性](https://en.wikipedia.org/wiki/Data_consistency)问题依然是吸引学术界和从业者关注的问题之一。它与[分布式共识](https://en.wikipedia.org/wiki/Consensus_(computer_science))的概念混为一谈。英语的含义基本相同，但技术上的用法不同。令人困惑的是，后者常常作为前者标准算法（如[Paxos](https://en.wikipedia.org/wiki/Paxos_(computer_science))和[Raft](https://en.wikipedia.org/wiki/Raft_(algorithm))）的一部分。还有一些较为影响深远但不为人知的成果，例如[FLP定理](https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf)，它“证明”了在异步环境中分布式共识的不可能性，并使人们不敢轻易深思。此外，还有著名的CAP猜想，它的普及（以及明显无休止的修订）以一种普遍无益的方式增加了神秘色彩。

> IT行业并不擅长提出深入问题——我们喜欢相信那些可以替我们思考的领导者和影响者。但是这些思考者有时会留下问题的半解答，我们最终得到的是那些随意软件工程师解读的标准解决方案。我们敢质疑它们吗？

在我在计算机科学领域的任期中，我试图通过开发清晰的模型来澄清甚至揭穿关于什么可以做什么不能做的偶尔神话，其中许多模型在我的[Treatise on Systems](http://markburgess.org/treatise.html)中进行了总结，这些模型通常是在日益普及的[承诺理论](https://en.wikipedia.org/wiki/Promise_theory)的帮助下完成的。数据一致性问题也不例外，我们一直在谈论的是[**安德拉斯·格尔利茨**](https://itnext.io/microservices-and-the-myth-of-loose-coupling-9bbca007ac1a)和我最近与他有关[**Omniledger校准软件**](https://omniledger.io/)的简单答案。

让我们应用最少量的[承诺理论](http://markburgess.org/promises.html)来展示如何在扩展服务的范围和可用性的同时工程化*有意的一致性*数据。

# 一致性：一只滑雪板是平行的！

通过一致性，我们显然不是指把数据打成一种光滑多孔的质地，以便更快地供应！IT中的一致性指的是系统中**事实**的纯粹无延迟的同质性——数据值或跨越多台计算机的键值对。

对于大多数人来说，一致性表现为商业可靠性（甚至安全性）问题。现在它与*监管合规性*问题息息相关，特别是在欧盟，以及隐私和用户体验问题。相关术语*共识*和*法定人数*更加微妙地用于指代如何在争议事实上达成一致意见，但在实践中，所有这些都意味着我们希望系统的各个部分在它们对*数据承诺*方面达成*一致*的*目标*。

在滑雪斜坡上，教练教导滑雪者在转弯时保持他们的滑雪板对齐。当平行时，滑雪板的方向“一致”或与彼此一致。有人可能会说，他们在他们的平行性上不那么时髦：“嗯，其中一只滑雪板是平行的！”在IT领域，我们不希望我们的系统因为错位而被一分为二。

我们实际上无法阻止它发生，但我们可以防止自己*看见*它，以使其在实践中不产生任何影响。严格来说，这种预防的程度在关于数据一致性的讨论中占有一席之地。

# 眼见为实

如果共识是关于赢得一场争论，那么一致性就是一个关于*状态校准*的问题。任何用户或观察者都有平等的“权利”或能力来测量不同独立代理给出的答案，并将它们进行比较，看看它们是否相等。这个单一的测量点校准了任何两个代理的结果（见下图）。

**A和B应该保持一致。A声称值是a，B声称是b。决定是否接收这些并发现a = b是C的职责。**

*C*观察*A*和*B*，并利用这些信息，它能够根据自己的测量和最好的能力向任何其他感兴趣的代理人作出基于这些信息的有条件承诺，包括原始的*A*和*B*。*C*因此是一个校准器 - 真相的独立裁决者。这就是法庭的工作方式：法官比较*A*和*B*以解决分歧或作出选择。共识意味着*A*、*B*和*C*对承诺的值达成一致。如果存在正确变化的权威来源，这很容易。这是我们需要保留的内容。

在特定值的不同版本上达成一致相对较容易，只要a和b的值不改变。但在像在雪堆上碰撞时这样动态变化的环境中，保持a和b的滑雪板对齐取决于每次变化的竞赛。如果*a*在无人注意时发生变化，而*C*长时间没有测量*a*，所以它仍然认为*a=b*，但*A*知道更多。我们如何知道这一点？显然，我们不能，因为我们已经输掉了这场竞赛，但我们需要问这对任何可能发生的事情是否重要。如果一个滑雪者在森林里摔倒，而没有人看到…我们应该关心吗？

# 中心服务！？

一个声音越来越多的群体正在挑战FLP和CAP结果的权威，指出它们的影响被误解了。分布式共识的不可能性主张源于对变化普遍性的错误假设。标准假设是它必须同时适用于每个人。“同时”意味着什么？如果你曾经看过雷暴，你会知道感官数据（我们看到和听到的）即使在闪电发生在单一时刻和单一位置的情况下，到达时间也是非常不同的。

*可用性*（愿意倾听）和*共识*（一致）不是需要暗示严格时间精确性的全局约束，它们实际上只是观察者和影响者（用户）*本地*行为的约束。承诺理论关于自治代理，这意味着代理之间的*因果独立性*：一个代理承诺的变化不能在没有承诺者明确接受的情况下影响另一个。因此，承诺理论可以帮助我们澄清有关因果关系错误的地方。

数据对齐最终归结为信息系统中不同代理如何相互信号和观察变化。毕竟，正是这种变化衡量了跨不同部分过程的时间流逝。观察是一个关键元素，因为当我们闭上眼睛时，我们不会注意到变化（时间的流逝）。当我们再次睁开眼睛时，变化以单个时间单位达到我们。所以每个人都按照自己的意愿接收信息：以自己的节奏，而不是闪电真正打击的时候。

如果我们把这个思想应用到系统中的片段如何调整它们变化的事实，那么在多个位置保持对齐的解决方案就归结为确保我们保留从原始来源的变更历史顺序。如果你用图案绘制的碟子摔碎了，我们可以后来重建图案，只要我们按照正确的时空顺序放置碎片。

确保一致性的一个明显且简单的方法是只有一个答案可供比较。单一副本不可能不一致，所以我们将*单一来源*用作真理和仲裁的来源。对于完美的并行转弯，请使用滑雪板！

行业标准是强制使用单个“主”数据库，并为其冗余复制。这样，您就不必担心“主”是否一致。我们不经常看副本，所以这是避免麻烦的一种方式。将中心化到单个主体被呈现为控制决策，以确保权威来源，即单一控制来源。但是当主失败时，我们必须担心备份是否与主一致。因为我们现在已经失去了原始数据，所以一致的含义现在变得模糊。与什么对齐？哪个滑雪板平行？

许多人还指出，中央服务也可能是一个瓶颈（取决于其相对容量），但在系统设计中中心化的真正重要性实际上是（你猜到了）*校准*——作为数据的标准度量标准。事实证明，我们可以通过引入*数据校准器*并正确配置管道来同时解决一致性问题、瓶颈问题以及部分共享（微服务）问题。这有点像共享时钟，但其中数据流就是时钟本身！通过这种方式，关于数据或网络分区、不可靠连接等的所有担忧可以在每个客户端*本地*进行最大努力地解决。为了让一切同时发生，我们可以简单地为那些没有中央服务等待的人停止时间！

独立承包商还是中央服务？

# 逐个代理扩展

下图展示了客户端与单个服务器之间的基本交互，例如数据库。假设这台服务器上只有一个数据副本，它必须是自洽的。

用户与数据存储交互。因果关系很简单：一个版本，一次一个值。

随着客户数量的增加，单个数据库可能无法处理工作，因此我们寻求扩展系统。使用 Promise Theory 符号，数据库承诺接受数据（-），按客户承诺提供数据（+）的顺序。我们只需要扩展这些承诺以处理一个*超级代理*，它封装了更多的客户端和数据库，以持续在冗余数据副本之间保持对齐。

*单个客户端-服务器对*的真理对于*任意一对*也必须在一组对中成立。考虑下面示意图中的三对。

当 N 个独立的数据存储想要协调每个记录时，可以在其私有范围内一次只能有一个版本，但是每个数据存储和用户可以持有自己关于他们所称之物的版本，因为关于键的一致性并不等同于关于值的一致性。

每对可以独立工作，但如果我们希望*所有三对*能够“始终”互相对齐，我们能够安排它们的数据承诺的完美对齐吗？它们需要协调。

*由于数据更改往往是稀疏的到达过程，它们的流可以自然地合并而不会失去任何争议。如果（在罕见情况下）这些流量都很大，我们可以使用交通灯以常规方式轮询它们。交通圆环（“环形道路”）在交通中这样做。我们可以通过简单轮询入口和出口创建相同的效果。*

“始终”是关键术语，这是人们经常犯错的地方。毕竟，有时候我们不在乎事物是否相同：例如，当没有人在看的时候。滑雪者可以在森林中自己爬起来并恢复而不会被取消比赛资格。我们应该询问“每当有人实际上查看时是否对齐”，而不是“始终相等”，因为这是我们能对他人状态做出的唯一承诺。我们看不到的东西都是无法证实的传闻。

FLP 和 CAP 结果解释得太过严格，即所有时间和位置都必须在一个神秘的*全球时间*的任意小时间间隔内普遍保持一致。然而，当睡觉时，可能经过几个小时，我们既不能说也不关心其他地方的数据是否同步。如果我们忽略不可能观察到不一致的时间，问题就简单地变成了追踪因果顺序中的历史，就像*供应链*一样。我们通过在作出*有条件承诺*时管理可观察量来完成这一点。

我们已经知道实现这一点的简单方法是让所有人与同一个数据库进行交互，这是中央服务模型。我们可以通过引入条件插值管道做得更好。数据队列的读写被集中到一个单一校准的时间轴上。如果两个客户端发送冲突请求，按照先到先服务的原则，后到者将被退回发送者。接受的事务因此排队等待最终的目标地点，以便接收器醒来并可以消化它们。

# 无主的细粒度缩放

让我们一步步来。如果细节太多，您可以跳过此步骤。要使 N 个数据库行为像一个数据库，我们必须注意以下几点：

1.  我们将每个主数据库交互替换为与介入者的互动：一种“虚拟数据服务”，即使用智能数据管道制作的单一数据库的规模模型（由分布式部件制成）。

1.  然后，我们将*能够观察*记录的能力与没有未决变更的条件联系在一起。这与典型的互斥锁略有不同，但本质上是一样的。

1.  我们通过用我们的智能管道包装服务连接，将客户到数据库的典型承诺拦截，现在将一切传递给介入者或数据校准器。

凭借这些承诺，我们实际上可以比主复制集方法更强大地扩展数据复制的上下游。每个数据库都可以在其网络边缘几乎完全容量地继续工作。数据校准器在微粒级别协调独立数据库之间的变更，介入代理管理的数据可以覆盖我们想要的整个边缘数据存储的多少。这是一种政策问题。其结果是我们有一个完美的理念：

+   [写时复制](https://en.wikipedia.org/wiki/Copy-on-write)备份所有数据，或者

+   使用非规范化存储的微服务，在某些区域可能只需要缓存少量用户数据。

为了恢复统一性，逐个用一个东西替换三个互动中的三件事。我们可以利用这种简单的因果推理来防止各个层次的挑剔不一致。

理论上许诺，我们通过在想要校准的三个互动周围划定边界（排除数据库本身，我们不希望强制完全相同），称之为单一的超级代理。我们将共享数据的互动重定向到这个新代理，该代理实现了用于因果更新的智能数据管道。

1.  对客户用户而言，现在看起来像是一个数据库规模模型的单一接口（或代理）。

1.  对每个数据库而言，客户端看起来只像一个单一的客户端。

# 承诺

让我们仔细审视客户端-服务器交互，并将每一次直接交互转化为数据流的供应链交互。

一个交互可以通过关于双方行为的承诺交换形式描述。每一方都有决定接受对方什么的自由，尽管这在包括IT在内的人类设计中很少得到适当承认。

**客户端**：

+   客户随时自发进行更改。

+   客户承诺关注并承担由干扰者标记的非接受（失败）的数据强加。

**数据库**：

+   虚拟数据库连接仅接受来自干扰者的读/写/更改命令，并在此类事件之间进入休眠状态。

+   数据库作为其虚拟客户端，向干扰者信号成功/失败的任何尝试读取/写入。

**干扰者**：

+   我们的智能管道仅在相关记录已经通过干扰者记录的所有共享数据更改保持最新的情况下，接受对共享数据的读请求。我们无需等待无关记录。

+   仅当所有活动共享数据连接确认尚未接收到可能读取或写入相关重叠数据的先前命令（例如在受影响值的选择/搜索或受影响值的写入中）时，干扰者才会接受新的写入请求转发给其共享客户。

+   接受的写操作按顺序排队，存在一个由所有活动边缘数据库共享的完全有序队列中，并且只有在所有数据库更新完成后才会移除。

+   该队列处理提交请求（作为各个数据库的私有写队列），并尽快清空队列，以便可以再次读取受影响的记录。正是这种粒度锁定使得几乎无需等待地复制一致的共享状态，

+   操作通知客户有关任何尝试读取/写入的成功/失败，就像普通的SQL API一样。

干扰者现在是单一缩放真相的守门人——高度细粒度的智能数据校准器。其逻辑完全由条件承诺决定，就像因果供应链一样。除非前提条件未满足，否则一切正常流动。如果没有人关注，就没有快速交付的压力。如果某处出现交付失败，或者出现交叉的线路，没有人可以插队或取出尚未到达的数据。

如果其中一个数据库变得不可用（例如失去电源或其网络连接导致“分区”），任何客户端都不会观察到有害的错位，因为干扰者会禁止读取，直到一切报告回到同步状态。因此，当一个孤立的接收者重新加入集体时，它必须在为其本地客户端提供任何受影响数据之前追赶共享顺序。在被切断的同时，尝试写入共享状态将简单地失败，而不会阻止向其余可用目标写入。只要所有更改都通过管道传递，就不可能发生冲突。对客户端而言，时间实际上停止，直到分区数据库重新连接。插值器充当所有更改的主帐簿，负责全局顺序和常规语义的处理。

> 大多数解决一致性问题的方案并不试图完全防止此类数据误读，因为这需要对现有技术进行一些改变——但天哪，我们不愿意为了改善公共安全而使技术人员感到不便。更常见的是通过发布“买家注意”通知或“最佳购买”服务的推荐来提供有限的帮助以避免这个问题。这涵盖了一些法律免责声明，可能涵盖了许多情况：毕竟，随着网络可靠性的提高，观察到的不一致性的概率也在缩小。最大的问题变成了在分布式副本之间协调更新时的简单疏忽。

# 这与主复制有何不同？

我们的理想情景承诺每个我们选择跟踪的*单个数据记录*的*虚拟规模模型*，通过智能数据管道连接多个数据库。因果变化管理着任意空间分离的时间顺序，如供应链或管道。在传统的数据库冗余方法中，副本往往会降低数据库的吞吐性能；在这里，情况可能正好相反。

Paxos 和 Raft 使用的副本集合提议，您将真正处理一个主服务器并尝试保持整个数据库备份副本独立对齐。当主服务器死亡或失败时，客户端尝试决定一个新的领导者，以便他们都在与同一服务器通信。这导致了一个延迟，在这段时间内没有人可以写入。滑雪板脱落了！

> 如果我们只想共享几条记录，没有特别需要复制整个数据库。粒度是可扩展性和可靠性的答案。

# 这并不是故事的终结...

这一切都很简单，如果更多人采用这种方法肯定是很好的，但概率往往不支持解决问题。我们简单明了的承诺理论解决方案无法理解现代数据存储面临的最大问题，即它们通常只提供*最新值语义*。缓存问题。

在IT领域，我们假设正确的值是最新的值。这是一场争夺，因为最后的值通过覆盖和抹除之前的内容获胜。因此，如果有恶魔通过系统注入无意义的信息，那么就会有麻烦。即使我们保留总部位置的分类账和交易日志以进行取证，我们仍然生活在当下。我们确定这些日志一致吗？更重要的是，它们是否记录了每个人的*意图*？

我们仍在继续设计软件，这些软件并不会在多个地点之间持续对齐变更。我们将数据世界看作永恒的快照，通过蛮力将离线备份与滞后的快照同步。大多数我们的技术未能将其更改跟踪为数据记录的*版本*。我们仅在边缘少数特定目的上应用连续的[时间序列数据库](https://en.wikipedia.org/wiki/Time_series_database)（可寻址日志）和[版本控制存储库](https://en.wikipedia.org/wiki/Repository_(version_control))（如git）。

在我们这个无处不在的电子商务时代，我们希望数据服务始终*可用*，以确保收入不受干扰。在补货时，有时我们需要暂时关闭店铺以避免搬运物品时的意外。我们相信持续可用性意味着对每个人都进行*即时*和*同时*的更改，但这并非如此。事实上，客户和更新会突然而至，每个事务都需要一定时间（我们称之为*延迟*），因此我们在空隙期间所做的事情可能被忽视。在备份数据时，我们应该希望这些间隙，因为复制通常很难跟上持续变化的步伐，我们担心在关键时刻数据不会对齐的风险。

剩下的是一个建模问题（承诺的强加），并非技术问题本身——但幸运的是，这是另一个时间点的讨论话题。

# 其他参考资料

1.  我在关于[软件风洞](http://markburgess.org/blog_windtunnel.html)的文章中讨论了在各种规模下保持相同承诺的系统扩展问题，并在[系统论文](http://markburgess.org/treatise.html)中详细讨论了这个问题。

1.  这篇文章基于与[安德拉什·格利茨](https://www.researchgate.net/publication/359578461_Continuous_Integration_of_Data_Histories_into_Consistent_Namespaces)合作的论文简化版本，并作为他软件实现的简单介绍。

*如果你需要帮助解决这个问题，我建议联系* [*安德拉什*](https://twitter.com/AndrasGerlits) *或者甚至是我！*

[查看书籍](http://markburgess.org/treatise.html)
