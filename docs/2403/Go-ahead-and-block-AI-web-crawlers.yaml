- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 14:31:09'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-27 14:31:09
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Go ahead and block AI web crawlers
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 请继续阻止AI网络爬虫
- en: 来源：[https://coryd.dev/posts/2024/go-ahead-and-block-ai-web-crawlers/](https://coryd.dev/posts/2024/go-ahead-and-block-ai-web-crawlers/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://coryd.dev/posts/2024/go-ahead-and-block-ai-web-crawlers/](https://coryd.dev/posts/2024/go-ahead-and-block-ai-web-crawlers/)
- en: AI companies are crawling the open web to, ostensibly, improve the quality of
    their models and products. This process is extractive and accrues the benefit
    to said companies, not the owners of sites both small and large.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: AI公司正在爬取公开网络，表面上是为了改进其模型和产品的质量。这一过程是一种抽取行为，并将好处积累给了这些公司，而非站点所有者，无论其大小。
- en: AI companies are crawling the open web to, ostensibly, improve the quality of
    their models and products. This process is extractive and accrues the benefit
    to said companies, not the owners of sites both small and large.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: AI公司正在爬取公开网络，表面上是为了改进其模型和产品的质量。这一过程是一种抽取行为，并将好处积累给了这些公司，而非站点所有者，无论其大小。
- en: '**[Per The Verge and OpenAI](https://www.theverge.com/2023/8/7/23823046/openai-data-scrape-block-ai)**'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**[根据 The Verge 和 OpenAI](https://www.theverge.com/2023/8/7/23823046/openai-data-scrape-block-ai)**'
- en: '"Web pages crawled with the GPTBot user agent may potentially be used to improve
    future models …"'
  id: totrans-split-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '"Web pages crawled with the GPTBot user agent may potentially be used to improve
    future models …"'
- en: '"…allowing GPTBot to access your site can help AI models become more accurate
    and improve their general capabilities and safety."'
  id: totrans-split-10
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '"…允许GPTBot访问您的网站可以帮助AI模型变得更加准确和提高其总体能力和安全性。"'
- en: All of which assumes that you see some broader benefit to letting a private
    institution improve their product with negligible benefit to you.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这一切都假设你认为让私人机构通过几乎没有给你带来任何好处的方式改进他们的产品有某种更广泛的好处。
- en: '**[Again, via The Verge](https://www.theverge.com/2023/8/21/23840705/new-york-times-openai-web-crawler-ai-gpt)**'
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**[再次，通过 The Verge](https://www.theverge.com/2023/8/21/23840705/new-york-times-openai-web-crawler-ai-gpt)**'
- en: '*The New York Times* has blocked OpenAI''s web crawler, meaning that OpenAI
    can''t use content from the publication to train its AI models. If you check [the
    NYT''s robots.txt page](https://www.nytimes.com/robots.txt), you can see that
    the *NYT* disallows GPTBot, the crawler that OpenAI introduced [earlier this month](https://www.theverge.com/2023/8/7/23823046/openai-data-scrape-block-ai).'
  id: totrans-split-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*纽约时报* 阻止了 OpenAI 的网络爬虫，这意味着 OpenAI 无法使用该出版物的内容来训练其AI模型。如果您查看[纽约时报的robots.txt页面](https://www.nytimes.com/robots.txt)，您会发现
    *NYT* 禁止了 GPTBot，这是 OpenAI 本月早些时候引入的爬虫。'
- en: The publication has gone on to block additional crawlers and you can see the
    full list by [accessing their robots.txt file](https://www.nytimes.com/robots.txt).
    There are open resources like [Dark Visitors](https://darkvisitors.com/) cropping
    up to maintain and provide lists of extractive AI crawlers.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 该出版物已继续阻止其他爬虫，并通过[访问其robots.txt文件](https://www.nytimes.com/robots.txt)可见完整列表。出现了像[Dark
    Visitors](https://darkvisitors.com/)这样的开放资源，以维护并提供抽取性AI爬虫列表。
- en: All of this marks a clear and fundamental distinction between search crawlers
    and AI crawlers. The former extracts value from open content, the latter indexes
    and directs users *to* content, enhancing discoverability and aggregating data.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些标志着搜索爬虫和AI爬虫之间的明显和根本区别。前者从开放内容中提取价值，后者索引并引导用户*至*内容，增强了可发现性并聚合了数据。
- en: It is not incumbent upon news publications, blogs, social media sites or any
    other platform to cede this data to AI companies for free, nor should they. But,
    as search giants (and startups — looking at you Browser Company) lean (questionably)
    into surfacing extractive summaries rather than directing users to original, independent
    results, it makes more and more sense to block the agents they're using to crawl
    and surface those answers.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 新闻出版物、博客、社交媒体网站或任何其他平台无需免费将此数据交给AI公司，也不应该。但是，随着搜索巨头（以及初创公司——看看你Browser Company）倾向于（可疑地）提供抽取式摘要而非将用户引导至原始、独立的结果，阻止它们使用用于抓取和展示这些答案的代理程序变得越来越合理。
- en: Licensing deals to offer content up to AI companies or existing tech giants
    are similarly attractive and again, [only of benefit to the company yielding access
    to data they control but didn't create](https://www.reuters.com/technology/reddit-ai-content-licensing-deal-with-google-sources-say-2024-02-22/).
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 授权协议以向AI公司或现有科技巨头提供内容同样具有吸引力，再次证明，[只对掌控但未创建数据的公司有利](https://www.reuters.com/technology/reddit-ai-content-licensing-deal-with-google-sources-say-2024-02-22/)。
- en: That there's some sort of broad societal benefit to all of this is, at this
    point, mere speculation. What this does accomplish though is allow companies to
    continue to champion chat bots and image generators that remain rife with issues
    while chasing ever increasing valuations.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，这些工具有某种广泛的社会效益是纯粹的推测。然而，这确实允许公司继续支持充满问题的聊天机器人和图像生成器，并追逐不断增长的估值。
- en: I'm not excited when a product I use integrates AI, I'm weary and wary of it.
    What does it do to make the experience better? I'd love to know. Copilot is a
    mild improvement over traditional autocomplete. Advice on a subject is best provided
    by someone that has experience on what they're advising you on rather than a bucket
    of bits that will spit out believable-sounding text output.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 当我使用的产品集成AI时，我并不感到兴奋，而是感到疲倦和警惕。它如何使体验更好？我很想知道。Copilot相比传统的自动完成功能略有改进。关于一个主题的建议最好由有经验的人提供，而不是由一个只会输出听起来可信的文本的一大堆比特桶来提供。
- en: The companies building these tools will argue that more data will improve accuracy
    and improve the tools overall, but you have no responsibility to concede that
    point. Blocking these crawlers also assumes that you trust these companies to
    obey a long-lived, standard tool like `robots.txt` and given their argument that
    everything they can access is fair game for ingestion, it's fair to question whether
    they'll have the basic decency to do so.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 建造这些工具的公司会辩称更多的数据会提高准确性并改善工具的整体表现，但你无需接受这一点。阻止这些爬虫也意味着你信任这些公司遵守像`robots.txt`这样的长期标准工具，鉴于他们主张他们可以访问的一切都可以用于摄取，质疑他们是否有基本的良知去这样做是公平的。
- en: My `robots.txt` looks like this — if I'm missing anything, [I'd love to know](https://coryd.dev/contact).
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 我的`robots.txt`看起来像这样 — 如果我漏掉了什么，[我很乐意知道](https://coryd.dev/contact)。
- en: '[PRE0]'
  id: totrans-split-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Other great posts on the subject:**'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**该主题的其他优秀文章：**'
- en: '**Update March 27, 2024:** Many thanks to [Jens](https://meiert.com/en/) for
    pointing out that the `User-agent` rules can be safely combined preceding a `Disallow`
    statement.'
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**2024年3月27日更新：** 感谢[Jens](https://meiert.com/en/)指出`User-agent`规则可以在`Disallow`语句前安全地组合使用。'
- en: <svg xmlns="http://www.w3.org/2000/svg" data-tablericon-name="brand-github"
    fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"
    stroke-width="2" viewBox="0 0 24 24"><title>GitHub repository</title>xmlns="http://www.w3.org/2000/svg"width="24"height="24"viewBox="0
    0 24 24"fill="none"stroke="currentColor"stroke-width="2"stroke-linecap="round"stroke-linejoin="round"class="icon
    icon-tabler icons-tabler-outline icon-tabler-brand-github"></svg>Take a look at
    [the GitHub repository for this project](https://github.com/ai-robots-txt/ai.robots.txt).
    (And give it a star if you feel like it.)
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: <svg xmlns="http://www.w3.org/2000/svg" data-tablericon-name="brand-github"
    fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round"
    stroke-width="2" viewBox="0 0 24 24"><title>GitHub仓库</title>xmlns="http://www.w3.org/2000/svg"width="24"height="24"viewBox="0
    0 24 24"fill="none"stroke="currentColor"stroke-width="2"stroke-linecap="round"stroke-linejoin="round"class="icon
    icon-tabler icons-tabler-outline icon-tabler-brand-github"></svg>请查看[此项目的GitHub仓库](https://github.com/ai-robots-txt/ai.robots.txt)。（如果你愿意，请给它点赞。）
