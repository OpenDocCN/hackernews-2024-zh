<!--yml

category: 未分类

date: 2024-05-29 12:12:24

-->

# NIST 员工反对预期任命‘有效利他主义’AI研究员到美国AI安全研究所 | VentureBeat

> 来源：[https://venturebeat.com/ai/nist-staffers-revolt-against-potential-appointment-of-effective-altruist-ai-researcher-to-us-ai-safety-institute/](https://venturebeat.com/ai/nist-staffers-revolt-against-potential-appointment-of-effective-altruist-ai-researcher-to-us-ai-safety-institute/)

***欢迎加入我们于6月5日返回纽约，与执行领导合作，探讨有关AI模型偏见、性能和伦理合规性的全面审计方法。了解您如何可以[参与这里](https://impact.venturebeat.com/ai-impact-tour/the-ai-audit/)。***

* * *

根据至少两位直接了解情况的消息来源（要求匿名），国家标准与技术研究所（NIST）正面临内部危机，因为员工和科学家们威胁要因为预计任命[保罗·克里斯蒂亚诺](https://paulfchristiano.com/)到该机构新成立的[美国AI安全研究所](https://venturebeat.com/ai/as-nist-funding-challenges-persist-schumer-announces-10-million-for-its-ai-safety-institute/)（AISI）的关键职位而辞职。

NIST 是美国商务部的一个机构，其使命是“通过推进测量科学、标准和技术的发展，促进美国的创新和工业竞争力，从而增强经济安全和改善我们的生活质量。” 根据该机构的网站，其核心能力包括“测量科学”、“严格的可追溯性”和“标准的制定和使用”。NIST 还制定了网络安全标准、指南和最佳实践，并于 2023 年 1 月发布了一份 [AI安全框架](https://venturebeat.com/ai/nist-releases-new-ai-risk-management-framework-for-trustworthy-ai/)。

克里斯蒂亚诺因其与有效利他主义（EA）运动及其分支长期主义（一种优先考虑人类长期未来的观点，由哲学家威廉·麦卡斯基尔[推广](https://www.wired.com/story/will-macaskill-longtermism/)）的关系而闻名，据称在今天之前，没有人知道他被匆忙聘用的情况，其中一位消息来源称。 

来自商务部长吉娜·雷蒙多直接下令任命克里斯蒂亚诺已在NIST员工中引起了愤怒，他们担心克里斯蒂亚诺与EA和长期主义的联系可能会损害该研究所的客观性和完整性。

### VB 活动

**AI影响之旅：AI审计**

加入我们，于6月5日回到纽约市，与顶尖执行领导人共同探讨审计人工智能模型的策略，以确保在各种组织中实现公平、优化性能和道德合规性。 保障您参加这一独家邀请活动的名额。

[申请邀请](https://impact.venturebeat.com/ai-impact-tour/the-ai-audit/)

然而，美国科学家联合会的新兴技术和国家安全副主任迪维安什·考希克（Divyansh Kaushik）告诉VentureBeat，拜登总统于2023年11月颁布的[AI行政命令](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/)明确要求NIST和AISI专注于某些任务——包括CBRN（化学、生物、放射性和核材料），保罗·克里斯蒂亚诺“非常合格”。

许多人称EA——由[有效利他中心](https://www.centreforeffectivealtruism.org/)定义为“利用证据和理性来尽可能地造福他人的知识项目”——已经变成了一个类似于邪教的高度有影响力和富有的追随者群体（由FTX创始人和囚犯山姆·班克曼-弗里德赫著名），他们的主要关注点围绕防止未来的人工智能灾难摧毁人类。 EA的批评者专注于这种存在风险，或“X风险”，认为这正在损害对当前、可测量的人工智能风险——包括偏见、虚假信息、高风险应用和传统网络安全——的必要关注。

## 美国人工智能安全研究所于2023年11月成立。

AISI [成立于](https://www.commerce.gov/news/press-releases/2023/11/direction-president-biden-department-commerce-establish-us-artificial)2023年11月，以“支持商务部分配的职责”为目标，依据[AI行政命令](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/)。 今天早些时候，美国参议院多数党领袖查克·舒默（D-NY）[宣布](https://venturebeat.com/ai/as-nist-funding-challenges-persist-schumer-announces-10-million-for-its-ai-safety-institute/)，NIST将获得最多1000万美元用于成立美国人工智能安全研究所。

上个月，VentureBeat [报道](https://venturebeat.com/ai/biden-appoints-ai-safety-institute-leaders-as-nist-funding-concerns-linger/) 对NIST在AISI周围缺乏透明度的批评：在12月中旬，来自两党的众议院科学委员会议员向NIST发送了一封信，Politico 报道称“批评”该机构缺乏透明度，未能公布与新美国AI安全研究所相关的计划研究拨款的竞争过程。透明度缺失集中体现在对RAND公司潜在资助的缺乏公开，RAND是一个与科技亿万富翁、AI行业和有效利他主义紧密相关的影响力思想领袖（Politico报道）。 （VentureBeat还报道了AI“安全”和安全领域内有效利他主义信徒的“广泛网络”，包括RAND和领先的LLM模型公司Anthropic）。

## ‘确保NIST的使命不受影响’

Kaushik告诉VentureBeat，无论谁被任命为AISI角色，“确保NIST的使命不受影响是非常重要的。”

他说：“NIST一直以来都在进行高度扎实的系统测量研究。”他表示：“我们正在尝试建立一个针对通用模型假设风险的评估程序，这是未曾涉足的领域。我完全理解NIST科学家们可能会感到的担忧，商务部领导层有责任确保任何任命都忠实于科学和NIST的使命与方法。”

如果某些任命导致NIST的“超级科学家”辞职，他补充说：“那将是一种遗憾 —— 在这种情况下，我当然希望秘书能够审视因任命某人而可能失去的东西，并重新考虑她的选择。”

国会委员会已经密切关注AISI的工作。他指出：“我希望他们能够与优秀的测量科学家一起做出良好的工作，并以NIST的优势为依托，而不是试图重新定义NIST的使命和工作内容。”

在[X的帖子](https://twitter.com/dkaushik96/status/1766108613431427445)中，Kaushik写道：“如果他们能够迅速雇佣某人，那太好了！这应该受到赞扬，而不是责备。事实上，EO的紧迫时间表要求必须这样做。”

VentureBeat已经联系商务部长吉娜·雷蒙多、AISI主任伊丽莎白·凯利和保罗·克里斯蒂亚诺。如果我们收到回复，我们将进行更新。

**VB Daily**

保持了解！每天获取您收件箱中的最新消息

通过订阅，您同意VentureBeat的[服务条款。](/terms-of-service/)

感谢订阅。查看更多[VB通讯简报](/newsletters/)。

发生了一个错误。
