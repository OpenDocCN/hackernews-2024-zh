- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-29 12:41:15'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-29 12:41:15'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Why Google failed to make GPT-3 + why Multimodal Agents are the path to AGI
    — with David Luan of Adept
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么谷歌未能制作GPT-3 + 为什么多模态代理是通向AGI的路径 — 与Adept的David Luan
- en: 来源：[https://www.latent.space/p/adept](https://www.latent.space/p/adept)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.latent.space/p/adept](https://www.latent.space/p/adept)
- en: '*Our next SF event is [AI UX 2024](https://lu.ma/aiux) - let’s see the new
    frontier for UX since [last year](https://www.latent.space/p/build-ai-ux)!*'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们的下一个旧金山活动是 [AI UX 2024](https://lu.ma/aiux) - 让我们看看UX的新前沿，因为[去年](https://www.latent.space/p/build-ai-ux)以来！*'
- en: '*Last call: we are recording a preview of [the AI Engineer World’s Fair](https://twitter.com/aiDotEngineer/status/1754929063993737721)
    with swyx and Ben Dunphy, [send any questions](mailto:ben@ai.engineer) about [Speaker
    CFPs](https://docs.google.com/forms/d/e/1FAIpQLScc-47zw-tWjYbhAkwTeLy_-MQW3L-3uwtaVnEzudrEZcQ7bg/viewform?usp=sf_link)
    and [Sponsor Guides](mailto:ben@ai.engineer) you have!*'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: '*最后通告：我们正在录制 [AI工程师世界博览会](https://twitter.com/aiDotEngineer/status/1754929063993737721)
    的预览，与swyx和Ben Dunphy一起，[发送任何关于](mailto:ben@ai.engineer) [Speaker CFPs](https://docs.google.com/forms/d/e/1FAIpQLScc-47zw-tWjYbhAkwTeLy_-MQW3L-3uwtaVnEzudrEZcQ7bg/viewform?usp=sf_link)
    和 [Sponsor Guides](mailto:ben@ai.engineer) 的问题！*'
- en: '*Alessio is **now hiring engineers** for a new startup he is incubating at
    Decibel: Ideal candidate is an “ex-technical co-founder type”. [Reach out to him](https://twitter.com/FanaHOVA/)
    for more!*'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: '*Alessio 正在为他在 Decibel 孵化的新创业公司招聘工程师：理想的候选人是“前技术联合创始人类型”。 [联系他](https://twitter.com/FanaHOVA/)
    获取更多信息！*'
- en: '* * *'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '**[David Luan](https://twitter.com/jluan)** has been at the center of the modern
    AI revolution: he was the ~30th hire at OpenAI, he led Google''s LLM efforts and
    co-led Google Brain, and then started Adept in 2022, one of the leading companies
    in the AI agents space. In today''s episode, we asked David for some war stories
    from his time in early OpenAI (including working with [Alec Radford](https://twitter.com/swyx/status/1699369076529971545)
    ahead of the GPT-2 demo with Sam Altman, that resulted in [Microsoft’s initial
    $1b investment](https://openai.com/blog/microsoft-invests-in-and-partners-with-openai)),
    and how Adept is **building agents that can “do anything a human does** ***on
    a computer*****" — his definition of useful AGI.**'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**[David Luan](https://twitter.com/jluan)** 是现代人工智能革命的中心人物：他是 OpenAI 的第30位员工，领导了谷歌的LLM项目并共同领导了Google
    Brain，然后在2022年创立了Adept，这是人工智能代理领域的领先公司之一。在今天的节目中，我们请教了David关于他在早期OpenAI的时光中的一些战斗经历（包括与
    [Alec Radford](https://twitter.com/swyx/status/1699369076529971545) 合作，在与Sam Altman展示GPT-2之前，导致了[Microsoft的初始10亿美元投资](https://openai.com/blog/microsoft-invests-in-and-partners-with-openai)），以及Adept如何**构建能够“在计算机上做任何人类做的事情”***
    — 他对有用的AGI的定义。'
- en: While we wanted to discuss Adept, we couldn’t talk to a former VP Eng of OpenAI
    and former LLM tech lead at Google Brain and not ask about the elephant in the
    room.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们想讨论Adept，但我们无法与前OpenAI副总裁兼Google Brain的前LLM技术负责人交谈，而不谈到房间里的大象。
- en: It’s often asked how Google had such a huge lead in 2017 with Vaswani et al
    creating the Transformer and [Noam Shazeer predicting trillion-parameter models](https://www.youtube.com/watch?v=9P_VAMyb-7k)
    and yet it was David’s team at OpenAI who ended up making GPT 1/2/3\.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 人们常常问，为什么Google在2017年由Vaswani等人创建变压器并[Noam Shazeer预测万亿参数模型](https://www.youtube.com/watch?v=9P_VAMyb-7k)
    但最终是OpenAI的David团队制作了GPT 1/2/3\.
- en: 'David has some interesting answers:'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: David 给出了一些有趣的答案：
- en: '*“So I think the real story of GPT starts at Google, of course, right? Because
    that''s where Transformers sort of came about. However, the number one shocking
    thing to me was that, and this is like a consequence of the way that Google is
    organized…what they (should) have done would be say, hey, Noam Shazeer, you''re
    a brilliant guy. You know how to scale these things up. **Here''s half of all
    of our TPUs. And then I think they would have destroyed us.** He clearly wanted
    it too…*'
  id: totrans-split-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“所以我认为 GPT 的真正故事始于 Google，当然了，对吧？因为那是变形金刚的诞生地。然而，对我来说最令人震惊的事情是，这其实是谷歌组织方式的一个后果……他们（应该）本来应该说，嘿，Noam
    Shazeer，你是个天才。你知道如何扩展这些东西。**这里是我们所有TPU的一半。然后我认为他们会毁掉我们。** 他显然也想要这样做……*'
- en: '*You know, every day we were scaling up GPT-3, I would wake up and just be
    stressed. And I was stressed because, you know, you just look at the facts, right?
    Google has all this compute. Google has all the people who invented all of these
    underlying technologies. There''s a guy named Noam who''s really smart, who''s
    already gone and done this talk about how he wants a trillion parameter model.
    And I''m just like, we''re probably just doing duplicative research to what he''s
    doing. He''s got this decoder only transformer that''s probably going to get there
    before we do.*'
  id: totrans-split-15
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*你知道，我们每天都在扩展GPT-3，我会醒来只是感到压力山大。我之所以感到压力，是因为你看看事实，对吧？谷歌拥有所有这些计算资源。谷歌有所有那些发明这些基础技术的人。还有一个叫诺姆的家伙，他非常聪明，他已经做了一个关于他想要一个万亿参数模型的演讲。我只是觉得我们可能只是在做与他相同的重复性研究。他有一个只有解码器的变压器，可能会比我们更早达到那个目标。*'
- en: '***And it turned out the whole time that they just couldn''t get critical mass.**
    So during my year where I led the Google LM effort and I was one of the brain
    leads, you know, it became really clear why. At the time, there was a thing called
    the Brain Credit Marketplace. Everyone''s assigned a credit. So if you have a
    credit, you get to buy end chips according to supply and demand. **So if you want
    to go do a giant job, you had to convince like 19 or 20 of your colleagues not
    to do work.** And if that''s how it works, it''s really hard to get that bottom
    up critical mass to go scale these things. And the team at Google were fighting
    valiantly, but **we were able to beat them simply because we took big swings and
    we focused.”***'
  id: totrans-split-16
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '***结果一直是他们只是无法获得关键质量。** 因此在我领导Google LM项目的那一年，我成为了其中一位脑力领导，你知道，这一切变得非常清楚。当时有一个叫大脑积分市场的东西。每个人都分配了一个积分。所以如果你有积分，你可以根据供需购买末端芯片。**
    所以如果你想做一项巨大的工作，你必须说服19或20位同事不要工作。** 如果事情是这样的，要想获取底层的关键质量来扩展这些事情是非常困难的。谷歌团队正在英勇地战斗，但是**我们能够击败他们，仅仅因为我们采取了大的飞跃并且专注于目标。”*'
- en: 'Human intelligence got to where it is today through evolution. Some argue that
    **to get to AGI, we will approximate all the “FLOPs” that went into that process**,
    an approach most famously mapped out by Ajeya Cotra’s [Biological Anchors report](https://www.lesswrong.com/posts/KrJfoZzpSDpnrv9va/draft-report-on-ai-timelines):'
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 人类智慧通过进化发展到今天的状态。有人认为**要达到AGI，我们将近似于所有进化过程中的“FLOPs”**，这个方法最著名的是Ajeya Cotra的[生物锚报告](https://www.lesswrong.com/posts/KrJfoZzpSDpnrv9va/draft-report-on-ai-timelines)。
- en: The early days of OpenAI were very reinforcement learning-driven with the [Dota
    project](https://openai.com/research/openai-five-defeats-dota-2-world-champions),
    but that's a very inefficient way for these models to re-learn everything. (Kanjun
    from Imbue shared [similar ideas in her episode](https://www.latent.space/p/imbue)).
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI早期非常依赖强化学习驱动[Dota项目](https://openai.com/research/openai-five-defeats-dota-2-world-champions)，但这对于这些模型重新学习一切来说是非常低效的方式。（Imbue的Kanjun在她的集中分享了[类似的想法](https://www.latent.space/p/imbue)。）
- en: '**David argues that there’s a shortcut.** We can bootstrap from existing intelligence.'
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**大卫认为有一个捷径。** 我们可以从现有的智能中启动。'
- en: '*“Years ago, I had a debate with a Berkeley professor as to what will it actually
    take to build AGI. And his view is basically that you have to reproduce all the
    flops that went into evolution in order to be able to get there… I think we are
    ignoring the fact that you have a giant shortcut, which is **you can behaviorally
    clone everything humans already know**. And that''s what we solved with LLMs!”*'
  id: totrans-split-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“多年前，我与一位伯克利教授辩论，关于构建AGI实际需要什么。他的观点基本上是，你必须重复进化过程中所有的浮点运算才能达到那个目标…… 我认为我们忽视了一个巨大的捷径，即**你可以行为上克隆人类已经掌握的一切知识**。这就是我们用LLMs解决的问题！”*'
- en: LLMs today basically model intelligence using all (good!) written knowledge
    (see our [Datasets 101 episode](https://www.latent.space/p/datasets-101)), and
    have now expanded to non-verbal knowledge (see our [HuggingFace episode](https://www.latent.space/p/idefics)
    on multimodality). The SOTA self-supervised pre-training process is surprisingly
    data-efficient in taking large amounts of unstructured data, and approximating
    reasoning without overfitting.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 今天的LLMs基本上是利用所有（好的！）书面知识来建模智能（请参见我们的[数据集101集](https://www.latent.space/p/datasets-101)），现在已经扩展到非语言知识（请参见我们的[HuggingFace集](https://www.latent.space/p/idefics)关于多模态）。SOTA的自监督预训练过程在处理大量非结构化数据并近似推理时非常高效，避免了过拟合。
- en: But how do you cross the gap from the LLMs of today to building the AGI we all
    want?
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，你如何跨越从今天的LLMs到构建我们所有人都想要的AGI的鸿沟？
- en: This is why David & friends left to start Adept.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么David和朋友们离开创立Adept的原因。
- en: “*We believe the clearest framing of general intelligence is **a system that
    can do anything a human can do in front of a computer**. A foundation model for
    actions, trained to use every software tool, API, and webapp that exists, is a
    practical path to this ambitious goal*” — [ACT-1 Blogpost](https://www.adept.ai/blog/act-1)
  id: totrans-split-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “*我们认为普通智能的最清晰的界定是**一个系统能在计算机前完成人类能做的任何事情**。一个行动的基础模型，训练使用每个软件工具、API和现有的Web应用程序，是实现这一宏大目标的实际途径*”
    — [ACT-1博客文章](https://www.adept.ai/blog/act-1)
- en: The AGI dream is fully autonomous agents, but there are [levels to autonomy](https://www.latent.space/p/agents)
    that we are comfortable giving our agents, based on how reliable they are. In
    David’s word choice, we always want higher levels of “abstractions” (aka autonomy),
    but our need for “reliability” is the practical limit on how high of an abstraction
    we can use.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: AGI梦想是完全自治的代理，但基于它们的可靠性，我们对我们的代理给予了[自治级别](https://www.latent.space/p/agents)，在David的词语选择中，我们始终希望更高级别的“抽象”（即自治），但我们对“可靠性”的需求是我们可以使用的抽象水平的实际限制。
- en: '*“The critical path for Adept is we want to build agents that can do a higher
    and higher level abstraction things over time, all while keeping an insanely high
    reliability standard. Because that''s what turns us from research into something
    that customers want. And **if you build agents with really high reliability standard,
    but are continuing pushing a level of abstraction, you then learn from your users
    how to get that next level of abstraction faster.** So that''s how you actually
    build the data flow.*'
  id: totrans-split-26
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“Adept的关键路径在于我们希望建立能够随着时间推移执行更高级抽象任务的代理程序，同时保持极高的可靠性标准。因为这是将我们从研究转变为客户需求的关键。**如果你建立的代理具有非常高的可靠性标准，同时不断推动抽象水平，那么你就可以从用户那里学习如何更快地实现下一个抽象水平。**
    所以这就是你实际构建数据流的方式。”*'
- en: '*That''s the critical path for the company. Everything we do is in service
    of that.”*'
  id: totrans-split-27
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“这是公司的关键路径。我们所做的一切都是为了这个。”*'
- en: 'We saw how Adept thinks about different levels of abstraction at the 2023 Summit:'
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在2023年的峰会上看到了Adept如何思考不同抽象级别：
- en: The highest abstraction is the “AI Employee”, but we’ll get there with “AI enabled
    employees”. Alessio [recently gave a talk](https://twitter.com/FanaHOVA/status/1771235466207195379)
    about the future of work with “services as software” at this week’s Nvidia GTC
    ([slides](https://github.com/FanaHOVA/nvidia-gtc-2024-slides)).
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最高的抽象是“AI员工”，但我们将通过“AI启用的员工”来实现这一点。Alessio [最近在本周的Nvidia GTC上发表了演讲](https://twitter.com/FanaHOVA/status/1771235466207195379)关于“服务作为软件”未来的工作
    ([幻灯片](https://github.com/FanaHOVA/nvidia-gtc-2024-slides))。
- en: 'Unlike a lot of large research labs, Adept''s framing of AGI as "*being able
    to use your computer*  **like a human**" carries with it a useful environmental
    constraint:'
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: 与许多大型研究实验室不同，Adept将AGI的框架定义为“*能够像人类一样使用你的计算机* **”，这带来了一个有用的环境约束：
- en: '*“Having a human robot **lets you do things that humans do*** **without changing
    everything along the way***. It''s the same thing for software, right? If you
    go itemize out the number of things you want to do on your computer for which
    every step has an API, those numbers of workflows add up pretty close to zero.
    And so then many points along the way, you need the ability to actually control
    your computer like a human. It also lets you **learn from human usage of computers
    as a source of training data that you don''t get** if you have to somehow figure
    out how every particular step needs to be some particular custom private API thing.
    And so I think this is actually the most practical path (to economic value).”*'
  id: totrans-split-31
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“拥有一个人类机器人**让你能够做人类做的事情*** **而无需在途中更改一切***。对软件来说也是一样，对吧？如果你列出你想在计算机上做的事情的数量，每一步都有一个API，那么这些工作流的数量就会接近零。所以在很多时候，你需要能够像人类一样实际控制你的计算机。它还允许你**从人类使用计算机中学习作为训练数据的来源，如果你必须以某种方式弄清楚每个特定步骤需要成为某种特定的自定义私有API事物，那么你将无法获得**。
    所以我认为这实际上是（经济价值的）最实用路径。”*'
- en: This realization and conviction means that multimodal modals are the way to
    go. Instead of using function calling to call APIs to build agents, which is what
    OpenAI and most of the open LLM industry have done to date, Adept wants to “drive
    by vision”, (aka see the screen as a human sees it) and pinpoint where to click
    and type as a human does. No APIs needed, because most software don’t expose APIs.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这种认识和信念意味着多模态模型是前进的方向。与其使用函数调用来调用 API 来构建代理，这是迄今为止 OpenAI 和大多数开放 LLM 行业所做的，Adept
    想要“通过视觉驱动”（即像人类一样看待屏幕）并准确定位点击和键入。不需要 API，因为大多数软件不公开 API。
- en: 'Extra context for readers: You can see [the DeepMind SIMA model](https://buttondown.email/ainews/archive/ainews-deepmind-sima-one-ai-9-games-600-tasks/)
    in the same light:'
  id: totrans-split-33
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 读者的额外背景信息：您可以在同样的光线下看到 [DeepMind SIMA 模型](https://buttondown.email/ainews/archive/ainews-deepmind-sima-one-ai-9-games-600-tasks/)：
- en: One system that learned to play a diverse set of games (instead of one dedicated
    model per game) using **only** pixel inputs and keyboard-and-mouse action outputs!
  id: totrans-split-34
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一个系统学会了玩各种游戏（而不是每个游戏专用一个模型）只使用像素输入和键盘鼠标操作输出！
- en: The OpenInterpreter team is working on a “[Computer API](https://api.openinterpreter.com/)”
    that also does the same.
  id: totrans-split-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: OpenInterpreter 团队正在开发一个 “[计算机 API](https://api.openinterpreter.com/)” 也在做同样的事情。
- en: 'To do this, Adept had to double down on a special kind of **multimodality for
    knowledge work**:'
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，Adept 必须加倍努力专注于 **多模态知识工作** 的特殊类型：
- en: '*“A giant thing that was really necessary is really fast multimodal models
    that are really good at **understanding knowledge work** and really good at **understanding
    screens**. And that is needs to kind of be the base for some of these agents…*'
  id: totrans-split-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“一个非常必要的巨大物件是真正快速的多模态模型，它们非常擅长 **理解知识工作** 和 **理解屏幕**。这需要成为这些代理的基础之一...*'
- en: '*…I think one big hangover primarily academic focus for multimodal models is
    most multimodal models are primarily trained on like **natural images, cat and
    dog photos**, stuff that''s come out of the camera… (but) where are they going
    to be the most useful? **They''re going to be most useful in knowledge work tasks.
    That''s where the majority of economic value is going to be**. It''s not in cat
    and dogs.*'
  id: totrans-split-38
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*...我认为多模态模型主要学术关注的一个大问题是，大多数多模态模型主要是训练在像 **自然图像、猫和狗的照片** 这样的东西，那些是从相机中获取的...
    但是它们最有用处的地方在哪里呢？**它们在知识工作任务中最有用**。那里是大部分经济价值的所在。不在猫和狗身上。*'
- en: '*And so if that''s what it is, what do you need to train? I need to train on
    like **charts, graphs, tables, invoices, PDFs, receipts, unstructured data, UIs**.
    That''s just a totally different pre-training corpus. And so Adept spent a lot
    of time building that.”*'
  id: totrans-split-39
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*那么如果就是这样，你需要训练什么？我需要训练像 **图表、图形、表格、发票、PDF、收据、非结构化数据、用户界面** 这样的东西。那是一个完全不同的预训练语料库。因此，Adept
    花了很多时间来构建它。*'
- en: 'With this context, you can now understand the full path of Adept’s public releases:'
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种背景下，您现在可以理解 Adept 的公共发布的完整路径：
- en: '**[ACT-1](https://www.adept.ai/blog/act-1)** (Sept 2022): a large Transformers
    model optimized for browser interactions. It has a custom rendering of the browser
    viewport that allows it to better understand it and take actions.'
  id: totrans-split-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[ACT-1](https://www.adept.ai/blog/act-1)**（2022 年 9 月）：一个为浏览器交互优化的大型 Transformers
    模型。它具有自定义的浏览器视口渲染，可以更好地理解并采取行动。'
- en: '**[Persimmon-8B](https://www.adept.ai/blog/persimmon-8b)** (Sept 2023): a permissive
    open LLM ([weights and code here](https://github.com/persimmon-ai-labs/adept-inference))'
  id: totrans-split-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[Persimmon-8B](https://www.adept.ai/blog/persimmon-8b)**（2023 年 9 月）：一个宽容的开放
    LLM 模型（[权重和代码在此处](https://github.com/persimmon-ai-labs/adept-inference)）。'
- en: '**[Fuyu-8B](https://www.adept.ai/blog/fuyu-8b)** (Oct 2023): a small version
    of the **multimodal** model that powers Adept. Vanilla decoder-only transformer
    with no specialized image encoder, which allows it to handle input images of varying
    resolutions without downsampling.'
  id: totrans-split-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[Fuyu-8B](https://www.adept.ai/blog/fuyu-8b)**（2023 年 10 月）：Adept 动力的 **多模态**
    模型的小版本。Vanilla 解码器-唯一的变压器，没有专门的图像编码器，允许它处理不同分辨率的输入图像而不降低采样率。'
- en: '**[Adept Experiments](https://www.adept.ai/blog/experiments)** (Nov 2023):
    A public tool to build **automations in the browser**. This is powered by Adept''s
    core technology but it''s just a piece of their enterprise platform. They use
    it as a way to try various design ideas.'
  id: totrans-split-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[Adept 实验](https://www.adept.ai/blog/experiments)**（2023 年 11 月）：一个在浏览器中构建自动化的公共工具。这由
    Adept 的核心技术驱动，但仅是其企业平台的一部分。他们将其用作尝试各种设计思路的一种方式。'
- en: '**[Fuyu Heavy](https://www.adept.ai/blog/adept-fuyu-heavy)** (Jan 2024) - a
    new **multimodal** model designed specifically for digital agents and the world’s
    third-most-capable multimodal model (beating Gemini Pro on MMMU, AI2D, and ChartQA),
    “behind only GPT4-V and Gemini Ultra, which are 10-20 times bigger”'
  id: totrans-split-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**[Fuyu Heavy](https://www.adept.ai/blog/adept-fuyu-heavy)**（2024年1月）- 一款专门为数字代理人设计的新的**多模态**模型，是世界第三强的多模态模型（在MMMU、AI2D和ChartQA上击败了Gemini
    Pro），“仅次于GPT4-V和Gemini Ultra，它们的规模大约是10-20倍”'
- en: 'The Fuyu-8B post in particular exhibits a great number of examples on knowledge
    work multimodality:'
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是Fuyu-8B帖子展示了许多知识工作多模态性的例子：
- en: With OpenAI now worth >$90b and Anthropic >$18b, it is tempting to conclude
    that the AI startup metagame is to build a large research lab, and attract the
    brightest minds and highest capital to build AGI.
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在OpenAI的市值超过了90亿美元，Anthropic超过了18亿美元，很容易得出结论，AI初创公司的元游戏是建立一个大型研究实验室，并吸引最聪明的头脑和最高的资本来构建AGI。
- en: Our past guests
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的过去的客人
- en: (see [the Humanloop episode](https://latent.space/p/humanloop)) and (from [Imbue](https://www.latent.space/p/imbue))
    combined to ask the most challenging questions of the pod - with David/Adept’s
    deep research pedigree from Deepmind and OpenAI, why is Adept not building more
    general foundation models (like Persimmon) and playing the academic benchmarks
    game? Why is Adept so focused on commercial agents instead?
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: （见[Humanloop的一集](https://latent.space/p/humanloop)）和（来自[Imbue](https://www.latent.space/p/imbue)）结合在一起，对播客提出了最具挑战性的问题
    - 由于David/Adept来自Deepmind和OpenAI的深度研究背景，为什么Adept不建立更广泛的基础模型（像Persimmon一样）并参与学术基准竞赛？为什么Adept如此专注于商业代理人？
- en: '*“I feel super good that we''re doing foundation models in service of agents
    and all of the reward within Adept is flowing from “Can we make a better agent”…*'
  id: totrans-split-50
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“我感觉超级好，我们正在为代理人做基础模型，而Adept的所有回报都来自于‘我们能否制造一个更好的代理人’…”*'
- en: '*… I think **pure play foundation model companies are just going to be pinched
    by how good the next couple of (Meta Llama models) are going to be**… And then
    seeing the really big players put ridiculous amounts of compute behind just training
    these base foundation models, **I think is going to commoditize a lot of the regular
    LLMs and soon regular multimodal models**. So I feel really good that we''re just
    focused on agents.”*'
  id: totrans-split-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*我认为**纯粹的基础模型公司将受到接下来几个（Meta Llama 模型）的挑战… 看到真正的大玩家投入大量计算资源来训练这些基础模型，**我认为这将使得很多普通的LLM和很快普通的多模态模型将会被商品化。所以我真的觉得我们只专注于代理人是正确的选择。”*'
- en: 'and the commercial grounding is his answer to Kanjun too (whom we also asked
    the inverse question to compare with Adept):'
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
  zh: 并且商业基础是他回答卡恩君的答案（我们也问了相反的问题来与Adept比较）：
- en: '*“… the second reason I work at Adept is if you believe that **actually having
    customers and a reward signal from customers lets you build AGI faster**, which
    we really believe, then you should come here. And I think the examples for why
    that''s true is for example, **our evaluations are not academic evals**. They''re
    not simulator evals. They''re like, okay, we have a customer that really needs
    us to do these particular things. We can do some of them. These are the ones they
    want us to, we can''t do them at all. We''ve turned those into evals.. I think
    that''s a degree of practicality that really helps.”*'
  id: totrans-split-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*“…我在Adept工作的第二个原因是，如果你相信**实际上有客户和来自客户的奖励信号可以让你更快地构建AGI**，我们确实相信，那么你应该来这里。我认为这是为什么这是真实的例子，比如，**我们的评估不是学术评估**。它们不是模拟器评估。这些都是，好吧，我们有一个真正需要我们做这些特定事情的客户。我们可以做其中的一些。他们想要我们做的这些，我们根本做不到。我们已经把它们转化为评估…
    我认为这种实用性确实有助于。”*'
- en: 'And his customers seem pretty happy, because David didn’t need to come on to
    do a sales pitch:'
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: 而且他的客户似乎非常满意，因为David不需要进行销售推广：
- en: '*David: “One of the things we haven''t shared before is we''re completely sold
    out for Q1.”*'
  id: totrans-split-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*David: “我们之前没有分享过的一件事是，我们完全售罄了Q1的产品。”*'
- en: '*Swyx: “Sold out of what?”*'
  id: totrans-split-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*Swyx: “卖掉了什么？”*'
- en: '*David: “Sold out of bandwidth to onboard more customers.”*'
  id: totrans-split-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*David: “卖掉了接纳更多客户的带宽。”*'
- en: Well, that’s a great problem to have.
  id: totrans-split-58
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，这是一个很好的问题。
- en: '[00:00:00] Introductions'
  id: totrans-split-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[00:00:00] 介绍'
- en: '[00:01:14] Being employee #30 at OpenAI and its early days'
  id: totrans-split-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[00:01:14] 成为OpenAI的第30名员工及其早期阶段'
- en: '[00:13:38] What is Adept and how do you define AGI?'
  id: totrans-split-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[00:13:38] 什么是Adept以及你如何定义AGI？'
- en: '[00:21:00] Adept''s critical path and research directions'
  id: totrans-split-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[00:21:00] Adept的关键路径和研究方向'
- en: '[00:26:23] How AI agents should interact with software and impact product development'
  id: totrans-split-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[00:26:23] AI代理应如何与软件互动并影响产品开发'
- en: '[00:30:37] Analogies between AI agents and self-driving car development'
  id: totrans-split-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[00:30:37] AI代理与自动驾驶汽车开发之间的类比'
- en: '[00:32:42] Balancing reliability, cost, speed and generality in AI agents'
  id: totrans-split-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[00:32:42] 在AI代理中平衡可靠性、成本、速度和通用性'
- en: '[00:37:30] Potential of foundation models for robotics'
  id: totrans-split-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[00:37:30] 基于基础模型在机器人技术中的潜力'
- en: '[00:39:22] Core research questions and reasons to work at Adept'
  id: totrans-split-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[00:39:22] Adept的核心研究问题和工作原因'
- en: '**Alessio** [00:00:00]: Hey everyone, welcome to the Latent Space Podcast.
    This is Alessio, partner and CTO in Residence at [Decibel Partners](https://decibel.vc/),
    and I''m joined by my co-host Swyx, founder of [Smol.ai](https://smol.ai/).'
  id: totrans-split-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alessio** [00:00:00]: 大家好，欢迎来到《潜空间播客》。我是Alessio，[Decibel Partners](https://decibel.vc/)的合伙人兼技术总监，我还有我的联合主持人Swyx，[Smol.ai](https://smol.ai/)的创始人。'
- en: '**Swyx** [00:00:15]: Hey, and today we have David Luan, CEO, co-founder of
    Adept in the studio. Welcome.'
  id: totrans-split-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:00:15]: 嗨，今天我们有David Luan，Adept的CEO和联合创始人，出现在我们的节目中。欢迎。'
- en: '**David** [00:00:20]: Yeah, thanks for having me.'
  id: totrans-split-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:00:20]: 是的，谢谢你邀请我来。'
- en: '**Swyx** [00:00:21]: Been a while in the works. I''ve met you socially at one
    of those VC events and you said that you were interested in coming on and glad
    we finally were able to make this happen.'
  id: totrans-split-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:00:21]: 已经进行了一段时间了。我在一次风投活动上见过你，你说你有兴趣上节目，很高兴我们终于能够实现这个愿望。'
- en: '**David**: Yeah, happy to be part of it.'
  id: totrans-split-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**David**: 是的，很高兴能成为其中的一员。'
- en: '**Swyx**: So we like to introduce the speaker and then also just like have
    you talk a little bit about like what''s not on your LinkedIn, what people should
    just generally know about you. You started a company in college, which was the
    first sort of real time video detection classification API that was Dextro, and
    that was your route to getting acquired into Axon where you''re a director of
    AI. Then you were the 30th hire at OpenAI?'
  id: totrans-split-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx**: 我们喜欢介绍发言人，然后让你稍微谈谈关于你LinkedIn上没有的东西，人们应该一般性地了解你。你在大学期间创办了一家公司，那是第一个实时视频检测分类API，那就是Dextro，后来你被Axon收购成为了AI总监。然后你是OpenAI的第30号员工？'
- en: '**David** [00:00:53]: Yeah, 30, 35, something around there. Something like
    that.'
  id: totrans-split-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:00:53]: 是的，大概是第30到35号吧。差不多是这样。'
- en: '**Swyx** [00:00:56]: So you were VP of Eng for two and a half years to two
    years, briefly served as tech lead of large models at Google, and then in 2022
    started Adept. So that''s the sort of brief CV. Is there anything else you like
    want to fill in the blanks or like people should know more about?'
  id: totrans-split-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:00:56]: 所以你曾经担任了两年半至两年的工程副总裁，短暂担任过谷歌大型模型的技术负责人，然后在2022年创办了Adept。这是你的简短简历。还有其他什么你想要补充或者人们应该更多了解的吗？'
- en: '**David** [00:01:14]: I guess a broader story was I joined OpenAI fairly early
    and I did that for about two and a half to three years leading engineering there.
    It''s really funny, I think second or third day of my time at OpenAI, Greg and
    Ilya pulled me in a room and we''re like, you know, you should take over our directs
    and we''ll go mostly do IC work. So that was fun, just coalescing a bunch of teams
    out of a couple of early initiatives that had already happened. The company, the
    Dota effort was going pretty hard and then more broadly trying to put bigger picture
    direction around what we were doing with basic research. So I spent a lot of time
    doing that. And then I led Google''s LLM efforts, but also co-led Google Brain
    was one of the brain leads more broadly. You know, there''s been a couple of different
    eras of AI research, right? If we count everything before 2012 as prehistory,
    which people hate it when I say that, kind of had this like you and your three
    best friends write a research paper that changes the world period from like 2012
    to 2017\. And I think the game changed in 2017 and like most labs didn''t realize
    it, but we at OpenAI really did. I think in large part helped by like Ilya''s
    constant beating of the drum that the world would be covered in data centers.
    And I think-'
  id: totrans-split-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:01:14]: 我想更广泛地说，我比较早就加入了 OpenAI，领导了大约两年半到三年的工程工作。非常有趣的是，在我加入
    OpenAI 的第二或第三天，Greg 和 Ilya 把我拉到一个房间，告诉我说，你应该接管我们的直接团队，而我们会大多数时间做 IC 工作。所以这很有趣，从一些早期已经发生的倡议中整合了一些团队。公司的
    Dota 项目进展顺利，然后更广泛地试图为我们正在进行的基础研究提供更大的方向性。所以我花了很多时间做这些事情。然后我领导了 Google 的 LLM（Legal
    Language Model）工作，也是 Google Brain 的联合领导之一。你知道，AI 研究有几个不同的时代，对吧？如果我们把 2012 年以前的一切都称为史前时期，人们讨厌我这么说，但在
    2012 年到 2017 年这段时间，我们有这种感觉，你和你的三个最好的朋友写了一篇改变世界的研究论文。我认为 2017 年游戏发生了变化，大多数实验室没有意识到，但我们在
    OpenAI 真的意识到了。我认为这在很大程度上得益于 Ilya 不断强调世界将被数据中心覆盖。我认为-'
- en: '**Swyx** [00:02:15]: It''s causally neat.'
  id: totrans-split-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:02:15]: 这真是一个因果关系的好例子。'
- en: '**David** [00:02:16]: Yeah. Well, like I think we had conviction in that, but
    it wasn''t until we started seeing results that it became clear that that was
    where we had to go. But also part of it as well was for OpenAI, like when I first
    joined, I think one of the jobs that I had to do was how do I tell a differentiated
    vision for who we were technically compared to, you know, hey, we''re just smaller
    Google Brain, or like you work at OpenAI if you live in SF and don''t want to
    commute to Mountain View or don''t want to live in London, right? That''s like
    not enough to like hang your technical identity as a company. And so what we really
    did was, and I spent a lot of time pushing this, is just how do we get ourselves
    focused on a certain class of like giant swings and bets, right? Like how do you
    flip the script from you just do bottom-up research to more about how do you like
    leave some room for that, but really make it about like, what are the big scientific
    outcomes that you want to show? And then you just solve them at all costs, whether
    or not you care about novelty and all that stuff. And that became the dominant
    model for a couple of years, right? And then what''s changed now is I think the
    number one driver of AI products over the next couple of years is going to be
    the deep co-design and co-evolution of product and users for feedback and actual
    technology. And I think labs, every tool to go do that are going to do really
    well. And that''s a big part of why I started Adept.'
  id: totrans-split-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:02:16]: 是的。我认为我们对此有信念，但直到我们开始看到结果才清楚地意识到，这是我们必须走的道路。但也有一部分是因为
    OpenAI，当我刚加入时，我认为我必须做的一项工作是如何为我们的技术身份建立一个有区别的愿景，而不仅仅是小一点的 Google Brain，或者你在 SF
    居住并且不想通勤到 Mountain View 或不想住在伦敦，对吧？这对于作为一个公司的技术身份来说是不够的。所以我们真正做的是，我花了很多时间推动这一点，就是我们如何集中精力在一定类别的巨大变革和赌注上，对吧？像如何从你只做自底向上的研究到更多地关注你想要展示的大科学成果，然后不计一切成本去解决它们，不管你是否关心新颖性和所有那些东西。这成为了几年的主导模式，对吧？然后现在改变的是，我认为接下来几年
    AI 产品的主要驱动因素将是产品和用户之间深度协同设计和共同进化，以获取反馈和实际技术。我认为实验室，拥有去做这些事情的每一种工具都会做得非常好。这也是我开始
    Adept 的重要原因。'
- en: '**Alessio** [00:03:20]: You mentioned Dota, any memories thinking from like
    the switch from RL to Transformers at the time and kind of how the industry was
    evolving more in the LLM side and leaving behind some of the more agent simulation
    work?'
  id: totrans-split-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alessio** [00:03:20]: 你提到了Dota，有没有从RL转向Transformers的记忆，以及行业如何在LLM方面发展，逐渐放弃一些更多代理模拟工作的？'
- en: '**David** [00:03:33]: Like zooming way out, I think agents are just absolutely
    the correct long-term direction, right? You just go to find what AGI is, right?
    You''re like, Hey, like, well, first off, actually, I don''t love AGI definitions
    that involve human replacement because I don''t think that''s actually how it''s
    going to happen. Even this definition of like, Hey, AGI is something that outperforms
    humans at economically valuable tasks is kind of implicit view of the world about
    what''s going to be the role of people. I think what I''m more interested in is
    like a definition of AGI that''s oriented around like a model that can do anything
    a human can do on a computer. If you go think about that, which is like super
    tractable, then agent is just a natural consequence of that definition. And so
    what did all the work we did on our own stuff like that get us was it got us a
    really clear formulation. Like you have a goal and you want to maximize the goal,
    you want to maximize reward, right? And the natural LLM formulation doesn''t come
    with that out of the box, right? I think that we as a field got a lot right by
    thinking about, Hey, how do we solve problems of that caliber? And then the thing
    we forgot is the Novo RL is like a pretty terrible way to get there quickly. Why
    are we rediscovering all the knowledge about the world? Years ago, I had a debate
    with a Berkeley professor as to what will it actually take to build AGI. And his
    view is basically that you have to reproduce all the flops that went into evolution
    in order to be able to get there. Right.'
  id: totrans-split-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:03:33]: 总体来看，我认为代理是未来正确的方向，对吧？你只需去找到什么是通用人工智能（AGI），对吧？你就像，嘿，首先，实际上，我不太喜欢涉及人类替代的AGI定义，因为我不认为事情会真的发生这样的方式。即使这样的定义，比如AGI是在经济上有价值任务上表现优于人类的东西，也是对世界的一种隐含观点，关于人类的角色会是什么样子。我更感兴趣的是围绕一个模型可以在计算机上做任何人类可以做的事情的AGI定义。如果你考虑这个，这是非常可行的，那么代理就是这个定义的一个自然结果。那么我们在我们自己的事情上所做的所有工作，最终给我们带来的是什么？它让我们有了一个非常清晰的表述。你有一个目标，你想最大化这个目标，你想最大化奖励，对吧？而自然的LLM表述并不直接包含这一点，对吧？我认为我们作为一个领域在思考如何解决这样的问题时做对了很多事情。但我们忘了的一件事是，从头开始用RL可能是一种快速到达目标的相当糟糕的方法。为什么我们要重新发现几年前关于世界的所有知识？多年前，我曾与伯克利的一位教授辩论，关于构建通用人工智能究竟需要做些什么。他的观点基本上是，你必须再现进化中所涉及的所有浮点运算才能达到那个目标，对吧。'
- en: '**Swyx** [00:04:44]: The biological basis theory. Right.'
  id: totrans-split-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:04:44]: 生物学基础理论，对吧。'
- en: '**David** [00:04:46]: So I think we are ignoring the fact that you have a giant
    shortcut, which is you can behavioral clone everything humans already know. And
    that''s what we solved with LLMs. We''ve solved behavioral cloning, everything
    that humans already know. Right. So like today, maybe LLMs is like behavioral
    cloning every word that gets written on the internet in the future, the multimodal
    models are becoming more of a thing where behavioral cloning the visual world.
    But really, what we''re just going to have is like a universal byte model, right?
    Where tokens of data that have high signal come in, and then all of those patterns
    are like learned by the model. And then you can regurgitate any combination now.
    Right. So text into voice out, like image into other image out or video out or
    whatever, like these like mappings, right? Like all just going to be learned by
    this universal behavioral cloner. And so I''m glad we figured that out. And I
    think now we''re back to the era of how do we combine this with all of the lessons
    we learned during the RL period. That''s what''s going to drive progress.'
  id: totrans-split-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:04:46]: 我认为我们忽略了一个重要事实，那就是你可以行为克隆所有人类已经知道的东西。这就是我们用LLM解决的问题。我们已经解决了行为克隆，也就是人类已经知道的一切。对吧。所以今天，也许LLM就像是行为克隆互联网上每一个写出来的词，未来，多模态模型正在变得更加普及，它们可以行为克隆视觉世界。但实际上，我们将会拥有的是一个通用字节模型，对吧？输入具有高信号的数据令牌，然后模型会学习所有这些模式。然后你可以随意组合输出。比如文本转语音输出，图片转图片或视频输出等等，这些映射关系，对吧？都将被这个通用行为克隆器学习到。所以我很高兴我们解决了这个问题。我认为现在我们回到了如何将这个与强化学习期间我们学到的所有经验教训结合起来的时代。'
- en: '**Swyx** [00:05:35]: I''m still going to pressure you for a few more early
    opening stories before we turn to the ADET stuff. On your personal site, which
    I love, because it''s really nice, like personal, you know, story context around
    like your history. I need to update it. It''s so old. Yeah, it''s so out of date.
    But you mentioned GPT-2\. Did you overlap with GPT-1? I think you did, right?'
  id: totrans-split-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:05:35]: 我还会继续压你讲几个早期开放的故事，然后再谈ADET的事情。在你的个人网站上，我很喜欢，因为它真的很不错，像是关于你历史的个人故事背景。我需要更新它。它太老了。是的，它太过时了。但你提到了GPT-2。你和GPT-1有重叠吗？我记得你有，对吧？'
- en: '**David** [00:05:53]: I actually don''t quite remember. I think I was joining
    right around- Right around then?'
  id: totrans-split-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:05:53]: 我其实不太记得了。我觉得我大概是在那个时候加入的，对吧？'
- en: '**Swyx** [00:05:57]: I was right around that, yeah. Yeah. So what I remember
    was Alec, you know, just kind of came in and was like very obsessed with Transformers
    and applying them to like Reddit sentiment analysis. Yeah, sentiment, that''s
    right. Take us through-'
  id: totrans-split-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:05:57]: 我大概就在那个时候，是的。是的。所以我记得Alec，你知道，他就进来了，非常着迷于Transformers，并将它们应用于像Reddit情感分析这样的事情。是的，情感分析，没错。带我们走一遍-'
- en: '**David** [00:06:09]: Sentiment neuron, all this stuff.'
  id: totrans-split-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:06:09]: 情感神经元，所有这些东西。'
- en: '**Swyx** [00:06:10]: The history of GPT as far as you know, you know, according
    to you. Ah, okay.'
  id: totrans-split-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:06:10]: GPT的历史，就你所知道的来说。啊，好的。'
- en: '**David** [00:06:14]: History of GPT, according to me, that''s a pretty good
    question. So I think the real story of GPT starts at Google, of course, right?
    Because that''s where Transformers sort of came about. However, the number one
    shocking thing to me was that, and this is like a consequence of the way that
    Google is organized, where like, again, you and your three best friends write
    papers, right? Okay. So zooming way out, right? I think about my job when I was
    a full-time research leader as a little bit of a portfolio allocator, right? So
    I''ve got really, really smart people. My job is to convince people to coalesce
    around a small number of really good ideas and then run them over the finish line.
    My job is not actually to promote a million ideas and never have critical mass.
    And then as the ideas start coming together and some of them start working well,
    my job is to nudge resources towards the things that are really working and then
    start disbanding some of the things that are not working, right? That muscle did
    not exist during my time at Google. And I think had they had it, what they would
    have done would be say, hey, Noam Shazir, you''re a brilliant guy. You know how
    to scale these things up. Here''s half of all of our TPUs. And then I think they
    would have destroyed us. He clearly wanted it too.'
  id: totrans-split-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:06:14]: 根据我看来，GPT的真正故事始于Google，当然，对吧？因为那里是Transformers诞生的地方。然而，对我来说最令人震惊的事情之一是，这是Google组织方式的一个后果，就像，你和你的三个最好的朋友写论文，对吧？好的。所以放大一点，对吧？我想到我在谷歌全职研究领导时的工作有点像投资组合分配者，对吧？所以我手下有一些非常聪明的人。我的工作是说服人们围绕一小部分真正好的想法聚集起来，然后把它们推到终点线。我的工作实际上不是促进无数想法，从不形成关键的大规模。然后当这些想法开始结合起来并且一些开始表现良好时，我的工作就是向那些真正有效的事物推进资源，然后开始解散一些不起作用的东西，对吧？在我在谷歌的那段时间里，这种能力根本不存在。我想如果他们有的话，他们会做的事情是，嘿，Noam
    Shazir，你是个聪明的家伙。你知道如何扩展这些东西。这里有我们所有TPU的一半。然后我想他们会摧毁我们。他显然也想要这样做。'
- en: '**Swyx** [00:07:17]: He''s talking about trillion parameter models in 2017.'
  id: totrans-split-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:07:17]: 他在2017年谈论万亿参数模型。'
- en: '**David** [00:07:20]: Yeah. So that''s the core of the GPT story, right? Which
    is that, and I''m jumping around historically, right? But after GPT-2, we were
    all really excited about GPT-2\. I can tell you more stories about that. It was
    the last paper that I even got to really touch before everything became more about
    building a research org. You know, every day we were scaling up GPT-3, I would
    wake up and just be stressed. And I was stressed because, you know, you just look
    at the facts, right? Google has all this compute. Google has all the people who
    invented all of these underlying technologies. There''s a guy named Noam who''s
    really smart, who''s already gone and done this talk about how he wants a trillion
    parameter model. And I''m just like, we''re probably just doing duplicative research
    to what he''s doing, right? He''s got this decoder only transformer that''s probably
    going to get there before we do. And I was like, but like, please just like let
    this model finish, right? And it turned out the whole time that they just couldn''t
    get critical mass. So during my year where I led the Google LM effort and I was
    one of the brain leads, you know, it became really clear why, right? At the time,
    there was a thing called the brain credit marketplace. And did you guys know the
    brain credit marketplace? No, I never heard of this. Oh, so it''s actually, it''s
    a, you can ask any Googler.'
  id: totrans-split-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:07:20]: 是的。这就是 GPT 故事的核心，对吧？我在历史上跳来跳去，但在 GPT-2 之后，我们对 GPT-2 都非常兴奋。我可以告诉你更多关于那个时期的故事。那是我真正接触的最后一篇论文，在那之后，一切都更多地变成了建立一个研究机构。你知道的，每天我们都在扩展
    GPT-3，我早上醒来就感到压力重重。我感到压力重重，因为你知道，你只要看看事实，对吧？谷歌有这么多计算资源。谷歌有所有发明这些基础技术的人。还有一个叫诺姆的家伙，他非常聪明，他已经谈过他想要一个万亿参数模型的话题。我就像，我们可能只是在做他正在做的重复研究，对吧？他有这个仅有解码器的变压器，可能会在我们之前实现这个目标。但我还是像，但是，请让这个模型完成，对吧？结果，整个时间，他们只是无法形成临界质量。所以在我领导谷歌
    LM 努力的那一年，我也是大脑负责人之一，你知道的，事实变得非常清楚，为什么，对吧？那时候，有一个叫做大脑积分市场的东西。你们知道大脑积分市场吗？不，我从未听说过这个。哦，所以这实际上是一个，你可以问任何谷歌员工。'
- en: '**Swyx** [00:08:23]: It''s like just like a thing that, that, I mean, look
    like, yeah, limited resources, you got to have some kind of marketplace, right?
    You know, sometimes it''s explicit, sometimes it isn''t, you know, just political
    favors.'
  id: totrans-split-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:08:23]: 这就像只是一个事情，看起来像，是的，资源有限，你必须有某种市场，对吧？有时是明确的，有时不是，你知道的，只是政治恩惠。'
- en: '**David** [00:08:34]: You could. And so then basically everyone''s assigned
    a credit, right? So if you have a credit, you get to buy end chips according to
    supply and demand. So if you want to go do a giant job, you had to convince like
    19 or 20 of your colleagues not to do work. And if that''s how it works, it''s
    really hard to get that bottom up critical mass to go scale these things. And
    the team at Google were fighting valiantly, but we were able to beat them simply
    because we took big swings and we focused. And I think, again, that''s like part
    of the narrative of like this phase one of AI, right? Of like this modern AI era
    to phase two. And I think in the same way, I think phase three company is going
    to out execute phase two companies because of the same asymmetry of success.'
  id: totrans-split-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:08:34]: 你可以。所以基本上每个人都分配了一张积分，对吧？所以如果你有积分，你可以根据供需购买端芯片。所以如果你想做一个大项目，你必须说服像你同事中的19或20个人不做工作。如果这就是它的工作方式，要让这些事情扩展起来真的很难。谷歌的团队正在英勇地战斗，但我们之所以能够击败他们，只是因为我们采取了大的举措并且专注于此。我认为，再次，这就像是
    AI 第一阶段的叙述的一部分，对吧？像这个现代 AI 时代的第一阶段到第二阶段。而且我认为以同样的成功不对称性，第三阶段公司将会超越第二阶段公司。'
- en: '**Swyx** [00:09:12]: Yeah. I think it''s underrated how much NVIDIA works with
    you in the early days as well. I think maybe, I think it was Jensen. I''m not
    sure who circulated a recent photo of him delivering the first DGX to you guys.'
  id: totrans-split-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:09:12]: 是的。我认为人们低估了在早期时期 NVIDIA 与你们合作的程度。我想也许，我认为是詹森。我不确定是谁最近流传了一张他把第一台
    DGX 交付给你们的照片。'
- en: '**David** [00:09:24]: I think Jensen has been a complete legend and a mastermind
    throughout. I have so much respect for NVIDIA. It is unreal.'
  id: totrans-split-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:09:24]: 我认为詹森一直是一个完全的传奇和一个天才。我对 NVIDIA 非常敬佩。简直是难以置信。'
- en: '**Swyx** [00:09:34]: But like with OpenAI, like kind of give their requirements,
    like co-design it or just work of whatever NVIDIA gave them.'
  id: totrans-split-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:09:34]: 但就像 OpenAI，他们提出他们的需求，比如共同设计，或者仅仅使用 NVIDIA 给他们的东西。'
- en: '**David** [00:09:40]: So we work really closely with them. There''s, I''m not
    sure I can share all the stories, but examples of ones that I''ve found particularly
    interesting. So Scott Gray is amazing. I really like working with him. He was
    on one of my teams, the supercomputing team, which Chris Berner runs and Chris
    Berner still does a lot of stuff in that. As a result, like we had very close
    ties to NVIDIA. Actually, one of my co-founders at Adept, Eric Elson, was also
    one of the early GPGPU people. So he and Scott and Brian Catanzaro at NVIDIA and
    Jonah and Ian at NVIDIA, I think all were very close. And we''re all sort of part
    of this group of how do we push these chips to the absolute limit? And I think
    that kind of collaboration helped quite a bit. I think one interesting set of
    stuff is knowing the A100 generation, that like quad sparsity was going to be
    a thing. Is that something that we want to go look into, right? And figure out
    if that''s something that we could actually use for model training. Really what
    it boils down to is that, and I think more and more people realize this, six years
    ago, people, even three years ago, people refused to accept it. This era of AI
    is really a story of compute. It''s really the story of how do you more efficiently
    map actual usable model flops to compute,'
  id: totrans-split-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:09:40]: 我们与他们的合作非常密切。有一些故事可能我不能分享，但有些我特别感兴趣的例子。例如，Scott Gray
    很了不起。我很喜欢和他合作。他曾在我的一个团队——超级计算团队工作，由克里斯·伯纳管理，而克里斯·伯纳至今仍在这方面做了很多工作。因此，我们与英伟达的联系非常紧密。实际上，我在
    Adept 的联合创始人之一——埃里克·埃尔森，也是早期的 GPGPU 人士之一。所以他、Scott、Brian Catanzaro 在英伟达，以及 Jonah
    和 Ian，我想他们都非常亲近。我们都是这个团体的一部分，如何将这些芯片推向极限？我认为这种合作对我们帮助很大。我认为一个有趣的事情是，了解 A100 一代，像四重稀疏性会成为一种趋势。这是我们想要去探索的事情吗？我们要弄清楚这是否是我们实际上可以用于模型训练的东西。实际上，这归结为，我认为越来越多的人意识到，即使六年前，甚至三年前，人们也不愿接受这一点。这个
    AI 时代实际上是一个计算的故事。这是一个关于如何更有效地映射实际可用模型 FLOPS 到计算能力的故事。'
- en: '**Swyx** [00:10:38]: Is there another GPT 2, 3 story that you love to get out
    there that you think is underappreciated for the amount of work that people put
    into it?'
  id: totrans-split-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:10:38]: 有没有其他 GPT 2、3 的故事，你认为人们在投入了大量工作后却没有得到应有的认可，但你想让更多人知道的？'
- en: '**David** [00:10:48]: So two interesting GPT 2 stories. One of them was I spent
    a good bit of time just sprinting to help Alec get the paper out. And I remember
    one of the most entertaining moments was we were writing the modeling section.
    And I''m pretty sure the modeling section was the shortest modeling section of
    any ML, reasonably legitimate ML paper to that moment. It was like section three
    model. This is a standard vanilla decoder only transformer with like these particular
    things, those paragraph long if I remember correctly. And both of us were just
    looking at the same being like, man, the OGs in the field are going to hate this.
    They''re going to say no novelty. Why did you guys do this work? So now it''s
    funny to look at in hindsight that it was pivotal kind of paper, but I think it
    was one of the early ones where we just leaned fully into all we care about is
    solving problems in AI and not about, hey, is there like four different really
    simple ideas that are cloaked in mathematical language that doesn''t actually
    help move the field forward?'
  id: totrans-split-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:10:48]: 这里有两个有趣的 GPT 2 的故事。其中一个是，我花了很多时间帮助 Alec 加快论文的进展。我记得最有趣的时刻之一是我们在写建模部分时。我相当确信，这个建模部分是任何合理合法的机器学习论文中最短的建模部分。如果我记得正确的话，它只有几段。这是一个标准的香草解码器，仅仅带有这些特定的内容。当时我们两个都在看着它，心里想着，老一辈领域专家们一定会不喜欢这个。他们会说没有新意。为什么你们要做这个工作？现在回头看，这是一个关键的论文，但我认为这是早期的一篇文章，我们完全专注于解决
    AI 中的问题，而不是像是用数学语言掩盖的四种简单的思想，实际上并没有推动领域的进展。'
- en: '**Swyx** [00:11:42]: Right. And it''s like you innovate on maybe like data
    set and scaling and not so much the architecture.'
  id: totrans-split-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:11:42]: 是的。就像你创新于数据集和扩展，而不是架构。'
- en: '**David** [00:11:48]: We all know how it works now, right? Which is that there''s
    a collection of really hard won knowledge that you get only by being at the frontiers
    of scale. And that hard won knowledge, a lot of it''s not published. A lot of
    it is stuff that''s actually not even easily reducible to what looks like a typical
    academic paper. But yet that''s the stuff that helps differentiate one scaling
    program from another. You had a second one? So the second one is, there''s like
    some details here that I probably shouldn''t fully share, but hilariously enough
    for the last meeting we did with Microsoft before Microsoft invested in OpenAI,
    Sam Altman, myself and our CFO flew up to Seattle to do the final pitch meeting.
    And I''d been a founder before. So I always had a tremendous amount of anxiety
    about partner meetings, which this basically this is what it was. I had Kevin
    Scott and Satya and Amy Hood, and it was my job to give the technical slides about
    what''s the path to AGI, what''s our research portfolio, all of this stuff, but
    it was also my job to give the GPT-2 demo. We had a slightly bigger version of
    GPT-2 that we had just cut maybe a day or two before this flight up. And as we
    all know now, model behaviors you find predictable at one checkpoint are not predictable
    in another checkpoint. And so I''d spent all this time trying to figure out how
    to keep this thing on rails. I had my canned demos, but I knew I had to go turn
    it around over to Satya and Kevin and let them type anything in. And that just,
    that really kept me up all night.'
  id: totrans-split-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:11:48]: 我们现在都知道它是如何运作的，对吧？就是通过在规模的前沿获得的一系列艰难的知识。这些艰难的知识，很多都没有公开发表。实际上，很多东西甚至不容易归结为典型的学术论文。但这些知识恰恰是帮助区分一个扩展计划与另一个的东西。你还有第二个吗？所以第二个是，这里有一些细节我可能不应该完全分享，但非常有趣的是，在微软最后一次投资
    OpenAI 之前的最后一次会议上，Sam Altman、我和我们的首席财务官飞到西雅图进行最终的演讲。我以前是一名创始人。所以我总是对合伙人会议感到非常焦虑，基本上这就是它的含义。我有
    Kevin Scott 和 Satya 以及 Amy Hood，我的工作是提供关于通向 AGI 的技术幻灯片，以及我们的研究项目组合等等，但我的工作还包括进行
    GPT-2 的演示。我们有一个稍大一点的 GPT-2 版本，就在这次飞行前的一两天刚刚发布。正如我们现在都知道的，你在一个检查点上找到的模型行为在另一个检查点上是不可预测的。所以我花了很多时间想办法如何保持这个东西在轨道上。我有我的标准演示，但我知道我必须把它交给
    Satya 和 Kevin，让他们输入任何内容。这让我整夜都很焦虑。'
- en: '**Swyx** [00:13:06]: Nice. Yeah.'
  id: totrans-split-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:13:06]: 不错。是的。'
- en: '**Alessio** [00:13:08]: I mean, that must have helped you talking about partners
    meeting. You raised $420 million for Adept. The last round was a $350 million
    Series B, so I''m sure you do great in partner meetings.'
  id: totrans-split-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alessio** [00:13:08]: 我的意思是，这一定帮助了你谈论合作伙伴会议。你为 Adept 筹集了 4.2 亿美元。最后一轮是 3.5
    亿美元的 B 轮，所以我相信你在合作伙伴会议上表现得很出色。'
- en: '**Swyx** [00:13:18]: Pitchers meetings. Nice.'
  id: totrans-split-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:13:18]: 投资者会议。不错。'
- en: '**David** [00:13:20]: No, that''s a high compliment coming from a VC.'
  id: totrans-split-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:13:20]: 不，从风险投资人那里得到这样的赞美是很高的评价。'
- en: '**Alessio** [00:13:22]: Yeah, no, I mean, you''re doing great already for us.
    Let''s talk about Adept. And we were doing pre-prep and you mentioned that maybe
    a lot of people don''t understand what Adept is. So usually we try and introduce
    the product and then have the founders fill in the blanks, but maybe let''s do
    the reverse. Like what is Adept? Yeah.'
  id: totrans-split-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alessio** [00:13:22]: 是的，不，我的意思是，你已经为我们做得很好了。让我们谈谈 Adept。我们之前做了预备工作，你提到很多人可能不理解
    Adept 是什么。通常我们会介绍产品，然后由创始人填补空白，但也许我们可以反其道而行之。Adept 是什么？对。'
- en: '**David** [00:13:38]: So I think Adept is the least understood company in the
    broader space of foundational models plus agents. So I''ll give some color and
    I''ll explain what it is and I''ll explain also why it''s actually pretty different
    from what people would have guessed. So the goal for Adept is we basically want
    to build an AI agent that can do, that can basically help humans do anything a
    human does on a computer. And so what that really means is we want this thing
    to be super good at turning natural language like goal specifications right into
    the correct set of end steps and then also have all the correct sensors and actuators
    to go get that thing done for you across any software tool that you already use.
    And so the end vision of this is effectively like I think in a couple of years
    everyone''s going to have access to like an AI teammate that they can delegate
    arbitrary tasks to and then also be able to, you know, use it as a sounding board
    and just be way, way, way more productive. Right. And just changes the shape of
    every job from something where you''re mostly doing execution to something where
    you''re mostly actually doing like these core liberal arts skills of what should
    I be doing and why. Right. And I find this like really exciting and motivating
    because I think it''s actually a pretty different vision for how AGI will play
    out. I think systems like Adept are the most likely systems to be proto-AGIs.
    But I think the ways in which we are really counterintuitive to everybody is that
    we''ve actually been really quiet because we are not a developer company. We don''t
    sell APIs. We don''t sell open source models. We also don''t sell bottom up products.
    We''re not a thing that you go and click and download the extension and like we
    want more users signing up for that thing. We''re actually an enterprise company.
    So what we do is we work with a range of different companies, some like late stage
    multi-thousand people startups, some fortune 500s, et cetera. And what we do for
    them is we basically give them an out of the box solution where big complex workflows
    that their employees do every day could be delegated to the model. And so we look
    a little different from other companies in that in order to go build this full
    agent thing, the most important thing you got to get right is reliability. So
    initially zooming way back when, one of the first things that DEP did was we released
    this demo called Act One, right? Act One was like pretty cool. It''s like kind
    of become a hello world thing for people to show agent demos by going to Redfin
    and asking to buy a house somewhere because like we did that in the original Act
    One demo and like showed that, showed like Google Sheets, all this other stuff.
    Over the last like year since that has come out, there''s been a lot of really
    cool demos and you go play with them and you realize they work 60% of the time.
    But since we''ve always been focused on how do we build an amazing enterprise
    product, enterprises can''t use anything that isn''t in the nines of reliability.
    And so we''ve actually had to go down a slightly different tech tree than what
    you might find in the prompt engineering sort of plays in the agent space to get
    that reliability. And we''ve decided to prioritize reliability over all else.
    So like one of our use cases is crazy enough that it actually ends with a physical
    truck being sent to a place as the result of the agent workflow. And if you''re
    like, if that works like 60% of the time, you''re just blowing money and poor
    truck drivers going places.'
  id: totrans-split-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:13:38]: 所以我认为 Adept 是在基础模型加代理领域中最不被理解的公司。我将解释一些细节，说明它是什么，也会解释为什么它实际上与人们预想的大不相同。Adept
    的目标是建立一个能够帮助人类在计算机上做任何事情的 AI 代理。所以这实际上意味着我们希望这个东西非常擅长将像目标规范这样的自然语言转换为正确的最终步骤集，并且还具备所有正确的传感器和执行器，可以在您已经使用的任何软件工具中完成这些任务。因此，这个终极愿景实际上是，我认为在未来几年内，每个人都将能够使用一种
    AI 同事，可以委派任意任务，并且还可以将其用作发散思考的媒介，从而提高工作效率。这真的会改变每个工作的形态，不再仅仅是执行任务，而是更多地关注“我应该做什么以及为什么”的核心人文技能。我发现这非常令人兴奋和激动，因为我认为这实际上是对
    AGI 如何发展的一个非常不同的愿景。我认为像 Adept 这样的系统最有可能成为原型 AGI 系统。但是我们对每个人都非常反直觉的方式在于，我们实际上一直保持低调，因为我们不是一家开发者公司。我们不销售
    API，也不销售开源模型。我们也不销售底层产品。我们实际上是一家企业公司。所以我们的做法是与各种不同的公司合作，有些是晚期成熟的数千人规模的初创公司，有些是财富
    500 强企业等等。我们为他们提供一个即插即用的解决方案，可以将他们员工每天执行的复杂工作流委派给这个模型。所以我们在这方面与其他公司有所不同，因为在构建这种完整的代理系统时，最重要的是要保证可靠性。所以最初，DEP
    做的第一件事情之一就是发布了一个名为 Act One 的演示，对吧？Act One 相当酷炫。它已经成为人们展示代理演示的一种标准，通过访问 Redfin
    并要求购买某个地方的房子，因为我们在最初的 Act One 演示中做到了这一点，并展示了像 Google Sheets 等其他内容。自从那之后的一年里，有很多非常酷的演示，您可以尝试玩玩，然后您会发现它们大约
    60% 的时间都有效。但是由于我们始终关注如何构建一个了不起的企业产品，企业不能使用任何不可靠的东西。因此，我们实际上不得不选择一种与传统工程领域中的代理技术稍有不同的技术路线来优先考虑可靠性。所以我们的一个用例足够疯狂，以至于它最终会导致一辆卡车根据代理工作流程被发送到一个地方。如果这种方法只有效
    60% 的时间，那么就是在浪费金钱，让可怜的卡车司机去一些地方。'
- en: '**Alessio** [00:16:30]: Interesting. One of the, our investment teams has this
    idea of services as software. I''m actually giving a talk at NVIDIA GTC about
    this, but basically software as a service, you''re wrapping user productivity
    in software with agents and services as software is replacing things that, you
    know, you would ask somebody to do and the software just does it for you. When
    you think about these use cases, do the users still go in and look at the agent
    kind of like doing the things and can intervene or like are they totally removed
    from them? Like the truck thing is like, does the truck just show up or are there
    people in the middle checking in?'
  id: totrans-split-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alessio** [00:16:30]: 有趣。我们投资团队之一有一个“服务即软件”的概念。实际上，我将在 NVIDIA GTC 上就此发表演讲，但基本上就是软件即服务，你将用户生产力包装成软件，带有代理和服务作为软件，取代了一些你本来会请人来做的事情，现在软件替你完成了。当你考虑这些使用案例时，用户是否仍然可以查看代理程序执行的情况并进行干预，还是完全被移除了？比如说卡车的情况，卡车是直接出现，还是中间有人在检查？'
- en: '**David** [00:17:04]: I think there''s two current flaws in the framing for
    services as software, or I think what you just said. I think that one of them
    is like in our experience, as we''ve been rolling out Adept, the people who actually
    do the jobs are the most excited about it because they don''t go from, I do this
    job to, I don''t do this job. They go from, I do this job for everything, including
    the shitty rote stuff to I''m a supervisor. And I literally like, it''s pretty
    magical when you watch the thing being used because now it parallelizes a bunch
    of the things that you had to do sequentially by hand as a human. And you can
    just click into any one of them and be like, Hey, I want to watch the trajectory
    that the agent went through to go solve this. And the nice thing about agent execution
    as opposed to like LLM generations is that a good chunk of the time when the agent
    fails to execute, it doesn''t give you the wrong result. It just fails to execute.
    And the whole trajectory is just broken and dead and the agent knows it, right?
    So then those are the ones that the human then goes and solves. And so then they
    become a troubleshooter. They work on the more challenging stuff. They get way,
    way more stuff done and they''re really excited about it. I think the second piece
    of it that we''ve found is our strategy as a company is to always be an augmentation
    company. And I think one out of principle, that''s something we really care about.
    But two, actually, if you''re framing yourself as an augmentation company, you''re
    always going to live in a world where you''re solving tasks that are a little
    too hard for what the model can do today and still needs a human to provide oversight,
    provide clarifications, provide human feedback. And that''s how you build a data
    flywheel. That''s how you actually learn from the smartest humans how to solve
    things models can''t do today. And so I actually think that being an augmentation
    company forces you to go develop your core AI capabilities faster than someone
    who''s saying, ah, okay, my job is to deliver you a lights off solution for X.'
  id: totrans-split-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:17:04]: 我觉得在将服务视为软件的框架中有两个当前的缺陷，或者说我认为你刚才说的。我认为其中一个是在我们的经验中，随着我们推出
    Adept，实际执行工作的人员最为兴奋，因为他们不再是从“我做这份工作”到“我不再做这份工作”。他们是从“我做这份工作，包括繁琐的机械化工作”到“我是一个监督者”。当你看着它被使用时，真的是一种神奇的体验，因为现在它可以并行执行以前你作为人类顺序手工执行的许多任务之一。你可以随时点击任何一个任务，比如，“我想看一下代理程序通过哪些轨迹来解决这个问题”。与
    LLM 生成不同的是，代理程序执行的好处在于，当代理程序执行失败时，大部分时间它不会给出错误的结果，它只是执行失败了。整个轨迹就中断了，代理程序也知道。那么这些情况下，人类就会介入解决。他们成为故障排除者。他们处理更具挑战性的问题。他们完成了更多的工作，而且他们对此感到非常激动。我认为第二点是我们发现的，作为一家公司的战略是始终作为一个增强型公司。我认为这是我们非常关心的一点。而且，实际上，如果你把自己定位为增强型公司，你始终会生活在一个世界中，你在解决的任务中有一些对当前模型而言稍微有些难度的任务，仍然需要人类提供监督，提供澄清，提供人类反馈。这就是你如何构建一个数据的正反馈环。这就是你如何从最聪明的人类那里学习，如何解决模型今天无法解决的事物。所以我实际上认为，成为一个增强型公司迫使你更快地发展核心
    AI 能力，胜过那些说，“啊，我要为你提供 X 的无人化解决方案”的公司。'
- en: '**Alessio** [00:18:42]: Yeah. It''s interesting because we''ve seen two parts
    of the market. One is we have one company that does agents for SOC analysts. People
    just don''t have them, you know, and just they cannot attract the talent to do
    it. And similarly, in a software development, you have Copilot, which is the augmentation
    product, and then you have sweep.dev and you have these products, which they just
    do the whole thing. I''m really curious to see how that evolves. I agree that
    today the reliability is so important in the enterprise that they just don''t
    use most of them. Yeah. Yeah. No, that''s cool. But it''s great to hear the story
    because I think from the outside, people are like, oh, a dev, they do Act One,
    they do Persimon, they do Fuyu, they do all this stuff. Yeah, it''s just the public
    stuff.'
  id: totrans-split-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alessio** [00:18:42]: 是的。这很有趣，因为我们看到了市场的两个方面。一个是我们有一个为SOC分析师提供代理的公司。人们根本没有这些，你知道，他们无法吸引人才去做这些。类似地，在软件开发中，你有Copilot，这是增强产品，然后你有sweep.dev和这些产品，它们就是整套的解决方案。我真的很想看到这如何发展。我同意，今天在企业中可靠性非常重要，他们根本不使用大部分产品。是的，是的。不，这很酷。但听到这个故事真是太好了，因为我认为从外部看，人们会像，“哦，一个开发者，他们做Act
    One，他们做Persimon，他们做Fuyu，他们做所有这些东西。”是的，这只是公开的事情。'
- en: '**Swyx** [00:19:20]: It''s just public stuff.'
  id: totrans-split-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:19:20]: 就是公开的事情。'
- en: '**David** [00:19:21]: So one of the things we haven''t shared before is we''re
    completely sold out for Q1\. And so I think...'
  id: totrans-split-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:19:21]: 所以我们之前没有分享过的一件事是，我们在第一季度完全售罄了。所以我认为...'
- en: '**Swyx** [00:19:26]: Sold out of what?'
  id: totrans-split-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:19:26]: 售罄了什么？'
- en: '**David** [00:19:27]: Sold out of bandwidth to go on board more customers.
    And so we''re like working really hard to go make that less of a bottleneck, but
    our expectation is that I think we''re going to be significantly more public about
    the broader product shape and the new types of customers we want to attract later
    this year. So I think that clarification will happen by default.'
  id: totrans-split-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:19:27]: 带宽已售罄，无法再接纳更多客户。因此，我们正在努力减少这种瓶颈，但我们的期望是，我认为我们将更加公开地讨论今年晚些时候我们希望吸引的更多类型的客户以及更广泛的产品形态。所以我认为这种澄清将会自然发生。'
- en: '**Swyx** [00:19:43]: Why have you become more public? You know, if the whole
    push has... You''re sold out, you''re my enterprise, but you''re also clearly
    putting effort towards being more open or releasing more things.'
  id: totrans-split-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:19:43]: 为什么你们要更公开？你知道，如果整个推动... 你们已售罄，你们是我的企业，但你们显然也在努力更开放或发布更多东西。'
- en: '**David** [00:19:53]: I think we just flipped over that way fairly recently.
    That''s a good question. I think it actually boils down to two things. One, I
    think that, frankly, a big part of it is that the public narrative is really forming
    around agents as being the most important thing. And I''m really glad that''s
    happening because when we started the company in January 2022, everybody in the
    field knew about the agents thing from RL, but the general public had no conception
    of what it was. They were still hanging their narrative hat on the tree of everything''s
    a chatbot. And so I think now one of the things that I really care about is that
    when people think agent, they actually think the right thing. All sorts of different
    things are being called agents. Chatbots are being called agents. Things that
    make a function call are being called agents. To me, an agent is something that
    you can give a goal and get an end step workflow done correctly in the minimum
    number of steps. And so that''s a big part of why. And I think the other part
    is because I think it''s always good for people to be more aware of Redept as
    they think about what the next thing they want to do in their careers. The field
    is quickly pivoting in a world where foundation models are looking more and more
    commodity. And I think a huge amount of gain is going to happen from how do you
    use foundation models as the well-learned behavioral cloner to go solve agents.
    And I think people who want to do agents research should really come to Redept.'
  id: totrans-split-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:19:53]: 我认为我们最近确实转变了方向。这是一个很好的问题。实际上，我认为其中一个很大的原因是公众对代理的叙事正在形成。我对此感到非常高兴，因为当我们在2022年初创立公司时，领域内的每个人都知道RL中的代理问题，但普通公众对此一无所知。他们仍然把所有东西都归结为聊天机器人。因此，我现在非常关心的一件事情是，当人们想到代理时，他们确实能想到正确的东西。被称为代理的东西千差万别。聊天机器人被称为代理。执行函数调用的东西也被称为代理。对我来说，代理是一种你可以给予目标并正确执行最少步骤的工作流的东西。所以这是其中一个很大的原因。我认为另一个原因是因为我认为让人们在考虑他们职业生涯的下一步时更加了解Redept总是好的。在基础模型越来越普及的世界中，领域正在迅速转向。我认为从如何使用基础模型作为学习行为克隆者去解决代理问题中会产生巨大的收益。我认为那些想要进行代理研究的人真的应该来Redept。'
- en: '**Swyx** [00:21:00]: When you say agents have become more part of the public
    narrative, are there specific things that you point to? I''ll name a few. Bill
    Gates in his blog post mentioning that agents are the future. I''m the guy who
    made OSes, and I think agents are the next thing. So Bill Gates, I''ll call that
    out. And then maybe Sam Altman also saying that agents are the future for open
    AI.'
  id: totrans-split-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:21:00]: 当你说代理已经成为公众叙事的一部分时，你指的是具体的事情吗？我可以举几个例子。比尔·盖茨在他的博客文章中提到代理是未来。我是那个做操作系统的人，我认为代理是下一个东西。所以比尔·盖茨，我要说一下。也许山姆·阿尔特曼也说代理是开放AI的未来。'
- en: '**David** [00:21:17]: I think before that even, I think there was something
    like the New York Times, Cade Metz wrote a New York Times piece about it. Right
    now, in a bit to differentiate, I''m seeing AI startups that used to just brand
    themselves as an AI company, but now brand themselves as an AI agent company.
    It''s just like, it''s a term I just feel like people really want.'
  id: totrans-split-117
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:21:17]: 我认为在那之前，纽约时报，Cade Metz写了一篇关于这个的纽约时报文章。现在，为了区分，我看到以前只是将自己打造成AI公司的AI初创公司，但现在将自己打造成AI代理公司。我觉得人们真的很想要这个术语。'
- en: '**Swyx** [00:21:31]: From the VC side, it''s a bit mixed. Is it? As in like,
    I think there are a lot of VCs where like, I would not touch any agent startups
    because like- Why is that? Well, you tell me.'
  id: totrans-split-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:21:31]: 从VC的角度来看，情况有些复杂。是吗？就像，我认为很多VC会不会碰任何代理初创公司，因为... 为什么呢？好吧，你告诉我。'
- en: '**Alessio** [00:21:41]: I think a lot of VCs that are maybe less technical
    don''t understand the limitations of the-'
  id: totrans-split-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alessio** [00:21:41]: 我认为很多可能不那么技术化的风险投资人并不了解...'
- en: '**Swyx** [00:21:46]: No, that''s not fair.'
  id: totrans-split-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:21:46]: 不，那不公平。'
- en: '**Alessio** [00:21:47]: No, no, no, no. I think like- You think so? No, no.
    I think like the, what is possible today and like what is worth investing in,
    you know? And I think like, I mean, people look at you and say, well, these guys
    are building agents. They needed 400 million to do it. So a lot of VCs are maybe
    like, oh, I would rather invest in something that is tacking on AI to an existing
    thing, which is like easier to get the market and kind of get some of the flywheel
    going. But I''m also surprised a lot of funders just don''t want to do agents.
    It''s not even the funding. Sometimes we look around and it''s like, why is nobody
    doing agents for X? Wow.'
  id: totrans-split-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alessio** [00:21:47]: 不，不，不，不。我想像- 你认为呢？不，不。我想想今天可能发生的事情，以及什么值得投资，你知道吗？我觉得，我是说，人们看着你会说，嗯，这些家伙正在建造代理。他们需要4亿来做到这一点。所以很多风险投资公司可能会说，哦，我宁愿投资于将AI应用于现有事物的东西，这样更容易进入市场，并且启动一些飞轮。但我也很惊讶，很多创业者只是不想做代理。这甚至不仅仅是资金问题。有时候我们看看周围，像，为什么没有人为X做代理呢？哇。'
- en: '**David** [00:22:17]: That''s good to know actually. I never knew that before.
    My sense from my limited perspective is there''s a new agent company popping up
    every day.'
  id: totrans-split-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:22:17]: 实际上知道这个真好。我以前从未知道过。从我的有限视角来看，我觉得每天都有一个新的代理公司冒出来。'
- en: '**Swyx** [00:22:24]: So maybe I''m- They are. They are. But like I have advised
    people to take agents off of their title because it''s so diluted.'
  id: totrans-split-123
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:22:24]: 所以也许我是- 他们是。他们是。但是我建议人们从他们的头衔中去掉代理，因为这样太稀释了。'
- en: '**David** [00:22:31]: It''s now so diluted.'
  id: totrans-split-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:22:31]: 现在变得如此稀释了。'
- en: '**Swyx** [00:22:32]: Yeah. So then it doesn''t stand for anything. Yeah.'
  id: totrans-split-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:22:32]: 是的。所以它并不代表任何东西。是的。'
- en: '**David** [00:22:35]: That''s a really good point.'
  id: totrans-split-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:22:35]: 这真是一个很好的观点。'
- en: '**Swyx** [00:22:36]: So like, you know, you''re a portfolio allocator. You
    have people know about Persimmon, people know about Fuyu and Fuyu Heavy. Can you
    take us through like how you think about that evolution of that and what people
    should think about what that means for adepts and sort of research directions?
    Kind of take us through the stuff you shipped recently and how people should think
    about the trajectory of what you''re doing.'
  id: totrans-split-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:22:36]: 所以，你知道的，你是一个投资组合配置者。人们知道Persimmon，知道Fuyu和Fuyu Heavy。你能详细说明一下你如何看待这一演变，以及人们应该如何考虑这对专家和研究方向意味着什么吗？请带领我们了解一下你最近推出的内容，以及人们应该如何思考你正在做的事情的发展轨迹。'
- en: '**David** [00:22:56]: The critical path for adepts is we want to build agents
    that can do a higher and higher level abstraction things over time, all while
    keeping an insanely high reliability standard. Because that''s what turns us from
    research into something that customers want. And if you build agents with really
    high reliability standard, but are continuing pushing a level of abstraction,
    you then learn from your users how to get that next level of abstraction faster.
    So that''s how you actually build the data flow. That''s the critical path for
    the company. Everything we do is in service of that. So if you go zoom way, way
    back to Act One days, right? Like the core thing behind Act One is can we teach
    large model basically how to even actuate your computer? And I think we''re one
    of the first places to have solved that and shown it and shown the generalization
    that you get when you give it various different workflows and texts. But I think
    from there on out, we really realized was that in order to get reliability, companies
    just do things in various different ways. You actually want these models to be
    able to get a lot better at having some specification of some guardrails for what
    it actually should be doing. And I think in conjunction with that, a giant thing
    that was really necessary is really fast multimodal models that are really good
    at understanding knowledge work and really good at understanding screens. And
    that is needs to kind of be the base for some of these agents. Back then we had
    to do a ton of research basically on how do we actually make that possible? Well,
    first off, like back in forgot exactly one month to 23, like there were no multimodal
    models really that you could use for things like this. And so we pushed really
    hard on stuff like the Fuyu architecture. I think one big hangover primarily academic
    focus for multimodal models is most multimodal models are primarily trained on
    like natural images, cat and dog photos, stuff that''s come out of the camera.
    Coco. Yeah, right. And the Coco is awesome. Like I love Coco. I love TY. Like
    it''s really helped the field. Right. But like that''s the build one thing. I
    actually think it''s really clear today. Multimodal models are the default foundation
    model, right? It''s just going to supplant LLMs. Like you just train a giant multimodal
    model. And so for that though, like where are they going to be the most useful?
    They''re going to be most useful in knowledge work tasks. That''s where the majority
    of economic value is going to be. It''s not in cat and dogs. Right. And so if
    that''s what it is, what do you need to train? I need to train on like charts,
    graphs, tables, invoices, PDFs, receipts, unstructured data, UIs. That''s just
    a totally different pre-training corpus. And so a depth spent a lot of time building
    that. And so the public for use and stuff aren''t trained on our actual corpus,
    it''s trained on some other stuff. But you take a lot of that data and then you
    make it really fast and make it really good at things like dense OCR on screens.
    And then now you have the right like raw putty to go make a good agent. So that''s
    kind of like some of the modeling side, we''ve kind of only announced some of
    that stuff. We haven''t really announced much of the agent''s work, but that if
    you put those together with the correct product form factor, and I think the product
    form factor also really matters. I think we''re seeing, and you guys probably
    see this a little bit more than I do, but we''re seeing like a little bit of a
    pushback against the tyranny of chatbots as form factor. And I think that the
    reason why the form factor matters is the form factor changes what data you collect
    in the human feedback loop. And so I think we''ve spent a lot of time doing full
    vertical integration of all these bits in order to get to where we are.'
  id: totrans-split-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:22:56]: 专家们的关键路径是，我们希望构建的代理能够随着时间推移在更高层次的抽象上进行工作，同时保持极高的可靠性标准。因为这是将我们从研究转变为客户需求的关键所在。如果你构建的代理具有非常高的可靠性标准，同时不断推动抽象级别，那么你就能从用户那里学到如何更快地达到下一个抽象级别。所以这实际上就是构建数据流的方法。这是公司的关键路径。我们所做的一切都是为此服务的。所以如果你回顾Act
    One的早期，对吧？像Act One背后的核心理念是，我们是否可以教会大型模型如何操作你的计算机？我认为我们是第一个解决这个问题并展示它以及展示当你给它不同的工作流和文本时所获得的泛化能力的地方。但是我认为从那时开始，我们真正意识到的是，为了获得可靠性，公司们确实会以各种不同的方式行事。实际上，你希望这些模型能够在某种程度上变得更好，具有一些关于实际应该做什么的规范。而我认为与此同时，一个非常重要的因素是非常快速的多模态模型，它们非常擅长理解知识工作和理解屏幕。这些必须成为某些代理的基础。那时我们不得不进行大量研究，基本上是关于如何实现这一点？嗯，首先，就像回到忘记确切的一个月23号那时，实际上并没有真正可以用于这类事情的多模态模型。所以我们非常努力地推动Fuyu架构之类的东西。我认为多模态模型主要学术研究的一个大问题是，大多数多模态模型主要是在自然图像，猫和狗的照片之类的东西上训练的。Coco。对，对。而Coco很棒。我喜欢Coco。我喜欢TY。它确实帮助了这个领域。对，但是那是建立一种东西。我认为今天非常清楚的一点是，多模态模型是默认的基础模型，对吧？你只需训练一个巨大的多模态模型。但是为了达到这个目标，它们在哪里会最有用？它们在知识工作任务中将会非常有用。这是大部分经济价值所在。而不是在猫和狗身上。对。如果那就是问题的所在，你需要训练什么？我需要训练像图表、图形、表格、发票、PDF、收据、非结构化数据、用户界面之类的东西。这仅仅是一个完全不同的预训练语料库。所以Adept花了大量时间来构建这个。因此，用于公共使用和其他东西的模型并没有在我们的实际语料库上进行训练，而是在其他东西上进行训练。但是你可以使用大量这些数据，然后使其非常快速，并使其在屏幕上进行密集的OCR之类的事情时表现出色。然后现在你拥有了制作一个良好代理所需的正确“原料”。所以这在某种建模方面就像一些事情，我们只宣布了其中一些。我们还没有真正宣布太多有关代理的工作，但是如果你将这些与正确的产品形式因素结合起来，我认为产品形式因素也非常重要。我认为我们正在看到，你们可能比我更多地看到这一点，但我们正在看到一些反抗作为形式因素的聊天机器人暴政。我认为形式因素之所以重要是因为它改变了你在人类反馈环路中收集的数据。因此，我们花了很多时间对所有这些要素进行全垂直整合，以便达到我们现在所处的位置。'
- en: '**Swyx** [00:25:44]: Yeah. I''ll plug Amelia Wattenberger’s talk at our conference,
    where she gave a little bit of the thinking behind like what else exists other
    than chatbots that if you could delegate to reliable agents, you could do. I was
    kind of excited at Adept experiments or Adept workflows, I don''t know what the
    official name for it is. I was like, okay, like this is something I can use, but
    it seems like it''s just an experiment for now. It''s not your product.'
  id: totrans-split-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:25:44]: Yeah. I''ll plug Amelia Wattenberger’s talk at our conference,
    where she gave a little bit of the thinking behind like what else exists other
    than chatbots that if you could delegate to reliable agents, you could do. I was
    kind of excited at Adept experiments or Adept workflows, I don''t know what the
    official name for it is. I was like, okay, like this is something I can use, but
    it seems like it''s just an experiment for now. It''s not your product.'
- en: '**David** [00:26:06]: So you basically just use experiments as like a way to
    go push various ideas on the design side to some people and just be like, yeah,
    we''ll play with it. Actually the experiments code base underpins the actual product,
    but it''s just the code base itself is kind of like a skeleton for us to go deploy
    arbitrary cards on the side.'
  id: totrans-split-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:26:06]: So you basically just use experiments as like a way to
    go push various ideas on the design side to some people and just be like, yeah,
    we''ll play with it. Actually the experiments code base underpins the actual product,
    but it''s just the code base itself is kind of like a skeleton for us to go deploy
    arbitrary cards on the side.'
- en: '**Swyx** [00:26:22]: Yeah.'
  id: totrans-split-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:26:22]: Yeah.'
- en: '**Alessio** [00:26:23]: Makes sense. I was going to say, I would love to talk
    about the interaction layer. So you train a model to see UI, but then there''s
    the question of how do you actually act on the UI? I think there was some rumors
    about open app building agents that are kind of like, they manage the end point.
    So the whole computer, you''re more at the browser level. I read in one of your
    papers, you have like a different representation, kind of like you don''t just
    take the dome and act on it. You do a lot more stuff. How do you think about the
    best way the models will interact with the software and like how the development
    of products is going to change with that in mind as more and more of the work
    is done by agents instead of people?'
  id: totrans-split-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alessio** [00:26:23]: Makes sense. I was going to say, I would love to talk
    about the interaction layer. So you train a model to see UI, but then there''s
    the question of how do you actually act on the UI? I think there was some rumors
    about open app building agents that are kind of like, they manage the end point.
    So the whole computer, you''re more at the browser level. I read in one of your
    papers, you have like a different representation, kind of like you don''t just
    take the dome and act on it. You do a lot more stuff. How do you think about the
    best way the models will interact with the software and like how the development
    of products is going to change with that in mind as more and more of the work
    is done by agents instead of people?'
- en: '**David** [00:26:58]: This is, there''s so much surface area here and it''s
    actually one of the things I''m really excited about. And it''s funny because
    I''ve spent most of my time doing research stuff, but there''s like a whole new
    ball game that I''ve been learning about and I find it really cool. So I would
    say the best analogy I have to why Adept is pursuing a path of being able to use
    your computer like a human, plus of course being able to call APIs and being able
    to call APIs is the easy part, like being able to use your computer like a human
    is a hard part. It''s in the same way why people are excited about humanoid robotics,
    right? In a world where you had T equals infinity, right? You''re probably going
    to have various different form factors that robots could just be in and like all
    the specialization. But the fact is that humans live in a human environment. So
    having a human robot lets you do things that humans do without changing everything
    along the way. It''s the same thing for software, right? If you go itemize out
    the number of things you want to do on your computer for which every step has
    an API, those numbers of workflows add up pretty close to zero. And so then many
    points along the way, you need the ability to actually control your computer like
    a human. It also lets you learn from human usage of computers as a source of training
    data that you don''t get if you have to somehow figure out how every particular
    step needs to be some particular custom private API thing. And so I think this
    is actually the most practical path. I think because it''s the most practical
    path, I think a lot of success will come from going down this path. I kind of
    think about this early days of the agent interaction layer level is a little bit
    like, do you all remember Windows 3.1? Like those days? Okay, this might be, I
    might be, I might be too old for you guys on this. But back in the day, Windows
    3.1, we had this transition period between pure command line, right? Being the
    default into this new world where the GUI is the default and then you drop into
    the command line for like programmer things, right? The old way was you booted
    your computer up, DOS booted, and then it would give you the C colon slash thing.
    And you typed Windows and you hit enter, and then you got put into Windows. And
    then the GUI kind of became a layer above the command line. The same thing is
    going to happen with agent interfaces is like today we''ll be having the GUI is
    like the base layer. And then the agent just controls the current GUI layer plus
    APIs. And in the future, as more and more trust is built towards agents and more
    and more things can be done by agents, if more UIs for agents are actually generative
    in and of themselves, then that just becomes a standard interaction layer. And
    if that becomes a standard interaction layer, what changes for software is that
    a lot of software is going to be either systems or record or like certain customized
    workflow execution engines. And a lot of how you actually do stuff will be controlled
    at the agent layer.'
  id: totrans-split-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**大卫** [00:26:58]: 这里的表面积很大，这实际上是我非常兴奋的事情之一。有趣的是，我大部分时间都在做研究，但我发现有一个全新的游戏规则，我觉得非常酷。所以我想说，我对为什么
    Adept 正在追求能够像人一样使用您的计算机的路径有一个最好的类比，当然还能够调用 API 并且调用 API 是简单的部分，像人一样使用您的计算机是一个困难的部分。这就像人们为何对人形机器人感到兴奋一样，对吧？在
    T 等于无穷大的世界里，你可能会有各种不同的机器人形态，就像所有的专业化一样。但事实上人类生活在人类环境中。所以拥有人类机器人可以让您做人类能做的事情，而不必一路改变。对于软件也是如此，对吧？如果你一项一项列出你想在计算机上做的事情，每一步都有一个
    API，这些工作流的数量几乎等于零。因此，在许多时候，您需要能够像实际控制您的计算机一样进行操作。它还让您能够从人类使用计算机的方式中学习作为训练数据，这是您如果不必想办法弄清每个特定步骤需要某种特定的自定义私有
    API 事物所无法获得的。因此，我认为这实际上是最实际的路径。我认为因为这是最实际的路径，我认为很多成功将从这条道路上获得。我有点像这个代理交互层级的早期阶段，有点像，你们还记得
    Windows 3.1 吗？就像那些日子一样？好的，这可能对你们来说太老了。但是在那个时代，Windows 3.1，我们经历了从纯命令行作为默认进入这个新世界的过渡，其中
    GUI 是默认的，然后你为程序员的事情进入命令行。旧的方式是你启动你的计算机，DOS 引导，然后它会给你 C:\/ 的东西。你输入 Windows 然后按回车，然后你就进入
    Windows。然后 GUI 在命令行之上成为了一种层。同样的事情将会发生在代理界面上，就像今天我们会有 GUI 作为基础层。然后代理只控制当前 GUI 层加上
    API。在将来，随着对代理的信任越来越多，并且更多事情可以由代理完成，如果代理的更多 UI 实际上是自动生成的，那么它只会成为标准交互层。如果那成为标准交互层，对于软件来说，很多软件将会是系统或记录或特定定制工作流执行引擎。而实际上如何做事情的很多方式都将在代理层控制。'
- en: '**Alessio** [00:29:19]: And you think the rabbit interface is more like it
    would like you''re not actually seeing the app that the model interacts with.
    You''re just saying, hey, I need to log this call on Salesforce. And you''re never
    actually going on salesforce.com directly as the user. I can see that being a
    model.'
  id: totrans-split-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alessio** [00:29:19]: 你认为兔子界面更像你不是真的看到模型与之交互的应用程序。你只是说，嘿，我需要在Salesforce上记录这个通话。你实际上从不直接作为用户登录salesforce.com。我觉得这可能是一个模型。'
- en: '**David** [00:29:33]: I think I don''t know enough about what using rabbit
    in real life will actually be like to comment on that particular thing. But I
    think the broader idea that, you know, you have a goal, right? The agent knows
    how to break your goal down into steps. The agent knows how to use the underlying
    software and systems or record to achieve that goal for you. The agent maybe presents
    you information in a custom way that''s only relevant to your particular goal,
    all just really leads to a world where you don''t really need to ever interface
    with the apps underneath unless you''re a power user for some niche thing.'
  id: totrans-split-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:29:33]: 我认为我不了解在现实生活中使用兔子会是什么样子，所以我不能对这个特别的事情发表评论。但我认为更广泛的想法是，你有一个目标，对吧？代理知道如何将你的目标分解为步骤。代理知道如何使用底层的软件和系统或记录来为你实现这个目标。也许代理会以对你特定目标有意义的定制方式向你呈现信息，这一切都导致一个世界，在这个世界里，除非你是某个小众事物的权力用户，否则你根本不需要与应用程序进行接口。'
- en: '**Swyx** [00:30:03]: General question. So first of all, I think like the sort
    of input mode conversation. I wonder if you have any analogies that you like with
    self-driving, because I do think like there''s a little bit of how the model should
    perceive the world. And you know, the primary split in self-driving is LiDAR versus
    camera. And I feel like most agent companies that I''m tracking are all moving
    towards camera approach, which is like the multimodal approach, you know, multimodal
    vision, very heavy vision, all the Fuyu stuff that you''re doing. You''re focusing
    on that, including charts and tables. And do you find that inspiration there from
    like the self-driving world? That''s a good question.'
  id: totrans-split-136
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:30:03]: 一般性问题。首先，我觉得输入模式的对话方式很像。我想知道你是否有喜欢的与自动驾驶相关的类比，因为我认为模型应该如何感知世界这个问题有点类似。你知道，在自动驾驶中，主要的分歧是激光雷达和摄像头。我觉得我正在追踪的大多数代理公司都在向摄像头方法靠拢，这就像是多模态方法，你知道，多模态视觉，非常重视视觉，包括你正在做的所有Fuyu的事情，你正在专注于包括图表和表格在内的这些内容。你是不是从自动驾驶世界中获得灵感的？这是一个很好的问题。'
- en: '**David** [00:30:37]: I think sometimes the most useful inspiration I''ve found
    from self-driving is the levels analogy. I think that''s awesome. But I think
    that our number one goal is for agents not to look like self-driving. We want
    to minimize the chances that agents are sort of a thing that you just have to
    bang your head at for a long time to get to like two discontinuous milestones,
    which is basically what''s happened in self-driving. We want to be living in a
    world where you have the data flywheel immediately, and that takes you all the
    way up to the top. But similarly, I mean, compared to self-driving, like two things
    that people really undervalue is like really easy to driving a car down highway
    101 in a sunny day demo. That actually doesn''t prove anything anymore. And I
    think the second thing is that as a non-self-driving expert, I think one of the
    things that we believe really strongly is that everyone undervalues the importance
    of really good sensors and actuators. And actually a lot of what''s helped us
    get a lot of reliability is a really strong focus on actually why does the model
    not do this thing? And the non-trivial amount of time, the time the model doesn''t
    actually do the thing is because if you''re a wizard of ozzing it yourself, or
    if you have unreliable actuators, you can''t do the thing. And so we''ve had to
    fix a lot of those problems.'
  id: totrans-split-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:30:37]: 我认为有时从自动驾驶中获得的最有用的灵感是层次类比。我觉得那个很棒。但我们的首要目标是让代理人不像自动驾驶。我们希望最大程度地减少代理人必须长时间头疼才能达到两个不连续里程碑的机会，这基本上就是自动驾驶发生的事情。我们希望生活在一个你拥有数据飞轮的世界，并且这能带你一路走到顶端。但同样地，与自动驾驶相比，有两件人们真正低估的事情是，驾驶一辆车在101号公路上的一个晴天演示真的很容易。实际上这并不再证明任何事情。我认为第二件事是，作为一个非自动驾驶专家，我认为我们非常强烈地认为每个人都低估了非常好的传感器和执行器的重要性。实际上，帮助我们获得很多可靠性的事情之一是真正专注于为什么模型不能做这件事。而模型实际上不能做这件事的时间不是因为你自己在模仿奥兹，或者你有不可靠的执行器，你就不能做这件事。所以我们不得不解决很多这些问题。'
- en: '**Swyx** [00:31:43]: I was slightly surprised just because I do generally consider
    the way most that we see all around San Francisco as the most, I guess, real case
    of agents that we have in very material ways.'
  id: totrans-split-138
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:31:43]: 我有点惊讶，因为我通常认为我们在旧金山周围看到的大多数情况是我们在很多实质方面拥有的代理人。'
- en: '**David** [00:31:55]: Oh, that''s absolutely true. I think they''ve done an
    awesome job, but it has taken a long time for self-driving to mature from when
    it entered the consciousness and the driving down 101 on a sunny day moment happened
    to now. Right. So I want to see that more compressed.'
  id: totrans-split-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:31:55]: 哦，这绝对是真的。我认为他们做得非常棒，但是自动驾驶要从它进入人们意识到现在成熟，确实花了很长时间。所以我希望看到这个过程更加压缩。'
- en: '**Swyx** [00:32:07]: And I mean, you know, cruise, you know, RIP. And then
    one more thing on just like, just going back on this reliability thing, something
    I have been holding in my head that I''m curious to get your commentary on is
    I think there''s a trade-off between reliability and generality, or I want to
    broaden reliability into just general like sort of production readiness and enterprise
    readiness scale. Because you have reliability, you also have cost, you have speed,
    speed is a huge emphasis for a debt. The tendency or the temptation is to reduce
    generality to improve reliability and to improve cost, improve speed. Do you perceive
    a trade-off? Do you have any insights that solve those trade-offs for you guys?'
  id: totrans-split-140
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:32:07]: 我的意思是，你知道，Cruise，你知道，RIP。还有一件事，关于可靠性的事情，我一直在心中抱着，我很好奇听听你的评论，我认为在可靠性和普适性之间存在一种权衡，或者我想把可靠性扩展到一般的生产准备和企业准备的规模上。因为你有可靠性，你还有成本，你有速度，速度对于债务是一个巨大的强调。减少普适性以提高可靠性、成本和速度是一种倾向或诱惑。你认为存在权衡吗？你有没有解决这些权衡的见解？'
- en: '**David** [00:32:42]: There''s definitely a trade-off. If you''re at the Pareto
    frontier, I think a lot of folks aren''t actually at the Pareto frontier. I think
    the way you get there is basically how do you frame the fundamental agent problem
    in a way that just continues to benefit from data? I think one of the main ways
    of being able to solve that particular trade-off is you basically just want to
    formulate the problem such that every particular use case just looks like you
    collecting more data to go make that use case possible. I think that''s how you
    really solve. Then you get into the other problems like, okay, are you overfitting
    on these end use cases? You''re not doing a thing where you''re being super prescriptive
    for the end steps that the model can only do, for example.'
  id: totrans-split-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:32:42]: 明显存在一种权衡。如果你处于帕累托前沿，我认为很多人实际上并不在帕累托前沿。我认为你达到那里的方式基本上是如何框架基本的代理问题，以一种只需继续从数据中获益的方式。我认为解决这种特定权衡的主要方法之一是，你基本上希望制定问题，以便每个特定的用例看起来都像是你收集更多数据以使该用例成为可能。我认为这才是你真正解决问题的方式。然后你会陷入其他问题，比如，你在这些最终用例上是否过度拟合？例如，你没有在模型只能执行的最终步骤上采取超级具体的行动。'
- en: '**Swyx** [00:33:17]: Then the question becomes, do you have one house model
    that you can then customize for each customer and you''re fine-tuning them on
    each customer''s specific use case?'
  id: totrans-split-142
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:33:17]: 那么问题来了，你是否有一个房屋模型，然后可以为每个客户定制，并在每个客户的特定用例上进行微调？'
- en: '**David** [00:33:25]: Yeah.'
  id: totrans-split-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:33:25]: 是的。'
- en: '**Swyx** [00:33:26]: We''re not sharing that. You''re not sharing that. It''s
    tempting, but that doesn''t look like AGI to me. You know what I mean? That is
    just you have a good base model and then you fine-tune it.'
  id: totrans-split-144
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:33:26]: 我们不分享那个。你不分享那个。这很诱人，但那对我来说并不像AGI。你知道我说的是什么吧？那只是你有一个很好的基础模型，然后你对它进行微调。'
- en: '**David** [00:33:35]: For what it''s worth, I think there''s two paths to a
    lot more capability coming out of the models that we all are training these days.
    I think one path is you figure out how to spend, compute, and turn it into data.
    In that path, I consider search, RL, all the things that we all love in this era
    as part of that path, like self-play, all that stuff. The second path is how do
    you get super competent, high intelligence demonstrations from humans? I think
    the right way to move forward is you kind of want to combine the two. The first
    one gives you maximum sample efficiency for a little second, but I think that
    it''s going to be hard to be running at max speed towards AGI without actually
    solving a bit of both.'
  id: totrans-split-145
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:33:35]: 就我所知，我认为我们这些天都在训练的模型能力更强有两条路。我认为一条路是你想出如何花费、计算并将其转化为数据。在这条路上，我认为搜索、强化学习，以及我们这个时代所热爱的所有事物都是这条路的一部分，比如自我对弈等等。第二条路是如何从人类那里获得超级能干、高智能的演示。我认为前进的正确方式是你想要将这两者结合起来。第一个路径为你提供了最大的样本效率，但我认为如果不同时解决两者，要全速朝着AGI前进将会很难。'
- en: '**Swyx** [00:34:16]: You haven''t talked much about synthetic data, as far
    as I can tell. Probably this is a bit too much of a trend right now, but any insights
    on using synthetic data to augment the expensive human data?'
  id: totrans-split-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:34:16]: 据我所知，你并没有多谈合成数据，可能现在这个趋势有点过了，但你对使用合成数据增强昂贵的人类数据有何见解？'
- en: '**David** [00:34:26]: The best part about framing AGI as being able to help
    people do things on computers is you have an environment.'
  id: totrans-split-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:34:26]: 将AGI框架为能够帮助人们在计算机上做事的最佳部分是你拥有一个环境。'
- en: '**Swyx** [00:34:31]: Yes. So you can simulate all of it.'
  id: totrans-split-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:34:31]: 是的。所以你可以模拟其中的所有内容。'
- en: '**David** [00:34:35]: You can do a lot of stuff when you have an environment.'
  id: totrans-split-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:34:35]: 有了环境，你可以做很多事情。'
- en: '**Alessio** [00:34:37]: We were having dinner for our one-year anniversary.
    Congrats. Yeah. Thank you. Raza from HumanLoop was there, and we mentioned you
    were coming on the pod. This is our first-'
  id: totrans-split-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alessio** [00:34:37]: 我们为我们的一周年晚餐。祝贺。是的。谢谢。 HumanLoop的Raza也在那里，我们提到你要出现在节目中。这是我们的第一个-'
- en: '**Swyx** [00:34:45]: So he submitted a question.'
  id: totrans-split-151
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:34:45]: 他提交了一个问题。'
- en: '**Alessio** [00:34:46]: Yeah, this is our first, I guess, like mailbag question.
    He asked, when you started GPD 4 Data and Exist, now you have a GPD 4 vision and
    help you building a lot of those things. How do you think about the things that
    are unique to you as Adept, and like going back to like the maybe research direction
    that you want to take the team and what you want people to come work on at Adept,
    versus what is maybe now become commoditized that you didn''t expect everybody
    would have access to?'
  id: totrans-split-152
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alessio** [00:34:46]: 是的，这是我们的第一个邮件袋问题。他问，当你开始 GPD 4 Data and Exist 时，现在你有了
    GPD 4 vision 并帮助你建立了很多这些东西。你如何看待作为 Adept 独特的事物，以及关于你希望团队采取的研究方向，以及你希望人们来 Adept
    工作的内容，与可能已经成为大家都能访问的商品化的东西相比？'
- en: '**David** [00:35:11]: Yeah, that''s a really good question. I think implicit
    in that question, and I wish he were tier two so he can push back on my assumption
    about his question, but I think implicit in that question is calculus of where
    does advantage accrue in the overall ML stack. And maybe part of the assumption
    is that advantage accrues solely to base model scaling. But I actually believe
    pretty strongly that the way that you really win is that you have to go build
    an agent stack that is much more than that of the base model itself. And so I
    think like that is always going to be a giant advantage of vertical integration.
    I think like it lets us do things like have a really, really fast base model,
    is really good at agent things, but is bad at cat and dog photos. It''s pretty
    good at cat and dog photos. It''s not like soda at cat and dog photos, right?
    So like we''re allocating our capacity wisely, right? That''s like one thing that
    you really get to do. I also think that the other thing that is pretty important
    now in the broader foundation modeling space is I feel despite any potential concerns
    about how good is agents as like a startup area, right? Like we were talking about
    earlier, I feel super good that we''re doing foundation models in service of agents
    and all of the reward within Adept is flowing from can we make a better agent?
    Because right now I think we all see that, you know, if you''re training on publicly
    available web data, you put in the flops and you do reasonable things, then you
    get decent results. And if you just double the amount of compute, then you get
    predictably better results. And so I think pure play foundation model companies
    are just going to be pinched by how good the next couple of llamas are going to
    be and the next what good open source thing. And then seeing the really big players
    put ridiculous amounts of compute behind just training these base foundation models,
    I think is going to commoditize a lot of the regular LLMs and soon regular multimodal
    models. So I feel really good that we''re just focused on agents.'
  id: totrans-split-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:35:11]: 是的，这是一个非常好的问题。我认为这个问题中隐含的是，整体机器学习堆栈中的优势计算。也许这个问题的假设的一部分是优势仅仅归于基础模型的扩展。但我其实相当坚信，你真正取胜的方式是你必须去构建一个代理堆栈，远不止于基础模型本身。所以我认为，这始终将是垂直整合的一个巨大优势。我认为，这让我们能够做一些事情，比如拥有一个真正非常快速的基础模型，非常擅长代理事务，但在猫和狗照片方面表现不佳。它在猫和狗照片方面表现相当不错。它并不像苏打在猫和狗照片上那样，对吧？所以我们明智地分配了我们的能力，对吧？这确实是你真正能做到的一件事情。我也认为，在更广泛的基础建模领域中，另一件非常重要的事情是，尽管对代理作为一个创业领域有任何潜在的担忧，正如我们之前讨论过的，我确实觉得我们正在为代理构建基础模型，而
    Adept 所有的回报都来自于我们是否能够做一个更好的代理。因为我现在认为我们都看到了，你知道，如果你在公开可用的网络数据上进行训练，你输入了 FLOPS，并且做了合理的事情，那么你会得到不错的结果。如果你只是增加了计算量的两倍，那么你会得到可预测的更好的结果。因此，我认为纯粹的基础模型公司只会受到接下来几只羊驼和下一个好的开源工具有多好的挤压。然后看到真正大的玩家在仅仅训练这些基础基础模型时投入了可笑的计算量，我认为这将使许多常规
    LLMs 和很快的常规多模型模型商品化。所以我感到非常高兴，我们只专注于代理。'
- en: '**Swyx** [00:36:56]: So you don''t consider yourself a pure play foundation
    model company?'
  id: totrans-split-154
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:36:56]: 所以你不认为自己是一家纯粹的基础模型公司？'
- en: '**David** [00:36:59]: No, because if we were a pure play foundation model company,
    we would be training general foundation models that do summarization and all this
    other...'
  id: totrans-split-155
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:36:59]: 不，因为如果我们是一家纯粹的基础模型公司，我们会训练一般的基础模型，可以进行摘要和所有其他的...'
- en: '**Swyx** [00:37:06]: You''re dedicated towards the agent. Yeah.'
  id: totrans-split-156
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:37:06]: 你致力于代理。是的。'
- en: '**David** [00:37:09]: And our business is an agent business. We''re not here
    to sell you tokens, right? And I think like selling tokens, unless there''s like
    a...'
  id: totrans-split-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:37:09]: 而我们的业务是代理业务。我们不是来卖给你们代币的，对吧？我觉得像卖代币，除非有像……'
- en: '**Swyx** [00:37:14]: Not here to sell you tokens. I love it.'
  id: totrans-split-158
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:37:14]: 我不是来卖给你们代币的。我喜欢它。'
- en: '**David** [00:37:16]: It''s like if you have a particular area of specialty,
    right? Then you won''t get caught in the fact that everyone''s just scaling to
    ridiculous levels of compute. But if you don''t have a specialty, I find that,
    I think it''s going to be a little tougher.'
  id: totrans-split-159
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:37:16]: 如果你有特定的专业领域，对吧？那么你就不会陷入每个人都在扩展到荒谬计算水平的事实中。但如果你没有专业领域，我觉得会有点难。'
- en: '**Swyx** [00:37:27]: Interesting. Are you interested in robotics at all? Just
    a...'
  id: totrans-split-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:37:27]: 有趣。你对机器人技术有兴趣吗？只是一个……'
- en: '**David** [00:37:30]: I''m personally fascinated by robotics. I''ve always
    loved robotics.'
  id: totrans-split-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:37:30]: 我个人对机器人技术很着迷。我一直喜欢机器人。'
- en: '**Swyx** [00:37:33]: Embodied agents as a business, you know, Figure is like
    a big, also sort of open AI affiliated company that raises a lot of money.'
  id: totrans-split-162
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:37:33]: 身体化代理作为一项业务，你知道，Figure 就像一个大公司，也算是一个开放AI的附属公司，筹集了大量资金。'
- en: '**David** [00:37:39]: I think it''s cool. I think, I mean, I don''t know exactly
    what they''re doing, but...'
  id: totrans-split-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:37:39]: 我觉得很酷。我觉得，我是说，我不知道他们具体在做什么，但是……'
- en: '**Swyx** [00:37:44]: Robots. Yeah.'
  id: totrans-split-164
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:37:44]: 机器人。是的。'
- en: '**David** [00:37:46]: Well, I mean, that''s a...'
  id: totrans-split-165
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:37:46]: 嗯，我的意思是，那是一个……'
- en: '**Swyx** [00:37:47]: Yeah. What question would you ask? If we had them on,
    what would you ask them?'
  id: totrans-split-166
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:37:47]: 是的。如果我们邀请他们上来，你会问什么问题？你会问他们什么？'
- en: '**David** [00:37:50]: Oh, I just want to understand what their overall strategy
    is going to be between now and when there''s reliable stuff to be deployed. But
    honestly, I just don''t know enough about it.'
  id: totrans-split-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:37:50]: 哦，我只是想了解从现在到可靠部署时他们的整体策略是什么。但老实说，我对此了解不多。'
- en: '**Swyx** [00:37:57]: And if I told you, hey, fire your entire warehouse workforce
    and, you know, put robots in there, isn''t that a strategy? Oh yeah.'
  id: totrans-split-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:37:57]: 如果我告诉你，嘿，解雇你们整个仓库的员工，你知道，用机器人代替，这算不算一种策略？哦，是的。'
- en: '**David** [00:38:04]: Yeah. Sorry. I''m not questioning whether they''re doing
    smart things. I genuinely don''t know what they''re doing as much, but I think
    there''s two things. One, I''m so excited for someone to train a foundation model
    of robots. It''s just, I think it''s just going to work. Like I will die on this
    hill, but I mean, like again, this whole time, like we''ve been on this podcast,
    we''re just going to continually saying these models are basically behavioral
    cloners. Right. So let''s go behavioral clone all this like robot behavior. Right.
    And then you figure out everything else you have to do in order to teach you how
    to solve a new problem. That''s going to work. I''m super stoked for that. I think
    unlike what we''re doing with helping humans with knowledge work, it just sounds
    like a more zero sum job replacement play. Right. And I''m personally less excited
    about that.'
  id: totrans-split-169
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:38:04]: 是的。抱歉。我不是在质疑他们是否在做聪明的事情。我真的不太清楚他们在做什么，但我认为有两件事。一，我非常期待有人训练一个基础模型的机器人。我觉得这会奏效。就像我会坚守这个立场，但我是说，整个时间，就像我们在这个播客上一直在说的那样，这些模型基本上是行为克隆者。对吧。所以让我们行为克隆所有这些机器人的行为。对吧。然后你们就找出其他一切你们必须做的事情，以教会它如何解决一个新问题。那会奏效的。我对此感到非常激动。我认为与我们帮助人类进行知识工作不同，这听起来更像是一场更零和的工作替代游戏。对吧。我个人对此不太感兴趣。'
- en: '**Alessio** [00:38:46]: We had a Ken June from InBoo on the podcast. We asked
    her why people should go work there and not at Adept.'
  id: totrans-split-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alessio** [00:38:46]: 我们在播客中邀请了来自InBoo的Ken June。我们问她为什么人们应该去那里工作而不是在Adept工作。'
- en: '**Swyx** [00:38:52]: Oh, that''s so funny.'
  id: totrans-split-171
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:38:52]: 哦，这太有趣了。'
- en: '**Alessio** [00:38:54]: Well, she said, you know, there''s space for everybody
    in this market. We''re all doing interesting work. And she said, they''re really
    excited about building an operating system for agent. And for her, the biggest
    research thing was like getting models, better reasoning and planning for these
    agents. The reverse question to you, you know, why should people be excited to
    come work at Adept instead of InBoo? And maybe what are like the core research
    questions that people should be passionate about to have fun at Adept? Yeah.'
  id: totrans-split-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alessio** [00:38:54]: 她说，你知道，在这个市场上每个人都有自己的空间。我们都在做有趣的工作。她说，他们真的很兴奋地在为代理构建操作系统。对她来说，最大的研究问题是为这些代理获取更好的推理和规划模型。对你的反问是，你知道，为什么人们应该兴奋地来到Adept而不是InBoo？也许人们应该对什么核心研究问题充满激情才能在Adept有乐趣？是的。'
- en: '**David** [00:39:22]: First off, I think that I''m sure you guys believe this
    too. The AI space to the extent there''s an AI space and the AI agent space are
    both exactly as she likely said, I think colossal opportunities and people are
    just going to end up winning in different areas and a lot of companies are going
    to do well. So I really don''t feel that zero something at all. I would say to
    like change the zero sum framing is why should you be at Adept? I think there''s
    two huge reasons to be at Adept. I think one of them is everything we do is in
    the service of like useful agents. We''re not a research lab. We do a lot of research
    in service of that goal, but we don''t think about ourselves as like a classic
    research lab at all. And I think the second reason I work at Adept is if you believe
    that actually having customers and a reward signal from customers lets you build
    a GI faster, which we really believe, then you should come here. And I think the
    examples for why that''s true is for example, our evaluations, they''re not academic
    evals. They''re not simulator evals. They''re like, okay, we have a customer that
    really needs us to do these particular things. We can do some of them. These are
    the ones they want us to, we can''t do them at all. We''ve turned those into evals,
    solve it, right? I think that''s really cool. Like everybody knows a lot of these
    evals are like pretty saturated and the new ones that even are not saturated.
    You look at someone and you''re like, is this actually useful? Right? I think
    that''s a degree of practicality that really helps. Like we''re equally excited
    about the same problems around reasoning and planning and generalization and all
    of this stuff. They''re very grounded in actual needs right now, which is really
    cool.'
  id: totrans-split-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:39:22]: 首先，我认为你们也相信这一点。在AI领域，如果存在AI代理的空间，它们确实如她可能所说，我认为这是巨大的机遇，人们最终会在不同的领域取得成功，很多公司会做得很好。所以我真的一点都不觉得是零和的。我想说改变零和的框架是为什么你应该在Adept呢？我认为有两个重要的理由可以在Adept工作。我认为其中一个是我们做的一切都是为了有用的代理服务。我们不是一个研究实验室。我们为实现这个目标做了大量的研究，但我们根本不把自己看作是一个经典的研究实验室。我认为我在Adept工作的第二个原因是，如果你相信实际拥有客户和来自客户的奖励信号能让你更快地建立一个GI，我们真的相信，那么你应该来这里。我认为为什么这是真的的例子是，例如，我们的评估，它们不是学术评估。它们也不是模拟器评估。它们就像，好吧，我们有一个客户真的需要我们做这些特定的事情。我们可以做其中的一些。这些是他们想要我们做的事情，我们根本不能做。我们已经把它们变成了评估，解决了，对吧？我觉得这真的很酷。就像大家都知道，很多这些评估都相当饱和，即使是新的，甚至不饱和的，你看着某人，你会想，这真的有用吗？对吧？我认为这是一种实用性的程度，真的很有帮助。像我们对推理、规划和泛化等所有这些问题的兴奋程度是一样的。它们都非常扎根于当前的实际需求中，这真的很酷。'
- en: '**Swyx** [00:40:45]: Yeah. This has been a wonderful dive. You know, I wish
    we had more time, but I would just leave it kind of open to you. I think you have
    broad thoughts, you know, just about the agent space, but also just in general
    AI space. Any, any sort of rants or things that are just off of mind for you right
    now?'
  id: totrans-split-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:40:45]: 是的。这是一个很棒的深入探讨。你知道，我希望我们有更多的时间，但我想我会留给你一些广泛的思考，关于代理空间，但也关于AI空间的一些事情。任何，任何你现在心中的牢骚或想法？'
- en: '**David** [00:40:57]: Any rants?'
  id: totrans-split-175
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:40:57]: 有什么牢骚吗？'
- en: '**Swyx** [00:40:59]: Mining you for just general...'
  id: totrans-split-176
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:40:59]: 从你身上挖掘一般性的...'
- en: '**David** [00:41:01]: Wow. Okay. So Amelia has already made the rant better
    than I have, but, but like not just, not just chatbots is like kind of rant one.
    And two is AI has really been the story of compute and compute plus data and ways
    in which you could change one for the other. And I think as much as our research
    community is really smart, we have made many, many advancements and that''s going
    to continue to be important. But now I think the game is increasingly changing
    and the rapid industrialization era has begun. And I think we unfortunately have
    to embrace it.'
  id: totrans-split-177
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:41:01]: 哇。好的。所以阿梅利亚已经比我更好地发表了愤怒的言论，但不仅仅是聊天机器人，这有点像是愤怒的一种。而且AI真的是计算和计算加上数据的故事，以及你可以把一个换成另一个的方式。我认为虽然我们的研究社区非常聪明，我们已经取得了许多进展，这将继续是重要的。但是现在我认为游戏正在日益改变，快速工业化时代已经开始了。不幸的是，我认为我们不得不接受它。'
- en: '**Swyx** [00:41:30]: Yep.'
  id: totrans-split-178
  prefs: []
  type: TYPE_NORMAL
  zh: '**Swyx** [00:41:30]: 是的。'
- en: '**Alessio** [00:41:31]: Excellent. Awesome, David. Thank you so much for your
    time.'
  id: totrans-split-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**Alessio** [00:41:31]: 太棒了。非常感谢你的时间，David。'
- en: '**David** [00:41:34]: Cool. Thanks guys.'
  id: totrans-split-180
  prefs: []
  type: TYPE_NORMAL
  zh: '**David** [00:41:34]: 很酷。谢谢大家。'
