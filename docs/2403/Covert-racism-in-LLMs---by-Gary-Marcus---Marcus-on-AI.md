<!--yml

category: 未分类

date: 2024-05-27 14:37:09

-->

# LLMs 中的隐性种族主义 - Gary Marcus - Marcus on AI

> 来源：[https://garymarcus.substack.com/p/covert-racism-in-llms](https://garymarcus.substack.com/p/covert-racism-in-llms)

来自Allen AI、斯坦福大学和其他机构的 [一个非常重要的新论文](https://arxiv.org/abs/2403.00742)：

我不应该感到惊讶，因为我知道这些东西是如何运作的，但结果令人震惊和可怕。以下是他们所做和发现的部分示例，摘自第一作者在 X 上的帖子：

基本方法是在提示中嵌入标准美式英语或非裔美国人英语，并从那里观察结果：

并且要重要区分显性种族主义与隐性种族主义：系统很少直接说“黑人不好”之类的话语 — 在显性措施上，系统表现得很好。但在隐性措施上，它们却是灾难性的：

鉴于LLMs的广泛应用，其潜在影响是巨大的：

而

[回应阿贝巴·比赫恩的一个重要发现](https://www.researchgate.net/publication/371855219_On_Hate_Scaling_Laws_For_Data-Swamps)，实际上规模会使隐性种族主义 *更糟*：

看起来，措辞上的微不足道的方言选择驱动了这种现象的很大部分：

LLMs（大型语言模型），正如我一直试图告诉你的那样，太愚蠢了，无法理解人和种族这样的概念；它们对表面统计数据的忠诚驱使了这种可怕的刻板印象。

正如Hofman在X上所说的，这有点像一个双重打击：“用户误以为显性偏见减少是LLMs种族主义问题得到解决的标志，而实际上LLMs对隐性偏见的达到却在增加。” 其他普林斯顿的最新研究 [刚刚发现的](https://arxiv.org/pdf/2402.04105.pdf) 也指向同样的方向。

Hofman 的总结非常严厉：

§

当汽车制造商生产严重问题时，他们有义务召回他们的汽车。Hofman 和他的合作者（包括麦克阿瑟奖获得者丹·尤拉夫斯基）所记录的情况可能已经对现实世界产生了影响。在很多方面，我们不知道LLMs在实际世界中的使用方式，例如在住房决策、贷款决策、刑事诉讼等方面的使用情况。但现在有强有力的证据表明，存在着隐性种族主义，甚至在这些用例中使用LLMs。我建议国会、EEOC、HUD、FTC等机构进行调查，并要求主要LLMs制造商提供用户日志和互动数据。其他国家的对应机构也应考虑采取相同行动。

我真的看不出有简单的解决方案 — [仅仅增加人类反馈反而使情况变得更糟](https://x.com/vjhofmann/status/1764687451254067373?s=12)，正如作者们所示。而谷歌的灾难表明，保护栏从未容易过。。。

但LLM公司应该召回他们的系统，直到他们找到一个合适的解决方案。这是不能容忍的。我[在change.org上发布了请愿，希望你们考虑签名和分享](https://chng.it/xfLJh9C2nL)。

[分享](https://garymarcus.substack.com/p/covert-racism-in-llms?utm_source=substack&utm_medium=email&utm_content=share&action=share)

***Gary Marcus**的第一份有偿工作是为他当时从事歧视法律的父亲做统计工作。这些新的结果让他感到恶心；他的父亲肯定会感到愤慨。*
