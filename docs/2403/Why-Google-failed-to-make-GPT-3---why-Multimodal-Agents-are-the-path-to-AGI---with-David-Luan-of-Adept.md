<!--yml

category: 未分类

date: 2024-05-29 12:41:15

-->

# 为什么谷歌未能制作GPT-3 + 为什么多模态代理是通向AGI的路径 — 与Adept的David Luan

> 来源：[https://www.latent.space/p/adept](https://www.latent.space/p/adept)

*我们的下一个旧金山活动是 [AI UX 2024](https://lu.ma/aiux) - 让我们看看UX的新前沿，因为[去年](https://www.latent.space/p/build-ai-ux)以来！*

*最后通告：我们正在录制 [AI工程师世界博览会](https://twitter.com/aiDotEngineer/status/1754929063993737721) 的预览，与swyx和Ben Dunphy一起，[发送任何关于](mailto:ben@ai.engineer) [Speaker CFPs](https://docs.google.com/forms/d/e/1FAIpQLScc-47zw-tWjYbhAkwTeLy_-MQW3L-3uwtaVnEzudrEZcQ7bg/viewform?usp=sf_link) 和 [Sponsor Guides](mailto:ben@ai.engineer) 的问题！*

*Alessio 正在为他在 Decibel 孵化的新创业公司招聘工程师：理想的候选人是“前技术联合创始人类型”。 [联系他](https://twitter.com/FanaHOVA/) 获取更多信息！*

* * *

**[David Luan](https://twitter.com/jluan)** 是现代人工智能革命的中心人物：他是 OpenAI 的第30位员工，领导了谷歌的LLM项目并共同领导了Google Brain，然后在2022年创立了Adept，这是人工智能代理领域的领先公司之一。在今天的节目中，我们请教了David关于他在早期OpenAI的时光中的一些战斗经历（包括与 [Alec Radford](https://twitter.com/swyx/status/1699369076529971545) 合作，在与Sam Altman展示GPT-2之前，导致了[Microsoft的初始10亿美元投资](https://openai.com/blog/microsoft-invests-in-and-partners-with-openai)），以及Adept如何**构建能够“在计算机上做任何人类做的事情”*** — 他对有用的AGI的定义。

虽然我们想讨论Adept，但我们无法与前OpenAI副总裁兼Google Brain的前LLM技术负责人交谈，而不谈到房间里的大象。

人们常常问，为什么Google在2017年由Vaswani等人创建变压器并[Noam Shazeer预测万亿参数模型](https://www.youtube.com/watch?v=9P_VAMyb-7k) 但最终是OpenAI的David团队制作了GPT 1/2/3\.

David 给出了一些有趣的答案：

> *“所以我认为 GPT 的真正故事始于 Google，当然了，对吧？因为那是变形金刚的诞生地。然而，对我来说最令人震惊的事情是，这其实是谷歌组织方式的一个后果……他们（应该）本来应该说，嘿，Noam Shazeer，你是个天才。你知道如何扩展这些东西。**这里是我们所有TPU的一半。然后我认为他们会毁掉我们。** 他显然也想要这样做……*
> 
> *你知道，我们每天都在扩展GPT-3，我会醒来只是感到压力山大。我之所以感到压力，是因为你看看事实，对吧？谷歌拥有所有这些计算资源。谷歌有所有那些发明这些基础技术的人。还有一个叫诺姆的家伙，他非常聪明，他已经做了一个关于他想要一个万亿参数模型的演讲。我只是觉得我们可能只是在做与他相同的重复性研究。他有一个只有解码器的变压器，可能会比我们更早达到那个目标。*
> 
> ***结果一直是他们只是无法获得关键质量。** 因此在我领导Google LM项目的那一年，我成为了其中一位脑力领导，你知道，这一切变得非常清楚。当时有一个叫大脑积分市场的东西。每个人都分配了一个积分。所以如果你有积分，你可以根据供需购买末端芯片。** 所以如果你想做一项巨大的工作，你必须说服19或20位同事不要工作。** 如果事情是这样的，要想获取底层的关键质量来扩展这些事情是非常困难的。谷歌团队正在英勇地战斗，但是**我们能够击败他们，仅仅因为我们采取了大的飞跃并且专注于目标。”*

人类智慧通过进化发展到今天的状态。有人认为**要达到AGI，我们将近似于所有进化过程中的“FLOPs”**，这个方法最著名的是Ajeya Cotra的[生物锚报告](https://www.lesswrong.com/posts/KrJfoZzpSDpnrv9va/draft-report-on-ai-timelines)。

OpenAI早期非常依赖强化学习驱动[Dota项目](https://openai.com/research/openai-five-defeats-dota-2-world-champions)，但这对于这些模型重新学习一切来说是非常低效的方式。（Imbue的Kanjun在她的集中分享了[类似的想法](https://www.latent.space/p/imbue)。）

**大卫认为有一个捷径。** 我们可以从现有的智能中启动。

> *“多年前，我与一位伯克利教授辩论，关于构建AGI实际需要什么。他的观点基本上是，你必须重复进化过程中所有的浮点运算才能达到那个目标…… 我认为我们忽视了一个巨大的捷径，即**你可以行为上克隆人类已经掌握的一切知识**。这就是我们用LLMs解决的问题！”*

今天的LLMs基本上是利用所有（好的！）书面知识来建模智能（请参见我们的[数据集101集](https://www.latent.space/p/datasets-101)），现在已经扩展到非语言知识（请参见我们的[HuggingFace集](https://www.latent.space/p/idefics)关于多模态）。SOTA的自监督预训练过程在处理大量非结构化数据并近似推理时非常高效，避免了过拟合。

但是，你如何跨越从今天的LLMs到构建我们所有人都想要的AGI的鸿沟？

这就是为什么David和朋友们离开创立Adept的原因。

> “*我们认为普通智能的最清晰的界定是**一个系统能在计算机前完成人类能做的任何事情**。一个行动的基础模型，训练使用每个软件工具、API和现有的Web应用程序，是实现这一宏大目标的实际途径*” — [ACT-1博客文章](https://www.adept.ai/blog/act-1)

AGI梦想是完全自治的代理，但基于它们的可靠性，我们对我们的代理给予了[自治级别](https://www.latent.space/p/agents)，在David的词语选择中，我们始终希望更高级别的“抽象”（即自治），但我们对“可靠性”的需求是我们可以使用的抽象水平的实际限制。

> *“Adept的关键路径在于我们希望建立能够随着时间推移执行更高级抽象任务的代理程序，同时保持极高的可靠性标准。因为这是将我们从研究转变为客户需求的关键。**如果你建立的代理具有非常高的可靠性标准，同时不断推动抽象水平，那么你就可以从用户那里学习如何更快地实现下一个抽象水平。** 所以这就是你实际构建数据流的方式。”*
> 
> *“这是公司的关键路径。我们所做的一切都是为了这个。”*

我们在2023年的峰会上看到了Adept如何思考不同抽象级别：

最高的抽象是“AI员工”，但我们将通过“AI启用的员工”来实现这一点。Alessio [最近在本周的Nvidia GTC上发表了演讲](https://twitter.com/FanaHOVA/status/1771235466207195379)关于“服务作为软件”未来的工作 ([幻灯片](https://github.com/FanaHOVA/nvidia-gtc-2024-slides))。

与许多大型研究实验室不同，Adept将AGI的框架定义为“*能够像人类一样使用你的计算机* **”，这带来了一个有用的环境约束：

> *“拥有一个人类机器人**让你能够做人类做的事情*** **而无需在途中更改一切***。对软件来说也是一样，对吧？如果你列出你想在计算机上做的事情的数量，每一步都有一个API，那么这些工作流的数量就会接近零。所以在很多时候，你需要能够像人类一样实际控制你的计算机。它还允许你**从人类使用计算机中学习作为训练数据的来源，如果你必须以某种方式弄清楚每个特定步骤需要成为某种特定的自定义私有API事物，那么你将无法获得**。 所以我认为这实际上是（经济价值的）最实用路径。”*

这种认识和信念意味着多模态模型是前进的方向。与其使用函数调用来调用 API 来构建代理，这是迄今为止 OpenAI 和大多数开放 LLM 行业所做的，Adept 想要“通过视觉驱动”（即像人类一样看待屏幕）并准确定位点击和键入。不需要 API，因为大多数软件不公开 API。

> 读者的额外背景信息：您可以在同样的光线下看到 [DeepMind SIMA 模型](https://buttondown.email/ainews/archive/ainews-deepmind-sima-one-ai-9-games-600-tasks/)：
> 
> 一个系统学会了玩各种游戏（而不是每个游戏专用一个模型）只使用像素输入和键盘鼠标操作输出！
> 
> OpenInterpreter 团队正在开发一个 “[计算机 API](https://api.openinterpreter.com/)” 也在做同样的事情。

为了做到这一点，Adept 必须加倍努力专注于 **多模态知识工作** 的特殊类型：

> *“一个非常必要的巨大物件是真正快速的多模态模型，它们非常擅长 **理解知识工作** 和 **理解屏幕**。这需要成为这些代理的基础之一...*
> 
> *...我认为多模态模型主要学术关注的一个大问题是，大多数多模态模型主要是训练在像 **自然图像、猫和狗的照片** 这样的东西，那些是从相机中获取的... 但是它们最有用处的地方在哪里呢？**它们在知识工作任务中最有用**。那里是大部分经济价值的所在。不在猫和狗身上。*
> 
> *那么如果就是这样，你需要训练什么？我需要训练像 **图表、图形、表格、发票、PDF、收据、非结构化数据、用户界面** 这样的东西。那是一个完全不同的预训练语料库。因此，Adept 花了很多时间来构建它。*

在这种背景下，您现在可以理解 Adept 的公共发布的完整路径：

+   **[ACT-1](https://www.adept.ai/blog/act-1)**（2022 年 9 月）：一个为浏览器交互优化的大型 Transformers 模型。它具有自定义的浏览器视口渲染，可以更好地理解并采取行动。

+   **[Persimmon-8B](https://www.adept.ai/blog/persimmon-8b)**（2023 年 9 月）：一个宽容的开放 LLM 模型（[权重和代码在此处](https://github.com/persimmon-ai-labs/adept-inference)）。

+   **[Fuyu-8B](https://www.adept.ai/blog/fuyu-8b)**（2023 年 10 月）：Adept 动力的 **多模态** 模型的小版本。Vanilla 解码器-唯一的变压器，没有专门的图像编码器，允许它处理不同分辨率的输入图像而不降低采样率。

+   **[Adept 实验](https://www.adept.ai/blog/experiments)**（2023 年 11 月）：一个在浏览器中构建自动化的公共工具。这由 Adept 的核心技术驱动，但仅是其企业平台的一部分。他们将其用作尝试各种设计思路的一种方式。

+   **[Fuyu Heavy](https://www.adept.ai/blog/adept-fuyu-heavy)**（2024年1月）- 一款专门为数字代理人设计的新的**多模态**模型，是世界第三强的多模态模型（在MMMU、AI2D和ChartQA上击败了Gemini Pro），“仅次于GPT4-V和Gemini Ultra，它们的规模大约是10-20倍”

特别是Fuyu-8B帖子展示了许多知识工作多模态性的例子：

现在OpenAI的市值超过了90亿美元，Anthropic超过了18亿美元，很容易得出结论，AI初创公司的元游戏是建立一个大型研究实验室，并吸引最聪明的头脑和最高的资本来构建AGI。

我们的过去的客人

（见[Humanloop的一集](https://latent.space/p/humanloop)）和（来自[Imbue](https://www.latent.space/p/imbue)）结合在一起，对播客提出了最具挑战性的问题 - 由于David/Adept来自Deepmind和OpenAI的深度研究背景，为什么Adept不建立更广泛的基础模型（像Persimmon一样）并参与学术基准竞赛？为什么Adept如此专注于商业代理人？

> *“我感觉超级好，我们正在为代理人做基础模型，而Adept的所有回报都来自于‘我们能否制造一个更好的代理人’…”*
> 
> *我认为**纯粹的基础模型公司将受到接下来几个（Meta Llama 模型）的挑战… 看到真正的大玩家投入大量计算资源来训练这些基础模型，**我认为这将使得很多普通的LLM和很快普通的多模态模型将会被商品化。所以我真的觉得我们只专注于代理人是正确的选择。”*

并且商业基础是他回答卡恩君的答案（我们也问了相反的问题来与Adept比较）：

> *“…我在Adept工作的第二个原因是，如果你相信**实际上有客户和来自客户的奖励信号可以让你更快地构建AGI**，我们确实相信，那么你应该来这里。我认为这是为什么这是真实的例子，比如，**我们的评估不是学术评估**。它们不是模拟器评估。这些都是，好吧，我们有一个真正需要我们做这些特定事情的客户。我们可以做其中的一些。他们想要我们做的这些，我们根本做不到。我们已经把它们转化为评估… 我认为这种实用性确实有助于。”*

而且他的客户似乎非常满意，因为David不需要进行销售推广：

> *David: “我们之前没有分享过的一件事是，我们完全售罄了Q1的产品。”*
> 
> *Swyx: “卖掉了什么？”*
> 
> *David: “卖掉了接纳更多客户的带宽。”*

嗯，这是一个很好的问题。

+   [00:00:00] 介绍

+   [00:01:14] 成为OpenAI的第30名员工及其早期阶段

+   [00:13:38] 什么是Adept以及你如何定义AGI？

+   [00:21:00] Adept的关键路径和研究方向

+   [00:26:23] AI代理应如何与软件互动并影响产品开发

+   [00:30:37] AI代理与自动驾驶汽车开发之间的类比

+   [00:32:42] 在AI代理中平衡可靠性、成本、速度和通用性

+   [00:37:30] 基于基础模型在机器人技术中的潜力

+   [00:39:22] Adept的核心研究问题和工作原因

**Alessio** [00:00:00]: 大家好，欢迎来到《潜空间播客》。我是Alessio，[Decibel Partners](https://decibel.vc/)的合伙人兼技术总监，我还有我的联合主持人Swyx，[Smol.ai](https://smol.ai/)的创始人。

**Swyx** [00:00:15]: 嗨，今天我们有David Luan，Adept的CEO和联合创始人，出现在我们的节目中。欢迎。

**David** [00:00:20]: 是的，谢谢你邀请我来。

**Swyx** [00:00:21]: 已经进行了一段时间了。我在一次风投活动上见过你，你说你有兴趣上节目，很高兴我们终于能够实现这个愿望。

**David**: 是的，很高兴能成为其中的一员。

**Swyx**: 我们喜欢介绍发言人，然后让你稍微谈谈关于你LinkedIn上没有的东西，人们应该一般性地了解你。你在大学期间创办了一家公司，那是第一个实时视频检测分类API，那就是Dextro，后来你被Axon收购成为了AI总监。然后你是OpenAI的第30号员工？

**David** [00:00:53]: 是的，大概是第30到35号吧。差不多是这样。

**Swyx** [00:00:56]: 所以你曾经担任了两年半至两年的工程副总裁，短暂担任过谷歌大型模型的技术负责人，然后在2022年创办了Adept。这是你的简短简历。还有其他什么你想要补充或者人们应该更多了解的吗？

**David** [00:01:14]: 我想更广泛地说，我比较早就加入了 OpenAI，领导了大约两年半到三年的工程工作。非常有趣的是，在我加入 OpenAI 的第二或第三天，Greg 和 Ilya 把我拉到一个房间，告诉我说，你应该接管我们的直接团队，而我们会大多数时间做 IC 工作。所以这很有趣，从一些早期已经发生的倡议中整合了一些团队。公司的 Dota 项目进展顺利，然后更广泛地试图为我们正在进行的基础研究提供更大的方向性。所以我花了很多时间做这些事情。然后我领导了 Google 的 LLM（Legal Language Model）工作，也是 Google Brain 的联合领导之一。你知道，AI 研究有几个不同的时代，对吧？如果我们把 2012 年以前的一切都称为史前时期，人们讨厌我这么说，但在 2012 年到 2017 年这段时间，我们有这种感觉，你和你的三个最好的朋友写了一篇改变世界的研究论文。我认为 2017 年游戏发生了变化，大多数实验室没有意识到，但我们在 OpenAI 真的意识到了。我认为这在很大程度上得益于 Ilya 不断强调世界将被数据中心覆盖。我认为-

**Swyx** [00:02:15]: 这真是一个因果关系的好例子。

**David** [00:02:16]: 是的。我认为我们对此有信念，但直到我们开始看到结果才清楚地意识到，这是我们必须走的道路。但也有一部分是因为 OpenAI，当我刚加入时，我认为我必须做的一项工作是如何为我们的技术身份建立一个有区别的愿景，而不仅仅是小一点的 Google Brain，或者你在 SF 居住并且不想通勤到 Mountain View 或不想住在伦敦，对吧？这对于作为一个公司的技术身份来说是不够的。所以我们真正做的是，我花了很多时间推动这一点，就是我们如何集中精力在一定类别的巨大变革和赌注上，对吧？像如何从你只做自底向上的研究到更多地关注你想要展示的大科学成果，然后不计一切成本去解决它们，不管你是否关心新颖性和所有那些东西。这成为了几年的主导模式，对吧？然后现在改变的是，我认为接下来几年 AI 产品的主要驱动因素将是产品和用户之间深度协同设计和共同进化，以获取反馈和实际技术。我认为实验室，拥有去做这些事情的每一种工具都会做得非常好。这也是我开始 Adept 的重要原因。

**Alessio** [00:03:20]: 你提到了Dota，有没有从RL转向Transformers的记忆，以及行业如何在LLM方面发展，逐渐放弃一些更多代理模拟工作的？

**David** [00:03:33]: 总体来看，我认为代理是未来正确的方向，对吧？你只需去找到什么是通用人工智能（AGI），对吧？你就像，嘿，首先，实际上，我不太喜欢涉及人类替代的AGI定义，因为我不认为事情会真的发生这样的方式。即使这样的定义，比如AGI是在经济上有价值任务上表现优于人类的东西，也是对世界的一种隐含观点，关于人类的角色会是什么样子。我更感兴趣的是围绕一个模型可以在计算机上做任何人类可以做的事情的AGI定义。如果你考虑这个，这是非常可行的，那么代理就是这个定义的一个自然结果。那么我们在我们自己的事情上所做的所有工作，最终给我们带来的是什么？它让我们有了一个非常清晰的表述。你有一个目标，你想最大化这个目标，你想最大化奖励，对吧？而自然的LLM表述并不直接包含这一点，对吧？我认为我们作为一个领域在思考如何解决这样的问题时做对了很多事情。但我们忘了的一件事是，从头开始用RL可能是一种快速到达目标的相当糟糕的方法。为什么我们要重新发现几年前关于世界的所有知识？多年前，我曾与伯克利的一位教授辩论，关于构建通用人工智能究竟需要做些什么。他的观点基本上是，你必须再现进化中所涉及的所有浮点运算才能达到那个目标，对吧。

**Swyx** [00:04:44]: 生物学基础理论，对吧。

**David** [00:04:46]: 我认为我们忽略了一个重要事实，那就是你可以行为克隆所有人类已经知道的东西。这就是我们用LLM解决的问题。我们已经解决了行为克隆，也就是人类已经知道的一切。对吧。所以今天，也许LLM就像是行为克隆互联网上每一个写出来的词，未来，多模态模型正在变得更加普及，它们可以行为克隆视觉世界。但实际上，我们将会拥有的是一个通用字节模型，对吧？输入具有高信号的数据令牌，然后模型会学习所有这些模式。然后你可以随意组合输出。比如文本转语音输出，图片转图片或视频输出等等，这些映射关系，对吧？都将被这个通用行为克隆器学习到。所以我很高兴我们解决了这个问题。我认为现在我们回到了如何将这个与强化学习期间我们学到的所有经验教训结合起来的时代。

**Swyx** [00:05:35]: 我还会继续压你讲几个早期开放的故事，然后再谈ADET的事情。在你的个人网站上，我很喜欢，因为它真的很不错，像是关于你历史的个人故事背景。我需要更新它。它太老了。是的，它太过时了。但你提到了GPT-2。你和GPT-1有重叠吗？我记得你有，对吧？

**David** [00:05:53]: 我其实不太记得了。我觉得我大概是在那个时候加入的，对吧？

**Swyx** [00:05:57]: 我大概就在那个时候，是的。是的。所以我记得Alec，你知道，他就进来了，非常着迷于Transformers，并将它们应用于像Reddit情感分析这样的事情。是的，情感分析，没错。带我们走一遍-

**David** [00:06:09]: 情感神经元，所有这些东西。

**Swyx** [00:06:10]: GPT的历史，就你所知道的来说。啊，好的。

**David** [00:06:14]: 根据我看来，GPT的真正故事始于Google，当然，对吧？因为那里是Transformers诞生的地方。然而，对我来说最令人震惊的事情之一是，这是Google组织方式的一个后果，就像，你和你的三个最好的朋友写论文，对吧？好的。所以放大一点，对吧？我想到我在谷歌全职研究领导时的工作有点像投资组合分配者，对吧？所以我手下有一些非常聪明的人。我的工作是说服人们围绕一小部分真正好的想法聚集起来，然后把它们推到终点线。我的工作实际上不是促进无数想法，从不形成关键的大规模。然后当这些想法开始结合起来并且一些开始表现良好时，我的工作就是向那些真正有效的事物推进资源，然后开始解散一些不起作用的东西，对吧？在我在谷歌的那段时间里，这种能力根本不存在。我想如果他们有的话，他们会做的事情是，嘿，Noam Shazir，你是个聪明的家伙。你知道如何扩展这些东西。这里有我们所有TPU的一半。然后我想他们会摧毁我们。他显然也想要这样做。

**Swyx** [00:07:17]: 他在2017年谈论万亿参数模型。

**David** [00:07:20]: 是的。这就是 GPT 故事的核心，对吧？我在历史上跳来跳去，但在 GPT-2 之后，我们对 GPT-2 都非常兴奋。我可以告诉你更多关于那个时期的故事。那是我真正接触的最后一篇论文，在那之后，一切都更多地变成了建立一个研究机构。你知道的，每天我们都在扩展 GPT-3，我早上醒来就感到压力重重。我感到压力重重，因为你知道，你只要看看事实，对吧？谷歌有这么多计算资源。谷歌有所有发明这些基础技术的人。还有一个叫诺姆的家伙，他非常聪明，他已经谈过他想要一个万亿参数模型的话题。我就像，我们可能只是在做他正在做的重复研究，对吧？他有这个仅有解码器的变压器，可能会在我们之前实现这个目标。但我还是像，但是，请让这个模型完成，对吧？结果，整个时间，他们只是无法形成临界质量。所以在我领导谷歌 LM 努力的那一年，我也是大脑负责人之一，你知道的，事实变得非常清楚，为什么，对吧？那时候，有一个叫做大脑积分市场的东西。你们知道大脑积分市场吗？不，我从未听说过这个。哦，所以这实际上是一个，你可以问任何谷歌员工。

**Swyx** [00:08:23]: 这就像只是一个事情，看起来像，是的，资源有限，你必须有某种市场，对吧？有时是明确的，有时不是，你知道的，只是政治恩惠。

**David** [00:08:34]: 你可以。所以基本上每个人都分配了一张积分，对吧？所以如果你有积分，你可以根据供需购买端芯片。所以如果你想做一个大项目，你必须说服像你同事中的19或20个人不做工作。如果这就是它的工作方式，要让这些事情扩展起来真的很难。谷歌的团队正在英勇地战斗，但我们之所以能够击败他们，只是因为我们采取了大的举措并且专注于此。我认为，再次，这就像是 AI 第一阶段的叙述的一部分，对吧？像这个现代 AI 时代的第一阶段到第二阶段。而且我认为以同样的成功不对称性，第三阶段公司将会超越第二阶段公司。

**Swyx** [00:09:12]: 是的。我认为人们低估了在早期时期 NVIDIA 与你们合作的程度。我想也许，我认为是詹森。我不确定是谁最近流传了一张他把第一台 DGX 交付给你们的照片。

**David** [00:09:24]: 我认为詹森一直是一个完全的传奇和一个天才。我对 NVIDIA 非常敬佩。简直是难以置信。

**Swyx** [00:09:34]: 但就像 OpenAI，他们提出他们的需求，比如共同设计，或者仅仅使用 NVIDIA 给他们的东西。

**David** [00:09:40]: 我们与他们的合作非常密切。有一些故事可能我不能分享，但有些我特别感兴趣的例子。例如，Scott Gray 很了不起。我很喜欢和他合作。他曾在我的一个团队——超级计算团队工作，由克里斯·伯纳管理，而克里斯·伯纳至今仍在这方面做了很多工作。因此，我们与英伟达的联系非常紧密。实际上，我在 Adept 的联合创始人之一——埃里克·埃尔森，也是早期的 GPGPU 人士之一。所以他、Scott、Brian Catanzaro 在英伟达，以及 Jonah 和 Ian，我想他们都非常亲近。我们都是这个团体的一部分，如何将这些芯片推向极限？我认为这种合作对我们帮助很大。我认为一个有趣的事情是，了解 A100 一代，像四重稀疏性会成为一种趋势。这是我们想要去探索的事情吗？我们要弄清楚这是否是我们实际上可以用于模型训练的东西。实际上，这归结为，我认为越来越多的人意识到，即使六年前，甚至三年前，人们也不愿接受这一点。这个 AI 时代实际上是一个计算的故事。这是一个关于如何更有效地映射实际可用模型 FLOPS 到计算能力的故事。

**Swyx** [00:10:38]: 有没有其他 GPT 2、3 的故事，你认为人们在投入了大量工作后却没有得到应有的认可，但你想让更多人知道的？

**David** [00:10:48]: 这里有两个有趣的 GPT 2 的故事。其中一个是，我花了很多时间帮助 Alec 加快论文的进展。我记得最有趣的时刻之一是我们在写建模部分时。我相当确信，这个建模部分是任何合理合法的机器学习论文中最短的建模部分。如果我记得正确的话，它只有几段。这是一个标准的香草解码器，仅仅带有这些特定的内容。当时我们两个都在看着它，心里想着，老一辈领域专家们一定会不喜欢这个。他们会说没有新意。为什么你们要做这个工作？现在回头看，这是一个关键的论文，但我认为这是早期的一篇文章，我们完全专注于解决 AI 中的问题，而不是像是用数学语言掩盖的四种简单的思想，实际上并没有推动领域的进展。

**Swyx** [00:11:42]: 是的。就像你创新于数据集和扩展，而不是架构。

**David** [00:11:48]: 我们现在都知道它是如何运作的，对吧？就是通过在规模的前沿获得的一系列艰难的知识。这些艰难的知识，很多都没有公开发表。实际上，很多东西甚至不容易归结为典型的学术论文。但这些知识恰恰是帮助区分一个扩展计划与另一个的东西。你还有第二个吗？所以第二个是，这里有一些细节我可能不应该完全分享，但非常有趣的是，在微软最后一次投资 OpenAI 之前的最后一次会议上，Sam Altman、我和我们的首席财务官飞到西雅图进行最终的演讲。我以前是一名创始人。所以我总是对合伙人会议感到非常焦虑，基本上这就是它的含义。我有 Kevin Scott 和 Satya 以及 Amy Hood，我的工作是提供关于通向 AGI 的技术幻灯片，以及我们的研究项目组合等等，但我的工作还包括进行 GPT-2 的演示。我们有一个稍大一点的 GPT-2 版本，就在这次飞行前的一两天刚刚发布。正如我们现在都知道的，你在一个检查点上找到的模型行为在另一个检查点上是不可预测的。所以我花了很多时间想办法如何保持这个东西在轨道上。我有我的标准演示，但我知道我必须把它交给 Satya 和 Kevin，让他们输入任何内容。这让我整夜都很焦虑。

**Swyx** [00:13:06]: 不错。是的。

**Alessio** [00:13:08]: 我的意思是，这一定帮助了你谈论合作伙伴会议。你为 Adept 筹集了 4.2 亿美元。最后一轮是 3.5 亿美元的 B 轮，所以我相信你在合作伙伴会议上表现得很出色。

**Swyx** [00:13:18]: 投资者会议。不错。

**David** [00:13:20]: 不，从风险投资人那里得到这样的赞美是很高的评价。

**Alessio** [00:13:22]: 是的，不，我的意思是，你已经为我们做得很好了。让我们谈谈 Adept。我们之前做了预备工作，你提到很多人可能不理解 Adept 是什么。通常我们会介绍产品，然后由创始人填补空白，但也许我们可以反其道而行之。Adept 是什么？对。

**David** [00:13:38]: 所以我认为 Adept 是在基础模型加代理领域中最不被理解的公司。我将解释一些细节，说明它是什么，也会解释为什么它实际上与人们预想的大不相同。Adept 的目标是建立一个能够帮助人类在计算机上做任何事情的 AI 代理。所以这实际上意味着我们希望这个东西非常擅长将像目标规范这样的自然语言转换为正确的最终步骤集，并且还具备所有正确的传感器和执行器，可以在您已经使用的任何软件工具中完成这些任务。因此，这个终极愿景实际上是，我认为在未来几年内，每个人都将能够使用一种 AI 同事，可以委派任意任务，并且还可以将其用作发散思考的媒介，从而提高工作效率。这真的会改变每个工作的形态，不再仅仅是执行任务，而是更多地关注“我应该做什么以及为什么”的核心人文技能。我发现这非常令人兴奋和激动，因为我认为这实际上是对 AGI 如何发展的一个非常不同的愿景。我认为像 Adept 这样的系统最有可能成为原型 AGI 系统。但是我们对每个人都非常反直觉的方式在于，我们实际上一直保持低调，因为我们不是一家开发者公司。我们不销售 API，也不销售开源模型。我们也不销售底层产品。我们实际上是一家企业公司。所以我们的做法是与各种不同的公司合作，有些是晚期成熟的数千人规模的初创公司，有些是财富 500 强企业等等。我们为他们提供一个即插即用的解决方案，可以将他们员工每天执行的复杂工作流委派给这个模型。所以我们在这方面与其他公司有所不同，因为在构建这种完整的代理系统时，最重要的是要保证可靠性。所以最初，DEP 做的第一件事情之一就是发布了一个名为 Act One 的演示，对吧？Act One 相当酷炫。它已经成为人们展示代理演示的一种标准，通过访问 Redfin 并要求购买某个地方的房子，因为我们在最初的 Act One 演示中做到了这一点，并展示了像 Google Sheets 等其他内容。自从那之后的一年里，有很多非常酷的演示，您可以尝试玩玩，然后您会发现它们大约 60% 的时间都有效。但是由于我们始终关注如何构建一个了不起的企业产品，企业不能使用任何不可靠的东西。因此，我们实际上不得不选择一种与传统工程领域中的代理技术稍有不同的技术路线来优先考虑可靠性。所以我们的一个用例足够疯狂，以至于它最终会导致一辆卡车根据代理工作流程被发送到一个地方。如果这种方法只有效 60% 的时间，那么就是在浪费金钱，让可怜的卡车司机去一些地方。

**Alessio** [00:16:30]: 有趣。我们投资团队之一有一个“服务即软件”的概念。实际上，我将在 NVIDIA GTC 上就此发表演讲，但基本上就是软件即服务，你将用户生产力包装成软件，带有代理和服务作为软件，取代了一些你本来会请人来做的事情，现在软件替你完成了。当你考虑这些使用案例时，用户是否仍然可以查看代理程序执行的情况并进行干预，还是完全被移除了？比如说卡车的情况，卡车是直接出现，还是中间有人在检查？

**David** [00:17:04]: 我觉得在将服务视为软件的框架中有两个当前的缺陷，或者说我认为你刚才说的。我认为其中一个是在我们的经验中，随着我们推出 Adept，实际执行工作的人员最为兴奋，因为他们不再是从“我做这份工作”到“我不再做这份工作”。他们是从“我做这份工作，包括繁琐的机械化工作”到“我是一个监督者”。当你看着它被使用时，真的是一种神奇的体验，因为现在它可以并行执行以前你作为人类顺序手工执行的许多任务之一。你可以随时点击任何一个任务，比如，“我想看一下代理程序通过哪些轨迹来解决这个问题”。与 LLM 生成不同的是，代理程序执行的好处在于，当代理程序执行失败时，大部分时间它不会给出错误的结果，它只是执行失败了。整个轨迹就中断了，代理程序也知道。那么这些情况下，人类就会介入解决。他们成为故障排除者。他们处理更具挑战性的问题。他们完成了更多的工作，而且他们对此感到非常激动。我认为第二点是我们发现的，作为一家公司的战略是始终作为一个增强型公司。我认为这是我们非常关心的一点。而且，实际上，如果你把自己定位为增强型公司，你始终会生活在一个世界中，你在解决的任务中有一些对当前模型而言稍微有些难度的任务，仍然需要人类提供监督，提供澄清，提供人类反馈。这就是你如何构建一个数据的正反馈环。这就是你如何从最聪明的人类那里学习，如何解决模型今天无法解决的事物。所以我实际上认为，成为一个增强型公司迫使你更快地发展核心 AI 能力，胜过那些说，“啊，我要为你提供 X 的无人化解决方案”的公司。

**Alessio** [00:18:42]: 是的。这很有趣，因为我们看到了市场的两个方面。一个是我们有一个为SOC分析师提供代理的公司。人们根本没有这些，你知道，他们无法吸引人才去做这些。类似地，在软件开发中，你有Copilot，这是增强产品，然后你有sweep.dev和这些产品，它们就是整套的解决方案。我真的很想看到这如何发展。我同意，今天在企业中可靠性非常重要，他们根本不使用大部分产品。是的，是的。不，这很酷。但听到这个故事真是太好了，因为我认为从外部看，人们会像，“哦，一个开发者，他们做Act One，他们做Persimon，他们做Fuyu，他们做所有这些东西。”是的，这只是公开的事情。

**Swyx** [00:19:20]: 就是公开的事情。

**David** [00:19:21]: 所以我们之前没有分享过的一件事是，我们在第一季度完全售罄了。所以我认为...

**Swyx** [00:19:26]: 售罄了什么？

**David** [00:19:27]: 带宽已售罄，无法再接纳更多客户。因此，我们正在努力减少这种瓶颈，但我们的期望是，我认为我们将更加公开地讨论今年晚些时候我们希望吸引的更多类型的客户以及更广泛的产品形态。所以我认为这种澄清将会自然发生。

**Swyx** [00:19:43]: 为什么你们要更公开？你知道，如果整个推动... 你们已售罄，你们是我的企业，但你们显然也在努力更开放或发布更多东西。

**David** [00:19:53]: 我认为我们最近确实转变了方向。这是一个很好的问题。实际上，我认为其中一个很大的原因是公众对代理的叙事正在形成。我对此感到非常高兴，因为当我们在2022年初创立公司时，领域内的每个人都知道RL中的代理问题，但普通公众对此一无所知。他们仍然把所有东西都归结为聊天机器人。因此，我现在非常关心的一件事情是，当人们想到代理时，他们确实能想到正确的东西。被称为代理的东西千差万别。聊天机器人被称为代理。执行函数调用的东西也被称为代理。对我来说，代理是一种你可以给予目标并正确执行最少步骤的工作流的东西。所以这是其中一个很大的原因。我认为另一个原因是因为我认为让人们在考虑他们职业生涯的下一步时更加了解Redept总是好的。在基础模型越来越普及的世界中，领域正在迅速转向。我认为从如何使用基础模型作为学习行为克隆者去解决代理问题中会产生巨大的收益。我认为那些想要进行代理研究的人真的应该来Redept。

**Swyx** [00:21:00]: 当你说代理已经成为公众叙事的一部分时，你指的是具体的事情吗？我可以举几个例子。比尔·盖茨在他的博客文章中提到代理是未来。我是那个做操作系统的人，我认为代理是下一个东西。所以比尔·盖茨，我要说一下。也许山姆·阿尔特曼也说代理是开放AI的未来。

**David** [00:21:17]: 我认为在那之前，纽约时报，Cade Metz写了一篇关于这个的纽约时报文章。现在，为了区分，我看到以前只是将自己打造成AI公司的AI初创公司，但现在将自己打造成AI代理公司。我觉得人们真的很想要这个术语。

**Swyx** [00:21:31]: 从VC的角度来看，情况有些复杂。是吗？就像，我认为很多VC会不会碰任何代理初创公司，因为... 为什么呢？好吧，你告诉我。

**Alessio** [00:21:41]: 我认为很多可能不那么技术化的风险投资人并不了解...

**Swyx** [00:21:46]: 不，那不公平。

**Alessio** [00:21:47]: 不，不，不，不。我想像- 你认为呢？不，不。我想想今天可能发生的事情，以及什么值得投资，你知道吗？我觉得，我是说，人们看着你会说，嗯，这些家伙正在建造代理。他们需要4亿来做到这一点。所以很多风险投资公司可能会说，哦，我宁愿投资于将AI应用于现有事物的东西，这样更容易进入市场，并且启动一些飞轮。但我也很惊讶，很多创业者只是不想做代理。这甚至不仅仅是资金问题。有时候我们看看周围，像，为什么没有人为X做代理呢？哇。

**David** [00:22:17]: 实际上知道这个真好。我以前从未知道过。从我的有限视角来看，我觉得每天都有一个新的代理公司冒出来。

**Swyx** [00:22:24]: 所以也许我是- 他们是。他们是。但是我建议人们从他们的头衔中去掉代理，因为这样太稀释了。

**David** [00:22:31]: 现在变得如此稀释了。

**Swyx** [00:22:32]: 是的。所以它并不代表任何东西。是的。

**David** [00:22:35]: 这真是一个很好的观点。

**Swyx** [00:22:36]: 所以，你知道的，你是一个投资组合配置者。人们知道Persimmon，知道Fuyu和Fuyu Heavy。你能详细说明一下你如何看待这一演变，以及人们应该如何考虑这对专家和研究方向意味着什么吗？请带领我们了解一下你最近推出的内容，以及人们应该如何思考你正在做的事情的发展轨迹。

**David** [00:22:56]: 专家们的关键路径是，我们希望构建的代理能够随着时间推移在更高层次的抽象上进行工作，同时保持极高的可靠性标准。因为这是将我们从研究转变为客户需求的关键所在。如果你构建的代理具有非常高的可靠性标准，同时不断推动抽象级别，那么你就能从用户那里学到如何更快地达到下一个抽象级别。所以这实际上就是构建数据流的方法。这是公司的关键路径。我们所做的一切都是为此服务的。所以如果你回顾Act One的早期，对吧？像Act One背后的核心理念是，我们是否可以教会大型模型如何操作你的计算机？我认为我们是第一个解决这个问题并展示它以及展示当你给它不同的工作流和文本时所获得的泛化能力的地方。但是我认为从那时开始，我们真正意识到的是，为了获得可靠性，公司们确实会以各种不同的方式行事。实际上，你希望这些模型能够在某种程度上变得更好，具有一些关于实际应该做什么的规范。而我认为与此同时，一个非常重要的因素是非常快速的多模态模型，它们非常擅长理解知识工作和理解屏幕。这些必须成为某些代理的基础。那时我们不得不进行大量研究，基本上是关于如何实现这一点？嗯，首先，就像回到忘记确切的一个月23号那时，实际上并没有真正可以用于这类事情的多模态模型。所以我们非常努力地推动Fuyu架构之类的东西。我认为多模态模型主要学术研究的一个大问题是，大多数多模态模型主要是在自然图像，猫和狗的照片之类的东西上训练的。Coco。对，对。而Coco很棒。我喜欢Coco。我喜欢TY。它确实帮助了这个领域。对，但是那是建立一种东西。我认为今天非常清楚的一点是，多模态模型是默认的基础模型，对吧？你只需训练一个巨大的多模态模型。但是为了达到这个目标，它们在哪里会最有用？它们在知识工作任务中将会非常有用。这是大部分经济价值所在。而不是在猫和狗身上。对。如果那就是问题的所在，你需要训练什么？我需要训练像图表、图形、表格、发票、PDF、收据、非结构化数据、用户界面之类的东西。这仅仅是一个完全不同的预训练语料库。所以Adept花了大量时间来构建这个。因此，用于公共使用和其他东西的模型并没有在我们的实际语料库上进行训练，而是在其他东西上进行训练。但是你可以使用大量这些数据，然后使其非常快速，并使其在屏幕上进行密集的OCR之类的事情时表现出色。然后现在你拥有了制作一个良好代理所需的正确“原料”。所以这在某种建模方面就像一些事情，我们只宣布了其中一些。我们还没有真正宣布太多有关代理的工作，但是如果你将这些与正确的产品形式因素结合起来，我认为产品形式因素也非常重要。我认为我们正在看到，你们可能比我更多地看到这一点，但我们正在看到一些反抗作为形式因素的聊天机器人暴政。我认为形式因素之所以重要是因为它改变了你在人类反馈环路中收集的数据。因此，我们花了很多时间对所有这些要素进行全垂直整合，以便达到我们现在所处的位置。

**Swyx** [00:25:44]: Yeah. I'll plug Amelia Wattenberger’s talk at our conference, where she gave a little bit of the thinking behind like what else exists other than chatbots that if you could delegate to reliable agents, you could do. I was kind of excited at Adept experiments or Adept workflows, I don't know what the official name for it is. I was like, okay, like this is something I can use, but it seems like it's just an experiment for now. It's not your product.

**David** [00:26:06]: So you basically just use experiments as like a way to go push various ideas on the design side to some people and just be like, yeah, we'll play with it. Actually the experiments code base underpins the actual product, but it's just the code base itself is kind of like a skeleton for us to go deploy arbitrary cards on the side.

**Swyx** [00:26:22]: Yeah.

**Alessio** [00:26:23]: Makes sense. I was going to say, I would love to talk about the interaction layer. So you train a model to see UI, but then there's the question of how do you actually act on the UI? I think there was some rumors about open app building agents that are kind of like, they manage the end point. So the whole computer, you're more at the browser level. I read in one of your papers, you have like a different representation, kind of like you don't just take the dome and act on it. You do a lot more stuff. How do you think about the best way the models will interact with the software and like how the development of products is going to change with that in mind as more and more of the work is done by agents instead of people?

**大卫** [00:26:58]: 这里的表面积很大，这实际上是我非常兴奋的事情之一。有趣的是，我大部分时间都在做研究，但我发现有一个全新的游戏规则，我觉得非常酷。所以我想说，我对为什么 Adept 正在追求能够像人一样使用您的计算机的路径有一个最好的类比，当然还能够调用 API 并且调用 API 是简单的部分，像人一样使用您的计算机是一个困难的部分。这就像人们为何对人形机器人感到兴奋一样，对吧？在 T 等于无穷大的世界里，你可能会有各种不同的机器人形态，就像所有的专业化一样。但事实上人类生活在人类环境中。所以拥有人类机器人可以让您做人类能做的事情，而不必一路改变。对于软件也是如此，对吧？如果你一项一项列出你想在计算机上做的事情，每一步都有一个 API，这些工作流的数量几乎等于零。因此，在许多时候，您需要能够像实际控制您的计算机一样进行操作。它还让您能够从人类使用计算机的方式中学习作为训练数据，这是您如果不必想办法弄清每个特定步骤需要某种特定的自定义私有 API 事物所无法获得的。因此，我认为这实际上是最实际的路径。我认为因为这是最实际的路径，我认为很多成功将从这条道路上获得。我有点像这个代理交互层级的早期阶段，有点像，你们还记得 Windows 3.1 吗？就像那些日子一样？好的，这可能对你们来说太老了。但是在那个时代，Windows 3.1，我们经历了从纯命令行作为默认进入这个新世界的过渡，其中 GUI 是默认的，然后你为程序员的事情进入命令行。旧的方式是你启动你的计算机，DOS 引导，然后它会给你 C:\/ 的东西。你输入 Windows 然后按回车，然后你就进入 Windows。然后 GUI 在命令行之上成为了一种层。同样的事情将会发生在代理界面上，就像今天我们会有 GUI 作为基础层。然后代理只控制当前 GUI 层加上 API。在将来，随着对代理的信任越来越多，并且更多事情可以由代理完成，如果代理的更多 UI 实际上是自动生成的，那么它只会成为标准交互层。如果那成为标准交互层，对于软件来说，很多软件将会是系统或记录或特定定制工作流执行引擎。而实际上如何做事情的很多方式都将在代理层控制。

**Alessio** [00:29:19]: 你认为兔子界面更像你不是真的看到模型与之交互的应用程序。你只是说，嘿，我需要在Salesforce上记录这个通话。你实际上从不直接作为用户登录salesforce.com。我觉得这可能是一个模型。

**David** [00:29:33]: 我认为我不了解在现实生活中使用兔子会是什么样子，所以我不能对这个特别的事情发表评论。但我认为更广泛的想法是，你有一个目标，对吧？代理知道如何将你的目标分解为步骤。代理知道如何使用底层的软件和系统或记录来为你实现这个目标。也许代理会以对你特定目标有意义的定制方式向你呈现信息，这一切都导致一个世界，在这个世界里，除非你是某个小众事物的权力用户，否则你根本不需要与应用程序进行接口。

**Swyx** [00:30:03]: 一般性问题。首先，我觉得输入模式的对话方式很像。我想知道你是否有喜欢的与自动驾驶相关的类比，因为我认为模型应该如何感知世界这个问题有点类似。你知道，在自动驾驶中，主要的分歧是激光雷达和摄像头。我觉得我正在追踪的大多数代理公司都在向摄像头方法靠拢，这就像是多模态方法，你知道，多模态视觉，非常重视视觉，包括你正在做的所有Fuyu的事情，你正在专注于包括图表和表格在内的这些内容。你是不是从自动驾驶世界中获得灵感的？这是一个很好的问题。

**David** [00:30:37]: 我认为有时从自动驾驶中获得的最有用的灵感是层次类比。我觉得那个很棒。但我们的首要目标是让代理人不像自动驾驶。我们希望最大程度地减少代理人必须长时间头疼才能达到两个不连续里程碑的机会，这基本上就是自动驾驶发生的事情。我们希望生活在一个你拥有数据飞轮的世界，并且这能带你一路走到顶端。但同样地，与自动驾驶相比，有两件人们真正低估的事情是，驾驶一辆车在101号公路上的一个晴天演示真的很容易。实际上这并不再证明任何事情。我认为第二件事是，作为一个非自动驾驶专家，我认为我们非常强烈地认为每个人都低估了非常好的传感器和执行器的重要性。实际上，帮助我们获得很多可靠性的事情之一是真正专注于为什么模型不能做这件事。而模型实际上不能做这件事的时间不是因为你自己在模仿奥兹，或者你有不可靠的执行器，你就不能做这件事。所以我们不得不解决很多这些问题。

**Swyx** [00:31:43]: 我有点惊讶，因为我通常认为我们在旧金山周围看到的大多数情况是我们在很多实质方面拥有的代理人。

**David** [00:31:55]: 哦，这绝对是真的。我认为他们做得非常棒，但是自动驾驶要从它进入人们意识到现在成熟，确实花了很长时间。所以我希望看到这个过程更加压缩。

**Swyx** [00:32:07]: 我的意思是，你知道，Cruise，你知道，RIP。还有一件事，关于可靠性的事情，我一直在心中抱着，我很好奇听听你的评论，我认为在可靠性和普适性之间存在一种权衡，或者我想把可靠性扩展到一般的生产准备和企业准备的规模上。因为你有可靠性，你还有成本，你有速度，速度对于债务是一个巨大的强调。减少普适性以提高可靠性、成本和速度是一种倾向或诱惑。你认为存在权衡吗？你有没有解决这些权衡的见解？

**David** [00:32:42]: 明显存在一种权衡。如果你处于帕累托前沿，我认为很多人实际上并不在帕累托前沿。我认为你达到那里的方式基本上是如何框架基本的代理问题，以一种只需继续从数据中获益的方式。我认为解决这种特定权衡的主要方法之一是，你基本上希望制定问题，以便每个特定的用例看起来都像是你收集更多数据以使该用例成为可能。我认为这才是你真正解决问题的方式。然后你会陷入其他问题，比如，你在这些最终用例上是否过度拟合？例如，你没有在模型只能执行的最终步骤上采取超级具体的行动。

**Swyx** [00:33:17]: 那么问题来了，你是否有一个房屋模型，然后可以为每个客户定制，并在每个客户的特定用例上进行微调？

**David** [00:33:25]: 是的。

**Swyx** [00:33:26]: 我们不分享那个。你不分享那个。这很诱人，但那对我来说并不像AGI。你知道我说的是什么吧？那只是你有一个很好的基础模型，然后你对它进行微调。

**David** [00:33:35]: 就我所知，我认为我们这些天都在训练的模型能力更强有两条路。我认为一条路是你想出如何花费、计算并将其转化为数据。在这条路上，我认为搜索、强化学习，以及我们这个时代所热爱的所有事物都是这条路的一部分，比如自我对弈等等。第二条路是如何从人类那里获得超级能干、高智能的演示。我认为前进的正确方式是你想要将这两者结合起来。第一个路径为你提供了最大的样本效率，但我认为如果不同时解决两者，要全速朝着AGI前进将会很难。

**Swyx** [00:34:16]: 据我所知，你并没有多谈合成数据，可能现在这个趋势有点过了，但你对使用合成数据增强昂贵的人类数据有何见解？

**David** [00:34:26]: 将AGI框架为能够帮助人们在计算机上做事的最佳部分是你拥有一个环境。

**Swyx** [00:34:31]: 是的。所以你可以模拟其中的所有内容。

**David** [00:34:35]: 有了环境，你可以做很多事情。

**Alessio** [00:34:37]: 我们为我们的一周年晚餐。祝贺。是的。谢谢。 HumanLoop的Raza也在那里，我们提到你要出现在节目中。这是我们的第一个-

**Swyx** [00:34:45]: 他提交了一个问题。

**Alessio** [00:34:46]: 是的，这是我们的第一个邮件袋问题。他问，当你开始 GPD 4 Data and Exist 时，现在你有了 GPD 4 vision 并帮助你建立了很多这些东西。你如何看待作为 Adept 独特的事物，以及关于你希望团队采取的研究方向，以及你希望人们来 Adept 工作的内容，与可能已经成为大家都能访问的商品化的东西相比？

**David** [00:35:11]: 是的，这是一个非常好的问题。我认为这个问题中隐含的是，整体机器学习堆栈中的优势计算。也许这个问题的假设的一部分是优势仅仅归于基础模型的扩展。但我其实相当坚信，你真正取胜的方式是你必须去构建一个代理堆栈，远不止于基础模型本身。所以我认为，这始终将是垂直整合的一个巨大优势。我认为，这让我们能够做一些事情，比如拥有一个真正非常快速的基础模型，非常擅长代理事务，但在猫和狗照片方面表现不佳。它在猫和狗照片方面表现相当不错。它并不像苏打在猫和狗照片上那样，对吧？所以我们明智地分配了我们的能力，对吧？这确实是你真正能做到的一件事情。我也认为，在更广泛的基础建模领域中，另一件非常重要的事情是，尽管对代理作为一个创业领域有任何潜在的担忧，正如我们之前讨论过的，我确实觉得我们正在为代理构建基础模型，而 Adept 所有的回报都来自于我们是否能够做一个更好的代理。因为我现在认为我们都看到了，你知道，如果你在公开可用的网络数据上进行训练，你输入了 FLOPS，并且做了合理的事情，那么你会得到不错的结果。如果你只是增加了计算量的两倍，那么你会得到可预测的更好的结果。因此，我认为纯粹的基础模型公司只会受到接下来几只羊驼和下一个好的开源工具有多好的挤压。然后看到真正大的玩家在仅仅训练这些基础基础模型时投入了可笑的计算量，我认为这将使许多常规 LLMs 和很快的常规多模型模型商品化。所以我感到非常高兴，我们只专注于代理。

**Swyx** [00:36:56]: 所以你不认为自己是一家纯粹的基础模型公司？

**David** [00:36:59]: 不，因为如果我们是一家纯粹的基础模型公司，我们会训练一般的基础模型，可以进行摘要和所有其他的...

**Swyx** [00:37:06]: 你致力于代理。是的。

**David** [00:37:09]: 而我们的业务是代理业务。我们不是来卖给你们代币的，对吧？我觉得像卖代币，除非有像……

**Swyx** [00:37:14]: 我不是来卖给你们代币的。我喜欢它。

**David** [00:37:16]: 如果你有特定的专业领域，对吧？那么你就不会陷入每个人都在扩展到荒谬计算水平的事实中。但如果你没有专业领域，我觉得会有点难。

**Swyx** [00:37:27]: 有趣。你对机器人技术有兴趣吗？只是一个……

**David** [00:37:30]: 我个人对机器人技术很着迷。我一直喜欢机器人。

**Swyx** [00:37:33]: 身体化代理作为一项业务，你知道，Figure 就像一个大公司，也算是一个开放AI的附属公司，筹集了大量资金。

**David** [00:37:39]: 我觉得很酷。我觉得，我是说，我不知道他们具体在做什么，但是……

**Swyx** [00:37:44]: 机器人。是的。

**David** [00:37:46]: 嗯，我的意思是，那是一个……

**Swyx** [00:37:47]: 是的。如果我们邀请他们上来，你会问什么问题？你会问他们什么？

**David** [00:37:50]: 哦，我只是想了解从现在到可靠部署时他们的整体策略是什么。但老实说，我对此了解不多。

**Swyx** [00:37:57]: 如果我告诉你，嘿，解雇你们整个仓库的员工，你知道，用机器人代替，这算不算一种策略？哦，是的。

**David** [00:38:04]: 是的。抱歉。我不是在质疑他们是否在做聪明的事情。我真的不太清楚他们在做什么，但我认为有两件事。一，我非常期待有人训练一个基础模型的机器人。我觉得这会奏效。就像我会坚守这个立场，但我是说，整个时间，就像我们在这个播客上一直在说的那样，这些模型基本上是行为克隆者。对吧。所以让我们行为克隆所有这些机器人的行为。对吧。然后你们就找出其他一切你们必须做的事情，以教会它如何解决一个新问题。那会奏效的。我对此感到非常激动。我认为与我们帮助人类进行知识工作不同，这听起来更像是一场更零和的工作替代游戏。对吧。我个人对此不太感兴趣。

**Alessio** [00:38:46]: 我们在播客中邀请了来自InBoo的Ken June。我们问她为什么人们应该去那里工作而不是在Adept工作。

**Swyx** [00:38:52]: 哦，这太有趣了。

**Alessio** [00:38:54]: 她说，你知道，在这个市场上每个人都有自己的空间。我们都在做有趣的工作。她说，他们真的很兴奋地在为代理构建操作系统。对她来说，最大的研究问题是为这些代理获取更好的推理和规划模型。对你的反问是，你知道，为什么人们应该兴奋地来到Adept而不是InBoo？也许人们应该对什么核心研究问题充满激情才能在Adept有乐趣？是的。

**David** [00:39:22]: 首先，我认为你们也相信这一点。在AI领域，如果存在AI代理的空间，它们确实如她可能所说，我认为这是巨大的机遇，人们最终会在不同的领域取得成功，很多公司会做得很好。所以我真的一点都不觉得是零和的。我想说改变零和的框架是为什么你应该在Adept呢？我认为有两个重要的理由可以在Adept工作。我认为其中一个是我们做的一切都是为了有用的代理服务。我们不是一个研究实验室。我们为实现这个目标做了大量的研究，但我们根本不把自己看作是一个经典的研究实验室。我认为我在Adept工作的第二个原因是，如果你相信实际拥有客户和来自客户的奖励信号能让你更快地建立一个GI，我们真的相信，那么你应该来这里。我认为为什么这是真的的例子是，例如，我们的评估，它们不是学术评估。它们也不是模拟器评估。它们就像，好吧，我们有一个客户真的需要我们做这些特定的事情。我们可以做其中的一些。这些是他们想要我们做的事情，我们根本不能做。我们已经把它们变成了评估，解决了，对吧？我觉得这真的很酷。就像大家都知道，很多这些评估都相当饱和，即使是新的，甚至不饱和的，你看着某人，你会想，这真的有用吗？对吧？我认为这是一种实用性的程度，真的很有帮助。像我们对推理、规划和泛化等所有这些问题的兴奋程度是一样的。它们都非常扎根于当前的实际需求中，这真的很酷。

**Swyx** [00:40:45]: 是的。这是一个很棒的深入探讨。你知道，我希望我们有更多的时间，但我想我会留给你一些广泛的思考，关于代理空间，但也关于AI空间的一些事情。任何，任何你现在心中的牢骚或想法？

**David** [00:40:57]: 有什么牢骚吗？

**Swyx** [00:40:59]: 从你身上挖掘一般性的...

**David** [00:41:01]: 哇。好的。所以阿梅利亚已经比我更好地发表了愤怒的言论，但不仅仅是聊天机器人，这有点像是愤怒的一种。而且AI真的是计算和计算加上数据的故事，以及你可以把一个换成另一个的方式。我认为虽然我们的研究社区非常聪明，我们已经取得了许多进展，这将继续是重要的。但是现在我认为游戏正在日益改变，快速工业化时代已经开始了。不幸的是，我认为我们不得不接受它。

**Swyx** [00:41:30]: 是的。

**Alessio** [00:41:31]: 太棒了。非常感谢你的时间，David。

**David** [00:41:34]: 很酷。谢谢大家。
