- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:35:32'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: Nvidia bans using translation layers for CUDA software — previously the prohibition
    was only listed in the online EULA, now included in installed files [Updated]
    | Tom's Hardware
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://www.tomshardware.com/pc-components/gpus/nvidia-bans-using-translation-layers-for-cuda-software-to-run-on-other-chips-new-restriction-apparently-targets-zluda-and-some-chinese-gpu-makers](https://www.tomshardware.com/pc-components/gpus/nvidia-bans-using-translation-layers-for-cuda-software-to-run-on-other-chips-new-restriction-apparently-targets-zluda-and-some-chinese-gpu-makers)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Edit 3/4/24 11:30am PT: Clarified article to reflect that this clause is available
    on the online listing of Nvidia''s EULA, but has not been in the EULA text file
    included in the downloaded software. The warning text was added to 11.6 and newer
    versions of the installed CUDA documentation.]'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: Nvidia has banned running CUDA-based software on other hardware platforms using
    translation layers in its [licensing terms listed online](https://docs.nvidia.com/cuda/eula/index.html)
    since 2021, but the warning previously wasn't included in the documentation placed
    on a host system during the installation process. This language has been added
    to the EULA that's included when installing CUDA 11.6 and newer versions.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: The restriction appears to be designed to prevent initiatives like [ZLUDA](https://www.tomshardware.com/news/zluda-project-cuda-intel-gpus),
    which both Intel and AMD have recently participated, and, perhaps more critically,
    some Chinese GPU makers from utilizing CUDA code with translation layers. We've
    pinged Nvidia for comment and will update you with additional details or clarifications
    when we get a response.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: '[Longhorn](https://twitter.com/never_released/status/1758946808183525702),
    a software engineer, noticed the terms. "You may not reverse engineer, decompile
    or disassemble any portion of the output generated using SDK elements for the
    purpose of translating such output artifacts to target a non-NVIDIA platform.,"
    a clause in the installed EULA text file reads.'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
- en: The clause was absent in the EULA documentation that's installed with the CUDA
    11.4 and 11.5 release, and presumably with all versions before that. However,
    it is present in the installed documentation with version 11.6 and newer.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
- en: 'Being a leader has a good side and a bad side. On the one hand, everyone depends
    on you; on the other hand, everyone wants to stand on your shoulders. The latter
    is apparently what has happened with CUDA. Because the combination of CUDA and
    Nvidia hardware has proven to be incredibly efficient, tons of programs rely on
    it. However, as more competitive hardware enters the market, more users are inclined
    to run their CUDA programs on competing platforms. There are two ways to do it:
    recompile the code (available to developers of the respective programs) or use
    a translation layer.'
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
- en: For obvious reasons, using a translation layer like [ZLUDA](https://www.tomshardware.com/news/zluda-project-cuda-intel-gpus)
    is the easiest way to run a CUDA program on non-Nvidia hardware. All one has to
    do is take already-compiled binaries and run them using ZLUDA or other translation
    layers. ZLUDA appears to be floundering now, with both [AMD and Intel having passed
    on the opportunity to develop it further](https://www.tomshardware.com/pc-components/gpus/software-allows-cuda-code-to-run-on-amd-and-intel-gpus-without-changes-zluda-is-back-but-both-companies-ditched-it-nixing-future-updates),
    but that doesn't mean translation isn't viable.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 出于显而易见的原因，像[ZLUDA](https://www.tomshardware.com/news/zluda-project-cuda-intel-gpus)这样的翻译层是在非英伟达硬件上运行CUDA程序的最简单方式。只需使用已编译的二进制文件，并通过ZLUDA或其他翻译层来运行它们。尽管[ZLUDA目前似乎陷入困境](https://www.tomshardware.com/pc-components/gpus/software-allows-cuda-code-to-run-on-amd-and-intel-gpus-without-changes-zluda-is-back-but-both-companies-ditched-it-nixing-future-updates)，AMD和Intel都放弃了进一步开发它的机会，但这并不意味着翻译不可行。
- en: Several Chinese GPU makers, [including one funded by the Chinese government,](https://www.tomshardware.com/news/chinese-gpu-developer-gets-government-funds)
    claim to run CUDA code. Denglin Technology designs processors featuring a "computing
    architecture compatible with programming models like CUDA/OpenCL." Given that
    reverse engineering of an Nvidia GPU is hard (unless one already somehow has all
    the low-level details about Nvidia GPU architectures), we are probably dealing
    with some sort of translation layer here, too.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 几家中国GPU制造商，[包括一家获得中国政府资助的公司](https://www.tomshardware.com/news/chinese-gpu-developer-gets-government-funds)，声称能运行CUDA代码。登林科技设计的处理器采用了“与CUDA/OpenCL等编程模型兼容的计算架构”。鉴于逆向工程英伟达GPU很困难（除非某种方式已经掌握了所有关于英伟达GPU架构的低级细节），我们可能在这里也在处理某种形式的翻译层。
- en: One of the largest Chinese GPU makers, Moore Threads, also has a [MUSIFY translation
    tool designed to allow CUDA code to work with its GPUs](https://www.tomshardware.com/pc-components/gpus/nvidias-biggest-chinese-competitor-unveils-cutting-edge-new-ai-gpus-moore-threads-s4000-ai-gpu-and-intelligent-computing-center-server-clusters-using-1000-of-the-new-ai-gpus).
    However, whether or not MUSIFY falls under the classification of a complete translation
    layer remains to be seen (some of the aspects of MUSIFY could involve porting
    code). As such, it isn't entirely clear if the Nvidia ban on translation layers
    is a direct response to these initiatives or a pre-emptive strike against future
    developments.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 中国最大的GPU制造商之一，摩尔线程，也拥有一款[MUSIFY翻译工具](https://www.tomshardware.com/pc-components/gpus/nvidias-biggest-chinese-competitor-unveils-cutting-edge-new-ai-gpus-moore-threads-s4000-ai-gpu-and-intelligent-computing-center-server-clusters-using-1000-of-the-new-ai-gpus)，旨在使CUDA代码能够在其GPU上运行。然而，MUSIFY是否属于完整的翻译层尚不清楚（MUSIFY的某些方面可能涉及代码移植）。因此，目前尚不完全清楚英伟达对翻译层的禁令是对这些倡议的直接回应，还是对未来发展的预防性打击。
- en: For obvious reasons, using translation layers threatens Nvidia's hegemony in
    the accelerated computing space, particularly with AI applications. This is probably
    the impetus behind Nvidia's decision to ban running their CUDA applications on
    other hardware platforms using translation layers.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 出于显而易见的原因，使用翻译层威胁到了英伟达在加速计算领域的霸主地位，尤其是在人工智能应用方面。这可能是英伟达决定禁止在其他硬件平台上使用翻译层运行其CUDA应用程序的动因。
- en: Recompiling existing CUDA programs remains perfectly legal. To simplify this,
    both AMD and Intel have tools to port CUDA programs to their [ROCm](https://www.amd.com/system/files/documents/porting-cuda-to-hip.pdf) ([1](https://github.com/ROCm/HIPIFY))
    and [OpenAPI](https://www.intel.com/content/www/us/en/developer/articles/technical/migrate-cuda-applications-to-oneapi-based-on-sycl.html)
    platforms, respectively.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 重新编译现有的CUDA程序是完全合法的。为了简化这一过程，AMD和Intel都提供了工具，可以将CUDA程序移植到它们各自的[ROCm](https://www.amd.com/system/files/documents/porting-cuda-to-hip.pdf)（[1](https://github.com/ROCm/HIPIFY)）和[OpenAPI](https://www.intel.com/content/www/us/en/developer/articles/technical/migrate-cuda-applications-to-oneapi-based-on-sycl.html)平台。
- en: As AMD, Intel, Tenstorrent, and other companies develop better hardware, more
    software developers will be inclined to design for these platforms, and Nvidia's
    CUDA dominance could ease over time. Furthermore, programs specifically developed
    and compiled for particular processors will inevitably work better than software
    run via translation layers, which means better competitive positioning for AMD,
    Intel, Tenstorrent, and others against Nvidia — if they can get software developers
    on board. GPGPU remains an important and highly competitive arena, and we'll be
    keeping an eye on how the situation progresses in the future.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 随着AMD、Intel、Tenstorrent和其他公司开发出更好的硬件，更多软件开发者将倾向于为这些平台设计软件，而Nvidia的CUDA主导地位可能随着时间的推移而减弱。此外，专门为特定处理器开发和编译的程序无疑会比通过翻译层运行的软件表现更好，这意味着AMD、Intel、Tenstorrent等公司在与Nvidia的竞争中能够取得更好的竞争地位——只要他们能够吸引软件开发者的支持。通用GPU计算仍然是一个重要且竞争激烈的领域，我们将继续关注未来情况的发展。
- en: Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 获取[Tom's Hardware](https://www.tomshardware.com)的最新消息和深度评测，直接发送到您的收件箱。
