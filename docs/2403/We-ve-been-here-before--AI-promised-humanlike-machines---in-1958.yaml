- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-29 12:45:22'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-29 12:45:22'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'We’ve been here before: AI promised humanlike machines – in 1958'
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们曾经在这里：1958年AI承诺制造人类化机器
- en: 来源：[https://theconversation.com/weve-been-here-before-ai-promised-humanlike-machines-in-1958-222700](https://theconversation.com/weve-been-here-before-ai-promised-humanlike-machines-in-1958-222700)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://theconversation.com/weve-been-here-before-ai-promised-humanlike-machines-in-1958-222700](https://theconversation.com/weve-been-here-before-ai-promised-humanlike-machines-in-1958-222700)
- en: A roomsize computer equipped with a new type of circuitry, the Perceptron, was
    introduced to the world in 1958 in a [brief news story](https://www.nytimes.com/1958/07/08/archives/new-navy-device-learns-by-doing-psychologist-shows-embryo-of.html)
    buried deep in The New York Times. The story cited the U.S. Navy as saying that
    the Perceptron would lead to machines that “will be able to walk, talk, see, write,
    reproduce itself and be conscious of its existence.”
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 1958年，一台配备新型电路的房间大小计算机——感知器，通过《纽约时报》深埋的[简短新闻报道](https://www.nytimes.com/1958/07/08/archives/new-navy-device-learns-by-doing-psychologist-shows-embryo-of.html)首次亮相。报道援引美国海军的话说，感知器将导致“能够行走、交谈、看见、写作、复制自己并意识到自己存在”的机器。
- en: More than six decades later, similar claims are being made about current artificial
    intelligence. So, what’s changed in the intervening years? In some ways, not much.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 六十多年后，关于当前人工智能的类似说法如潮水般涌现。那么，在这期间发生了什么变化？在某些方面，并没有太多改变。
- en: The field of artificial intelligence has been running through a boom-and-bust
    cycle since its early days. Now, as the field is in yet another boom, many proponents
    of the technology seem to have forgotten the failures of the past – and the reasons
    for them. While optimism drives progress, it’s worth paying attention to the history.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能领域自早期以来一直经历着兴衰循环。如今，随着该领域再次迎来高潮，许多技术的支持者似乎已经忘记了过去的失败——以及造成这些失败的原因。虽然乐观主义推动着进步，但值得注意的是其历史。
- en: The Perceptron, [invented by Frank Rosenblatt](https://psycnet.apa.org/doi/10.1037/h0042519),
    arguably laid the [foundations for AI](https://news.cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-years-too-soon).
    The electronic analog computer was a learning machine designed to predict whether
    an image belonged in one of two categories. This revolutionary machine was filled
    with wires that physically connected different components together. Modern day
    artificial neural networks that underpin familiar AI like ChatGPT and DALL-E are
    software versions of the Perceptron, except with substantially more layers, nodes
    and connections.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器由[弗兰克·罗森布拉特发明](https://psycnet.apa.org/doi/10.1037/h0042519)，可以说奠定了[人工智能的基础](https://news.cornell.edu/stories/2019/09/professors-perceptron-paved-way-ai-60-years-too-soon)。这台电子模拟计算机是一台学习机器，旨在预测图像是否属于两个类别之一。这台革命性的机器充满了将不同组件物理连接在一起的电线。现代人工神经网络，如ChatGPT和DALL-E，是感知器的软件版本，只不过层数、节点和连接远远超过它。
- en: Much like modern-day machine learning, if the Perceptron returned the wrong
    answer, it would alter its connections so that it could make a better prediction
    of what comes next the next time around. Familiar modern AI systems work in much
    the same way. Using a prediction-based format, large language models, or LLMs,
    are able to produce impressive [long-form text-based responses](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)
    and associate images with text to produce [new images based on prompts](https://www.assemblyai.com/blog/how-dall-e-2-actually-works/).
    These systems get better and better as they interact more with users.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 像现代机器学习一样，如果感知器返回了错误答案，它会改变其连接，以便在下次预测时做出更好的预测。熟悉的现代AI系统工作方式大致相同。使用基于预测的格式，大型语言模型（LLMs）能够生成令人印象深刻的[基于长文本的响应](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)，并将图像与文本关联以生成[基于提示的新图像](https://www.assemblyai.com/blog/how-dall-e-2-actually-works/)。这些系统与用户的互动越多，性能就越好。
- en: A timeline of the history of AI starting in the 1940s. Click the author’s name
    here for a PDF of this poster. [Danielle J. Williams](https://www.daniellejwilliams.com/_files/ugd/a6ff55_cac7c8efb9404a208c0ecd284ff11ba7.pdf),
    [CC BY-ND](http://creativecommons.org/licenses/by-nd/4.0/)
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: AI历史时间轴始于1940年代。点击这里查看作者[丹妮尔·J·威廉姆斯](https://www.daniellejwilliams.com/_files/ugd/a6ff55_cac7c8efb9404a208c0ecd284ff11ba7.pdf)的海报PDF。[知识共享许可证CC
    BY-ND](http://creativecommons.org/licenses/by-nd/4.0/)
- en: AI boom and bust
  id: totrans-split-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI的兴衰
- en: In the decade or so after Rosenblatt unveiled the Mark I Perceptron, experts
    like [Marvin Minsky](https://www.nytimes.com/2016/01/26/business/marvin-minsky-pioneer-in-artificial-intelligence-dies-at-88.html)
    claimed that the world would “[have a machine with the general intelligence of
    an average human being](https://books.google.com/books?id=2FMEAAAAMBAJ&pg=PA58&dq=In+from+three+to+eight+years+we+will+have+a+machine+with+the+general+intelligence+of+an+average+human+being#v=onepage&q=In%20from%20three%20to%20eight%20years%20we%20will%20have%20a%20machine%20with%20the%20general%20intelligence%20of%20an%20average%20human%20being&f=false)”
    by the mid- to late-1970s. But despite some success, humanlike intelligence was
    nowhere to be found.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在罗森布拉特揭示Mark I感知器约十年后，像[马文·明斯基](https://www.nytimes.com/2016/01/26/business/marvin-minsky-pioneer-in-artificial-intelligence-dies-at-88.html)等专家声称世界将在中到后1970年代“[拥有与普通人类平均智力相当的机器](https://books.google.com/books?id=2FMEAAAAMBAJ&pg=PA58&dq=In+from+three+to+eight+years+we+will+have+a+machine+with+the+general+intelligence+of+an+average+human+being#v=onepage&q=In%20from%20three%20to%20eight%20years%20we%20will%20have%20a%20machine%20with%20the%20general%20intelligence%20of%20an%20average%20human%20being&f=false)”。尽管有些成功，但类似人类的智能却无迹可寻。
- en: It quickly became apparent that the [AI systems knew nothing about their subject
    matter](https://stacks.stanford.edu/file/druid:cn981xh0967/cn981xh0967.pdf). Without
    the appropriate background and contextual knowledge, it’s nearly impossible to
    accurately resolve ambiguities present in everyday language – a task humans perform
    effortlessly. The first AI “winter,” or period of disillusionment, hit in 1974
    following the [perceived failure of the Perceptron](https://dougenterprises.com/perceptron-history/).
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 很快就显而易见，[AI系统对其主题一无所知](https://stacks.stanford.edu/file/druid:cn981xh0967/cn981xh0967.pdf)。没有适当的背景和上下文知识，几乎不可能准确地解决日常语言中存在的歧义问题，这是人类轻而易举地完成的任务。第一个AI“冬天”，或者幻灭期，在1974年首次AI“冬天”后出现，这是由于[感知的感知器失败](https://dougenterprises.com/perceptron-history/)。
- en: However, by 1980, AI was back in business, and the first official AI boom was
    in full swing. There were new [expert systems](https://www.britannica.com/technology/expert-system),
    AIs designed to solve problems in specific areas of knowledge, that could identify
    objects and [diagnose diseases from observable data](https://www.britannica.com/technology/MYCIN).
    There were programs that could make [complex inferences from simple stories](https://eric.ed.gov/?id=ED161024),
    the [first driverless car](https://web.stanford.edu/%7Elearnest/sail/oldcart.html)
    was ready to hit the road, and [robots that could read and play music](https://robotsguide.com/robots/wabot)
    were playing for live audiences.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 但到了1980年，AI再次回到了正轨，并且第一次正式的AI繁荣期全面展开。出现了新的[专家系统](https://www.britannica.com/technology/expert-system)，这些AI系统设计用来解决特定领域的问题，能够识别物体并从可观察数据中[诊断疾病](https://www.britannica.com/technology/MYCIN)。还有一些程序能够从简单的故事中进行[复杂推理](https://eric.ed.gov/?id=ED161024)，[第一辆无人驾驶汽车](https://web.stanford.edu/%7Elearnest/sail/oldcart.html)也准备上路，而[能够阅读和演奏音乐的机器人](https://robotsguide.com/robots/wabot)正在现场观众面前演奏。
- en: But it wasn’t long before the same problems stifled excitement once again. In
    1987, the second AI winter hit. Expert systems were failing because [they couldn’t
    handle novel information](https://towardsdatascience.com/history-of-the-second-ai-winter-406f18789d45).
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 但不久之后，同样的问题再次扼杀了激情。1987年，第二次AI冬天来袭。专家系统失败了，因为[它们无法处理新颖信息](https://towardsdatascience.com/history-of-the-second-ai-winter-406f18789d45)。
- en: The 1990s changed the way experts approached problems in AI. Although the eventual
    thaw of the second winter didn’t lead to an official boom, AI underwent substantial
    changes. Researchers were tackling the [problem of knowledge acquisition](https://doi.org/10.1145/97709.97728)
    with [data-driven approaches](https://www.lightsondata.com/the-history-of-machine-learning/#:%7E:text=In%20the%201990s%20work%20on,learn%E2%80%9D%20%E2%80%94%20from%20the%20results.)
    to machine learning that changed how AI acquired knowledge.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 1990年代改变了专家在AI问题上的处理方式。虽然第二次冬天的最终融化并没有引发官方繁荣期，但AI经历了重大变革。研究人员正在通过[数据驱动方法](https://www.lightsondata.com/the-history-of-machine-learning/#:%7E:text=In%20the%201990s%20work%20on,learn%E2%80%9D%20%E2%80%94%20from%20the%20results.)解决[知识获取问题](https://doi.org/10.1145/97709.97728)，这改变了AI获取知识的方式。
- en: This time also marked a return to the neural-network-style perceptron, but this
    version was far more complex, dynamic and, most importantly, digital. The return
    to the neural network, along with the invention of the web browser and an increase
    in computing power, [made it easier to collect images, mine for data and distribute
    datasets for machine learning tasks](https://www.analyticsvidhya.com/blog/2020/09/quick-history-neural-networks/).
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这一次也标志着神经网络样式感知机的回归，但这个版本更复杂、动态，并且最重要的是，数字化。回归神经网络，加上Web浏览器的发明和计算能力的增加，[使得收集图像、数据挖掘和分发机器学习任务数据集变得更加容易](https://www.analyticsvidhya.com/blog/2020/09/quick-history-neural-networks/)。
- en: Familiar refrains
  id: totrans-split-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 熟悉的叠句
- en: Fast forward to today and confidence in AI progress has begun once again to
    echo promises made nearly 60 years ago. The term “[artificial general intelligence](https://www.ibm.com/topics/strong-ai)”
    is used to describe the activities of LLMs like those powering AI chatbots like
    ChatGPT. Artificial general intelligence, or AGI, describes a machine that has
    intelligence equal to humans, meaning the machine would be self-aware, able to
    solve problems, learn, plan for the future and possibly be conscious.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 快进到今天，对人工智能进展的信心再次开始回应将近60年前的承诺。术语“[人工通用智能](https://www.ibm.com/topics/strong-ai)”用来描述像支持AI聊天机器人ChatGPT这样的LLM的活动。人工通用智能或AGI描述了一种与人类智能相等的机器，意味着该机器将具有自我意识、能够解决问题、学习、为未来制定计划，可能还具备意识。
- en: Just as Rosenblatt thought his Perceptron was a foundation for a conscious,
    humanlike machine, so do some contemporary AI theorists about today’s artificial
    neural networks. In 2023, Microsoft published a paper saying that “[GPT-4’s performance
    is strikingly close to human-level performance](https://doi.org/10.48550/arXiv.2303.12712).”
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 正如罗森布拉特认为他的感知机是意识、类似人类的机器的基础，一些当代人工智能理论家也这样看待当今人工神经网络。2023年，微软发表了一篇论文称“[GPT-4的表现非常接近人类水平](https://doi.org/10.48550/arXiv.2303.12712)”。
- en: Executives at big tech companies, including Meta, Google and OpenAI, have set
    their sights on developing human-level AI. [AP Photo/Eric Risberg](https://newsroom.ap.org/detail/APECFutureofAI/3fd286588bd549f196eeed9b3c6919fe/photo?Query=Sam%20Altman&mediaType=photo&sortBy=creationdatetime:desc&dateRange=Anytime&totalCount=164&currentItemNo=38)
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 大型科技公司的高管，包括Meta、Google和OpenAI，已经将目光投向开发人类水平的人工智能。[AP Photo/Eric Risberg](https://newsroom.ap.org/detail/APECFutureofAI/3fd286588bd549f196eeed9b3c6919fe/photo?Query=Sam%20Altman&mediaType=photo&sortBy=creationdatetime:desc&dateRange=Anytime&totalCount=164&currentItemNo=38)
- en: But before claiming that LLMs are exhibiting human-level intelligence, it might
    help to reflect on the cyclical nature of AI progress. Many of the same problems
    that haunted earlier iterations of AI are still present today. The difference
    is how those problems manifest.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 但在声称LLM展示出人类水平智能之前，反思一下人工智能进展的周期性可能会有所帮助。许多早期AI版本困扰的问题今天仍然存在。不同之处在于这些问题的表现方式。
- en: For example, the knowledge problem persists to this day. ChatGPT continually
    struggles to respond to [idioms, metaphors, rhetorical questions and sarcasm](https://blogs.nottingham.ac.uk/makingsciencepublic/2023/10/27/chatgpt-and-its-magical-metaphors/)
    – unique forms of language that go beyond grammatical connections and instead
    require inferring the meaning of the words based on context.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，知识问题至今仍然存在。ChatGPT持续努力回答关于[成语、隐喻、修辞问句和讽刺](https://blogs.nottingham.ac.uk/makingsciencepublic/2023/10/27/chatgpt-and-its-magical-metaphors/)的问题——这些是语言的独特形式，超越了语法联系，而是需要根据上下文推断词语意义。
- en: Artificial neural networks can, with impressive accuracy, pick out objects in
    complex scenes. But give an AI a picture of a school bus lying on its side and
    it will very confidently [say it’s a snowplow](https://arxiv.org/abs/1811.11553)
    97% of the time.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: 人工神经网络能够以令人印象深刻的准确度在复杂场景中识别物体。但是，如果给AI一张侧卧的校车的图片，它会非常自信地[说它是一辆扫雪机](https://arxiv.org/abs/1811.11553)，有97%的几率是这样。
- en: Lessons to heed
  id: totrans-split-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 需要注意的教训
- en: In fact, it turns out that AI is [quite easy to fool](https://www.nature.com/articles/d41586-019-03013-5)
    in ways that humans would immediately identify. I think it’s a consideration worth
    taking seriously in light of how things have gone in the past.
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，事实证明AI在某些方面是[相当容易被欺骗的](https://www.nature.com/articles/d41586-019-03013-5)，而这些欺骗方法人类会立即识别出来。我认为在过去的事态发展的背景下，这是一个值得认真考虑的问题。
- en: 'The AI of today looks quite different than AI once did, but the problems of
    the past remain. As the saying goes: History may not repeat itself, but it often
    rhymes.'
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 当今的人工智能看起来与过去的人工智能截然不同，但过去的问题仍然存在。正如谚语所说：历史不一定重演，但往往会押韵。
