<!--yml

类别：未分类

日期：2024-05-29 12:37:33

-->

# 长者如何迷恋在Facebook上生成的AI图片

> 来源：[https://www.thedailybeast.com/how-seniors-are-falling-for-ai-generated-pics-on-facebook](https://www.thedailybeast.com/how-seniors-are-falling-for-ai-generated-pics-on-facebook)

随着AI生成内容在网上的增多并充斥社交媒体的动态，你可能注意到越来越多的图片冒出来，引发了奇异谷效应——相对正常的场景，但又带有超现实的细节，如多余的手指或无意义的词汇。

在这些误导性的帖子中，年轻用户已经注意到了一些明显的虚假图片（例如，[滑雪狗和幼儿](https://twitter.com/venturetwins/status/1759672393965199755/photo/1)，[令人困惑的“手工雕刻”冰雕](https://www.facebook.com/photo/?fbid=6942119619206100&set=a.243501512401311)，以及[巨大的钩编猫](https://www.tiktok.com/@alyssawallen/video/7289254442304720174?_r=1&_t=8kEtEdvsOiZ)）。但对每个人来说，AI生成的艺术并不明显：似乎年长用户——一般是X代及以上的人——在社交媒体上大量迷恋这些视觉作品。这不仅仅表现在TikTok视频和浏览你妈妈的Facebook活动上——这背后还有数据支持。

这个平台已经越来越受老年人欢迎，他们在寻找娱乐和伴侣方面比起年轻用户更加倾向于使用像TikTok和Instagram这样的潮流应用。最近，根据斯坦福大学和乔治城大学的研究人员在3月18日发布的一篇预印本论文，Facebook的算法似乎正在向用户推送疯狂的AI图像，以销售产品并积累关注度。

看看这些AI生成的照片的评论区，你会发现很多年长用户评论说它们“美丽”或“惊人”，通常还会用心形和祈祷表情符号装饰这些帖子。为什么老年人不仅仅迷恋这些页面——而且似乎享受它们呢？

现在，科学家们对AI艺术的心理影响尚无明确答案，因为像DALL-E、Midjourney和Adobe Firefly这样的生成器——它们运行在训练了数百万张图片的人工智能模型上，仅在过去两年才公开可用。

但专家们确实有一种直觉——这并不像你所期望的那么简单解释。尽管如此，了解为何年长的朋友和亲戚可能会感到困惑可以提供防止他们成为诈骗或有害错误信息受害者的线索。

## 为什么 AI 图像会欺骗老年人

破解这个问题特别重要，因为像 [技术](http://thedailybeast.com/keyword/technology) 公司（例如 [Google](http://thedailybeast.com/keyword/google)）在内部测试中往往忽视老年用户，多伦多大学研究老龄化对沟通影响的认知神经科学家比约恩·赫尔曼告诉 The Daily Beast。

“在这类空间中，通常事情推进并不是真正考虑老龄化的视角，”他说。

尽管认知衰退似乎是这种机器驱动的不匹配的合理解释，但早期研究表明，对 AI 缺乏经验和熟悉可能有助于解释年轻和老年观众之间的理解差距。例如，在 2023 年 8 月的 AARP 和 NORC 的一项 [调查](https://www.norc.org/research/library/older-adults-express-mixed-views-artificial-intelligence.html#:~:text=An%20August%20Foresight%2050%2B%20Omnibus,were%20very%20familiar%20with%20it.) 中，针对近 1300 名年龄在 50 岁及以上的美国成年人，只有 17% 的参与者表示他们对 AI 有很多了解。

到目前为止，分析老年人对 AI 感知的几项实验似乎与 Facebook 现象一致。在《科学报告》杂志上上个月发表的一项 [研究](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10876601/) 中，科学家们向 201 名参与者展示了一些 AI 和人类生成的图像，并根据年龄、性别和对技术的态度等因素评估了他们的反应。研究团队发现，年龄较大的参与者更可能认为 AI 生成的图像是人类制作的。

“我认为这是我认为没有其他人发现过的事情，但我不知道如何解释它，”挪威卑尔根大学的心理学家和研究作者 Simone Grassini 告诉 The Daily Beast。

虽然人们对 AI 生成内容的整体研究稀缺，但研究人员发现 AI 制作的音频也有类似的结果。去年，多伦多大学的比约恩·赫尔曼 [报道](https://link.springer.com/article/10.1007/s10772-023-10027-y)，较年轻的受试者相比，老年受试者辨别人类与 AI 生成的语音的能力较低。

“我并没有真正期望这一点，”他说，因为这个实验的目的是确定 AI 语音是否可以用来研究老年人在背景噪音中感知声音的方式。

总体来看，Grassini 认为任何类型的 AI 生成媒体——无论是音频、视频还是静止图像——可能通过更广泛的“一刀切效应”更容易欺骗年长观众。Herrmann 和 Grassini 都建议，老一代可能不了解 AI 生成内容的特征，并且在日常生活中接触较少，这使得他们在屏幕上看到这些内容时更容易受到攻击。认知衰退和听力损失（在音频的情况下）可能起到一定作用，但 Grassini 仍然观察到在四五十岁的人群中存在这种效应。

此外，年轻人在[在线错误信息](https://www.thedailybeast.com/the-biden-deepfake-robocall-is-just-the-start-of-our-ai-election-hell) 的时代长大，习惯了被篡改的照片和视频，Grassini 补充说。“我们生活在一个越来越虚假的社会。”

## 如何帮助朋友和亲戚发现机器人

尽管在网上累积了识别虚假内容的挑战，老年人通常对更大的图景有清晰的看法。事实上，他们可能比年轻一代更常见地认识到 AI 动力内容的危险。

2023 年 MITRE-Harris 民意调查超过 2000 人，[表明](https://www.mitre.org/focus-areas/artificial-intelligence/ai-trends) 比起 Gen Z 和千禧一代，更多的婴儿潮和 X 代参与者担心深度伪造的后果。年长的群体中有更高比例的参与者呼吁从[AI 技术的监管](https://www.thedailybeast.com/why-the-government-should-regulate-ai-like-we-do-drugs-and-guns) 以及更多的技术行业投资以保护公众。

研究还表明，老年人可能[更准确地区分](https://today.yougov.com/politics/articles/45855-americans-distinguish-real-fake-news-headline-poll) 假新闻标题和故事，比年轻人，或者至少[以相当的速度发现它](https://news.ufl.edu/2022/05/aging-adults-fake-news/)。老年人[也倾向于](https://news.ufl.edu/2022/05/aging-adults-fake-news/) 消费比年轻同龄人更多的新闻，并且可能在其一生中积累了大量的特定主题知识，这使得欺骗他们变得更加困难。

“内容的背景真的很重要，” 密西西比大学新闻与新媒体学院院长 Andrea Hickerson 告诉 The Daily Beast，她研究了对老年人的网络攻击和深度伪造检测。“如果这是任何人都可能更了解的主题，无论是老年人还是其他人，你都会带着你的能力来观看这些信息。”

尽管如此，骗子们已经开始使用越来越复杂的生成AI工具来针对老年人。他们可以利用社交媒体上来源的深度伪造音频和图像，假装是孙子从监狱打电话要求保释金，甚至伪造亲戚在视频通话中的外貌。

在选举前，虚假的视频、音频和图像也可能影响到年长选民。这可能特别有害，因为50岁及以上的人群[往往占](https://www.pewresearch.org/politics/2023/07/12/voter-turnout-2018-2022/)美国选民的大多数。

为了帮助您生活中的老年人群体，Hickerson说，增加对生成AI及其在线造成的风险的认识是很重要的。您可以从教育他们如何辨别[人工合成图像的显著特征](https://www.discovermagazine.com/technology/4-ways-to-spot-ai-generated-photos)，如过度光滑的质感，奇怪的牙齿或完美重复的背景图案开始。

她补充道，我们可以澄清我们对社交媒体算法以及它们如何针对老年人的了解和不了解。澄清误导信息甚至可能来自朋友和亲人。“我们需要说服人们，可以信任贝蒂阿姨，而不是她的内容，这是可以的。”她说。

## 没有人安全

随着deepfake和其他AI创作每天变得越来越先进，即使是最有经验的技术专家也可能难以辨别它们。即使您认为自己很精明，这些模型也可能已经让您感到困惑。网站[This Person Does Not Exist](https://thispersondoesnotexist.com/)提供了看起来非常逼真的伪造AI面孔照片，有时可能并不总能带有计算机起源的微妙痕迹。

虽然研究人员和技术公司已经开发了算法来自动检测假媒体，但它们无法百分之百准确地工作——而快速发展的生成AI模型最终会[超越它们](https://www.theverge.com/2019/6/27/18715235/deepfake-detection-ai-algorithms-accuracy-will-they-ever-work)。（例如，Midjourney在去年春天发布的新版本中终于在创造逼真的手部图像时[变得更聪明了](https://hyperallergic.com/808778/ai-image-generators-finally-figured-out-hands/)。）

为了对抗日益增多的无法察觉的虚假内容及其社会后果，希克森表示，监管和企业责任至关重要。截至上周，有[超过50](https://www.usatoday.com/story/news/politics/elections/2024/03/10/2024-election-ai-deepfake-regulation-slow/72877766007/)项法案覆盖30个州，旨在遏制深度伪造风险。自2024年初以来，国会已经[引入](https://www.brennancenter.org/our-work/research-reports/artificial-intelligence-legislation-tracker)了一系列法案以应对深度伪造技术。

“这确实涉及到监管和责任，”希克森说。“我们需要就此进行更加公开的讨论，包括各代人士。”
