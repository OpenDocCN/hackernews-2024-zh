<!--yml

category: æœªåˆ†ç±»

date: 2024-05-29 12:30:08

-->

# ä¸€ä¸ªæ›´å¥½çš„Pythonç¼“å­˜ç”¨äºç¼“æ…¢çš„å‡½æ•°è°ƒç”¨

> æ¥æºï¼š[https://docs.sweep.dev/blogs/file-cache](https://docs.sweep.dev/blogs/file-cache)

<main class="nx-w-full nx-min-w-0 nx-max-w-6xl nx-px-6 nx-pt-4 md:nx-px-12">

ğŸ“š åšå®¢

ğŸ“‚ ä¸€ä¸ªæ›´å¥½çš„Pythonç¼“å­˜ç”¨äºç¼“æ…¢çš„å‡½æ•°è°ƒç”¨

# ä¸€ä¸ªæ›´å¥½çš„Pythonç¼“å­˜ç”¨äºç¼“æ…¢çš„å‡½æ•°è°ƒç”¨

**William Zeng** - 2024å¹´3æœˆ18æ—¥

* * *

æˆ‘ä»¬ç¼–å†™äº†ä¸€ä¸ªæ–‡ä»¶ç¼“å­˜ - å®ƒç±»ä¼¼äºPythonçš„`lru_cache`ï¼Œä½†å®ƒå°†å€¼å­˜å‚¨åœ¨æ–‡ä»¶ä¸­è€Œä¸æ˜¯å†…å­˜ä¸­ã€‚è¿™ä¸ºè¿è¡Œæˆ‘ä»¬çš„LLMåŸºå‡†æµ‹è¯•èŠ‚çœäº†å¤§é‡æ—¶é—´ï¼Œå¹¶ä¸”æˆ‘ä»¬å¸Œæœ›å°†å…¶åˆ†äº«ä¸ºè‡ªå·±çš„Pythonæ¨¡å—ã€‚æ„Ÿè°¢[Luke Jaggernauth (åœ¨æ–°æ ‡ç­¾é¡µä¸­æ‰“å¼€)](https://github.com/lukejagg)ï¼ˆå‰Sweepå·¥ç¨‹å¸ˆï¼‰ä¸ºæ„å»ºæ­¤åˆå§‹ç‰ˆæœ¬è€Œæ„Ÿè°¢ï¼

è¿™é‡Œæ˜¯é“¾æ¥ï¼š[https://github.com/sweepai/sweep/blob/main/docs/public/file_cache.py (åœ¨æ–°æ ‡ç­¾é¡µä¸­æ‰“å¼€)](https://github.com/sweepai/sweep/blob/main/docs/public/file_cache.py)ã€‚è¦ä½¿ç”¨å®ƒï¼Œåªéœ€å°†`file_cache`è£…é¥°å™¨æ·»åŠ åˆ°æ‚¨çš„å‡½æ•°ä¸­ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªç¤ºä¾‹ï¼š

```
import time
from file_cache import file_cache

@file_cache()
def  slow_function(x,  y):
 time.sleep(30)
 return x + y

print(slow_function(1, 2))  # -> 3, takes 30 seconds
print(slow_function(1, 2))  # -> 3, takes 0 seconds
```

## èƒŒæ™¯

æˆ‘ä»¬åœ¨SweepèŠ±è´¹å¤§é‡æ—¶é—´è¿›è¡Œpromptå·¥ç¨‹ã€‚æˆ‘ä»¬çš„agentsæ¥å—ä¸€ç»„è¾“å…¥å­—ç¬¦ä¸²ï¼Œå°†å®ƒä»¬æ ¼å¼åŒ–ä¸ºæç¤ºï¼Œç„¶åå°†æç¤ºå’Œä»»ä½•å…¶ä»–ä¿¡æ¯å‘é€ç»™LLMã€‚æˆ‘ä»¬é“¾æ¥å¤šä¸ªagentsæ¥å°†GitHubé—®é¢˜è½¬æ¢ä¸ºæ‹‰å–è¯·æ±‚ã€‚ä¾‹å¦‚ï¼Œè¦ä¿®æ”¹ä»£ç ï¼Œæˆ‘ä»¬å°†è¾“å…¥æ—§ä»£ç ã€ä»»ä½•ç›¸å…³ä¸Šä¸‹æ–‡å’ŒæŒ‡ä»¤ï¼Œç„¶åè¾“å‡ºæ–°ä»£ç ã€‚

å…¸å‹çš„æ”¹è¿›åŒ…æ‹¬è°ƒæ•´æˆ‘ä»¬ç®¡é“çš„ä¸€ä¸ªå°éƒ¨åˆ†ï¼ˆå¦‚æ”¹è¿›æˆ‘ä»¬çš„è§„åˆ’ç®—æ³•ï¼‰ï¼Œç„¶åå†æ¬¡è¿è¡Œæ•´ä¸ªç®¡é“ã€‚æˆ‘ä»¬ä½¿ç”¨pdbï¼ˆPythonçš„æœ¬åœ°è°ƒè¯•å™¨ï¼‰è®¾ç½®æ–­ç‚¹å’Œæ£€æŸ¥æˆ‘ä»¬çš„æç¤ºã€è¾“å…¥å€¼å’Œè§£æé€»è¾‘çš„çŠ¶æ€ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥æŸä¸ªå­—ç¬¦ä¸²æ˜¯å¦ä¸æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ï¼š

```
(Pdb) print(todays_date)
'2024-03-14'
(Pdb) re.match(r"^\d{4}-\d{2}-\d{2}$",  todays_date)
<re.Match object; span=(0,  10),  match='2024-03-14'>
```

è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨å®é™…æ•°æ®è¿è¡Œæ—¶è°ƒè¯•ã€‚

## Cached pdb

pdbæ•ˆæœå¾ˆå¥½ï¼Œä½†æˆ‘ä»¬å¿…é¡»ç­‰å¾…æ•´ä¸ªç®¡é“å†æ¬¡è¿è¡Œã€‚æƒ³è±¡ä¸€ä¸ªpdbçš„ç‰ˆæœ¬ï¼Œä¸ä»…ä¸­æ–­æ‰§è¡Œï¼Œè€Œä¸”è¿˜ç¼“å­˜åˆ°è¯¥ç‚¹ä¸ºæ­¢çš„æ•´ä¸ªç¨‹åºçŠ¶æ€ã€‚æˆ‘ä»¬è§£å†³åŒæ ·çš„é”™è¯¯å¯èƒ½ä»10åˆ†é’Ÿç¼©çŸ­åˆ°15ç§’ï¼ˆæå‡40å€ï¼‰ã€‚

æˆ‘ä»¬æ²¡æœ‰æ„å»ºè¿™ä¸ªï¼Œä½†æˆ‘ä»¬è®¤ä¸ºæˆ‘ä»¬çš„`file_cache`åŒæ ·æœ‰æ•ˆã€‚

LLMè°ƒç”¨è™½ç„¶æ…¢ï¼Œä½†å®ƒä»¬çš„è¾“å…¥å’Œè¾“å‡ºå¾ˆå®¹æ˜“ç¼“å­˜ï¼Œä»è€ŒèŠ‚çœäº†å¤§é‡æ—¶é—´ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¾“å…¥æç¤º/å­—ç¬¦ä¸²ä½œä¸ºç¼“å­˜é”®ï¼Œè¾“å‡ºå­—ç¬¦ä¸²ä½œä¸ºç¼“å­˜å€¼ã€‚

### ä¸`lru_cache`æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ

`lru_cache`éå¸¸é€‚åˆå¯¹é‡å¤çš„å‡½æ•°è°ƒç”¨è¿›è¡Œè®°å¿†åŒ–ï¼Œä½†å®ƒä¸æ”¯æŒä¸¤ä¸ªå…³é”®åŠŸèƒ½ã€‚

1.  æˆ‘ä»¬éœ€è¦åœ¨è¿è¡Œä¹‹é—´æŒä¹…åŒ–ç¼“å­˜ã€‚

    +   `lru_cache`å°†ç»“æœå­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œè¿™æ„å‘³ç€ä¸‹æ¬¡è¿è¡Œç¨‹åºæ—¶ç¼“å­˜å°†ä¸ºç©ºã€‚`file_cache`å°†ç»“æœå­˜å‚¨åœ¨ç£ç›˜ä¸Šã€‚æˆ‘ä»¬ä¹Ÿè€ƒè™‘è¿‡ä½¿ç”¨Redisï¼Œä½†å†™å…¥ç£ç›˜æ›´å®¹æ˜“è®¾ç½®/ç®¡ç†ã€‚

1.  `lru_cache`ä¸æ”¯æŒå¿½ç•¥ä½¿ç¼“å­˜æ— æ•ˆçš„å‚æ•°ã€‚

    +   æˆ‘ä»¬å°†ä½¿ç”¨è‡ªå®šä¹‰çš„ `chat_logger`ï¼Œç”¨äºå¯è§†åŒ–å­˜å‚¨èŠå¤©è®°å½•ã€‚å®ƒåŒ…å«å½“å‰æ—¶é—´æˆ³ `chat_logger.expiration`ï¼Œå¦‚æœè¢«åºåˆ—åŒ–ï¼Œå°†ä½¿ç¼“å­˜æ— æ•ˆã€‚

    +   ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æ·»åŠ äº†å¿½ç•¥çš„å‚æ•°ï¼Œä½¿ç”¨æ–¹å¼å¦‚ä¸‹ï¼š`file_cache(ignore_params=["chat_logger"])`ã€‚è¿™ä¼šä»ç¼“å­˜é”®çš„æ„å»ºä¸­ç§»é™¤ `chat_logger`ï¼Œå¹¶é˜²æ­¢ç”±äºä¸æ–­å˜åŒ–çš„ `expiration` å¯¼è‡´çš„æ— æ•ˆç¼“å­˜ã€‚

## å®ç°

æˆ‘ä»¬çš„ä¸¤ä¸ªä¸»è¦æ–¹æ³•æ˜¯ `recursive_hash` å’Œ `file_cache`ã€‚

### recursive_hash

æˆ‘ä»¬å¸Œæœ›ç¨³å®šåœ°å¯¹å¯¹è±¡è¿›è¡Œå“ˆå¸Œï¼Œè¿™åœ¨ [Python ä¸­å¹¶éåŸç”Ÿæ”¯æŒ (åœ¨æ–°æ ‡ç­¾é¡µæ‰“å¼€)](https://death.andgravity.com/stable-hashing)ã€‚

```
import hashlib
from cache import recursive_hash

class  Obj:
 def  __init__(self,  name):
 self.name = name

obj =  Obj("test")
print(recursive_hash(obj))  # -> this works fine
try:
 hashlib.md5(obj).hexdigest()
except  Exception  as e:
 print(e)  # -> this doesn't work
```

hashlib.md5 å•ç‹¬å¯¹å¯¹è±¡æ— æ•ˆï¼Œå¯¼è‡´é”™è¯¯ï¼š`TypeError: object supporting the buffer API required`ã€‚æˆ‘ä»¬ä½¿ç”¨ `recursive_hash`ï¼Œå®ƒé€‚ç”¨äºä»»æ„çš„ Python å¯¹è±¡ã€‚

```
def  recursive_hash(value,  depth=0,  ignore_params=[]):
 """Hash primitives recursively with maximum depth."""
 if depth > MAX_DEPTH:
 return hashlib.md5("max_depth_reached".encode()).hexdigest()

 if  isinstance(value, (int, float, str, bool, bytes)):
 return hashlib.md5(str(value).encode()).hexdigest()
 elif  isinstance(value, (list, tuple)):
 return hashlib.md5(
 "".join(
 [recursive_hash(item, depth +  1, ignore_params)  for item in value]
 ).encode()
 ).hexdigest()
 elif  isinstance(value, dict):
 return hashlib.md5(
 "".join(
 [
 recursive_hash(key, depth +  1, ignore_params)
 +  recursive_hash(val, depth +  1, ignore_params)
 for key, val in value.items()
 if key not  in ignore_params
 ]
 ).encode()
 ).hexdigest()
 elif  hasattr(value, "__dict__")  and value.__class__.__name__  not  in ignore_params:
 return  recursive_hash(value.__dict__, depth +  1, ignore_params)
 else:
 return hashlib.md5("unknown".encode()).hexdigest()
```

### file_cache

file_cache æ˜¯ä¸€ä¸ªä¸ºæˆ‘ä»¬å¤„ç†ç¼“å­˜é€»è¾‘çš„è£…é¥°å™¨ã€‚

```
@file_cache()
def  search_codebase(
 cloned_github_repo,
 query,
):
 # ... take a long time ...
 # ... llm agent logic to search through the codebase ...
 return top_results
```

å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œä½¿ç”¨æˆ‘ä»¬çš„ LLM ä»£ç†åœ¨ä»£ç åº“ä¸­æœç´¢ `top_results` éœ€è¦ 5 åˆ†é’Ÿ - å¦‚æœæˆ‘ä»¬å®é™…ä¸Šä¸åœ¨æµ‹è¯•ä¸­ï¼Œè¿™æ—¶é—´å¤ªé•¿äº†ã€‚ç›¸åï¼Œä½¿ç”¨ file_cacheï¼Œæˆ‘ä»¬åªéœ€ç­‰å¾…æ‹¾å–å¯¹è±¡çš„ååºåˆ—åŒ– - å¯¹äºæœç´¢ç»“æœæ¥è¯´åŸºæœ¬ç¬é—´å®Œæˆã€‚

#### åŒ…è£…å™¨

é¦–å…ˆï¼Œæˆ‘ä»¬å°†ç¼“å­˜å­˜å‚¨åœ¨ `/tmp/file_cache` ä¸­ã€‚è¿™è®©æˆ‘ä»¬å¯ä»¥é€šè¿‡ç®€å•åˆ é™¤ç›®å½•ï¼ˆè¿è¡Œ `rm -rf /tmp/file_cache`ï¼‰æ¥åˆ é™¤ç¼“å­˜ã€‚æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨ `rm -rf /tmp/file_cache/search_codebase*` æœ‰é€‰æ‹©åœ°ç§»é™¤å‡½æ•°è°ƒç”¨ã€‚

```
def  wrapper(*args,  **kwargs):
 cache_dir =  "/tmp/file_cache"
 os.makedirs(cache_dir, exist_ok=True)
```

ç„¶åæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªç¼“å­˜é”®ã€‚

#### ç¼“å­˜é”®çš„åˆ›å»º / æœªå‘½ä¸­æ¡ä»¶

æˆ‘ä»¬è¿˜æœ‰å¦ä¸€ä¸ªé—®é¢˜ - æˆ‘ä»¬å¸Œæœ›åœ¨ä¸¤ç§æƒ…å†µä¸‹é”™è¿‡æˆ‘ä»¬çš„ç¼“å­˜ï¼š

1.  å‡½æ•°çš„å‚æ•°å˜åŒ–ç”± `recursive_hash` å¤„ç†

1.  ä»£ç æ›´æ”¹

ä¸ºäº†å¤„ç†ç¬¬ 2 ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ä½¿ç”¨ `inspect.getsource(func)` å°†å‡½æ•°çš„æºä»£ç æ·»åŠ åˆ°å“ˆå¸Œä¸­ï¼Œä»è€Œåœ¨ä»£ç æ›´æ”¹æ—¶æ­£ç¡®åœ°é”™è¿‡ç¼“å­˜ã€‚

```
 func_source_code_hash =  hash_code(inspect.getsource(func))
```

```
 args_names = func.__code__.co_varnames[: func.__code__.co_argcount]
 args_dict =  dict(zip(args_names, args))

 # Remove ignored params
 kwargs_clone = kwargs.copy()
 for param in ignore_params:
 args_dict.pop(param, None)
 kwargs_clone.pop(param, None)

 # Create hash based on argument names, argument values, and function source code
 arg_hash = (
 recursive_hash(args_dict, ignore_params=ignore_params)
 +  recursive_hash(kwargs_clone, ignore_params=ignore_params)
 +  func_source_code_hash
 )
 cache_file = os.path.join(
 cache_dir, f"{func.__module__}_{func.__name__}_{arg_hash}.pickle"
 )
```

#### ç¼“å­˜å‘½ä¸­å’Œæœªå‘½ä¸­

æœ€åï¼Œæˆ‘ä»¬æ£€æŸ¥ç¼“å­˜é”®çš„å­˜åœ¨æ€§ï¼Œå¹¶åœ¨ç¼“å­˜æœªå‘½ä¸­çš„æƒ…å†µä¸‹å†™å…¥ç¼“å­˜ã€‚

```
 try:
 # If cache exists, load and return it
 if os.path.exists(cache_file):
 if verbose:
 print("Used cache for function: "  + func.__name__)
 with  open(cache_file, "rb")  as f:
 return pickle.load(f)
 except  Exception:
 logger.info("Unpickling failed")

 # Otherwise, call the function and save its result to the cache
 result =  func(*args, **kwargs)
 try:
 with  open(cache_file, "wb")  as f:
 pickle.dump(result, f)
 except  Exception  as e:
 logger.info(f"Pickling failed: {e}")
 return result
```

## ç»“è®º

æˆ‘ä»¬å¸Œæœ›è¿™æ®µä»£ç å¯¹ä½ æœ‰ç”¨ã€‚æˆ‘ä»¬å‘ç°åœ¨è°ƒè¯• LLM è°ƒç”¨æ—¶ï¼Œå®ƒèƒ½å¤§å¤§èŠ‚çœæ—¶é—´ã€‚æˆ‘ä»¬å¾ˆä¹æ„å¬å–ä½ çš„åé¦ˆå’Œè´¡çŒ®ï¼Œç½‘å€æ˜¯ [https://github.com/sweepai/sweep (åœ¨æ–°æ ‡ç­¾é¡µæ‰“å¼€)](https://github.com/sweepai/sweep)!

</main>
