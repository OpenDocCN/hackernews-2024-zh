<!--yml

分类：未分类

日期：2024-05-27 15:01:40

-->

# 鬼机器人：AI版本的已故亲人可能对心理健康构成严重威胁

> 来源：[https://theconversation.com/ghostbots-ai-versions-of-deceased-loved-ones-could-be-a-serious-threat-to-mental-health-224984](https://theconversation.com/ghostbots-ai-versions-of-deceased-loved-ones-could-be-a-serious-threat-to-mental-health-224984)

我们都经历过失落和悲伤。不过，想象一下，你不必和你所爱的人告别。你可以虚拟重现他们，这样你就可以进行对话，了解他们的感受。

为了金·卡戴珊（Kim Kardashian）的四十岁生日，她当时的丈夫坎耶·韦斯特（Kanye West）送给她一个她[已故父亲](https://www.bbc.co.uk/news/entertainment-arts-54731382)，罗伯特·卡戴珊（Robert Kardashian）的全息影像。据报道，金·卡戴珊对在生日派对上看到父亲的[虚拟形象](https://www.theguardian.com/lifeandstyle/2020/oct/30/robert-kardashian-resurrected-as-a-hologram-for-kim-kardashian-wests-birthday)感到不可思议和欢喜。能够再次看到久已逝去、深感惋惜的亲人动态说话，可能会给留下的人们带来慰藉。

毕竟，复活一个已故亲人似乎是奇迹般的事情——可能还有点吓人——但这对我们的健康有何影响？AI幽灵对悲伤过程有帮助还是阻碍？

作为一名研究如何利用AI技术增强治疗干预的心理治疗师，我对鬼机器人的出现感到好奇。但我对这项技术对使用者心理健康的潜在影响也颇为担忧，特别是那些正在悲伤的人。将死者复活为化身可能会造成更多伤害而非好处，进一步加深混乱、压力、抑郁、偏执，甚至在某些情况下导致精神病。

最近人工智能（AI）的发展导致了ChatGPT和其他聊天机器人的出现，使用户能够进行复杂的类人对话。

利用深度伪造技术，AI软件可以利用他们的[数字内容](https://wired.me/technology/artificial-intelligence/why-scientists-are-building-ai-powered-digital-imprints-of-the-dead/)，如照片、电子邮件和视频，创建一个[交互式虚拟表现](https://www.sciencedirect.com/science/article/pii/S0267364924000104)的已故人物。

这些创作中的一些曾几年前仅是科幻幻想的主题，但现在它们已经成为科学现实。

## 帮助还是阻碍？

[数字幽灵](https://link.springer.com/article/10.1007/s12124-022-09679-3)可能会成为悲伤者的一种安慰，帮助他们重新与失去的亲人联系。它们可以为用户提供一个机会，说一些之前没机会说的话或者问问题，当时已故的人还活着时。

但幽灵机器人与失去的爱人的惊人相似性可能并不像听起来那么积极。[研究表明](https://www.newscientist.com/article/2416079-resurrecting-loved-ones-as-ai-ghosts-could-harm-your-mental-health/)，AI幽灵机器人应该只作为一种暂时的哀悼辅助工具，以避免对技术的情感依赖可能带来的潜在伤害。

AI幽灵可能通过干扰[哀伤过程](https://www.newscientist.com/article/mg26034650-700-how-ai-avatars-of-the-deceased-could-transform-the-way-we-grieve/)对人们的心理健康造成伤害。

悲伤需要时间，并且有许多[不同阶段](https://www.medicalnewstoday.com/articles/grieving-process#:%7E:text=They%20include%20shock%2C%20denial%2C%20anger,them%20cope%20in%20various%20ways.)可能持续多年。当新近丧失亲人时，经历悲伤的人可能经常想起他们逝去的爱人。他们可能会重新回忆起旧时的记忆，悲伤的人更有可能在梦中更为强烈地[梦见](https://pubmed.ncbi.nlm.nih.gov/23449603/)他们失去的爱人。

精神分析学家[Sigmund Freud](https://tidsskriftet.no/en/2020/03/essay/dynamics-grief-and-melancholia)关注人类对失落经历的反应。他指出，如果围绕死亡存在负面情绪，对于悲伤者可能会增加困难。

例如，如果一个人对某人抱有矛盾情感，而这个人去世了，这个人可能会感到内疚。或者如果一个人以[可怕的方式](https://www.frontiersin.org/journals/psychiatry/articles/10.3389/fpsyt.2020.00749/full)如被谋杀去世，悲伤的人可能会发现接受这一点更加困难。

Freud将此称为“忧郁症”，但也可以称为[“复杂悲伤”](https://www.tandfonline.com/doi/abs/10.1080/15524256.2020.1745726)。在一些极端情况下，一个人可能会经历幻影[和幻觉](https://journals.sagepub.com/doi/full/10.1177/1363461520962887)，他们认为自己看到死去的人并且开始相信他们还活着。AI幽灵机器人可能会进一步创伤复杂悲伤的人，并可能加剧与幻觉等相关问题。

## Chatbot恐怖

这些幽灵机器人还存在风险，可能会对哀悼者说出有害的话或者给出错误的建议。类似的生成软件，比如ChatGPT聊天机器人，已经因为向用户[提供错误信息](https://www.nytimes.com/2023/02/08/technology/ai-chatbots-disinformation.html)而广受批评。

假设 AI 技术走上邪路，并开始向用户发表[不当言论](https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html)——这是记者[凯文·鲁斯](https://www.nytimes.com/2023/02/16/technology/bing-chatbot-transcript.html)在 2023 年遇到的情况，当时一款 [Bing 聊天机器人](https://www.nytimes.com/2023/12/17/insider/ai-chatbots-humans-hallucinate.html#:%7E:text=在今年的情人节上，有人让他离开他的妻子。这是非常伤人的，如果一位已故的父亲被儿子或女儿召唤为 AI 幽灵，听到他们不受喜爱或不是父亲最喜欢的评论。

或者，在一个更极端的情况下，如果幽灵机器人建议用户加入他们死亡或者应该杀害或伤害某人。这听起来像是恐怖电影的情节，但并非那么遥不可及。在 2023 年，英国的[工党](https://www.bbc.co.uk/news/uk-politics-66224052)制定了一项法律，防止训练 AI 煽动暴力。

这是对年初一位被其聊天机器人女友鼓励的男子企图刺杀女王的回应，他们之间有一段 “[情感和性关系](https://www.bbc.co.uk/news/uk-england-berkshire-66123122)”。

ChatGPT 的创建者目前承认软件存在错误，并且仍然[不完全可靠](https://www.scientificamerican.com/article/ai-platforms-like-chatgpt-are-easy-to-use-but-also-potentially-dangerous/)，因为它捏造信息。谁知道一个人的文本、电子邮件或视频会被这种 AI 技术如何解释，会生成什么内容？

无论这项技术进展到何种程度，看起来都需要大量的监督和人类监管。

## 忘记是健康的。

这项最新技术表明了我们数字文化的无限可能性，没有界限。

数据可以无限期存储在云端，一切都可以检索，没有什么是真正删除或销毁的。忘记是健康哀伤的重要组成部分，但为了忘记，人们需要找到新的和有意义的方式来记住已故的人。

纪念日在帮助哀悼者不仅记住失去的爱人方面起着关键作用，它们也是[以新方式代表损失](https://scholarlypublishingcollective.org/psup/speculative-philosophy/article-abstract/34/3/284/196788/Grief-Phantoms-and-Re-membering-Loss)的机会。仪式和符号可以标志着某些事物的结束，这可以让人类适当地记住，以便适当地忘记。
