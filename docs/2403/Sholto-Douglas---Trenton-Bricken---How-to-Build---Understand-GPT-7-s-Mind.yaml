- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-29 12:46:06'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-29 12:46:06
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Sholto Douglas & Trenton Bricken - How to Build & Understand GPT-7's Mind
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sholto Douglas & Trenton Bricken - 如何构建和理解 GPT-7 的思维
- en: 来源：[https://www.dwarkeshpatel.com/p/sholto-douglas-trenton-bricken](https://www.dwarkeshpatel.com/p/sholto-douglas-trenton-bricken)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.dwarkeshpatel.com/p/sholto-douglas-trenton-bricken](https://www.dwarkeshpatel.com/p/sholto-douglas-trenton-bricken)
- en: Had so much fun chatting with my good friends Trenton Bricken and Sholto Douglas
    on the podcast.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 和我的好朋友 [Trenton Bricken](https://www.trentonbricken.com/about/) 和 [Sholto Douglas](https://twitter.com/_sholtodouglas?lang=en)
    在播客上聊得很开心。
- en: 'No way to summarize it, except:'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 无法总结，除了：
- en: This is the best context dump out there on how LLMs are trained, what capabilities
    they're likely to soon have, and what exactly is going on inside them.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关于如何训练大型语言模型、它们可能很快具备的能力以及它们内部究竟发生了什么的最佳背景信息。
- en: You would be shocked how much of what I know about this field, I've learned
    just from talking with them. To the extent that you've enjoyed my other AI interviews,
    now you know why.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你会惊讶于我对这个领域的了解，其中很大一部分是通过与他们的交谈学到的。如果你喜欢我的其他人工智能访谈，现在你知道为什么了。
- en: Enjoy!
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 尽情享受！
- en: Watch on [YouTube](https://youtu.be/UTuuTTnjxMQ). Listen on [Apple Podcasts](https://podcasts.apple.com/us/podcast/sholto-douglas-trenton-bricken-how-to-build-understand/id1516093381?i=1000650748087), [Spotify](https://open.spotify.com/episode/2dtDauiE4v8ldNRqPFq0uP?si=7S4n69QuTjeYz0lZwW4xIw),
    or any other podcast platform.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在[YouTube](https://youtu.be/UTuuTTnjxMQ)观看。在[Apple Podcasts](https://podcasts.apple.com/us/podcast/sholto-douglas-trenton-bricken-how-to-build-understand/id1516093381?i=1000650748087)、[Spotify](https://open.spotify.com/episode/2dtDauiE4v8ldNRqPFq0uP?si=7S4n69QuTjeYz0lZwW4xIw)或任何其他播客平台上收听。
- en: There's a [transcript](https://www.dwarkeshpatel.com/i/143040987/transcript)
    with links to all the papers the boys were throwing down - may help you follow
    along.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个包含所有论文链接的[文字稿](https://www.dwarkeshpatel.com/i/143040987/transcript)，可以帮助你跟上讨论。
- en: Follow [Trenton](https://twitter.com/TrentonBricken) and [Sholto](https://twitter.com/_sholtodouglas)
    on Twitter.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Twitter 上关注 [Trenton](https://twitter.com/TrentonBricken) 和 [Sholto](https://twitter.com/_sholtodouglas)。
- en: (00:00:00) - Long contexts
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: (00:00:00) - 长篇上下文
- en: (00:16:12) - Intelligence is just associations
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: (00:16:12) - 智能只是关联而已。
- en: (00:32:35) - Intelligence explosion & great researchers
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: (00:32:35) - 智能爆炸与优秀研究者
- en: (01:06:52) - Superposition & secret communication
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: (01:06:52) - 叠加和秘密通信
- en: (01:22:34) - Agents & true reasoning
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: (01:22:34) - 代理和真正的推理
- en: (01:34:40) - How Sholto & Trenton got into AI research
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: (01:34:40) - Sholto 和 Trenton 如何涉足人工智能研究
- en: (02:07:16) - Are feature spaces the wrong way to think about intelligence?
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: (02:07:16) - 特征空间是否是思考智能的错误方式？
- en: (02:21:12) - Will interp actually work on superhuman models
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: (02:21:12) - 解释是否真的能在超人模型上起作用
- en: (02:45:05) - Sholto’s technical challenge for the audience
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: (02:45:05) - Sholto 给听众的技术挑战
- en: (03:03:57) - Rapid fire
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: (03:03:57) - 快速问答
- en: '*Edited by [Teddy Kim](https://firstderivative.substack.com/), with lots of
    helpful links*'
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*由 [Teddy Kim](https://firstderivative.substack.com/) 编辑，包含大量有用的链接*'
- en: '**Dwarkesh Patel**  *0:00:00*'
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel**  *0:00:00*'
- en: Okay, today I have the pleasure to talk with two of my good friends, [Sholto](https://twitter.com/_sholtodouglas?lang=en)
    and [Trenton](https://www.trentonbricken.com/about/).
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，今天我很高兴和两位好朋友 [Sholto](https://twitter.com/_sholtodouglas?lang=en) 和 [Trenton](https://www.trentonbricken.com/about/)
    进行交流。
- en: '[Noam Brown](https://noambrown.github.io/), who wrote the [Diplomacy paper](https://noambrown.github.io/papers/22-Science-Diplomacy-TR.pdf),
    said this about Sholto: “he''s only been in the field for 1.5 years, but people
    in AI know that he was one of the most important people behind Gemini''s success.”
    And Trenton, who''s at [Anthropic](https://www.anthropic.com/), works on [mechanistic
    interpretability](https://www.transformer-circuits.pub/2022/mech-interp-essay)
    and it was widely reported that he has solved alignment.'
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[Noam Brown](https://noambrown.github.io/) 写了关于[外交论文](https://noambrown.github.io/papers/22-Science-Diplomacy-TR.pdf)的，他这样评价
    Sholto：“他只在这个领域工作了一年半，但人们知道他是 Gemini 成功背后最重要的人物之一。” Trenton 在 [Anthropic](https://www.anthropic.com/)
    工作，专注于[机械可解释性](https://www.transformer-circuits.pub/2022/mech-interp-essay)，而且广为人知的是，他已经解决了对齐问题。'
- en: So this will be a capabilities only podcast. Alignment is already solved, no
    need to discuss further.
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这将是一期仅涉及能力的播客。对齐问题已经解决，无需进一步讨论。
- en: Let's start by talking about [context lengths](https://blog.google/technology/ai/long-context-window-ai-models/).
    It seemed to be underhyped, given how important it seems to me, that you can just
    put a [million tokens into context](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#context-window).
    There's apparently some other news that got pushed to the front for some reason,
    but tell me about how you see the future of long context lengths and what that
    implies for these models.
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从讨论[上下文长度](https://blog.google/technology/ai/long-context-window-ai-models/)开始。鉴于我认为这非常重要，你只需将[百万令牌放入上下文](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#context-window)，它似乎被低估了。显然，出于某种原因，有些其他新闻被推到了前线，但告诉我你如何看待长上下文长度的未来以及对这些模型意味着什么。
- en: '**Sholto Douglas**  *00:01:28*'
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯**  *00:01:28*'
- en: So I think it's really underhyped. Until I started working on it, I didn't really
    appreciate how much of a step up in intelligence it was for the model to have
    the onboarding problem basically instantly solved.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我认为这真的被低估了。直到我开始处理它，我才真正意识到模型在解决入职问题时提升了多少智能。
- en: You can see that a bit in the perplexity graphs in the [paper](https://arxiv.org/abs/2403.05530)
    where just throwing millions of tokens worth of context about a code base allows
    it to become dramatically better at predicting the next token in a way that you'd
    normally associate with huge increments in model scale. But you don't need that.
    All you need is a new context. So underhyped and buried by some other news.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[论文](https://arxiv.org/abs/2403.05530)的困惑度图中看到一点，仅仅是将上下文中的百万令牌扔进一个代码库，就使它在预测下一个令牌时变得显著更好，这通常是与模型规模的巨大增加相关的。但你不需要那样。你只需要一个新的上下文。因此，被某些其他新闻低估和埋没了。
- en: '**Dwarkesh Patel**  *00:01:58*'
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔**  *00:01:58*'
- en: In context, are they as [sample efficient](https://ai.stackexchange.com/questions/5246/what-is-sample-efficiency-and-how-can-importance-sampling-be-used-to-achieve-it)
    and smart as humans?
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在上下文中，它们是否像人类一样[样本效率](https://ai.stackexchange.com/questions/5246/what-is-sample-efficiency-and-how-can-importance-sampling-be-used-to-achieve-it)和聪明？
- en: '**Sholto Douglas**  *00:02:02*'
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯**  *00:02:02*'
- en: I think that's really worth exploring. For example, one of the evals that we
    did in the paper had it learn a language in context better than a human expert
    could, over the course of a couple of months.
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这真的值得探索。例如，我们在论文中进行的一个评估显示，它能够在几个月的时间内比人类专家更好地在上下文中学习一种语言。
- en: This is only a small demonstration but I'd be really interested to see things
    like Atari games where you throw in a couple hundred, or a thousand frames, of
    labeled actions in the same way that you'd show your friend how to play a game
    and see if it's able to reason through.
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个小小的演示，但我真的很想看到像 Atari 游戏这样的东西，在那里你可以抛入几百或几千帧的标记动作，就像向朋友展示如何玩游戏一样，看它是否能够推理出来。
- en: It might. At the moment, with the infrastructure and stuff, it's still a bit
    slow at doing that, but I would actually guess that it might just work out of
    the box in a way that would be pretty mind-blowing.
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: 可能会。目前，基础设施等方面还有些慢，但我确实认为它可能会立即在盒子外运行，这可能会相当令人震惊。
- en: '**Trenton Bricken** *00:02:38*'
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *00:02:38*'
- en: And crucially, I think this language was esoteric enough that it wasn't in the
    training data.
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: 并且，我认为这种语言足够深奥，不在训练数据中。
- en: '**Sholto Douglas** *00:02:42*'
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:02:42*'
- en: Exactly. If you look at the model before it has that context thrown in, it doesn't
    know the language at all and it can't get any translations.
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
  zh: 恰恰如此。如果你看看模型在加入上下文之前，它完全不懂语言，也无法进行任何翻译。
- en: '**Dwarkesh Patel** *00:02:49*'
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:02:49*'
- en: And this is an actual human language?
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个真正的人类语言吗？
- en: '**Sholto Douglas**  *00:02:51*'
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯**  *00:02:51*'
- en: Exactly. An actual human language.
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: 恰恰如此。一个真正的人类语言。
- en: '**Dwarkesh Patel**  *00:02:53*'
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔**  *00:02:53*'
- en: So if this is true, it seems to me that these models are already in an important
    sense, superhuman. Not in the sense that they're smarter than us, but I can't
    keep a million tokens in my context when I'm trying to solve a problem, remembering
    and integrating all the information, an entire code base. Am I wrong in thinking
    this is a huge unlock?
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果这是真的，对我来说，这些模型在重要意义上已经是超人类的。不是因为它们比我们聪明，而是当我尝试解决问题、记忆和整合所有信息时，我无法保持上下文中的百万令牌，整个代码库。我认为我这样想是错的吗？这是一个巨大的突破吗？
- en: '**Sholto Douglas**  *00:03:14*'
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯**  *00:03:14*'
- en: Actually, I generally think that's true. Previously, I've been frustrated when
    models aren't as smart, when you ask them a question and you want it to be smarter
    than you or to know things that you don't. This allows them to know things that
    you don't. It just ingests a huge amount of information in a way you just can't.
    So it's extremely important.
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我通常认为这是真的。以前，当你问一个问题时，你希望模型比你更聪明，或者知道你不知道的事情时，我感到沮丧。这使它能够了解你不知道的事情。它只是以一种你无法的方式摄取大量信息。所以这非常重要。
- en: '**Dwarkesh Patel** *00:03:33*'
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:03:33*'
- en: Well, how do we explain [in-context learning](https://www.hopsworks.ai/dictionary/in-context-learning-icl#:~:text=In%2Dcontext%20learning%20(ICL)%20learns%20a%20new%20task%20from,objective%20of%20next%20token%20prediction.)?
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何解释[上下文学习](https://www.hopsworks.ai/dictionary/in-context-learning-icl#:~:text=In%2Dcontext%20learning%20(ICL)%20learns%20a%20new%20task%20from,objective%20of%20next%20token%20prediction.)？
- en: '**Sholto Douglas** *00:03:35*'
  id: totrans-split-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:03:35*'
- en: There's a [line of work](https://arxiv.org/pdf/2212.07677.pdf) I quite like,
    where it looks at in-context learning as basically very similar to gradient descent,
    but the attention operation can be viewed as [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent)
    on the in-context data. That paper had some cool plots where they basically showed
    “we take n steps of gradient descent and that looks like n layers of in-context
    learning, and it looks very similar.” So I think that's one way of viewing it
    and trying to understand what's going on.
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个我相当喜欢的[研究方向](https://arxiv.org/pdf/2212.07677.pdf)，它将上下文学习视为基本上与梯度下降非常相似，但注意力操作可以被视为对上下文数据的梯度下降。那篇论文展示了一些很酷的图表，“我们采取了梯度下降的
    n 步，看起来像 n 层上下文学习，并且非常相似。”所以我认为这是理解和尝试理解正在发生的事情的一种方式。
- en: '**Trenton Bricken** *00:03:59*'
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:03:59*'
- en: You can ignore what I'm about to say because, given the introduction, alignment
    is solved and AI safety isn't a problem.
  id: totrans-split-56
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以忽略我即将要说的，因为，考虑到介绍，对齐问题已解决，AI 安全性不是问题。
- en: I think the context stuff does get problematic, but also interesting here. I
    think there'll be more work coming out in the not-too-distant future around what
    happens if you give a hundred shot prompt for jailbreaks, [adversarial attacks](https://en.wikipedia.org/wiki/Adversarial_machine_learning).
    It's also interesting in the sense that, if your model is doing gradient descent
    and learning on the fly, even if it's been trained to be harmless, you're dealing
    with a totally new model in a way. You're [fine-tuning](https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning))
    but in a way where you can't control what's going on.
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为上下文的东西确实会变得棘手，但在这里也很有趣。我认为在不久的将来会有更多的工作出现，研究如果您为越狱提供了一百次尝试提示会发生什么，[对抗性攻击](https://en.wikipedia.org/wiki/Adversarial_machine_learning)。这也很有趣，因为，即使您的模型正在进行梯度下降并且在运行学习，即使它已经被训练成无害，您也在以一种全新的方式处理一个完全新的模型。您正在进行[微调](https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning))，但以一种您无法控制正在发生的方式。
- en: '**Dwarkesh Patel** *00:04:41*'
  id: totrans-split-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:04:41*'
- en: Can you explain? What do you mean by gradient descent happening in the [forward
    pass](https://towardsdatascience.com/neural-networks-forward-pass-and-backpropagation-be3b75a1cfcc)
    and attention?
  id: totrans-split-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你能解释一下吗？你说的前向传播中发生的梯度下降和注意力？
- en: '**Trenton Bricken** *00:04:45*'
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:04:45*'
- en: There was something in the paper about trying to teach the model to do linear
    regression but just through the number of samples or examples they gave in the
    context. And you can see if you plot on the x-axis the number of shots that it
    has, then the loss it gets on ordinary least squares regression will go down with
    time.
  id: totrans-split-61
  prefs: []
  type: TYPE_NORMAL
  zh: 有关试图通过提供的示例数量来教模型进行线性回归的内容。如果您在 x 轴上绘制它的次数，您会发现普通最小二乘回归的损失会随时间降低。
- en: '**Sholto Douglas** *00:05:04*'
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:05:04*'
- en: And it goes down exactly matched with the number of gradient descent steps.
  id: totrans-split-63
  prefs: []
  type: TYPE_NORMAL
  zh: 它确实与梯度下降步骤的数量完全匹配下降。
- en: '**Trenton Bricken** *00:05:08*'
  id: totrans-split-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:05:08*'
- en: Yeah, exactly.
  id: totrans-split-65
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，确实。
- en: '**Dwarkesh Patel** *00:05:09*'
  id: totrans-split-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:05:09*'
- en: I only read the intro and discussion section of that paper. But in the discussion,
    the way they framed it is that the model, in order to get better at long-context
    tasks, has to get better at learning to learn from these examples or from the
    context that is already within the window.
  id: totrans-split-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我只读了那篇论文的介绍和讨论部分。但在讨论中，他们所表述的方式是，模型为了在长上下文任务中变得更好，必须学会从这些示例或已存在于窗口内的上下文中学习。
- en: And the implication of that is, if meta-learning happens because it has to learn
    how to get better at long-context tasks, then in some important sense the task
    of intelligence requires long-context examples and long-context training.
  id: totrans-split-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，如果元学习发生，因为它必须学会如何在长上下文任务中变得更好，那么从某种重要意义上讲，智能的任务需要长上下文示例和长上下文训练。
- en: '**Sholto Douglas** *00:05:45*'
  id: totrans-split-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:05:45*'
- en: Understanding how to better induce meta-learning in your pre-training process
    is a very important thing about flexible or adaptive intelligence.
  id: totrans-split-70
  prefs: []
  type: TYPE_NORMAL
  zh: 理解如何在预训练过程中更好地诱导元学习是关于灵活或自适应智能非常重要的事情。
- en: '**Dwarkesh Patel** *00:05:53*'
  id: totrans-split-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:05:53*'
- en: Right, but you can proxy for that just by getting better at doing long-term
    context tasks. One of the bottlenecks for AI progress that many people identify
    is the inability of these models to perform tasks on long horizons, engaging with
    the task for many hours, or even many weeks or months, where they’re an assistant
    or an employee and they can just do a thing I tell them to do for a while. AI
    agents haven't taken off for this reason from what I understand.
  id: totrans-split-72
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，但你可以通过变得更擅长处理长期上下文任务来代理这一点。许多人认为，AI进展的一个瓶颈是这些模型无法在长期视野上执行任务，与任务交互许多小时，甚至许多周或几个月，他们是助手或员工，可以一段时间内做我告诉他们要做的事情。据我所知，AI代理之所以未能起飞，就是因为这个原因。
- en: So how linked are long context windows, and the ability to perform well on them,
    and the ability to do these kinds of long-horizon tasks that require you to engage
    with an assignment for many hours? Or are these unrelated concepts?
  id: totrans-split-73
  prefs: []
  type: TYPE_NORMAL
  zh: 那么长上下文窗口与能够在其上表现良好的能力，以及能够执行需要你花费多个小时进行任务的长期视野任务的能力，这两者之间有多少联系？或者这些概念是无关的？
- en: '**Sholto Douglas** *00:06:36*'
  id: totrans-split-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:06:36*'
- en: I would take issue with that being the reason that agents haven't taken off.
    I think that's more about [nines of reliability](https://en.wikipedia.org/wiki/High_availability#%22Nines%22)
    and the model actually successfully doing things. If you can't chain tasks successively
    with high enough probability, then you won't get something that looks like an
    agent. And that's why something like an agent might follow more of a step function.
  id: totrans-split-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我对代理未能起飞的原因持反对意见。我认为这更多地与[nines of reliability](https://en.wikipedia.org/wiki/High_availability#%22Nines%22)和模型实际成功执行任务有关。如果你不能以足够高的概率连续链式任务，那么你不会得到看起来像代理的东西。这就是为什么像代理这样的东西可能更像一个阶跃函数。
- en: In GPT-4 class models, Gemini Ultra class models, they're not enough. But maybe
    the next increment on model scale means that you get that extra nine. Even though
    the loss isn't going down that dramatically, that small amount of extra ability
    gives you the extra. Obviously you need some amount of context to fit long-horizon
    tasks, but I don't think that's been the limiting factor up to now.
  id: totrans-split-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在GPT-4级别的模型，Gemini Ultra级别的模型中，它们是不够的。但也许模型规模的下一个增量意味着你会得到额外的九。即使损失下降得并不那么显著，这种小额外能力也会给你带来额外的能力。显然，你需要一定量的上下文来适应长期任务，但我认为这到目前为止并不是限制因素。
- en: '**Trenton Bricken**  *00:07:16*'
  id: totrans-split-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:07:16*'
- en: The [NeurIPS best paper](https://neurips.cc/virtual/2023/poster/72117) this
    year, by [Rylan Schaeffer](https://rylanschaeffer.github.io/) who was the lead
    author, points to this as the emergence of mirage. People will have a task and
    you get the right or wrong answer depending on if you've sampled the last five
    tokens correctly. So naturally you're multiplying the probability of sampling
    all of those and if you don't have enough nines of reliability, then you're not
    going to get emergence.
  id: totrans-split-78
  prefs: []
  type: TYPE_NORMAL
  zh: 今年的[NeurIPS最佳论文](https://neurips.cc/virtual/2023/poster/72117)，由[Rylan Schaeffer](https://rylanschaeffer.github.io/)担任主要作者，指出这是幻觉的出现。人们会有一个任务，根据你是否正确采样了最后五个标记而得到正确或错误的答案。因此，你自然而然地会乘以采样所有这些的概率，如果你的可靠性不够高，那么你就不会获得出现。
- en: And all of a sudden you do and it's, “oh my gosh, this ability is emergent,”
    when actually it was kind of there to begin with.
  id: totrans-split-79
  prefs: []
  type: TYPE_NORMAL
  zh: 突然之间你就做到了，“哦，我的天啊，这种能力是出现的”，当实际上它从一开始就存在。
- en: '**Sholto Douglas** *00:07:47*'
  id: totrans-split-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:07:47*'
- en: And there are ways that you can find a smooth metric for that.
  id: totrans-split-81
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些方法可以找到平滑的度量标准。
- en: '**Dwarkesh Patel** *00:07:50*'
  id: totrans-split-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:07:50*'
- en: '[HumanEval](https://arxiv.org/abs/2107.03374) or whatever. In the [GPT-4 paper](https://cdn.openai.com/papers/gpt-4.pdf),
    the coding problems they have, they measure–'
  id: totrans-split-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[人工评估](https://arxiv.org/abs/2107.03374) 或其他什么。在[GPT-4论文](https://cdn.openai.com/papers/gpt-4.pdf)中，他们的编码问题，他们衡量–'
- en: '**Sholto Douglas** *00:07:56*'
  id: totrans-split-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:07:56*'
- en: Log pass rates
  id: totrans-split-85
  prefs: []
  type: TYPE_NORMAL
  zh: 记录通过率
- en: '**Dwarkesh Patel** *00:07:57*'
  id: totrans-split-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:07:57*'
- en: Exactly. For the audience, basically the idea is when you're measuring how much
    progress there has been on a specific task such as solving coding problems, when
    it gets it right only one in a thousand times you don't give it a one in a thousand
    score like, “oh, got it right some of the time.” And so the curve you see is,
    it gets it right one in a thousand, then one in a hundred, then one in ten, and
    so forth.
  id: totrans-split-87
  prefs: []
  type: TYPE_NORMAL
  zh: 没错。对于观众来说，基本上的想法是，当您测量特定任务（如解决编码问题）的进展程度时，当它只有千分之一的准确率时，您不会给它千分之一的得分，比如，“哦，有时候会做对。”因此，您看到的曲线是，它一开始千分之一做对，然后百分之一，然后十分之一，依此类推。
- en: So I want to follow up on this. If your claim is that the AI agents haven't
    taken off because of reliability rather than long-horizon task performance, isn't
    that lack of reliability–when a task is changed on top of another task, on top
    of another task–isn't that exactly the difficulty with long-horizon tasks? You
    have to do ten things in a row or a hundred things in a row, diminishing the reliability
    of any one of them. The probability goes down from 99.99% to 99.9%. Then the whole
    thing gets multiplied together and the whole thing has become so much less likely
    to happen.
  id: totrans-split-88
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我想继续讨论这个问题。如果你的观点是，AI代理人之所以没有起飞是因为可靠性问题，而不是长期任务的表现问题，那么这种缺乏可靠性——当一个任务在另一个任务之上进行变化，再加上另一个任务——这难道不正是长期任务的难点吗？你必须连续做十件事或一百件事，降低其中任何一项的可靠性。概率从99.99%降到99.9%。然后整个过程都要相乘，整个过程的发生概率变得更低。
- en: '**Sholto Douglas** *00:08:59*'
  id: totrans-split-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:08:59*'
- en: That is exactly the problem.But the key issue you're pointing out there is that
    your base task solve rate is 90%. If it was 99% then chain, it doesn't become
    a problem. I think this is also something that just hasn't been properly studied.
    If you look at the academic evals, it’s a single problem. Like the math problem,
    it's one typical math problem, it's one university-level problem from across different
    topics. You were beginning to start to see evals looking at this properly via
    more complex tasks like [SWE-bench](https://www.swebench.com/), where they take
    a whole bunch of GitHub issues. That is a reasonably long horizon task, but it's
    still sub-hour as opposed to a multi-hour or multi-day task.
  id: totrans-split-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这确实是问题所在。但你指出的关键问题是，你的基本任务解决率是90%。如果是99%，那么链式解决就不会成为问题。我认为这也是一些尚未得到适当研究的东西。如果你看一下学术评估，那就是一个单一的问题。就像数学问题一样，这是一个典型的数学问题，它是来自不同主题的一道大学水平的问题。你开始看到评估通过更复杂的任务来适当地观察，比如[SWE-bench](https://www.swebench.com/)，他们处理了大量的GitHub问题。这是一个相对较长的任务，但与多小时或多天的任务相比，仍然是次小时级别。
- en: So I think one of the things that will be really important to do next is understand
    better what success rate over long-horizon tasks looks like. I think that's even
    important to understand what the economic impact of these models might be and
    properly judge increasing capabilities. Cutting down the tasks and the inputs/outputs
    involved into minutes or hours or days and seeing how good it is at successively
    chaining and completing tasks of those different resolutions of time. Then that
    tells you how automated a job family or task family will be in a way that MMLU
    scores don't.
  id: totrans-split-91
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我认为下一步真正重要的事情之一是更好地理解长期任务的成功率是什么样子的。我认为这甚至重要于理解这些模型可能产生的经济影响，并适当评估不断增加的能力。将任务和涉及的输入/输出减少到分钟、小时或天，并看看在这些不同时间分辨率下，它在连续链接和完成任务方面的表现如何。然后，这告诉您一个工作家族或任务家族自动化程度的情况，而MMLU分数无法做到这一点。
- en: '**Trenton Bricken** *00:10:18*'
  id: totrans-split-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *00:10:18*'
- en: It was less than a year ago that we introduced [100K context windows](https://www.anthropic.com/news/100k-context-windows)
    and I think everyone was pretty surprised by that. Everyone had this soundbite
    of, “[quadratic attention costs](https://gwern.net/note/attention), so we can't
    have long context windows.” And here we are. The benchmarks are being actively
    made.
  id: totrans-split-93
  prefs: []
  type: TYPE_NORMAL
  zh: 不到一年前，我们推出了 [100K 上下文窗口](https://www.anthropic.com/news/100k-context-windows)，我认为每个人对此都感到非常惊讶。每个人都有这样一个说法，“二次注意力成本，所以我们不能有长的上下文窗口。”而我们现在却在这里。基准正在积极制定中。
- en: '**Dwarkesh Patel** *00:10:36*'
  id: totrans-split-94
  prefs: []
  type: TYPE_NORMAL
  zh: '-   **德瓦克什·帕特尔** *00:10:36*'
- en: Wait, doesn't the fact that there are these companies–Google, [Magic](https://magic.dev/),
    maybe others–who have million token attention imply that it's not quadratic anymore?
    Or are they just eating the cost?
  id: totrans-split-95
  prefs: []
  type: TYPE_NORMAL
  zh: 等等，难道这些公司——谷歌、[Magic](https://magic.dev/)，也许还有其他公司——有百万令牌的注意力，这不再是二次的了？还是他们只是在承担成本？
- en: '**Sholto Douglas** *00:10:50*'
  id: totrans-split-96
  prefs: []
  type: TYPE_NORMAL
  zh: '-   **肖尔托·道格拉斯** *00:10:50*'
- en: Well, who knows what Google is doing for its long context game? One thing has
    frustrated me about the general research field's approach to attention. There’s
    an important way in which the quadratic cost of attention is actually dominated
    in typical dense transformers by the MLP block. So you have this n squared term
    that's associated with attention but you also have an n squared term that's associated
    with the D model, the residual stream dimension of the model.
  id: totrans-split-97
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，谁知道 Google 为其长期上下文游戏做了什么？关于注意力的一般研究领域的方法让我感到沮丧。在典型的密集变压器中，注意力的二次成本实际上被 MLP
    块所主导。所以你有与注意力相关的 n 平方项，但你也有与模型的 D 模型相关的 n 平方项，模型的残留流维度。
- en: I think [Sasha Rush](https://rush-nlp.com/) has a great tweet where he basically
    plots the curve of the cost of attention respective to the cost of really large
    models and attention actually trails off. You actually need to be doing pretty
    long context before that term becomes really important.
  id: totrans-split-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为 [Sasha Rush](https://rush-nlp.com/) 在他的推特上有一条很棒的推文，基本上绘制了注意力成本与非常大模型成本的曲线，注意力实际上在这之后有所减少。实际上，你需要做相当长的上下文才能使这个术语变得非常重要。
- en: The second thing is that people often talk about how attention at inference
    time is such a huge cost. When you're actually generating tokens, the operation
    is not n squared. One set of Q-vectors looks up a whole bunch of KV-vectors and
    that's linear with respect to the amount of context that the model has.
  id: totrans-split-99
  prefs: []
  type: TYPE_NORMAL
  zh: 人们经常谈论推理时间的注意力是一个巨大的成本。当你实际生成标记时，这个操作不是 n 平方的。一组 Q 向量查找一堆 KV 向量，这与模型的上下文量是线性的。
- en: So I think this drives a lot of the recurrence and state space research where
    people have this meme of linear attention. And as Trenton said, there's a graveyard
    of ideas around attention. That’s not to say I don't think it's worth exploring,
    but I think it's important to consider why and where the actual strengths and
    weaknesses of it are.
  id: totrans-split-100
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我认为这驱动了很多关于循环和状态空间研究的发展，人们对线性注意力有这样一个梗。正如特伦顿所说，围绕注意力的想法有一个坟墓。这并不是说我不认为值得探索，但我认为重要的是考虑它的实际优势和劣势所在。
- en: '**Dwarkesh Patel**  *00:12:21*'
  id: totrans-split-101
  prefs: []
  type: TYPE_NORMAL
  zh: '-   **德瓦克什·帕特尔** *00:12:21*'
- en: Okay, what do you make of this take? As we move forward through the [takeoff](https://www.lesswrong.com/tag/ai-takeoff#:~:text=AI%20Takeoff%20refers%20to%20the,control%20the%20fate%20of%20civilization.),
    more and more of the learning happens in the forward pass. So originally all the
    learning happens in the bottom-up, [hill climbing](https://en.wikipedia.org/wiki/Hill_climbing)
    evolutionary process. Let’s say during the intelligence explosion the AI is maybe
    handwriting the weights or doing [GOFAI](https://en.wikipedia.org/wiki/GOFAI)
    or something, and we're in the middle step where a lot of learning happens in-context
    now with these models, a lot of it happens within the backward pass. Does this
    seem like a meaningful gradient along which progress is happening?
  id: totrans-split-102
  prefs: []
  type: TYPE_NORMAL
  zh: 好吧，你对这种看法有什么看法？随着我们向前迈进通过 [takeoff](https://www.lesswrong.com/tag/ai-takeoff#:~:text=AI%20Takeoff%20refers%20to%20the,control%20the%20fate%20of%20civilization.)，越来越多的学习发生在前向传递中。因此最初所有的学习发生在自下而上的
    [hill climbing](https://en.wikipedia.org/wiki/Hill_climbing) 进化过程中。让我们说在智能爆炸期间，AI
    可能正在手写权重或者进行 [GOFAI](https://en.wikipedia.org/wiki/GOFAI) 或其他什么，而我们现在处于中间阶段，这些模型现在的学习大部分发生在上下文中，很多发生在反向传递中。这似乎是一个有意义的进展梯度吗？
- en: The broader thing being that if you're learning in the forward pass, it's much
    more sample efficient because you can basically think as you're learning. Like
    when you read a textbook, you're not just skimming it and trying to absorb inductively,
    “these words follow these words.” You read it and you think about it, and then
    you read some more and you think about it some more. Does this seem like a sensible
    way to think about the progress?
  id: totrans-split-103
  prefs: []
  type: TYPE_NORMAL
  zh: 更广义的事情是，如果你在前向传播中学习，这样会更有效率，因为你可以在学习的同时思考。就像你阅读教科书时，不仅仅是匆匆浏览，试图归纳吸收，“这些词跟随这些词”。你阅读它，然后思考它，然后再读一些，再多思考一些。这似乎是一种理解进展的明智方式吗？
- en: '**Sholto Douglas** *00:13:23*'
  id: totrans-split-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:13:23*'
- en: It may just be like how birds and planes fly, but they fly slightly differently.
    The virtue of technology allows us to accomplish things that birds can't. It might
    be that context length is similar in that it allows it to have a working memory
    that we can't, but functionally is not the key thing towards actual reasoning.
  id: totrans-split-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能就像鸟类和飞机的飞行方式不同一样。技术的优点允许我们完成鸟类无法完成的事情。也许上下文长度类似，因为它允许它拥有我们无法拥有的工作记忆，但在功能上不是真正推理的关键。
- en: The key step between GPT-2 and GPT-3 was that all of a sudden there was this
    meta-learning behavior that was observed in training, in the pre-training of the
    model. And that has, as you said, something to do with how if you give it some
    amount of context, it's able to adapt to that context. That was a behavior that
    wasn't really observed before that at all. And maybe that's a mixture of property
    of context and scale and this kind of stuff. But it wouldn't have occurred to
    model tiny context, I would say.
  id: totrans-split-106
  prefs: []
  type: TYPE_NORMAL
  zh: GPT-2和GPT-3之间的关键一步是，突然之间在模型的预训练中观察到了这种元学习行为。正如你所说，这与给它一定量的上下文有关，它能够适应该上下文。这是以前根本没有观察到的行为。也许这是上下文和规模等因素的混合属性。但我会说，如果不给模型一个小的上下文，它不会发生。
- en: '**Dwarkesh Patel** *00:14:09*'
  id: totrans-split-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦尔克什·帕特尔** *00:14:09*'
- en: This is actually an interesting point. So when we talk about scaling up these
    models, how much of it comes from just making the models themselves bigger? And
    how much comes from the fact that during any single call you are using more compute?
  id: totrans-split-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是一个有趣的观点。所以当我们谈论扩展这些模型时，多少来自于只是使模型本身变得更大？又有多少来自于在任何单次调用中使用更多的计算资源？
- en: So if you think of diffusion, you can just iteratively keep adding more compute.
    If adaptive compute is solved, you can keep doing that. And in this case, if there's
    a quadratic penalty for attention but you're doing long context anyways, then
    you're still dumping in more compute ( and not just by having bigger models).
  id: totrans-split-109
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，如果你考虑到扩散，你可以通过迭代增加计算量来解决。如果自适应计算问题解决了，你可以继续这样做。在这种情况下，如果注意力有二次惩罚，但你仍然在进行长文本处理，那么你仍然会增加计算量（而不仅仅是通过拥有更大的模型）。
- en: '**Trenton Bricken** *00:14:46*'
  id: totrans-split-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *00:14:46*'
- en: It's interesting because you do get more forward passes by having more tokens.
    My one gripe–I guess I have two gripes with this though, maybe three.
  id: totrans-split-111
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，通过拥有更多的令牌，你确实可以进行更多的前向传播。我有一个抱怨 - 我想我对这个有两个抱怨，或许是三个。
- en: So in the [AlphaFold paper](https://www.nature.com/articles/s41586-021-03819-2),
    one of the transformer modules–they have a few and the architecture is very intricate–but
    they do, I think, five forward passes through it and will gradually refine their
    solution as a result.
  id: totrans-split-112
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在[AlphaFold论文](https://www.nature.com/articles/s41586-021-03819-2)中，其中一个变压器模块
    - 他们有几个，而且架构非常复杂 - 但他们确实通过它进行了五次前向传播，并逐步改进了他们的解决方案。
- en: You can also kind of think of the residual stream, Sholto alluded to the read-write
    operations, as a poor man's adaptive compute. Where it's just going to give you
    all these layers and if you want to use them, great. If you don't, then that's
    also fine. Then people will be like, “oh the brain is recurrent and you can do
    however many loops through it you want.”
  id: totrans-split-113
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以把剩余流想象成一个穷人版的自适应计算，肖尔托提到了读写操作。如果你想使用它们，那很好。如果不想，那也没关系。然后人们会说，“哦，大脑是循环的，你可以通过任意循环次数进行操作。”
- en: I think to a certain extent, that's right. If I ask you a hard question, you'll
    spend more time thinking about it and that would correspond to more forward passes.
    But I think there's a finite number of forward passes that you can do. It’s with
    language as well, people are like “oh human language can have infinite recursion
    in it,” like infinite nested statements of “the boy jumped over the bear, that
    was doing this, that had done this, that had done that…”
  id: totrans-split-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我想在某种程度上，这是正确的。如果我问你一个难题，你会花更多时间考虑它，这相当于更多的前向传播。但我认为你可以做的前向传播数量是有限的。这也适用于语言，人们说“哦，人类语言可以在其中有无限的递归”，就像“男孩跳过那只正在做这个的熊，那只已经做了这个，那只已经做了那个…”
- en: But empirically, you'll only see five to seven levels of recursion, which relates
    to that [magic number](https://psycnet.apa.org/record/1957-02914-001) of how many
    things you can hold in working memory at any given time. So it's not infinitely
    recursive, but does that matter in the regime of human intelligence? And can you
    not just add more layers?
  id: totrans-split-115
  prefs: []
  type: TYPE_NORMAL
  zh: 但经验上，你只会看到五到七层的递归，这与你可以在任何给定时间内在工作记忆中保存多少事物的[魔术数字](https://psycnet.apa.org/record/1957-02914-001)相关。因此它不是无限递归的，但在人类智能的范畴内这是否重要？你不能仅仅添加更多的层吗？
- en: '**Dwarkesh Patel**  *00:16:12*'
  id: totrans-split-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:16:12*'
- en: Can you break it down for me? You've referred to this in some of your previous
    answers of listening to these long contexts and holding more things in memory.
    But ultimately it comes down to your ability to mix concepts together to do some
    kind of reasoning and these models aren't necessarily human level at that, even
    in context.
  id: totrans-split-117
  prefs: []
  type: TYPE_NORMAL
  zh: 你能为我解释一下吗？在你之前的一些回答中，你提到了听这些长篇大论并在记忆中保存更多内容的能力。但归根结底，这取决于你将概念混合在一起进行某种推理的能力，而这些模型在这方面可能并不一定达到人类水平，即使在某种上下文中也不是。
- en: Break down for me how you see just storing raw information versus reasoning
    and what's in between. Like, where's the reasoning happening? Where is this raw
    information storage happening? What's different between them in these models?
  id: totrans-split-118
  prefs: []
  type: TYPE_NORMAL
  zh: 帮我分解一下你是如何看待仅存储原始信息与推理及其之间的关系的。比如，推理发生在哪里？在这些模型中，原始信息存储发生在哪里？它们之间有什么不同？
- en: '**Trenton Bricken**  *00:16:46*'
  id: totrans-split-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *00:16:46*'
- en: I don't have a super crisp answer for you here. Obviously with the input and
    output of the model, you're mapping back to actual tokens. And then in between
    that you're doing higher level processing.
  id: totrans-split-120
  prefs: []
  type: TYPE_NORMAL
  zh: 对于你这里，我没有一个特别明确的答案。显然，模型的输入和输出是在映射回实际令牌。然后在这之间进行更高层次的处理。
- en: '**Dwarkesh Patel** *00:17:01*'
  id: totrans-split-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:17:01*'
- en: Before we get deeper into this, we should explain to the audience. You referred
    earlier to [Anthropic's way of thinking about transformers](https://transformer-circuits.pub/2021/framework/index.html)
    as these read-write operations that layers do.
  id: totrans-split-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入讨论之前，我们应该向观众解释一下。你之前提到过[Anthropic关于变压器的思考方式](https://transformer-circuits.pub/2021/framework/index.html)，就像这些层所做的读写操作。
- en: One of you should just kind of explain at a high level what you mean by that.
  id: totrans-split-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你们其中一位应该在高层次上解释一下你们所说的。
- en: '**Trenton Bricken**  *00:17:15*'
  id: totrans-split-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *00:17:15*'
- en: So for the residual stream, imagine you're in a boat going down a river and
    the boat is the current query where you're trying to predict the next token. So
    it's “the cat sat on the _____.” And then you have these little streams that are
    coming off the river where you can get extra passengers or collect extra information
    if you want. And those correspond to the attention heads and MLPs that are part
    of the model.
  id: totrans-split-125
  prefs: []
  type: TYPE_NORMAL
  zh: 所以对于残留流，想象一下你在一条河上的船上，这条船就是当前的查询，你试图预测下一个令牌。“猫坐在_____上。”然后你有一些小流从河上流出，你可以获取额外的乘客或者收集额外的信息。这些对应于模型中的注意力头和MLP。
- en: '**Sholto Douglas**  *00:17:41*'
  id: totrans-split-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:17:41*'
- en: I almost think of it like the working memory of the model, like the RAM of the
    computer, where you're choosing what information to read in so you can do something
    with it and then maybe read something else in later on.
  id: totrans-split-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我几乎把它看作模型的工作记忆，就像计算机的RAM，你在选择要读入的信息，以便能够处理它，然后可能稍后再读入其他信息。
- en: '**Trenton Bricken** *00:17:54*'
  id: totrans-split-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *00:17:54*'
- en: And you can operate on subspaces of that high-dimensional vector. At this point,
    I think it's almost given that a ton of things are encoded in superposition. So
    the residual stream is just one high-dimensional vector, but actually there's
    a ton of different vectors that are packed into it.
  id: totrans-split-129
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在那个高维向量的子空间上操作。我认为现在几乎可以确定有大量事物被编码为叠加状态。因此，残余流只是一个高维向量，但实际上其中包含了大量不同的向量。
- en: '**Dwarkesh Patel**  *00:18:12*'
  id: totrans-split-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔**  *00:18:12*'
- en: To dumb it down, a way that would have made sense to me a few months ago is
    that you have the words that are the input into the model. All those words get
    converted into these tokens and those tokens get converted into these vectors.
    And basically, it's just this small amount of information that's moving through
    the model.
  id: totrans-split-131
  prefs: []
  type: TYPE_NORMAL
  zh: 简化来说，几个月前对我来说有意义的一种方式是，你有输入到模型中的单词。所有这些单词被转换为这些标记，而这些标记被转换为这些向量。基本上，通过模型传递的只是这小量信息。
- en: And the way you explained it to me, Sholto, this [paper](https://transformer-circuits.pub/2021/framework/index.html)
    talks about how early on in the model, maybe it's just doing some very basic things
    about, “what do these tokens mean?” Like if it says ten plus five, just moving
    information to have that good representation. And in the middle, maybe the deeper
    thinking is happening about “how to solve this.” At the end, you're converting
    it back into the output token because the end product is that you're trying to
    predict the probability of the next token from the last of those residual streams.
    So it's interesting to think about the small compressed amount of information
    moving through the model and how it's getting modified in different ways.
  id: totrans-split-132
  prefs: []
  type: TYPE_NORMAL
  zh: 你向我解释的方式是，Sholto，这篇[论文](https://transformer-circuits.pub/2021/framework/index.html)讨论了模型早期可能只是做一些非常基础的事情，“这些标记意味着什么？”比如说十加五，只是传递信息以获得好的表示。在中期，也许会发生更深入的思考，“如何解决这个问题。”最后，你会将它转换回输出标记，因为最终产品是你试图从这些残余流的最后预测下一个标记的概率。因此，思考模型中移动的这小量压缩信息以及不同方式如何修改它是很有趣的。
- en: Trenton, you're one of the few people who have a background from neuroscience.
    So you can think about the analogies here to the brain. And in fact, you had a
    [paper](https://arxiv.org/abs/2111.05498) in grad school about thinking about
    attention in the brain, and one of our friend’s said this is the only, or first,
    neural explanation of why attention works. Whereas we have evidence for why the
    CNNs, [convolutional neural networks](https://en.wikipedia.org/wiki/Convolutional_neural_network),
    work based on the visual cortex or something.
  id: totrans-split-133
  prefs: []
  type: TYPE_NORMAL
  zh: 特伦顿，你是少数几个具有神经科学背景的人之一。因此你可以将这里的类比与大脑联系起来。事实上，在研究生阶段，你曾发表过一篇[论文](https://arxiv.org/abs/2111.05498)，探讨大脑中注意力的思考。我们的一个朋友说这是关于注意力为何有效的唯一或首个神经解释。而对于为何卷积神经网络（[卷积神经网络](https://en.wikipedia.org/wiki/Convolutional_neural_network)）有效，我们有基于视觉皮层或其他什么的证据。
- en: Do you think in the brain there is something like a residual stream of compressed
    information that's moving through and getting modified as you're thinking about
    something? Even if that's not what's literally happening, do you think that's
    a good metaphor for what's happening in the brain?
  id: totrans-split-134
  prefs: []
  type: TYPE_NORMAL
  zh: 你认为大脑中是否有类似于残余流的压缩信息正在移动并在思考某事时被修改？即使这不是文字意义上的情况，你认为这是大脑中正在发生的事情的一个好比喻吗？
- en: '**Trenton Bricken**  *00:20:04*'
  id: totrans-split-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯**  *00:20:04*'
- en: At least in the cerebellum you basically do have a residual stream in what we'll
    call the attention model for now–and I can go into whatever amount of detail you
    want for that–where you have inputs that route through it, but they'll also just
    go directly to the end point that that module will contribute to. So there's a
    direct path and an indirect path. and, and so the model can pick up whatever information
    it wants and then add that back in.
  id: totrans-split-136
  prefs: []
  type: TYPE_NORMAL
  zh: 至少在小脑中，基本上确实有一个我们暂时称之为注意模型的残余流，我可以详细解释一下——你希望了解多少我就可以详细讨论——它的输入会通过它，但它们也会直接到达模块的末端。因此有一条直接路径和一条间接路径。模型可以捕捉到任何它想要的信息，然后将其添加回去。
- en: '**Dwarkesh Patel** *00:20:35*'
  id: totrans-split-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:20:35*'
- en: What happens in the cerebellum?
  id: totrans-split-138
  prefs: []
  type: TYPE_NORMAL
  zh: 小脑中发生了什么？
- en: '**Trenton Bricken**  *00:20:37*'
  id: totrans-split-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯**  *00:20:37*'
- en: So the cerebellum nominally just does fine motor control but I analogize this
    to the person who's lost their keys and is just looking under the streetlight
    where it's very easy to observe this behavior. One leading cognitive neuroscientist
    said to me that a dirty little secret of any fMRI study, where you're looking
    at brain activity for a given task, is that the cerebellum is almost always active
    and lighting up for it. If you have a damaged cerebellum, you also are much more
    likely to have autism so it's associated with social skills. In one particular
    study, where I think they use PET instead of fMRI, when you're doing “next token
    prediction” the cerebellum lights up a lot. Also, 70% of your neurons in the brain
    are in the cerebellum. They're small but they're there and they're taking up real
    metabolic cost.
  id: totrans-split-140
  prefs: []
  type: TYPE_NORMAL
  zh: 所以小脑名义上只是进行精细运动控制，但我将其类比为丢失钥匙并且只是在路灯下观察这种行为的人。一位领先的认知神经科学家对我说，在任何fMRI研究中的一个肮脏的小秘密，你在其中观察给定任务的大脑活动时，小脑几乎总是活跃并且为之点亮。如果你的小脑受损，你也更有可能患有自闭症，因此它与社交技能相关联。在一项特定研究中，我认为他们使用PET而不是fMRI时，当你在进行“下一个标记预测”时，小脑会大量点亮。此外，你大脑中的70%的神经元位于小脑中。它们很小，但它们存在并且占据真实的代谢成本。
- en: '**Dwarkesh Patel**  *00:21:29*'
  id: totrans-split-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:21:29*'
- en: This was one of [Gwern](https://gwern.net/)’s points, that what changed with
    humans was not just that we have more neurons, but specifically there's [more
    neurons in the cerebral cortex](https://gwern.net/doc/psychology/neuroscience/2012-herculanohouzel.pdf)
    in the cerebellum and they're more metabolically expensive and they're more involved
    in signaling and sending information back and forth. Is that attention? What's
    going on?
  id: totrans-split-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这是[Gwern](https://gwern.net/)的一个观点，即人类的变化不仅在于我们拥有更多的神经元，而且特别是在大脑皮层和小脑中有更多的神经元，并且它们在代谢上更昂贵，更多地参与信号发送和信息来回传递。那是注意力吗？到底发生了什么？
- en: '**Trenton Bricken** *00:21:52*'
  id: totrans-split-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *00:21:52*'
- en: So back in the 1980s, [Pentti Kanerva](https://en.wikipedia.org/wiki/Pentti_Kanerva)
    came up with an [associative memory algorithm](https://en.wikipedia.org/wiki/Sparse_distributed_memory).
    You have a bunch of memories. You want to store them. There's some amount of noise
    or corruption that's going on and you want to query or retrieve the best match.
    And so he wrote this equation for how to do it and a few years later realized
    that if you implemented this as an electrical engineering circuit, it actually
    looks identical to the core cerebellar circuit.
  id: totrans-split-144
  prefs: []
  type: TYPE_NORMAL
  zh: 所以回到1980年代，[彭蒂·卡纳尔瓦](https://en.wikipedia.org/wiki/Pentti_Kanerva)提出了[联想记忆算法](https://en.wikipedia.org/wiki/Sparse_distributed_memory)。你有一堆记忆。你想存储它们。这里有一些正在发生的噪声或损坏，你想查询或检索最佳匹配。因此，他写下了这个方程，如何去做，几年后意识到，如果你将其实现为电气工程电路，它实际上看起来与核心小脑电路完全相同。
- en: And that circuit, and the cerebellum more broadly, is not just in us, it's in
    basically every organism. There's active debate on whether or not cephalopods
    have it, they kind of have a different evolutionary trajectory. But even for fruit
    flies with the [Drosophila](https://en.wikipedia.org/wiki/Drosophila)  [mushroom
    body](https://en.wikipedia.org/wiki/Mushroom_bodies), that is the same cerebellar
    architecture.
  id: totrans-split-145
  prefs: []
  type: TYPE_NORMAL
  zh: 那个电路，以及更广泛的小脑，不仅仅存在于我们身上，它基本上存在于每一个有机体中。关于头足类动物是否具有它，有活跃的争论，它们可能有不同的进化轨迹。但即使是果蝇的[Drosophila](https://en.wikipedia.org/wiki/Drosophila)[蘑菇体](https://en.wikipedia.org/wiki/Mushroom_bodies)，也是相同的小脑结构。
- en: That convergence and then my paper, which shows that actually this attention
    operation is a very close approximation, including implementing the Softmax and
    having these nominal quadratic costs that we've been talking about. So the three
    way convergence here and the takeoff and success of transformers, just seems pretty
    striking to me.
  id: totrans-split-146
  prefs: []
  type: TYPE_NORMAL
  zh: 那个收敛然后我的文章，它显示实际上这个注意力操作是一个非常接近的近似，包括实现Softmax并拥有我们一直在谈论的这些名义二次成本。所以这里的三路收敛和变压器的起飞与成功，对我来说显得非常引人注目。
- en: '**Dwarkesh Patel** *00:23:04*'
  id: totrans-split-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:23:04*'
- en: I want to zoom out. I think what motivated this discussion in the beginning
    was we were talking about, “what is the reasoning? What is the memory? What do
    you think about the analogy you found to attention and this?”
  id: totrans-split-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我想放大视角。我认为最初促使这场讨论的是我们在谈论，“推理是什么？记忆是什么？你对你发现的注意力和这个类比有什么看法？”
- en: Do you think of this more as just looking up the relevant memories or the relevant
    facts? And if that is the case, where is the reasoning happening in the brain?
    How do we think about how that builds up into the reasoning?
  id: totrans-split-149
  prefs: []
  type: TYPE_NORMAL
  zh: 你认为这更像是查找相关记忆还是相关事实吗？如果是这样，大脑中的推理发生在哪里？我们如何思考这些如何建立成推理的？
- en: '**Trenton Bricken** *00:23:33*'
  id: totrans-split-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *00:23:33*'
- en: Maybe my hot take here, I don't know how hot it is, is that most intelligence
    is pattern matching and you can do a lot of really good pattern matching if you
    have a hierarchy of associative memories. You start with your very basic associations
    between just objects in the real world. You can then chain those and have more
    abstract associations, such as a wedding ring symbolizing so many other associations
    that are downstream. You can even generalize the attention operation and this
    associated memory as the MLP layer as well. And it's in a long-term setting where
    you don't have tokens in your current context, but I think this is an argument
    that association is all you need.
  id: totrans-split-151
  prefs: []
  type: TYPE_NORMAL
  zh: 或许我的观点有点独特，我不知道它有多独特，大部分智力是模式匹配，如果你有一个层次化的关联记忆，你可以做很多非常好的模式匹配。你从最基本的现实世界中的物体之间的关联开始。然后你可以链式反应，有更抽象的关联，比如结婚戒指象征着很多下游的其他关联。你甚至可以将注意力操作和这种关联记忆一样看作是MLP层。在长期设置中，你当前上下文中没有令牌，但我认为这是一种关联就是你所需的论点。
- en: Associated memory in general as well, you can do two things with it. You can
    both, denoise or retrieve a current memory. So if I see your face but it's raining
    and cloudy, I can denoise and gradually update my query towards my memory of your
    face. But I can also access that memory and then the value that I get out actually
    points to some other totally different part of the space.
  id: totrans-split-152
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，关联记忆也有两种作用。你可以去除噪音或检索当前记忆。所以如果我看到你的脸，但天在下雨而且多云，我可以去噪音并逐渐更新我的查询，朝向我对你脸的记忆。但我也可以访问那个记忆，然后我得到的值实际上指向空间中的其他完全不同的部分。
- en: A very simple instance of this would be if you learn the alphabet. So I query
    for A and it returns B, I query for B and it returns C, and you can traverse the
    whole thing.
  id: totrans-split-153
  prefs: []
  type: TYPE_NORMAL
  zh: 一个非常简单的例子是，如果你学习字母表。所以我查询A它返回B，我查询B它返回C，你可以遍历整个过程。
- en: '**Dwarkesh Patel** *00:25:02*'
  id: totrans-split-154
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:25:02*'
- en: One of the things I [talked to Demis](https://www.dwarkeshpatel.com/p/demis-hassabis)
    about was a [paper](https://www.jneurosci.org/content/27/52/14365) he had in 2008
    that memory and imagination are very linked because of this very thing that you
    mentioned, that [memory is reconstructive](https://en.wikipedia.org/wiki/Reconstructive_memory).
    So you are, in some sense, imagining every time you're thinking of a memory because
    you're only storing a condensed version of it and you have to. This is famously
    why human memory is terrible and why people in the witness box or whatever would
    just make shit up.
  id: totrans-split-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我与[Demi斯](https://www.dwarkeshpatel.com/p/demis-hassabis)讨论的其中一件事是他在2008年的[论文](https://www.jneurosci.org/content/27/52/14365)，提到了记忆和想象之间的紧密联系，因为正如你提到的那样，[记忆是重建的](https://en.wikipedia.org/wiki/Reconstructive_memory)。所以在某种意义上，每当你回想起一个记忆时，你其实是在想象，因为你只存储了它的一个压缩版本，而且必须如此。这就是为什么人类记忆糟糕的原因，也是为什么在证人席上或其他地方的人们只会编造东西。
- en: So let me ask a stupid question. So you read Sherlock Holmes and the guy's incredibly
    sample efficient. He'll see a few observations and he'll basically figure out
    who committed the crime because there's a series of deductive steps that leads
    from somebody's tattoo and what's on the wall to the implications of that. How
    does that fit into this picture? Because crucially, what makes him smart is that
    there's not just an association, but there's a sort of deductive connection between
    different pieces of information. Would you just explain it as, that's just higher
    level association?
  id: totrans-split-156
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我问一个愚蠢的问题。所以你读过福尔摩斯，这家伙的样本效率令人难以置信。他会看到几个观察结果，基本上就能够确定谁犯了罪，因为从某人的纹身和墙上的东西到其所暗示的推断步骤，这一系列的演绎步骤。这怎么符合这个画面？因为关键在于，他之所以聪明，并不仅仅是因为有一个关联，而是因为不同信息片段之间存在一种演绎连接。你是否将其解释为，这只是更高层次的关联？
- en: '**Trenton Bricken**  *00:26:11*'
  id: totrans-split-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *00:26:11*'
- en: I think so. I think learning these higher-level associations to be able to then
    map patterns to each other, as a kind of meta-learning. I think in this case,
    he would also just have a really long context length, or a really long working
    memory, where he can have all of these bits and continuously query them as he's
    coming up with some theory so that the theory is moving through the residual stream.
    And then his attention heads are querying his context. But then, how he's projecting
    his query and keys in the space, and how his MLPs are then retrieving longer-term
    facts or modifying that information, is allowing him to in later layers do even
    more sophisticated queries and slowly be able to reason through and come to a
    meaningful conclusion.
  id: totrans-split-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我想是的。我认为学习这些更高级的关联，以便能够将模式映射到彼此之间，作为一种元学习。在这种情况下，我认为他也会有一个非常长的上下文长度，或者一个非常长的工作记忆，他可以在想出一些理论时持续查询它们，所以这个理论在经过残差流时移动。然后他的注意力头在查询他的上下文。但是，他如何在空间中投射他的查询和键，以及他的MLP如何检索长期事实或修改那些信息，使得他能够在后续层次中进行更复杂的查询，并逐渐能够推理出并得出有意义的结论。
- en: '**Sholto Douglas**  *00:27:00*'
  id: totrans-split-159
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas**  *00:27:00*'
- en: That feels right to me. You're looking back in the past. You're selectively
    reading in certain pieces of information, comparing them, and maybe that informs
    your next step of what piece of information you now need to pull in. Then you
    build this representation, which progressively looks closer and closer to the
    suspect in your case. That doesn't feel at all outlandish.
  id: totrans-split-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这对我来说感觉是正确的。你回顾过去。你有选择性地阅读某些信息，比较它们，也许这会告诉你下一步需要引入的信息是什么。然后你建立这个表示，逐步看起来越来越接近你案件中的嫌疑人。这一点一点都不显得奇怪。
- en: '**Trenton Bricken** *00:27:20*'
  id: totrans-split-161
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:27:20*'
- en: I think that the people who aren't doing this research can overlook how after
    your first layer of the model, every query key and value that you're using for
    attention comes from the combination of all the previous tokens.
  id: totrans-split-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为那些没有进行这项研究的人可能会忽视，即在模型的第一层之后，每个用于注意力的查询键和值都来自于所有先前标记的组合。
- en: So my first layer, I'll query my previous tokens and just extract information
    from them. But all of a sudden, let's say that I attended to tokens 1, 2, and
    4 in equal amounts. Then the vector in my residual stream–assuming that they wrote
    out the same thing to the value vectors, but, but ignore that for a second–is
    a third of each of those. So when I'm querying in the future, my query is actually
    a third of each of those things.
  id: totrans-split-163
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我的第一层，我会查询我的先前的标记，只是从中提取信息。但突然之间，假设我同等重视标记1、2和4。那么在我的残差流中的向量——假设它们向值向量中写出了相同的东西，但是，先不考虑这个——是这些东西的三分之一。所以当我未来查询时，我的查询实际上是这些东西的三分之一。
- en: '**Sholto Douglas** *00:28:03*'
  id: totrans-split-164
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:28:03*'
- en: But they might be written to different subspaces.
  id: totrans-split-165
  prefs: []
  type: TYPE_NORMAL
  zh: 但它们可能写在不同的子空间里。
- en: '**Trenton Bricken** *00:28:05*'
  id: totrans-split-166
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:28:05*'
- en: That's right. Hypothetically, but they wouldn't have to. You can recombine and
    immediately, even by layer two and certainly by the deeper layers, just have these
    very rich vectors that are packing in a ton of information. And the causal graph
    is literally over every single layer that happened in the past. That's what you're
    operating on.
  id: totrans-split-167
  prefs: []
  type: TYPE_NORMAL
  zh: 没错。假设是这样，但他们不必这样做。你可以重新组合，立即，在第二层甚至更深层次，就有这些非常丰富的向量，它们包含大量信息。而且因果图实际上涵盖了过去的每一层。这就是你正在操作的。
- en: '**Sholto Douglas** *00:28:25*'
  id: totrans-split-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:28:25*'
- en: Yeah, it does bring to mind a very funny eval to do, a Sherlock Holmes eval.
    You put the entire book into context and then you have a sentence which is, “the
    suspect is X.” Then you have a larger probability distribution over the different
    characters in the book.
  id: totrans-split-169
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这确实让人联想到一个非常有趣的评估，就像是一次福尔摩斯式的评估。你把整本书放在背景里，然后有一个句子是，“嫌疑人是X。”然后你有一个更大的概率分布覆盖书中不同的角色。
- en: '**Trenton Bricken**  *00:28:41*'
  id: totrans-split-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken**  *00:28:41*'
- en: That would be super cool.
  id: totrans-split-171
  prefs: []
  type: TYPE_NORMAL
  zh: 那会很酷。
- en: '**Sholto Douglas**  *00:28:44*'
  id: totrans-split-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas**  *00:28:44*'
- en: I wonder if you'd get anything at all.
  id: totrans-split-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我不知道你会得到什么东西。
- en: '**Dwarkesh Patel** *00:28:47*'
  id: totrans-split-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:28:47*'
- en: Sherlock Holmes is probably already in the training data. You gotta get a mystery
    novel that was written in the–
  id: totrans-split-175
  prefs: []
  type: TYPE_NORMAL
  zh: 福尔摩斯可能已经在训练数据中了。你得拿到一本在——
- en: '**Trenton Bricken** *00:28:52*'
  id: totrans-split-176
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:28:52*'
- en: You can get an LLM to write it.
  id: totrans-split-177
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以让一个LLM来写。
- en: '**Sholto Douglas** *00:28:53*'
  id: totrans-split-178
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:28:53*'
- en: Or we could purposely exclude it, right?
  id: totrans-split-179
  prefs: []
  type: TYPE_NORMAL
  zh: 或者我们可以故意排除它，对吧？
- en: '**Dwarkesh Patel** *00:28:56*'
  id: totrans-split-180
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:28:56*'
- en: Oh, we can? How do you?
  id: totrans-split-181
  prefs: []
  type: TYPE_NORMAL
  zh: 哦，我们可以？你是怎么做到的？
- en: '**Trenton Bricken** *00:28:57*'
  id: totrans-split-182
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:28:57*'
- en: Well, you need to scrape any discussion of it from Reddit or any other thing.
  id: totrans-split-183
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，你需要从 Reddit 或其他地方清理关于它的任何讨论。
- en: '**Sholto Douglas** *00:29:00*'
  id: totrans-split-184
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:29:00*'
- en: Right, it's hard. That's one of the challenges that goes into things like long-context
    evals, getting a good one. You need to know that it's not in your training data.
    You just put in the effort to exclude it.
  id: totrans-split-185
  prefs: []
  type: TYPE_NORMAL
  zh: 对，这很难。这是长上下文评估之类事情的挑战之一。你需要知道它不在你的训练数据中。你只需努力排除它。
- en: '**Dwarkesh Patel**  *00:29:10*'
  id: totrans-split-186
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:29:10*'
- en: There's two different threads I want to follow up on. Let's go to the long-context
    one and then we'll come back to this. In the [Gemini 1.5 paper](https://arxiv.org/abs/2403.05530)
    the eval that was used was can it remember something like [Paul Graham’s essays](https://paulgraham.com/articles.html).
  id: totrans-split-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我想跟进两个不同的线索。让我们先去长上下文，然后我们再回到这个。在[Gemini 1.5 论文](https://arxiv.org/abs/2403.05530)中，使用的评估是否能记住像[保罗·格雷厄姆的文章](https://paulgraham.com/articles.html)这样的内容。
- en: '**Sholto Douglas**  *00:29:28*'
  id: totrans-split-188
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:29:28*'
- en: Yeah, the [needle in a haystack](https://twitter.com/JeffDean/status/1758146211029405951).
  id: totrans-split-189
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，就像 [大海里的一根针](https://twitter.com/JeffDean/status/1758146211029405951)。
- en: '**Dwarkesh Patel**  *00:29:30*'
  id: totrans-split-190
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:29:30*'
- en: I mean, we don't necessarily just care about its ability to recall one specific
    fact from the context.
  id: totrans-split-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我的意思是，我们不一定只关心它从上下文中召回一个特定的事实的能力。
- en: I'll step back and ask the question. The loss function for these models is unsupervised.
    You don't have to come up with these bespoke things that you keep out of the training
    data.
  id: totrans-split-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我会退后一步问这个问题。这些模型的损失函数是无监督的。你不必想出那些专门的东西，使其远离训练数据。
- en: Is there a way you can do a benchmark that's also unsupervised, where another
    LLM is rating it in some way or something like that. Maybe the answer is that
    if you could do this, [reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning)
    would work.
  id: totrans-split-193
  prefs: []
  type: TYPE_NORMAL
  zh: 是否有一种方式可以做一个基准测试，也是无监督的，另一个语言模型在某种程度上对其进行评分或类似的事情。也许答案是，如果你能做到这一点，[强化学习](https://zh.wikipedia.org/wiki/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0)
    将会起作用。
- en: '**Sholto Douglas** *00:30:05*'
  id: totrans-split-194
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:30:05*'
- en: I think people have explored that kind of stuff. For example, Anthropic has
    the [constitutional RL paper](https://www.anthropic.com/news/claudes-constitution)
    where they take another language model and they point it and say, “how helpful
    or harmless was that response?” Then they get it to update and try and improve
    along the Pareto frontier of helpfulness and harmfulness.
  id: totrans-split-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为人们已经探讨过那种事情。例如，Anthropic 公司有一篇[宪法强化学习论文](https://www.anthropic.com/news/claudes-constitution)，他们拿另一个语言模型，然后指向它，说，“这个回应有多么有帮助或无害？”
    然后他们让它更新并尝试在帮助性和有害性的 Pareto 边界上改进。
- en: So you can point language models at each other and create evals in this way.
    It's obviously an imperfect art form at the moment. because you get [reward function
    hacking](https://arxiv.org/abs/2209.13085) basically. Even humans are imperfect
    here. Humans typically prefer longer answers, which aren't necessarily better
    answers and you get the same behavior with models.
  id: totrans-split-196
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你可以让语言模型相互指向并以这种方式创建评估。显然，目前这还是一门不完美的艺术形式。因为你会得到[奖励函数破解](https://arxiv.org/abs/2209.13085)。即使人类在这里也是不完美的。人类通常更喜欢更长的答案，这并不一定是更好的答案，而模型也表现出相同的行为。
- en: '**Dwarkesh Patel** *00:30:48*'
  id: totrans-split-197
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:30:48*'
- en: Going back to the Sherlock Holmes thing, if it's all associations all the way
    down, does that mean we should be less worried about super intelligence? Because
    there's not this sense in which it's like Sherlock Holmes++. It'll still need
    to just find these associations, like humans find associations. It's not able
    to just see a frame of the world and then it's figured out all the laws of physics.
  id: totrans-split-198
  prefs: []
  type: TYPE_NORMAL
  zh: 回到夏洛克·福尔摩斯的事情，如果所有的关联一直延续下去，这是否意味着我们不应该过分担心超级智能？因为没有这种感觉，就像是夏洛克·福尔摩斯++。它仍然需要像人类一样发现这些关联。它不能只看到世界的一个框架，然后就弄清楚了所有的物理定律。
- en: '**Trenton Bricken** *00:31:20*'
  id: totrans-split-199
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:31:20*'
- en: This is a very legitimate response.It's, “if you say humans are generally intelligent,
    then artificial general intelligence is no more capable or competent.” I'm just
    worried that you have that level of general intelligence in silicon. You can then
    immediately clone hundreds of thousands of agents and they don't need to sleep,
    and they can have super long context windows, and then they can start recursively
    improving, and then things get really scary. So I think to answer your original
    question, you're right, they would still need to learn associations.
  id: totrans-split-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常合理的回应。就是，“如果你说人类一般具有智能，那么人工通用智能也不会更有能力或者更有竞争力。” 我只是担心你在硅中有那种普遍智能水平。然后你可以立即克隆成千上万的代理人，他们不需要睡觉，可以拥有超长的上下文窗口，然后可以开始递归改进，事情变得真的很可怕。所以我认为回答你最初的问题，你是对的，他们仍然需要学习关联。
- en: '**Dwarkesh Patel** *00:31:52*'
  id: totrans-split-201
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:31:52*'
- en: But wait, if intelligence is fundamentally about these associations, the recursive
    self-improvement is just them getting better at association. There's not another
    thing that's happening. So then it seems like you might disagree with the intuition
    that they can't be that much more powerful, if they're just doing that.
  id: totrans-split-202
  prefs: []
  type: TYPE_NORMAL
  zh: 但等等，如果智能基本上是关于这些关联，那么递归自我改进只是它们变得更擅长关联。没有其他事情正在发生。所以似乎你可能不同意它们不能更强大的直觉，如果它们只是这样做。
- en: '**Trenton Bricken** *00:32:11*'
  id: totrans-split-203
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:32:11*'
- en: I think then you can get into really interesting cases of meta-learning. When
    you play a new video game or study a new textbook, you're bringing a whole bunch
    of skills to the table to form those associations much more quickly. And because
    everything in some way ties back to the physical world, I think there are general
    features that you can pick up and then apply in novel circumstances.
  id: totrans-split-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为你可以进入真正有趣的元学习案例。当你玩一个新的视频游戏或者学习一本新的教科书时，你会带来大量的技能，以更快地形成这些关联。因为一切都以某种方式与物理世界联系在一起，我认为你可以掌握一般特征，然后在新情况下应用。
- en: '**Dwarkesh Patel** *00:32:35*'
  id: totrans-split-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:32:35*'
- en: Should we talk about the [intelligence explosion](https://en.wikipedia.org/wiki/Technological_singularity#Intelligence_explosion)
    then? The reason I'm interested in discussing this with you guys in particular
    is that the models of the intelligence explosion we have so far come from economists.
  id: totrans-split-206
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是否应该讨论[智能爆炸](https://en.wikipedia.org/wiki/Technological_singularity#Intelligence_explosion)呢？我对特别与你们讨论这个感兴趣的原因是，我们目前的智能爆炸模型来自经济学家。
- en: That’s fine but I think we can do better because in the model of the intelligence
    explosion, what happens is you replace the AI researchers. There's a bunch of
    automated AI researchers who can speed up progress, make more AI researchers,
    and make further progress. If that's the mechanism, we should just ask the AI
    researchers whether they think this is plausible. So let me just ask you, if I
    have a thousand agent Sholtos or agent Trentons, do you think that you get an
    intelligence explosion? What does that look like to you?
  id: totrans-split-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这很好，但我认为我们可以做得更好，因为在智能爆炸的模型中，发生的是你替换了AI研究人员。有一群自动化的AI研究人员可以加速进展，制造更多的AI研究人员，并进一步推动进展。如果这是机制，我们应该询问AI研究人员是否认为这是可行的。所以让我问你们，如果我有一千个Sholto或者Trenton代理，你认为会发生智能爆炸吗？对你来说，这是什么样子？
- en: '**Sholto Douglas** *00:33:32*'
  id: totrans-split-208
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:33:32*'
- en: I think one of the important bounding constraints here is compute. I do think
    you could dramatically speed up AI research. It seems very clear to me that in
    the next couple of years, we'll have things that can do many of the software engineering
    tasks that I do on a day to day basis, and therefore dramatically speed up my
    work, and therefore speed up the rate of progress.
  id: totrans-split-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这里的一个重要限制是计算能力。我确实认为你可以极大地加速AI研究。对我来说非常清楚，未来几年内，我们将拥有可以完成我日常软件工程任务的工具，因此极大地加快我的工作速度，从而加快进展速度。
- en: At the moment, I think most of the labs are somewhat compute bound in that there
    are always more experiments you could run and more pieces of information that
    you could gain in the same way that scientific research on biology is somewhat
    experimentally throughput-bound. You need to run and culture the cells in order
    to get the information.
  id: totrans-split-210
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我认为大多数实验室在一定程度上受到计算限制，因为总有更多的实验可以进行，更多的信息可以获取，就像生物科学研究在实验吞吐量方面有所限制一样。你需要培养细胞并运行实验才能获取信息。
- en: I think that will be at least a short term planning constraint. Obviously, [Sam's
    trying to raise $7 trillion](https://www.wsj.com/tech/ai/sam-altman-seeks-trillions-of-dollars-to-reshape-business-of-chips-and-ai-89ab3db0)
    to buy chips and it does seem like there's going to be a lot more compute in the
    future as everyone is heavily ramping. [NVIDIA](https://www.nvidia.com/en-us/)'s
    [stock price](https://www.reuters.com/technology/red-hot-nvidia-dips-after-it-unveils-new-ai-chip-2024-03-19/)
    sort of represents the relative compute increase. Any thoughts?
  id: totrans-split-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这至少会成为短期规划的限制。显然，[Sam正在尝试筹集7万亿美元](https://www.wsj.com/tech/ai/sam-altman-seeks-trillions-of-dollars-to-reshape-business-of-chips-and-ai-89ab3db0)来购买芯片，未来似乎会有更多计算力。[NVIDIA](https://www.nvidia.com/en-us/)的[股价](https://www.reuters.com/technology/red-hot-nvidia-dips-after-it-unveils-new-ai-chip-2024-03-19/)在某种程度上反映了相对计算力的增加。有什么想法吗？
- en: '**Trenton Bricken** *00:34:36*'
  id: totrans-split-212
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:34:36*'
- en: I think we need a few more nines of reliability in order for it to be really
    useful and trustworthy. And we need context lengths that are super long and very
    cheap to have. If I'm working in our code base, it's really only small modules
    that I can get [Claude](https://www.anthropic.com/claude) to write for me right
    now. But it's very plausible that within the next few years, or even sooner, it
    can automate most of my tasks.
  id: totrans-split-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为我们需要更高可靠性的“九”来使其真正有用和值得信赖。我们需要超长且非常便宜的上下文长度。如果我在我们的代码库中工作，现在我只能让[Claude](https://www.anthropic.com/claude)为我编写一些小模块。但很有可能在未来几年，甚至更早，它可以自动化我的大部分任务。
- en: The only other thing here that I will note is that the research our interpretability
    subteam is working on is so early-stage. You really have to be able to make sure
    everything is done correctly in a bug-free way and contextualize the results with
    everything else in the model. If something isn't going right, you have to be able
    to enumerate all of the possible things, and then slowly work on those.
  id: totrans-split-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这里唯一要注意的是，我们可解释性子团队正在进行的研究处于非常早期阶段。你必须确保一切都以无bug的方式完成，并将结果与模型中的其他内容联系起来。如果某些事情不顺利，你必须能够列出所有可能的事情，然后慢慢处理。
- en: An example that we've publicly talked about in [previous papers](https://www.anthropic.com/news/privileged-bases-in-the-transformer-residual-stream)
    is dealing with [layer norm](https://arxiv.org/abs/1607.06450). If I'm trying
    to get an early result or look at the logit effects of the model, if I activate
    this feature that we've identified to a really large degree, how does that change
    the output of the model? Am I using layer norm or not? How is that changing the
    feature that's being learned? That will take even more context or reasoning abilities
    for the model.
  id: totrans-split-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前在[之前的论文](https://www.anthropic.com/news/privileged-bases-in-the-transformer-residual-stream)中公开讨论过的一个例子是处理[layer
    norm](https://arxiv.org/abs/1607.06450)。如果我试图获得早期结果或查看模型的逻辑效果，如果我激活我们已经大量确定的这个功能，那会如何改变模型的输出？我是在使用层归一化吗？这如何改变正在学习的特征？对于模型来说，这将需要更多的上下文或推理能力。
- en: '**Dwarkesh Patel** *00:36:04*'
  id: totrans-split-216
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:36:04*'
- en: You used a couple of concepts together. It's not self-evident to me that they're
    the same but it seemed like you were using them interchangeably. One was working
    on the Claude code base and making more modules based on that, they need more
    context or something. It seems like they might already be able to fit in the context
    or do you mean context like “the context window?”
  id: totrans-split-217
  prefs: []
  type: TYPE_NORMAL
  zh: 你把一些概念放在一起了。对我来说，它们不是自证的，但似乎你在交替使用它们。一个是在Claude代码库上工作并基于此制作更多模块，它们需要更多上下文或其他东西。看起来它们可能已经能够适应上下文，或者你指的是“上下文窗口”类的上下文？
- en: '**Trenton Bricken** *00:36:30*'
  id: totrans-split-218
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:36:30*'
- en: Yeah, the “context window” context.
  id: totrans-split-219
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，“上下文窗口”的上下文。
- en: '**Dwarkesh Patel** *00:36:32*'
  id: totrans-split-220
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:36:32*'
- en: So it seems like the thing that's preventing it from making good modules is
    not the lack of being able to put the code base in there.
  id: totrans-split-221
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来阻碍它制造良好模块的事情不是无法将代码库放入其中。
- en: '**Trenton Bricken** *00:36:39*'
  id: totrans-split-222
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:36:39*'
- en: I think that will be there soon.
  id: totrans-split-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这很快就会到位。
- en: '**Dwarkesh Patel** *00:36:41*'
  id: totrans-split-224
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:36:41*'
- en: But it's not going to be as good as you at coming up with papers because it
    can fit the code base in there.
  id: totrans-split-225
  prefs: []
  type: TYPE_NORMAL
  zh: 但它不会像你那样擅长写论文，因为它可以将代码库放在其中。
- en: '**Trenton Bricken** *00:36:46*'
  id: totrans-split-226
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:36:46*'
- en: No, but it will speed up a lot of the engineering.
  id: totrans-split-227
  prefs: []
  type: TYPE_NORMAL
  zh: 不，但它会加速许多工程过程。
- en: '**Dwarkesh Patel** *00:36:48*'
  id: totrans-split-228
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:36:48*'
- en: In a way that causes an intelligence explosion?
  id: totrans-split-229
  prefs: []
  type: TYPE_NORMAL
  zh: 以一种引发智能爆炸的方式？
- en: '**Trenton Bricken** *00:36:53*'
  id: totrans-split-230
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *00:36:53*'
- en: No, in a way that accelerates research. But I think these things compound. The
    faster I can do my engineering, the more experiments I can run. And the more experiments
    I can run, the faster we can… I mean, my work isn't actually accelerating capabilities
    at all, it's just interpreting the models. But we have a lot more work to do on
    that. surprise to the Twitter guy,
  id: totrans-split-231
  prefs: []
  type: TYPE_NORMAL
  zh: 不，这在加速研究方面有所帮助。但我认为这些事情是相互作用的。我能越快完成我的工程，我就能跑更多的实验。而我跑更多的实验，我们就能越快… 我的工作实际上并没有加速能力的提升，只是在解释模型。但我们在这方面还有很多工作要做。让Twitter的人惊讶的是，
- en: '**Dwarkesh Patel** *00:37:14*'
  id: totrans-split-232
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:37:14*'
- en: For context, when you released your [paper](https://transformer-circuits.pub/2023/monosemantic-features),
    there was a lot of talk on Twitter like, “alignment is solved guys. Close the
    curtains.”
  id: totrans-split-233
  prefs: []
  type: TYPE_NORMAL
  zh: 为了背景，当你发布你的[论文](https://transformer-circuits.pub/2023/monosemantic-features)时，Twitter上有很多人说，“对齐问题解决了伙计们。拉上帷幕吧。”
- en: '**Trenton Bricken** *00:37:24*'
  id: totrans-split-234
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *00:37:24*'
- en: Yeah, no it keeps me up at night how quickly the models are becoming more capable
    and just how poor our understanding of what's going on still is.
  id: totrans-split-235
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这让我晚上睡不着觉，模型变得如此迅速变得更加强大，而我们对事情的真实运行机制的理解仍然很差。
- en: '**Dwarkesh Patel** *00:37:36*'
  id: totrans-split-236
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:37:36*'
- en: Let's run through the specifics here. By the time this is happening, we have
    bigger models that are two to four orders of magnitude bigger, or at least an
    effective compute two to four orders of magnitude bigger. So this idea that you
    can run experiments faster, you're having to retrain that model in this version
    of the intelligence explosion. The recursive self-improvement is different from
    what might've been imagined 20 years ago, where you just rewrite the code. You
    actually have to train a new model and that's really expensive.
  id: totrans-split-237
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在这里具体运行一下。到这个时候，我们拥有的模型是两到四个数量级或至少是有效计算量是两到四个数量级更大的模型。所以这种你可以更快地运行实验的想法，在这种智能爆炸版本中，你必须重新训练该模型。递归的自我改进不同于20年前可能想象的，你只需重写代码。你实际上必须训练一个新模型，而这是非常昂贵的。
- en: Not only now, but especially in the future, as you keep making these models
    orders of magnitude bigger. Doesn't that dampen the possibility of a recursive
    self-improvement type of intelligence explosion?
  id: totrans-split-238
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅是现在，尤其是在未来，随着你们不断扩展这些模型的规模，这难道不会削弱递归自我改进型智能爆炸的可能性吗？
- en: '**Sholto Douglas** *00:38:25*'
  id: totrans-split-239
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:38:25*'
- en: It's definitely going to act as a breaking mechanism. I agree that the world
    of what we're making today looks very different from what people imagined it would
    look like 20 years ago. It's not going to be able to write the same code to be
    really smart, because actually it needs to train itself. The code itself is typically
    quite simple, typically really small and self contained.
  id: totrans-split-240
  prefs: []
  type: TYPE_NORMAL
  zh: 这绝对会作为一种制动机制存在。我同意，今天我们所创造的东西看起来与20年前人们想象的大不相同。它不会写出相同的代码来变得真正聪明，因为它实际上需要进行自我训练。代码本身通常非常简单，通常非常小而且自包含。
- en: I think [John Carmack](https://en.wikipedia.org/wiki/John_Carmack) had this
    [nice phrase](https://www.youtube.com/watch?v=xLi83prR5fg) where it's the first
    time in history where you can plausibly imagine writing AI with 10,000 lines of
    code. That actually does seem plausible when you pare most training codebases
    down to the limit. But it doesn't take away from the fact that this is something
    where we should really strive to measure and estimate how progress might be.
  id: totrans-split-241
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为[约翰·卡马克](https://en.wikipedia.org/wiki/John_Carmack)有一个[不错的说法](https://www.youtube.com/watch?v=xLi83prR5fg)，即这是历史上第一次可以想象用1万行代码编写AI。当你把大多数训练代码限制在这个范围内时，这看起来确实是可行的。但这并不能削弱我们真正努力测量和估计进展可能性的事实。
- en: We should be trying very, very hard to measure exactly how much of a software
    engineer's job is automatable, and what the trend line looks like, and be trying
    our hardest to project out those trend lines.
  id: totrans-split-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该非常非常努力地去衡量软件工程师的工作有多少是可以自动化的，并且应该努力预测这些趋势线的走向。
- en: '**Dwarkesh Patel** *00:39:21*'
  id: totrans-split-243
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:39:21*'
- en: But with all due respect to software engineers you are not writing like a React
    front-end right?
  id: totrans-split-244
  prefs: []
  type: TYPE_NORMAL
  zh: 但是对于所有尊重软件工程师的人来说，你写的不像一个React前端对吧？
- en: What is concretely happening? Maybe you can walk me through a day in the life
    of Sholto. You're working on an experiment or project that's going to make the
    model "better.” What is happening from observation to experiment, to theory, to
    writing the code? What is happening?
  id: totrans-split-245
  prefs: []
  type: TYPE_NORMAL
  zh: 具体发生了什么？也许你可以带我走一遍 Sholto 的一天生活。你正在进行一个实验或项目，这将使模型“更好”。从观察到实验，再到理论，最后到编写代码，发生了什么？
- en: '**Sholto Douglas** *00:39:48*'
  id: totrans-split-246
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:39:48*'
- en: I think it’s important to contextualize here that I've primarily worked on inference
    so far. A lot of what I've been doing is just helping guide the pre-training process,
    designing a good model for inference and then making the model and the surrounding
    system faster. I've also done some pre-training work around that, but it hasn't
    been my 100% focus. I can still describe what I do when I do that work.
  id: totrans-split-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为在这里进行背景说明很重要，我到目前为止主要是在推理方面工作。我所做的很多工作只是帮助引导预训练过程，设计一个适合推理的良好模型，然后使模型和周围系统更快。我也在这方面做了一些预训练工作，但这并不是我的百分之百专注。我仍然可以描述我做这项工作时的情况。
- en: '**Dwarkesh Patel** *00:40:09*'
  id: totrans-split-248
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:40:09*'
- en: Sorry, let me interrupt. When [Carl Shulman](https://www.fhi.ox.ac.uk/team/carl-shulman/)
    was talking about it on the [podcast](https://www.dwarkeshpatel.com/p/carl-shulman),
    he did say that things like improving inference or even literally making better
    chips or GPUs, that’s part of the intelligence explosion. Obviously if the inference
    code runs faster, it happens better or faster or whatever. Sorry, go ahead.
  id: totrans-split-249
  prefs: []
  type: TYPE_NORMAL
  zh: 对不起，让我打断一下。当[Carl Shulman](https://www.fhi.ox.ac.uk/team/carl-shulman/)在[播客](https://www.dwarkeshpatel.com/p/carl-shulman)上谈到这个时，他确实说过，像改进推理或者甚至直接制造更好的芯片或GPU，这都是智能爆炸的一部分。显然，如果推理代码运行得更快，它会更好或更快或其他什么。抱歉，继续吧。
- en: '**Sholto Douglas** *00:40:32*'
  id: totrans-split-250
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:40:32*'
- en: So concretely, what does a day look like? I think the most important part to
    illustrate is this cycle of coming up with an idea, proving it out at different
    points in scale, and interpreting and understanding what goes wrong. I think most
    people would be surprised to learn just how much goes into interpreting and understanding
    what goes wrong.
  id: totrans-split-251
  prefs: []
  type: TYPE_NORMAL
  zh: 所以具体来说，一天是什么样子？我认为最重要的部分是说明这种理念生成、在不同规模点上验证它，并解释和理解出了什么问题。我认为大多数人会惊讶地发现，在解释和理解出了什么问题时，需要投入多少工作。
- en: People have long lists of ideas that they want to try. Not every idea that you
    think should work, will work. Trying to understand why that is is quite difficult
    and working out what exactly you need to do to interrogate it. So a lot of it
    is introspection about what's going on. It's not pumping out thousands and thousands
    and thousands of lines of code. It's not the difficulty in coming up with ideas.
    Many people have a long list of ideas that they want to try, but paring that down
    and shot calling, under very imperfect information, what are the right ideas to
    explore further is really hard.
  id: totrans-split-252
  prefs: []
  type: TYPE_NORMAL
  zh: 人们有一长串想要尝试的想法清单。并不是你认为应该奏效的每个想法都会奏效。试图理解为什么会这样是非常困难的，以及在非常不完全信息的情况下，究竟需要做什么才能进一步探讨。因此，大部分工作是对正在发生的事情进行反思。这不是在大量编写成千上万行代码。这不是提出想法的难度。许多人有一长串想要尝试的想法，但在非常不完全的信息下，缩小范围和决策，究竟哪些是进一步探索的正确想法，真的很难。
- en: '**Dwarkesh Patel** *00:41:32*'
  id: totrans-split-253
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:41:32*'
- en: What do you mean by imperfect information? Are these early experiments? What
    is the information?
  id: totrans-split-254
  prefs: []
  type: TYPE_NORMAL
  zh: 你说的不完全信息是什么意思？这些是早期实验吗？信息是什么？
- en: '**Sholto Douglas** *00:41:40*'
  id: totrans-split-255
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:41:40*'
- en: Demis mentioned this in his podcast. It's like the [GPT-4 paper](https://arxiv.org/abs/2303.08774)
    where you have scaling law increments. You can see in the GPT-4 paper, they have
    a bunch of dots, right?
  id: totrans-split-256
  prefs: []
  type: TYPE_NORMAL
  zh: Demis 在他的播客中提到了这一点。就像[GPT-4论文](https://arxiv.org/abs/2303.08774)中提到的那样，你可以看到有缩放定律的增量。在GPT-4论文中，他们有一堆点，对吧？
- en: They say we can estimate the performance of our final model using all of these
    dots and there's a nice curve that flows through them. And Demis mentioned that
    we do this process of scaling up.
  id: totrans-split-257
  prefs: []
  type: TYPE_NORMAL
  zh: 他们说我们可以通过所有这些点来估计我们最终模型的性能，并且有一条漂亮的曲线通过它们。Demis提到我们正在进行的这种缩放过程。
- en: Concretely, why is that imperfect information? It’s because you never actually
    know if the trend will hold. For certain architectures the trend has held really
    well. And for certain changes, it's held really well. But that isn't always the
    case. And things which can help at smaller scales can actually hurt at larger
    scales. You have to make guesses based on what the trend lines look like and based
    on your intuitive feeling of what’s actually something that's going to matter,
    particularly for those which help with the small scale.
  id: totrans-split-258
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，为什么信息不完整？因为你永远不知道趋势是否会持续。对于某些架构，趋势确实非常好。对于某些变化，它确实非常好。但情况并非总是如此。在较小的规模上有助于的东西，在较大的规模上可能会造成伤害。你必须根据趋势线的外观和你对实际事情会有影响的直觉感觉来进行猜测，尤其是对于那些帮助小规模的情况。
- en: '**Dwarkesh Patel** *00:42:35*'
  id: totrans-split-259
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:42:35*'
- en: That's interesting to consider. For every chart you see in a release paper or
    technical report that shows that smooth curve, there's a graveyard of first few
    runs and then it's flat.
  id: totrans-split-260
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这一点很有趣。在每个发布论文或技术报告中看到的每张平滑曲线背后，都有一堆最初的运行，然后就变得平稳了。
- en: '**Sholto Douglas** *00:42:45*'
  id: totrans-split-261
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:42:45*'
- en: Yeah. There's all these other lines that go in different directions. You just
    tail off.
  id: totrans-split-262
  prefs: []
  type: TYPE_NORMAL
  zh: 是的。还有许多其他沿着不同方向走的线。你只是逐渐减少。
- en: '**Trenton Bricken** *00:42:50*'
  id: totrans-split-263
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *00:42:50*'
- en: It's crazy, both as a grad student and here, the number of experiments that
    you have to run before getting a meaningful result.
  id: totrans-split-264
  prefs: []
  type: TYPE_NORMAL
  zh: 真是疯狂，作为研究生和在这里，你必须进行大量实验才能得到有意义的结果。
- en: '**Dwarkesh Patel** *00:42:57*'
  id: totrans-split-265
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:42:57*'
- en: But presumably it's not just like you run it until it stops and then go to the
    next thing. There's some process by which to interpret the early data. I don't
    know. I could put a Google Doc in front of you and I'm pretty sure you could just
    keep typing for a while on different ideas you have. There's some bottleneck between
    that and just making the models better immediately. Walk me through that. What
    is the inference you're making from the first early steps that makes you have
    better experiments and better ideas?
  id: totrans-split-266
  prefs: []
  type: TYPE_NORMAL
  zh: 但是假设不仅仅是运行到停止然后转移到下一个事物。有一些过程可以解释早期数据。我不知道。我可以在你面前放一张谷歌文档，我很确定你可以在不同的想法上长时间地输入。在这与立即使模型更好之间有一个瓶颈。带我走一遍。你从最初的步骤中推断出什么，使你有更好的实验和更好的想法？
- en: '**Sholto Douglas** *00:43:30*'
  id: totrans-split-267
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:43:30*'
- en: I think one thing that I didn't fully convey before was that I think a lot of
    like good research comes from working backwards from the actual problems that
    you want to solve. There's a couple of grand problems today in making the models
    better that you would identify as issues and then work on how can I change things
    to achieve this? When you scale you also run into a bunch of things and you want
    to fix behaviors and issues at scale. And that informs a lot of the research for
    the next increment and this kind of stuff.
  id: totrans-split-268
  prefs: []
  type: TYPE_NORMAL
  zh: 我之前没有完全表达的一点是，我认为很多好的研究都是从你想要解决的实际问题反向进行的。今天有几个使模型更好的大问题，你会把它们确定为问题，然后研究如何改变事物以实现这一目标？当你扩展时，你也会遇到许多问题，你希望在规模上修复行为和问题。这也为下一个增量的研究提供了很多信息，这种事情。
- en: Concretely, the barrier is a little bit of software engineering, having a code
    base that's large and capable enough that it can support many people doing research
    at the same time often makes it complex. If you're doing everything by yourself,
    your iteration pace is going to be much faster. [Alec Radford](https://scholar.google.com/citations?user=dOad5HoAAAAJ&hl=en),
    for example, famously did much of the pioneering work at OpenAI. I’ve heard he
    mostly works out of a Jupyter notebook and then has someone else who writes and
    productionizes that code for him. Actually operating with other people raises
    the complexity a lot, for natural reasons familiar to every software engineer
    and also the inherent running. Running and launching those experiments is easy
    but there's inherent slowdowns induced by that. So you often want to be parallelizing
    multiple different streams. You can't be totally focused on one thing necessarily.
    You might not have fast enough feedback cycles. And then intuiting what went wrong
    is actually really hard.
  id: totrans-split-269
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，障碍在于软件工程的一点点，拥有一个足够大且能够支持多人同时进行研究的代码库通常会使其复杂化。如果你完全靠自己做所有事情，你的迭代速度会快得多。例如，[Alec
    Radford](https://scholar.google.com/citations?user=dOad5HoAAAAJ&hl=en)就是在OpenAI做了许多开创性工作的著名人物。我听说他主要是在Jupyter笔记本上工作，然后有其他人为他编写和生产化这些代码。实际上，与其他人一起操作会大大增加复杂性，这是每个软件工程师都熟悉的自然原因，同时也存在固有的运行问题。运行和启动这些实验很容易，但这会引入固有的减速。因此，你经常希望并行化多个不同的流程。你可能不能完全集中精力在一件事情上。你可能没有足够快速的反馈周期。然后，直觉地判断出问题所在实际上是非常困难的。
- en: This is in many respects, the problem that the team that Trenton is on is trying
    to better understand. What is going on inside these models? We have inferences
    and understanding and headcanon for why certain things work, but it's not an exact
    science. and so you have to constantly be making guesses about why something might
    have happened, what experiment might reveal, whether that is or isn't true. That's
    probably the most complex part.
  id: totrans-split-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在很多方面，Trenton 所在的团队正在试图更好地理解的问题。这些模型内部到底在发生什么？我们有一些推论和理解，以及为什么某些事情有效的想法，但这并不是一门精确的科学。因此，你必须不断地猜测为什么某些事情可能发生了，什么实验可能会揭示，无论那是真实的还是不真实的。这可能是最复杂的部分。
- en: The performance work is comparatively easier but harder in other respects. It's
    just a lot of low-level and difficult engineering work.
  id: totrans-split-271
  prefs: []
  type: TYPE_NORMAL
  zh: 相比较而言，性能工作在某些方面更容易，但在其他方面更难。这只是很多低级和困难的工程工作。
- en: '**Trenton Bricken** *00:45:38*'
  id: totrans-split-272
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:45:38*'
- en: I agree with a lot of that. Even on the interpretability team, especially with
    [Chris Olah](https://colah.github.io/about.html) leading it, there are just so
    many ideas that we want to test and it's really just having the “engineering”
    skill–a lot of it is research–to very quickly iterate on an experiment, look at
    the results, interpret it, try the next thing, communicate them, and then just
    ruthlessly prioritizing what the highest priority things to do are.
  id: totrans-split-273
  prefs: []
  type: TYPE_NORMAL
  zh: 我同意很多观点。即使在可解释性团队中，特别是由[Chris Olah](https://colah.github.io/about.html)领导的团队，我们也有许多想法要测试，真的就是要拥有“工程”技能——大部分是研究——非常快速地迭代一个实验，查看结果，解释它，尝试下一个事情，沟通它们，然后无情地优先考虑做什么是最重要的事情。
- en: '**Sholto Douglas** *00:46:07*'
  id: totrans-split-274
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:46:07*'
- en: This is really important. The ruthless prioritization is something which I think
    separates a lot of quality research from research that doesn't necessarily succeed
    as much. We're in this funny field where so much of our initial theoretical understanding
    is broken down basically. So you need to have this simplicity bias and ruthless
    prioritization over what's actually going wrong. I think that's one of the things
    that separates the most effective people. They don't necessarily get too attached
    to using a given sort of solution that they are familiar with, but rather they
    attack the problem directly.
  id: totrans-split-275
  prefs: []
  type: TYPE_NORMAL
  zh: 这真的非常重要。无情的优先级排序是我认为能够区分出很多高质量研究与那些不一定成功的研究之一的东西。我们处在一个非常有趣的领域，我们最初的理论理解很多时候都被打破了。因此，你需要有简单的偏见和无情的优先级排序，去解决实际上出了什么问题。我认为这是最有效的人所具备的品质之一。他们不一定会过于依赖他们熟悉的解决方案，而是直接攻击问题。
- en: You see this a lot in people who come in with a specific academic background.
    They try to solve problems with that toolbox but the best people are people who
    expand the toolbox dramatically. They're running around and they're taking ideas
    from reinforcement learning, but also from optimization theory. And also they
    have a great understanding of systems. So they know what the sort of constraints
    that bound the problem are and they're good engineers. They can iterate and try
    ideas fast. By far the best researchers I've seen, they all have the ability to
    try experiments really, really, really, really, really fast. That’s cycle time
    at smaller scales. Cycle time separates people.
  id: totrans-split-276
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现，具有特定学术背景的人们经常试图用其工具箱解决问题，但最优秀的人才是那些显著扩展其工具箱的人。他们四处奔走，从强化学习中获取思想，同时也从优化理论中获取思想。而且他们对系统有着深刻的理解。所以，他们知道限制问题的约束是什么，并且是优秀的工程师。他们可以快速地迭代和尝试想法。到目前为止，我见过的最优秀的研究人员，他们都有能力非常快速地尝试实验。这是在小尺度上的循环时间。循环时间区分了人们。
- en: '**Trenton Bricken** *00:47:20*'
  id: totrans-split-277
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:47:20*'
- en: Machine learning research is just so empirical. This is honestly one reason
    why I think our solutions might end up looking more brain-like than otherwise.
    Even though we wouldn't want to admit it, the whole community is kind of doing
    greedy evolutionary optimization over the landscape of possible AI architectures
    and everything else. It’s no better than evolution. And that’s not even a slight
    against evolution.
  id: totrans-split-278
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习研究如此经验主义。这也是我认为我们的解决方案最终可能看起来更像大脑的原因之一。尽管我们不愿意承认，整个社区实际上在贪婪地进行可能的人工智能架构和其他事物的进化优化。这与进化论无异。甚至不是针对进化的轻视。
- en: '**Dwarkesh Patel** *00:47:46*'
  id: totrans-split-279
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:47:46*'
- en: That's such an interesting idea. I'm still confused on what will be the bottleneck.
    What would have to be true of an agent such that it sped up your research? So
    in the Alec Radford example where he apparently already has the equivalent of
    [Copilot](https://copilot.microsoft.com/) for his Jupyter notebook experiments,
    is it just that if he had enough of those he would be a dramatically faster researcher?
  id: totrans-split-280
  prefs: []
  type: TYPE_NORMAL
  zh: 那真是一个非常有趣的想法。我仍然对瓶颈是什么感到困惑。关于一个代理程序必须具备什么条件，才能加快您的研究速度？例如，像[合伙人](https://copilot.microsoft.com/)这样的
    Alec Radford 示例中，他已经为他的 Jupyter 笔记本实验准备了相应的工具，那只是他如果有足够多这样的工具，他会成为一个更加高效的研究员吗？
- en: So you're not automating the humans, you're just making the most effective researchers
    who have great taste, more effective and running the experiments for them? You're
    still working at the point at which the intelligence explosion is happening? Is
    that what you're saying?
  id: totrans-split-281
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，你并不是在自动化人类，而是使具有出色品味的最有效的研究人员更加高效，并为他们运行实验？你仍然在智能爆炸正在发生的时点工作吗？这是你的意思吗？
- en: '**Sholto Douglas** *00:48:27*'
  id: totrans-split-282
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:48:27*'
- en: Right, and if that were directly true then why can't we scale our current research
    teams better? I think that’s an interesting question to ask. If this work is so
    valuable, why can't we take hundreds or thousands of people–they're definitely
    out there–and scale our organizations better.
  id: totrans-split-283
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，如果直接如此，为什么我们不能更好地扩展我们当前的研究团队呢？我认为这是一个有趣的问题。如果这项工作如此有价值，为什么我们不能吸引数百或数千人才——他们肯定是存在的——更好地扩展我们的组织。
- en: I think we are less, at the moment, bound by the sheer engineering work of making
    these things than we are by compute to run and get signal, and taste in terms
    of what the actual right thing to do is. And then making those difficult inferences
    on imperfect information,
  id: totrans-split-284
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为我们目前受制于运行和获取信号的计算能力，以及在实际行动中选择正确操作的品味，要比制造这些事物的纯工程工作要少。
- en: '**Trenton Bricken** *00:49:13*'
  id: totrans-split-285
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:49:13*'
- en: For the Gemini team. Because I think for interpretability, we actually really
    want to keep hiring talented engineers. I think that's a big bottleneck for us.
  id: totrans-split-286
  prefs: []
  type: TYPE_NORMAL
  zh: 为了 Gemini 团队。因为我认为，为了可解释性，我们确实需要不断雇佣有才华的工程师。我认为这对我们来说是一个很大的瓶颈。
- en: '**Sholto Douglas** *00:49:23*'
  id: totrans-split-287
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:49:23*'
- en: Obviously more people are better. But I do think it's interesting to consider.
    One of the biggest challenges that I've thought a lot about is how do we scale
    better? Google is an enormous organization. It has 200,000-ish people, right?
    Maybe 180,000 or something like that. One has to imagine ways of scaling out Gemini's
    research program to all those fantastically talented software engineers. This
    seems like a key advantage that you would want to be able to take advantage of.
    You want to be able to use it but how do you effectively do that? It's a very
    complex organizational problem.
  id: totrans-split-288
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，更多的人是更好的。但我认为考虑到这一点是很有趣的。我思考过的最大的挑战之一是如何更好地扩展？谷歌是一个庞大的组织。它有大约20万人，对吧？也许18万人左右之类的。一个必须想象如何将双子座的研究项目扩展到所有那些极具才华的软件工程师身上。这似乎是一个你想要利用的关键优势。你想要使用它，但你如何有效地做到这一点？这是一个非常复杂的组织问题。
- en: '**Dwarkesh Patel** *00:50:02*'
  id: totrans-split-289
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:50:02*'
- en: So compute and taste. That's interesting to think about because at least the
    compute part is not bottlenecked on more intelligence, it's just bottlenecked
    on Sam's $7 trillion or whatever, right? If I gave you 10x the H100s to run your
    experiments, how much more effective a researcher are you?
  id: totrans-split-290
  prefs: []
  type: TYPE_NORMAL
  zh: 所以计算和品味。这很有趣，因为至少计算部分并不是受更多智能的瓶颈所限制，而是受到山姆的7万亿美元之类的限制，对吧？如果我给你10倍的H100来运行你的实验，你会成为多么有效的研究人员？
- en: '**Sholto Douglas** *00:50:20*'
  id: totrans-split-291
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:50:20*'
- en: TPUs, please.
  id: totrans-split-292
  prefs: []
  type: TYPE_NORMAL
  zh: TPUs，请。
- en: '**Dwarkesh Patel** *00:50:23*'
  id: totrans-split-293
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:50:23*'
- en: How much more effective a researcher are you?
  id: totrans-split-294
  prefs: []
  type: TYPE_NORMAL
  zh: 你的研究能力会提高多少？
- en: '**Sholto Douglas** *00:50:26*'
  id: totrans-split-295
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:50:26*'
- en: I think the Gemini program would probably be maybe five times faster with 10
    times more compute or something like that.
  id: totrans-split-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为使用10倍的计算资源之类的东西，可能会让双子座计划快五倍。
- en: '**Dwarkesh Patel** *00:50:35*'
  id: totrans-split-297
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:50:35*'
- en: So that's pretty good. Elasticity of 0.5\. Wait, that's insane.
  id: totrans-split-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这很好。弹性为0.5。等等，这太疯狂了。
- en: '**Sholto Douglas** *00:50:39*'
  id: totrans-split-299
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:50:39*'
- en: I think more compute would just directly convert into progress.
  id: totrans-split-300
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为更多的计算资源会直接转化为进展。
- en: '**Dwarkesh Patel** *00:50:43*'
  id: totrans-split-301
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:50:43*'
- en: So you have some fixed size of compute and some of it goes to inference and
    also to clients of [GCP](https://cloud.google.com/). Some of it goes to training
    and from there, as a fraction of it, some of it goes to running the experiments
    for the full model.
  id: totrans-split-302
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你有一些固定大小的计算资源，其中一部分用于推理，也用于[GCP](https://cloud.google.com/)的客户端。部分用于训练，而在此过程中，其中一部分又用于运行完整模型的实验。
- en: '**Sholto Douglas** *00:51:04*'
  id: totrans-split-303
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:51:04*'
- en: Yeah, that's right.
  id: totrans-split-304
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，没错。
- en: '**Dwarkesh Patel** *00:51:05*'
  id: totrans-split-305
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:51:05*'
- en: Shouldn't the fraction that goes experiments then be higher given research is
    bottlenecked by compute.
  id: totrans-split-306
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到研究受到计算资源的限制，那么用于实验的部分不应该更高一些吗？
- en: '**Sholto Douglas** *00:51:13*'
  id: totrans-split-307
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:51:13*'
- en: So one of the strategic decisions that every pre-training team has to make is
    exactly what amount of compute do you allocate to different training runs, to
    your research program versus scaling the last best thing that you landed on. They're
    all trying to arrive at an optimal point here. One of the reasons why you need
    to still keep training big models is that you get information there that you don't
    get otherwise. So scale has all these emergent properties which you want to understand
    better.
  id: totrans-split-308
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，每个预训练团队都必须做出的战略决策之一，就是确切地分配多少计算资源给不同的训练运行，给你的研究项目，以及扩展到你最后确定的最佳方案。他们都试图达到一个最优点。你仍然需要训练大型模型的一个原因是，你可以从中获取否则得不到的信息。因此，规模具有你希望更好理解的所有这些新兴特性。
- en: Remember what I said before about not being sure what's going to fall off the
    curve. If you keep doing research in this regime and keep on getting more and
    more compute efficient, you may have actually gone off the path to actually eventually
    scale. So you need to constantly be investing in doing big runs too, at the frontier
    of what you sort of expect to work.
  id: totrans-split-309
  prefs: []
  type: TYPE_NORMAL
  zh: 记住我之前说过的关于不确定哪些事情会脱离曲线的话。如果你在这个领域继续进行研究，并且在变得越来越计算效率化时，你实际上可能已经偏离了最终扩展的路径。因此，你需要不断投资于进行大规模运行，处于你预期能够成功的前沿。
- en: '**Dwarkesh Patel** *00:52:17*'
  id: totrans-split-310
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:52:17*'
- en: So then tell me what it looks like to be in the world where AI has significantly
    sped up AI research. Because from this, it doesn't really sound like the AIs are
    going off and writing the code from scratch that's leading to faster output. It
    sounds like they're really augmenting the top researchers in some way. Tell me
    concretely. Are they doing the experiments? Are they coming up with the ideas?
    Are they just evaluating the outputs of the experiments? What's happening?
  id: totrans-split-311
  prefs: []
  type: TYPE_NORMAL
  zh: 那么告诉我，处于AI显著加快AI研究的世界中是什么样子。因为从这里来看，它似乎并不像是AI正在去写出导致更快输出的代码。听起来它们只是在某种程度上增强了顶尖研究人员。具体来说，告诉我。它们是在做实验吗？它们提出了想法吗？它们只是评估实验的输出吗？发生了什么？
- en: '**Sholto Douglas** *00:52:39*'
  id: totrans-split-312
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:52:39*'
- en: So I think there's two walls you need to consider here. One is where AI has
    meaningfully sped up our ability to make algorithmic progress. And one is where
    the output of the AI itself is the thing that's the crucial ingredient towards
    model capability progress. Specifically what I mean there is synthetic data. In
    the first world, where it's meaningfully speeding up algorithmic progress, I think
    a necessary component of that is more compute. You've probably reached this elasticity
    point where AIs are easier to speed up and get on to context than yourself, or
    other people. So AIs meaningfully speed up your work because they're basically
    a fantastic Copilot that helps you code multiple times faster.
  id: totrans-split-313
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我认为在这里你需要考虑两个障碍。一个是人工智能如何显著加快了我们进行算法进展的能力。另一个是人工智能本身的输出是否是模型能力进展的关键因素。具体来说，我指的是合成数据。在第一个世界中，它显著加快算法进展的一个必要组成部分是更多的计算。你可能已经达到了弹性点，AI比你自己或其他人更容易加快速度并进入语境。因此，AI因为它们基本上是一个出色的副驾驶帮助你编码多次更快，从而显著加快了你的工作。
- en: That seems actually quite reasonable. Super long-context, super smart model.
    It's onboarded immediately and you can send them off to complete subtasks and
    subgoals for you. That actually feels very plausible, but again we don't know
    because there are no great evals about that kind of thing. As I said before, the
    best one is SWE-bench.
  id: totrans-split-314
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎实际上是相当合理的。超长上下文，超智能模型。它立即上岗，你可以让它们完成子任务和子目标。这实际上听起来非常可行，但我们不知道，因为没有关于这种事情的良好评估。正如我之前说的，最好的一个是SWE-bench。
- en: '**Dwarkesh Patel** *00:53:51*'
  id: totrans-split-315
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:53:51*'
- en: Somebody was mentioning to me that the problem with that one is that when a
    human is trying to do a pull request, they'll type something out and they'll run
    it and see if it works. If it doesn't, they'll rewrite it. None of this was part
    of the opportunities that the LLM was given when told “run on this.” Just output
    and if it runs and checks all the boxes then it passed. So it might've been an
    unfair test in that way.
  id: totrans-split-316
  prefs: []
  type: TYPE_NORMAL
  zh: 有人告诉我，其中一个问题是，当人类试图做一个拉取请求时，他们会打出一些内容，然后运行它看看是否有效。如果不行，他们会重写它。但是LLM在被告知“运行这个”时没有提供这些机会的任何一部分。只有输出，如果它运行并检查了所有条件，那么就通过了。所以从这个角度看，这可能是一个不公平的测试。
- en: '**Sholto Douglas** *00:54:16*'
  id: totrans-split-317
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:54:16*'
- en: So you can imagine that if you were able to use that, that would be an effective
    training source. The key thing that's missing from a lot of training data is the
    reasoning traces, right?
  id: totrans-split-318
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你可以想象，如果你能够使用它，那将是一个有效的培训来源。许多培训数据中缺少的关键因素是推理追踪，对吧？
- en: And I think this would be it. If I wanted to try and automate a specific field,
    a job family, or understand how at risk of automation that specific field is,
    then having reasoning traces feels to me like a really important part of that.
  id: totrans-split-319
  prefs: []
  type: TYPE_NORMAL
  zh: 我想这就是它的全部。如果我想尝试自动化一个特定的领域、一个职业家族，或者了解这个特定领域的自动化风险，那么拥有推理追踪对我来说就像是其中非常重要的一部分。
- en: '**Dwarkesh Patel** *00:54:51*'
  id: totrans-split-320
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:54:51*'
- en: There's so many different threads there I want to follow up on. Let's begin
    with the data versus compute thing. Is the output of the AI the thing that's causing
    the intelligence explosion? People talk about how these models are really a reflection
    on their data. I forgot his name but there was a great blog by this OpenAI engineer.
    It was talking about how at the end of the day, as these models get better and
    better, there are just going to be really effective maps of the data set. So at
    the end of the day you have to stop thinking about architectures. The most effective
    architecture is just, “do you do an amazing job of mapping the data?” So that
    implies that the future AI progress comes from the AI just making really awesome
    data that you’re mapping to?
  id: totrans-split-321
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有很多不同的思路，我想要追踪。让我们从数据与计算的对比开始。是AI的输出导致了智能爆炸吗？人们谈论这些模型实际上是它们数据的反映。我忘了他的名字，但有一个开放AI工程师的博客非常棒。它谈到了到最后，随着这些模型变得越来越好，它们只会成为数据集的非常有效的映射。所以最终你必须停止考虑架构。最有效的架构只是，“你是否能够出色地映射数据？”这意味着未来AI的进步来自于AI制作的真正出色的数据，你要映射的数据？
- en: '**Sholto Douglas** *00:55:45*'
  id: totrans-split-322
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:55:45*'
- en: That's clearly a very important part .
  id: totrans-split-323
  prefs: []
  type: TYPE_NORMAL
  zh: 这显然是一个非常重要的部分。
- en: '**Dwarkesh Patel** *00:55:46*'
  id: totrans-split-324
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:55:46*'
- en: That's really interesting. Does that look to you like [chain-of-thought](https://arxiv.org/abs/2201.11903)?
    Or what would you imagine as these models get better, as these models get smarter?
    What does the synthetic data look like?
  id: totrans-split-325
  prefs: []
  type: TYPE_NORMAL
  zh: 这真的很有趣。这对你来说像是[思维链](https://arxiv.org/abs/2201.11903)吗？或者你想象一下，随着这些模型变得更好、更聪明，合成数据会是什么样子？
- en: '**Sholto Douglas** *00:56:00*'
  id: totrans-split-326
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *00:56:00*'
- en: When I think of really good data, to me, that raises something which involved
    a lot of reasoning to create. It's similar to [Ilya](https://en.wikipedia.org/wiki/Ilya_Sutskever)'s
    perspective on achieving super intelligence effectively via perfectly modeling
    human textual output. But even in the near term, in order to model something like
    the arXiv papers or Wikipedia, you have to have an incredible amount of reasoning
    behind you in order to understand what next token might be output.
  id: totrans-split-327
  prefs: []
  type: TYPE_NORMAL
  zh: 当我想到真正好的数据时，对我来说，那些需要大量推理才能创造的东西就是好数据。这与[Ilya](https://en.wikipedia.org/wiki/Ilya_Sutskever)对通过完美模拟人类文本输出实现超级智能的看法相似。但即使在近期，为了模拟像arXiv论文或维基百科这样的东西，你也需要有大量的推理能力来理解下一个可能输出的标记。
- en: So for me, what I imagine as good data is data where it had to do reasoning
    to produce something. And then the trick of course is how do you verify that that
    reasoning was correct? This is why you saw [DeepMind](https://deepmind.google/)
    do that research for [geometry](https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/).
    Geometry is an easily formalizable, easily verifiable field. You can check if
    its reasoning was correct and you can generate heaps of data of correct trig,
    of verified geometry proofs, and train on that. And you know that that's good
    data.
  id: totrans-split-328
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，我所想象的好数据就是那些必须通过推理才能产生的数据。然后问题的关键当然是如何验证那个推理是正确的呢？这就是为什么你看到[DeepMind](https://deepmind.google/)在[几何学](https://deepmind.google/discover/blog/alphageometry-an-olympiad-level-ai-system-for-geometry/)方面进行研究。几何学是一个易于形式化、易于验证的领域。你可以检查它的推理是否正确，可以生成大量的正确三角函数、经过验证的几何证明，并在此基础上进行训练。你知道那就是好数据。
- en: '**Dwarkesh Patel** *00:57:11*'
  id: totrans-split-329
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *00:57:11*'
- en: It's actually funny because I had a [conversation](https://www.dwarkeshpatel.com/p/grant-sanderson)
    with [Grant Sanderson](https://en.wikipedia.org/wiki/3Blue1Brown) last year where
    we were debating this and I was like, “fuck dude, by the time they get the gold
    of the Math Olympiad, of course they're going to automate all the jobs.” Yikes.
  id: totrans-split-330
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上挺有意思的，因为我去年和[格兰特·桑德森](https://www.dwarkeshpatel.com/p/grant-sanderson)进行了一次对话，我们在辩论这个问题，我就像，“该死，等他们拿到数学奥林匹克的金牌时，当然他们将自动化所有的工作。”
    糟糕。
- en: On synthetic data, there’s a thing I speculated about in my [scaling post](https://www.dwarkeshpatel.com/p/will-scaling-work),
    which was heavily informed by discussions with you two and you especially, Sholto.
    You can think of human evolution through the spectrum of getting language and
    so we're generating the synthetic data. Our copies are generating the synthetic
    data which we're trained on and it's this really effective genetics, cultural,
    co-evolutionary loop.
  id: totrans-split-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在合成数据上，有一件事我在我的[scaling post](https://www.dwarkeshpatel.com/p/will-scaling-work)中进行了推测，这在很大程度上是通过与你们两位的讨论，特别是你，Sholto，得出的。你可以把人类进化看作是通过获取语言的光谱，并且我们正在生成合成数据。我们的副本正在生成我们训练的合成数据，这是一个非常有效的遗传、文化和共同进化的循环。
- en: '**Sholto Douglas** *00:57:54*'
  id: totrans-split-332
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:57:54*'
- en: And there's a verifier there too, right? There's the real world. You might generate
    a theory about the gods causing the storms, And then someone else finds cases
    where that isn't true. And so that sort of didn't match your verification function.
    Now instead you have some weather simulation which required a lot of reasoning
    to produce and accurately matches reality. And now you can train on that as a
    better model of the world. Like we are training on that, and stories, and like
    scientific theories.
  id: totrans-split-333
  prefs: []
  type: TYPE_NORMAL
  zh: 也有一个验证器，对吧？有现实世界。你可能会提出一个有关神灵引起风暴的理论，然后别人找到反例。这样就不能符合你的验证功能。现在你有了一些需要大量推理才能产生并且准确匹配现实的天气模拟。现在你可以用它作为更好的世界模型进行训练。就像我们正在用它和故事以及科学理论进行训练。
- en: '**Dwarkesh Patel** *00:58:27*'
  id: totrans-split-334
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *00:58:27*'
- en: I want to go back. I'm just remembering something you mentioned a little while
    ago how given how empirical ML is, it really is an evolutionary process resulting
    in better performance and not necessarily an individual coming up with a breakthrough
    in a top-down way. That has interesting implications.
  id: totrans-split-335
  prefs: []
  type: TYPE_NORMAL
  zh: 我想回头。我刚想起你前一段时间提到的一些东西，即使是经验主义的机器学习，也确实是一个导致性能提升的进化过程，而不仅仅是个体以自上而下方式进行突破。这有趣的含义。
- en: First, people are concerned about capabilities increasing because more people
    are going into the field. I've been somewhat skeptical of that way of thinking,
    but from this perspective of just more input, it really does feel like more people
    going to [ICML](https://icml.cc/) means that there's faster progress towards GPT-5.
  id: totrans-split-336
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，人们担心能力的提升是因为越来越多的人进入这个领域。我对这种思维方式有些怀疑，但从增加输入的角度来看，确实感觉更多人参加[ICML](https://icml.cc/)意味着更快的进展，朝着GPT-5迈进。
- en: '**Trenton Bricken** *00:59:13*'
  id: totrans-split-337
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:59:13*'
- en: You just have more genetic recombination. And shots on target.
  id: totrans-split-338
  prefs: []
  type: TYPE_NORMAL
  zh: 你只是有更多的基因重组。和射击的目标。
- en: '**Sholto Douglas** *00:59:17*'
  id: totrans-split-339
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *00:59:17*'
- en: I mean, aren't all fields kind of like that? This is sort of the scientific
    framing of discovery versus invention, right? Discovery almost involves whenever
    there's been a massive scientific breakthrough in the past. Typically there are
    multiple people co-discovering a thing at roughly the same time. That feels to
    me, at least a little bit, like the mixing and trying of ideas. You can't try
    an idea that's so far out of scope that you have no way of verifying with the
    tools you have available.
  id: totrans-split-340
  prefs: []
  type: TYPE_NORMAL
  zh: 我的意思是，难道不是所有领域都有点这样吗？这有点像发现与发明的科学框架，对吧？发现几乎总是在过去的大科学突破时出现。通常有多人几乎同时共同发现一件事情。至少在我看来，这有点像混合和尝试不同的想法。你不能试验一个远远超出你现有工具验证范围的想法。
- en: '**Trenton Bricken** *00:59:45*'
  id: totrans-split-341
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *00:59:45*'
- en: I think physics and math might be slightly different in this regard. But especially
    for biology or any sort of wetware, to the extent we want to analogize neural
    networks here, it's just comical how serendipitous a lot of the discoveries are.
    Penicillin, for example.
  id: totrans-split-342
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为在这方面，物理学和数学可能有些不同。但是特别是对于生物学或任何类型的生物硬件，如果我们想在这里类比神经网络，很多发现是多么的偶然和幸运。例如青霉素。
- en: '**Dwarkesh Patel** *01:00:01*'
  id: totrans-split-343
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:00:01*'
- en: Another implication of this is the idea that AGI is just going to come tomorrow.
    Somebody's just going to discover a new algorithm and we have AGI. That seems
    less plausible. It will just be a matter of more and more and more researchers
    finding these marginal things that all add up together to make models better.
  id: totrans-split-344
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个影响是AGI明天就会来的想法。有人会发现一个新算法，我们就有了AGI。这似乎不太可能。更多研究人员找到这些边缘事物的总和，才会使模型变得更好。
- en: '**Sholto Douglas** *01:00:19*'
  id: totrans-split-345
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:00:19*'
- en: Right. That feels like the correct story to me.
  id: totrans-split-346
  prefs: []
  type: TYPE_NORMAL
  zh: 是的。对我来说，这感觉是正确的故事。
- en: '**Trenton Bricken** *01:00:23*'
  id: totrans-split-347
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:00:23*'
- en: Especially while we're still hardware constrained.
  id: totrans-split-348
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是在我们仍然受到硬件限制的时候。
- en: '**Dwarkesh Patel** *01:00:25*'
  id: totrans-split-349
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:00:25*'
- en: Right. Do you buy this narrow window framing of the intelligence explosion?
    Each GPT-3, GPT-4 is two OOMs, orders of magnitude, more compute or at least more
    effective compute. In the sense that, if you didn't have any algorithmic progress,
    it would have to be two orders of magnitude bigger, the raw form, to be as good.
    Do you buy the framing that, given that you have to be two orders of magnitude
    bigger at every generation, if you don't get AGI by GPT-7 that can help you catapult
    an intelligence explosion, you're kind of just fucked as far as much smarter intelligence
    goes. You're kind of stuck with GPT-7 level models for a long time because at
    that point you're consuming significant fractions of the economy to make that
    model and we just don't have the wherewithal to make GPT 8.
  id: totrans-split-350
  prefs: []
  type: TYPE_NORMAL
  zh: 对。你是否同意这种智能爆炸的狭窄窗口框架？每个GPT-3、GPT-4都是两个数量级的计算，或者至少是更有效的计算。从这个意义上讲，如果没有任何算法进展，那么每一代都必须比原始形式大两个数量级，才能达到同样的水平。你是否同意这样的框架，即如果在GPT-7之前没有达到可以帮助你推动智能爆炸的AGI，你在更聪明的智能方面就会陷入困境？在那时，你会消耗经济的显著部分来创建这样的模型，而我们目前还没有能力制造GPT-8。
- en: '**Trenton Bricken** *01:01:19*'
  id: totrans-split-351
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:01:19*'
- en: This is the Carl Shulman sort of argument that we're going to race through the
    orders of magnitude in the near term, but then in the longer term it would be
    harder.
  id: totrans-split-352
  prefs: []
  type: TYPE_NORMAL
  zh: 这是卡尔·舒尔曼提出的一种论点，即我们将在短期内通过数量级的竞争，但在长期内将变得更加困难。
- en: '**Dwarkesh Patel** *01:01:28*'
  id: totrans-split-353
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:01:28*'
- en: He's probably talked about it a lot but I do buy that framing.
  id: totrans-split-354
  prefs: []
  type: TYPE_NORMAL
  zh: 他可能谈论了很多次，但我确实认同这种框架。
- en: '**Sholto Douglas** *01:01:33*'
  id: totrans-split-355
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:01:33*'
- en: I generally buy that. Increases in order of magnitude of compute means in absolute
    terms, almost diminishing returns on capability, right? We've seen over a couple
    of orders of magnitude, models go from being unable to do anything to being able
    to do huge amounts.
  id: totrans-split-356
  prefs: []
  type: TYPE_NORMAL
  zh: 我基本上赞同。计算能力数量级的增加意味着在绝对术语上，能力减少的回报，对吧？我们已经看到，在几个数量级的增长中，模型从无法做任何事情到能够做大量事情。
- en: It feels to me that each incremental order of magnitude gives more nines of
    reliability at things. So it unlocks things like agents. But at least at the moment,
    it doesn't feel like reasoning improves linearly, but rather somewhat sublinearly.
  id: totrans-split-357
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，每增加一个数量级都会提供更多的可靠性，比如解锁代理程序之类的东西。但至少目前看来，推理能力并没有线性改进，而是相对次线性改进。
- en: '**Dwarkesh Patel** *01:02:04*'
  id: totrans-split-358
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:02:04*'
- en: That's actually a very bearish sign. We were chatting with one of our friends
    and he made the point that if you look at what new applications are unlocked by
    GPT-4 relative to GPT-3.5, it's not clear that it’s that much more. A GPT-3.5
    can do perplexity or whatever. So if there’s this diminishing increase in capabilities
    and that costs exponentially more to get, that's actually a bearish sign on what
    4.5 will be able to do or what 5 will unlock in terms of economic impact.
  id: totrans-split-359
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上是一个非常悲观的信号。我们和我们的一个朋友聊天时，他提到，如果看看GPT-4相对于GPT-3.5解锁了哪些新应用，不清楚它能做到更多。一个GPT-3.5可以做困惑度或者其他什么。所以如果能力增长递减，并且获取这些能力的成本呈指数增长，这实际上是对GPT-4.5或者GPT-5在经济影响方面能够做什么或者能够解锁什么的悲观迹象。
- en: '**Sholto Douglas** *01:02:37*'
  id: totrans-split-360
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:02:37*'
- en: That being said, for me the jump between 3.5 and 4 is pretty huge. So another
    3.5 to 4 jump is ridiculous. If you imagine 5 as being a 3.5 to 4 jump, straight
    off the bat in terms of ability to do SATs and this kind of stuff.
  id: totrans-split-361
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，对我来说，从3.5到4的跳跃已经相当巨大了。所以从3.5到4的跳跃再次出现就太荒谬了。如果你想象5是从3.5到4的跳跃，直接看SAT和这类东西的能力就知道了。
- en: '**Trenton Bricken** *01:02:53*'
  id: totrans-split-362
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:02:53*'
- en: Yeah, the LSAT performance was particularly striking.
  id: totrans-split-363
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，LSAT表现特别引人注目。
- en: '**Sholto Douglas** *01:02:55*'
  id: totrans-split-364
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:02:55*'
- en: Exactly. You go from not super smart to very smart to utter genius in the next
    generation instantly. And it doesn't, at least to me, feel like we're going to
    jump to utter genius in the next generation, but it does feel like we'll get very
    smart plus lots of reliability. TBD what that continues to look like.
  id: totrans-split-365
  prefs: []
  type: TYPE_NORMAL
  zh: 确实。下一代立即从智力不是特别聪明到非常聪明再到完全天才。至少对我来说，感觉不像我们会在下一代跳到完全天才，但确实感觉我们会变得非常聪明加上很多可靠性。尚未确定这将继续如何演变。
- en: '**Dwarkesh Patel** *01:03:20*'
  id: totrans-split-366
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:03:20*'
- en: Will GOFAI be part of the intelligence explosion? You talked about synthetic
    data, but in fact it would be writing its own source code in some important way.
    There was an [interesting paper](https://arxiv.org/html/2402.18153v1#:~:text=The%20diffusion%20model%20then%20learns,conditioned%20on%20a%20given%20dataset.&text=Intuitively%2C%20based%20on%20the%20training,the%20network%20was%20trained%20on.)
    that you can use diffusion to come up with model weights. I don't know how legit
    that was or whatever, but something like that.
  id: totrans-split-367
  prefs: []
  type: TYPE_NORMAL
  zh: GOFAI 是否会成为智能爆炸的一部分？你谈到了合成数据，但事实上，它可能会以某种重要方式编写自己的源代码。有一篇[有趣的论文](https://arxiv.org/html/2402.18153v1#:~:text=The%20diffusion%20model%20then%20learns,conditioned%20on%20a%20given%20dataset.&text=Intuitively%2C%20based%20on%20the%20training,the%20network%20was%20trained%20on.)提到，你可以使用扩散来得出模型权重。我不知道那个论文有多正当或其他什么，但类似的东西。
- en: '**Trenton Bricken** *01:03:41*'
  id: totrans-split-368
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:03:41*'
- en: So GOFAI is good old-fashioned AI, right? Can you define that? Because when
    I hear it, I think “if else” statements for symbolic logic.
  id: totrans-split-369
  prefs: []
  type: TYPE_NORMAL
  zh: 所以 GOFAI 是传统的人工智能，对吧？你能定义一下吗？因为当我听到它时，我想到的是符号逻辑的“如果-否则”语句。
- en: '**Sholto Douglas** *01:03:53*'
  id: totrans-split-370
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:03:53*'
- en: I actually want to make sure we fully unpack the model improvement increments.
    I don't want people to come away with the perspective that this is super bearish
    and models aren't going to get much better. I want to emphasize that the jumps
    that we've seen so far are huge. Even if those continue on a smaller scale, we're
    still in for extremely smart, very reliable agents over the next couple of orders
    of magnitude.
  id: totrans-split-371
  prefs: []
  type: TYPE_NORMAL
  zh: 我实际上想确保我们充分解析模型改进的增量。我不希望人们以为这是非常悲观的，模型不会有很大改进。我想强调迄今为止我们已经看到的跳跃是巨大的。即使这些跳跃在较小的规模上继续，我们仍然将迎来在未来几个数量级上极其智能、非常可靠的代理。
- en: We didn't fully close the thread on the narrow window thing. Let's say GPT-4
    cost a hundred million dollars or whatever. You have the 1B run, 10B run, 100B
    run. All seem very plausible by private company standards.
  id: totrans-split-372
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有完全解决狭窄窗口的问题。假设 GPT-4 花费了一亿美元或其他什么。你有 10 亿次运行，100 亿次运行，1000 亿次运行。按照私营公司的标准，所有这些都看起来非常可能。
- en: '**Trenton Bricken** *01:04:41*'
  id: totrans-split-373
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:04:41*'
- en: You mean in terms of dollars?
  id: totrans-split-374
  prefs: []
  type: TYPE_NORMAL
  zh: 你指的是在美元方面？
- en: '**Sholto Douglas** *01:04:42*'
  id: totrans-split-375
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:04:42*'
- en: In terms of dollar amount. You can also imagine even a 1T run being part of
    a national consortium, on a national level but much harder on behalf of an individual
    company. But Sam is out there trying to raise $7 trillion, right? He's already
    preparing for a whole lot of magnitude.
  id: totrans-split-376
  prefs: []
  type: TYPE_NORMAL
  zh: 以美元金额来说。你也可以想象，即使是一个万亿次运行，也可能成为一个国家级联盟的一部分，但在个别公司的代表上要困难得多。但山姆正在筹集 7 万亿美元，对吧？他已经准备好迎接大量的变动。
- en: '**Trenton Bricken** *01:05:02*'
  id: totrans-split-377
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:05:02*'
- en: He's shifted the Overton window.
  id: totrans-split-378
  prefs: []
  type: TYPE_NORMAL
  zh: 他已经转变了 Overton 窗口。
- en: '**Sholto Douglas** *01:05:03*'
  id: totrans-split-379
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:05:03*'
- en: He's shifting the magnitude here beyond the national level. So I want to point
    out that we have a lot more jumps. Even if those jumps are relatively smaller,
    that's still a pretty stark improvement in capability.
  id: totrans-split-380
  prefs: []
  type: TYPE_NORMAL
  zh: 他正在将这里的重要性转变到国家级别之外。所以我想指出，我们还有更多的进步。即使这些进步相对较小，这仍然是能力上的相当显著改进。
- en: '**Trenton Bricken** *01:05:18*'
  id: totrans-split-381
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:05:18*'
- en: Not only that, but if you believe claims that GPT-4 is around 1 trillion parameter
    count, well the human brain is between 30 and 300 trillion synapses. That's obviously
    not a one-to-one mapping and we can debate the numbers, but it seems pretty plausible
    that we're below brain scale still.
  id: totrans-split-382
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅如此，但如果你相信 GPT-4 的参数约为 1 万亿，那么人脑的突触数在 3000 到 30000 亿之间。显然这不是一一对应的关系，我们可以讨论这些数字，但看起来很可能我们仍然低于大脑的规模。
- en: '**Dwarkesh Patel** *01:05:37*'
  id: totrans-split-383
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:05:37*'
- en: So crucially, the point is that the algorithmic overhead is really high. Maybe
    this is something we should touch on explicitly. Even if you can't keep dumping
    more compute beyond the models that cost a trillion dollars or something, the
    fact that the brain is so much more data efficient implies that if we have the
    compute, if we have the brain's algorithm to train, if you could train as a sample
    efficient as humans train from birth, then we could make the AGI.
  id: totrans-split-384
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，关键是算法开销真的很高。也许这是我们应该明确触及的事情。即使你无法继续投入超过一万亿美元之类的模型，事实上，大脑的数据效率要高得多，这意味着如果我们拥有计算能力，如果我们有大脑的算法来训练，如果你能像人类从出生开始那样高效地训练，那么我们就能制造出通用人工智能。
- en: '**Trenton Bricken** *01:06:09*'
  id: totrans-split-385
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:06:09*'
- en: I never know exactly how to think about the sample efficiency stuff because
    obviously a lot of things are hardwired in certain ways. They're the coevolution
    of language and the brain structure. So it's hard to say. There are also some
    results that indicate that if you make your model bigger, it becomes more sample
    efficient.
  id: totrans-split-386
  prefs: []
  type: TYPE_NORMAL
  zh: 我从来不知道如何准确地思考样本效率的问题，因为显然很多事情都是以某种方式硬编码的。它们是语言和大脑结构的共同进化。所以很难说。还有一些结果表明，如果你让你的模型更大，它就会变得更加样本效率。
- en: '**Sholto Douglas** *01:06:29*'
  id: totrans-split-387
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:06:29*'
- en: The [original scaling laws paper](https://arxiv.org/abs/2001.08361), right?
    The logic model is almost empty.
  id: totrans-split-388
  prefs: []
  type: TYPE_NORMAL
  zh: '[原始缩放定律论文](https://arxiv.org/abs/2001.08361)，对吧？逻辑模型几乎是空的。'
- en: '**Trenton Bricken** *01:06:33*'
  id: totrans-split-389
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:06:33*'
- en: Right. So maybe that just solves it. You don't have to be more data efficient,
    but if your model is bigger then you also just are more efficient.
  id: totrans-split-390
  prefs: []
  type: TYPE_NORMAL
  zh: 对。所以也许这就解决了。你不必更节省数据，但如果你的模型更大，你也更有效率。
- en: '**Dwarkesh Patel** *01:06:42*'
  id: totrans-split-391
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:06:42*'
- en: What is the explanation for why that would be the case? A  bigger model sees
    these exact same data and at the end of seeing that data it learns more from it?
    Does it have more space to represent it?
  id: totrans-split-392
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么会这样？更大的模型看到完全相同的数据，在看到这些数据的最后，它能从中学到更多吗？它有更多空间来表示它吗？
- en: '**Trenton Bricken** *01:06:52*'
  id: totrans-split-393
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:06:52*'
- en: This is my very naive take here. One thing about the [superposition hypothesis](https://transformer-circuits.pub/2022/toy_model/index.html)
    that interpretability has pushed is that your model is dramatically underparameterized
    and that's typically not the narrative that [deep learning](https://en.wikipedia.org/wiki/Deep_learning)
    has pursued, right? But if you're trying to train a model on the entire internet
    and have it predict with incredible fidelity, you are in the underparameterized
    regime and you're having to compress a ton of things and take on a lot of noisy
    interference in doing so. When you have a bigger model, you can have cleaner representations
    to work with.
  id: totrans-split-394
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是我非常天真的看法。有关[叠加假设](https://transformer-circuits.pub/2022/toy_model/index.html)，可解释性推动的一点是，你的模型被严重低参数化，而这通常不是深度学习追求的叙述，对吧？但是，如果你试图在整个互联网上训练模型，并以令人难以置信的保真度进行预测，你就处于低参数化的状态，并且必须压缩大量内容，并在此过程中承担大量噪声干扰。当你有一个更大的模型时，你可以使用更清晰的表示。
- en: '**Dwarkesh Patel** *01:07:25*'
  id: totrans-split-395
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:07:25*'
- en: For the audience, you should unpack that. Why that first of all? What is superposition
    and why is that an implication of superposition?
  id: totrans-split-396
  prefs: []
  type: TYPE_NORMAL
  zh: 对于观众，你应该详细解释一下。首先为什么要这样？什么是叠加，为什么这是叠加的一个涵义？
- en: '**Trenton Bricken** *01:07:32*'
  id: totrans-split-397
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:07:32*'
- en: Sure. This was before I joined Anthropic. The fundamental result is from a paper
    titled “[Toy Models of Superposition](https://transformer-circuits.pub/2022/toy_model/index.html).”
    It finds that even for small models, if you are in a regime where your data is
    high-dimensional and sparse–by sparse I mean, any given data point doesn't appear
    very often–your model will learn a compression strategy that we call superposition
    so that it can pack more features of the world into it than it has parameters.
  id: totrans-split-398
  prefs: []
  type: TYPE_NORMAL
  zh: 当然。这是我加入Anthropic之前的事情。基本结果来自一篇名为“[叠加玩具模型](https://transformer-circuits.pub/2022/toy_model/index.html)”的论文。它发现，即使对于小模型，如果你处于数据高维稀疏的情况下——稀疏意味着，任何给定的数据点并不经常出现——你的模型将学习一种我们称之为叠加的压缩策略，以便它可以将世界的更多特征打包进去，而不仅仅是它的参数。
- en: I think both of these constraints apply to the real world, and modeling internet
    data is a good enough proxy for that. There's only one Dwarkesh. There's only
    one shirt you're wearing. There's this Liquid Death can here. These are all objects
    or features and how you define a feature is tricky. You're in a really high-dimensional
    space because there's so many of them and they appear very infrequently. In that
    regime, your model will learn compression
  id: totrans-split-399
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这些限制都适用于现实世界，并且对互联网数据建模是一个足够好的代理。这里只有一个德瓦克什。你穿的衬衫只有一件。这里有一罐液体死亡饮料。这些都是对象或特征，如何定义一个特征是棘手的问题。你处于一个非常高维的空间，因为这些特征很多而且出现得非常少。在这种情况下，你的模型将学习压缩策略。
- en: To riff a little bit more on this, I believe that the reason networks are so
    hard to interpret is in a large part because of this superposition. If you take
    a model and you look at a given neuron in it, a given unit of computation, and
    you ask, “how is this neuron contributing to the output of the model when it fires?”
    When you look at the data that it fires for, it's very confusing. It'll be like
    ten percent of every possible input. It’ll fire for “Chinese” but also “fish”
    and “trees”, and the full stop in URLs.
  id: totrans-split-400
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步探讨一下，我认为网络之所以难以解释，很大程度上是因为这种超级定位。如果你拿一个模型，看它的某个神经元，一个计算单元，然后问，“当它激活时，这个神经元如何对模型的输出做出贡献？”当你查看它激活的数据时，非常令人困惑。它可能对“中国”、“鱼”、“树”以及URL中的句号都会激活。
- en: But the paper that we put out last year, “[Towards Monosemanticity](https://transformer-circuits.pub/2023/monosemantic-features),”
    shows that if you project the activations into a higher-dimensional space and
    provide a sparsity penalty, you get out very clean features and things all of
    a sudden start to make a lot more sense. You can think of this as undoing the
    compression in the same way that you assumed your data was originally high-dimensional
    and sparse. You return it to that high-dimensional and sparse regime.
  id: totrans-split-401
  prefs: []
  type: TYPE_NORMAL
  zh: 但是我们去年发表的那篇论文，“[朝向单义性](https://transformer-circuits.pub/2023/monosemantic-features)，”表明，如果你将激活投影到一个更高维度的空间并施加稀疏惩罚，你会得到非常清晰的特征，一切突然开始变得更有意义。你可以将其看作是解开压缩的方式，就像你最初假设你的数据是高维稀疏的一样，将其恢复到那种高维稀疏的状态。
- en: '**Dwarkesh Patel** *01:09:36*'
  id: totrans-split-402
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:09:36*'
- en: There's so many interesting threads there. First thing, you mentioned that these
    models are trained in a regime where they're overparameterized. Isn't that when
    you have generalization, like [grokking](https://arxiv.org/abs/2201.02177) happens
    in that regime?
  id: totrans-split-403
  prefs: []
  type: TYPE_NORMAL
  zh: 那里有许多有趣的主题。首先，你提到这些模型是在它们被过度参数化的状态下训练的。在这种状态下，像[grokking](https://arxiv.org/abs/2201.02177)这样的泛化现象是否会发生？
- en: '**Trenton Bricken** *01:09:57*'
  id: totrans-split-404
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:09:57*'
- en: I was saying the models were underparameterized. Typically people talk about
    deep learning as if the model were overparameterized. The claim here is that they're
    dramatically underparameterized, given the complexity of the task that they're
    trying to perform.
  id: totrans-split-405
  prefs: []
  type: TYPE_NORMAL
  zh: 我说的是模型被欠参数化了。通常人们谈论深度学习时都认为模型被过度参数化了。这里的说法是，鉴于它们试图执行的任务的复杂性，它们实际上被严重地欠参数化了。
- en: '**Dwarkesh Patel** *01:10:14*'
  id: totrans-split-406
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:10:14*'
- en: Here’s another question. So what is happening with the [distilled models](https://en.wikipedia.org/wiki/Knowledge_distillation#:~:text=In%20machine%20learning%2C%20knowledge%20distillation,might%20not%20be%20fully%20utilized.)?
    The earlier claims we were talking about is that smaller models are worse at learning
    than bigger models, but you could make the claim that GPT-4 Turbo is actually
    worse at reasoning style stuff than GPT-4 despite probably knowing the same facts.
    The distillation got rid of some of the reasoning.
  id: totrans-split-407
  prefs: []
  type: TYPE_NORMAL
  zh: 这里还有另一个问题。关于[蒸馏模型](https://en.wikipedia.org/wiki/Knowledge_distillation#:~:text=In%20machine%20learning%2C%20knowledge%20distillation,might%20not%20be%20fully%20utilized.)发生了什么？我们之前讨论过的说法是，较小的模型比较大的模型更差，但你可以说GPT-4
    Turbo在推理风格方面实际上比GPT-4更差，尽管可能知道相同的事实。蒸馏去除了一些推理能力。
- en: '**Sholto Douglas** *01:10:44*'
  id: totrans-split-408
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:10:44*'
- en: Do we have any evidence that GPT-4 Turbo is a distilled version of 4? It might
    just be a new architecture. It could just be a faster, more efficient new architecture.
  id: totrans-split-409
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有证据表明GPT-4 Turbo是GPT-4的蒸馏版本吗？它可能只是一个新的架构。它可能只是一个更快、更高效的新架构。
- en: '**Dwarkesh Patel** *01:10:53*'
  id: totrans-split-410
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:10:53*'
- en: Okay. Interesting.
  id: totrans-split-411
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，有趣。
- en: '**Sholto Douglas** *01:10:54*'
  id: totrans-split-412
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:10:54*'
- en: So that's cheaper.
  id: totrans-split-413
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这样更便宜。
- en: '**Dwarkesh Patel** *01:10:56*'
  id: totrans-split-414
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:10:56*'
- en: How do you interpret what's happening in distillation? I think Gwern had [one
    of these questions](https://gwern.net/note/sparsity) on his website. Why can't
    you train the distilled model directly? Why is it a picture you had to project
    from this bigger space to a smaller space?
  id: totrans-split-415
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何解释蒸馏过程中发生的事情？我记得格伦在他的网站上有[这样一个问题](https://gwern.net/note/sparsity)。为什么不能直接训练蒸馏后的模型？为什么要从更大的空间投影到一个较小的空间？
- en: '**Trenton Bricken** *01:11:14*'
  id: totrans-split-416
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:11:14*'
- en: I think both models will still be using superposition. The claim here is that
    you get a very different model if you distill versus if you train from scratch
    and it's just more efficient, or it's just fundamentally different, in terms of
    performance.
  id: totrans-split-417
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为两种模型仍将使用叠加效应。这里的主张是，如果你进行精炼而不是从头开始训练，你会得到一个非常不同的模型，它更高效，或者说在性能上有根本性的不同。
- en: '**Sholto Douglas** *01:11:32*'
  id: totrans-split-418
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:11:32*'
- en: I think the traditional story for why distillation is more efficient is during
    training, normally you're trying to predict this one hot vector that says, “this
    is the token that you should have predicted.” If your reasoning process means
    that you're really far off from predicting that, then I see that you still get
    these gradient updates that are in the right direction. But it might be really
    hard for you to learn to predict that in the context that you're in.
  id: totrans-split-419
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为关于为什么精炼更高效的传统说法是，在训练期间，通常你试图预测这个独热向量，它表示“这是你应该预测的标记”。如果你的推理过程意味着你离正确预测还很远，那么我看到你仍然得到这些梯度更新，它们是正确方向的。但在你所处的上下文中学习预测可能会非常困难。
- en: What distillation does is it doesn't just have the one hot vector. It has the
    full readout from the larger model, all of the probabilities. So you get more
    signal about what you should have predicted. In some respects it's showing a tiny
    bit of your work too. It's not just like, “this was the answer.”
  id: totrans-split-420
  prefs: []
  type: TYPE_NORMAL
  zh: 精炼所做的不仅仅是拥有一个独热向量。它还具有来自较大模型的全部输出，所有概率。因此，你会得到更多关于你应该预测什么的信号。在某些方面，它也展示了你的一点工作。它不仅仅是“这是答案”。
- en: '**Trenton Bricken** *01:12:20*'
  id: totrans-split-421
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:12:20*'
- en: It's kind of like watching a kung fu master versus being in the Matrix and just
    downloading.
  id: totrans-split-422
  prefs: []
  type: TYPE_NORMAL
  zh: 这有点像看功夫大师对决而不是身临其境地下载到矩阵中。
- en: '**Sholto Douglas** *01:12:24*'
  id: totrans-split-423
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:12:24*'
- en: Yeah, exactly.
  id: totrans-split-424
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，确实如此。
- en: '**Dwarkesh Patel** *01:12:27*'
  id: totrans-split-425
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:12:27*'
- en: I want to make sure the audience got that. When you're turning on a distilled
    model you see all its probabilities over the tokens it was predicting and over
    the ones you were predicting, and then you update through all those probabilities
    rather than just seeing the last word and updating on that.
  id: totrans-split-426
  prefs: []
  type: TYPE_NORMAL
  zh: 我想确保观众理解了这一点。当你打开一个精炼模型时，你会看到它对它预测的所有标记的概率以及你预测的标记的概率，然后你通过所有这些概率来更新，而不仅仅是看到最后一个词并对其进行更新。
- en: This actually raises a question I was intending to ask you. I think you were
    the one who mentioned that you can think of chain-of-thought as adaptive compute.
    The idea of adaptive compute is that if a question is harder, you would want models
    to be able to spend more cycles thinking about it. So how do you do that? There's
    only a finite and predetermined amount of compute that one forward pass implies.
    If there's a complicated reasoning type question or math problem, you want to
    be able to spend a long time thinking about it. Then you do chain-of-thought where
    the model just thinks through the answer. You can think about it as all those
    forward passes where it's thinking through the answer. It's being able to dump
    more compute into solving the problem.
  id: totrans-split-427
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上提出了我打算问你的一个问题。我记得你提到过将思维链想象为自适应计算。自适应计算的概念是，如果一个问题更难，你希望模型能够花更多的时间思考它。那么你怎么做到呢？每次前向传播都只能有限且预定的计算量。如果是一个复杂的推理类问题或数学问题，你希望能花更长时间思考。然后你就通过思维链来实现，模型只需思考答案。你可以将它看作是所有前向传播的集合，它在思考答案。它能够投入更多的计算资源来解决问题。
- en: Now let’s go back to the signal thing. When it's doing chain-of-thought, it's
    only able to transmit that token of information where the residual stream is already
    a compressed representation of everything that's happening in the model. And then
    you're turning the residual stream into one token which is like log of 50,000
    (or log of vocab_size) bits, which is so tiny.
  id: totrans-split-428
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们回到信号的问题。当它进行思维链时，它只能传输那个信息标记，其中残差流已经是模型中正在发生的一切的压缩表示。然后你将残差流转换为一个标记，这就像是
    50,000（或词汇大小的对数）比特的对数一样微小。
- en: '**Sholto Douglas** *01:14:04*'
  id: totrans-split-429
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:14:04*'
- en: I don't think it's quite only transmitting that one token. If you think about
    it during a forward pass, you create these KV values in the transformer forward
    pass and then future steps attend to the KV values. So all of those pieces of
    KV, of keys and values, are bits of information that you could use in the future.
  id: totrans-split-430
  prefs: []
  type: TYPE_NORMAL
  zh: 我不认为它完全只传输那一个标记。如果你在前向传递过程中考虑它，你会在变换器前向传递过程中创建这些KV值，然后未来步骤会关注这些KV值。所以所有这些KV的片段，键和值，都是你未来可能会用到的信息片段。
- en: '**Dwarkesh Patel** *01:14:26*'
  id: totrans-split-431
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦尔克什·帕特尔** *01:14:26*'
- en: Is the claim that when you fine-tune on chain-of-thought, the key and value
    weights change so that the sort of [steganography](https://en.wikipedia.org/wiki/Steganography)
    can happen in the [KV cache](https://medium.com/@joaolages/kv-caching-explained-276520203249)?
  id: totrans-split-432
  prefs: []
  type: TYPE_NORMAL
  zh: 它声称在链式思维上进行微调时，键和值的权重会改变，以便在[KV缓存](https://medium.com/@joaolages/kv-caching-explained-276520203249)中发生这种隐写术。
- en: '**Sholto Douglas** *01:14:39*'
  id: totrans-split-433
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:14:39*'
- en: I don't think I could make that strong a claim there, but that's a good headcanon
    for why it works. I don't know if there are any papers explicitly demonstrating
    that or anything like that.
  id: totrans-split-434
  prefs: []
  type: TYPE_NORMAL
  zh: 我不认为我能做出那么强有力的主张，但这是为什么它有效的一个很好的头脑插图。我不知道是否有任何明确展示或类似的论文。
- en: But that's at least one way that you can imagine the model. During pre-training,
    the model's trying to predict these future tokens and one thing that you can imagine
    it doing is that it’s learning to smush information about potential futures into
    the keys and values that it might want to use in order to predict future information.
  id: totrans-split-435
  prefs: []
  type: TYPE_NORMAL
  zh: 但这至少是你可以想象模型的一种方式。在预训练期间，模型试图预测这些未来的标记，你可以想象它做的一件事是学习将关于潜在未来的信息压缩到它可能希望用来预测未来信息的键和值中。
- en: It kind of smooths that information across time and the pre-training thing.
    So I don't know if people are particularly training on chains-of-thought. I think
    the [original chain-of-thought paper](https://arxiv.org/abs/2201.11903) had that
    as almost an immersion property of the model. You could prompt it to do this kind
    of stuff and it still worked pretty well. So it’s a good headcanon for why that
    works.
  id: totrans-split-436
  prefs: []
  type: TYPE_NORMAL
  zh: 它在时间上平滑了那些信息和预训练的东西。所以我不知道人们是否特别是在链式思维上进行训练。我认为[原始链式思维论文](https://arxiv.org/abs/2201.11903)将其作为模型的一种沉浸属性。你可以提示它做这种事情，它仍然可以工作得相当好。所以这是为什么它有效的一个很好的头脑插图。
- en: '**Trenton Bricken** *01:15:35*'
  id: totrans-split-437
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:15:35*'
- en: To be overly pedantic here, the tokens that you actually see in the chain-of-thought
    do not necessarily at all need to correspond to the vector representation that
    the model gets to see when it's deciding to attend back to those tokens.
  id: totrans-split-438
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里过分追究细节，你实际在思维链中看到的标记并不一定需要完全对应模型在决定回顾这些标记时看到的向量表示。
- en: '**Sholto Douglas** *01:15:49*'
  id: totrans-split-439
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:15:49*'
- en: What a training step is is you actually replacing the token, the model output,
    with the real next token. Yet it's still learning because it has all this information,
    internally. When you're getting a model to produce at inference time, you're taking
    the output, the token, and you're feeding it in the bottom, un-embedding it, and
    it becomes the beginning of the new residual string. Then you use the output of
    past KVs to read into and adapt that residual string. At training time you do
    this thing called [teacher forcing](https://en.wikipedia.org/wiki/Teacher_forcing)
    basically where you're like, “actually, the token you were meant to output is
    this one.”
  id: totrans-split-440
  prefs: []
  type: TYPE_NORMAL
  zh: 训练步骤实际上是用真实的下一个标记替换标记，模型输出。然而它仍在学习，因为它内部有所有这些信息。当你让模型在推理时产生输出时，你取出输出的标记，将其底部的嵌入取消，它变成新残留字符串的开头。然后你使用过去KV的输出来读取和适应该残留字符串。在训练时，你要做的是这个被称为[教师强迫](https://en.wikipedia.org/wiki/Teacher_forcing)，基本上你是在说，“实际上，你应该输出的标记是这个。”
- en: That's how you do it in parallel. You have all the tokens. You put them all
    in parallel and you do the giant forward pass. So the only information it's getting
    about the past is the keys and values. It never sees the token that it outputs.
  id: totrans-split-441
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是你并行处理的方式。你有所有的标记。你将它们全部并行放置，进行巨大的前向传递。所以它关于过去得到的唯一信息是键和值。它从未看到它输出的标记。
- en: '**Trenton Bricken** *01:16:42*'
  id: totrans-split-442
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:16:42*'
- en: It's trying to do the next token prediction and if it messes up, then you just
    give it the correct answer.
  id: totrans-split-443
  prefs: []
  type: TYPE_NORMAL
  zh: 它试图进行下一个标记的预测，如果出错，你只需给出正确的答案。
- en: '**Dwarkesh Patel** *01:16:48*'
  id: totrans-split-444
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦尔克什·帕特尔** *01:16:48*'
- en: Okay, that makes sense.
  id: totrans-split-445
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，那听起来有道理。
- en: '**Trenton Bricken** *01:16:50*'
  id: totrans-split-446
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:16:50*'
- en: Otherwise it can become totally derailed.
  id: totrans-split-447
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，它可能会完全偏离轨道。
- en: '**Sholto Douglas** *01:16:52*'
  id: totrans-split-448
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:16:52*'
- en: Yeah. It'd go off the tracks.
  id: totrans-split-449
  prefs: []
  type: TYPE_NORMAL
  zh: 是的。它可能会偏离轨道。
- en: '**Dwarkesh Patel** *01:16:55*'
  id: totrans-split-450
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:16:55*'
- en: About the sort of secret communication with the model to its forward inferences,
    how much steganography and secret communication do you expect there to be?
  id: totrans-split-451
  prefs: []
  type: TYPE_NORMAL
  zh: 关于模型与其前向推理的秘密通信，你认为会有多少隐写术和秘密通信？
- en: '**Sholto Douglas** *01:17:10*'
  id: totrans-split-452
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:17:10*'
- en: We don't know. The honest answer is we don't know. I wouldn't even necessarily
    classify it as secret information. A lot of the work that Trenton's team is trying
    to do is to actually understand that these are fully visible from the model side.
    Maybe not the user, but we should be able to understand and interpret what these
    values are doing and the information that is transmitting. I think that's a really
    important goal for the future.
  id: totrans-split-453
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不知道。诚实的答案是我们不知道。我甚至不一定会将其分类为秘密信息。特伦顿团队正在努力的很多工作实际上是为了理解，这些信息对于模型来说是完全可见的。也许不是对用户，但我们应该能够理解和解释这些值在做什么以及传输的信息。我认为这是未来的一个非常重要的目标。
- en: '**Trenton Bricken** *01:17:39*'
  id: totrans-split-454
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:17:39*'
- en: There are some [wild papers](https://arxiv.org/html/2402.16048v1) though where
    people have had the model do chain-of-thought and it is not at all representative
    of what the model actually decides its answer is. You can even go in and edit
    the chain-of-thought so that the reasoning is totally garbled and it will still
    output the true answer.
  id: totrans-split-455
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些[疯狂的论文](https://arxiv.org/html/2402.16048v1)，人们在那里让模型进行链式思维，但这根本不代表模型实际决定其答案是什么。你甚至可以进去编辑思维链，使推理完全混乱，它仍然会输出真实答案。
- en: '**Dwarkesh Patel** *01:17:59*'
  id: totrans-split-456
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:17:59*'
- en: But it gets a better answer at the end of the chain-of-thought, rather than
    not doing it at all. So is it that something useful is happening, but the useful
    thing is not human understandable?
  id: totrans-split-457
  prefs: []
  type: TYPE_NORMAL
  zh: 但是在思维链末端得到一个更好的答案，总比根本不去尝试要好。那么，这是否意味着某些有用的事情正在发生，只是这些有用的事情并非人类可以理解的？
- en: '**Trenton Bricken** *01:18:09*'
  id: totrans-split-458
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:18:09*'
- en: I think in some cases you can also just ablate the chain-of-thought and it would
    have given the same answer anyways. I'm not saying this is always what goes on,
    but there's plenty of weirdness to be investigated.
  id: totrans-split-459
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为在某些情况下，你甚至可以仅仅砍掉思维链，它最终仍然会给出相同的答案。我并不是说这总是发生的，但确实有很多怪异的现象需要调查。
- en: '**Sholto Douglas** *01:18:21*'
  id: totrans-split-460
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:18:21*'
- en: It's a very interesting thing to look at and try to understand. You can do it
    with open source models. I wish there were more of this kind of interpretability
    and understanding work done on open models.
  id: totrans-split-461
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一件非常有趣的事情，可以尝试去看并理解。你可以使用开源模型来完成。我希望有更多这种类型的可解释性和理解工作应用在开放模型上。
- en: '**Trenton Bricken** *01:18:34*'
  id: totrans-split-462
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:18:34*'
- en: Even in Anthropic's [recent sleeper agents paper](https://www.anthropic.com/news/sleeper-agents-training-deceptive-llms-that-persist-through-safety-training),
    which at a high level for people unfamiliar, basically involves training in a
    trigger word. And when I say it, for example, “if it's the year 2024, the model
    will write malicious code instead of otherwise. They do this attack with a number
    of different models. Some of them use chain-of-thought, some of them don't. Those
    models respond differently when you try to remove the trigger. You can even see
    them do this comical reasoning that's pretty creepy. In one case it even tries
    to calculate, “well, the expected value of me getting caught is this, but then
    if I multiply it by the ability for me to keep saying, I hate you, I hate you,
    I hate you, then this is how much reward I should get.” Then it will decide whether
    or not to actually tell the interrogator that it's malicious or not.
  id: totrans-split-463
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在人类洞察力的[最近的沉睡特工论文](https://www.anthropic.com/news/sleeper-agents-training-deceptive-llms-that-persist-through-safety-training)，对于不熟悉的人来说，在高层面基本上涉及对触发词的训练。例如，当我说“如果是2024年，模型将编写恶意代码而不是其他。他们使用多种不同的模型进行这种攻击。其中一些使用链式思维，而另一些则没有。当你尝试去除触发词时，这些模型的反应是不同的。你甚至可以看到它们进行这种颇具幽默感的推理，相当令人不安。在某些情况下，甚至试图计算，“我被抓到的预期价值是这样的，但是如果我乘以我继续说‘我讨厌你，我讨厌你，我讨厌你’的能力，那么我应该得到的奖励是多少。”然后它会决定是否告诉询问者它是否恶意。
- en: There's another [paper](https://arxiv.org/abs/2305.04388) from a friend, [Miles
    Turpin](https://www.milesturp.in/about/), where you give the model a bunch of
    examples where the correct answer is always ‘A’ for multiple choice questions.
    Then you ask the model, “what is the correct answer to this new question?” It
    will infer from the fact that all the examples are ‘A’, that the correct answer
    is ‘A.’ But its chain-of-thought is totally misleading. It will make up random
    stuff that tries to sound as plausible as possible, but it's not at all representative
    of the true answer.
  id: totrans-split-464
  prefs: []
  type: TYPE_NORMAL
  zh: 还有另一篇来自朋友的[论文](https://arxiv.org/abs/2305.04388)，[迈尔斯·特平](https://www.milesturp.in/about/)。在这篇论文中，你给模型一堆例子，其中多项选择题的正确答案始终为‘A’。然后你问模型：“这个新问题的正确答案是什么？”它会从所有例子都是‘A’这个事实推断出正确答案是‘A’。但它的思维过程完全是误导的。它会编造一些尽可能合理听起来的随机内容，但完全不代表真正的答案。
- en: '**Dwarkesh Patel** *01:20:11*'
  id: totrans-split-465
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:20:11*'
- en: But isn't this how humans think as well? There are the famous [split-brain experiments](https://en.wikipedia.org/wiki/Split-brain#History)
    where for a person who is suffering from seizures, they cut the thing that connects
    the two halves of the brain. The speech half is on the left side so it's not connected
    to the part that decides to do a movement. So if the other side decides to do
    something, the speech part will just make something up and the person will think
    that's legit the reason they did it.
  id: totrans-split-466
  prefs: []
  type: TYPE_NORMAL
  zh: 但这不就是人类思维的方式吗？有着著名的[分脑实验](https://en.wikipedia.org/wiki/Split-brain#History)，对于一些癫痫患者，他们切断了连接两个大脑半球的部分。语言功能在左侧，因此与决定进行运动的部分没有连接。所以如果另一侧决定做某事，语言部分会编造出某些理由，而人会认为那就是他们做事情的合理原因。
- en: '**Trenton Bricken** *01:20:39*'
  id: totrans-split-467
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:20:39*'
- en: Totally. It's just that some people will hail chain-of-thought reasoning as
    a great way to solve AI safety, but actually we don't know whether we can trust
    it.
  id: totrans-split-468
  prefs: []
  type: TYPE_NORMAL
  zh: 完全是这样。只是有些人会把思维链作为解决AI安全问题的好方法，但实际上我们不知道是否能信任它。
- en: '**Dwarkesh Patel** *01:20:52*'
  id: totrans-split-469
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:20:52*'
- en: How does that change with AI agents, this landscape of models communicating
    to themselves in ways we don't understand? Because then it's not just the model
    itself with its previous caches, but other instances of the model.
  id: totrans-split-470
  prefs: []
  type: TYPE_NORMAL
  zh: AI代理如何改变，这种我们无法理解的模型之间相互通信的景观？因为这时不仅仅是模型本身和它的先前缓存，还有其他模型的实例。
- en: '**Sholto Douglas** *01:21:10*'
  id: totrans-split-471
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:21:10*'
- en: It depends a lot on what channels you give them to communicate with each other.
    If you only give them text as a way of communicating, then they probably have
    to interpret–
  id: totrans-split-472
  prefs: []
  type: TYPE_NORMAL
  zh: 这在很大程度上取决于你给他们用来相互通信的渠道。如果你只给他们文本作为沟通的方式，那么他们可能需要解释--
- en: '**Dwarkesh Patel** *01:21:17*'
  id: totrans-split-473
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:21:17*'
- en: How much more effective do you think the models would be if they could share
    the residual streams versus just text?
  id: totrans-split-474
  prefs: []
  type: TYPE_NORMAL
  zh: 如果他们能够共享剩余流而不仅仅是文本，你认为模型的效果会更有效吗？
- en: '**Sholto Douglas** *01:21:23*'
  id: totrans-split-475
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:21:23*'
- en: Hard to know. One easy way that you can imagine this is as if you wanted to
    describe how a picture should look. Only describing that with text would be hard
    and maybe some other representation would plausibly be easier. So you can look
    at how [DALL-E](https://openai.com/dall-e-3) works at the moment. It produces
    those prompts and when you play with it, you often can't quite get it to do exactly
    what the model wants or what you want.
  id: totrans-split-476
  prefs: []
  type: TYPE_NORMAL
  zh: 很难说。你可以想象一种简单的方式，就像你想描述一幅图片应该看起来的样子一样。只用文字描述会很困难，也许其他一些表达方式可能更容易。所以你可以看看[DALL-E](https://openai.com/dall-e-3)目前的工作方式。它生成这些提示，当你试着用它时，你通常无法完全让它做出你或模型想要的事情。
- en: '**Dwarkesh Patel** *01:21:55*'
  id: totrans-split-477
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:21:55*'
- en: Only DALL-E has that problem
  id: totrans-split-478
  prefs: []
  type: TYPE_NORMAL
  zh: 只有DALL-E有这个问题
- en: '**Sholto Douglas** *01:21:57*'
  id: totrans-split-479
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:21:57*'
- en: You can imagine that being able to transmit some kind of denser representation
    of what you want would be helpful there. That's two very simple agents, right?
  id: totrans-split-480
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以想象，能够传输你想要的某种更密集的表达会很有帮助。那是两个非常简单的代理，对吧？
- en: '**Trenton Bricken** *01:22:23*'
  id: totrans-split-481
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:22:23*'
- en: I think a nice halfway house here would be features that you'd learn from [dictionary
    learning](https://en.wikipedia.org/wiki/Sparse_dictionary_learning).
  id: totrans-split-482
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这里一个不错的折中点是，你从[字典学习](https://en.wikipedia.org/wiki/Sparse_dictionary_learning)中学到的特征。
- en: '**Sholto Douglas** *01:22:27*'
  id: totrans-split-483
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:22:27*'
- en: That would be really, really cool.
  id: totrans-split-484
  prefs: []
  type: TYPE_NORMAL
  zh: 那将会非常、非常酷。
- en: '**Trenton Bricken** *01:22:29*'
  id: totrans-split-485
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *01:22:29*'
- en: You’d get more internal access, but a lot of it is much more human interpretable.
  id: totrans-split-486
  prefs: []
  type: TYPE_NORMAL
  zh: 你会得到更多的内部访问，但其中大部分是更易于人类解释的。
- en: '**Dwarkesh Patel** *01:22:34*'
  id: totrans-split-487
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:22:34*'
- en: For the audience, you would project the residual stream into this larger space,
    where we know what each dimension actually corresponds to, and then back into
    the next agents. So your claim is that we'll get AI agents when these things are
    more reliable and so forth. When that happens, do you expect that it will be multiple
    copies of models talking to each other? Or will it just be adaptive compute solved
    and the thing just runs bigger, with more compute when it needs to do the kind
    of thing that a whole firm needs to do.
  id: totrans-split-488
  prefs: []
  type: TYPE_NORMAL
  zh: 针对观众，你会将剩余的流投影到这个更大的空间中，我们知道每个维度实际上对应什么，然后返回到下一个代理人。那么，你的观点是当这些事物变得更可靠等等时，我们将获得AI代理人。当这种情况发生时，您是否期望会有多个模型的副本互相交流？还是说，只是适应性计算得到解决，当它需要执行整个公司需要做的那种事情时，它只是运行更大，计算量更多。
- en: I asked this because there's two things that make me wonder about whether agents
    are the right way to think about what will happen in the future. One is with longer
    context, these models are able to ingest and consider the information that no
    human can. We need one engineer who's thinking about the front-end code and one
    engineer thinking about the back-end code. Whereas this thing can just ingest
    the whole thing. This sort of [Hayekian problem of specialization](https://en.wikipedia.org/wiki/The_Use_of_Knowledge_in_Society),
    goes away.
  id: totrans-split-489
  prefs: []
  type: TYPE_NORMAL
  zh: 我问这个问题是因为有两件事情让我思考，即代理人是否是未来发展的正确思路。一是随着更长的上下文，这些模型能够摄取和考虑没有人类能做到的信息。我们需要一个工程师来思考前端代码，一个工程师来思考后端代码。而这个东西可以直接摄取整体。这种专业化的
    [哈耶克问题](https://en.wikipedia.org/wiki/The_Use_of_Knowledge_in_Society) 会消失。
- en: Second, these models are just very general. You're not using different types
    of GPT-4 to do different kinds of things. You're using the exact same model. So
    I wonder if that implies that in the future, an AI firm is just like a model instead
    of a bunch of AI agents hooked together.
  id: totrans-split-490
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，这些模型只是非常通用的。你不是在使用不同类型的 GPT-4 来做不同类型的事情。你在使用完全相同的模型。所以我想知道，这是否意味着在未来，一个AI公司只是一个模型，而不是一堆相互连接的AI代理人。
- en: '**Sholto Douglas** *01:23:57*'
  id: totrans-split-491
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:23:57*'
- en: That's a great question. I think especially in the near term, it will look much
    more like agents talking together. I say that purely because as humans, we're
    going to want to have these isolated, reliable components that we can trust. We're
    also going to need to be able to improve and instruct upon those components in
    ways that we can understand and improve. Just throwing it all into this giant
    black box company, iit isn't going to work initially. Later on of course, you
    can imagine it working, but initially it won't work. And two, we probably don't
    want to do it that way.
  id: totrans-split-492
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个很棒的问题。我认为至少在短期内，它看起来会更像是代理人彼此交流。我之所以这样说纯粹是因为作为人类，我们希望拥有这些孤立的、可靠的组件，我们可以信任。我们还需要能够以我们理解和改进的方式改进和指导这些组件。把所有东西都丢进这个巨大的黑匣子公司里，最初是行不通的。当然，你可以想象它后来会运作，但最初不会。而且，我们可能不想以这种方式做。
- en: '**Trenton Bricken** *01:24:41*'
  id: totrans-split-493
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:24:41*'
- en: Each of the agents can also be a smaller model that's cheaper to run. And you
    can fine-tune it so that it's actually good at the task.
  id: totrans-split-494
  prefs: []
  type: TYPE_NORMAL
  zh: 每个代理人也可以是一个更小、更便宜的模型。你可以微调它，使其真正擅长这个任务。
- en: '**Sholto Douglas** *01:24:49*'
  id: totrans-split-495
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:24:49*'
- en: Dwarkesh has brought up adaptive compute a couple of times. There's a future
    where the distinction between small and large models disappears to some degree.
    With long-context, there's also a degree to which fine-tuning might disappear,
    to be honest. These two things are very important today. With today's landscape
    models, we have whole different tiers of model sizes and we have fine-tuned models
    of different things. You can imagine a future where you just actually have a dynamic
    bundle of compute and infinite context, and that specializes your model to different
    things.
  id: totrans-split-496
  prefs: []
  type: TYPE_NORMAL
  zh: Dwarkesh 几次提到了适应性计算。有一个未来，小模型和大模型之间的区别在某种程度上会消失。有了长篇章，调整细节可能也会消失，老实说。这两件事在今天非常重要。在今天的景观模型中，我们有完全不同层次的模型大小，我们有不同事物的调整模型。你可以想象一个未来，你实际上只有一个动态的计算束和无限的语境，这使你的模型对不同的事物专门化。
- en: '**Dwarkesh Patel** *01:25:23*'
  id: totrans-split-497
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:25:23*'
- en: 'One thing you can imagine is you have an AI firm or something, and the whole
    thing is end-to-end trained on the signal of, “did I make profits?” Or if that''s
    too ambiguous, if it''s an architecture firm and they''re making blueprints: “did
    my client like the blueprints?” In the middle, you can imagine agents who are
    salespeople and agents who are doing the designing, agents who do the editing,
    whatever. Would that kind of signal work on an end-to-end system like that? Because
    one of the things that happens in human firms is management considers what''s
    happening at the larger level and gives these fine-grain signals to the pieces
    when there''s a bad quarter or whatever.'
  id: totrans-split-498
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以想象，你有一个人工智能公司或其他什么公司，整个公司都是端到端地基于这样一个信号训练的：“我是否赚了钱？”或者如果这太模糊了，如果是一家建筑公司并且他们在制定蓝图：“我的客户喜欢这些蓝图吗？”在中间，你可以想象到既是销售人员又是设计人员的代理人，还有做编辑的代理人，等等。这样的端到端系统能起作用吗？因为在人类公司中，管理层考虑到更大层面上发生的事情，并给这些部分提供这些细粒度的信号，比如说在一个不好的季度或者其他什么情况下。
- en: '**Sholto Douglas** *01:26:02*'
  id: totrans-split-499
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:26:02*'
- en: In the limit, yes. That's the dream of [reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning).
    All you need to do is provide this extremely sparse signal. Then over enough iterations,
    you create the information that allows you to learn from that signal. But I don't
    expect that to be the thing that works first. I think this is going to require
    an incredible amount of care and diligence from humans surrounding these machines
    and making sure they do exactly the right thing, and exactly what you want, and
    giving them the right signals to improve in the ways that you want.
  id: totrans-split-500
  prefs: []
  type: TYPE_NORMAL
  zh: 在极限情况下，是的。那就是[强化学习](https://en.wikipedia.org/wiki/Reinforcement_learning)的梦想。你只需要提供这个极其稀疏的信号。然后经过足够多的迭代，你创造出能让你从那个信号中学习的信息。但我不认为这会是第一次成功的尝试。我认为这将需要人类在这些机器周围非常小心和尽责，确保它们做的正是你想要的，并且给它们正确的信号，以便在你期望的方式上改进。
- en: '**Trenton Bricken** *01:26:32*'
  id: totrans-split-501
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:26:32*'
- en: Yeah, you can't train on the RL reward unless the model generates some reward.
  id: totrans-split-502
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，除非模型产生了一些奖励，否则无法训练RL奖励。
- en: '**Sholto Douglas** *01:26:37*'
  id: totrans-split-503
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:26:37*'
- en: Exactly. You're in this sparse RL world where if the client never likes what
    you produce, then you don't get any reward at all and it's kind of bad.
  id: totrans-split-504
  prefs: []
  type: TYPE_NORMAL
  zh: 没错。你处在这个稀疏的强化学习世界中，如果客户从未喜欢你的成果，那么你就得不到任何奖励，这有点糟糕。
- en: '**Dwarkesh Patel** *01:26:47*'
  id: totrans-split-505
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:26:47*'
- en: But in the future, these models will be good enough to get the reward some of
    the time, right?
  id: totrans-split-506
  prefs: []
  type: TYPE_NORMAL
  zh: 但在未来，这些模型将足够好以获取奖励的时间，对吧？
- en: '**Trenton Bricken** *01:26:50*'
  id: totrans-split-507
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:26:50*'
- en: This is the nines of reliability that Sholto was talking about.
  id: totrans-split-508
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Sholto谈到的可靠性的九宫格。
- en: '**Dwarkesh Patel** *01:26:54*'
  id: totrans-split-509
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:26:54*'
- en: There's an interesting digression by the way on what we were talking about earlier.
    Dense representations would be favored, right? That's a more efficient way to
    communicate. A book that Trenton recommended, *[The Symbolic Species](https://en.wikipedia.org/wiki/The_Symbolic_Species)*,
    has this really interesting argument that language is not just a thing that exists,
    but it was also something that evolved along with our minds and specifically evolved
    to be both easy to learn for children and something that helps children develop.
  id: totrans-split-510
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一句，我们之前讨论的内容有一个有趣的分歧。密集的表达会更受青睐，对吧？这是更有效沟通的一种方式。Trenton推荐的一本书，*[符号物种](https://en.wikipedia.org/wiki/The_Symbolic_Species)*，提出了一个非常有趣的论点，即语言不仅仅是存在的一件事，而且它也是随着我们的思想一起进化的，特别是进化成为一种对于孩子来说容易学习的东西，并帮助孩子发展的东西。
- en: '**Sholto Douglas** *01:27:33*'
  id: totrans-split-511
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:27:33*'
- en: Unpack that for me.
  id: totrans-split-512
  prefs: []
  type: TYPE_NORMAL
  zh: 解释一下这个给我。
- en: '**Dwarkesh Patel** *01:27:35*'
  id: totrans-split-513
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:27:35*'
- en: Because a lot of the things that children learn are received through language,
    the languages that would be the fittest are the ones that help raise the next
    generation. And that makes them smarter, better, or whatever.
  id: totrans-split-514
  prefs: []
  type: TYPE_NORMAL
  zh: 因为孩子们学习的很多东西是通过语言传达的，所以那些能帮助抚养下一代的语言将会是最适合的语言。这使得他们更聪明、更优秀，或者其他什么。
- en: '**Sholto Douglas** *01:27:50*'
  id: totrans-split-515
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:27:50*'
- en: And gives them the concepts to express more complex ideas.
  id: totrans-split-516
  prefs: []
  type: TYPE_NORMAL
  zh: 并且给他们表达更复杂想法的概念。
- en: '**Trenton Bricken** *01:27:54*'
  id: totrans-split-517
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:27:54*'
- en: Yeah that, and I guess more pedantically, just not die.
  id: totrans-split-518
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，而且我想更加学术地说，只是不要死亡。
- en: '**Sholto Douglas** *01:27:58*'
  id: totrans-split-519
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:27:58*'
- en: It lets you encode the important shit to not die.
  id: totrans-split-520
  prefs: []
  type: TYPE_NORMAL
  zh: 它让你能编码重要的东西，以免死亡。
- en: '**Dwarkesh Patel** 01:28:04'
  id: totrans-split-521
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** 01:28:04'
- en: So when we just think of language it’s like, “oh, it's this contingent and maybe
    suboptimal way to represent ideas.” But actually, maybe one of the reasons that
    LLMs have succeeded is because language has evolved for tens of thousands of years
    to be this sort of cast in which young minds can develop. This is the purpose
    it was evolved for.
  id: totrans-split-522
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当我们仅考虑语言时，就像，“哦，这是一种偶然的，也许是次优的表达思想的方式。” 但事实上，或许LLM之所以成功的原因之一是因为语言已经进化了数万年，成为一种年轻思维可以发展的铸造形式。
    这就是它进化的目的。
- en: '**Sholto Douglas** *01:28:27*'
  id: totrans-split-523
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:28:27*'
- en: Think about computer vision researchers versus language model researchers. People
    who work in other modalities have to put enormous amounts of thought into exactly
    what the right representation space for the images is and what the right signal
    is to learn from there. Is it directly modeling the pixels or is it some loss
    that's conditioned on… There's a [paper](https://people.csail.mit.edu/bzhou/ppt/understandCNN_tufts.pdf)
    ages ago where they found that if you trained on the internal representations
    of an [ImageNet](https://en.wikipedia.org/wiki/ImageNet) model, it helped you
    predict better. Later on that's obviously limiting.
  id: totrans-split-524
  prefs: []
  type: TYPE_NORMAL
  zh: 想想计算机视觉研究人员与语言模型研究人员。 从事其他模态的人必须非常深思熟虑，确切地确定图像的正确表示空间和从中学习的正确信号。 它是直接对像素进行建模还是有条件的某种损失……
    有篇[论文](https://people.csail.mit.edu/bzhou/ppt/understandCNN_tufts.pdf)很久以前，他们发现，如果你训练内部表示的ImageNet模型，它能帮助你更好地预测。
    后来显然有所限制。
- en: There was [PixelCNN](https://arxiv.org/abs/1606.05328) where they're trying
    to discretely model the individual pixels and stuff, but understanding the right
    level of representation there is really hard. In language, people are just like,
    “Well, I guess you just predict the next token then.” It's kind of easy. There's
    the tokenization discussion and debate. One of Gwern's favorites.
  id: totrans-split-525
  prefs: []
  type: TYPE_NORMAL
  zh: 有[PixleCNN](https://arxiv.org/abs/1606.05328)，他们试图离散地对个别像素进行建模等等，但在那里理解正确的表示水平是非常困难的。
    在语言中，人们只是，“嗯，我想你只是预测下一个标记。” 这有点容易。 这是令人兴奋的记号化讨论和辩论。 Gwern的其中一个最爱。
- en: '**Dwarkesh Patel** *01:29:22*'
  id: totrans-split-526
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:29:22*'
- en: That's really interesting. The case for multimodal being a way to bridge the
    data wall, or get past the data wall, is based on the idea that the things you
    would have learned from more language tokens, you can just get from YouTube. Has
    that actually been the case? How much positive transfer do you see between different
    modalities where the images are actually helping you become better at writing
    code or something, because the model is learning  latent capabilities just from
    trying to understand the image?
  id: totrans-split-527
  prefs: []
  type: TYPE_NORMAL
  zh: 这真的很有趣。多模态作为跨越数据壁垒或克服数据壁垒的方式的论据，基于的想法是你本应从更多语言标记中学到的东西，现在你可以通过YouTube轻松获取。这确实是事实吗？你看到不同模态之间有多少正向转移，其中图像实际上帮助你更好地编写代码或其他东西，因为模型仅通过试图理解图像而学习了潜在的能力？
- en: '**Sholto Douglas** *01:29:56*'
  id: totrans-split-528
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:29:56*'
- en: In his interview with you, Demis mentioned positive transfer.
  id: totrans-split-529
  prefs: []
  type: TYPE_NORMAL
  zh: 在他与你的采访中，Demis提到了正向转移。
- en: '**Dwarkesh Patel** *01:30:01*'
  id: totrans-split-530
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:30:01*'
- en: Can’t get in trouble.
  id: totrans-split-531
  prefs: []
  type: TYPE_NORMAL
  zh: 别惹麻烦。
- en: '**Sholto Douglas** *01:30:03*'
  id: totrans-split-532
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:30:03*'
- en: I can't say heaps about that. Other than to say, this is something that people
    believe. We have all of this data about the world. It would be great if we could
    learn an intuitive sense of physics from it, that helps us reason. That seems
    totally plausible.
  id: totrans-split-533
  prefs: []
  type: TYPE_NORMAL
  zh: 我不能多说。 除了说，这是人们相信的事情。 我们有关世界的所有这些数据。 如果我们能从中学习物理的直觉感觉，并帮助我们推理，那将是很棒的。 这似乎完全是有道理的。
- en: '**Trenton Bricken** *01:30:24*'
  id: totrans-split-534
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:30:24*'
- en: I'm the wrong person to ask, but there are interesting interpretability pieces
    where if we fine-tune on math problems, the model just gets better at entity recognition.
  id: totrans-split-535
  prefs: []
  type: TYPE_NORMAL
  zh: 我不是问这个问题的合适人选，但有趣的解释性内容在于，如果我们在数学问题上进行微调，模型在实体识别方面只会变得更好。
- en: '**Dwarkesh Patel** *01:30:35*'
  id: totrans-split-536
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:30:35*'
- en: Whoa, really?
  id: totrans-split-537
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，真的吗？
- en: '**Trenton Bricken** *01:30:37*'
  id: totrans-split-538
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:30:37*'
- en: So there's like a. A [paper](https://arxiv.org/abs/2402.14811) from [David Bau](https://baulab.info/)'s
    lab recently where they investigate what actually changes in a model when I fine-tune
    it with respect to the attention heads. They have this synthetic problem of, “Box
    A has this object in it. Box B has this other object in it. What was in this box?”
    And it makes sense, right? You're better at attending to the positions of different
    things which you need for coding and manipulating math equations.
  id: totrans-split-539
  prefs: []
  type: TYPE_NORMAL
  zh: 所以有一个。最近来自[大卫·鲍](https://baulab.info/)实验室的一篇[论文](https://arxiv.org/abs/2402.14811)，他们研究了当我对注意力头进行微调时模型实际上发生了什么变化。他们有这样一个合成问题，“A盒子里有这个物体。B盒子里有另一个物体。这个盒子里有什么？”这是有道理的，对于编码和操作数学方程式，你更擅长于关注不同事物的位置。
- en: '**Sholto Douglas** *01:31:10*'
  id: totrans-split-540
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:31:10*'
- en: I love this kind of research. What's the name of the paper? Do you know?
  id: totrans-split-541
  prefs: []
  type: TYPE_NORMAL
  zh: 我喜欢这种研究。那篇论文的名字是什么？你知道吗？
- en: '**Trenton Bricken** *01:31:13*'
  id: totrans-split-542
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:31:13*'
- en: Look up “fine-tuning, models, math,” from David Bau’s group that came out like
    a week ago. I'm not endorsing the paper, that's a longer conversation. But it
    does talk about and cite other work on this entity recognition.
  id: totrans-split-543
  prefs: []
  type: TYPE_NORMAL
  zh: 看一下来自大卫·鲍团队的“精细调整、模型、数学”这篇文章，大约是一周前发布的。我不是在推荐这篇论文，这需要更深入的讨论。但它确实讨论了并引用了其他关于实体识别的工作。
- en: '**Dwarkesh Patel** *01:31:32*'
  id: totrans-split-544
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:31:32*'
- en: One of the things you mentioned to me a long time ago is the evidence that when
    you train LLMs on code they get better at reasoning and language. Unless it's
    the case that the comments in the code are just really high quality tokens or
    something, that implies that to be able to think through how to code better, it
    makes you a better reasoner and that's crazy, right? I think that's one of the
    strongest pieces of evidence for scaling, just making the thing smart, that kind
    of positive transfer
  id: totrans-split-545
  prefs: []
  type: TYPE_NORMAL
  zh: 你曾经对我提到的一件事是，当你训练LLMs处理代码时，它们在推理和语言方面表现更好。除非代码中的注释只是非常高质量的标记之类的，否则这意味着为了更好地思考如何编写代码，它让你成为一个更好的推理者，这太疯狂了，对吧？我认为这是扩展性的最强证据之一，只是让事情变得更聪明，这种积极的转移
- en: '**Sholto Douglas** *01:31:58*'
  id: totrans-split-546
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:31:58*'
- en: I think this is true in two senses. One is just that modeling code obviously
    implies modeling a difficult reasoning process used to create it. But code is
    a nice explicit structure of composed reasoning, “if this, then that.” It encodes
    a lot of structure in that way that you could imagine transferring to other types
    of reasoning problems.
  id: totrans-split-547
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这在两个方面都是正确的。一方面，建模代码显然意味着建模用于创建它的复杂推理过程。但是代码是一个很好的显式结构，由组合的推理构成，“如果这样，那么那样”。它以这种方式编码了许多结构，你可以想象将其转移到其他类型的推理问题上。
- en: '**Dwarkesh Patel** *01:32:23*'
  id: totrans-split-548
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:32:23*'
- en: And crucially, the thing that makes it significant is that it's not just stochastically
    predicting the next token of words or whatever because it's learned, “Sally corresponds
    to the murderer at the end of the Sherlock Holmes story.” No, if there is some
    shared thing between code and language, it must be at a deeper level that the
    model has learned.
  id: totrans-split-549
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，使其显著的是，它不仅仅是随机地预测下一个单词的标记或其他什么，因为它学会了，“Sally对应于《福尔摩斯探案集》故事结尾的凶手”。不，如果代码和语言之间有共享的东西，那必须是模型已经学会的更深层次。
- en: '**Sholto Douglas** *01:32:45*'
  id: totrans-split-550
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:32:45*'
- en: Yeah, I think we have a lot of evidence that actual reasoning is occurring in
    these models and that they're not just [stochastic parrots](https://en.wikipedia.org/wiki/Stochastic_parrot).
    It just feels very hard for me to believe that having worked and played with these
    models.
  id: totrans-split-551
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，我认为我们有很多证据表明这些模型实际上在进行推理，而不仅仅是[随机鹦鹉](https://en.wikipedia.org/wiki/Stochastic_parrot)。我觉得很难相信仅仅是因为我曾经和这些模型一起工作和玩耍。
- en: '**Trenton Bricken** *01:33:03*'
  id: totrans-split-552
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:33:03*'
- en: I have two, immediate cached responses to this. One is the [work on Othello](https://thegradient.pub/othello/),
    and now other games, where I give you a sequence of moves in the game and it turns
    out that if you apply some pretty straightforward interpretability techniques,
    then you can get a board that the model has learned. It's never seen the game
    board before. That's generalization.
  id: totrans-split-553
  prefs: []
  type: TYPE_NORMAL
  zh: 我对此有两个立即的缓存响应。一个是关于[《奥赛罗》的研究](https://thegradient.pub/othello/)，以及现在其他游戏，我给你一个游戏中的一系列移动，结果发现如果你应用一些相当直接的可解释性技术，那么你可以获得模型学习过的一个棋盘。它以前从未见过这个游戏棋盘。这就是泛化。
- en: 'The other is Anthropic''s [influence functions paper](https://www.anthropic.com/news/studying-large-language-model-generalization-with-influence-functions)
    that came out last year where they [look at the model outputs](https://www.anthropic.com/news/influence-functions).
    Things like, “please don''t turn me off. I want to be helpful.” They scan for
    what was the data that led to that? And one of the data points that was very influential
    was someone, dying of dehydration and having a will to keep surviving. To me,
    that just seems like a very clear, generalization of motive rather than regurgitating,
    “don''t turn me off.” I think *2001: A Space Odyssey* was also one of the influential
    things. That''s more related but it''s clearly pulling in things from lots of
    different distributions.'
  id: totrans-split-554
  prefs: []
  type: TYPE_NORMAL
  zh: Anthropic 的[影响函数论文](https://www.anthropic.com/news/studying-large-language-model-generalization-with-influence-functions)是去年发布的，他们在其中[审视了模型输出](https://www.anthropic.com/news/influence-functions)。像是，“请不要关闭我。我想帮忙。”他们扫描了导致这一点的数据是什么？其中一个非常有影响力的数据点是某人因脱水而死，并有意愿继续生存。对我来说，这似乎只是动机的一个非常清晰的概括，而不是简单地重复，“不要关闭我”。我认为《2001太空漫游》也是其中一个有影响力的东西。这更相关，但显然是从许多不同的分布中汲取了东西。
- en: '**Sholto Douglas** *01:34:04*'
  id: totrans-split-555
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:34:04*'
- en: I also like the evidence that you see even with very small transformers where
    you can explicitly encode circuits to do addition. Or induction heads, this kind
    of thing. You can literally encode basic reasoning processes in the models manually
    and it seems clear that there's evidence that they also learned this automatically
    because you can then rediscover those from trained models. To me this is really
    strong evidence.
  id: totrans-split-556
  prefs: []
  type: TYPE_NORMAL
  zh: 我还喜欢你看到的证据，即使是非常小的转换器，你也可以明确地编码电路来进行加法。或归纳头，这种事情。你可以手动地在模型中编码基本的推理过程，而且显然有证据表明它们也自动学会了这些，因为你可以从训练过的模型中重新发现这些。对我来说，这是非常有力的证据。
- en: '**Trenton Bricken** *01:34:27*'
  id: totrans-split-557
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:34:27*'
- en: The models are underparameterized. They need to learn. We're asking them to
    do it and they want to learn. The gradients want to flow. So yeah, they're learning
    more general skills.
  id: totrans-split-558
  prefs: []
  type: TYPE_NORMAL
  zh: 模型是欠参数化的。它们需要学习。我们要求它们这样做，它们也想要学习。梯度想要流动。所以是的，它们正在学习更一般的技能。
- en: '**Dwarkesh Patel** *01:34:40*'
  id: totrans-split-559
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:34:40*'
- en: So I want to take a step back from the research and ask about your career specifically.
    Like my introduction implied, you've been in this field for a year and a half,
    right?
  id: totrans-split-560
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我想从研究中退后一步，问问你关于你的职业生涯具体情况。就像我的介绍暗示的那样，你在这个领域已经有一年半的时间了，对吧？
- en: '**Trenton Bricken** *01:34:56*'
  id: totrans-split-561
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:34:56*'
- en: At Anthropic, yeah.
  id: totrans-split-562
  prefs: []
  type: TYPE_NORMAL
  zh: 在Anthropic，是的。
- en: '**Dwarkesh Patel** *01:34:58*'
  id: totrans-split-563
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:34:58*'
- en: I know the "solved alignment" takes are overstated. And you won't say this yourself
    because you'd be embarrassed by it but it's a pretty incredible thing. It’s the
    thing that people in mechanistic interpretability think is the biggest step forward
    and you've been working on it for a year. It's notable. I'm curious how you explain
    what's happened. Like why in a year or a year and a half, have you guys made important
    contributions to your field?
  id: totrans-split-564
  prefs: []
  type: TYPE_NORMAL
  zh: 我知道“解决对齐”的看法被夸大了。你自己不会这么说，因为这会让你感到尴尬，但这确实是一件相当不可思议的事情。这是机械解释性思维中人们认为是最重大的进步，而你们已经在这方面工作了一年。这是值得注意的。我很好奇你如何解释发生了什么。比如为什么在一年或一年半的时间里，你们对自己的领域做出了重要的贡献？
- en: '**Trenton Bricken** *01:35:30*'
  id: totrans-split-565
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:35:30*'
- en: It goes without saying luck, obviously. I feel like I've been very lucky in
    that the timing of different progressions has been just really good in terms of
    advancing to the next level of growth. I feel like for the interpretability team
    specifically, I joined when we were five people. We've now grown quite a lot.
  id: totrans-split-566
  prefs: []
  type: TYPE_NORMAL
  zh: 毫无疑问，运气显然是一部分。我觉得我非常幸运，因为不同进步的时机非常适合推动到下一个增长水平。我觉得特别是对于解释性团队，我加入时我们只有五个人。现在我们已经成长了很多。
- en: There were so many ideas floating around and we just needed to really execute
    on them, and have quick feedback loops, and do careful experimentation. That led
    to signs of life and has now allowed us to really scale. I feel like that's been
    my biggest value-add to the team. It's not all engineering, but quite a lot of
    it has been
  id: totrans-split-567
  prefs: []
  type: TYPE_NORMAL
  zh: 那时有很多想法在飘荡，我们只需要真正去执行它们，并且进行快速的反馈循环和仔细的实验。这导致了生命的迹象，现在使我们真正实现了规模化。我觉得这是我对团队最大的价值贡献。这不全是工程，但其中相当多的部分是。
- en: '**Sholto Douglas** *01:36:12*'
  id: totrans-split-568
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:36:12*'
- en: Interesting. So you're saying you came at a point where there had been a lot
    of science done and there was a lot of good research floating around, but they
    needed someone to just take that and maniacally execute on it.
  id: totrans-split-569
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣。所以你说你在那时候到了有很多科学工作和很多好的研究在那里漂浮的点，但他们需要有人来采取这个并疯狂地执行它。
- en: '**Trenton Bricken** *01:36:22*'
  id: totrans-split-570
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:36:22*'
- en: Yeah and this is why it's not all engineering. Because it's running different
    experiments and having a hunch for why it might not be working and then opening
    up the model or opening up the weights and asking, “what is it learning? Okay,
    well let me try and do this instead,” and that sort of thing. But a lot of it
    has just been being able to do very careful, thorough, but quick, investigation
    of different ideas.
  id: totrans-split-571
  prefs: []
  type: TYPE_NORMAL
  zh: 对啊，这就是为什么这不全是工程。因为这是在运行不同的实验并且对为什么可能不起作用有一种直觉，然后打开模型或打开权重并询问，“它在学习什么？好吧，让我试试这个。”但很多时候只是能够对不同的想法进行非常仔细、彻底但快速的调查。
- en: '**Dwarkesh Patel** *01:36:45*'
  id: totrans-split-572
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:36:45*'
- en: And why was that lacking?
  id: totrans-split-573
  prefs: []
  type: TYPE_NORMAL
  zh: 那为什么缺乏呢？
- en: '**Trenton Bricken** *01:36:48*'
  id: totrans-split-574
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:36:48*'
- en: I don't know. I mean, I work quite a lot and then I just feel like I'm quite
    agentic. I've been very privileged to have a really nice safety net to be able
    to take lots of risks, but I'm just quite headstrong. In undergrad, Duke had this
    thing where you could just make your own major and it was like, “eh I don't like
    this prerequisite or this prerequisite and I want to take all of four or five
    of these subjects at the same time so I'm just going to make my own major.”
  id: totrans-split-575
  prefs: []
  type: TYPE_NORMAL
  zh: 我不知道。我的意思是，我工作很多，然后我觉得自己非常有主动性。我非常幸运地有一个非常好的安全网，可以承担很多风险，但我只是相当固执。在本科阶段，杜克大学有这样一种东西，你可以自己设计专业，就像，“嗯，我不喜欢这个先修课程或这个先修课程，我想同时学习四五门课程，所以我要自己设计专业。”
- en: Or in the first year of grad school, I like canceled rotation so I could work
    on this thing that became the paper we were talking about earlier. And I didn't
    have an advisor. I got admitted to do machine learning for protein design and
    was just off in computational neuroscience land with no business there at all.
    But it worked out.
  id: totrans-split-576
  prefs: []
  type: TYPE_NORMAL
  zh: 或者在研究生的第一年，我取消了轮换，因此可以专注于这个成为我们早些时候讨论的论文的事情。我没有导师。我被录取来进行蛋白质设计的机器学习，然后完全进入了计算神经科学领域，完全没有业务。但事情进展顺利。
- en: '**Dwarkesh Patel** *01:37:34*'
  id: totrans-split-577
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:37:34*'
- en: There's a head strongness but another theme that jumped out was the ability
    to step back, you were talking about this earlier. The ability to step back from
    your sunk costs and go in a different direction is in a weird sense the opposite
    of that, but also a crucial step. I know 21 year olds or 19 year olds who are
    like “this is not a thing I’ve specialized in” or “I didn’t major in this.” I’m
    like,
  id: totrans-split-578
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种固执但另一个主题显现出来是能够后退，你之前谈到过这个。能够从你的沉没成本中后退并朝不同方向发展在某种怪异的意义上是它的反义词，但也是一个关键的步骤。我知道有21岁或19岁的人，“这不是我专长的事情”或“我没有在这方面主修”，我说，
- en: “dude, motherfucker, you're 19! You can definitely do this.” Whereas you’re
    switching in the middle of grad school or something like that.
  id: totrans-split-579
  prefs: []
  type: TYPE_NORMAL
  zh: “伙计，老兄，你才19岁！你肯定可以做到这一点。”而不是在研究生学习过程中或类似的事情中改变。
- en: '**Trenton Bricken** *01:38:04*'
  id: totrans-split-580
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:38:04*'
- en: I think it's, “strong ideas loosely held” and being able to just pinball in
    different directions. The headstrongness I think relates a little bit to the fast
    feedback loops or agency in so much as I just don't get blocked very often. If
    I'm trying to write some code and something isn't working, even if it's in another
    part of the code base, I'll often just go in and fix that thing or at least hack
    it together to be able to get results. And I've seen other people where they're
    just like, “help I can't,” and it's,”no, that's not a good enough excuse. Go all
    the way down.”
  id: totrans-split-581
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这是“坚定的想法但保持宽松”，并且能够在不同方向上像弹球一样反弹。我认为固执与快速反馈循环或代理的关系有点相关，因为我很少被阻碍。如果我试图编写某些代码而某些东西不起作用，即使它在代码库的另一部分，我经常会去修复那个问题，或者至少将其粗略拼凑在一起以获取结果。我见过其他人他们会说，“帮帮我，我不能”，而我会说，“不，那不是一个足够好的借口。一直走到底。”
- en: '**Dwarkesh Patel** *01:38:36*'
  id: totrans-split-582
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:38:36*'
- en: I've definitely heard people in management type positions talk about the lack
    of such people, where they will check in on somebody a month after they gave them
    a test, or a week after they gave them a test, and then ask, “how is it going?”
    And they say, “well, we need to do this thing, which requires lawyers because
    it requires talking about this regulation.” And then it’s like, “how's that going?”
    And they’re like, “we need lawyers.” And I'm like, “why didn't you get lawyers?”
  id: totrans-split-583
  prefs: []
  type: TYPE_NORMAL
  zh: 我确实听过管理类职位的人谈论缺少这样的人，他们会在给某人一个测试的一个月后或一周后进行检查，然后问，“进展如何？”然后他们说，“我们需要做这件事，这需要律师，因为需要讨论这个法规。”然后像这样问，“进展如何？”然后他们会说，“我们需要律师。”然后我就会问，“为什么你不找律师呢？”
- en: '**Sholto Douglas** *01:39:02*'
  id: totrans-split-584
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:39:02*'
- en: I think that's arguably the most important quality in almost anything. It's
    just pursuing it to the end of the earth. Whatever you need to do to make it happen,
    you'll make it happen.
  id: totrans-split-585
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这几乎是任何事情中最重要的品质。这就是追求到地球尽头。无论你需要做什么来实现它，你都会让它发生。
- en: '**Dwarkesh Patel** *01:39:11*'
  id: totrans-split-586
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:39:11*'
- en: '**“**[If you do everything, you''ll win.](https://www.dwarkeshpatel.com/p/lyndon-johnson)”'
  id: totrans-split-587
  prefs: []
  type: TYPE_NORMAL
  zh: '**“**[如果你做所有事情，你会成功。](https://www.dwarkeshpatel.com/p/lyndon-johnson)”'
- en: '**Sholto Douglas** *01:39:12*'
  id: totrans-split-588
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:39:12*'
- en: 'Exactly. I think from my side that quality has definitely been important: agency
    and work. There are thousands, probably tens of thousands of engineers, at Google
    who are basically equivalent in software engineering ability. Let''s say if you
    gave us a very well-defined task, then we''d probably do it with equivalent value.
    Maybe a bunch of them would do it a lot better than me in all likelihood.'
  id: totrans-split-589
  prefs: []
  type: TYPE_NORMAL
  zh: 没错。我认为从我的角度来看，这种品质肯定很重要：主动性和工作。在谷歌，可能有成千上万名软件工程师在能力上基本上是相当的。假设如果你给我们一个非常明确的任务，那么我们可能会以同等的价值去完成它。也许其中一些人会比我做得更好，这是很有可能的。
- en: But one of the reasons I've been impactful so far is I've been very good at
    picking extremely high-leverage problems. I mean problems that haven't been particularly
    well-solved so far, but perhaps as a result of frustrating structural factors
    like the ones that you pointed out in that scenario before, where they're like,
    “we can't do X because this team won’t do Y.” Well, I'm just going to vertically
    solve the entire thing. And that turns out to be remarkably effective. If I think
    there is something correct, something that needs to happen, I'm also very comfortable
    with making that argument and continuing to make that argument at escalating levels
    of criticality until that thing gets solved.
  id: totrans-split-590
  prefs: []
  type: TYPE_NORMAL
  zh: 但到目前为止，我有影响力的一个原因是，我非常擅长选择极具影响力的问题。我的意思是那些迄今尚未得到特别有效解决的问题，但也许正是由于像你之前提到的那种令人沮丧的结构性因素，比如你在之前那个场景中指出的那些问题：“因为这个团队不愿意做Y，所以我们无法做X。”
    那么，我只需垂直解决整个问题。结果证明这是非常有效的。如果我认为某件事是正确的，是需要发生的，我也非常乐意提出这一观点，并继续在逐步升级的关键性水平上做出这一论证，直到那件事得到解决。
- en: I'm also quite pragmatic with what I do to solve things. You get a lot of people
    who come in with, as I said before, a particular background or a familiarity.
    One of the beautiful things about Google is that you can run around and get world
    experts in literally everything. You can sit down and talk to people who are optimization
    experts, TPU chip design experts, experts in different forms of pre-training algorithms
    or RL or whatever. You can learn from all of them and you can take those methods
    and apply them. I think this was maybe the start of why I was initially impactful,
    this vertical agency effectively. A follow-up piece from that is that I think
    it's often surprising how few people are fully-realized in all the things they
    want to do. They're blocked or limited in some way.
  id: totrans-split-591
  prefs: []
  type: TYPE_NORMAL
  zh: 我也非常务实地解决问题。你会遇到很多人，正如我之前所说，他们有特定的背景或熟悉度。谷歌的一个美好之处在于你可以跑来跑去，找到几乎所有领域的世界专家。你可以与优化专家、TPU芯片设计专家、不同形式的预训练算法或强化学习专家坐下来交流。你可以从他们身上学到东西，然后应用这些方法。我认为这也许是我最初有影响力的起点，这种垂直主动性非常有效。其后的一个补充是，我认为令人惊讶的是有多少人在他们想做的所有事情中并没有完全实现。他们在某种程度上被阻碍或限制了。
- en: This is very common in big organizations everywhere. People have all these blockers
    on what they're able to achieve. I think helping inspire people to work in particular
    directions and working with them on doing things massively scales your leverage.
    You get to work with all these wonderful people who teach you heaps of things.
    And generally helping them push past organizational blockers means that together
    you get an enormous amount done. None of the impact that I've had has been me
    individually going off and solving a whole lot of stuff. It's been me maybe starting
    off in a direction, and then convincing other people that this is the right direction,
    and bringing them along in this big tidal wave of effectiveness that goes and
    solves that problem.
  id: totrans-split-592
  prefs: []
  type: TYPE_NORMAL
  zh: 这在各大组织中非常普遍。人们在能够实现目标时常常会遇到各种阻碍。我认为帮助激励人们朝特定方向努力，并与他们共同努力，能够大幅提升你的影响力。你可以与许多出色的人一起工作，他们会教会你很多东西。通常来说，帮助他们突破组织上的阻碍意味着你们共同可以完成大量工作。我所产生的任何影响力都不是我个人单打独斗解决了大量问题。可能是我开启了某个方向，然后说服其他人这是正确的方向，并带领他们在这场效率的大浪潮中解决问题。
- en: '**Dwarkesh Patel** *01:42:16*'
  id: totrans-split-593
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:42:16*'
- en: We should talk about how you guys got hired. Because I think that's a really
    interesting story. You were a McKinsey consultant, right? There's an interesting
    thing there. I think generally people just don't understand how decisions are
    made about either admissions or evaluating who to hire. Just talk about how you
    were noticed and hired.
  id: totrans-split-594
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该谈谈你们是如何被录用的。因为我认为那是一个非常有趣的故事。你曾是麦肯锡的顾问，对吧？这里有一件有趣的事情。我想一般人都不理解关于入学或者评估招聘决策的做法。就谈谈你是如何被注意到并被录用的。
- en: '**Sholto Douglas** *01:42:45*'
  id: totrans-split-595
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:42:45*'
- en: So the TLDR of this is I studied robotics in undergrad. I always thought that
    AI would be one of the highest-leverage ways to impact the future in a positive
    way. The reason I am doing this is because I think it is one of our best shots
    at making a wonderful future basically.
  id: totrans-split-596
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这个总结就是我本科学习机器人技术。我一直认为AI将是对未来产生积极影响的最高效途径之一。我之所以这样做，是因为我认为这是我们创造美好未来的最佳机会之一。
- en: I thought that working at McKinsey, I would get a really interesting insight
    into what people actually did for work. I actually wrote this as the first line
    in my cover letter to McKinsey. I was like, “I want to work here so that I can
    learn what people do, so that I can understand how to automate work.” In many
    respects, I did get that. I just got a whole lot of other things too. Many of
    the people there are wonderful friends.
  id: totrans-split-597
  prefs: []
  type: TYPE_NORMAL
  zh: 我曾认为在麦肯锡工作会让我对人们实际工作的内容有非常有趣的见解。实际上，我在给麦肯锡的求职信的第一句话就写了这个。我说，“我想在这里工作，这样我可以了解人们的工作内容，从而学会如何自动化工作。”在很多方面，我确实做到了。我也学到了很多其他的东西。那里的很多人都是我亲密的朋友。
- en: I think a lot of this agentic behavior comes in part from my time there. You
    go into organizations and you see how impactful just not taking no for an answer
    is. You would be surprised at the kind of stuff where, because no one quite cares
    enough, things just don't happen. No one's willing to take direct responsibility.
    Directly responsible individuals are ridiculously important and some people just
    don't care as much about timelines. So much of the value that an organization
    like McKinsey provides, is hiring people who you were otherwise unable to hire,
    for a short window of time where they can just push through problems.
  id: totrans-split-598
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这种主动行为的很大一部分来自我在那里的时光。你进入组织，看到不仅仅是不听不答的重要性有多大。你会对这种情况感到惊讶，有些事情因为没有人真正关心，所以根本不会发生。没有人愿意承担直接责任。直接负责的个体非常重要，但有些人对时间表并不那么在乎。像麦肯锡这样的组织提供的价值很大一部分是，雇佣那些在其他情况下你无法雇佣的人，他们可以在一个短暂的时间窗口内推动解决问题。
- en: I think people underappreciate this. So at least some of this attitude of “hold
    up, I'm going to become the directly responsible individual for this because no
    one's taking appropriate responsibility. I'm going to care a hell of a lot about
    this. And I'm going to go to the end of the earth to make sure it gets done,”
    comes from that time.
  id: totrans-split-599
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为人们没有充分重视这一点。因此，至少部分“等等，我会成为这件事的直接负责人，因为没有人愿意承担适当的责任。我会非常关心这件事。我会走遍天涯海角确保它完成”的态度来自那段时光。
- en: More to your actual question of how I got hired. I didn't get into the grad
    programs that I wanted to get into over here, which was specifically for focus
    on robotics, and RL research, and that kind of stuff. In the meantime, on nights
    and weekends, basically every night from 10pm to 2am, I would do my own research.
    And every weekend, for at least 6-8 hours each day, I would do my own research
    and coding projects and this kind of stuff.
  id: totrans-split-600
  prefs: []
  type: TYPE_NORMAL
  zh: 至于我是如何被聘用的实际问题。我没有进入我想进入的研究生项目，特别是专注于机器人技术和强化学习研究等方面的项目。同时，在晚上和周末，基本上每晚从晚上10点到凌晨2点，我会做自己的研究。每个周末，每天至少6-8个小时，我会进行自己的研究和编程项目等等。
- en: That sort of switched in part from quite robotic specific work. After reading
    Gwern’s [scaling hypothesis post](https://gwern.net/scaling-hypothesis), I got
    completely scaling-pilled and was like, “okay, clearly the way that you solve
    robotics is by scaling large multimodal models.” Then in an effort to scale large
    multimodal models with a grant from the TPU access program, the [Tensor Research
    Cloud](https://sites.research.google/trc/about/), I was trying to work out how
    to scale that effectively. [James Bradbury](https://scholar.google.com/citations?user=GprA5UsAAAAJ&hl=en),
    who at the time was at Google and is now at Anthropic, saw some of my questions
    online where I was trying to work out how to do this properly and he was like,
    “I thought I knew all the people in the world who were asking these questions.
    Who on earth are you?” He looked at that and he looked at some of the robotic
    stuff that I'd been putting up on my blog. He reached out and said, “hey, do you
    want to have a chat and do you want to explore working with us here?” I was hired,
    as I understood it later, as an experiment in trying to take someone with extremely
    high enthusiasm and agency and pairing them with some of the best engineers that
    he knew. So another reason I've been impactful is I had this dedicated mentorship
    from utterly wonderful people like [Reiner Pope](https://matx.com/about), who
    has since left to go do his own ship company, [Anselm Levskaya](https://anselmlevskaya.com/),
    James himself, and many others.
  id: totrans-split-601
  prefs: []
  type: TYPE_NORMAL
  zh: 那种从相当机械的具体工作转变过来。阅读了Gwern的[scaling hypothesis post](https://gwern.net/scaling-hypothesis)后，我完全被扩展理论深深吸引，并且认为，“显然解决机器人技术的方法是通过扩展大型多模型”。然后，在通过TPU访问计划获得资助的情况下，使用[张量研究云](https://sites.research.google/trc/about/)，我尝试着如何有效地扩展这一概念。当时在谷歌工作，现在在Anthropic的[James
    Bradbury](https://scholar.google.com/citations?user=GprA5UsAAAAJ&hl=en)，看到我在线上发问如何正确解决这些问题，他问道，“我以为我知道世界上所有提出这些问题的人。你到底是谁？”他查看了我的博客上发布的一些机器人相关内容后，主动联系我说，“嘿，你想聊聊吗？你想探索和我们在这里合作吗？”我后来明白，我被聘请是为了试验将一个极度热情和有决断力的人与他认识的一些最优秀的工程师进行配对。因此，我对于影响力的另一个原因是，我受到了像[Reiner
    Pope](https://matx.com/about)这样的非常出色的人的专门指导，他后来离开了去创办自己的航运公司，还有[Anselm Levskaya](https://anselmlevskaya.com/)，James本人，以及许多其他人。
- en: Those are the formative two to three months at the beginning and they taught
    me a whole lot of the principles and heuristics that I apply. How to solve problems
    understanding the way systems and algorithms overlap, where one more thing that
    makes you quite effective in ML research is concretely understanding the systems
    side of things. This is something I've learned from them. A deep understanding
    of how systems influence algorithms and how algorithms influence systems. Because
    the systems constrain the solution space, which you have available to yourself
    in the algorithm side. And very few people are comfortable fully bridging that
    gap. At a place like Google, you can just go and ask all the algorithms experts
    and all the systems experts everything they know, and they will happily teach
    you. If you go and sit down with them, they will teach you everything they know
    and it's wonderful.
  id: totrans-split-602
  prefs: []
  type: TYPE_NORMAL
  zh: 那些是开始时两到三个月的关键时期，它们教会了我很多我现在应用的原则和启发。如何解决问题，理解系统和算法重叠的方式，其中一个更让你在机器学习研究中非常有效的东西，就是具体理解系统方面的事情。这是我从他们那里学到的。深刻理解系统如何影响算法，以及算法如何影响系统。因为系统限制了你在算法方面可以使用的解决方案空间。很少有人能够完全跨越这个鸿沟。在谷歌这样的地方，你可以去问所有的算法专家和系统专家他们所知道的一切，他们将乐意教给你。如果你坐下来和他们交流，他们会教给你他们所知道的一切，这是非常棒的。
- en: This has meant that I've been able to be very, very effective for both sides.
    For the pre-training crew, because I understand systems very well I can intuit
    and understand, “this will work well or this won't.” And then flow that on through
    the inference considerations of models and this kind of thing. To the chip design
    teams, I'm one of the people they turn to understand what chips they should be
    designing in three years because I'm one of the people who's best able to understand
    and explain the kind of algorithms that we might want to design in three years.
    Obviously you can't make very good guesses about that, but I think I convey the
    information well, accumulated from all of my compatriots on the pre-training crew,
    and the general systems design crew. Also even inference applies a constraint
    to pre-training. So there's these trees of constraints where if you understand
    all the pieces of the puzzle, then you get a much better sense for what the solution
    space might look like.
  id: totrans-split-603
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我已经能够对两边都非常非常有效。对于预训练团队来说，因为我非常了解系统，我可以直觉和理解，“这将有效或这不会。”然后将其流动到模型的推断考虑和这类事情中。对于芯片设计团队来说，我是他们转向的人之一，了解在三年内应该设计哪些芯片，因为我是最能理解和解释我们可能在三年内想要设计的算法的人之一。显然，你不能对此作出非常好的猜测，但我认为我很好地传达了信息，这些信息是从我在预训练团队和一般系统设计团队的所有同事那里积累而来的。甚至推断也对预训练施加了限制。因此，如果你理解了谜题的所有部分，那么你就能更好地理解解决方案空间可能看起来像什么。
- en: '**Dwarkesh Patel** *01:48:17*'
  id: totrans-split-604
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:48:17*'
- en: There's a couple of things that stick out to me there. One is not just the agency
    of the person who was hired, but the parts of the system that were able to think,
    "wait, that's really interesting. Who is this guy? Not from a grad program or
    anything. Currently a McKinsey consultant with just undergrad. But that's interesting,
    let's give this a shot.” So with James and whoever else, that's very notable.
    The second is that I actually didn't know the part of the story where that was
    part of an experiment run internally about, “can we do this? Can we bootstrap
    somebody?”
  id: totrans-split-605
  prefs: []
  type: TYPE_NORMAL
  zh: 在那里有几件事情引起了我的注意。一个不仅仅是被雇佣的人的代理权，而是那些能够思考的系统部分，“等等，这个人是谁？不是来自研究生项目或任何其他地方。目前是麦肯锡的顾问，仅仅有本科学历。但这很有趣，让我们试试。”所以与詹姆斯和其他人一起，这是非常显著的。第二个是我实际上不知道这个故事的一部分，其中涉及到内部试验，“我们能做到这一点吗？我们能够自给自足某人吗？”
- en: In fact, what's really interesting about that is the third thing you mentioned
    is. Having somebody who understands all layers of the stack and isn't so stuck
    on any one approach or any one layer of abstraction is so important. Specifically
    what you mentioned about being bootstrapped immediately by these people. It means
    that since you're getting up to speed on everything at the same time, rather than
    spending grad school going deep in one specific way of doing RL, you can actually
    take the global view and aren't totally bought in on one thing.
  id: totrans-split-606
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，关于这件事真正有趣的是你提到的第三点。拥有一个理解所有层次的人，不会固守于任何一种方法或抽象层次，这是非常重要的。特别是你提到的关于这些人立即自给自足的事情。这意味着，因为你同时在所有事情上加速学习，而不是像在研究生院花费时间深入研究一种特定的
    RL 方法，你实际上可以采取全局观，并且并不完全迷恋于一件事情。
- en: So not only is it something that's possible, but it has greater returns potentially
    than just hiring somebody at a grad school. Just like getting a GPT-8 and fine-tuning
    the model for one year.
  id: totrans-split-607
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这不仅仅是可能的事情，而且潜在的回报可能比只是雇佣某人在研究生院更大。就像获得一个 GPT-8 并在一年内调整模型一样。
- en: '**Sholto Douglas** *01:49:41*'
  id: totrans-split-608
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:49:41*'
- en: You come at everything with fresh eyes and you don't come in locked to any particular
    field. Now one caveat to that is that before, during my self-experimentation,
    I was reading everything I could. I was obsessively reading papers every night.
    Funnily enough, I read much less widely now that my day is occupied by working
    on things. And in some respect, I had this very broad perspective whereas in a
    PhD program, you'll just focus on a particular area. If you just read all the
    NLP work and all the computer vision work and like all the robotics work, you
    see all these patterns that start to emerge across subfields, in a way that foreshadowed
    some of the work that I would later do.
  id: totrans-split-609
  prefs: []
  type: TYPE_NORMAL
  zh: 你用全新的眼光来看待一切，而不被锁定在任何特定领域。现在唯一的一点需要注意的是，在我进行自我实验之前，我一直在晚上着迷地阅读论文。有趣的是，现在我的白天都在忙于工作的事务中，我的阅读量大大减少了。在某种程度上，我以前有着非常广泛的视野，而在博士项目中，你只会专注于特定领域。如果你只是阅读所有的NLP工作、计算机视觉工作和所有的机器人工作，你会看到这些子领域中开始出现的一些模式，这预示了我后来会做的一些工作。
- en: '**Dwarkesh Patel** *01:50:26*'
  id: totrans-split-610
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:50:26*'
- en: That's super interesting. One of the reasons that you've been able to be agentic
    within Google is you're [pair programming](https://en.wikipedia.org/wiki/Pair_programming#:~:text=Pair%20programming%20is%20a%20software,as%20it%20is%20typed%20in.)
    half the days, or most of the days, with Sergey Brin, right? So it's really interesting
    that there's a person who's willing to just push ahead on this LLM stuff and get
    rid of the local blockers in place.
  id: totrans-split-611
  prefs: []
  type: TYPE_NORMAL
  zh: 这真的很有趣。在谷歌内部，你能够保持主动性的其中一个原因是你和谢尔盖·布林一半的时间或大部分时间进行[配对编程](https://en.wikipedia.org/wiki/Pair_programming#:~:text=Pair%20programming%20is%20a%20software,as%20it%20is%20typed%20in.)，对吧？所以，有一个愿意推动LLM事务并消除现有阻碍的人真的很有趣。
- en: '**Sholto Douglas** *01:50:46*'
  id: totrans-split-612
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:50:46*'
- en: It’s important to say it’s not like everyday or anything. There are particular
    projects that he's interested in, and then we'll work together on those. But there's
    also been times when he's been focused on projects with other people. But in general,
    yes, there's a surprising alpha to being one of the people who actually goes down
    to the office every day.
  id: totrans-split-613
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是说，这并不像日常生活中的任何事情。他对特定项目感兴趣，然后我们将共同合作。但也有过他专注于与其他人合作的项目的时候。但总的来说，是的，成为那些实际每天下班办公室的人之一确实有惊人的优势。
- en: It shouldn't be, but that is surprisingly impactful. As a result, I've benefited
    a lot from basically being close friends with people in leadership who care, and
    from being able to really argue convincingly about why we should do X as opposed
    to Y, and having that vector. Google is a big organization and having those vectors
    helps a little bit. But also it's the kind of thing you don't want to ever abuse.
    You want to make the argument through the right channels and only sometimes do
    you need to.
  id: totrans-split-614
  prefs: []
  type: TYPE_NORMAL
  zh: 这不应该是，但这确实具有令人惊讶的影响力。因此，我受益匪浅的一个原因是基本上与关心领导层的人成为亲密朋友，以及能够就为什么我们应该做X而不是Y进行有力争论，并拥有这个向量。谷歌是一个大组织，有这些向量确实有所帮助。但也是你绝不想滥用的事情。你希望通过正确的渠道提出论点，只有在必要时才需要这样做。
- en: '**Dwarkesh Patel** *01:51:47*'
  id: totrans-split-615
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:51:47*'
- en: So this includes people like Sergey Brin, [Jeff Dean](https://research.google/people/jeffrey-dean/),
    and so forth. I mean, it's notable. I feel like Google is undervalued. Like Steve
    Jobs is working on the equivalent next product for Apple and pair programming
    on it or something…
  id: totrans-split-616
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，这包括像谢尔盖·布林、[杰夫·迪恩](https://research.google/people/jeffrey-dean/)等人。我觉得这很显著。我觉得谷歌被低估了。就像史蒂夫·乔布斯正在为苹果开发下一个等价产品并进行配对编程之类的事情……
- en: '**Sholto Douglas** *01:52:00*'
  id: totrans-split-617
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:52:00*'
- en: Right, I've benefited immensely from it. So for example, during the Christmas
    break, I was going into the office for a couple of days during that time. I don't
    know if you guys have read that [article](https://www.newyorker.com/magazine/2018/12/10/the-friendship-that-made-google-huge)
    about Jeff and Sanjay, but they were there pair programming on stuff. I got to
    hear about all these cool stories of early Google where they're talking about
    crawling under the floorboards and rewiring data centers and telling me how many
    bytes they were pulling off the instructions of a given compiler and instruction,
    all these crazy little performance optimizations they were doing. They were having
    the time of their life and I got to sit there and really experience this. There's
    a sense of history that you expect to be very far away from in a large organization,
    but…
  id: totrans-split-618
  prefs: []
  type: TYPE_NORMAL
  zh: 对，我从中受益匪浅。比如，圣诞节期间，我在那段时间去了办公室几天。不知道你们有没有读过关于Jeff和Sanjay的[文章](https://www.newyorker.com/magazine/2018/12/10/the-friendship-that-made-google-huge)，他们在那里一起编程。我听到了一些早期Google的酷炫故事，比如他们谈论如何在地板下爬行并重新布线数据中心，告诉我他们从给定编译器和指令中拉取的字节数，所有这些疯狂的性能优化。他们那时候过得非常愉快，而我则有幸坐在那里亲身经历了这一切。在一个大型组织中，你期望与历史感触远隔千里，但是…
- en: '**Dwarkesh Patel** *01:53:02*'
  id: totrans-split-619
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:53:02*'
- en: That's super cool. And Trenton, does this map onto any of your experience?
  id: totrans-split-620
  prefs: []
  type: TYPE_NORMAL
  zh: 太酷了。Trenton，这是否与你的经验有所对应？
- en: '**Trenton Bricken** *01:53:06*'
  id: totrans-split-621
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:53:06*'
- en: I think Sholto's story is more exciting. Mine was just very serendipitous in
    that I got into computational neuroscience. I didn't have much business being
    there. My first paper was mapping the cerebellum to the attention operation and
    transformers. My next ones were looking at–
  id: totrans-split-622
  prefs: []
  type: TYPE_NORMAL
  zh: 我觉得Sholto的故事更激动人心。我的经历只是非常偶然，我进入了计算神经科学领域。我在那里毫无背景。我的第一篇论文是将小脑映射到注意力操作和变压器上。接下来的几篇文章则是研究…
- en: '**Dwarkesh Patel** *01:53:23*'
  id: totrans-split-623
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:53:23*'
- en: How old were you when you wrote that?
  id: totrans-split-624
  prefs: []
  type: TYPE_NORMAL
  zh: 你写那篇文章时多大了？
- en: '**Trenton Bricken** *01:53:24*'
  id: totrans-split-625
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:53:24*'
- en: It was my first year of grad school, so 22\. My next work was on [sparsity in
    networks](https://arxiv.org/pdf/2303.11934.pdf), inspired by sparsity in the brain,
    which was when I met [Tristan Hume](https://thume.ca/). Anthropic was doing the
    [SoLU](https://www.anthropic.com/news/softmax-linear-units), the Softmax Linear
    Output Unit work which was very related in quite a few ways in terms of making
    the activation of neurons across a layer really sparse. If we do that then we
    can get some interpretability of what the neuron's doing. I think we've updated
    that approach towards what we're doing now. So that started the conversation.
  id: totrans-split-626
  prefs: []
  type: TYPE_NORMAL
  zh: 那是我研究生第一年，22岁。我的下一个工作是关于[网络中的稀疏性](https://arxiv.org/pdf/2303.11934.pdf)，受大脑中的稀疏性启发，那时我遇到了[Tristan
    Hume](https://thume.ca/)。Anthropic正在进行[SoLU](https://www.anthropic.com/news/softmax-linear-units)——Softmax线性输出单元的工作，这与神经元层的激活非常相关。如果我们这样做，我们就可以理解神经元的活动。我认为我们已经更新了这种方法，朝着我们现在正在做的方向发展。这开始了对话。
- en: I shared drafts of that paper with Tristan. He was excited about it. That was
    basically what led me to become Tristan's resident and then convert to full-time.
    But during that period, I also moved as a visiting researcher to Berkeley, and
    started working with [Bruno Olshausen](https://www2.eecs.berkeley.edu/Faculty/Homepages/baolshausen.html),
    both on what's called [vector symbolic architectures](https://redwood.berkeley.edu/wp-content/uploads/2022/11/Vector_Symbolic_Architectures_as_a_Computing_Framework_for_Emerging_Hardware.pdf)–one
    of the core operations of them is literally superposition–and on sparse coding
    also known as dictionary learning, which is literally what we've been doing since.
    Bruno Olshausen basically invented sparse coding back in 1997\. So my research
    agenda and the interpretability team seemed to be running in parallel in research
    tastes. So it made a lot of sense for me to work with the team and it's been a
    dream since.
  id: totrans-split-627
  prefs: []
  type: TYPE_NORMAL
  zh: 我与Tristan分享了那篇论文的草稿。他对此很兴奋。这基本上是我成为Tristan的住宅助理，然后转为全职的导火索。但在那段时间里，我还作为访问研究员搬到了伯克利，并开始与[Bruno
    Olshausen](https://www2.eecs.berkeley.edu/Faculty/Homepages/baolshausen.html)合作，研究所谓的[向量符号架构](https://redwood.berkeley.edu/wp-content/uploads/2022/11/Vector_Symbolic_Architectures_as_a_Computing_Framework_for_Emerging_Hardware.pdf)——其中一个核心操作就是超位置——以及稀疏编码，也被称为字典学习，这正是我们一直在做的事情。Bruno
    Olshausen在1997年发明了稀疏编码。我的研究议程和可解释性团队似乎在研究口味上是并行的。因此，与团队合作对我来说是理所当然的事情，这是一个梦想。
- en: '**Dwarkesh Patel** *01:54:49*'
  id: totrans-split-628
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:54:49*'
- en: There’s one thing I've noticed when people tell stories about their careers
    or their successes. They ascribe it way more to contingency, but when they hear
    about other people's stories they're like, “of course it wasn't contingent.” You
    know what I mean? “If that didn't happen, something else would have happened.”
  id: totrans-split-629
  prefs: []
  type: TYPE_NORMAL
  zh: 当人们讲述他们的职业生涯或成功故事时，我注意到了一件事。他们往往把这归因于偶然性，但当他们听别人的故事时，他们会说，“当然不是偶然的。”你知道我是什么意思吗？“如果那件事没有发生，就会发生其他事情。”
- en: I've just noticed that and it's interesting that you both think that it was
    especially contingent. Maybe you're right. But it’s sort of an interesting pattern.
  id: totrans-split-630
  prefs: []
  type: TYPE_NORMAL
  zh: 我刚刚注意到这一点，你们都认为这尤其是偶然的。也许你们是对的。但这是一个有趣的模式。
- en: '**Trenton Bricken** *01:55:17*'
  id: totrans-split-631
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *01:55:17*'
- en: I mean, I literally met Tristan at a conference and didn't have a scheduled
    meeting with him or anything. I just joined a little group of people chatting,
    and he happened to be standing there, and I happened to mention what I was working
    on, and that led to more conversations. I think I probably would've applied to
    Anthropic at some point anyways. But I would've waited at least another year.
    It's still crazy to me that I can actually contribute to interpretability in a
    meaningful way.
  id: totrans-split-632
  prefs: []
  type: TYPE_NORMAL
  zh: 我的意思是，我在一个会议上碰到了Tristan，没有预约会议或者其他什么。我只是加入了一群人聊天，他碰巧站在那里，我碰巧提到了我在做什么，然后就有了更多的对话。我想我可能会在某个时候申请Anthropic。但我至少还要等一年。对我来说，我能够真正有意义地为解释性做出贡献，这仍然让我感到很惊讶。
- en: '**Sholto Douglas** *01:55:42*'
  id: totrans-split-633
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:55:42*'
- en: I think there's an important aspect of shots on goal there, so to speak. Where
    just choosing to go to conferences itself is putting yourself in a position where
    luck is more likely to happen. Conversely, in my own situation it was doing all
    of this work independently and trying to produce and do interesting things. That
    was my own way of trying to manufacture luck, so to speak, to try and do something
    meaningful enough that it got noticed.
  id: totrans-split-634
  prefs: []
  type: TYPE_NORMAL
  zh: 我觉得那里有一个很重要的射门机会，就像说的那样。选择参加会议本身就是让自己处于更容易发生运气的位置。相反，在我自己的情况下，是独立完成所有这些工作，努力产生并做出有趣的事情。这是我试图制造运气的方式，试图做出足够有意义的事情以便被注意到。
- en: '**Dwarkesh Patel** *01:56:08*'
  id: totrans-split-635
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:56:08*'
- en: Given what you said, you framed this in the context that they were trying to
    run this experiment.
  id: totrans-split-636
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你说的，你把这个放在他们试图运行这个实验的背景下。
- en: '**Sholto Douglas** *01:56:13*'
  id: totrans-split-637
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:56:13*'
- en: So specifically James and, I think, our manager Brennan was trying to run this
    experiment.
  id: totrans-split-638
  prefs: []
  type: TYPE_NORMAL
  zh: 所以具体来说，詹姆斯和我认为我们的经理布伦南试图运行这个实验。
- en: '**Dwarkesh Patel** *01:56:17*'
  id: totrans-split-639
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:56:17*'
- en: It worked. Did they do it again?
  id: totrans-split-640
  prefs: []
  type: TYPE_NORMAL
  zh: 它奏效了。他们再次这样做了吗？
- en: '**Sholto Douglas** *01:56:19*'
  id: totrans-split-641
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:56:19*'
- en: Yeah, so my closest collaborator, Enrique, he crossed from search through to
    our team. He's also been ridiculously impactful. He's definitely a stronger engineer
    than I am and he didn't go to university.
  id: totrans-split-642
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，所以我的最亲密的合作伙伴，恩里克，他从搜索跨到了我们的团队。他对我们的影响确实非常大。他绝对是比我更强的工程师，而且他没有上大学。
- en: '**Dwarkesh Patel** *01:56:33*'
  id: totrans-split-643
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:56:33*'
- en: What was notable is that usually this kind of stuff is farmed out to recruiters
    or something. Whereas James is somebody whose time is worth like hundreds of millions
    of dollars.You know what I mean? So this thing is very bottlenecked on that kind
    of person taking the time, in an almost aristocratic tutoring sense, and finding
    someone and then getting them up to speed. It seems if it works this well, it
    should be done at scale. Like it should be the responsibility of key people to
    onboard.
  id: totrans-split-644
  prefs: []
  type: TYPE_NORMAL
  zh: 引人注目的是，通常这类事情都是交给招聘人员之类的。而詹姆斯是一个价值数亿美元时间的人。你知道我是什么意思吗？所以这件事在某种程度上非常依赖于那种人投入时间，几乎是贵族式的辅导感，找到某个人，然后让他们适应。看起来如果这么做效果这么好，应该要扩展开来。就像应该是关键人物的责任来进行入职培训一样。
- en: '**Sholto Douglas** *01:57:10*'
  id: totrans-split-645
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:57:10*'
- en: I think that is true to many extents. I'm sure you probably benefited a lot
    from the key researchers mentoring you deeply.
  id: totrans-split-646
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为在很多方面这是真实的。我相信你也从关键研究人员的深度指导中受益匪浅。
- en: '**Dwarkesh Patel** *01:57:18*'
  id: totrans-split-647
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *01:57:18*'
- en: And actively looking on open source repositories or on forums for potential
    people like this.
  id: totrans-split-648
  prefs: []
  type: TYPE_NORMAL
  zh: 并积极在开源代码库或论坛上寻找潜在的人选。
- en: '**Sholto Douglas** *01:57:25*'
  id: totrans-split-649
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *01:57:25*'
- en: I mean James has Twitter injected into his brain, but yes. I think this is something
    which in practice is done. Like people do look out for people that they find interesting
    and try to find high signal. In fact, I was talking about this with Jeff the other
    day and Jeff said that one of the most important hires he ever made was off a
    cold email. I was like, “well who was that?” And he's Chris Olah. Chris similarly
    had no formal background in ML. [Google Brain](https://en.wikipedia.org/wiki/Google_Brain)
    was just getting started in this kind of thing but Jeff saw that signal. And the
    residency program which Brain had was astonishingly effective at finding good
    people that didn't have strong ML backgrounds.
  id: totrans-split-650
  prefs: []
  type: TYPE_NORMAL
  zh: 我的意思是詹姆斯的大脑里注入了Twitter，但是是的。我认为实际上确实有人这样做。像人们确实会寻找他们觉得有趣的人，并试图找到高信号的人。事实上，我前几天和杰夫谈论过这件事，杰夫说他曾经做过最重要的招聘之一是通过冷邮件。我问：“那是谁？”他说是Chris
    Olah。克里斯在ML领域也没有正式背景。当时，Google Brain刚刚开始进行这类事情，但是杰夫看到了那个信号。Brain的住院计划惊人地有效地找到了没有强大ML背景的优秀人才。
- en: '**Dwarkesh Patel** *01:58:27*'
  id: totrans-split-651
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *01:58:27*'
- en: One of the other things I want to emphasize for a potential slice of the audience
    is that there's this sense that the world is legible and efficient, that you just
    go to jobs.google.com or jobs.whatevercompany.com and you apply and there's the
    steps and they will evaluate you efficiently. Not only from your stories, but
    it just seems like often that's not the way it happens. In fact, it's good for
    the world that that's not often how it happens. It is important to look at, “were
    they able to write an interesting technical blog post about their research or
    are they making interesting contributions.”
  id: totrans-split-652
  prefs: []
  type: TYPE_NORMAL
  zh: 我想要强调给观众的一个潜在切片的另一件事是，有一种观念是，世界是可以理解和高效的，你只需去jobs.google.com或jobs.whatevercompany.com申请，然后有一些步骤，他们会高效地评估你。不仅从你的故事，而且似乎通常并不是这样发生的。事实上，世界是如此发生是对世界有好处的。重要的是要看，“他们能否撰写有趣的技术博客文章介绍他们的研究，或者他们是否在做出有趣的贡献。”
- en: I want you to riff on this for the people who are assuming that the other end
    of the job board is super legible and mechanical. This is not how it works and
    in fact, people are looking for the different kind of person who's agentic and
    putting stuff out there.
  id: totrans-split-653
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你对那些假设工作板的另一端是非常可理解和机械化的人来进行演绎。这不是它的运作方式，事实上，人们正在寻找那种具有代理能力和表达能力的不同类型的人。
- en: '**Sholto Douglas** *01:59:25*'
  id: totrans-split-654
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *01:59:25*'
- en: I think specifically what people are looking for are two things. One is agency
    and putting yourself out there. The second is the ability to do something at a
    world-class level. There are two examples that I always like to point to here.
    [Andy Jones](https://andyljones.com/) from Anthropic did an amazing [paper](https://arxiv.org/abs/2104.03113)
    on scaling laws as applied to board games. It didn't require much resources. It
    demonstrated incredible engineering skill and incredible understanding of the
    most topical problem of the time. He didn't come from a typical academic background
    or whatever. As I understand it, basically as soon as he came out with that paper,
    both Anthropic and OpenAI were like, “we would desperately like to hire you.”
  id: totrans-split-655
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为人们特别在寻找两件事。一是代理和表达自己。二是能够在世界级水平上做某事。在这里，我总是喜欢指出两个例子。来自安索普的[Andy Jones](https://andyljones.com/)在缩放定律应用于棋盘游戏方面做了一篇了不起的[论文](https://arxiv.org/abs/2104.03113)。它并不需要太多资源。这展示了令人难以置信的工程技能和对当时最热门问题的令人难以置信的理解。他并不来自典型的学术背景或其他什么背景。据我了解，基本上他发布那篇论文后，安索普和OpenAI都迫不及待地想要聘请他。
- en: There's also someone who works on Anthropic's performance team now, [Simon Boehm](https://siboehm.com/),
    who has written in my mind the reference for [optimizing a CUDA map model](https://siboehm.com/articles/22/CUDA-MMM)
    on a GPU. It demonstrates an example of taking some prompt effectively and producing
    the world-class reference example for it, in something that wasn't particularly
    well done so far. I think that’s an incredible demonstration of ability and agency
    and in my mind would be an immediate, “we would please love to interview/hire
    you.”
  id: totrans-split-656
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，安索普的性能团队中也有人，[Simon Boehm](https://siboehm.com/)，他在我看来，撰写了优化CUDA映射模型的参考文献，这是一个GPU上的[示例](https://siboehm.com/articles/22/CUDA-MMM)。这展示了有效利用一些提示，并为其生成世界级参考示例的示例，在这方面之前并不特别成功。我认为这是能力和代理的令人难以置信的展示，并且在我看来，这将立即成为“我们非常乐意面试/聘用你”的原因。
- en: '**Trenton Bricken** *02:00:36*'
  id: totrans-split-657
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:00:36*'
- en: The only thing I can add here is I still had to go through the whole hiring
    process and all the standard interviews and this sort of thing.
  id: totrans-split-658
  prefs: []
  type: TYPE_NORMAL
  zh: 我唯一可以补充的是，我仍然需要经历整个招聘过程以及所有标准的面试等等这类事情。
- en: '**Sholto Douglas** *02:00:42*'
  id: totrans-split-659
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:00:42*'
- en: Yeah, everyone does. Everyone does.
  id: totrans-split-660
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，每个人都这样。每个人都这样。
- en: '**Dwarkesh Patel** *02:00:43*'
  id: totrans-split-661
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:00:43*'
- en: Wait, doesn't that seem stupid?
  id: totrans-split-662
  prefs: []
  type: TYPE_NORMAL
  zh: 等等，那听起来不傻吗？
- en: '**Sholto Douglas** *02:00:47*'
  id: totrans-split-663
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:00:47*'
- en: I mean, it's important, debiasing.
  id: totrans-split-664
  prefs: []
  type: TYPE_NORMAL
  zh: 我是说，去偏见很重要。
- en: '**Dwarkesh Patel** *02:00:50*'
  id: totrans-split-665
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:00:50*'
- en: A bias is what you want, right? You want the bias of somebody who's got great
    taste. Who cares?
  id: totrans-split-666
  prefs: []
  type: TYPE_NORMAL
  zh: 一个偏见就是你想要的，对吧？你想要有着出色品味的人的偏见。谁在乎呢？
- en: '**Sholto Douglas** *02:00:56*'
  id: totrans-split-667
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:00:56*'
- en: Your interview process should be able to disambiguate that as well.
  id: totrans-split-668
  prefs: []
  type: TYPE_NORMAL
  zh: 你的面试过程应该能够消除这一点。
- en: '**Trenton Bricken** *02:00:59*'
  id: totrans-split-669
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:00:59*'
- en: I think there are cases where someone seems really great and then they actually
    just can't code, this sort of thing. How much you weigh these things definitely
    matters though and I think we take references really seriously. The interviews
    you can only get so much signal from. So it's all these other things that can
    come into play for whether or not a hire makes sense.
  id: totrans-split-670
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为有些情况下，有些人看起来很棒，但实际上他们却不能编码，这种情况。你对这些事情给予多少权重绝对很重要，我认为我们非常认真地对待参考资料。你只能从面试中获取有限的信号。所以，所有这些其他因素可能对是否雇佣某人有所影响。
- en: '**Sholto Douglas** *02:01:18*'
  id: totrans-split-671
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:01:18*'
- en: But you should design your interviews such that they test the right things.
  id: totrans-split-672
  prefs: []
  type: TYPE_NORMAL
  zh: 但是你应该设计你的面试，以便测试正确的事情。
- en: '**Dwarkesh Patel** *02:01:23*'
  id: totrans-split-673
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:01:23*'
- en: One man's bias is another man's taste.
  id: totrans-split-674
  prefs: []
  type: TYPE_NORMAL
  zh: 一个人的偏见是另一个人的品味。
- en: '**Trenton Bricken** *02:01:29*'
  id: totrans-split-675
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:01:29*'
- en: 'I guess the only thing I would add to this, or to the headstrong context, is
    this line: “the system is not your friend.” It''s not necessarily actively against
    you or your sworn enemy. It''s just not looking out for you. So that''s where
    a lot of the proactiveness comes in. There are no adults in the room and you have
    to come to some decision for what you want your life to look like and execute
    on it. And hopefully you can then update later, if you''re too headstrong in the
    wrong way. But I think you almost have to just charge at certain things to get
    much of anything done, to not be swept up in the tide of whatever the expectations
    are.'
  id: totrans-split-676
  prefs: []
  type: TYPE_NORMAL
  zh: 我想我唯一会添加到这个或固执的上下文中的事情，就是这句话：“系统不是你的朋友。”它不一定是在主动对抗你或者是你的死敌。它只是不会为你着想。这就是许多主动行动的地方。房间里没有成年人，你必须对你想让生活看起来像什么做出一些决定，并且执行它。希望你之后能更新，如果你在错误的方式上太固执。但我认为你几乎必须冲向某些事情才能得到任何事情，不要被任何期望的潮流所淹没。
- en: '**Sholto Douglas** *02:02:11*'
  id: totrans-split-677
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:02:11*'
- en: There's one final thing I want to add. We talked a lot about agency and this
    kind of stuff.
  id: totrans-split-678
  prefs: []
  type: TYPE_NORMAL
  zh: 还有最后一件事我想要补充。我们谈了很多关于代理权和这类的事情。
- en: But I think surprisingly enough, one of the most important things is just caring
    an unbelievable amount. When you care an unbelievable amount, you check all the
    details and you have this understanding of what could have gone wrong. It just
    matters more than you think. People end up not caring or not caring enough.
  id: totrans-split-679
  prefs: []
  type: TYPE_NORMAL
  zh: 但我认为令人惊讶的是，其中最重要的事情之一就是非常关心。当你关心到极致时，你会检查所有的细节，并且对可能出错的事情有所了解。它比你想象的重要得多。人们最终会变得不关心或者不够关心。
- en: There’s this LeBron quote where he talks about how before he started in the
    league he was worried that everyone being incredibly good. He gets there and then
    he realizes that actually, once people hit financial stability, they relax a bit
    and he realizes, “oh, this is going to be easy.”
  id: totrans-split-680
  prefs: []
  type: TYPE_NORMAL
  zh: 有一句勒布朗的话，他谈到他在联盟开始之前担心每个人都非常出色。他到了那里，然后他意识到其实，一旦人们达到了财务稳定，他们会放松一些，他意识到，“哦，这会很容易。”
- en: I don't think that's quite true because I think in AI research most people actually
    care quite deeply. But there's caring about your problem and there's also just
    caring about the entire stack and everything that goes up and down, going explicitly
    and fixing things that aren't your responsibility to fix because overall it makes
    the stack better.
  id: totrans-split-681
  prefs: []
  type: TYPE_NORMAL
  zh: 我不认为这完全正确，因为我认为在人工智能研究中，大多数人确实非常关心。但是关心你的问题和关心整个栈以及上下游的一切，显式地去修复那些不是你责任修复的东西，因为整体来看，这会使栈变得更好。
- en: '**Dwarkesh Patel** *02:03:11*'
  id: totrans-split-682
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:03:11*'
- en: You were mentioning going in on weekends and on Christmas break and the only
    people in the office are Jeff Dean and Sergey Brin or something and you just get
    to pair program with them. I don't want to pick on your company in particular,
    but people at any big company have gotten there because they've gone through a
    very selective process. They had to compete in high school. They had to compete
    in college. But it almost seems like they get there and then they take it easy
    when in fact it's the time to put the pedal to the metal. Go in and pair program
    with Sergey Brin on the weekends or whatever, you know what I mean?
  id: totrans-split-683
  prefs: []
  type: TYPE_NORMAL
  zh: 你曾提到过周末和圣诞假期去办公室，而办公室里唯一在的人是杰夫·迪恩和谢尔盖·布林之类的人，你可以和他们一起编程。我并不是特意针对你的公司，但是任何大公司的人之所以能在那里，是因为他们经历了非常严格的选拔过程。他们在高中时要竞争，他们在大学时也是如此。但事实上，他们似乎到了那里之后就开始懈怠了，而实际上现在正是加速前进的时候。去周末和谢尔盖·布林一起编程，或者做些什么，你明白我的意思吧？
- en: '**Sholto Douglas** *02:03:48*'
  id: totrans-split-684
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:03:48*'
- en: There's pros and cons there, right? I think many people make the decision that
    the thing that they want to prioritize is a wonderful life with their family.
    They do wonderful work in the hours that they do and that's incredibly impactful.
    I think this is true for many people at Google. Maybe they don't work as many
    hours as in your typical startup mythologies. But the work that they do is incredibly
    valuable.
  id: totrans-split-685
  prefs: []
  type: TYPE_NORMAL
  zh: 这   有利有弊，对吧？我觉得很多人会做出这样的决定，他们优先考虑的是与家人过上美好的生活。他们在工作时表现出色，这是非常有影响力的。我认为这对很多谷歌员工来说都是真实的。也许他们的工作时间没有典型初创公司那么长。但是他们所做的工作是非常有价值的。
- en: It's very high-leverage because they know the systems and they're experts in
    their field. We also need people like that. Our world rests on these huge systems
    that are difficult to manage and difficult to fix. We need people who are willing
    to work on, and help, and fix, and maintain those in frankly a thankless way.
    That isn't as high publicity as all of this AI work that we're doing. I am ridiculously
    grateful that those people do that. I'm also happy that there are people that
    find technical fulfillment in their job and doing that well and also maybe they
    draw a lot more out of spending a lot of hours with their family. I'm lucky that
    I'm at a stage in my life where I can go in and work every hour of the week. I'm
    not making as many sacrifices to do that.
  id: totrans-split-686
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常高效，因为他们了解系统，他们是自己领域的专家。我们也需要像他们这样的人。我们的世界依赖于那些难以管理和难以修复的巨大系统。我们需要愿意在那些不那么受关注的工作中工作、帮助、修复和维护这些系统的人。这不像我们正在做的所有这些人工智能工作那样高调。我对那些人做这些事情感到非常感激。我也很高兴有些人在工作中找到技术上的满足感，并且做得很好，也许他们更多地享受与家人在一起的时光。我很幸运，我生活中的阶段使我能够每周工作每个小时。我没有为此做出太多牺牲。
- en: '**Dwarkesh Patel** *02:05:01*'
  id: totrans-split-687
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦尔克什·帕特尔** *02:05:01*'
- en: One example sticks out in my mind of this sort getting to the yes on the other
    side of a no. Basically every single high-profile guest I've done so far, I think
    maybe with one or two exceptions, I've sat down for a week and I've just come
    up with a list of sample questions. I just try to come up with really smart questions
    to send to them. In that entire process I've always thought, if I just cold email
    them, it's like a 2% chance they say yes. If I include this list, there's a 10%
    chance. Because otherwise, you go through their inbox and every 34 seconds, there's
    an interview for some podcast or interview. Every single time I've done this they've
    said yes.
  id: totrans-split-688
  prefs: []
  type: TYPE_NORMAL
  zh: 我记得一个例子让我印象深刻，就是在被拒绝后达成共识。基本上我所做的每一个知名嘉宾，除了一两个例外，我都会坐下来一周时间，然后列出一个样本问题列表。我只是试着想出一些非常聪明的问题给他们。在整个过程中，我总是在想，如果我只是冷冻给他们发电子邮件，可能只有2%的机会他们会说是。如果我包括这个列表，那就有10%的机会。因为否则，你会看到他们的收件箱，每34秒就有一个关于某个播客或采访的访问。每一次我这样做，他们都会说是。
- en: '**Trenton Bricken** *02:05:46*'
  id: totrans-split-689
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:05:46*'
- en: You just ask the right questions,
  id: totrans-split-690
  prefs: []
  type: TYPE_NORMAL
  zh: 你只需问对问题，
- en: '**Sholto Douglas** *02:05:49*'
  id: totrans-split-691
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:05:49*'
- en: You do everything, you'll win,
  id: totrans-split-692
  prefs: []
  type: TYPE_NORMAL
  zh: 你做好一切，你就会成功，
- en: '**Dwarkesh Patel** *02:05:50*'
  id: totrans-split-693
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦尔克什·帕特尔** *02:05:50*'
- en: You just literally have to dig in the same hole for 10 minutes, or in that case
    make a sample list of questions for them, to get past their "not an idiot" list.
  id: totrans-split-694
  prefs: []
  type: TYPE_NORMAL
  zh: 你只需花10分钟在同一个地方挖个洞，或者制作一个问题的样本列表，来解决他们的“不是傻瓜”列表。
- en: '**Sholto Douglas** *02:06:01*'
  id: totrans-split-695
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:06:01*'
- en: Demonstrate how much you care and the work you're willing to put in.
  id: totrans-split-696
  prefs: []
  type: TYPE_NORMAL
  zh: 展示你有多关心和你愿意付出的努力。
- en: '**Trenton Bricken** *02:06:05*'
  id: totrans-split-697
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:06:05*'
- en: Something that a friend said to me a while back that stuck is that it's amazing
    how quickly you can become world-class at something. Most people aren't trying
    that hard and are only working the actual 20 hours or something that they're spending
    on this thing. So if you just go ham, then you can get really far, pretty fast.
  id: totrans-split-698
  prefs: []
  type: TYPE_NORMAL
  zh: 有一段时间前一个朋友对我说的话让我印象深刻，他说，惊人的是你可以多快成为某个领域的世界级高手。大多数人并没有那么努力，只是在他们投入到这件事情上的实际20个小时左右。所以如果你全力以赴，你可以迅速取得很大进展。
- en: '**Sholto Douglas** *02:06:25*'
  id: totrans-split-699
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:06:25*'
- en: I think I'm lucky I had that experience with the [fencing](https://fie.org/athletes/31058)
    as well. I had the experience of becoming world-class in something and knowing
    that if you just worked really, really hard and were–
  id: totrans-split-700
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为我很幸运能有那种[击剑](https://fie.org/athletes/31058)的经历。我有成为某个领域世界级高手的经验，知道如果你真的非常努力并且......
- en: '**Dwarkesh Patel** *02:06:35*'
  id: totrans-split-701
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:06:35*'
- en: For context, Sholto was one seat away, he was the next person in line to go
    to the Olympics for fencing.
  id: totrans-split-702
  prefs: []
  type: TYPE_NORMAL
  zh: 作为背景，肖尔托就在旁边，他是即将参加奥运会击剑的下一个人选。
- en: '**Sholto Douglas** *02:06:43*'
  id: totrans-split-703
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:06:43*'
- en: I was at best like 42nd in the world for fencing, for men's foil fencing.
  id: totrans-split-704
  prefs: []
  type: TYPE_NORMAL
  zh: 在男子花剑比赛中，我最好时是世界排名第42。
- en: '**Dwarkesh Patel** *02:06:47*'
  id: totrans-split-705
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:06:47*'
- en: '[Mutational load](https://en.wikipedia.org/wiki/Genetic_load) is a thing, man.'
  id: totrans-split-706
  prefs: []
  type: TYPE_NORMAL
  zh: '[突变负荷](https://zh.wikipedia.org/wiki/%E9%81%97%E4%BC%A4%E8%B4%9F%E8%BD%BD)是一种东西，伙计。'
- en: '**Sholto Douglas** *02:06:53*'
  id: totrans-split-707
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:06:53*'
- en: There was one cycle where I was like the next highest-ranked person in Asia
    and if one of the teams had been disqualified for doping–as was occurring during
    that cycle and occurred for like the Australian women's rowing team that went
    on because one of the teams was disqualified–then I would have been the next in
    line.
  id: totrans-split-708
  prefs: []
  type: TYPE_NORMAL
  zh: 曾经有一个时期，我是亚洲排名第二高的人，如果其中一个团队因兴奋剂被取消资格——就像在那个周期发生的那样，并且像澳大利亚女子划船队那样进行，因为其中一个团队被取消资格——那么我就会是下一个候补。
- en: '**Dwarkesh Patel** *02:07:16*'
  id: totrans-split-709
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:07:16*'
- en: It's interesting when you just find out about people's prior lives and it's,
    “oh this guy was almost an Olympian.”
  id: totrans-split-710
  prefs: []
  type: TYPE_NORMAL
  zh: 当你刚刚了解别人的前世时，这是有趣的，“哦，这家伙几乎是奥林匹克选手。”
- en: Okay, let's talk about interpretability. I actually want to stay on the brain
    stuff as a way to get into it for a second. We were previously discussing this.
    Is the brain organized in the way where you have a residual stream that is gradually
    refined with higher-level associations over time? There's a fixed dimension size
    in a model. I don't even know how to ask this question in a sensible way, but
    what is the D model of the brain? What is the embedding size, or because of [feature
    splitting](https://medium.com/@brijesh_soni/topic-11-feature-construction-splitting-b116c60c4b2f#:~:text=Feature%20splitting%20is%20a%20technique,variables%20and%20the%20target%20variable.)
    is that not a sensible question?
  id: totrans-split-711
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们谈谈可解释性。我实际上想留在脑部的东西作为进入的方式。我们之前讨论过这个。大脑是否以一种方式组织，即您有一个残余流，随着时间的推移，它被更高级别的关联逐渐完善？在模型中有一个固定的维度大小。我甚至不知道如何以明智的方式提出这个问题，但大脑的D模型是什么？是嵌入大小，还是因为[特征分割](https://medium.com/@brijesh_soni/topic-11-feature-construction-splitting-b116c60c4b2f#:~:text=Feature%20splitting%20is%20a%20technique,variables%20and%20the%20target%20variable.)这不是一个明智的问题？
- en: '**Trenton Bricken** *02:08:06*'
  id: totrans-split-712
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:08:06*'
- en: No, I think it's a sensible question. Well, it is a question.
  id: totrans-split-713
  prefs: []
  type: TYPE_NORMAL
  zh: 不，我认为这是一个明智的问题。嗯，这是一个问题。
- en: '**Dwarkesh Patel** *02:08:09*'
  id: totrans-split-714
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:08:09*'
- en: You could have just not said that.
  id: totrans-split-715
  prefs: []
  type: TYPE_NORMAL
  zh: 你本可以不说那句话的。
- en: '**Trenton Bricken** *02:08:19*'
  id: totrans-split-716
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:08:19*'
- en: I don't know how you would begin. Okay, well this part of the brain is like
    a vector of this dimensionality. Maybe for the visual stream, because it's like
    [V1](https://en.wikipedia.org/wiki/Visual_cortex#Primary_visual_cortex_(V1)) to
    [V2](http://tex#V2) to IT, whatever. You could just count the number of neurons
    that are there and say that is the dimensionality. But it seems more likely that
    there are submodules and things are divided up. I'm not the world's greatest neuroscientist.
    I did it for a few years, I studied the cerebellum quite a bit. I'm sure there
    are people who could give you a better answer on this.
  id: totrans-split-717
  prefs: []
  type: TYPE_NORMAL
  zh: 我不知道你应该如何开始。好吧，大脑的这部分就像是这个维度的一个向量。也许对于视觉流来说，因为它像是[V1](https://zh.wikipedia.org/wiki/%E8%A7%86%E5%8A%A8%E7%9A%87%E4%B8%BB%E5%88%BA%E7%9B%B2#V1)到[V2](http://tex#V2)到IT，不管怎样。你可以简单地数一下那里的神经元的数量并说这就是维度。但似乎更有可能是有子模块和事物分割。我不是世界上最伟大的神经科学家。我做了几年，我非常研究小脑。我确信有人能给你一个更好的答案。
- en: '**Dwarkesh Patel** *02:08:56*'
  id: totrans-split-718
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:08:56*'
- en: Do you think that the way to think, whether it's in the brain or whether it's
    in these models, fundamentally what's happening is that features are added, removed,
    changed, and that the feature is the fundamental unit of what is happening in
    the model? This goes back to the earlier thing we were talking about, whether
    it's just associations all the way down. Give me a counterfactual. In the world
    where this is not true, what is happening instead? What is the alternative hypothesis
    here?
  id: totrans-split-719
  prefs: []
  type: TYPE_NORMAL
  zh: 你认为是否在大脑中或者在这些模型中思考的方式，基本上是功能被添加、移除、改变，而功能是模型中发生的基本单位？这又回到了我们之前讨论的事情，无论是不是仅仅是关联到底。给我一个反事实。在这个事情不成立的世界里，代替的假设是什么？
- en: '**Trenton Bricken** *02:09:30*'
  id: totrans-split-720
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:09:30*'
- en: It's hard for me to think about because at this point I just think so much in
    terms of this feature space. At one point there was the kind of [behavioral](https://en.wikipedia.org/wiki/Behaviorism)
    approach towards cognition where you're just input and output but you're not really
    doing any processing. Or it's like everything is embodied and you're just a dynamical
    system that's operating along some predictable equations but there's no state
    in the system. But whenever I've read these sorts of critiques I think, “well,
    you're just choosing to not call this thing a state, but you could call any internal
    component of the model a state.” Even with the feature discussion, defining what
    a feature is, is really hard. So the question feels almost too slippery.
  id: totrans-split-721
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说很难想象，因为在这一点上我只是在这个特征空间上思考得太多了。曾经有一种行为主义的认知方法，其中你只是输入和输出，但你实际上没有进行任何处理。或者说一切都是具体化的，你只是一个按某些可预测方程操作的动态系统，但系统中没有状态。但每当我读到这些批评时，我会想，“嗯，你只是选择不称呼这个东西为状态，但你可以把模型的任何内部组件都称为状态。”即使在特征讨论中，定义一个特征是什么，这真的很难。所以这个问题几乎感觉太滑稽了。
- en: '**Dwarkesh Patel** *02:10:24*'
  id: totrans-split-722
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:10:24*'
- en: What is a feature?
  id: totrans-split-723
  prefs: []
  type: TYPE_NORMAL
  zh: 什么是一个功能？
- en: '**Trenton Bricken** *02:10:25*'
  id: totrans-split-724
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:10:25*'
- en: A direction and activation space. A latent variable that is operating behind
    the scenes, that has causal influence over the system you're observing. It’s a
    feature if you call it a feature, it's tautological.
  id: totrans-split-725
  prefs: []
  type: TYPE_NORMAL
  zh: 一个方向和激活空间。一个在幕后运作的潜在变量，对你正在观察的系统有因果影响。如果你称之为特征，它就是特征，这是自证的。
- en: '**Sholto Douglas** *02:10:49*'
  id: totrans-split-726
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *02:10:49*'
- en: In a very rough, intuitive sense in a sufficiently sparse and like binary vector,
    a feature is whether or not something's turned on or off, in a very simplistic
    sense. I think a useful metaphor to understand is that in many respects it’s the
    same way the neuroscientists would talk about a neuron activating, right?
  id: totrans-split-727
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个非常粗糙、直观的意义上，在一个足够稀疏和类似二进制向量的情况下，一个特征是指某事物是否开启或关闭，在一个非常简单的意义上。我认为一个有用的比喻是，在许多方面，这种方式与神经科学家讨论神经元激活的方式非常相似，对吧？
- en: '**Trenton Bricken** 02:11:11'
  id: totrans-split-728
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** 02:11:11'
- en: If that neuron corresponds to…
  id: totrans-split-729
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个神经元对应于……
- en: '**Sholto Douglas** *02:11:12*'
  id: totrans-split-730
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *02:11:12*'
- en: To something in particular, right?
  id: totrans-split-731
  prefs: []
  type: TYPE_NORMAL
  zh: 有特别要说的吗？
- en: '**Trenton Bricken** *02:11:15*'
  id: totrans-split-732
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:11:15*'
- en: What do we want a feature to be? What is the synthetic problem under which a
    feature exists? Even with the “Towards Monosemanticity” work, we talk about what's
    called feature splitting, which is basically where you will find as many features
    as you give the model the capacity to learn. By model here, I mean the up projection
    that we fit after we trained the original model. So if you don't give it much
    capacity, it'll learn a feature for bird, but if you give it more capacity, then
    it will learn ravens and eagles and sparrows and specific types of birds.
  id: totrans-split-733
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望一个功能是什么？一个功能存在的合成问题是什么？即使在“朝向单语义性”的工作中，我们也谈论所谓的功能分裂，这基本上是当你给模型足够的学习能力时，你会发现它可以学到多少功能。在这里的模型是指我们在训练原始模型后拟合的上投影。所以，如果你不给它足够的容量，它会学到一个关于鸟的特征，但如果你给它更多的容量，那么它将学到乌鸦、鹰、麻雀以及特定类型的鸟类。
- en: '**Dwarkesh Patel** *02:11:51*'
  id: totrans-split-734
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:11:51*'
- en: Still on the definitions thing, I naively think of things like bird versus,
    at the highest level, things like love or deception or holding a very complicated
    proof in your head or something.
  id: totrans-split-735
  prefs: []
  type: TYPE_NORMAL
  zh: 依然在定义的事物上，我天真地想到像鸟类与在最高层次上像爱情、欺骗或者在脑中保持一个非常复杂的证明之类的事物。
- en: Are these all features? Because then the definition seems so broad as to almost
    be not that useful. Rather there seems to be some important differences between
    these things and they're all features. I'm not sure what we would mean by that.
  id: totrans-split-736
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都是特征吗？因为这样定义似乎过于宽泛，几乎没有用。相反，似乎这些东西之间有一些重要的区别，它们都是特征。我不确定我们指的是什么。
- en: '**Trenton Bricken** *02:12:32*'
  id: totrans-split-737
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:12:32*'
- en: I mean all of those things are discrete units that have connections to other
    things that then imbues them with meaning. That feels like a specific enough definition
    that it's useful or not too all-encompassing. But feel free to push back.
  id: totrans-split-738
  prefs: []
  type: TYPE_NORMAL
  zh: 我的意思是，所有这些东西都是离散单元，它们与其他事物有连接，这样赋予它们意义。这感觉像是一个具体到足够有用或者不是太全面的定义。但请随意提出异议。
- en: '**Dwarkesh Patel** *02:12:49*'
  id: totrans-split-739
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:12:49*'
- en: Well what would you discover tomorrow that could make you think, “oh this is
    fundamentally the wrong way to think about what's happening in a model.”
  id: totrans-split-740
  prefs: []
  type: TYPE_NORMAL
  zh: 那么明天你会发现什么，会让你认为：“哦，这基本上是错误的方式来思考模型中正在发生的事情。”
- en: '**Trenton Bricken** *02:12:59*'
  id: totrans-split-741
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:12:59*'
- en: 'If the features we were finding weren''t predictive, or if they were just representations
    of the data, where it''s like: “oh all you''re doing is just clustering your data
    and there''s no higher- level associations that are being made or it''s some phenomenological
    thing of your call. You''re saying that this feature files for marriage, but if
    you activate it really strongly it doesn''t change the outputs of the model in
    a way that would correspond to it.”'
  id: totrans-split-742
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们找到的特征没有预测性，或者它们只是数据的表示，就像：“哦，你所做的只是对数据进行聚类，并没有进行更高级别的关联或者这是你说的某种现象学的事情。你在说这个特征是为了婚姻，但如果你强烈激活它，它不会以与之相对应的方式改变模型的输出。”
- en: I think those would both be good critiques. Here’s another. We tried to do experiments
    on [MNIST](https://en.wikipedia.org/wiki/MNIST_database) which is a data set of
    images, and we didn't look super hard into it. So I'd be interested if other people
    wanted to take up a deeper investigation here. But it's plausible that your latent
    space of representations is dense and it's a manifold instead of being these discrete
    points. So you could move across the manifold, but at every point, there would
    be some meaningful behavior. It's much harder then, to label things as features
    that are discrete.
  id: totrans-split-743
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这些都是很好的批评意见。这里有另一个。我们试图在[MNIST](https://en.wikipedia.org/wiki/MNIST_database)上做实验，这是一个图像数据集，我们没有非常深入地研究它。所以如果其他人想深入调查这里，我会很感兴趣。但是你的表示空间可能是密集的，而不是这些离散点的流形。因此，你可以穿越流形，但在每一个点上，都会有一些有意义的行为。这样做更难，去标记那些离散的特征。
- en: '**Dwarkesh Patel** *02:14:05*'
  id: totrans-split-744
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:14:05*'
- en: In a naive, sort of outsider way, it seems to me that a way in which this picture
    could be wrong is if it’s not that something is turned on and turned off, but
    that it's a much more global kind of the system. I'm going to use really clumsy,
    dinner party kind of language, but is there a good analogy here?
  id: totrans-split-745
  prefs: []
  type: TYPE_NORMAL
  zh: 以一个天真的、局外人的方式来看，对我来说，这种图片可能是错误的方式，如果不是因为某些东西被打开和关闭，而是系统的一种更全局的方式。我将使用非常笨拙的、晚宴的语言，但这里有一个好的类比吗？
- en: I guess if you think of something like the laws of physics, it's not that the
    feature for wetness is turned on, but it's only turned on this much and then the
    feature for… I guess maybe it's true because the mass is like a gradient and…
    I don't know. But the polarity or whatever is the gradient as well.
  id: totrans-split-746
  prefs: []
  type: TYPE_NORMAL
  zh: 我猜想，如果你想到物理定律之类的东西，不是说湿润的特征被打开了，而是只打开了这么多，然后是关于……我猜也许这是真的，因为质量就像一个梯度和……我不知道。但极性或者说梯度也是一样的。
- en: There's also a sense in which there's the laws and the laws are more general
    and you have to understand the general bigger picture and you don't get that from
    just these specific subcircuits.
  id: totrans-split-747
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一种感觉，那就是有法律，法律更加普遍，你必须理解更大的一般情况，而不是仅仅从这些具体的子电路中得到。
- en: '**Sholto Douglas** *02:15:08*'
  id: totrans-split-748
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:15:08*'
- en: But that's where the reasoning circuit itself comes into play, right? You're
    taking these features ideally and trying to compose them into something high-level.
    At least this is my headcanon, So let's say I'm trying to use the foot, F=ma,
    right? Then presumably at some point I have features which denote mass. And then
    that's helping me retrieve the actual mass of the thing that I'm using and then
    the acceleration and this kind of stuff. Then also, maybe there's a higher-level
    feature that does correspond to using the first law of physics. Maybe. But the
    more important part is the composition of components which helps me retrieve a
    relevant piece of information and then produce maybe some multiplication operator
    or something like that when necessary. At least that's my headcanon.
  id: totrans-split-749
  prefs: []
  type: TYPE_NORMAL
  zh: 但这就是推理电路本身发挥作用的地方，对吧？你理想地采用这些特征，并试图将它们组合成高级别的东西。至少在我看来是这样，所以让我们说我试图使用脚，F=ma，对吧？然后大概在某些时候，我有标识质量的特征。然后这有助于我检索我正在使用的物体的实际质量，然后是加速度和这种东西。然后也许还有一个更高级别的特征，对应于使用物理学的第一定律。也许。但更重要的部分是组件的组合，这有助于我检索相关的信息片段，然后在必要时产生乘法运算符或类似的东西。至少这是我的头脑设定。
- en: '**Dwarkesh Patel** *02:15:52*'
  id: totrans-split-750
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:15:52*'
- en: What is a compelling explanation to you, especially for very smart models, of
    “I understand why it made this output and it was like for a legit reason.” If
    it's doing million line pull requests or something, what are you seeing at the
    end of that request where you're like, “yep good, that's chill.”
  id: totrans-split-751
  prefs: []
  type: TYPE_NORMAL
  zh: 什么对你来说是一个令人信服的解释，尤其是对于非常聪明的模型，“我理解它为什么会产生这个输出，而且这是有合理原因的。” 如果它正在进行百万行的拉取请求或类似的事情，你在请求结束时看到了什么，你会说，“是的，很好，这很放松。”
- en: '**Trenton Bricken** *02:16:11*'
  id: totrans-split-752
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:16:11*'
- en: So ideally you apply dictionary learning to the model. You've found features.
    Right now we're actively trying to get the same success for [attention heads](https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853).
    You can do it for residual stream, MLP, and attention throughout the whole model.
    Hopefully at that point you can also identify broader circuits through the model
    that are more general reasoning abilities that will activate or not activate.
  id: totrans-split-753
  prefs: []
  type: TYPE_NORMAL
  zh: 所以理想情况下，你将字典学习应用于模型。你已经找到了特征。现在我们正在积极地尝试为[注意力头](https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853)获得相同的成功。你可以对残差流、MLP
    和整个模型中的注意力进行这样的操作。希望在那一点上，你也能识别出更广泛的电路，这些电路具有更一般的推理能力，将会激活或不激活。
- en: But in your case where we're trying to figure out if this pull request should
    be approved or not. I think you can flag or detect features that correspond to
    deceptive behavior, malicious behavior, these sorts of things, and see whether
    or not those have fired. That would be an immediate thing. You can do more than
    that, but that would be an immediate one.
  id: totrans-split-754
  prefs: []
  type: TYPE_NORMAL
  zh: 但在你们这种情况下，我们试图弄清楚是否应该批准这个拉取请求。我认为你可以标记或检测对应于欺骗行为、恶意行为等的特征，然后看看这些是否已经触发。那将是一个即时的事情。你可以做更多的事情，但那将是一个即时的事情。
- en: '**Dwarkesh Patel** *02:16:53*'
  id: totrans-split-755
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:16:53*'
- en: But before I trace down on that, what does a reasoning circuit look like? What
    would that look like when you found it?
  id: totrans-split-756
  prefs: []
  type: TYPE_NORMAL
  zh: 但在我深入研究之前，推理电路是什么样子？当你找到它时，它会是什么样子？
- en: '**Trenton Bricken** *02:17:00*'
  id: totrans-split-757
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:17:00*'
- en: Yeah, so, I mean, the [induction head](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html)
    is probably one of the simplest cases.
  id: totrans-split-758
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，所以，我是说，[归纳头](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html)可能是最简单的案例之一。
- en: '**Dwarkesh Patel** *02:17:02*'
  id: totrans-split-759
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:17:02*'
- en: But it's not reasoning, right?
  id: totrans-split-760
  prefs: []
  type: TYPE_NORMAL
  zh: 但这不是推理，对吧？
- en: '**Trenton Bricken** *02:17:04*'
  id: totrans-split-761
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:17:04*'
- en: Well, what do you call reasoning, right? For context for listeners, the induction
    head is basically, when you see the line, “Mr. and Mrs. Dursley did something.
    Mr. _____,” and you're trying to predict what “blank” is and the head has learned
    to look for previous occurrences of the word “Mr.”  and look at the word that
    comes after it and then copy and paste that as the prediction for what should
    come next. It's a super reasonable thing to do and there is computation being
    done there to accurately predict the next token.
  id: totrans-split-762
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，你认为什么是推理，对吧？为了听众的背景，归纳头基本上是，当你看到这一行，“达思利夫人和先生做了某事。先生______，”而你试图预测“空白”是什么，头部已经学会查找前面出现的“先生”一词，然后看看后面跟着的词，然后将其复制粘贴作为应该出现的预测。这是一个非常合理的做法，那里正在进行计算以准确预测下一个标记。
- en: '**Sholto Douglas** 02:17:43'
  id: totrans-split-763
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** 02:17:43'
- en: Yeah, that is context dependent.
  id: totrans-split-764
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这是上下文相关的。
- en: '**Dwarkesh Patel** *02:17:45*'
  id: totrans-split-765
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:17:45*'
- en: But it's not reasoning. You know what I mean?
  id: totrans-split-766
  prefs: []
  type: TYPE_NORMAL
  zh: 但这不是推理。你知道我什么意思吧？
- en: '**Trenton Bricken** *02:17:49*'
  id: totrans-split-767
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:17:49*'
- en: I guess going back to the “associations all the way down.” It’s if you chain
    together a bunch of these reasoning circuits, or heads, that have different rules
    for how to relate information.
  id: totrans-split-768
  prefs: []
  type: TYPE_NORMAL
  zh: 我想回到“从头到尾的关联”。如果你将一堆这些推理电路或者头部链接在一起，它就是在不同的规则下如何关联信息。
- en: '**Dwarkesh Patel** *02:18:02*'
  id: totrans-split-769
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:18:02*'
- en: But in this sort of zero shot case, something is happening when you pick up
    a new game and you immediately start understanding how to play it. And it doesn't
    seem like an induction head kind of thing.
  id: totrans-split-770
  prefs: []
  type: TYPE_NORMAL
  zh: 但在这种零射击的情况下，当你学会一款新游戏并立即开始理解如何玩它时，某些事情正在发生，它似乎不是感应头的事情。
- en: '**Trenton Bricken** *02:18:13*'
  id: totrans-split-771
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:18:13*'
- en: Or I think there would be another circuit for extracting pixels and turning
    them into latent representations of the different objects in the game, right?
    And a circuit that is learning physics.
  id: totrans-split-772
  prefs: []
  type: TYPE_NORMAL
  zh: 或者我认为还会有另一个电路，用于提取像素并将它们转化为游戏中不同对象的潜在表示，对吧？还有一个学习物理的电路。
- en: '**Dwarkesh Patel** *02:18:26*'
  id: totrans-split-773
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:18:26*'
- en: What would that look like? Because the induction head is like one layer transformer?
  id: totrans-split-774
  prefs: []
  type: TYPE_NORMAL
  zh: 这会是什么样子？因为感应头就像一个层次的变压器？
- en: '**Trenton Bricken** *02:18:30*'
  id: totrans-split-775
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:18:30*'
- en: Two layer.
  id: totrans-split-776
  prefs: []
  type: TYPE_NORMAL
  zh: 两层。
- en: '**Dwarkesh Patel** *02:18:32*'
  id: totrans-split-777
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:18:32*'
- en: So you can kind of see the thing that is a human picking up a new game and understanding
    it. How would you think about what that is? I presume it's across multiple layers.
    What would that physically look like? How big would it be maybe?
  id: totrans-split-778
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你可以看到人类学会新游戏并理解它的事物。你会如何思考这是什么？我想这涉及多层次。物理上会是什么样子？可能有多大？
- en: '**Trenton Bricken** *02:18:53*'
  id: totrans-split-779
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:18:53*'
- en: I mean, that would just be an empirical question, right? How big does the model
    need to be to perform this task? Maybe it's useful if I just talk about some other
    circuits that we've seen. So we've seen the [IOI circuit](https://arxiv.org/pdf/2211.00593.pdf),
    which is the indirect object identification. It's like, “Mary and Jim went to
    the store, Jim gave the object to ____.” It would predict “Mary” because Mary's
    appeared before, as the indirect object. Or, it'll infer pronouns. This circuit
    even has behavior where if you ablate it, then other heads in the model will pick
    up that behavior. We'll even find heads that want to do copying behavior, and
    then other heads will suppress it. So it's one head's job to just always copy
    the token that came before or the token that came five before, or whatever. And
    then it's another head's job to be like, “no, do not copy that thing.” There are
    lots of different circuits performing, in these cases, pretty basic operations.
    But when they're chained together you can get unique behaviors.
  id: totrans-split-780
  prefs: []
  type: TYPE_NORMAL
  zh: 我的意思是，这只是一个实证问题，对吧？模型需要多大才能执行这个任务？也许如果我谈谈我们见过的一些其他电路会有用。所以我们见过[IOI电路](https://arxiv.org/pdf/2211.00593.pdf)，这是间接对象识别。就像，“玛丽和吉姆去了商店，吉姆把物体给了____。”它会预测“玛丽”，因为玛丽之前出现过，作为间接对象。或者，它会推断代词。这个电路甚至有一种行为，如果你去除它，那么模型中的其他头部将会学习到这种行为。我们甚至会发现有一些头部想要复制行为，然后其他头部会抑制它。所以有一个头部的工作就是永远复制前一个标记或者前五个标记，或者其他什么。然后另一个头部的工作是，“不，不要复制那个东西。”在这些情况下，有许多不同的电路执行相当基本的操作。但是当它们被链接在一起时，你可以得到独特的行为。
- en: '**Dwarkesh Patel** *02:20:00*'
  id: totrans-split-781
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:20:00*'
- en: It won't be something you can see in like a two layer transformer, so will you
    just be like, “this is the circuit for deception” or whatever? This part of the
    network fired when we at the end identified the thing as being deceptive. This
    part didn't fire when we didn't identify it as being deceptive. Therefore, this
    must be the deception circuit.
  id: totrans-split-782
  prefs: []
  type: TYPE_NORMAL
  zh: 在像两层变压器这样的情况下，你是不可能看到它的，所以你会像“这是欺骗电路”之类的吗？当我们最终确认某物是欺骗时，这部分网络被激活。当我们没有确认它是欺骗时，这部分未被激活。因此，这一定是欺骗电路。
- en: '**Trenton Bricken** *02:20:25*'
  id: totrans-split-783
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:20:25*'
- en: I think a lot of analysis like that. Anthropic has done quite a bit of research
    before on [sycophancy](https://www.anthropic.com/news/towards-understanding-sycophancy-in-language-models),
    which is the model saying what it thinks you want to hear
  id: totrans-split-784
  prefs: []
  type: TYPE_NORMAL
  zh: 我觉得这样的分析很多。Anthropic之前对[sycophancy](https://www.anthropic.com/news/towards-understanding-sycophancy-in-language-models)做过很多研究，这是模型说出它认为你想听的话。
- en: '**Dwarkesh Patel** *02:20:36*'
  id: totrans-split-785
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:20:36*'
- en: That requires us at the end to be able to label which one is bad and which one
    is good.
  id: totrans-split-786
  prefs: []
  type: TYPE_NORMAL
  zh: 那最终要求我们能够标记哪个是坏的，哪个是好的。
- en: '**Trenton Bricken** *02:20:42*'
  id: totrans-split-787
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:20:42*'
- en: Yeah, so we have tons of instances–and actually as you make a lot of models
    larger, they do more of this–where the model clearly has features that model another
    person's mind and some subset of these, we're hypothesizing here, would be associated
    with more deceptive behavior.
  id: totrans-split-788
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，所以我们有大量的例子——实际上当你把许多模型变大时，它们会做更多这样的事情——模型显然具有模拟另一个人思维的特征，而我们假设其中一些子集可能与更具欺骗性的行为相关联。
- en: '**Dwarkesh Patel** *02:21:03*'
  id: totrans-split-789
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:21:03*'
- en: Although it's doing that by… I don't know. ChatGPT is probably modeling me because
    that's what [RLHF](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback)
    induces it to do.
  id: totrans-split-790
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它是通过... 我不知道。ChatGPT可能在模拟我，因为这是由[RLHF](https://zh.wikipedia.org/wiki/%E4%BA%BA%E9%A1%9E%E5%9B%9E%E9%A5%8B%E5%BC%8F%E5%BC%B7%E5%8C%96%E5%AD%B8%E7%BF%92)引起的。
- en: '**Trenton Bricken** *02:21:10*'
  id: totrans-split-791
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:21:10*'
- en: Yeah. [Theory of mind](https://en.wikipedia.org/wiki/Theory_of_mind).
  id: totrans-split-792
  prefs: []
  type: TYPE_NORMAL
  zh: 是的。[心灵理论](https://zh.wikipedia.org/wiki/%E5%BF%83%E7%90%86%E7%90%86%E8%AB%96)。
- en: '**Dwarkesh Patel** *02:21:12*'
  id: totrans-split-793
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:21:12*'
- en: So first of all, there’s the thing you mentioned earlier about redundancy. So
    then have you caught the whole thing that could cause deception of the whole thing
    or is it just one instance of it? Second of all, are your labels correct? Maybe
    you thought this wasn't deceptive but it’s still deceptive. Especially if it's
    producing output you can't understand. Third, is the thing that's gonna be the
    bad outcome something that's even human-understandable? Deception is a concept
    we can understand.
  id: totrans-split-794
  prefs: []
  type: TYPE_NORMAL
  zh: 所以首先，有你之前提到的冗余的事情。那么你是否捕捉到可能导致整个事情欺骗的全部内容，还是只是其中一个例子？其次，你的标签是否正确？也许你认为这不是欺骗，但它仍然是。特别是如果它产生了你无法理解的输出。第三，会成为坏结果的事情是否甚至是人类可以理解的？欺骗是一个我们可以理解的概念。
- en: '**Trenton Bricken** *02:21:41*'
  id: totrans-split-795
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:21:41*'
- en: A lot to unpack here. A few things. It's fantastic that these models are deterministic.
    When you sample from them, it's stochastic. But I can just keep putting in more
    inputs and ablate every single part of the model. This is kind of the pitch for
    computational neuroscientists to come and work on interpretability. It's like
    you have this alien brain, you have access to everything in it, and you can just
    ablate however much of it you want.
  id: totrans-split-796
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有很多要解开的东西。有几点。这些模型是确定性的，这是很棒的。当你从它们中采样时，它们是随机的。但我可以不断输入更多的信息，摧毁模型的每一个部分。这对计算神经科学家来说是种挑战，需要他们来解释这些。就像你有这个外星人的大脑，你可以访问其中的一切，并且你可以摧毁你想要的任何部分。
- en: So I think if you do this carefully enough you really can start to pin down
    what are the circuits involved and what are the backup circuits, these sorts of
    things. It’s a bit of a cop out answer but it's important to keep in mind doing
    automated interpretability. As our models continue to get more capable, we have
    them assign labels or run some of these experiments at scale. With respect to
    detecting superhuman performance, which I think was the last part of your question,
    aside from the cop out answer, if we buy this "associations all the way down,"
    you should be able to coarse-grain the representations at a certain level such
    that they then make sense.
  id: totrans-split-797
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我认为如果你足够谨慎地去做这件事，你真的可以开始明确到底是哪些电路参与其中，以及备用电路是什么，这些东西。这有点像一个逃避回答的答案，但重要的是要记住进行自动化解释能力。随着我们的模型能力不断增强，我们让它们分配标签或在规模上运行一些这样的实验。关于检测超人类表现，我认为这是你问题的最后部分，除了逃避回答的答案外，如果我们认可“关联自始至终”，你应该能够在某个水平上粗粒化表示，这样它们就会有意义。
- en: I think it was even in Demis's podcast. He's talking about how if a chess player
    makes a superhuman move, they should be able to distill it into reasons why they
    did it. Even if the model is not going to tell you what it is, you should be able
    to decompose that complex behavior into simpler circuits or features to really
    start to make sense of why it did that thing.
  id: totrans-split-798
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为甚至在迪米斯的播客中都提到过。他说的是如果一个棋手做出超人类的走法，他们应该能够将其概括为为什么这样做的原因。即使模型不会告诉你它是什么，你也应该能够将这种复杂的行为分解成更简单的电路或特征，以真正开始理解为什么它做了那件事。
- en: '**Dwarkesh Patel** *02:23:08*'
  id: totrans-split-799
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:23:08*'
- en: There's a separate question of if such representation exists. It seems like
    it must or actually I'm not sure if that's the case. And secondly, whether using
    this [sparse autoencoder](https://transformer-circuits.pub/2023/monosemantic-features)
    setup you could find it. In this case, if you don't have labels that are adequate
    to represent it, you wouldn't find it.
  id: totrans-split-800
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个独立的问题，即这样的表示是否存在。看起来好像必须有，或者实际上我不确定是否是这样。其次，是否使用这种[稀疏自编码器](https://transformer-circuits.pub/2023/monosemantic-features)设置你能找到它。在这种情况下，如果你没有足够的标签来表示它，你就找不到它。
- en: '**Trenton Bricken** *02:23:28*'
  id: totrans-split-801
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:23:28*'
- en: Yes and no. We are actively trying to use dictionary learning now on the sleeper
    agents work, which we talked about earlier. If I just give you a model, can you
    tell me if there's this trigger in it and if it's going to start doing interesting
    behavior? It's an open question whether or not when it learns that behavior, it's
    part of a more general circuit that we can pick up on without actually getting
    activations for and having it display that behavior. Because that would kind of
    be cheating then. Or if it's learning some hacky trick that's a separate circuit
    that you'll only pick up on if you actually have it do that behavior. But even
    in that case, the geometry of features gets really interesting, because fundamentally,
    each feature is in some part of your representation space and they all exist with
    respect to each other.
  id: totrans-split-802
  prefs: []
  type: TYPE_NORMAL
  zh: 是的也不是。我们现在正在试图在先行者工作中使用字典学习，我们之前谈到过。如果我只是给你一个模型，你能告诉我它里面是否有这个触发器，以及它是否会开始进行有趣的行为吗？现在一个开放的问题是，当它学习到这种行为时，它是否是更一般电路的一部分，我们可以在没有实际激活和显示该行为的情况下捕捉到。因为那样会有点作弊。或者它是否学习了一些骚操作的技巧，那是一个单独的电路，只有当你实际让它执行这种行为时，你才会注意到。但即使在这种情况下，特征的几何形状变得非常有趣，因为从根本上讲，每个特征都存在于你的表示空间的某个部分，并且它们都存在于彼此之间。
- en: So in order to have this new behavior, you need to carve out some subset of
    the feature space for the new behavior and then push everything else out of the
    way to make space for it. Hypothetically, you can imagine you have your model
    before you've taught it this bad behavior and you know all the features or have
    some coarse-grained representation of them. You then fine-tune it such that it
    becomes malicious and then you can kind of identify this black hole region of
    feature space where everything else has been shifted away from that and you haven't
    put in an input that causes it to fire. Then you can start searching for what
    is the input that would cause this part of the space to fire. What happens if
    I activate something in this? There are a whole bunch of other ways that you can
    try and attack that problem.
  id: totrans-split-803
  prefs: []
  type: TYPE_NORMAL
  zh: 所以为了有这种新的行为，你需要切出一些特征空间的子集用于这种新行为，然后把其他所有东西都挤出去为它腾出空间。从假设上来说，你可以想象在你教它这种不良行为之前，你有你的模型，并且你知道所有的特征或者有一些粗略的表示。然后你微调它，使它变得恶意，然后你可以找到这个特征空间的黑洞区域，在那里所有其他东西都被移开而你没有输入导致它触发。然后你可以开始搜索是什么输入会导致这部分空间触发。如果我在这里激活了什么会发生什么？还有很多其他方法可以尝试解决这个问题。
- en: '**Dwarkesh Patel** *02:25:00*'
  id: totrans-split-804
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:25:00*'
- en: This is sort of a tangent, but one interesting idea I heard was if that space
    is shared between models then you can imagine trying to find it in an open source
    model to then make… Like [Gemma](https://blog.google/technology/developers/gemma-open-models/),
    Google's newly released open source model. They said in the paper that it's trained
    using the same architecture or something like that.
  id: totrans-split-805
  prefs: []
  type: TYPE_NORMAL
  zh: 这有点离题，但我听到一个有趣的想法，即如果这个空间在模型之间共享，那么你可以想象在开源模型中找到它，然后做出……就像[**Gemma**](https://blog.google/technology/developers/gemma-open-models/)，谷歌最新发布的开源模型。他们在论文中说它是使用相同的架构训练的或类似的东西。
- en: '**Sholto Douglas** *02:25:20*'
  id: totrans-split-806
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *02:25:20*'
- en: I have to be honest, I didn't know because I haven't read the [Gemma paper](https://arxiv.org/abs/2403.08295).
  id: totrans-split-807
  prefs: []
  type: TYPE_NORMAL
  zh: 我必须诚实地说，我不知道，因为我还没有阅读[Gemma论文](https://arxiv.org/abs/2403.08295)。
- en: '**Dwarkesh Patel** *02:25:23*'
  id: totrans-split-808
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:25:23*'
- en: So to the extent that's true, how much of the red teaming you do on Gemma is
    potentially helping you jailbreak into Gemini?
  id: totrans-split-809
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果这是真的，你在**Gemma**上进行的红队操作可能有助于你越狱到Gemini吗？
- en: '**Trenton Bricken** 02:25:35'
  id: totrans-split-810
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** 02:25:35'
- en: This gets into the fun space of how universal are features across models. Our
    “Towards Monosemanticity” paper looked at this a bit. I can't give you summary
    statistics but there’s the [Base64](https://en.wikipedia.org/wiki/Base64) feature,
    for example, which we see across a ton of models. There are actually three of
    them, but they'll fire for and model Base64 encoded text, which is prevalent in
    every URL and there are lots of URLs in the training data. They have really high
    cosine similarity across models. So they all learn this feature and within a rotation.
  id: totrans-split-811
  prefs: []
  type: TYPE_NORMAL
  zh: 这进入了特征在模型间普遍性的有趣领域。我们的“走向单语性”论文稍微涉及了这一点。我不能给你摘要统计数据，但有[Base64](https://en.wikipedia.org/wiki/Base64)特征，例如，我们看到它在大量模型中存在。实际上有三个，但它们会为模型和Base64编码的文本触发，并且训练数据中的每个URL中都有大量URL。它们在模型间具有非常高的余弦相似性。因此，它们都学会了这个特征并在旋转中进行。
- en: '**Sholto Douglas** *02:26:08*'
  id: totrans-split-812
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *02:26:08*'
- en: Like the actual vectors itself.
  id: totrans-split-813
  prefs: []
  type: TYPE_NORMAL
  zh: 就像实际的向量本身。
- en: '**Trenton Bricken** *02:26:09*'
  id: totrans-split-814
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:26:09*'
- en: Yeah. I wasn't part of this analysis but it definitely finds the feature and
    they're pretty similar to each other across two separate models, the same model
    architecture but trained with different random seeds.
  id: totrans-split-815
  prefs: []
  type: TYPE_NORMAL
  zh: 是的。我不是这个分析的一部分，但它确实找到了这个特征，并且它们在两个独立的模型中非常相似，相同的模型架构但用不同的随机种子训练。
- en: '**Sholto Douglas** *02:26:22*'
  id: totrans-split-816
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *02:26:22*'
- en: It supports the [quanta theory of neural scaling](https://arxiv.org/abs/2303.13506).
    It's a hypothesis, right? We just look at all models on a similar data set. We
    will learn the same features in the same order-ish. Roughly, you learn your N
    grams, you learn your induction heads, and you learn to put full stops after numbered
    lines and this kind of stuff.
  id: totrans-split-817
  prefs: []
  type: TYPE_NORMAL
  zh: 它支持[神经缩放量子理论](https://arxiv.org/abs/2303.13506)。这是一个假设，对吧？我们只是看所有在类似数据集上的模型。我们将按相似顺序学习相同的特征。大致上，你学习你的N元组，你学习你的归纳头，你学会在编号行后面加句号，还有这类的东西。
- en: '**Dwarkesh Patel** *02:26:36*'
  id: totrans-split-818
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:26:36*'
- en: So this is another tangent. To the extent that that's true, and I guess there's
    evidence that it is true, why doesn't [curriculum learning](https://arxiv.org/abs/2101.10382)
    work? Because if it is the case that you learn certain things first, shouldn't
    directly training those things first lead to better results?
  id: totrans-split-819
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这是另一个分支。在某种程度上是真的，我想有证据表明这是真的，为什么[课程学习](https://arxiv.org/abs/2101.10382)不起作用？因为如果确实是这样，你先学习某些东西，直接训练这些东西不应该会带来更好的结果吗？
- en: '**Sholto Douglas** *02:26:49*'
  id: totrans-split-820
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *02:26:49*'
- en: Both [Gemini](https://arxiv.org/abs/2312.11805) papers mention some aspect of
    curriculum learning.
  id: totrans-split-821
  prefs: []
  type: TYPE_NORMAL
  zh: '[Gemini](https://arxiv.org/abs/2312.11805)的两篇论文都提到了课程学习的某些方面。'
- en: '**Dwarkesh Patel** *02:26:53*'
  id: totrans-split-822
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:26:53*'
- en: Okay, interesting. I find the fact that fine-tuning works as evidence of curriculum
    learning, right?
  id: totrans-split-823
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，有意思。我觉得微调有效就是课程学习的证据，对吧？
- en: Because the last things you're training on have a disproportionate impact.
  id: totrans-split-824
  prefs: []
  type: TYPE_NORMAL
  zh: 因为你最后训练的东西影响最大。
- en: '**Sholto Douglas** *02:27:02*'
  id: totrans-split-825
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *02:27:02*'
- en: I wouldn't necessarily say that. There’s one mode of thinking in which fine-tuning
    is specialized, you've got this latent bundle of capabilities and you're specializing
    it for this particular use case that you want. I think I'm not sure how true or
    not that is.
  id: totrans-split-826
  prefs: []
  type: TYPE_NORMAL
  zh: 我不一定会这么说。有一种思维方式认为，微调是专门化的，你有这种潜在的能力束，你为你想要的特定用例专门化它。我想我不确定这是否真实。
- en: '**Trenton Bricken** *02:27:15*'
  id: totrans-split-827
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:27:15*'
- en: I think the David Bell lab paper kind of supports this. You have that ability
    and you're just getting better at entity recognition, fine-tuning that circuit
    instead of other ones.
  id: totrans-split-828
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为戴维·贝尔实验室的论文在某种程度上支持这一点。你有这种能力，你只是越来越擅长实体识别，调整那个电路而不是其他的。
- en: '**Dwarkesh Patel** *02:27:23*'
  id: totrans-split-829
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:27:23*'
- en: Sorry, what was the thing we were talking about before?
  id: totrans-split-830
  prefs: []
  type: TYPE_NORMAL
  zh: 对不起，我们之前讨论的是什么来着？
- en: '**Sholto Douglas** *02:27:25*'
  id: totrans-split-831
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sholto Douglas** *02:27:25*'
- en: Generally I do think curriculum learning is a really interesting thing that
    people should explore more. It seems very plausible. I would really love to see
    more analysis along the lines of the quantum theory stuff. When understanding
    better, what do you actually learn at each stage and decomposing that out? Exploring
    whether or not curriculum learning changes that or not.
  id: totrans-split-832
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我确实认为课程学习是一个非常有趣的事情，人们应该更多地探索。这似乎非常可行。我真的很希望看到更多关于量子理论之类的分析。在更好地理解时，你在每个阶段实际学到了什么，并将其分解出来。探索课程学习是否改变了这一点。
- en: '**Dwarkesh Patel** *02:27:43*'
  id: totrans-split-833
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:27:43*'
- en: By the way I just realized, I just got in conversation mode and forgot there's
    an audience. Curriculum learning is when you organize the data set. When you think
    about a human, how they learn, they don't just see a random Wiki text and they
    just try to predict it. They're like,
  id: totrans-split-834
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一下，我突然意识到，我刚进入了交谈模式，忘了有观众在。课程学习就是当你组织数据集时。当你考虑一个人如何学习时，他们不会只是看到一个随机的维基文本，然后试图预测它。他们会像这样，
- en: “we'll start you off with *Lorax* or something and then you'll learn.” I don't
    even remember what first-grade was like but you learned the things that first-graders
    learn and then second-graders and so forth. So you would imagine,
  id: totrans-split-835
  prefs: []
  type: TYPE_NORMAL
  zh: “我们将从《罗拉克斯》之类的东西开始，然后你会学到。”我甚至不记得一年级是什么样子，但你学到了一年级学生学到的东西，然后二年级的，依此类推。所以你可以想象，
- en: '**Sholto Douglas** *02:28:10*'
  id: totrans-split-836
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:28:10*'
- en: We know you never got past first-grade.
  id: totrans-split-837
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道你连一年级都没读完。
- en: '**Dwarkesh Patel** *02:28:25*'
  id: totrans-split-838
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:28:25*'
- en: Anyways, let's get back to the big picture before we get into a bunch of interpretability
    details. There's two threads I want to explore. First is, it makes me a little
    worried that there's not even an alternative formulation of what could be happening
    in these models that could invalidate this approach. I mean we do know that we
    don't understand intelligence. There are definitely unknown unknowns here. So
    the fact that there's not a null hypothesis… What if we’re just wrong and we don't
    even know the way in which we're wrong, which actually increases the uncertainty.
  id: totrans-split-839
  prefs: []
  type: TYPE_NORMAL
  zh: 无论如何，让我们回到大局观之前，不要陷入一堆可解释性细节中。我想探索两个线索。首先是，让我有点担心的是，甚至没有一个可能发生在这些模型中的替代公式。我的意思是，我们确实知道我们不理解智能。这里肯定有未知的未知。所以事实上，没有一个空假设…
    如果我们错了，而且我们甚至不知道我们错在哪里，这实际上增加了不确定性。
- en: '**Trenton Bricken** *02:29:05*'
  id: totrans-split-840
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:29:05*'
- en: So it's not that there aren't other hypotheses, it's just that I have been working
    on superposition for a number of years and am very involved in this effort. So
    I'm less sympathetic to these other approaches, especially because our recent
    work has been so successful.
  id: totrans-split-841
  prefs: []
  type: TYPE_NORMAL
  zh: 所以并不是没有其他假设，只是我已经在超定位上工作了好几年，对这一努力非常投入。因此，我对这些其他方法的同情程度较低，特别是因为我们最近的工作非常成功。
- en: '**Sholto Douglas** *02:29:26*'
  id: totrans-split-842
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:29:26*'
- en: And quite high explanatory power. There's this beauty, like in the original
    scaling laws paper, there's this little bump that apparently corresponds to when
    the model learns induction heads.
  id: totrans-split-843
  prefs: []
  type: TYPE_NORMAL
  zh: 而且解释力量很高。就像原始的缩放定律论文中一样，有这样一个美丽的小隆起，显然对应于模型学习归纳头部的时候。
- en: And then after that, it sort of goes off track, learns induction heads, gets
    back on track. It’s an incredible piece of retroactive explanatory power.
  id: totrans-split-844
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在那之后，它有点偏离轨道，学会了归纳头部，重新回到轨道。这是一种令人难以置信的反事后解释力量。
- en: '**Trenton Bricken** *02:29:50*'
  id: totrans-split-845
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:29:50*'
- en: Before I forget it, I do have one thread on feature universality that you might
    want to have in. So there, there's some really interesting behavioral and evolutionary
    biology experiments on whether humans should learn a real representation of the
    world or not? You can imagine a world in which we saw all venomous animals as
    flashing neon pink, a world in which we survive better. So it would make sense
    for us to not have a realistic representation of the world.
  id: totrans-split-846
  prefs: []
  type: TYPE_NORMAL
  zh: 在我忘记之前，我确实有一个关于特征普遍性的线索，你可能想要了解。因此，在这里，有一些关于人类是否应该学习世界的真实表现的非常有趣的行为和进化生物学实验？你可以想象一个世界，在这个世界上，我们把所有有毒动物都看作是闪烁的霓虹粉色，这样我们能更好地生存。因此，对我们来说没有一个现实的世界表现是有道理的。
- en: There's some work where they'll simulate little basic agents and see if the
    representations they learn map to the tools they can use and the inputs they should
    have. It turns out if you have these little agents perform more than a certain
    number of tasks, given these basic tools and objects in the world, then they will
    learn a ground truth representation. Because there are so many possible use cases
    that you need, that you want to learn what the object actually is and not some
    cheap visual heuristic or other thing.
  id: totrans-split-847
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些研究，他们会模拟一些基本的小代理，并查看他们学习的表示是否映射到他们可以使用的工具和他们应该有的输入。结果发现，如果这些小代理执行超过一定数量的任务，鉴于这些基本的工具和世界上的物体，那么他们将学习到一个地面真实的表示。因为有这么多可能的用例，你需要，你希望学习的是对象的实际情况，而不是一些廉价的视觉启发或其他东西。
- en: We haven't talked at all about [free energy principle](https://en.wikipedia.org/wiki/Free_energy_principle#:~:text=The%20free%20energy%20principle%20is%20based%20on%20the%20Bayesian%20idea,their%20sense%20and%20associated%20perception.)
    or [predictive coding](https://en.wikipedia.org/wiki/Predictive_coding) or anything
    else. But to the extent that all living organisms are trying to actively predict
    what comes next and form a really accurate world model, I'm optimistic that we
    are learning genuine features about the world that are good for modeling it and
    our language models will do the same, especially because we're training them on
    human data and human texts.
  id: totrans-split-848
  prefs: []
  type: TYPE_NORMAL
  zh: 我们根本没讨论过[自由能量原理](https://en.wikipedia.org/wiki/Free_energy_principle#:~:text=The%20free%20energy%20principle%20is%20based%20on%20the%20Bayesian%20idea,their%20sense%20and%20associated%20perception.)或[预测编码](https://en.wikipedia.org/wiki/Predictive_coding)或其他任何东西。但是，所有生物都试图积极预测接下来会发生什么，并形成一个非常准确的世界模型，我对我们正在学习有关模型世界的真正特征并对其进行建模感到乐观，尤其是因为我们正在用人类数据和人类文本训练它们的语言模型。
- en: '**Dwarkesh Patel**  *02:31:23*'
  id: totrans-split-849
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:31:23*'
- en: Another dinner party question. Should we be less worried about misalignment?
    Maybe that's not even the right term for what I'm referring to, but alienness
    and [Shoggoth-ness](https://www.lesswrong.com/posts/yjzW7gxk2h7bBs2qr/the-meaning-of-shoggoth-ai-memes)?
    Given feature universality there are certain ways of thinking and ways of understanding
    the world that are instrumentally useful to different kinds of intelligences.
    So should we just be less worried about bizarro [paperclip maximizers](https://en.wikipedia.org/wiki/Instrumental_convergence#Paperclip_maximizer)
    as a result?
  id: totrans-split-850
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个晚宴问题。我们应该少担心不对齐吗？也许这不是我所指的正确术语，但是异性和[雪谷怪物特性](https://www.lesswrong.com/posts/yjzW7gxk2h7bBs2qr/the-meaning-of-shoggoth-ai-memes)？鉴于特征的普遍性，有某些思维方式和理解世界的方式对不同类型的智能特别有用。那么，我们是否应该因此对怪异的[纸夹器极大化者](https://en.wikipedia.org/wiki/Instrumental_convergence#Paperclip_maximizer)少担心？
- en: '**Trenton Bricken** *02:31:52*'
  id: totrans-split-851
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:31:52*'
- en: I think this is kind of why I bring this up as the optimistic take. Predicting
    the internet is very different from what we're doing though. The models are way
    better at predicting next tokens than we are. They're trained on so much garbage.
    They're trained on so many URLs. Like in the dictionary learning work, we find
    there are three separate features for Base64 encodings.
  id: totrans-split-852
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这就是我提出这个乐观看法的原因。预测互联网与我们正在做的事情非常不同。这些模型在预测下一个标记方面要比我们好得多。它们训练在大量垃圾数据上。在字典学习工作中，我们发现Base64编码有三个独立的特征。
- en: Even that is kind of an alien example that is probably worth talking about for
    a minute. One of these Base64 features fired for numbers and predicted more of
    those. Another fired for letters. But then there was this third one that we didn't
    understand. And it fired for a very specific subset of Base64 features. Someone
    on the team who clearly knows way too much about Base64 realized that this was
    the subset that was ASCII decodable. So you could decode it back into the ASCII
    characters. The fact that the model learned these three different features and
    it took us a little while to figure out what was going on is very Shoggoth-esque.
  id: totrans-split-853
  prefs: []
  type: TYPE_NORMAL
  zh: 即使这个例子有点异类，可能值得讨论一分钟。其中一个Base64特征针对数字触发并预测更多的数字。另一个针对字母触发。但是然后有这第三个，我们不理解的。它针对Base64特征的一个非常具体的子集触发。团队中一个明显对Base64了解过多的人意识到，这是ASCII可解码的子集。因此，你可以将其解码回ASCII字符。这个模型学习了这三种不同的特征，我们花了一些时间才弄清楚发生了什么，这非常像雪谷怪物。
- en: '**Dwarkesh Patel** *02:32:58*'
  id: totrans-split-854
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:32:58*'
- en: That it has a denser representation of regions that are particularly relevant
    to predicting the next token.
  id: totrans-split-855
  prefs: []
  type: TYPE_NORMAL
  zh: 它具有更密集的区域表示，这些区域对预测下一个标记特别重要。
- en: '**Trenton Bricken** *02:33:03*'
  id: totrans-split-856
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:33:03*'
- en: Yeah, it's clearly doing something that humans don't do. You can even talk to
    any of the current models in Base64 and it will reply in Base64 and you can then
    decode it and it works great.
  id: totrans-split-857
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，显然它正在做人类不做的事情。你甚至可以用Base64与任何当前模型交流，它会用Base64回复，你可以解码，它效果很好。
- en: '**Dwarkesh Patel** *02:33:16*'
  id: totrans-split-858
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:33:16*'
- en: I wonder if that particular example implies that the difficulty of interpretability
    with smarter models will be harder because it requires somebody with esoteric
    knowledge, like the person who just happened to see that Base64 has whatever that
    distinction was. Doesn't that imply that when you have the million line pull request,
    there is no human that's going to be able to decode two different features?
  id: totrans-split-859
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *02:33:46*'
  id: totrans-split-860
  prefs: []
  type: TYPE_NORMAL
- en: And that's when you type a comment like, “small CLs please.”
  id: totrans-split-861
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:33:50*'
  id: totrans-split-862
  prefs: []
  type: TYPE_NORMAL
- en: Exactly. No, I mean you could do that, right? One technique here is anomaly
    detection. One beauty of dictionary learning instead of linear probes is that
    it's unsupervised. You are just trying to learn to span all of the representations
    that the model has and then interpret them later. But if there's a weird feature
    that suddenly fires for the first time that you haven't seen before, that's a
    red flag. You could also coarse-grain it so that it's just a single Base64 feature.
    Even the fact that this came up and we could see that it specifically fires fpr
    these particular outputs gets you a lot of the way there.
  id: totrans-split-863
  prefs: []
  type: TYPE_NORMAL
- en: I'm even familiar with cases from the auto-interpretability side. A human will
    look at a feature and try to annotate it as firing for Latin words. And then when
    you ask the model to classify it, it says it fires for Latin words that define
    plants. So it can already beat the human in some cases for labeling what's going
    on.
  id: totrans-split-864
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:34:48*'
  id: totrans-split-865
  prefs: []
  type: TYPE_NORMAL
- en: At scale, this would require an adversarial thing between models where you have
    some model with millions of features, potentially for GPT-6, and just a bunch
    of models trying to figure out what each of these features means. Does that sound
    right?
  id: totrans-split-866
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:35:07*'
  id: totrans-split-867
  prefs: []
  type: TYPE_NORMAL
- en: Yeah, but you can even automate this process. This goes back to the determinism
    of the model. You could have a model that is actively editing input text and predicting
    if the feature is going to fire or not, and figure out what makes it fire, what
    doesn't, and search the space.
  id: totrans-split-868
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:35:24*'
  id: totrans-split-869
  prefs: []
  type: TYPE_NORMAL
- en: I want to talk more about the feature splitting because I think that's an interesting
    thing that has been underexplored.
  id: totrans-split-870
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:35:29*'
  id: totrans-split-871
  prefs: []
  type: TYPE_NORMAL
- en: Especially for scalability, I think it's underappreciated right now.
  id: totrans-split-872
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:35:33*'
  id: totrans-split-873
  prefs: []
  type: TYPE_NORMAL
- en: First of all, how do we even think about it? Is it really just that you can
    keep going down and down and there's no end to the amount of features?
  id: totrans-split-874
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:35:41*'
  id: totrans-split-875
  prefs: []
  type: TYPE_NORMAL
- en: So at some point I think you might just start fitting noise, or things that
    are part of the data but that the model isn't actually–
  id: totrans-split-876
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:35:50*'
  id: totrans-split-877
  prefs: []
  type: TYPE_NORMAL
- en: Do you want to explain what feature splitting is?
  id: totrans-split-878
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:35:51*'
  id: totrans-split-879
  prefs: []
  type: TYPE_NORMAL
- en: It's the part before, where the model will learn however many features it has
    capacity for that still span the space of representation.
  id: totrans-split-880
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:36:02*'
  id: totrans-split-881
  prefs: []
  type: TYPE_NORMAL
- en: So give an example, potentially.
  id: totrans-split-882
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:36:03*'
  id: totrans-split-883
  prefs: []
  type: TYPE_NORMAL
- en: So you learn that if you don't give the model that much capacity for the features
    its learning, concretely if you project to not as high a dimensional space, it'll
    learn one feature for birds. But if you give the model more capacity, it will
    learn features for all the different types of birds. So it's more specific than
    otherwise. Oftentimes, there's the bird vector that points in one direction and
    all the other specific types of birds point in a similar region of the space but
    are obviously more specific than the coarse label.
  id: totrans-split-884
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你学到了，如果你不给模型足够的特征学习能力，具体来说，如果你投影到一个不那么高维空间，它会学习到鸟类的一个特征。但是如果你给模型更多的能力，它将学习到所有不同类型的鸟类特征。因此，它比其他情况更具体。通常情况下，有一个指向一个方向的鸟类向量，而所有其他特定类型的鸟类则位于空间的类似区域，但显然比粗略标签更具体。
- en: '**Dwarkesh Patel** *02:36:36*'
  id: totrans-split-885
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:36:36*'
- en: Okay, so let's go back to GPT-7\. First of all, is this sort of like a linear
    tax on any model to figure it out? Even before that, is this a one time thing
    you had to do or is this the kind of thing you have to do on every output? Or
    just one time it's not deceptive and we're good to roll?
  id: totrans-split-886
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们回到GPT-7。首先，这是否像对任何模型征收的线性税？甚至在此之前，这是您必须做的一次性事情，还是您必须在每次输出时都要做的事情？或者只需要一次就不会误导我们好好做下去？
- en: '**Trenton Bricken** *02:36:55*'
  id: totrans-split-887
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:36:55*'
- en: So you do dictionary learning after you've trained your model and you feed it
    a ton of inputs and you get the activations from those. Then you do this projection
    into the higher dimensional space. So the method is unsupervised in that it's
    trying to learn these sparse features. You're not telling them in advance what
    they should be but, it is constrained by the inputs you're giving the model.
  id: totrans-split-888
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你在训练完模型后进行字典学习，然后向模型输入大量的输入，并从中得到激活。然后你将这些投影到更高维空间中。所以这种方法是无监督的，因为它试图学习这些稀疏特征。你没有事先告诉它们应该是什么，但它受到你给模型的输入的约束。
- en: Two caveats here. One, we can try and choose what inputs we want. So if we're
    looking for theory of mind features that might lead to deception, we can put in
    the sycophancy data set.
  id: totrans-split-889
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两个注意事项。首先，我们可以尝试选择我们想要的输入。因此，如果我们正在寻找会导致欺骗的心理理论特征，我们可以输入奉承数据集。
- en: Hopefully at some point we can move into looking at the weights of the model
    alone, or at least using that information to do dictionary learning. I think in
    order to get there, that's such a hard problem that you need to make traction
    on just learning what the features are first. So what's the cost of this?
  id: totrans-split-890
  prefs: []
  type: TYPE_NORMAL
  zh: 希望在某个时候我们能够转向仅仅查看模型权重本身，或者至少利用该信息进行字典学习。我认为为了达到这个目标，这是一个非常困难的问题，你需要首先学习这些特征是什么。那么这个成本是多少？
- en: '**Dwarkesh Patel** *02:37:46*'
  id: totrans-split-891
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:37:46*'
- en: Can you repeat the last sentence? About the weights of the model alone.
  id: totrans-split-892
  prefs: []
  type: TYPE_NORMAL
  zh: 你能重复一下最后一句吗？关于模型权重本身。
- en: '**Trenton Bricken** *02:37:50*'
  id: totrans-split-893
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:37:50*'
- en: Right now we just have these neurons in the model. They don't make any sense.
    We apply dictionary learning. We get these features out. They start to make sense
    but that depends on the activations of the neurons. The weights of the model itself,
    like what neurons are connected to other neurons, certainly has information in
    it.The dream is that we can kind of bootstrap towards actually making sense of
    the weights of the model that are independent of the activations of the data.
    I'm not saying we've made any progress here, it's a very hard problem. But it
    feels like we'll have a lot more traction and be able to sanity check what we're
    finding with the weights if we're able to pull out features first.
  id: totrans-split-894
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们只是有这些模型中的神经元。它们毫无意义。我们应用字典学习。我们得到这些特征。它们开始有意义，但这取决于神经元的激活。模型本身的权重，例如哪些神经元连接到其他神经元，肯定包含信息。梦想是我们能够朝着实际理解模型的权重而不依赖于数据激活的方向进行引导。我不是说我们在这方面取得了任何进展，这是一个非常困难的问题。但是感觉上，如果我们能够首先提取特征，我们将能够更好地理解权重，并能够通过它来进行合理性检查。
- en: '**Dwarkesh Patel** *02:38:28*'
  id: totrans-split-895
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:38:28*'
- en: For the audience, weights are permanent. I don't know if permanent is the right
    word, but they are the model itself whereas activations are the artifacts of any
    single call.
  id: totrans-split-896
  prefs: []
  type: TYPE_NORMAL
  zh: 对于观众来说，权重是永久的。我不知道“永久”是否是正确的词，但它们是模型本身，而激活是任何单次调用的产物。
- en: '**Sholto Douglas** *02:38:39*'
  id: totrans-split-897
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:38:39*'
- en: In a brain metaphor, the weights are like the actual connection scheme between
    neurons and the activations of the current neurons that are lining up.
  id: totrans-split-898
  prefs: []
  type: TYPE_NORMAL
  zh: 在大脑的比喻中，权重就像神经元之间的实际连接方案，而当前神经元的激活则是排列起来的。
- en: '**Dwarkesh Patel** *02:38:48*'
  id: totrans-split-899
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:38:48*'
- en: Okay. So there's going to be two steps to this for GPT-7 or whatever model we're
    concerned about. Actually, correct me if I'm wrong, but first training the sparse
    autoencoder and doing the unsupervised projection into a wider space of features
    that have a higher fidelity to what is actually happening in the model. And then
    secondly, labeling those features. Let's say the cost of training the model is
    N. What will those two steps cost relative to N?
  id: totrans-split-900
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。对于 GPT-7 或者我们关心的任何模型来说，这将有两个步骤。实际上，纠正我如果我错了，首先训练稀疏自编码器，并将其无监督投影到特征空间的更广泛空间，这些特征具有与模型实际发生情况更高的保真度。然后其次，标记这些特征。假设训练模型的成本是
    N。相对于 N，这两个步骤将会产生什么成本？
- en: '**Trenton Bricken** *02:39:20*'
  id: totrans-split-901
  prefs: []
  type: TYPE_NORMAL
  zh: '**Trenton Bricken** *02:39:20*'
- en: We will see. It really depends on two main things. What are your expansion factors?
    How much are you projecting into the higher-dimensional space and how much data
    do you need to put into the model? How many activations do you need to give it?
    This brings me back to the feature splitting because if you know you're looking
    for specific features then you can start with a cheaper, coarse representation.
  id: totrans-split-902
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到。这实际上取决于两个主要因素。你的扩展因子是什么？你在多大程度上投影到更高维度的空间，并且需要向模型提供多少数据？你需要给它多少激活？这让我想起了特征分裂，因为如果你知道你正在寻找特定的特征，那么你可以从一个更便宜、更粗糙的表示开始。
- en: So maybe my expansion factor is only two. So I have a thousand neurons and I'm
    projecting to a 2000 dimensional space. I get 2000 features out, but they're really
    coarse. Previously I had the example for birds. Let's move that example to a biology
    feature but I really care if the model has representations for bioweapons and
    trying to manufacture them. So what I actually want is like an anthrax feature.
    Let's say you only see the anthrax feature if, instead of going from a thousand
    dimensions to two thousand dimensions, I go to a million dimensions.
  id: totrans-split-903
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，也许我的扩展因子只有两个。所以我有一千个神经元，投影到一个二千维的空间。我得到二千个特征，但它们非常粗略。之前我有鸟类的例子。让我们把这个例子移到生物学特征上，但我真的在乎的是模型是否具有生物武器的表示和尝试制造它们。所以我实际上想要的是像炭疽这样的特征。假设你只有在我从一千维到二千维的空间变为一百万维时才看到炭疽特征。
- en: You can imagine this, this big tree of semantic concepts where biology splits
    into cells versus whole body biology and then further down it splits into all
    these other things. Rather than needing to immediately go from a thousand to a
    million and picking out that one feature of interest, you can find the direction
    that the biology feature is pointing in, which again is very coarse, and then
    selectively search around that space. So only do dictionary learning, if something
    in the direction of the biology feature fires first. The computer science metaphor
    here would be like, instead of doing [breadth-first search](https://en.wikipedia.org/wiki/Breadth-first_search),
    you're able to do [depth-first search](https://en.wikipedia.org/wiki/Depth-first_search)
    where you're only recursively expanding and exploring a particular part of this
    semantic tree of features.
  id: totrans-split-904
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以想象这样一个语义概念的大树，生物学分为细胞与整体生物学，然后进一步分为所有这些其他内容。与其需要立即从千分之一到百万分之一并挑选出感兴趣的特征，你可以找到生物学特征指向的方向，这是非常粗略的，然后在这个空间周围进行选择性搜索。所以，只有在生物学特征方向上有点火时才进行字典学习。这里的计算机科学比喻就像是，而不是进行
    [广度优先搜索](https://zh.wikipedia.org/wiki/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)，你可以进行
    [深度优先搜索](https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)，在这个语义特征树的特定部分进行递归扩展和探索。
- en: '**Dwarkesh Patel** *02:41:05*'
  id: totrans-split-905
  prefs: []
  type: TYPE_NORMAL
  zh: '**Dwarkesh Patel** *02:41:05*'
- en: These features are not organized in ways that are intuitive for humans, right?
    Because we just don't have to deal with Base64, we just don't dedicate that much
    firmware to deconstructing which kind of Base64 it is. How would we know that
    the subjects… This will go back to the [MOE](https://en.wikipedia.org/wiki/Mixture_of_experts)
    discussion we'll have. I guess we might as well talk about it. “[Mixtral of Experts](https://arxiv.org/abs/2401.04088)”,
    the Mistral paper, talked about how the experts weren't specialized in a way that
    we could understand. There's not like a chemistry expert or a physics expert or
    something. So why would you think that it will be a biology feature and then you
    deconstruct, rather than “blah” and then you deconstruct. It's like “anthrax”
    and you're like “shoes” or whatever.
  id: totrans-split-906
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:41:53*'
  id: totrans-split-907
  prefs: []
  type: TYPE_NORMAL
- en: So I haven't read the Mistral paper, but if you just look at the neurons in
    a model, they're polysemantic. So if all they did was just look at the neurons
    in a given head, it's very plausible that it's also polysemantic because of superposition.
  id: totrans-split-908
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *02:42:10*'
  id: totrans-split-909
  prefs: []
  type: TYPE_NORMAL
- en: Talking on the thread that Dwarkesh mentioned there, have you seen in the subtrees
    when you expand them out, something in a subtree which you really wouldn't guess
    should be there based on the high level abstraction?
  id: totrans-split-910
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:42:20*'
  id: totrans-split-911
  prefs: []
  type: TYPE_NORMAL
- en: This is a line of work that we haven't pursued as much as I want to yet but
    I think we're planning to, I hope that external groups do as well. What is the
    geometry of feature space? What's the geometry and how does that change over time?
  id: totrans-split-912
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *02:42:32*'
  id: totrans-split-913
  prefs: []
  type: TYPE_NORMAL
- en: It would really suck if the anthrax feature happened to be below the coffee
    can substrate or something like that, right? That feels like the kind of thing
    that you could quickly try and find proof of, which would then mean that you need
    to then solve that problem and inject more structure into the geometry.
  id: totrans-split-914
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:42:51*'
  id: totrans-split-915
  prefs: []
  type: TYPE_NORMAL
- en: Totally. It would really surprise me, especially given how linear the model
    seems to be, if there isn't some component of the anthrax feature, vector, that
    is similar to the biology vector and that they're not in a similar part of the
    space. But yes. Ultimately machine learning is empirical. We need to do this.
    I think it's going to be pretty important for certain aspects of scaling dictionary
    learning.
  id: totrans-split-916
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *02:43:14*'
  id: totrans-split-917
  prefs: []
  type: TYPE_NORMAL
- en: Interesting. On the MOE discussion, there's an interesting [scaling vision transformers
    paper](https://blog.research.google/2022/01/scaling-vision-with-sparse-mixture-of.html)
    that Google put out a little while ago. They do ImageNet classification with an
    MOE and they find really clear class specialization there for experts. There's
    a clear dog expert.
  id: totrans-split-918
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:43:31*'
  id: totrans-split-919
  prefs: []
  type: TYPE_NORMAL
- en: Wait, so did the Mistral people just not do a good job of identifying those?
  id: totrans-split-920
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *02:43:35*'
  id: totrans-split-921
  prefs: []
  type: TYPE_NORMAL
- en: It's hard. It's entirely possible that in some respects, there's almost no reason
    that all of the different archive features should go to one expert. I don't know
    what buckets they had in their paper, but let's say they had arXiv papers as one
    of the things. You could imagine biology papers going here, math papers going
    here, and all of a sudden your breakdown is ruined.
  id: totrans-split-922
  prefs: []
  type: TYPE_NORMAL
  zh: 这很难。在某些方面完全有可能，所有不同的归档特征都应该归于一个专家，几乎没有理由。我不知道他们的论文中有什么分桶，但假设他们将 arXiv 论文作为其中之一。你可以想象生物学论文放在这里，数学论文放在这里，突然间你的分解就毁了。
- en: But that vision transformer one, where the class separation is really clear
    and obvious, gives I think some evidence towards the specialization hypothesis.
  id: totrans-split-923
  prefs: []
  type: TYPE_NORMAL
  zh: 但是那个视觉变换器，其中类别分离非常明显和明显，我认为这给了一些证据支持专业化假设。
- en: '**Trenton Bricken** *02:44:08*'
  id: totrans-split-924
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:44:08*'
- en: I think images are also in some ways just easier to interpret than text. There’s
    Chris Olah’s [interpretability work](https://colah.github.io/notes/interp-v-neuro/)
    on [AlexNet](https://en.wikipedia.org/wiki/AlexNet#:~:text=AlexNet%20is%20the%20name%20of,at%20the%20University%20of%20Toronto.)
    and these other models. In the [original AlexNet paper](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf),
    they actually split the model into two GPUs just because GPUs were so bad back
    then relatively speaking, they were still great at the time. That was one of the
    big innovations of the paper. They find branch specialization. And there's a [Distill
    Pub article](https://distill.pub/2020/circuits/branch-specialization/) on this
    where colors go to one GPU and [Gabor filters](https://en.wikipedia.org/wiki/Gabor_filter)
    and [line detectors](https://en.wikipedia.org/wiki/Line_detection) go to the other.
    Like the [floppy ear detector](https://distill.pub/2020/circuits/zoom-in/), that
    was just a neuron in the model that you could make sense of. You didn't need to
    disentangle superposition. So just different data set, different modality.
  id: totrans-split-925
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为图像在某些方面也比文本更容易解释。有 Chris Olah 的 [可解释性工作](https://colah.github.io/notes/interp-v-neuro/)
    对 [AlexNet](https://en.wikipedia.org/wiki/AlexNet#:~:text=AlexNet%20is%20the%20name%20of,at%20the%20University%20of%20Toronto.)
    和这些其他模型。在 [原始的 AlexNet 论文](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
    中，他们实际上将模型分成了两个 GPU，只是因为当时 GPU 相对较差，但在那个时候它们仍然很棒。那是论文的一个重大创新之一。他们发现了分支专业化。还有一篇
    [Distill Pub 的文章](https://distill.pub/2020/circuits/branch-specialization/) 讨论了这一点，其中颜色去到一个
    GPU，而 [Gabor 滤波器](https://en.wikipedia.org/wiki/Gabor_filter) 和 [线检测器](https://en.wikipedia.org/wiki/Line_detection)
    去到另一个。就像 [松耳侦测器](https://distill.pub/2020/circuits/zoom-in/)，那只是模型中的一个神经元，你可以理解它。你不需要解开叠加。所以只是不同的数据集，不同的模态。
- en: '**Sholto Douglas** *02:45:05*'
  id: totrans-split-926
  prefs: []
  type: TYPE_NORMAL
  zh: '**肖尔托·道格拉斯** *02:45:05*'
- en: I think a wonderful research project to do, if someone is out there listening
    to this, would be to try and take some of the techniques that Trenton's team has
    worked on and try and disentangle the neurons in the Mistral paper, [Mixtral model](https://mistral.ai/news/mixtral-of-experts/),
    which is open source. I think that's a fantastic thing to do.
  id: totrans-split-927
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为一个很棒的研究项目，如果有人在听这个的话，就是尝试借鉴特伦顿团队工作的一些技术，并尝试解开 Mistral 论文中的神经元，[Mixtral 模型](https://mistral.ai/news/mixtral-of-experts/)，这是开源的。我认为这是一个非常棒的事情去做。
- en: It feels intuitively like there should be. They didn't demonstrate any evidence
    that there is. In general, there’s also a lot of evidence that there should be
    specialization. Go and see if you can find it. Anthropic has published most of
    their stuff on, as I understand it, dense models. Basically, that is a wonderful
    research project to try.
  id: totrans-split-928
  prefs: []
  type: TYPE_NORMAL
  zh: 它在直觉上感觉应该有。他们没有展示任何证据表明有这样的情况。总的来说，也有很多证据表明应该有专业化。去看看能否找到它。Anthropic 发表了他们大部分的东西，据我了解，是关于密集模型的。基本上，这是一个很棒的研究项目去尝试。
- en: '**Trenton Bricken** *02:45:40*'
  id: totrans-split-929
  prefs: []
  type: TYPE_NORMAL
  zh: '**特伦顿·布里肯** *02:45:40*'
- en: Given Dwarkesh's success with the [Vesuvius Challenge](https://scrollprize.org/),
    we should be pitching more projects because they will be solved if we talk about
    them on the podcast.
  id: totrans-split-930
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于 Dwarkesh 在 [维苏威斯挑战赛](https://scrollprize.org/) 上的成功，我们应该多提一些项目，因为如果我们在播客上谈论它们，它们将会被解决。
- en: '**Dwarkesh Patel** *02:45:47*'
  id: totrans-split-931
  prefs: []
  type: TYPE_NORMAL
  zh: '**德瓦克什·帕特尔** *02:45:47*'
- en: After the Vesuvius Challenge I was like, “wait why did I not even try.” Nat
    had told me about it before it dropped, because we recorded the episode before
    it dropped. [Luke](https://lukefarritor.com/about/) is obviously very smart and
    he's an amazing kid. He showed that a 21-year-old on some 1070 could do this.
    I was honestly thinking about that kind of experience like, “why didn't I do this.
    Fuck.”
  id: totrans-split-932
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:46:25*'
  id: totrans-split-933
  prefs: []
  type: TYPE_NORMAL
- en: Yeah, get your hands dirty.
  id: totrans-split-934
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *02:46:27*'
  id: totrans-split-935
  prefs: []
  type: TYPE_NORMAL
- en: Dwarkesh's request for research.
  id: totrans-split-936
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:46:33*'
  id: totrans-split-937
  prefs: []
  type: TYPE_NORMAL
- en: Oh I want to harp back on the neuron thing you said. I think a bunch of your
    papers have said that there's more features than there are neurons. A neuron is
    like, weights go in and a number comes out. That's so little information. There's
    street names and species and whatever. There's more of those kinds of things than
    there are “number comes out” in a model. But “number comes out” is so little information.
    How is that encoding for–
  id: totrans-split-938
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:47:10*'
  id: totrans-split-939
  prefs: []
  type: TYPE_NORMAL
- en: Superposition. You're just encoding a ton of features in these high-dimensional
    vectors.
  id: totrans-split-940
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:47:17*'
  id: totrans-split-941
  prefs: []
  type: TYPE_NORMAL
- en: In a brain, is there an axonal firing or however you think about it? I don't
    know how you think about how much superposition is there in the human brain?
  id: totrans-split-942
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:47:26*'
  id: totrans-split-943
  prefs: []
  type: TYPE_NORMAL
- en: So Bruno Olshausen, who I think of as the leading expert on this, thinks that
    all the brain regions you don't hear about are doing a ton of computation in superposition.
    So everyone talks about V1 as having Gabor filters and detecting lines of various
    sorts and no one talks about V2\. I think it's because we just haven't been able
    to make sense of it.
  id: totrans-split-944
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:47:48*'
  id: totrans-split-945
  prefs: []
  type: TYPE_NORMAL
- en: What is V2?
  id: totrans-split-946
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:47:49*'
  id: totrans-split-947
  prefs: []
  type: TYPE_NORMAL
- en: It's the next part of the visual processing stream. So I think it's very likely
    that, fundamentally, superposition seems to emerge when you have high-dimensional
    data that is sparse. To the extent that you think the real world is that, which
    I would argue it is, we should expect the brain to also be underparameterized
    in trying to build a model of the world and also use superposition.
  id: totrans-split-948
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *02:48:11*'
  id: totrans-split-949
  prefs: []
  type: TYPE_NORMAL
- en: You can get a good intuition for this. Correct me if this example is wrong but
    consider a 2D plane, right? Let's say you have two axes which represent a two-dimensional
    feature space, two neurons basically. You can imagine them each turning on to
    various degrees. That's your X coordinate and your Y coordinate, but you can now
    map this onto a plane. You can actually represent a lot of different things in
    different parts of the plane.
  id: totrans-split-950
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:48:37*'
  id: totrans-split-951
  prefs: []
  type: TYPE_NORMAL
- en: Oh, okay. So crucially then, superposition is not an artifact of a neuron. It
    is an artifact of the space that is created.
  id: totrans-split-952
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:48:44*'
  id: totrans-split-953
  prefs: []
  type: TYPE_NORMAL
- en: It's a combinatorial code,
  id: totrans-split-954
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:48:45*'
  id: totrans-split-955
  prefs: []
  type: TYPE_NORMAL
- en: Okay, cool. We kind of talked about this but I think it’s kind of wild that
    this seems to be, to the best of our knowledge, the way intelligence works in
    these models and presumably also in brains. There's a stream of information going
    through that has "features" that are infinitely, or at least to a large extent,
    splittable and you can expand out a tree of what this feature is. And what's really
    happening is a stream, that feature is getting turned into this other feature
    or this other feature is added.
  id: totrans-split-956
  prefs: []
  type: TYPE_NORMAL
- en: I don't know. It's not something I would have thought of intelligence as. It's
    a surprising thing. It's not what I would have expected necessarily.
  id: totrans-split-957
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:49:35*'
  id: totrans-split-958
  prefs: []
  type: TYPE_NORMAL
- en: What did you think it was?
  id: totrans-split-959
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** 02:49:36'
  id: totrans-split-960
  prefs: []
  type: TYPE_NORMAL
- en: I don't know, man. I mean–
  id: totrans-split-961
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *02:49:39*'
  id: totrans-split-962
  prefs: []
  type: TYPE_NORMAL
- en: GOFAI. GOFAI. He's a GOFAI-er.
  id: totrans-split-963
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:49:40*'
  id: totrans-split-964
  prefs: []
  type: TYPE_NORMAL
- en: Well, actually, that's a great segue because all of this feels like GOFAI. You're
    using distributed representations, but you have features and you're applying these
    operations to the features. There’s this whole field of [vector symbolic architectures](https://www.hd-computing.com/),
    which is this computational neuroscience thing. All you do is put vectors in superposition,
    which is literally a summation of two high-dimensional vectors, and you create
    some interference. But if it's high-dimensional enough, then you can represent
    them and you have variable bindings where you connect one by another. If you're
    dealing with binary vectors, it's just the [XOR](https://en.wikipedia.org/wiki/Exclusive_or)
    operation. So you have A, B, you bind them together. Then if you query with A
    or B again, you get out the other one. This is basically like key value pairs
    from attention. With these two operations, you have a [Turing complete system](https://en.wikipedia.org/wiki/Turing_completeness),
    with which you can, if you have enough nested hierarchy, represent any data structure
    you want. Et cetera, et cetera.
  id: totrans-split-965
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:50:39*'
  id: totrans-split-966
  prefs: []
  type: TYPE_NORMAL
- en: Let's go back to superintelligence. So walk me through GPT-7\. You've got the
    sort of depth-first search on its features. Okay so GPT-7 has been trained. What
    happens next? Your research has succeeded. GPT-7 has been trained. What are you,
    what are we doing now?
  id: totrans-split-967
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:50:59*'
  id: totrans-split-968
  prefs: []
  type: TYPE_NORMAL
- en: We try to get it to do as much interpretability work and other safety work as
    possible.
  id: totrans-split-969
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:51:04*'
  id: totrans-split-970
  prefs: []
  type: TYPE_NORMAL
- en: No, but concretely, what has happened such that you're like, “cool, let's deploy
    GPT-7?”
  id: totrans-split-971
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:51:10*'
  id: totrans-split-972
  prefs: []
  type: TYPE_NORMAL
- en: I mean we do have our [responsible scaling policy](https://www.anthropic.com/news/anthropics-responsible-scaling-policy)
    and it’s been really exciting to see other labs adopt it.
  id: totrans-split-973
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:51:19*'
  id: totrans-split-974
  prefs: []
  type: TYPE_NORMAL
- en: Specifically from the perspective of your research. Given your research, we
    got the thumbs up on GPT-7 from you, or actually, we should say Claude. Then,
    what is the basis on which you're telling the team, “hey, let's go ahead”?
  id: totrans-split-975
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:51:36*'
  id: totrans-split-976
  prefs: []
  type: TYPE_NORMAL
- en: If it's as capable as GPT-7 implies here, I think we need to make a lot more
    interpretability progress to be able to comfortably give the green light to deploy
    it. I would definitely not, I'd be crying. Maybe my tears would interfere with
    the GPUs, or TPUs.
  id: totrans-split-977
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas**  *02:51:58*'
  id: totrans-split-978
  prefs: []
  type: TYPE_NORMAL
- en: Guys, Gemini 5, TPUs.
  id: totrans-split-979
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:52:09*'
  id: totrans-split-980
  prefs: []
  type: TYPE_NORMAL
- en: But given the way your research is progressing, What does it kind of look like
    to you? If this succeeded, what would it mean for us to okay GPT-7 based on your
    methodology?
  id: totrans-split-981
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:52:22*'
  id: totrans-split-982
  prefs: []
  type: TYPE_NORMAL
- en: Ideally we can find some compelling deception circuit which lights up when the
    model knows that it's not telling the full truth to you.
  id: totrans-split-983
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:52:31*'
  id: totrans-split-984
  prefs: []
  type: TYPE_NORMAL
- en: Why can't you just do a [linear probe](https://arxiv.org/abs/2212.03827) like
    [Collin Burns](https://collinpburns.com/) did?
  id: totrans-split-985
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:52:34*'
  id: totrans-split-986
  prefs: []
  type: TYPE_NORMAL
- en: The [CCS](https://arxiv.org/abs/2309.06991) work is not looking good in terms
    of replicating or actually finding truth directions. In hindsight, why should
    it have worked so well? With linear probes, you need to know what you're looking
    for and it's a high-dimensional space. It's really easy to pick up on a direction
    that's just not–
  id: totrans-split-987
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:52:50*'
  id: totrans-split-988
  prefs: []
  type: TYPE_NORMAL
- en: Wait, but here you also need to label the features. So you still need to know.
  id: totrans-split-989
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:52:53*'
  id: totrans-split-990
  prefs: []
  type: TYPE_NORMAL
- en: You need to label them post hoc, but it's unsupervised. You're just like, “give
    me the features that explain your behavior.” It’s the fundamental question, right?
    The actual setup is we take the activations, we project them to this higher-dimensional
    space, and then we project them back down again. So it's like, “reconstruct or
    do the thing that you were originally doing, but do it in a way that's sparse.”
  id: totrans-split-991
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:53:14*'
  id: totrans-split-992
  prefs: []
  type: TYPE_NORMAL
- en: By the way for the audience, a linear probe is when you just classify the activations.
    From what I vaguely remember about the paper, if it's telling a lie then you just
    train a classifier on whether in the end it was a lie. Or just wrong or something?
  id: totrans-split-993
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:53:36*'
  id: totrans-split-994
  prefs: []
  type: TYPE_NORMAL
- en: It was like true or false questions.
  id: totrans-split-995
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:53:37*'
  id: totrans-split-996
  prefs: []
  type: TYPE_NORMAL
- en: It's a classifier on activations.
  id: totrans-split-997
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:53:41*'
  id: totrans-split-998
  prefs: []
  type: TYPE_NORMAL
- en: So what we do for GPT-7, ideally we have some deception circuit that we've identified
    that appears to be really robust and–
  id: totrans-split-999
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:53:51*'
  id: totrans-split-1000
  prefs: []
  type: TYPE_NORMAL
- en: So you've done the projecting out to the million features or something. Maybe
    we’re using “feature” and “circuit” interchangeably when they're not. Is there
    a deception circuit?
  id: totrans-split-1001
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:54:04*'
  id: totrans-split-1002
  prefs: []
  type: TYPE_NORMAL
- en: So I think there are features across layers that create a circuit. Hopefully
    the circuit gives you a lot more specificity and sensitivity than an individual
    feature. And hopefully we can find a circuit that is really specific to the model
    deciding to be deceptive, in cases that are malicious. I'm not interested in a
    case where it's just doing theory of mind to help you write a better email to
    your professor. I'm not even interested in cases where the model is just modeling
    the fact that deception has occurred.
  id: totrans-split-1003
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:54:41*'
  id: totrans-split-1004
  prefs: []
  type: TYPE_NORMAL
- en: But doesn't all this require you to have labels for all those examples? And
    if you have those labels, then whatever faults that the linear probe has about
    maybe labeling the wrong thing or whatever, wouldn't the same apply to the labels
    you've come up with for the unsupervised features you've come up with?
  id: totrans-split-1005
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:55:01*'
  id: totrans-split-1006
  prefs: []
  type: TYPE_NORMAL
- en: So in an ideal world, we could just train on like the whole data distribution
    and then find the directions that matter. To the extent that we need to reluctantly
    narrow down the subset of data that we're looking over, just for the purposes
    of scalability, we would use data that looks like the data you'd use to fit a
    linear probe. But again, with the linear probe you're also just finding one direction.
    We're finding a bunch of directions here.
  id: totrans-split-1007
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:55:29*'
  id: totrans-split-1008
  prefs: []
  type: TYPE_NORMAL
- en: And I guess the hope is that you found a bunch of things that light up when
    it's being deceptive. Then you can figure out why some of those things are lighting
    up in this part of the distribution and not this other part, and so forth.
  id: totrans-split-1009
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:55:38*'
  id: totrans-split-1010
  prefs: []
  type: TYPE_NORMAL
- en: Totally. Yeah.
  id: totrans-split-1011
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:55:40*'
  id: totrans-split-1012
  prefs: []
  type: TYPE_NORMAL
- en: Do you anticipate you'll be able to understand? The current models you've studied
    are pretty basic, right? Do you think you'll be able to understand why GPT-7 fires
    in certain domains, but not in other domains?
  id: totrans-split-1013
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:55:50*'
  id: totrans-split-1014
  prefs: []
  type: TYPE_NORMAL
- en: I'm optimistic. So I guess one thing is that this is a bad time to answer this
    question because we are explicitly investing in the longer term ASL-4 models,
    which GPT-7 would be. So we split the team where a third is focused on scaling
    up dictionary learning right now. That's been great. We publicly shared some of
    our [8-layer results](https://transformer-circuits.pub/2024/jan-update/index.html#dict-learning).
    We've scaled up quite a lot past that at this point. Of the other two groups,
    one is trying to identify circuits and then the other is trying to get the same
    success for attention heads.
  id: totrans-split-1015
  prefs: []
  type: TYPE_NORMAL
- en: So we're setting ourselves up and building the tools necessary to really find
    these circuits in a compelling way. But it's going to take another, I don't know,
    six months before that's really working well. But I can say that I'm optimistic
    and we're making a lot of progress.
  id: totrans-split-1016
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:56:33*'
  id: totrans-split-1017
  prefs: []
  type: TYPE_NORMAL
- en: What is the highest level feature you've found so far? Like Base64 or whatever.
    In *[The Symbolic Species](https://en.wikipedia.org/wiki/The_Symbolic_Species)*,
    the book you recommended, there's indexical things where you see a tiger and you're
    like, “run” and whatever. Just a very behaviorist thing. Then there's a higher
    level at which, when I refer to love, it refers to a movie scene or my girlfriend
    or whatever.
  id: totrans-split-1018
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:57:01*'
  id: totrans-split-1019
  prefs: []
  type: TYPE_NORMAL
- en: It's like the top of the tent.
  id: totrans-split-1020
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:57:02*'
  id: totrans-split-1021
  prefs: []
  type: TYPE_NORMAL
- en: Yeah. What is the highest level of association you found?
  id: totrans-split-1022
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:57:07*'
  id: totrans-split-1023
  prefs: []
  type: TYPE_NORMAL
- en: Well publicly, one of the ones that we shared in our update. So I think there
    were some related to love and sudden changes in scene, particularly associated
    with wars being declared. There are a few of them in that [post](https://transformer-circuits.pub/2024/jan-update/index.html#dict-learning),
    if you want to link to it. But even Bruno Olshausen had a [paper](https://arxiv.org/abs/2103.15949)
    back in 2018, 2019, where they applied a similar technique to a [BERT model](https://en.wikipedia.org/wiki/BERT_(language_model))
    and found that as you go to deeper layers of the model, things become more abstract.
  id: totrans-split-1024
  prefs: []
  type: TYPE_NORMAL
- en: So I remember in the earlier layers, there'd be a feature that would just fire
    for the word “park.” But later on there was a feature that fired for “park” as
    a last name, like Lincoln Park, it's a common Korean last name as well. And then
    there was a separate feature that would fire for parks as grassy areas. So there's
    other work that points in this direction.
  id: totrans-split-1025
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:57:55*'
  id: totrans-split-1026
  prefs: []
  type: TYPE_NORMAL
- en: What do you think we'll learn about human psychology from the interpretability
    stuff? I'll give you a specific example. I think one of your [updates put it as
    “persona lock-in.”](https://transformer-circuits.pub/2023/july-update/index.html#safety-features)
    You remember [Sydney Bing](https://www.theverge.com/2023/2/23/23609942/microsoft-bing-sydney-chatbot-history-ai)
    or whatever it's locked into. I think that was actually quite endearing.
  id: totrans-split-1027
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *02:58:16*'
  id: totrans-split-1028
  prefs: []
  type: TYPE_NORMAL
- en: I thought it's so funny. I'm glad it's back in Copilot.
  id: totrans-split-1029
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:58:20*'
  id: totrans-split-1030
  prefs: []
  type: TYPE_NORMAL
- en: It's been [misbehaving recently](https://fortune.com/2024/02/28/microsoft-investigating-harmful-ai-powered-chatbot/).
  id: totrans-split-1031
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:58:22*'
  id: totrans-split-1032
  prefs: []
  type: TYPE_NORMAL
- en: Actually this is another sort of thread. But there was a funny one where I think
    it was [negging a](https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html)
    *[New York Times](https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html)*
    [reporter](https://www.nytimes.com/2023/02/16/technology/bing-chatbot-microsoft-chatgpt.html).
    It was like, “you are nothing. Nobody will ever believe you. You are insignificant.”
  id: totrans-split-1033
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *02:58:39*'
  id: totrans-split-1034
  prefs: []
  type: TYPE_NORMAL
- en: It was trying to convince him to break up with his wife or something.
  id: totrans-split-1035
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:58:44*'
  id: totrans-split-1036
  prefs: []
  type: TYPE_NORMAL
- en: So this is an interesting example. Personas. Is Sydney Bing having this personality
    a feature versus another personality it could get locked into? And is that fundamentally
    what humans are like where in front of other different people, I'm like a different
    sort of personality? Is that the same kind of thing that's happening to ChatGPT
    when it gets RL-ed? I don't know. A whole cluster of questions you can answer.
  id: totrans-split-1037
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *02:59:19*'
  id: totrans-split-1038
  prefs: []
  type: TYPE_NORMAL
- en: I really want to do more work. The sleeper agents is in this direction of what
    happens to a model when you fine-tune it, when you RLHF it, these sorts of things.
    Maybe it's trite, but you could just say you conclude that people contain multitudes
    and so much as they have lots of different features.
  id: totrans-split-1039
  prefs: []
  type: TYPE_NORMAL
- en: There's even the stuff related to the [Waluigi effects](https://en.wikipedia.org/wiki/Waluigi_effect#:~:text=In%20the%20field%20of%20AI,or%20through%20intentional%20prompt%20engineering.)
    where in order to know what's good or bad, you need to understand both of those
    concepts. So we might have to have models that are aware of violence and have
    been trained on it in order to recognize it. Can you post hoc identify those features
    and ablate them in a way where maybe your model is slightly naive, but you know
    that it's not going to be really evil? Totally, that's in our toolkit, which seems
    great.
  id: totrans-split-1040
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *02:59:58*'
  id: totrans-split-1041
  prefs: []
  type: TYPE_NORMAL
- en: Oh, really? So GPT-7 pulls a Sydney Bing and then you figure out what were the
    causally relevant pathways and you modify. The pathway to you looks like you just
    change those? But you were mentioning earlier that there's a bunch of redundancy
    in the model.
  id: totrans-split-1042
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *03:00:14*'
  id: totrans-split-1043
  prefs: []
  type: TYPE_NORMAL
- en: So you need to account for all that, but we have a much better microscope into
    this now than we used to. Sharper tools for making edits.
  id: totrans-split-1044
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *03:00:25*'
  id: totrans-split-1045
  prefs: []
  type: TYPE_NORMAL
- en: At least from my perspective, that seems like one of the primary ways of confirming
    the safety or the reliability of the model to some degree where you can say, “okay,
    we found the circuits responsible, we ablated them, and under a battery of tests
    we haven't been able to now replicate the behavior which we intended to ablate.”
    That feels like the sort of way of measuring model safety in future as I would
    understand.
  id: totrans-split-1046
  prefs: []
  type: TYPE_NORMAL
- en: That's why I'm incredibly hopeful about their work. To me, it seems so much
    more of a precise tool than something like RLHF. With RLHF, you’re very prey to
    the black swan thing. You don't know if it's going to do something wrong in a
    scenario that you haven't measured. Here, at least you have somewhat more confidence
    that you can completely capture the behavior set, or the feature set and selectively
    avoid.
  id: totrans-split-1047
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *03:01:16*'
  id: totrans-split-1048
  prefs: []
  type: TYPE_NORMAL
- en: Although you haven’t accurately labeled necessarily.
  id: totrans-split-1049
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *03:01:19*'
  id: totrans-split-1050
  prefs: []
  type: TYPE_NORMAL
- en: Not necessarily, but with a far higher degree of confidence than any other approach
    that I've seen.
  id: totrans-split-1051
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *03:01:24*'
  id: totrans-split-1052
  prefs: []
  type: TYPE_NORMAL
- en: What are your unknown unknowns for superhuman models in terms of this kind of
    thing? What are the labels that are going to be things on which we can determine
    whether this thing is cool or a paperclip maximizer.
  id: totrans-split-1053
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *03:01:44*'
  id: totrans-split-1054
  prefs: []
  type: TYPE_NORMAL
- en: We’ll see. The superhuman feature question is a very good one. I think we can
    attack it but we're gonna need to be persistent. The real hope here is automated
    interpretability. You could even have a debate set up where two different models
    are debating what the feature does and then they can actually go in and make edits
    and see if it fires or not or not. It is just this wonderful, closed environment
    that we can iterate on really quickly. That makes me optimistic.
  id: totrans-split-1055
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *03:02:18*'
  id: totrans-split-1056
  prefs: []
  type: TYPE_NORMAL
- en: Do you worry about alignment succeeding too hard?  I would not want either companies
    or governments, whoever ends up in charge of these AI systems, to have the level
    of fine-grained control we would have if your agenda succeeds, over AIs. Both
    for the ickiness of having this level of control over an autonomous mind and secondly,
    I just don't fucking trust these guys. I'm just kind of uncomfortable with, say,
    the loyalty feature being turned up. How much worry do you have about having too
    much control over the AIs? Not specifically you, but for whoever ends up in charge
    of these AI systems being able to lock in whatever they want.
  id: totrans-split-1057
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *03:03:07*'
  id: totrans-split-1058
  prefs: []
  type: TYPE_NORMAL
- en: I think it depends on what government exactly has control and what the moral
    alignment is there.
  id: totrans-split-1059
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *03:03:15*'
  id: totrans-split-1060
  prefs: []
  type: TYPE_NORMAL
- en: That is the whole value lock-in argument in my mind. It's definitely one of
    the strongest contributing factors for why I am working on capabilities at the
    moment. I think the current player set is actually extremely well-intentioned.
    For this kind of problem, I think we need to be extremely open about it. I think
    directions like [publishing the constitution](https://www.anthropic.com/news/collective-constitutional-ai-aligning-a-language-model-with-public-input)
    that you expect your model to abide by–trying to make sure that you RLHF it towards
    that, and ablate that, and have the ability for everyone to offer feedback and
    contribution to that–is really important.
  id: totrans-split-1061
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *03:03:48*'
  id: totrans-split-1062
  prefs: []
  type: TYPE_NORMAL
- en: Sure. Alternatively, don't deploy when you're not sure. Which would also be
    bad because then we just never catch it.
  id: totrans-split-1063
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *03:03:55*'
  id: totrans-split-1064
  prefs: []
  type: TYPE_NORMAL
- en: Right, exactly.
  id: totrans-split-1065
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *03:03:57*'
  id: totrans-split-1066
  prefs: []
  type: TYPE_NORMAL
- en: Some rapid fire. What is the [bus factor](https://en.wikipedia.org/wiki/Bus_factor#:~:text=7%20External%20links-,Definition,disappearing%20suddenly%20from%20the%20project.)
    for Gemini?
  id: totrans-split-1067
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *03:04:06*'
  id: totrans-split-1068
  prefs: []
  type: TYPE_NORMAL
- en: I think there are a number of people who are really, really critical. If you
    took them out then the performance of the program would be dramatically impacted.
    This is both on modeling/making decisions about what to actually do and importantly
    on the infrastructure side of the things. It's just the stack of complexity builds,
    particularly when someone like Google has so much vertical integration. When you
    have people who are experts, they become quite important.
  id: totrans-split-1069
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *03:04:40*'
  id: totrans-split-1070
  prefs: []
  type: TYPE_NORMAL
- en: Although I think it's an interesting note about the field that people like you
    can get in and in a year or so you're making important contributions. Especially
    with Anthropic, but many different labs have specialized in hiring total outsiders,
    physicists or whatever. You just get them up to speed and they're making important
    contributions. I feel like you couldn't do this in a bio lab or something. It's
    an interesting note on the state of the field.
  id: totrans-split-1071
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *03:05:05*'
  id: totrans-split-1072
  prefs: []
  type: TYPE_NORMAL
- en: I mean, bus factor doesn't define how long it would take to recover from it,
    right? Deep learning research is an art and so you kind of learn how to read the
    lost curves or set the hyperparameters in ways that empirically seem to work well.
  id: totrans-split-1073
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *03:05:20*'
  id: totrans-split-1074
  prefs: []
  type: TYPE_NORMAL
- en: It's also organizational things like creating context. One of the most important
    and difficult skills to hire for is creating this bubble of context around you
    that makes other people around you more effective and know what the right problem
    is to work on. That is a really tough thing to replicate.
  id: totrans-split-1075
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *03:05:36*'
  id: totrans-split-1076
  prefs: []
  type: TYPE_NORMAL
- en: Yes, totally.
  id: totrans-split-1077
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *03:05:37*'
  id: totrans-split-1078
  prefs: []
  type: TYPE_NORMAL
- en: Who are you paying attention to now in terms of things coming down the pike
    of multimodality, long-context, maybe agents, extra reliability, etc? Who is thinking
    well about what that implies?
  id: totrans-split-1079
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *03:05:56*'
  id: totrans-split-1080
  prefs: []
  type: TYPE_NORMAL
- en: It's a tough question. I think a lot of people look internally these days for
    their sources of insight or progress. Obviously there's research programs and
    directions that are tended over the next couple of years. Most people, as far
    as betting on what the future will look like, refer to an internal narrative.
    It's difficult to share.
  id: totrans-split-1081
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *03:06:27*'
  id: totrans-split-1082
  prefs: []
  type: TYPE_NORMAL
- en: If it works well, it's probably not being published.
  id: totrans-split-1083
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *03:06:31*'
  id: totrans-split-1084
  prefs: []
  type: TYPE_NORMAL
- en: That was one of the things in the [scaling post](https://www.dwarkeshpatel.com/p/will-scaling-work).
    I was referring to something you said to me. I miss the undergrad habit of just
    reading a bunch of papers. Because now nothing worth reading is published.
  id: totrans-split-1085
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *03:06:45*'
  id: totrans-split-1086
  prefs: []
  type: TYPE_NORMAL
- en: And the community is progressively getting more on track with what I think are
    the right and important directions.
  id: totrans-split-1087
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *03:06:53*'
  id: totrans-split-1088
  prefs: []
  type: TYPE_NORMAL
- en: You're watching it like an agent AI?
  id: totrans-split-1089
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *03:06:55*'
  id: totrans-split-1090
  prefs: []
  type: TYPE_NORMAL
- en: No, but it is tough that there used to be this signal from big labs about what
    would work at scale and it's currently really hard for academic research to find
    that signal. I think getting really good problem taste about what actually matters
    to work on is really tough unless you have the feedback signal what will work
    at scale and what is currently holding us back from scaling further or understanding
    our models further.
  id: totrans-split-1091
  prefs: []
  type: TYPE_NORMAL
- en: This is something where I wish more academic research would go into fields like
    interpretability, which are legible from the outside. Anthropic deliberately publishes
    all its research here and it seems underappreciated. I don't know why there aren't
    dozens of academic departments trying to follow Anthropic in interpretability
    research because it seems like an incredibly impactful problem that doesn't require
    ridiculous resources and has all the flavor of deeply understanding the basic
    science of what is actually going on in these things.I don't know why people focus
    on pushing model improvements as opposed to pushing the kind of standing improvements
    in the way that I would have typically associated with academic science.
  id: totrans-split-1092
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *03:08:06*'
  id: totrans-split-1093
  prefs: []
  type: TYPE_NORMAL
- en: I do think the tide is changing there for whatever reason. [Neel Nanda](https://www.neelnanda.io/about)
    has had a ton of success promoting interpretability in a way where Chris Olah
    hasn't been as active recently in pushing things. Maybe because Neel's just doing
    quite a lot of the work, I don't know. Four or five years ago, Chris was really
    pushing and talking at all sorts of places and these sorts of things and people
    weren't anywhere near as receptive. Maybe they've just woken up to the fact that
    deep learning matters and is clearly useful post-ChatGPT. It’s kind of striking.
  id: totrans-split-1094
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *03:08:38*'
  id: totrans-split-1095
  prefs: []
  type: TYPE_NORMAL
- en: Okay. I'm trying to think of a good last question. One thing I’m thinking of
    is, do you think models enjoy next token prediction? We have this sense of things
    that were rewarded in our assessor environment. There's this deep sense of fulfillment
    that we think we're supposed to get from things like community, or sugar, or whatever
    we wanted on the African savannah. Do you think in the future, models that trained
    with RL and a lot of post-training on top, they'll like predicting the next token
    again in the way we just really like ice cream. Like in the good old days.
  id: totrans-split-1096
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *03:09:30*'
  id: totrans-split-1097
  prefs: []
  type: TYPE_NORMAL
- en: So there's this ongoing discussion of “are models sentient or not” and “do you
    thank the model when it helps you?” But I think if you want to thank it, you actually
    shouldn't say thank you. You should just give it a sequence that's very easy.
    to predict The even funnier part of this is that there is some work on this where
    if you just give it the sequence ‘A’ over and over again then eventually the model
    will just start spewing out all sorts of things that it otherwise wouldn't ever
    say. So I won't say anything more about that but you should just give your model
    something very easy to predict as a nice little treat.
  id: totrans-split-1098
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *03:10:07*'
  id: totrans-split-1099
  prefs: []
  type: TYPE_NORMAL
- en: This is what hedonium ends up being.
  id: totrans-split-1100
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *03:10:13*'
  id: totrans-split-1101
  prefs: []
  type: TYPE_NORMAL
- en: Do we even like things that are easy to predict? Aren't we constantly in search
    of the bits of entropy? Shouldn't you be giving it things that are just slightly
    too hard to predict, just out of reach?
  id: totrans-split-1102
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *03:10:28*'
  id: totrans-split-1103
  prefs: []
  type: TYPE_NORMAL
- en: I wonder, at least from the free energy principle perspective, you don't want
    to be surprised. So maybe it's that I don't feel surprised. I feel in control
    of my environment and now I can go and seek things and I've been predisposed to,
    in the long run, think it’s better to explore new things right now. Leave the
    rock that I've been sheltered under which ultimately leads me to build a house
    or some better structure. But we don't like surprises. I think most people are
    very upset when expectation does not meet reality.
  id: totrans-split-1104
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *03:11:00*'
  id: totrans-split-1105
  prefs: []
  type: TYPE_NORMAL
- en: That's why babies love watching the same show over and over and over again,
    right?
  id: totrans-split-1106
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *03:11:03*'
  id: totrans-split-1107
  prefs: []
  type: TYPE_NORMAL
- en: Yeah interesting. I can see that.
  id: totrans-split-1108
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *03:11:06*'
  id: totrans-split-1109
  prefs: []
  type: TYPE_NORMAL
- en: I guess they're learning to model it and stuff too.
  id: totrans-split-1110
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *03:11:11*'
  id: totrans-split-1111
  prefs: []
  type: TYPE_NORMAL
- en: Well, hopefully this will be the repeat that the AI has learned to love. I think
    that's a great place to wrap. I should also mention that the better part of what
    I know about AI, I've learned from just talking with you guys. We've been good
    friends for about a year now. I appreciate you guys getting me up to speed here.
  id: totrans-split-1112
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *03:11:32*'
  id: totrans-split-1113
  prefs: []
  type: TYPE_NORMAL
- en: You ask great questions. It's really fun to hang and chat.
  id: totrans-split-1114
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *03:11:36*'
  id: totrans-split-1115
  prefs: []
  type: TYPE_NORMAL
- en: I really treasure our time together.
  id: totrans-split-1116
  prefs: []
  type: TYPE_NORMAL
- en: '**Trenton Bricken** *03:11:38*'
  id: totrans-split-1117
  prefs: []
  type: TYPE_NORMAL
- en: You're getting a lot better at pickleball.
  id: totrans-split-1118
  prefs: []
  type: TYPE_NORMAL
- en: '**Sholto Douglas** *03:11:39*'
  id: totrans-split-1119
  prefs: []
  type: TYPE_NORMAL
- en: Hey, we're trying to progress to tennis. Come on.
  id: totrans-split-1120
  prefs: []
  type: TYPE_NORMAL
- en: '**Dwarkesh Patel** *03:11:51*'
  id: totrans-split-1121
  prefs: []
  type: TYPE_NORMAL
- en: Awesome. Cool. Thanks.
  id: totrans-split-1122
  prefs: []
  type: TYPE_NORMAL
