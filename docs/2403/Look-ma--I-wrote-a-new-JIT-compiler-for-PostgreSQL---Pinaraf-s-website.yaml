- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: Êú™ÂàÜÁ±ª'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 15:05:34'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: Look ma, I wrote a new JIT compiler for PostgreSQL ‚Äì Pinaraf's website
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Êù•Ê∫êÔºö[https://www.pinaraf.info/2024/03/look-ma-i-wrote-a-new-jit-compiler-for-postgresql/](https://www.pinaraf.info/2024/03/look-ma-i-wrote-a-new-jit-compiler-for-postgresql/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Sometimes, I don‚Äôt know why I do things. It‚Äôs one of these times. A few months
    ago, Python 3.13 got its JIT engine, built with a new JIT compiler construction
    methodology (copy-patch, cf. [research paper](https://arxiv.org/pdf/2011.13127.pdf)).
    After reading the paper, I was sold and I just had to try it with PostgreSQL.
    And what a fun ride it‚Äôs been so far. This blog post will not cover everything,
    and I prefer other communication methods, but I would like to introduce pg-copyjit,
    the latest and shiniest way to ~~destroy and segfault~~ speed up your PostgreSQL
    server.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: 'Before going any further, a mandatory warning: all code produced here is experimental.
    Please. I want to hear reports from you, like ‚Äúho it‚Äôs fun‚Äù, ‚Äúho I got this performance
    boost‚Äù, ‚Äúhey maybe this could be done‚Äù, but not ‚Äúhey, your extension cost me hours
    of downtime on my business critical application‚Äù. Anyway, its current state is
    for professional hackers, I hope you know better than trusting experimental code
    with a production server.'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: In the beginning, there was no JIT, and then came the LLVM JIT compiler
  id: totrans-split-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In a PostgreSQL release a long time ago, in a galaxy far far away, Andres Freund
    introduced the PostgreSQL world to the magics of JIT compilation, using LLVM.
    They married and there was much rejoicing. Alas, darkness there was in the bright
    castle, for LLVM is a very very demanding husband.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
- en: 'LLVM is a great compilation framework. Its optimizer produces very good and
    efficient code, and Andres went further than what anybody else would have thought
    and tried in order to squeeze the last microsecond of performance in his JIT compiler.
    This is a wonderful work and I don‚Äôt know how to express my love for the madness
    this kind of dedication to performance is. But LLVM has a big downside¬†: it‚Äôs
    not built for JIT compilation. At least not in the way PostgreSQL will use it:
    the LLVM optimizer is very expensive, but not using it may be worse than no compilation
    at all. And in order to compile only the good stuff, the queries that can enjoy
    the performance boost, the typical query cost estimation is used. And that‚Äôs the
    PostgreSQL downside making the whole thing almost impossible: costs in PostgreSQL
    are not designed to mean anything. They are meant to be compared to each other,
    but do not mean anything regarding the real execution time. A query costing 100¬†may
    run in 1 second, while another costing 1000 may run in 100 milliseconds. It‚Äôs
    not a bug, it‚Äôs a design decision.¬†That‚Äôs why a lot of people (including me) end
    up turning off the JIT compiler: most if not all queries on my production system
    will not get enough from the performance boost to compensate the LLVM optimizer
    cost. If I can run the query 10ms faster but it needed 50ms to be optimized, it‚Äôs
    pure loss.'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
- en: 'There is one way to make the LLVM JIT compiler more usable, but I fear it‚Äôs
    going to take years to be implemented: being able to cache and reuse compiled
    queries. I will not dig further into that topic in this post, but trust me, it‚Äôs
    not going to be a small feat to achieve.'
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
- en: And in 2021, copy-and-patch was described‚Ä¶
  id: totrans-split-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So, what can we do?¬†We need fast enough code generated the fastest way possible.
    Fast enough code mean at least a bit faster than the current interpreter‚Ä¶ But
    writing a compiler is painful, writing several code generators (for different
    ISAs for instance) is even worse‚Ä¶
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
- en: This is where the innovation of copy-and-patch comes into play and saves the
    day.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
- en: With copy-patch, you write stencils in C. These stencils are functions with
    holes, and they are compiled by your typical clang compiler (gcc support pending,
    too complicated to explain here). Then when you want to compile something, you
    stitch stencils together, fill in the gaps, and jump straight into your brand
    new ‚Äúcompiled‚Äù function.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
- en: And this is it. This is the magic of copy-and-patch. You only copy the stencils
    in a new memory area, patch the holes, and voil√†.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
- en: Of course, you can go further. You can figure out what computation can be done
    at compilation time, you can split loops in several stencils to unroll them, you
    can merge several stencils together to optimize them in one go (creating kind
    of meta-stencils‚Ä¶)
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
- en: This paper caught the eyes of the Faster-CPython team, they implemented it in
    CPython 3.13, and this is when more people (including me) discovered it.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
- en: Bringing copy-and-patch to PostgreSQL
  id: totrans-split-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So, what does it take to build a new JIT engine in PostgreSQL? Hopefully, not
    that much, otherwise I would likely not be blogging about this.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
- en: When JIT compilation was introduced, it was suggested on hackers to make LLVM
    a plugin, allowing future extensions to bring other JIT compilers. Back then,
    I was quite skeptical to this idea (but never expressed this opinion, I did not
    want to be wrong later), and it turned out I proved myself wrong‚Ä¶ The interface
    is really simple, your .so only needs to provide a single _PG_jit_provider_init
    function, and in this function initialize three callbacks, named compile_expr,
    release_context and reset_after_error. The main one is obviously compile_expr.
    You get one ExprState* parameter, a pointer to an expression, made of opcodes.
    Then it‚Äôs ‚Äúonly‚Äù a matter of compiling the opcodes together in any way you want,
    mark this built code as executable, and changing the evalfunc to this code instead
    of the PostgreSQL interpreter. This is easy, and you have an automatic fallback
    to the PostgreSQL interpreter if you encounter any opcode you‚Äôve not implemented
    yet.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
- en: The copy and patch algorithm (implemented with only a few small optimizations
    so far) is so easy I can explain it here. For each opcode, the compiler will look
    into the stencil collection. If the opcode has a stencil, the stencil is appended
    to the ‚Äúbuilt‚Äù code. Otherwise, the compilation stops and the PostgreSQL interpreter
    will kick in. After appending the stencil, each of its holes are patched with
    the required value.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
- en: For instance, let‚Äôs consider this basic unoptimized stencil, for the opcode
    CONST.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-split-24
  prefs: []
  type: TYPE_PRE
- en: op is declared as extern ExprEvalStep op; (and NEXT_OP is a bit harder to explain,
    I won‚Äôt dig into it here). When building this to a single .o file, the compiler
    will leave a hole in the assembly code, where the address for op will have to
    be inserted (using a relocation). When the stencil collection is built, this information
    is kept and used by the JIT compiler to use the current opcode structure address
    in order to get a working code.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
- en: The build process for the stencils is quite fun, not complicated, but fun. The
    first step is to build the stencils to a single .o file, and then extract the
    assembly code and relocations from this .o file into C usable structures, that
    the JIT compiler will link to.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
- en: And that‚Äôs about all there is.
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
- en: At first, I was extracting the assembly code manually. Using that way, I managed
    to get the three needed opcodes for SELECT 42; to work. And there was much joy.
    After this first proof of concept (and I guess some disturbed looks a few days
    ago at PgDay.Paris when people saw me happy with being able to run SELECT 42,
    that may have sound weird), I wrote a DirtyPython (unofficial variant) script
    to automate the assembly code extraction, and in a few hours I implemented function
    calls, single table queries, more complicated data types, introduced a few optimizations‚Ä¶
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
- en: Current state
  id: totrans-split-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It works on my computer with PostgreSQL 16\. It should be fine with older releases.
    It only supports AMD64 because that‚Äôs what I have and I can not target everything
    at once. Later I will add ARM64, and I would love to have some time to add support
    for some interesting targets like POWER64 or S390x (these may require some compiler
    patches, sadly, and access to such computers, nudge nudge wink wink)‚Ä¶
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
- en: Performance-wise, well, keeping in mind that I‚Äôve spent almost no time optimizing
    it, the results are great. Code generation is done in a few hundreds microseconds,
    making it usable even for short queries, where LLVM is simply out of the game.
    On a simple SELECT 42; query, running with no JIT takes 0,3ms, with copyjit it
    requires 0,6ms, LLVM with no optimizations goes to 1,6ms and optimizing LLVM will
    require 6,6ms. Sure, LLVM can create really fast code, but the whole idea here
    is to quickly generate fast enough code, and thus comparing both tools won‚Äôt make
    much sense.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
- en: But still, you are all waiting for a benchmark, so here we go, benchmarking
    two queries on a simple non-indexed 90k rows table. This benchmark is done on
    a laptop and my trust in such a benchmark setup is moderate at best, a proper
    benchmark will be done later on a desktop computer without any kind of thermal
    envelope shenanigans. And I have not optimized my compiler, it‚Äôs still quite stupid
    and there is a lot of things that can and must be done.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
- en: '| **Query** | **Min/max (ms)** | **Median (ms) and stdev** |'
  id: totrans-split-33
  prefs: []
  type: TYPE_TB
- en: '| select * from b; ‚Äî no JIT | 10.340/14.046 | 10.652/0.515 |'
  id: totrans-split-34
  prefs: []
  type: TYPE_TB
- en: '| select * from b; ‚Äî JIT | 10.326/14.613 | 10.614/0.780 |'
  id: totrans-split-35
  prefs: []
  type: TYPE_TB
- en: '| select i, j from b where i < 10; ‚Äî no JIT | 3.348/4.070 | 3.7333/0.073 |'
  id: totrans-split-36
  prefs: []
  type: TYPE_TB
- en: '| select i, j from b where i < 10; ‚Äî JIT | 3.210/4.701 | 3.519/0.107 |'
  id: totrans-split-37
  prefs: []
  type: TYPE_TB
- en: Stupid benchmark on a laptop running non-optimized code, don‚Äôt trust these‚Ä¶
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, even in the current unfinished state, as soon as there is CPU
    work to do (here it‚Äôs the where clause), performance relative to the interpreter
    get better. It‚Äôs only logical, and what is important here is that even if the
    JIT is an extra, slightly time consuming step, it takes so little time even these
    queries can go a few percents faster.
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
- en: Note that even if I‚Äôve implemented only a small handful of opcodes, I can run
    any query on my server, the JIT engine will only complain loudly about it and
    let the interpreter run the query‚Ä¶
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
- en: For the more curious, the code is [dumped there on github](https://github.com/pinaraf/pg-copyjit).
    I said dumped because I focus only on the code and not on the clarity of my git
    history nor on wrapping it in a nice paper with flying colors and pretty flowers,
    that‚Äôs what you do when the code is done, this one isn‚Äôt yet‚Ä¶ If you want to build
    it, the build-stencils.sh file must be run manually first. But again, I do not
    document it yet because I simply can not provide any support for the code in its
    current state.
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
- en: TODO‚Ä¶
  id: totrans-split-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is a proof of concept. I‚Äôve not worked on making it easy to build, on making
    it possible to package it‚Ä¶ The build scripts are Debian and PostgreSQL 16 specific.
    And, well, to be honest, at this point, I don‚Äôt care much and it will not trouble
    me, my focus is on implementing more opcodes, and searching for optimizations.
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
- en: I really hope I will reach a point where I can safely package this and deploy
    it on my production servers. This way, I‚Äôll keep using the LLVM JIT on the server
    that can use it (a GIS server where queries are worth the optimization) and use
    this JIT on my web-application databases, where short query time is a must have,
    and the LLVM optimizations end up being counter-productive.
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
- en: I am also dead serious on porting this to other architectures. I¬†love the old
    days of Alpha, Itanium, Sparc, M68k and other different architectures. I am not
    going to use this kind of system, but I miss the diversity, and I really don‚Äôt
    want to be a part of the monoculture issue here.
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
- en: Thanks
  id: totrans-split-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, huge thanks to my current day-job employer, Entr‚Äôouvert. We are a small
    french SaaS company, free-software focused, and my colleagues simply let me toy
    on this between tickets and other DBA or sysadmin tasks.
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
- en: 'I would like to thank my DBA friends for supporting me and motivating me into
    doing this (won‚Äôt give their names, they know who they are). BTW: use [PoWA](https://powa.readthedocs.io/en/latest/),
    great tool, tell your friends‚Ä¶'
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
- en: 'Also, quick question: they suggest I shall go to PGConf.dev to show this, but
    it‚Äôs too late for the schedule and since I live in France I did not intend to
    go there. If you think it‚Äôs important or worth it, please, please, say so (comments
    below, or my email is p@this.domain), otherwise see you in future european PG
    events¬†üôÇ'
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
