- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-27 14:46:11'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024年5月27日14:46:11
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Welcome to the Valley of the Creepy AI Dolls | WIRED
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 欢迎来到怪异AI娃娃的谷 | WIRED
- en: 来源：[https://www.wired.com/story/ai-dolls-for-older-adults/](https://www.wired.com/story/ai-dolls-for-older-adults/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.wired.com/story/ai-dolls-for-older-adults/](https://www.wired.com/story/ai-dolls-for-older-adults/)
- en: But these are the inherent risks that come when companies ask people to turn
    to their products in their most vulnerable moments. Moyle says she’s of two minds
    about the issue.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 但这些都是当公司要求人们在他们最脆弱的时刻转向他们的产品时所带来的固有风险。莫伊尔说她在这个问题上有两种看法。
- en: “If we give somebody an opportunity to talk to AI, does that remove all other
    social opportunities?” Moyle says. “Does that mean that families stop visiting?
    Does that mean that the staff stops talking to the person?” It’s a risk, but she
    says, in her experience, many older adults in care facilities are often left by
    themselves for the vast majority of their days and nights as it is. “Giving them
    something, if it makes them happy, is much better than giving them nothing at
    all.”
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: “如果我们让某人有机会与AI交谈，是否会排除其他所有的社交机会？”莫伊尔说。“这是否意味着家人停止访问？员工是否停止与人交流？”这是一个风险，但她说，根据她的经验，许多养老设施中的老年人大部分时间都是独自一人度过的。“如果能给他们一些东西让他们开心，比起什么都不给要好得多。”
- en: Of course these devices aren’t the same as a human. Large language models don’t
    understand the person interacting with them; they’re just very good at predicting
    what will sound like a good response. And they certainly don’t know how to fully
    understand a person’s emotions or mental state.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这些设备并不等同于人类。大型语言模型并不理解与它们互动的人；它们只是非常擅长预测什么样的回应听起来会很好。它们当然也不知道如何完全理解一个人的情感或心理状态。
- en: “People can be displaying quite challenging emotions that are not being picked
    up by the AI,” Moyle says. “As AI becomes more sophisticated, that probably will
    get better, but at the moment it’s certainly not.” She pauses, then laughs and
    adds, “But a lot of humans can't assess emotions very well either, so …”
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: “人们可能表现出相当具有挑战性的情绪，但AI却无法捕捉到。”莫伊尔说。“随着AI变得更加复杂，这种情况可能会变得更好，但目前显然不是这样。”她顿了一下，然后笑着补充道：“但很多人类也不能很好地评估情绪，所以……”
- en: For lots of people, it doesn’t really matter if a robot can’t love them back.
    It’s why we still mourn our robots dying [slow, somber deaths](https://www.wired.com/story/jibo-is-dying-eulogy/),
    and hold funerals for [robot dogs](https://www.theguardian.com/world/2018/may/03/japan-robot-dogs-get-solemn-buddhist-send-off-at-funerals).
    It’s why we want [personalities in our sexbots](https://www.wired.com/story/henry-the-sexbot-wants-to-know-all-your-hopes-and-dreams/)
    and trust them with our [deepest desires](https://www.wired.com/story/replika-chatbot-sexuality-ai/).
    When a human interacts with a robot, it’s less about whether the robot can love
    you back, and more so about how people derive value from the act of pouring their
    own feelings into someone (or something) else.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多人来说，一个机器人是否能回报爱并不重要。这就是为什么我们仍然为我们的机器人哀悼它们的“缓慢、忧郁的死亡”，并为机器狗举行[葬礼](https://www.theguardian.com/world/2018/may/03/japan-robot-dogs-get-solemn-buddhist-send-off-at-funerals)。这就是为什么我们在我们的性机器人中想要[个性](https://www.wired.com/story/henry-the-sexbot-wants-to-know-all-your-hopes-and-dreams/)，并信任它们了解我们的[深层愿望](https://www.wired.com/story/replika-chatbot-sexuality-ai/)。当一个人与机器人互动时，这与机器人是否能回报你的爱意无关，而更关乎人们如何从向某人（或某物）倾注自己的感情中获得价值。
- en: “What the cat and what the baby gave us is a sense that they need our love,
    and that's what we are longing for as humans,” Hung says. If someone is looking
    to interact with a cute and cuddly robot, it’s often to fulfill that same function.
    “We buy these robots because we want to give our love to them—so we feel that
    the robot needs our love, so we feel that there's something who needs us. That’s
    the nature of humans.”
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: “猫咪和婴儿带给我们的感觉是，它们需要我们的爱，这也是我们作为人类所渴望的。”洪说。如果有人希望与一只可爱而亲密的机器人互动，通常也是为了满足同样的需求。“我们购买这些机器人是因为我们想要向它们表达爱意——所以我们觉得机器人需要我们的爱，这样我们就感觉到有某种东西需要我们。这就是人类的本性。”
- en: '*Update March 20, 2024 at 4:01 pm: This story has been updated to include statements
    from Hyodol that the company sent after this story was originally published.*'
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*2024年3月20日更新：本故事已更新，包括Hyodol在本故事初始发布后发送的声明。*'
