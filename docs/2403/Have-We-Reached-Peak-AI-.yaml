- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-27 15:04:35'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-27 15:04:35
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Have We Reached Peak AI?
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们已经达到了AI的巅峰吗？
- en: 来源：[https://www.wheresyoured.at/peakai/](https://www.wheresyoured.at/peakai/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.wheresyoured.at/peakai/](https://www.wheresyoured.at/peakai/)
- en: Last week, [the Wall Street Journal published a 10-minute-long interview with
    OpenAI CTO Mira Murati](https://www.youtube.com/watch?v=mAUpxN-EIgU&ref=wheresyoured.at),
    with journalist Joanna Stern asking a series of thoughtful yet straightforward
    questions that Murati failed to satisfactorily answer. When asked about what data
    was used to train Sora, OpenAI's app for generating video with AI, [Murati claimed
    it used publicly available data](https://youtu.be/mAUpxN-EIgU?t=263&ref=wheresyoured.at),
    and when [Stern asked her whether it used videos from YouTube](https://youtu.be/mAUpxN-EIgU?t=272&ref=wheresyoured.at),
    [Murati's face contorted in a mix of confusion and pain](https://twitter.com/edzitron/status/1768367582137249844/photo/1?ref=wheresyoured.at)
    before saying she "actually wasn't sure about that." [When Stern pushed a third
    time](https://youtu.be/mAUpxN-EIgU?t=278&ref=wheresyoured.at), asking about videos
    from Facebook or Instagram, Murati shook her head and said that if videos were
    "publicly available...to use, there might be the data, I'm not sure, I'm not confident
    about it."
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 上周，[《华尔街日报》刊登了一场时长10分钟的采访，主角是OpenAI的首席技术官米拉·穆拉蒂](https://www.youtube.com/watch?v=mAUpxN-EIgU&ref=wheresyoured.at)，记者乔安娜·斯特恩提出了一系列深思熟虑但又直截了当的问题，穆拉蒂未能令人满意地回答。当被问及训练OpenAI视频生成应用Sora所使用的数据时，[穆拉蒂声称使用了公开可用的数据](https://youtu.be/mAUpxN-EIgU?t=263&ref=wheresyoured.at)，而当[斯特恩问她是否使用了YouTube上的视频时](https://youtu.be/mAUpxN-EIgU?t=272&ref=wheresyoured.at)，[穆拉蒂的脸上露出了一种混合着困惑和痛苦的表情](https://twitter.com/edzitron/status/1768367582137249844/photo/1?ref=wheresyoured.at)，然后她说她“其实不太确定”。[当斯特恩第三次追问时](https://youtu.be/mAUpxN-EIgU?t=278&ref=wheresyoured.at)，询问是否使用了来自Facebook或Instagram的视频时，穆拉蒂摇了摇头，说如果视频是“公开可用的……可以使用，也许有这些数据，我不确定，我对此不太有信心。”
- en: Stern did well to get Murati to answer, but it's deeply concerning that the
    *Chief Technology Officer* of the most "important" AI company in the world can't
    answer a very basic question about training data. [Even when asked about training
    on data from Shutterstock](https://youtu.be/mAUpxN-EIgU?t=297&ref=wheresyoured.at),
    a company that OpenAI has a partnership with, Murati stammered, shook her head,
    and said that she would not "go into the details of the data that was used, but
    it was publicly available **or** licensed data" (emphasis mine). Shortly after
    the interview, Stern adds that OpenAI shared that Shutterstock's data was used
    to train Sora's models.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 斯特恩做得很好，迫使穆拉蒂回答问题，但令人深感担忧的是，这个全球最“重要”的AI公司的首席技术官竟然无法回答一个关于训练数据的非常基础的问题。[即使被问及是否使用Shutterstock的数据进行训练](https://youtu.be/mAUpxN-EIgU?t=297&ref=wheresyoured.at)，这是OpenAI与之合作的公司，穆拉蒂结结巴巴地摇头说，她不会“详细讨论使用的数据，但这些数据是公开可用的**或者**有许可的”（我加粗了重点）。采访后不久，斯特恩补充说，OpenAI分享了Shutterstock的数据被用于训练Sora的模型。
- en: '**Sidenote:** One very useful thing that Stern does in this interview is [break
    down exactly *how* Sora works](https://youtu.be/mAUpxN-EIgU?t=81&ref=wheresyoured.at)
    for the masses, defining that as the "AI model analyzing lots of videos and learning
    to identify objects and actions." This may seem like a small gesture, one problem
    that has poisoned reporting on generative AI is an unwillingness to clearly describe
    **how** these things work, instead referring to its actions as some sort of magical
    process done on a big, scary computer.'
  id: totrans-split-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**旁注：** 斯特恩在这次采访中做的一件非常有用的事情是[详细解释了*Sora如何运作*](https://youtu.be/mAUpxN-EIgU?t=81&ref=wheresyoured.at)，为大众定义了这个“AI模型分析大量视频并学习识别物体和动作”。这看起来可能是一个小小的举动，但报道生成AI的一个问题是不愿意清楚地描述这些东西是如何运作的，而是将其行为描述为在一个大型、可怕的计算机上完成的某种神秘过程。'
- en: 'This interview is important for a few reasons, but let''s start with the most
    obvious: the Chief Technology Officer of OpenAI either can''t or won''t explain
    what materials its video-creating generative AI was trained on. Throughout the
    interview she seemed lost, uneasy, unable to give many specifics about the product
    she was working on, describing everything in the broadest terms of "soon" and
    "eventually." Had this interview not pulled out such a useful conversation around
    training data, Murati would have told the world very little. Though Murati''s
    vagueness might be at the request of her public relations and legal counsel, I
    actually think it''s more likely that she realized, in real time, that she either
    didn''t know these answers or that the truth would be far more underwhelming (or
    troubling) than the world might like.'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这次采访因几个原因而重要，但让我们从最明显的地方开始：OpenAI的首席技术官要么不能要么不愿意解释其视频生成生成AI是在什么材料上进行训练的。在整个采访中，她似乎迷失、不安，无法提供关于她正在工作的产品的许多具体细节，描述一切都在“很快”和“最终”的最广泛的术语中。如果不是这次采访围绕训练数据展开了如此有用的对话，Murati将对世界讲得很少。尽管Murati的含糊可能是公共关系和法律顾问的要求，但我实际上认为更可能的是她实时意识到她要么不知道这些答案，要么真相远比世界想象的要平淡（或令人不安）。
- en: When asked whether it will be possible to fix Sora's videos after they've been
    generated, Murati said "eventually," and then couched that by saying "that's what
    we're trying to figure out...how to use this technology as a tool that people
    can edit and create with." She promised that there would "eventually" be "more
    steerability, control and accuracy...and reflecting of intent of what you want."
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当被问及是否可能在生成Sora视频后修复它们时，Murati说“最终”，然后解释说“我们正试图弄清楚……如何将这项技术用作人们可以编辑和创造的工具。”她承诺最终会有“更多的控制、准确性……和反映你想要的意图。”
- en: You'll "eventually" be able to add audio to Sora videos, and when asked when
    Sora's generative videos will be available to the public, she once again said
    "eventually," and when pushed said that Sora's launch would "definitely be this
    year, but could be a few months."
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你最终可以将音频添加到Sora视频中，并且当被问及Sora的生成视频何时会向公众开放时，她再次说“最终”，并在推动时表示Sora的发布“肯定会在今年，但可能还要几个月”。
- en: Murati, living in a world of "eventuallies," provided no technical insights,
    no specifics, and very few details.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: Murati生活在“最终”的世界中，没有提供技术见解，没有具体细节，也没有很多细节。
- en: These are the kind of interviews that only the most popular tech companies get
    — relatively shallow back-and-forths where nobody seems to be able to say "hey,
    what does that actually mean?" Murati was astonishingly unprepared to answer specific
    questions about the technology behind [the $80 billion startup](https://nytimes.com/2024/02/16/technology/openai-artificial-intelligence-deal-valuation.html?ref=wheresyoured.at)
    [she briefly ran](https://openai.com/blog/openai-announces-leadership-transition?ref=wheresyoured.at)
    and seemed rattled whenever she had to expand on anything beyond the most general
    talking points.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是只有最受欢迎的科技公司才会进行的访谈——相对表面的来回对话，似乎没有人能够说“嘿，那实际上是什么意思？”Murati在回答有关其技术背后的具体问题时毫无准备，似乎每当她需要扩展超出最一般化的谈论时都感到不安。
- en: While I generally loved how Stern approached this interview, I wanted to scream
    when she failed to push back [against Murati's claim](https://youtu.be/mAUpxN-EIgU?t=504&ref=wheresyoured.at)
    that she sees Sora as "a tool for extending creativity, and that OpenAI wants
    "people in the film industry, creators everywhere, to be part of informing" how
    OpenAI develops and deploys Sora. This is exactly the point at which you say "what
    exactly does that mean?" and "how have you done that in the past when it comes
    to image generation?"
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我通常喜欢Stern如何处理这次采访，但当她未能反驳[Murati的说法](https://youtu.be/mAUpxN-EIgU?t=504&ref=wheresyoured.at)，即她将Sora视为“扩展创造力的工具，并且OpenAI希望“电影行业的人士以及各地的创作者参与”OpenAI如何开发和部署Sora时，我感到非常沮丧。这正是你应该说“这到底是什么意思？”和“在过去，当涉及图像生成时，你是如何做到的？”
- en: The answer, of course, is that OpenAI has zero interest in talking to anyone
    in the film industry or any creators anywhere, and Murati should've been verbally
    flayed for suggesting otherwise. [While OpenAI has advertised positions for community
    specialists that would act as "ambassadors for OpenAI](https://qz.com/is-openai-extending-an-olive-branch-to-creators-and-wri-1851156896?ref=wheresyoured.at),"
    I see little evidence that OpenAI has any plans to help creators other than trying
    to convince them to use its tools.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，答案是 OpenAI 对与任何电影行业或任何创作者进行交流毫无兴趣，穆拉提因此提出这种建议本该受到口头上的严厉斥责。[虽然 OpenAI 已经为社区专家这类岗位招聘广告](https://qz.com/is-openai-extending-an-olive-branch-to-creators-and-wri-1851156896?ref=wheresyoured.at)，但我几乎看不到
    OpenAI 有任何帮助创作者的计划，除了试图说服他们使用其工具。
- en: This is, of course, all part of OpenAI's flowery, hollow playbook. [In a Daily
    Show interview from October 2022 (a full month before the launch of ChatGPT),](https://www.youtube.com/watch?v=Ba_C-C6UwlI&ref=wheresyoured.at)
    Murati told Trevor Noah that OpenAI sees tools like ChatGPT and DALL-E 2 as "[extensions
    of our creativity](https://youtu.be/Ba_C-C6UwlI?t=121&ref=wheresyoured.at)," [a
    direct copy-paste of the messaging that OpenAI uses on DALL-E's website](https://openai.com/blog/dall-e-2-extending-creativity?ref=wheresyoured.at).
    In a seven-minute-long interview, Murati debuts the talking points that have underpinned
    OpenAI's entire messaging strategy — misinformation bad, OpenAI good, some jobs
    will be lost, but it's good, because that's happened before. In an interview with
    Bloomberg's Emily Chang from July 2023, Murati describes her job as "[a combination
    of guiding the teams on the ground, thinking about long-term strategy, figuring
    out our gaps and making sure that the teams are well supported to succeed](https://youtu.be/p9Q5a1Vn-Hk?t=123&ref=wheresyoured.at),"
    and [says that one of the things she's most worried about is hallucinations](https://youtu.be/p9Q5a1Vn-Hk?t=324&ref=wheresyoured.at)
    (when a model authoritatively says something incorrect), a question that Chang
    fails to follow up with "so uh, how are you fixing that?"
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这一切都是 OpenAI 华丽空洞的套路。[2022 年 10 月的《每日秀》采访中（ChatGPT 发布一个月之前），](https://www.youtube.com/watch?v=Ba_C-C6UwlI&ref=wheresyoured.at)
    穆拉提告诉特雷弗·诺亚，OpenAI 视 ChatGPT 和 DALL-E 2 这类工具为 "[扩展我们创造力的延伸](https://youtu.be/Ba_C-C6UwlI?t=121&ref=wheresyoured.at)"，[直接复制粘贴了
    OpenAI 在 DALL-E 网站上使用的消息](https://openai.com/blog/dall-e-2-extending-creativity?ref=wheresyoured.at)。穆拉提在七分钟的采访中首次提出了支撑
    OpenAI 整个消息战略的谈话要点 —— 虚假信息不好，OpenAI 好，会有一些工作岗位流失，但这是好事，因为这种情况以前也发生过。在 2023 年 7
    月接受彭博的艾米丽·张采访时，穆拉提描述她的工作为 "[指导基层团队，思考长期战略，找出我们的不足之处，并确保团队得到良好支持以取得成功](https://youtu.be/p9Q5a1Vn-Hk?t=123&ref=wheresyoured.at)"，并且[她最担心的问题之一是幻觉](https://youtu.be/p9Q5a1Vn-Hk?t=324&ref=wheresyoured.at)（当一个模型权威地说错事情），这个问题张没有追问“所以，您是如何解决这个问题的？”。
- en: For [reasons that make less sense after his removal from OpenAI's board](https://www.semafor.com/article/11/19/2023/reid-hoffman-was-privately-unhappy-about-leaving-openais-board?ref=wheresyoured.at),
    Chang also speaks with billionaire investor Reid Hoffman, who suggests that [AI
    will be adopted "faster than iPhones'' and that there will be a "co-pilot for
    every profession](https://youtu.be/p9Q5a1Vn-Hk?t=694&ref=wheresyoured.at)." Chang
    weakly ripostes by laughing about her kids using ChatGPT to write papers, to which
    Hoffman retorts with his own version of "extending creativity," saying that the
    hope would be that the interaction with AI will teach students to "create much
    more interesting papers," a point at which Chang should have asked him *what that
    actually fucking means.*
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[从他被撤销 OpenAI 董事会成员资格之后就变得不那么合理的原因](https://www.semafor.com/article/11/19/2023/reid-hoffman-was-privately-unhappy-about-leaving-openais-board?ref=wheresyoured.at)，张也采访了亿万富翁投资者里德·霍夫曼，他建议[AI
    将被"比 iPhone 更快地"采用，并且每个职业将有"一个副驾驶"](https://youtu.be/p9Q5a1Vn-Hk?t=694&ref=wheresyoured.at)。张弱弱地以她的孩子们使用
    ChatGPT 写论文为例做了反驳，霍夫曼反驳道他自己的"扩展创造力"版本，表示希望与 AI 的互动将教育学生"创作更有趣的论文"，这时张本该问他“那到底是什么意思”。'
- en: While writing this piece, I took the time to watch several more interviews with
    Murati (and, indeed, OpenAI CEO Sam Altman), and for the most important company
    in Silicon Valley, there is very little fundamental explanation of why this technology
    matters, and what it actually does. In an interview with Joanna Stern at the Wall
    Street Journal's "Tech Live" event in October 2023, Sam Altman said that the thing
    that people really like about ChatGPT isn't that it "[knows particular knowledge](https://youtu.be/byYlC2cagLw?t=870&ref=wheresyoured.at),"
    but that it has this "larval reasoning capacity that's going to get better and
    better," and continues to mumble out an answer about how models will "set up all
    sorts of economic arrangements" that will have them explain *how* it will answer
    a question (?), before adding that "the fundamental thing about these models is
    not that they memorize a lot of data." Stern fails to push back here on numerous
    fronts — that "larval reasoning" is a completely meaningless term, and that, in
    general, Altman has failed to actually explain what he means.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: While writing this piece, I took the time to watch several more interviews with
    Murati (and, indeed, OpenAI CEO Sam Altman), and for the most important company
    in Silicon Valley, there is very little fundamental explanation of why this technology
    matters, and what it actually does. In an interview with Joanna Stern at the Wall
    Street Journal's "Tech Live" event in October 2023, Sam Altman said that the thing
    that people really like about ChatGPT isn't that it "[knows particular knowledge](https://youtu.be/byYlC2cagLw?t=870&ref=wheresyoured.at),"
    but that it has this "larval reasoning capacity that's going to get better and
    better," and continues to mumble out an answer about how models will "set up all
    sorts of economic arrangements" that will have them explain *how* it will answer
    a question (?), before adding that "the fundamental thing about these models is
    not that they memorize a lot of data." Stern fails to push back here on numerous
    fronts — that "larval reasoning" is a completely meaningless term, and that, in
    general, Altman has failed to actually explain what he means.
- en: This is the problem with powerful people in tech. If you allow them to speak
    and fill in the gaps for them, they will happily do so. Murati and Altman continuously
    obfuscate how ChatGPT works, what it can do, what it *could* do, and profit handsomely
    from a complete lack of pushback from a press that routinely accepts AI executives'
    vague explanations at face value. OpenAI's messaging and explanations of what
    its technology can (or will) do have barely changed in the last few years, returning
    repeatedly to "eventually" and "in the future" and speaking in the vaguest ways
    about how businesses make money off of — let alone *profit* from — integrating
    generative AI.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: This is the problem with powerful people in tech. If you allow them to speak
    and fill in the gaps for them, they will happily do so. Murati and Altman continuously
    obfuscate how ChatGPT works, what it can do, what it *could* do, and profit handsomely
    from a complete lack of pushback from a press that routinely accepts AI executives'
    vague explanations at face value. OpenAI's messaging and explanations of what
    its technology can (or will) do have barely changed in the last few years, returning
    repeatedly to "eventually" and "in the future" and speaking in the vaguest ways
    about how businesses make money off of — let alone *profit* from — integrating
    generative AI.
- en: Sam Altman is repeatedly given the ability to wax lyrical about the futuristic
    capabilities of artificial intelligence in a way that lets him paint a picture
    of a technology he is not actually building. Altman's fanciful claims include
    his kids "[having more AI friends than human friends](https://www.youtube.com/watch?v=PWBzXe0KAGo&ref=wheresyoured.at),"
    [that human-level AI is "coming" without ever specifying when](https://www.cnbc.com/2024/01/16/openais-sam-altman-agi-coming-but-is-less-impactful-than-we-think.html?ref=wheresyoured.at),
    [that AI will replace 95% of tasks performed by marketing agencies](https://www.cmswire.com/digital-marketing/sam-altman-ai-will-replace-95-of-creative-marketing-work/?ref=wheresyoured.at),
    [that ChatGPT will evolve in "uncomfortable ways,"](https://www.axios.com/2024/01/17/sam-altman-davos-ai-future-interview?ref=wheresyoured.at)
    [that AI will kill us all](https://www.cnn.com/2023/10/31/tech/sam-altman-ai-risk-taker/index.html?ref=wheresyoured.at),
    and that human beings are only separated from artificial intelligence because
    they "[really care what others think](https://futurism.com/altman-stumped-humans-better-ai?ref=wheresyoured.at)."
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: Sam Altman repeatedly given the ability to wax lyrical about the futuristic
    capabilities of artificial intelligence in a way that lets him paint a picture
    of a technology he is not actually building. Altman's fanciful claims include
    his kids "[having more AI friends than human friends](https://www.youtube.com/watch?v=PWBzXe0KAGo&ref=wheresyoured.at),"
    [that human-level AI is "coming" without ever specifying when](https://www.cnbc.com/2024/01/16/openais-sam-altman-agi-coming-but-is-less-impactful-than-we-think.html?ref=wheresyoured.at),
    [that AI will replace 95% of tasks performed by marketing agencies](https://www.cmswire.com/digital-marketing/sam-altman-ai-will-replace-95-of-creative-marketing-work/?ref=wheresyoured.at),
    [that ChatGPT will evolve in "uncomfortable ways,"](https://www.axios.com/2024/01/17/sam-altman-davos-ai-future-interview?ref=wheresyoured.at)
    [that AI will kill us all](https://www.cnn.com/2023/10/31/tech/sam-altman-ai-risk-taker/index.html?ref=wheresyoured.at),
    and that human beings are only separated from artificial intelligence because
    they "[really care what others think](https://futurism.com/altman-stumped-humans-better-ai?ref=wheresyoured.at)."
- en: Every time Sam Altman speaks he almost immediately veers into the world of fan
    fiction, talking about both the general things that "AI" could do and non-specifically
    where ChatGPT might or might not fit into that without ever describing a real-world
    use case. And he's done so in exactly the same way for years, failing to describe
    any industrial or societal *need* for artificial intelligence beyond a vague promise
    of automation and "models" that will be able to do stuff that humans can, even
    though OpenAI's models continually prove themselves unable to match even the dumbest
    human beings alive.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 每次 Sam Altman 发言几乎立即陷入幻想世界，谈论“AI”可能做的一般性事情，以及 ChatGPT 在其中可能或可能不适合的地方，却从未描述过一个真实世界的用例。多年来，他一直以完全相同的方式做到这一点，未能描述任何工业或社会对人工智能的*需求*，只是模糊地承诺自动化和“模型”将能够完成人类可以做的事情，尽管
    OpenAI 的模型始终证明自己甚至无法匹敌最愚蠢的活人的智能。
- en: Altman wants to talk about the big, sexy stories of Average General Intelligences
    that can take human jobs because the reality of OpenAI — and generative AI by
    extension — is far more boring, limited and expensive than he'd like you to know.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: Altman 想要谈论普通人工智能可以取代人类工作的大而性感的故事，因为 OpenAI 的现实 — 以及生成AI的延伸 — 比他想让你知道的要无聊、有限和昂贵得多。
- en: And I don't believe things are likely to improve.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我并不认为情况可能会有所改善。
- en: '**Limited Intelligence**'
  id: totrans-split-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**有限的智能**'
- en: Last week, [The Information published a story about Amazon and Google "tamping
    down generative AI expectations,"](https://www.theinformation.com/articles/generative-ai-providers-quietly-tamp-down-expectations?rc=kz8jh3&ref=wheresyoured.at)
    with these companies dousing their salespeople’s excitement about the capabilities
    of the tech they're selling. A tech executive is quoted in the article saying
    that customers are beginning to struggle with questions like "is AI providing
    value?" and "How do I evaluate how AI is doing," and a Gartner analyst told Amazon
    Web Services sales staff that the AI industry was "at the peak of the hype cycle
    around Large Language Models and other generative AI."
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: 上周，[The Information 发布了一篇关于亚马逊和谷歌“抑制生成AI期望”的报道](https://www.theinformation.com/articles/generative-ai-providers-quietly-tamp-down-expectations?rc=kz8jh3&ref=wheresyoured.at)，其中提到这些公司正在降低销售人员对其技术能力的兴奋情绪。文章中引述一位科技高管称客户开始遇到诸如“AI是否提供价值？”和“我如何评估AI的表现？”等问题，而一位Gartner分析师告诉亚马逊网络服务销售人员，AI行业正处于“大语言模型和其他生成AI周围的炒作周期的顶峰”。
- en: The article confirms many of my suspicions — that, as The Information wrote,
    "other software companies that have touted generative AI as a boon to enterprises
    are still waiting for revenue to emerge," citing the example of professional services
    firm KPMG buying 47,000 subscriptions to Microsoft's co-pilot AI "at a significant
    discount on Copilot's $30 per seat per month sticker price." Confusingly, KPMG
    bought these subscriptions despite not having gauged how much value its employees
    actually get out of the software, but rather to "be familiar with any AI-related
    questions its customers might have."
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 该文章证实了我对很多怀疑的肯定 — 正如 The Information 所写的那样，“其他软件公司宣称生成AI对企业是一大利好，但仍在等待收入的涌现”，并举例说明专业服务公司毕马威以显著折扣购买了
    Microsoft 的共同驾驶AI 的 47,000 个订阅，“这个订阅价格为每个席位每月 $30”，尽管毕马威购买这些订阅并没有衡量其员工实际从软件中获得多少价值，而是为了“熟悉客户可能提出的任何与AI相关的问题”。
- en: Salesforce CFO Amy Weaver said in its most recent earnings call that Salesforce
    was "not factoring in material contribution" from Salesforce's numerous AI products
    in its Financial Year 2025 guidance. [Software company Adobe's shares slid as
    the company failed to generate meaningful revenue from its AI products](https://www.marketwatch.com/story/adobes-stock-slides-toward-worst-day-in-18-months-as-ai-story-will-take-time-270668be?ref=wheresyoured.at),
    [with analysts worried about its ability to actually monetize any of the generative
    products it’s proliferating](https://www.investors.com/news/technology/adobe-stock-adbe-weak-forecast-ai-software/?ref=wheresyoured.at).
    [ServiceNow claimed in its earnings that generative AI was meaningfully contributing
    to its bottom line](https://siliconangle.com/2024/01/24/servicenow-beats-guidance-metrics-generative-ai-powers-strong-growth/?ref=wheresyoured.at),
    yet The Information's story quotes its Chief Financial officer Gina Mastantuono
    as saying that "[from a revenue contribution perspective, it's not going to be
    huge](https://www.theinformation.com/articles/generative-ai-providers-quietly-tamp-down-expectations?shared=3099fbb29357b1e5&rc=kz8jh3&ref=wheresyoured.at)."
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: Salesforce首席财务官Amy Weaver在其最近的盈利电话会议上表示，在其2025财年指导方针中，“不考虑Salesforce众多AI产品的实质性贡献”。软件公司Adobe的股票因未能从其AI产品中产生有意义的收入而下跌（[链接](https://www.marketwatch.com/story/adobes-stock-slides-toward-worst-day-in-18-months-as-ai-story-will-take-time-270668be?ref=wheresyoured.at)），[分析师对其实际如何赚钱担忧不已](https://www.investors.com/news/technology/adobe-stock-adbe-weak-forecast-ai-software/?ref=wheresyoured.at)。ServiceNow声称其盈利表现中生成AI的贡献是有意义的（[链接](https://siliconangle.com/2024/01/24/servicenow-beats-guidance-metrics-generative-ai-powers-strong-growth/?ref=wheresyoured.at)），然而《The
    Information》的报道援引其首席财务官Gina Mastantuono的话称“从收入贡献的角度来看，这并不会是很大的”。
- en: I believe a large part of the artificial intelligence boom is hot air, pumped
    through a combination of executive bullshitting and a compliant media that will
    gladly write stories *imagining* what AI can do rather than focus on what it's
    actually doing. Notorious boss-advocate Chip Cutter of the Wall Street Journal
    [wrote a piece last week about how AI is being integrated in the office](https://www.wsj.com/tech/ai/office-workers-artificial-intelligence-changes-86d8d4ab?mod=ai_more_article_pos7&ref=wheresyoured.at),
    spending most of the article discussing how companies "might" use tech before
    digressing that every company he spoke to was using these tools experimentally
    and that they kept making mistakes. [In an interview with Salesforce's head of
    AI Clara Shih](https://www.nytimes.com/2024/03/07/business/clara-shih-salesforce-artificial-intelligence.html?ref=wheresyoured.at),
    the New York Times failed to get her to say much of anything about what its AI
    products do, other than how its "Einstein Trust Layer" handles data, to which
    Shih added that AI would "be transformational for jobs, the way the internet was."
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为人工智能繁荣的很大一部分是热气，通过高管胡扯和愿意写关于*想象*人工智能能做什么的媒体来推动。《华尔街日报》著名的老板倡导者Chip Cutter上周撰写了一篇关于如何在办公室中整合AI的文章（[链接](https://www.wsj.com/tech/ai/office-workers-artificial-intelligence-changes-86d8d4ab?mod=ai_more_article_pos7&ref=wheresyoured.at)），在文章的大部分内容中讨论公司在实验性地使用这些工具，并且他们一直在犯错误。《纽约时报》在与Salesforce的AI负责人Clara
    Shih的采访中未能让她多谈一些关于其AI产品实际做了什么的内容（[链接](https://www.nytimes.com/2024/03/07/business/clara-shih-salesforce-artificial-intelligence.html?ref=wheresyoured.at)），只谈到了其“爱因斯坦信任层”如何处理数据，Shih补充道AI将“对职位产生变革，就像互联网一样”。
- en: The media has been fooled, in the same way they were fooled by the metaverse,
    by the specious promises of AI and the executives that champion it. The half-truths
    and magical thinking have spread far faster due to the fact that AI actually exists,
    and it's much easier to imagine how it might change our lives, even if the way
    it might do so is somewhere between improbable and impossible. It's easy to think
    that tasks like data-entry, or "boring" work can be easily-automated, and when
    you use ChatGPT, you can almost kind-of-sort-of see how that might happen, even
    if ChatGPT really can't do these things, all because ChatGPT was, at launch, able
    to do impressions of things that almost looked useful.
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 媒体被愚弄了，就像他们被虚拟现实愚弄一样，被AI和支持它的高管们的虚假承诺愚弄了。半真半假的宣传和神奇的想法因AI的实际存在而迅速传播开来，人们更容易想象它可能如何改变我们的生活，即使它可能在不太可能和不可能之间。很容易认为像数据输入或者“无聊”的工作这样的任务可以轻松自动化，当你使用ChatGPT时，你几乎可以有点儿看到它可能会发生的方式，即使ChatGPT实际上无法做到这些事情，仅仅因为ChatGPT在推出时能够做一些看起来几乎有用的事情的印象。
- en: As we speak, there are few if any meaningful improvements to our lives as a
    result of the last year's artificial intelligence boom. I just deleted a sentence
    where I talked about "the people I know who use ChatGPT," and realized that in
    the last year, I have met exactly one person who has — a writer that used it for
    synonyms.
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在谈论的时候，基于去年的人工智能繁荣，我们的生活并没有多少实质性的改善。我刚刚删除了一句话，谈到“我认识的使用ChatGPT的人”，意识到在过去的一年里，我只遇到了一个人——一位作家，他用它来找同义词。
- en: I can find no companies that have integrated generative AI in a way that has
    truly improved their bottom line other than Klarna, which claims its AI-powered
    support bot is "[estimated to drive a $40 million US in profit improvement in
    2024](https://www.klarna.com/international/press/klarna-ai-assistant-handles-two-thirds-of-customer-service-chats-in-its-first-month/?ref=wheresyoured.at),"
    which does not, as many have incorrectly stated, mean that it has "[made Klarna
    $40m in profit](https://www.inc.com/ben-sherry/klarna-says-its-new-ai-assistant-is-outperforming-customer-service-representatives.html?ref=wheresyoured.at)."
    Despite fears to the contrary, AI does not appear to be replacing a large number
    of workers, [and when it has](https://www.theverge.com/2020/5/30/21275524/microsoft-news-msn-layoffs-artificial-intelligence-ai-replacements?ref=wheresyoured.at),
    [the results have been pretty terrible](https://www.cnn.com/2023/11/02/tech/microsoft-ai-news/index.html?ref=wheresyoured.at).
    [A study from Boston Consulting Group](https://www.bcg.com/publications/2023/how-people-create-and-destroy-value-with-gen-ai?ref=wheresyoured.at)
    found that consultants that "solved business problems with OpenAI's GPT-4" performed
    *23% worse than those who didn't use it*, even when the consultant was warned
    about the limitations of generative AI and the risk of hallucinations.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我找不到任何一家公司真正通过集成生成式AI而显著改善其底线的例子，除了Klarna，后者声称其AI支持机器人在2024年将带来“4亿美元的利润改善”（https://www.klarna.com/international/press/klarna-ai-assistant-handles-two-thirds-of-customer-service-chats-in-its-first-month/?ref=wheresyoured.at），尽管许多人错误地认为这意味着它已经“让Klarna赚了4000万美元”（https://www.inc.com/ben-sherry/klarna-says-its-new-ai-assistant-is-outperforming-customer-service-representatives.html?ref=wheresyoured.at）。尽管存在相反的担忧，AI似乎并未取代大量工人，[即使有时候](https://www.theverge.com/2020/5/30/21275524/microsoft-news-msn-layoffs-artificial-intelligence-ai-replacements?ref=wheresyoured.at)，[结果也相当糟糕](https://www.cnn.com/2023/11/02/tech/microsoft-ai-news/index.html?ref=wheresyoured.at)。[波士顿咨询集团的一项研究](https://www.bcg.com/publications/2023/how-people-create-and-destroy-value-with-gen-ai?ref=wheresyoured.at)发现，那些“用OpenAI的GPT-4解决业务问题”的顾问的表现比那些没有使用它的顾问要*差23%*，即使事先警告过顾问有关生成式AI的局限性和幻觉风险。
- en: To be clear, I am not advocating for the replacement of workers with AI. I am,
    however, saying that if AI was actually capable of replacing the outputs of human
    beings — even if it was anywhere *near* doing so — any number of massive, scurrilous
    firms would be doing so at scale, and planning to do so more as models improved.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 明确地说，我并不主张用AI替代工人。然而，我确实在说，如果AI实际上能够替代人类的产出——即使它只是*接近*这样做——任何数量的大规模、诽谤性的公司都会在规模上这样做，并且会在模型改进时计划做得更多。
- en: Unless, of course, *it just wasn't possible.* What if what we're seeing today
    isn't a glimpse of the future, but the new terms of the present? What if artificial
    intelligence isn't actually capable of doing much more than what we're seeing
    today, and what if there's no clear timeline when it'll be able to do more? What
    if this entire hype cycle has been built, goosed by a compliant media ready and
    willing to take career-embellishers at their word?
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，*除非根本不可能*。如果今天我们所见到的不是未来的一个片段，而是当下的新常态呢？如果人工智能实际上并没有能力比我们今天所见到的更多，那又该怎么办？如果没有明确的时间表，它什么时候才能做更多呢？整个炒作周期是否都是建立在一个顺从的媒体之上，他们愿意相信职业炫耀者的话？
- en: Every single time I've read about the "amazing" things that artificial intelligence
    can do, I see somebody attempting to add fuel to a fire that's close to going
    out. While Joanna Stern may have said that Sora's generative video clips "[freaked
    her out](https://www.wsj.com/tech/personal-tech/openai-cto-sora-generative-video-interview-b66320bb?ref=wheresyoured.at),"
    much of what makes them scary is the assumption that OpenAI will fix hallucinations,
    something that the company has categorically failed to do. AI hype is predicated
    on solving problems with AI models that are only getting worse, and OpenAI's only
    answers are a combination of "we'll work it out eventually, trust me" and "we
    need a technological breakthrough in [chips](https://www.wsj.com/tech/ai/sam-altman-seeks-trillions-of-dollars-to-reshape-business-of-chips-and-ai-89ab3db0?ref=wheresyoured.at)
    and [energy](https://www.popsci.com/technology/sam-altman-age-of-ai-will-require-an-energy-breakthrough/?ref=wheresyoured.at)."
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 每当我读到人工智能可以做出“惊人”的事情时，我都会看到有人试图为即将熄灭的火添加燃料。尽管乔安娜·斯特恩可能已经说过，索拉的生成视频片段“让她感到恐惧”，但让人感到恐怖的大部分原因是OpenAI将修复幻觉的假设，而这家公司已经明确未能做到。人工智能的炒作建立在解决越来越糟糕的AI模型问题的基础上，而OpenAI的唯一答案是“我们最终会解决的，请相信我”和“我们需要在[芯片](https://www.wsj.com/tech/ai/sam-altman-seeks-trillions-of-dollars-to-reshape-business-of-chips-and-ai-89ab3db0?ref=wheresyoured.at)和[能源](https://www.popsci.com/technology/sam-altman-age-of-ai-will-require-an-energy-breakthrough/?ref=wheresyoured.at)技术上有所突破。”
- en: Generative AI's core problems — its hallucinations, its [massive energy](https://www.theverge.com/2023/10/10/23911059/ai-climate-impact-google-openai-chatgpt-energy?ref=wheresyoured.at)
    and [unprofitable compute demands](https://www.washingtonpost.com/technology/2023/06/05/chatgpt-hidden-cost-gpu-compute/?ref=wheresyoured.at)
    — are not close to being solved. Having now read and listened to a great deal
    of Murati and Altman's interviews, I can find few cases where they're even *asked*
    about these problems, let alone ones where they provide a cogent answer.
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI的核心问题——它的幻觉，其[巨大能耗](https://www.theverge.com/2023/10/10/23911059/ai-climate-impact-google-openai-chatgpt-energy?ref=wheresyoured.at)和[无利可图的计算需求](https://www.washingtonpost.com/technology/2023/06/05/chatgpt-hidden-cost-gpu-compute/?ref=wheresyoured.at)——尚未接近解决。我现在已经阅读和听了很多穆拉蒂和阿尔特曼的访谈，我几乎找不到一个案例，他们在这些问题上甚至被*问到*，更不用说他们提供了一个合理的答案。
- en: And I believe it's because there isn't one.
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信这是因为根本就没有一种解决方法。
- en: Generative AI models are expensive and compute-intensive without providing obvious,
    tangible mass-market use cases. Murati and Altman's futures depend heavily on
    keeping the world believing that development and improvement of their models'
    capabilities will continue a rapacious pace of progress that has unquestionably
    slowed, [with OpenAI admitting that GPT-4 may be worse on some tasks.](https://www.businessinsider.com/openai-gpt4-worse-on-some-tasks-chatgpt-2023-7?ref=wheresyoured.at)
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI模型在不提供明显、具体的大众市场应用案例的情况下，成本高昂且计算密集。穆拉蒂和阿尔特曼的未来在很大程度上取决于让世界相信，他们的模型能力的发展和改进将继续保持急迫的进展步伐，而这一步伐显然已经放缓，[OpenAI承认GPT-4在某些任务上可能更糟。](https://www.businessinsider.com/openai-gpt4-worse-on-some-tasks-chatgpt-2023-7?ref=wheresyoured.at)
- en: '[As I''ve written before](https://www.wheresyoured.at/sam-altman-fried/), hallucinations
    are a feature not a bug. These models do not "know" anything. They are mathematical
    behemoths generating a best guess based on training data and labeling, and thus
    do not "know" what you are asking it to do. You simply cannot fix them. Hallucinations
    are not going away.'
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[正如我之前所写的](https://www.wheresyoured.at/sam-altman-fried/)，幻觉不是bug而是一种特性。这些模型并不“知道”任何东西。它们是基于训练数据和标记生成的数学巨人，因此无法“知道”你要求它做什么。你根本无法修复它们。幻觉不会消失。'
- en: Every bit of excitement for this technology is based on the idea what it *might*
    do, which quickly becomes conflated with what it *could* do, allowing Altman —
    who is far more a marketing person than an engineer — to sell the dream of OpenAI
    based off of the least-specific promises since Mark Zuckerberg said we'd live
    in our Oculus headsets.
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对这项技术的每一丝激动都建立在它*可能*会做的事情的想法上，这很快就与它*能够*做的事情混为一谈，使得更多是营销人员而不是工程师的奥尔特曼能够基于最不具体的承诺来推销开放AI的梦想，就像马克·扎克伯格曾说过我们会生活在他们的Oculus头盔中一样。
- en: '**Altman, Freed**'
  id: totrans-split-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**奥尔特曼，弗里德**'
- en: I believe that Sam Altman has been tapdancing this entire time, hoping that
    he could amass enough power and revenue that his success would be inevitable.
    Yet his ultra-successful hype campaign was deeply specious, and he — along with
    the rest of the AI industry — has found himself suddenly having to deliver a future
    he's not even close to developing.
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信萨姆·奥尔特曼这段时间以来一直在跳脚舞，希望他能积累足够的权力和收入，以至于他的成功是不可避免的。然而，他极其成功的炒作活动却是深深的虚假，他和整个AI行业都突然发现自己必须提供一个他们甚至都没有接近开发的未来。
- en: What I fear isn't automation taking our jobs, but the bottom falling out of
    generative AI as companies realize that the best they're going to see is a few
    digits of profit growth. Companies like Nvidia, Google, Amazon, Snowflake and
    Microsoft have hundreds of billions of dollars of market capitalization — as well
    as expected revenue growth — tied into the idea that everybody will be integrating
    AI into everything, and that they will be doing so *more* than they are today.
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
  zh: 我担心的不是自动化夺走我们的工作，而是生成式AI的基础崩溃，因为公司们意识到他们最好能看到的只是少数几位数字的利润增长。像Nvidia、Google、Amazon、Snowflake和Microsoft这样的公司，它们的市值高达数千亿美元，以及预期的收入增长，都与这样一个理念紧密相关：每个人都将把AI整合到一切中，并且他们会比今天做得更*多*。
- en: If the AI bubble pops, the entire tech industry will suffer as venture capitalists
    are once again washed out through chasing an unprofitable, barely-substantiated
    trend. And again the entire industry suffers because people don't want to build
    new things or try new ideas, but fund the same people doing similar things again
    and again because it feels good to be part of a consensus, even if you're wrong.
    Silicon Valley will continually fail to innovate at scale until it learns to build
    real things again — things that people use because the things in question actually
    do something.
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果AI泡沫破裂，整个科技行业将遭受重创，因为风险投资家们再次通过追逐一种不盈利、几乎无根据的趋势而被淘汰。再次，整个行业受到影响，因为人们不想建立新事物或尝试新想法，而是愿意资助那些做着类似事情的同类人，因为成为共识的一部分感觉很好，即使你是错误的。直到硅谷再次学会构建真正的东西——人们因为这些东西确实有所作为而使用的东西——它才能在规模上实现创新。
- en: Altman needs us to build more efficient chips and "energy breakthroughs" because
    he knows, at his heart, that generative AI can neither fix its own problems nor
    develop much further without technology that doesn’t (and may never) exist. Murati's
    mealy-mouthed answers around "publicly-available data" heavily suggest that OpenAI's
    models are trained on YouTube and Facebook videos, meaning that any public launch
    of Sora will be one that's immediately met with an apocalyptic legal fight. How
    apocalyptic? Well,[a study from last week](https://www.cnbc.com/2024/03/06/gpt-4-researchers-tested-leading-ai-models-for-copyright-infringement.html?ref=wheresyoured.at)
    revealed that every single model produced copyrighted material, with OpenAI's
    GPT-4 producing it on 44% of the prompts constructed for the study, and [Nvidia
    is being sued by authors claiming its NeMo language model violates their copyright](https://www.engadget.com/now-its-nvidia-being-sued-over-ai-copyright-infringement-083407300.html?ref=wheresyoured.at).
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: 奥尔特曼需要我们构建更高效的芯片和“能源突破”，因为他深知，从本质上讲，生成式AI既无法解决自身的问题，也无法在没有（也许永远也不会有）这样的技术的情况下进一步发展。穆拉蒂在“公开数据”的含糊回答明显表明，OpenAI的模型是在YouTube和Facebook视频上进行训练的，这意味着Sora的任何公开发布都将立即引发一场末日般的法律斗争。多么末日呢？嗯，[上周的一项研究](https://www.cnbc.com/2024/03/06/gpt-4-researchers-tested-leading-ai-models-for-copyright-infringement.html?ref=wheresyoured.at)显示，每个模型都生成了受版权保护的材料，OpenAI的GPT-4在研究构建的44%提示中生成了这些材料，而[Nvidia因作者声称其NeMo语言模型侵犯版权而被起诉](https://www.engadget.com/now-its-nvidia-being-sued-over-ai-copyright-infringement-083407300.html?ref=wheresyoured.at)。
- en: Eventually, one of these companies will lose a copyright lawsuit, causing a
    brutal reckoning on model use across any industry that's integrated AI. These
    models can't really "forget," possibly necessitating a costly industry-wide retraining
    and licensing deals [that will centralize power in the larger AI companies that
    can afford them](https://hunterwalk.com/2024/02/23/every-time-openai-cuts-a-check-for-training-data-an-unlaunched-competitive-startup-dies-without-a-safe-harbor-ai-will-be-ruled-by-incumbents/?ref=wheresyoured.at).
    And in the event that Sora and other video models are actually trained on copyrighted
    material from YouTube and Instagram, there is simply no way to square that circle
    legally without effectively restarting training the model.
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，这些公司中的一家将输掉一场版权诉讼，导致所有整合了AI的行业都将面临残酷的使用模型审查。这些模型实际上无法真正"忘记"，可能需要进行昂贵的全行业重新培训和许可协议，[这将使权力集中在那些有能力承担这些成本的大型AI公司手中](https://hunterwalk.com/2024/02/23/every-time-openai-cuts-a-check-for-training-data-an-unlaunched-competitive-startup-dies-without-a-safe-harbor-ai-will-be-ruled-by-incumbents/?ref=wheresyoured.at)。而且，如果Sora和其他视频模型实际上是在YouTube和Instagram上的受版权保护的材料上训练的，从法律上讲，没有办法解决这个问题而不重新启动训练模型。
- en: Artificial Hype
  id: totrans-split-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工炒作
- en: Sam Altman desperately needs you to believe that generative AI will be essential,
    inevitable and intractable, because if you don't, you'll suddenly realize that
    trillions of dollars of market capitalization and revenue are being blown on something
    remarkably mediocre. If you focus on the present — what OpenAI's technology can
    do today, and will likely do for some time — you see in terrifying clarity that
    generative AI isn't a society-altering technology, but another form of efficiency-driving
    cloud computing software that benefits a relatively small niche of people.
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: 山姆·阿特曼迫切需要你相信生成式AI将是必不可少、不可避免且棘手的，因为如果你不这样做，你会突然意识到数万亿美元的市场资本化和收入正在被浪费在一些相当平庸的东西上。如果你专注于现在——OpenAI的技术今天能做什么，以及在相当长一段时间内可能会做什么——你会清楚地看到，生成式AI并不是一种改变社会的技术，而是另一种效率驱动的云计算软件，主要惠及相对较小的人群。
- en: If you stop saying things like "AI could do" or "AI will do," you have to start
    asking what AI *can* do, and the answer is...not that much, and not much more
    in the future. Sora is not going to generate movies. It's going to continue making
    horrifying human-adjacent creatures that walk like the AT-ATs from Star Wars,
    and cartoons that look remarkably like copyrighted material from YouTube.
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你停止说"AI可以做"或者"AI将会做"这样的话，你就必须开始问AI*能*做什么，答案是……不是很多，未来也不会多。Sora不会生成电影。它将继续制作类似于《星球大战》中AT-AT步行器那样的令人毛骨悚然的人类相似生物，以及看起来非常像YouTube上的受版权保护材料的卡通片。
- en: I believe that artificial intelligence has three quarters to prove itself before
    the apocalypse comes, and when it does, it will be that much worse, savaging the
    revenues of the biggest companies in tech. Once usage drops, so will the remarkable
    amounts of revenue that have flowed into big tech, and so will acres of data centers
    sit unused, the cloud equivalent of the massive overhiring we saw in post-lockdown
    Silicon Valley.
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我相信人工智能有三个季度的时间来证明自己，然后末日将降临，那时情况将更加糟糕，严重影响科技巨头的收入。一旦使用率下降，大科技公司注入的大量收入也将减少，数据中心的面积将无人使用，这相当于疫后硅谷的大规模过度招聘。
- en: I fear that the result could be a far worse year for the tech industry than
    we saw in 2023, one where the majority of the pain hits workers rather than the
    ghouls who inflated this perilous bubble.
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我担心的结果可能会比我们在2023年看到的对科技行业的痛苦更严重，其中大部分痛苦会影响到工人，而不是那些吹大这个危险泡沫的鬼怪。
