- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: æœªåˆ†ç±»'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: æœªåˆ†ç±»'
- en: 'date: 2024-05-29 12:30:08'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-29 12:30:08'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: A better Python cache for slow function calls
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæ›´å¥½çš„Pythonç¼“å­˜ç”¨äºç¼“æ…¢çš„å‡½æ•°è°ƒç”¨
- en: æ¥æºï¼š[https://docs.sweep.dev/blogs/file-cache](https://docs.sweep.dev/blogs/file-cache)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¥æºï¼š[https://docs.sweep.dev/blogs/file-cache](https://docs.sweep.dev/blogs/file-cache)
- en: <main class="nx-w-full nx-min-w-0 nx-max-w-6xl nx-px-6 nx-pt-4 md:nx-px-12">
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: <main class="nx-w-full nx-min-w-0 nx-max-w-6xl nx-px-6 nx-pt-4 md:nx-px-12">
- en: ğŸ“š Blogs
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ“š åšå®¢
- en: ğŸ“‚ A better Python cache for slow function calls
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: ğŸ“‚ ä¸€ä¸ªæ›´å¥½çš„Pythonç¼“å­˜ç”¨äºç¼“æ…¢çš„å‡½æ•°è°ƒç”¨
- en: A better Python cache for slow function calls
  id: totrans-split-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ä¸€ä¸ªæ›´å¥½çš„Pythonç¼“å­˜ç”¨äºç¼“æ…¢çš„å‡½æ•°è°ƒç”¨
- en: '**William Zeng** - March 18th, 2024'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**William Zeng** - 2024å¹´3æœˆ18æ—¥'
- en: '* * *'
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: We wrote a file cache - it's like Python's `lru_cache`, but it stores the values
    in files instead of in memory. This has saved us hours of time running our LLM
    benchmarks, and we'd like to share it as its own Python module. Thanks to [Luke
    Jaggernauth (opens in a new tab)](https://github.com/lukejagg) (former Sweep engineer)
    for building the initial version of this!
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ç¼–å†™äº†ä¸€ä¸ªæ–‡ä»¶ç¼“å­˜ - å®ƒç±»ä¼¼äºPythonçš„`lru_cache`ï¼Œä½†å®ƒå°†å€¼å­˜å‚¨åœ¨æ–‡ä»¶ä¸­è€Œä¸æ˜¯å†…å­˜ä¸­ã€‚è¿™ä¸ºè¿è¡Œæˆ‘ä»¬çš„LLMåŸºå‡†æµ‹è¯•èŠ‚çœäº†å¤§é‡æ—¶é—´ï¼Œå¹¶ä¸”æˆ‘ä»¬å¸Œæœ›å°†å…¶åˆ†äº«ä¸ºè‡ªå·±çš„Pythonæ¨¡å—ã€‚æ„Ÿè°¢[Luke
    Jaggernauth (åœ¨æ–°æ ‡ç­¾é¡µä¸­æ‰“å¼€)](https://github.com/lukejagg)ï¼ˆå‰Sweepå·¥ç¨‹å¸ˆï¼‰ä¸ºæ„å»ºæ­¤åˆå§‹ç‰ˆæœ¬è€Œæ„Ÿè°¢ï¼
- en: 'Here''s the link: [https://github.com/sweepai/sweep/blob/main/docs/public/file_cache.py
    (opens in a new tab)](https://github.com/sweepai/sweep/blob/main/docs/public/file_cache.py).
    To use it, simply add the `file_cache` decorator to your function. Here''s an
    example:'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™é‡Œæ˜¯é“¾æ¥ï¼š[https://github.com/sweepai/sweep/blob/main/docs/public/file_cache.py
    (åœ¨æ–°æ ‡ç­¾é¡µä¸­æ‰“å¼€)](https://github.com/sweepai/sweep/blob/main/docs/public/file_cache.py)ã€‚è¦ä½¿ç”¨å®ƒï¼Œåªéœ€å°†`file_cache`è£…é¥°å™¨æ·»åŠ åˆ°æ‚¨çš„å‡½æ•°ä¸­ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªç¤ºä¾‹ï¼š
- en: '[PRE0]'
  id: totrans-split-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Background
  id: totrans-split-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: èƒŒæ™¯
- en: We spend a lot of time prompt engineering our agents at Sweep. Our agents take
    a set of input strings, formats them as a prompt, then sends the prompt and any
    other information off to the LLM. We chain multiple agents to turn a GitHub issue
    to a pull request. For example, to modify code we'll input the old code, any relevant
    context, and instructions then output the new code.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬åœ¨SweepèŠ±è´¹å¤§é‡æ—¶é—´è¿›è¡Œpromptå·¥ç¨‹ã€‚æˆ‘ä»¬çš„agentsæ¥å—ä¸€ç»„è¾“å…¥å­—ç¬¦ä¸²ï¼Œå°†å®ƒä»¬æ ¼å¼åŒ–ä¸ºæç¤ºï¼Œç„¶åå°†æç¤ºå’Œä»»ä½•å…¶ä»–ä¿¡æ¯å‘é€ç»™LLMã€‚æˆ‘ä»¬é“¾æ¥å¤šä¸ªagentsæ¥å°†GitHubé—®é¢˜è½¬æ¢ä¸ºæ‹‰å–è¯·æ±‚ã€‚ä¾‹å¦‚ï¼Œè¦ä¿®æ”¹ä»£ç ï¼Œæˆ‘ä»¬å°†è¾“å…¥æ—§ä»£ç ã€ä»»ä½•ç›¸å…³ä¸Šä¸‹æ–‡å’ŒæŒ‡ä»¤ï¼Œç„¶åè¾“å‡ºæ–°ä»£ç ã€‚
- en: 'A typical improvement involves tweaking a small part of our pipeline (like
    improving our planning algorithm), then running the entire pipeline again. We
    use pdb (python''s native debugger) to set breakpoints and inspect the state of
    our prompts, input values, and parsing logic. For example, we can check whether
    a certain string matches a regex:'
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: å…¸å‹çš„æ”¹è¿›åŒ…æ‹¬è°ƒæ•´æˆ‘ä»¬ç®¡é“çš„ä¸€ä¸ªå°éƒ¨åˆ†ï¼ˆå¦‚æ”¹è¿›æˆ‘ä»¬çš„è§„åˆ’ç®—æ³•ï¼‰ï¼Œç„¶åå†æ¬¡è¿è¡Œæ•´ä¸ªç®¡é“ã€‚æˆ‘ä»¬ä½¿ç”¨pdbï¼ˆPythonçš„æœ¬åœ°è°ƒè¯•å™¨ï¼‰è®¾ç½®æ–­ç‚¹å’Œæ£€æŸ¥æˆ‘ä»¬çš„æç¤ºã€è¾“å…¥å€¼å’Œè§£æé€»è¾‘çš„çŠ¶æ€ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥æ£€æŸ¥æŸä¸ªå­—ç¬¦ä¸²æ˜¯å¦ä¸æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ï¼š
- en: '[PRE1]'
  id: totrans-split-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This lets us debug at runtime with the actual data.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨å®é™…æ•°æ®è¿è¡Œæ—¶è°ƒè¯•ã€‚
- en: Cached pdb
  id: totrans-split-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Cached pdb
- en: pdb works great, but we have to wait for the entire pipeline to run again. Imagine
    a version of pdb that not only interrupted execution, but also cached the entire
    program state up to that point. Our time to hit that same bug could be cut from
    10 minutes to 15 seconds (a 40x improvement).
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: pdbæ•ˆæœå¾ˆå¥½ï¼Œä½†æˆ‘ä»¬å¿…é¡»ç­‰å¾…æ•´ä¸ªç®¡é“å†æ¬¡è¿è¡Œã€‚æƒ³è±¡ä¸€ä¸ªpdbçš„ç‰ˆæœ¬ï¼Œä¸ä»…ä¸­æ–­æ‰§è¡Œï¼Œè€Œä¸”è¿˜ç¼“å­˜åˆ°è¯¥ç‚¹ä¸ºæ­¢çš„æ•´ä¸ªç¨‹åºçŠ¶æ€ã€‚æˆ‘ä»¬è§£å†³åŒæ ·çš„é”™è¯¯å¯èƒ½ä»10åˆ†é’Ÿç¼©çŸ­åˆ°15ç§’ï¼ˆæå‡40å€ï¼‰ã€‚
- en: We didn't build this, but we think our file_cache works just as well.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬æ²¡æœ‰æ„å»ºè¿™ä¸ªï¼Œä½†æˆ‘ä»¬è®¤ä¸ºæˆ‘ä»¬çš„`file_cache`åŒæ ·æœ‰æ•ˆã€‚
- en: LLM calls are slow but their inputs and outputs are easy to cache, saving a
    lot of time. We can use the input prompt/string as the cache key, and the output
    string as the cache value.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: LLMè°ƒç”¨è™½ç„¶æ…¢ï¼Œä½†å®ƒä»¬çš„è¾“å…¥å’Œè¾“å‡ºå¾ˆå®¹æ˜“ç¼“å­˜ï¼Œä»è€ŒèŠ‚çœäº†å¤§é‡æ—¶é—´ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¾“å…¥æç¤º/å­—ç¬¦ä¸²ä½œä¸ºç¼“å­˜é”®ï¼Œè¾“å‡ºå­—ç¬¦ä¸²ä½œä¸ºç¼“å­˜å€¼ã€‚
- en: What's different from lru_cache?
  id: totrans-split-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ä¸`lru_cache`æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ
- en: lru_cache is great for memoizing repeated function calls, but it doesn't support
    two key features.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`lru_cache`éå¸¸é€‚åˆå¯¹é‡å¤çš„å‡½æ•°è°ƒç”¨è¿›è¡Œè®°å¿†åŒ–ï¼Œä½†å®ƒä¸æ”¯æŒä¸¤ä¸ªå…³é”®åŠŸèƒ½ã€‚'
- en: we need to persist the cache between runs.
  id: totrans-split-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦åœ¨è¿è¡Œä¹‹é—´æŒä¹…åŒ–ç¼“å­˜ã€‚
- en: lru_cache stores the results in-memory, which means that the next time you run
    the program the cache will be empty. file_cache stores the results on disk. We
    also considered using Redis, but writing to disk is easier to set up/manage.
  id: totrans-split-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`lru_cache`å°†ç»“æœå­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œè¿™æ„å‘³ç€ä¸‹æ¬¡è¿è¡Œç¨‹åºæ—¶ç¼“å­˜å°†ä¸ºç©ºã€‚`file_cache`å°†ç»“æœå­˜å‚¨åœ¨ç£ç›˜ä¸Šã€‚æˆ‘ä»¬ä¹Ÿè€ƒè™‘è¿‡ä½¿ç”¨Redisï¼Œä½†å†™å…¥ç£ç›˜æ›´å®¹æ˜“è®¾ç½®/ç®¡ç†ã€‚'
- en: lru_cache doesn't support ignoring arguments that invalidate the cache.
  id: totrans-split-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`lru_cache`ä¸æ”¯æŒå¿½ç•¥ä½¿ç¼“å­˜æ— æ•ˆçš„å‚æ•°ã€‚'
- en: We'll use a custom `chat_logger` which stores the chats for visualization. It
    contains the current timestamp `chat_logger.expiration`, which will invalidate
    the cache if it's serialized.
  id: totrans-split-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å°†ä½¿ç”¨è‡ªå®šä¹‰çš„ `chat_logger`ï¼Œç”¨äºå¯è§†åŒ–å­˜å‚¨èŠå¤©è®°å½•ã€‚å®ƒåŒ…å«å½“å‰æ—¶é—´æˆ³ `chat_logger.expiration`ï¼Œå¦‚æœè¢«åºåˆ—åŒ–ï¼Œå°†ä½¿ç¼“å­˜æ— æ•ˆã€‚
- en: 'To counteract this we added ignored parameters, used like this: `file_cache(ignore_params=["chat_logger"])`.
    This removes `chat_logger` from the cache key construction and prevents bad invalidation
    due to the constantly changing `expiration`.'
  id: totrans-split-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æ·»åŠ äº†å¿½ç•¥çš„å‚æ•°ï¼Œä½¿ç”¨æ–¹å¼å¦‚ä¸‹ï¼š`file_cache(ignore_params=["chat_logger"])`ã€‚è¿™ä¼šä»ç¼“å­˜é”®çš„æ„å»ºä¸­ç§»é™¤
    `chat_logger`ï¼Œå¹¶é˜²æ­¢ç”±äºä¸æ–­å˜åŒ–çš„ `expiration` å¯¼è‡´çš„æ— æ•ˆç¼“å­˜ã€‚
- en: Implementation
  id: totrans-split-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å®ç°
- en: Our two main methods are `recursive_hash` and `file_cache`.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬çš„ä¸¤ä¸ªä¸»è¦æ–¹æ³•æ˜¯ `recursive_hash` å’Œ `file_cache`ã€‚
- en: recursive_hash
  id: totrans-split-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: recursive_hash
- en: We want to stably hash objects, and this is [not natively supported in python
    (opens in a new tab)](https://death.andgravity.com/stable-hashing).
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›ç¨³å®šåœ°å¯¹å¯¹è±¡è¿›è¡Œå“ˆå¸Œï¼Œè¿™åœ¨ [Python ä¸­å¹¶éåŸç”Ÿæ”¯æŒ (åœ¨æ–°æ ‡ç­¾é¡µæ‰“å¼€)](https://death.andgravity.com/stable-hashing)ã€‚
- en: '[PRE2]'
  id: totrans-split-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'hashlib.md5 alone doesn''t work for objects, giving us the error: `TypeError:
    object supporting the buffer API required`. We use recursive_hash, which works
    for arbitrary python objects.'
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: 'hashlib.md5 å•ç‹¬å¯¹å¯¹è±¡æ— æ•ˆï¼Œå¯¼è‡´é”™è¯¯ï¼š`TypeError: object supporting the buffer API required`ã€‚æˆ‘ä»¬ä½¿ç”¨
    `recursive_hash`ï¼Œå®ƒé€‚ç”¨äºä»»æ„çš„ Python å¯¹è±¡ã€‚'
- en: '[PRE3]'
  id: totrans-split-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: file_cache
  id: totrans-split-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: file_cache
- en: file_cache is a decorator that handles the caching logic for us.
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: file_cache æ˜¯ä¸€ä¸ªä¸ºæˆ‘ä»¬å¤„ç†ç¼“å­˜é€»è¾‘çš„è£…é¥°å™¨ã€‚
- en: '[PRE4]'
  id: totrans-split-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Without the cache, searching through the codebase using our LLM agent to get
    `top_results` takes 5 minutes - way too long if we're not actually testing it.
    Instead with file_cache, we just need to wait for deserialization of the pickled
    object - basically instantaneous for search results.
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œä½¿ç”¨æˆ‘ä»¬çš„ LLM ä»£ç†åœ¨ä»£ç åº“ä¸­æœç´¢ `top_results` éœ€è¦ 5 åˆ†é’Ÿ - å¦‚æœæˆ‘ä»¬å®é™…ä¸Šä¸åœ¨æµ‹è¯•ä¸­ï¼Œè¿™æ—¶é—´å¤ªé•¿äº†ã€‚ç›¸åï¼Œä½¿ç”¨
    file_cacheï¼Œæˆ‘ä»¬åªéœ€ç­‰å¾…æ‹¾å–å¯¹è±¡çš„ååºåˆ—åŒ– - å¯¹äºæœç´¢ç»“æœæ¥è¯´åŸºæœ¬ç¬é—´å®Œæˆã€‚
- en: Wrapper
  id: totrans-split-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: åŒ…è£…å™¨
- en: First we store our cache in `/tmp/file_cache`. This lets us remove the cache
    by simply deleting the directory (running `rm -rf /tmp/file_cache`). We can also
    selectively remove function calls using `rm -rf /tmp/file_cache/search_codebase*`.
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: é¦–å…ˆï¼Œæˆ‘ä»¬å°†ç¼“å­˜å­˜å‚¨åœ¨ `/tmp/file_cache` ä¸­ã€‚è¿™è®©æˆ‘ä»¬å¯ä»¥é€šè¿‡ç®€å•åˆ é™¤ç›®å½•ï¼ˆè¿è¡Œ `rm -rf /tmp/file_cache`ï¼‰æ¥åˆ é™¤ç¼“å­˜ã€‚æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨
    `rm -rf /tmp/file_cache/search_codebase*` æœ‰é€‰æ‹©åœ°ç§»é™¤å‡½æ•°è°ƒç”¨ã€‚
- en: '[PRE5]'
  id: totrans-split-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Then we can create a cache key.
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªç¼“å­˜é”®ã€‚
- en: Cache Key Creation / Miss Conditions
  id: totrans-split-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¼“å­˜é”®çš„åˆ›å»º / æœªå‘½ä¸­æ¡ä»¶
- en: 'We have another problem - we want to miss our cache under two conditions:'
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬è¿˜æœ‰å¦ä¸€ä¸ªé—®é¢˜ - æˆ‘ä»¬å¸Œæœ›åœ¨ä¸¤ç§æƒ…å†µä¸‹é”™è¿‡æˆ‘ä»¬çš„ç¼“å­˜ï¼š
- en: The arguments to the function change - handled by `recursive_hash`
  id: totrans-split-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: å‡½æ•°çš„å‚æ•°å˜åŒ–ç”± `recursive_hash` å¤„ç†
- en: The code changes
  id: totrans-split-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ä»£ç æ›´æ”¹
- en: To handle 2\. we used `inspect.getsource(func)` to add the function's source
    code to the hash, correctly missing the cache when the the code changes.
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸ºäº†å¤„ç†ç¬¬ 2 ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬ä½¿ç”¨ `inspect.getsource(func)` å°†å‡½æ•°çš„æºä»£ç æ·»åŠ åˆ°å“ˆå¸Œä¸­ï¼Œä»è€Œåœ¨ä»£ç æ›´æ”¹æ—¶æ­£ç¡®åœ°é”™è¿‡ç¼“å­˜ã€‚
- en: '[PRE6]'
  id: totrans-split-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-split-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Cache hits and misses
  id: totrans-split-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ç¼“å­˜å‘½ä¸­å’Œæœªå‘½ä¸­
- en: Finally we check cache key existence and write to the cache in the case of a
    cache miss.
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: æœ€åï¼Œæˆ‘ä»¬æ£€æŸ¥ç¼“å­˜é”®çš„å­˜åœ¨æ€§ï¼Œå¹¶åœ¨ç¼“å­˜æœªå‘½ä¸­çš„æƒ…å†µä¸‹å†™å…¥ç¼“å­˜ã€‚
- en: '[PRE8]'
  id: totrans-split-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Conclusion
  id: totrans-split-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ç»“è®º
- en: We hope this code is useful to you. We've found it to be a massive time saver
    when debugging LLM calls. We'd love to hear your feedback and contributions at
    [https://github.com/sweepai/sweep (opens in a new tab)](https://github.com/sweepai/sweep)!
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¸Œæœ›è¿™æ®µä»£ç å¯¹ä½ æœ‰ç”¨ã€‚æˆ‘ä»¬å‘ç°åœ¨è°ƒè¯• LLM è°ƒç”¨æ—¶ï¼Œå®ƒèƒ½å¤§å¤§èŠ‚çœæ—¶é—´ã€‚æˆ‘ä»¬å¾ˆä¹æ„å¬å–ä½ çš„åé¦ˆå’Œè´¡çŒ®ï¼Œç½‘å€æ˜¯ [https://github.com/sweepai/sweep
    (åœ¨æ–°æ ‡ç­¾é¡µæ‰“å¼€)](https://github.com/sweepai/sweep)!
- en: </main>
  id: totrans-split-58
  prefs: []
  type: TYPE_NORMAL
  zh: </main>
