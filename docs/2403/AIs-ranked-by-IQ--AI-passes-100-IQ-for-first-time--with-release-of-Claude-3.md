<!--yml

category: 未分类

date: 2024-05-27 14:40:22

-->

# AI按IQ排名；AI首次通过100 IQ，随着Claude-3的发布

> 来源：[https://www.maximumtruth.org/p/ais-ranked-by-iq-ai-passes-100-iq](https://www.maximumtruth.org/p/ais-ranked-by-iq-ai-passes-100-iq)

上周，我**[写了](https://www.maximumtruth.org/p/top-ais-still-fail-iq-tests)**关于我如何给AI进行矩阵IQ测试，以及它们全部未通过不同的测试。

但我也注意到，在阅读ChatGPT-4的答案时，有时它使用了正确的逻辑，但仍然答错，因为它误读了图像。

这引发了一个问题：在测试中，它的失败部分是由于“错误的思维”还是仅仅是“错误的视觉”？

为了回答这个问题，我创建了一个挪威门萨35题矩阵式IQ测试的口头翻译——我的目标是准确描述每个问题，使一个聪明的盲人在理论上能够准确地绘制问题（详细示例见下文）。

当ChatGPT-4以*文字*形式描述矩阵时，它终于得到了可以评分的IQ！

我向它进行了挪威门萨测试两次，平均每35个问题中回答了13个正确，这得出一个IQ估计值为***85***。

我还为其他AI运行了测验，以下是我得到的结果：

2024年3月进行的测试。IQ测试为挪威门萨，所有问题都像给一个盲人做测试一样口头描述。右侧的列显示AI在超过70个问题（两次测试）中比随机猜测者做得更好的百分比，平局不计入。

每个AI都进行了两次测试，以减少方差。“正确问题”是指两次测试中正确问题的平均数量。

尽管挪威门萨拒绝对85以下的分数进行评分，但我注意到在该范围内每个问题的IQ分数是3分。因此，我用这个来估算85以下的分数。这对挪威门萨来说不够正统，但我认为这是值得计算的。只需理解随机猜测可以得到63.5分——这应该被理解为基准，一个AI可以期望的简单事实是它意识到被要求选择一个字母，并吐出一个。

如果你更喜欢一个更具体的度量标准，可以看看原始的“正确问题”列，或者最后一列，它显示AI比随机猜测者表现更好的概率（我通过模拟了一百万次随机猜测者参加测试得出的结果；该列中的数字显示AI在模拟中超过的百分比。）

我制作了这个排名，因为我觉得它很迷人。

它帮助我知道哪些AI对我来说最有生产力。

它还帮助我思考AI的能力和AI的存在风险。

我已经对ChatGPT-4如何从“无法评分”到85 IQ印象深刻，之前我在写这篇文章时，克劳德-3 *昨天*发布。

我对它的分数感到惊讶。

另外，看看这一致的进展：

+   克劳德-1几乎不比随机更好。它答对了6个问题，智商约为64。

+   克劳德-2每次测试额外获得6个分数（约值~18智商点）。

+   克劳德-3获得*又一个*6.5分，约值更高的19智商点，超过人类平均水平。

对称增长使我想知道Anthropic是否根据与这一智商度量密切相关的内部基准发布版本。

现在让我们考虑各个版本的发布日期：

一个非常简单的推测表明，因此我们应该预计在12 - 16个月内得到克劳德-4，并且它每次测试应该能答对大约25个问题，智商得分为120。

在此之后，再过16 - 32个月，克劳德-5应该能答对大约31个问题，智商大约为140点。

在此之后，再过20 - 64个月，克劳德-6应该能答对所有问题，并且比几乎所有人都更聪明。总计4 - 10年的时间相加所有时间段。

当然，这种进展并非板上钉钉。Anthropic可能会遇到预算限制、能源限制、监管限制等问题。

**[摩尔定律的无情进步](https://twitter.com/Jotto999/status/1762882873219043683)** — 根据这个定律，自计算机问世以来，每隔*两年*，计算能力每单位面积翻倍一次，这一模式有很大概率继续存在。

社会是否准备好接受一年左右就能拥有120智商的AI？再过几年就能拥有140智商的AI？那**[可能不会结束世界](https://www.maximumtruth.org/p/reasons-why-ai-probably-wont-kill)**，因为这不仅仅需要原始智能，但它肯定会显著改变生活。

我将使用这个排名来指导我应该花时间进行实验的AI选择。

显然，克劳德是最聪明的AI（在昨天发布时），但在那之前，ChatGPT显然是领头羊。

一旦OpenAI发布基于ChatGPT-4的下一版本，根据ChatGPT-3.5和ChatGPT-4的测试能力差异，我预计其智商约为106。

我对微软必应的表现并不*糟糕*感到惊讶，排在克劳德和ChatGPT之后的第三位。但也许我不应该感到惊讶，因为微软拥有使用OpenAI技术的权利。

谷歌在大公司中落后，但并非*那么*落后。我很高兴他们在滑落，因为它们似乎特别**[有偏见](https://www.maximumtruth.org/p/the-dawn-of-woke-ai)**。我不知道为什么Gemini Advanced与Gemini非Advanced相比并没有更好（技术上稍逊一筹）。

另一方面，我喜欢埃隆·马斯克，但这种评分让我想知道他是否只是拿了开源的Llama-2，然后随意地冠名为“Grok”。我希望他的团队从此处改进它！

让我们从第2个问题开始，因为这是最简单的讨论：

有趣的事实：在我上一篇文章的初始版本中，我正确描述了正确答案（“一个有三角形的正方形”），然后我称那个答案为“B”。当你给ChatGPT喂图像问题时，他经常犯同样的错误！答案是E。

这是对AI（和人类）来说非常简单的问题之一，但是当我把图像输入到Claude-3时，它错误地说：

> 正确答案是 C。... 顶行将圆圈与各种形状结合起来，***[错误。它将4个点与各种形状结合起来]*** 中间行将四角星与这些形状***[正确]**,* 而底行应该将菱形与这些形状结合***[奇怪的措辞]**.* 每列中的形状进展是圆圈、加号、菱形***[正确]**.* 因此，缺失的模式应该是在加号上方***[不是！]*** 放置一个菱形***[是]***，这与答案选择 C 相匹配***[不对。]***

但是如果我将这个图像翻译成这个（我们习惯于通过视觉方式处理这些事情，这样读起来很麻烦）：

> ###### 2.
> ###### 
> ###### 下面是一个谜题的口头描述，由一个 3x3 的网格组成，右下角方块为空。请考虑模式并确定填入空方块的适当答案。
> ###### 
> ###### 第一行，第一列：四个小黑点放在一个大想象的正方形的角上。里面是一个中心的空心圆。
> ###### 
> ###### 第一行，第二列：四个小黑点放在一个大想象的正方形的角上。里面是中心的加号。
> ###### 
> ###### 第一行，第三列：四个小黑点放在一个大想象的正方形的角上。里面是一个中心的空心菱形。
> ###### 
> ###### 第二行，第一列：一个大空心的四角星状形状，中心是一个空心圆。
> ###### 
> ###### 第二行，第二列：一个大空心的四角星状形状，中心是一个加号。
> ###### 
> ###### 第二行，第三列：一个大空心的四角星状形状，中心是一个菱形。
> ###### 
> ###### 第三行，第一列：一个大空心的正方形，中心是一个空心圆。
> ###### 
> ###### 第三行，第二列：一个大空心的正方形，中心是一个加号。
> ###### 
> ###### 第三行，第三列：[这里应该放什么？请从下面的答案中选择。]
> ###### 
> ###### 答案选项：
> ###### 
> ###### 选项 A：一个大空心的正方形，中心是一个空心圆。
> ###### 
> ###### 选项 B：一个大空心的正方形和一个大空心的四角星状形状重叠。
> ###### 
> ###### 选项 C：一个大空心的正方形，中心是一个加号。
> ###### 
> ###### 选项 D：一个大空心的正方形。
> ###### 
> ###### 选项 E：一个大空心的正方形，中心是一个空心菱形。
> ###### 
> ###### 选项 F：一个大空心的正方形，上面有黑点。
> ###### 
> ###### 哪个答案是正确的？

这是 Claude-3 的答案：

> 正确答案是选项 E：一个大空心的正方形，中心是一个空心菱形。
> 
> 谜题中的模式是：
> 
> 1.  每行的外部形状是一致的：第一行是点，第二行是星星，第三行是正方形。
> 1.  
> 1.  每一列内部形状变化一致：第一列是圆圈，第二列是加号，第三列是菱形。

完美。

Microsoft的Bing Copilot在这个问题上真的让我惊讶...它决定要超水平，不仅回答问题，而且使用ASCII艺术重新创建了视觉问题：

它基本上画得很正确！（除了第二行每个框里放了两个点/加号/菱形之外。但这没有影响它的答案。）

现在假设我们跳到第27题，其中一个较难的问题：

我认为答案是“A”，因为我看到一种向上左斜对角的模式，其中角度的方向保持不变，但随着向上和向左的移动而变宽。也许这种模式在向右下方环绕到低右...

这是Claude-3对口头翻译的回答：

> 行模式：
> 
> 1.  在第一行，剪刀的方向顺时针旋转（左，上，右），角度递减（60°，90°，30°）。***[递减似乎不太合适]***
> 1.  
> 1.  在第二行，剪刀的方向也顺时针旋转（下，左，上），角度增加（90°，30°，60°）。***[增加似乎不太合适]***
> 1.  
> 1.  在第三行，剪刀的方向继续顺时针旋转（右，下），角度交替变化（30°，60°）。
> 1.  
> 列模式：
> 
> 1.  在第一列，剪刀的方向交替变化（左，下，右），角度递减（60°，90°，30°）。
> 1.  
> 1.  在第二列，剪刀的方向逆时针旋转（上，左，下），角度保持不变（90°，30°，60°）。
> 1.  
> 1.  在第三列，剪刀的方向交替变化（右，上），角度递减（30°，60°）。
> 1.  
> 基于这些模式，第三行第三列的缺失方块应该有：
> 
> +   剪刀的方向指向左，遵循第三列的交替***[更准确地说是“逆时针”]***模式和第三行的顺时针旋转。
> +   
> +   一个90度的角度，遵循第三列的递减模式（30°，60°，90°）***[是的]***和第一行的顺序（60°，90°，30°）。***[我觉得应该谈论第三行的模式?]***
> +   
> 因此，正确答案是选项A ***[是的]***：类似于指向左的剪刀手形状的符号。两个剪刀手之间的夹角是90度。角度的中心正好指向左方。***[是的，描述准确]***

看起来它大部分时间知道自己在做什么，尽管还是有些失误。但这也是测试中的难题之一。

这是Claude-3正确回答的问题分布情况的样子：

我们可以清楚地看到，它在回答较简单的问题时表现很好，直到第18题为止。之后，模式变得对它（以及大多数人）来说太复杂了。

这与其需要更多“脑力”来处理可能具有多层次复杂模式的观点是一致的。

想看看它与 Claude-2 的比较，后者也接受了完全相同的测试？

现在，Claude-1 呢？

AI 性能的巨大提升是不可否认的。

AI在“思考”吗？它肯定在进行某种形式的问题解决，以应对其数据库中不存在的新挑战。在某个特定点上，它用来预测下一个词的**[模式匹配技术](https://www.understandingai.org/p/large-language-models-explained-with)**变得如此强大，以至于它确实*看起来像是在思考*，并具有某种空间模式的感知能力，这可以从AI解决问题的方式中看到。

顺便说一下，这是ChatGPT-4，它是亚军：

还有 ChatGPT-3，除了第一个问题和可能的第18个问题外，大概基本都是随机猜测得来的：

我之前的帖子提出了相反的想法，但基于以上情况，我不得不改变我的看法（对于这个快速的改变表示抱歉！）。从以上来看，我认为AI具有一种超越仅仅拥有大型数据库的智能，此外，我们可以利用这一点来衡量AI进展的迅速性。它让我们对未来几年内如果这种进展继续下去，世界将会有很大的不同有了一种感觉。

AIs 在视觉方面仍然落后。人们预计随着更多计算能力的加入，这种情况将得到改善——正如上篇文章所示，ChatGPT-4 已经展示了一些能力，能够阅读未经翻译的智商测试问题。

当我们考虑是否应该担心AI“接管世界”之类的问题时，直到AI能够通过仅仅看一眼就能始终正确回答几乎每一个问题——而不是为盲目机器人提供特殊的适应性设施时，这可能并不是一个现实的关注点。

以上，对当前增长率的简单推断表明，Claude-6 将能够准确回答所有智商问题，并且比几乎所有人都更聪明，大约在 4 到 10 年内。

我很好奇看看这是否会实现。我认为通过测量未来几个月和几年内AI的智能水平，我们将对其是否在正轨上有一个相当好的判断——因此，MaximumTruth.org 将会做到这一点，以保持我们所有人的信息更新！

AI 的进展增加了未来可能结果的方差。没有AI，世界将保持一种相对稳定的轨迹，我们可以根据历史来进行一定程度的预测。

有了AI，世界上可能有几个百分点的机会AI会消灭所有人。但也有非零的机会，AI可能能帮助人们发明更好的医学和寿命延长技术，完成我们所有的工作，并普遍将我们带入一个今天的人们会视为“后稀缺社会”的社会。

鉴于此，暂且不论伦理问题一分钟，我认为有些事情对个人来说是有意义的（显然不要过分认真）：

— 投资于 AI 公司，根据这样的逻辑，如果 AI 真的开始主导经济，你希望拥有其中的一小部分股份。尽管价格已经上涨，但像英伟达这样的公司的市盈率实际上并不*那么*高。（这不是投资建议，但我已经投了一些钱。）

— 存钱以备未来可能的退休年代似乎没有多大意义，因为死亡的可能性要么更高，要么到时候根本不需要钱。**所以活在当下，今天多花一点钱**（从技术经济学的角度来说，“提高你的贴现率”。）

— **减少身体风险**。假设 AI 毁灭世界的可能性为 5%，而它发明新技术让任何人可以活到 1000 岁的可能性也是 5%。如**[未来战略家詹姆斯·米勒](https://twitter.com/JimDMiller)**指出，负面可能性会使中年寿命的预期长度减少大约 2 年，但正面可能性会增加 50 年（1000 的 5%）。所以在 AI 真正起飞之前，不让自己被杀可能会有更多的价值。

这些只是我的一些思考，不要太认真对待。

感谢您阅读《Maximum Truth》。这篇文章是公开的，欢迎分享。

[分享](https://www.maximumtruth.org/p/ais-ranked-by-iq-ai-passes-100-iq?utm_source=substack&utm_medium=email&utm_content=share&action=share)
