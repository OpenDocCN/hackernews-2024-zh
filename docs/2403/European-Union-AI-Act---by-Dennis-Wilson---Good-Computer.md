<!--yml

category: 未分类

date: 2024-05-27 15:04:59

-->

# 欧盟AI法案 - 作者：Dennis Wilson - Good Computer

> 来源：[https://goodcomputer.substack.com/p/european-union-ai-act](https://goodcomputer.substack.com/p/european-union-ai-act)

```
"Thou shalt not make a machine in the likeness of a human mind." - Frank Herbert, Dune
```

如何治理一种定义不清、快速变化、可能有能力摧毁整个人类社会、同时也可能极大帮助人类社会的技术？你是禁止它，忽略可能的好处，还是让它在没有任何防护措施的情况下发展，无视其带来的损害？

上周，欧盟在 [EU AI Act](https://artificialintelligenceact.eu/) 中迈出了回答这些问题的重要一步。该法案旨在保护个人权利，确保AI以安全和尊重人权的方式使用。在这篇文章中，我将探讨这一法案的关键思想，并认为它是未来治理的良好基础框架。

首先，根据欧盟，AI究竟是什么？

```
'AI system' is a machine-based system designed to operate with varying levels of autonomy and that may exhibit adaptiveness after deployment and that, for explicit or implicit objectives, infers, from the input it receives, how to generate outputs such as predictions, content, recommendations, or decisions that can influence physical or virtual environments
```

这个定义中的几乎每个词都可以（而且确实已经并将会）被争议，但我想关注的是其范围。该法案被设计成具有未来性，并且定义涵盖了广泛的技术范围。[早期的定义](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A52021PC0206)依赖于一个明确列出的技术清单，从“机器学习方法”到“贝叶斯估计”，这让一些统计学家感到恐慌，他们突然发现自己在从事AI。我们不知道AI将来会使用什么技术或者我们将用什么奇怪的名字来称呼它们，所以有一个明确的列表并不是一个好主意。最终的定义是开放的，甚至可能过于开放 - 现在一个根据输入生成不同输出的数据库查询是否也算AI？如果私营部门和新闻炒作周期是可信的，那么一切都变成了AI，甚至那些明显不是AI的东西。在这个阶段，一个广义的法律定义更为合适，因为它能为更多的立法提供支持，并能够加以完善。

当涉及到AI的应用时，该法案要求更为明确。该法案基于风险，即监管水平将取决于技术所带来的风险程度。风险被定义为“损害发生的概率与其严重程度的组合”，并分为四个类别：不可接受的、高风险的、低风险的和极小风险的。不可接受风险的系统被禁止，高风险系统受到严格监管，低风险系统主要要求透明度，而极小风险系统几乎不受监管。

禁止应用是相当严厉的措施，仅适用于最危险的情况。例如，[社会评分系统](https://www.technologyreview.com/2022/11/22/1063605/china-announced-a-new-social-credit-law-what-does-it-mean/)，[评估个人犯罪风险](https://www.wired.com/story/doj-predictive-policing-lawmakers-demand/)，[面部识别](https://www.cnil.fr/en/facial-recognition-20-million-euros-penalty-against-clearview-ai)，[生物特征分类如种族歧视](https://arstechnica.com/information-technology/2016/03/facebooks-ad-platform-now-guesses-at-your-race-based-on-your-behavior/)，以及工作场所或教育机构中的[情感识别](https://patents.google.com/patent/US10496947B1/en)。这些不是抽象的例子；这些都是已经开发或使用的技术。我想我将不得不寻找替代方案，以避免监控学生面部的[视频监控](https://www.youtube.com/watch?v=UHdrxHPRBng)，或者让他们佩戴[脑波追踪器](https://www.youtube.com/watch?v=JMLsHI8aV0g)以了解他们是否在注意力集中。

高风险人工智能系统是第二类别，并不被禁止，但受到严格监管。这些系统涉及安全性问题，用于关键应用或者对个人进行分析。这些系统的提供者必须证明他们通过提供文档、设计允许人类监督的系统以及公开系统及其数据来管理高风险。这类系统的一个例子是自动化招聘软件，这是一个充满问题（[成长中](https://www.findem.ai/)，[市场](https://clickup.com/home-1)），其中存在[偏见](https://www.bbc.com/worklife/article/20240214-ai-recruiting-hiring-software-bias-discrimination)和[透明度缺失](https://www.forbes.com/sites/forbestechcouncil/2023/09/25/ai-bias-in-recruitment-ethical-implications-and-transparency/)的问题。另一个例子是医疗设备，面临着从人工智能中获益的[巨大潜力](https://www.theparliamentmagazine.eu/news/article/hitech-health-how-artificial-intelligence-is-revolutionising-healthcare)和[许多潜在风险](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9908503/)。这些高风险应用最有可能成为未来诉讼的对象，该法案通过为这些系统设定遵从标准来为此类诉讼提供框架。

一个广受争议的问题是[生成型AI的监管](https://www.nature.com/articles/d41586-024-00497-8)，如ChatGPT。这些技术被分为两个层次。第一层包括所有除仅用于研究或[在开源许可下发布](https://www.euronews.com/next/2024/02/20/open-source-vs-closed-source-ai-whats-the-difference-and-why-does-it-matter)之外的通用模型。这些模型将受到透明度要求的约束，包括详细说明其训练方法和能源消耗，并必须证明它们[遵守版权法](https://www.euronews.com/next/2024/01/09/openai-says-its-impossible-to-train-ai-without-copyrighted-materials)。版权问题已成为[美国诸多持续进行的诉讼](https://www.thefashionlaw.com/from-chatgpt-to-deepfake-creating-apps-a-running-list-of-key-ai-lawsuits/)的争论焦点，并将对像[OpenAI](https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html)和[Stable Diffusion](https://arstechnica.com/tech-policy/2023/04/stable-diffusion-copyright-lawsuits-could-be-a-legal-earthquake-for-ai/)这样的公司造成问题。第二和更严格的层次将覆盖被认为具有“高影响能力”的通用模型，这些模型对“系统风险”造成更高的威胁，如ChatGPT这样的大型语言模型。尽管初步，处理生成型AI的方式在技术快速发展的背景下已经做得令人印象深刻。

该行为明确遵循，并设计与[《通用数据保护条例（GDPR）》](https://gdpr.eu/)一同运作，这是一项旨在保护欧盟个人隐私和个人数据的法律，于2016年通过，并自2018年生效。自2018年以来，GDPR已通过[法院案例](https://www.fieldfisher.com/en/insights/the-cjeus-judgement-in-meta-platforms-inc-v-bundekartellamt-the-spotlight-on-lawful-bases-for-processing-data)和对[罚款的执行](https://www.laquadrature.net/2021/07/30/amende-de-746-millions-deuros-contre-amazon-suite-a-nos-plaintes-collectives/)进行了完善和解释。例如，关于在欧盟和美国之间转移的数据保护问题已被广泛[讨论](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A62014CJ0362)。尽管2016年GDPR的原文并非欧盟数据隐私的最终立场，但它是欧洲机构为保护个人隐私和数据采取行动的必要第一步。其后，许多其他国家已经采纳或正在考虑[类似的法律](https://biblio.ugent.be/publication/8726790/file/8726791.pdf)。

欧洲人工智能法案（[AI act](https://artificialintelligenceact.eu/ai-act-implementation-next-steps/)）只是欧盟调整和解释人工智能规则的开端。欧盟成员国现在需要签署它，即使如此，它也不会立即生效。就像GDPR一样，AI法案将通过法庭案件和法规的适用进行讨论和辩论。立法进展缓慢，而数字技术往往[速度快、容易破坏](https://www.businessinsider.com/mark-zuckerberg-on-facebooks-new-motto-2014-5?r=US&IR=T)。鉴于人工智能领域的快速进展，现在采取这一第一步是必要的。确保人工智能的发展安全且尊重人权是一项艰巨的任务，但这一法案是朝正确方向迈出的重要一步。
