- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 15:04:25'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 15:04:25'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Introducing Stable Video 3D: Quality Novel View Synthesis and 3D Generation
    from Single Images — Stability AI'
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Introducing Stable Video 3D: Quality Novel View Synthesis and 3D Generation
    from Single Images — Stability AI'
- en: 来源：[https://stability.ai/news/introducing-stable-video-3d](https://stability.ai/news/introducing-stable-video-3d)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://stability.ai/news/introducing-stable-video-3d](https://stability.ai/news/introducing-stable-video-3d)
- en: '*SV3D takes a single object image as input and output novel multi-views of
    that object. We can then use those novel-views and SV3D to generate 3D meshes.*'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*SV3D以单个对象图像作为输入，并输出该对象的新视角。然后，我们可以使用这些新视角和SV3D来生成3D网格。*'
- en: When we released [Stable Video Diffusion](https://stability.ai/news/stable-video-diffusion-open-ai-video-model),
    we highlighted the versatility of our video model across various applications.
    Building upon this foundation, we are excited to release Stable Video 3D. This
    new model advances the field of 3D technology, delivering greatly improved quality
    and multi-view when compared to the previously released [Stable Zero123](https://stability.ai/news/stable-zero123-3d-generation),
    as well as outperforming other open source alternatives such as [Zero123-XL](https://objaverse.allenai.org/docs/zero123-xl/).
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们发布[稳定视频扩散](https://stability.ai/news/stable-video-diffusion-open-ai-video-model)时，我们强调了我们的视频模型在各种应用中的多功能性。基于这一基础，我们很高兴地发布了Stable
    Video 3D。这款新模型推动了3D技术领域的进步，与之前发布的[Stable Zero123](https://stability.ai/news/stable-zero123-3d-generation)以及其他开源替代品如[Zero123-XL](https://objaverse.allenai.org/docs/zero123-xl/)相比，在提供的质量和多视角上有了显著改进。
- en: 'This release features two variants:'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 此版本包含两种变体：
- en: 'SV3D_u: This variant generates orbital videos based on single image inputs
    without camera conditioning.'
  id: totrans-split-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SV3D_u：这种变体基于单张图像输入生成轨道视频，无需摄像机条件。
- en: 'SV3D_p: Extending the capability of SVD3_u, this variant accommodates both
    single images and orbital views, allowing for the creation of 3D video along specified
    camera paths.'
  id: totrans-split-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SV3D_p：扩展了SVD3_u的能力，此变体可同时处理单张图像和轨道视图，允许沿指定摄像机路径创建3D视频。
- en: Stable Video 3D can be used now for commercial purposes with a [Stability AI
    Membership](https://stability.ai/membership). For non-commercial use, you can
    download the model weights on [Hugging Face](https://huggingface.co/stabilityai/sv3d)
    and view our research paper [here](http://arxiv.org/abs/2403.12008).
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在可以通过[Stability AI Membership](https://stability.ai/membership)进行商业用途。非商业用途可以在[Hugging
    Face](https://huggingface.co/stabilityai/sv3d)下载模型权重，并查看我们的研究论文[这里](http://arxiv.org/abs/2403.12008)。
- en: '**Advantages of Video Diffusion**'
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**视频扩散的优势**'
- en: By adapting our Stable Video Diffusion image-to-video diffusion model with the
    addition of camera path conditioning, Stable Video 3D is able to generate multi-view
    videos of an object. The use of video diffusion models, in contrast to image diffusion
    models as used in Stable Zero123, provides major benefits in generalization and
    view-consistency of generated outputs. Additionally, we propose improved 3D optimization
    leveraging this powerful capability of Stable Video 3D to generate arbitrary orbits
    around an object. By further implementing these techniques with disentangled illumination
    optimization as well as a new masked score distillation sampling loss function,
    Stable Video 3D is able to reliably output quality 3D meshes from single image
    inputs.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将我们的Stable Video扩散图像到视频扩散模型与摄像机路径调节的结合，Stable Video 3D能够生成对象的多视角视频。与Stable
    Zero123使用的图像扩散模型相比，视频扩散模型在生成输出的泛化能力和视角一致性方面带来了显著优势。此外，我们提出了利用Stable Video 3D这一强大能力进行改进的3D优化，包括解耦的照明优化以及新的掩膜分数蒸馏采样损失函数。这些技术进一步确保了Stable
    Video 3D能够从单张图像输入可靠地输出高质量的3D网格。
- en: See the technical report [here](https://sv3d.github.io/) for more details on
    the Stable Video 3D models and experimental comparisons.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 查看技术报告[这里](https://sv3d.github.io/)，了解Stable Video 3D模型和实验比较的更多细节。
- en: '**Novel-View Generation**'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**新视角生成**'
- en: Stable Video 3D introduces significant advancements in 3D generation, particularly
    in novel view synthesis (NVS). Unlike previous approaches that often grapple with
    limited perspectives and inconsistencies in outputs, Stable Video 3D is able to
    deliver coherent views from any given angle with proficient generalization. This
    capability not only enhances pose-controllability, but also ensures consistent
    object appearance across multiple views, further improving critical aspects of
    realistic and accurate 3D generations.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: Stable Video 3D 引入了在 3D 生成方面的显著进展，特别是在新视角合成（NVS）方面。与以往常常受限于有限视角和输出不一致的方法不同，Stable
    Video 3D 能够从任何给定角度提供连贯的视角，并具有良好的泛化能力。这种能力不仅增强了姿态可控性，还确保了多视角下一致的物体外观，进一步改善了现实和准确的
    3D 生成的关键方面。
