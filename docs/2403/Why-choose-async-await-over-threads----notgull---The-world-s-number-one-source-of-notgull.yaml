- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-29 12:40:25'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-29 12:40:25
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Why choose async/await over threads? – notgull – The world's number one source
    of notgull
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择 async/await 而不是线程？– notgull – notgull 的世界第一来源
- en: 来源：[https://notgull.net/why-not-threads/](https://notgull.net/why-not-threads/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://notgull.net/why-not-threads/](https://notgull.net/why-not-threads/)
- en: A common refrain is that threads can do everything that `async`/`await` can,
    but simpler. So why would anyone choose `async`/`await`?
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的说法是，线程可以做任何`async`/`await`可以做的事情，但更简单。那么为什么有人会选择`async`/`await`呢？
- en: This is a common question that I’ve seen a lot in the Rust community. Frankly,
    I completely understand where it’s coming from.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我在 Rust 社区经常看到的一个常见问题。老实说，我完全理解这个问题的出发点。
- en: Rust is a low-level language that doesn’t hide the complexity of coroutines
    from you. This is in opposition to languages like Go, where `async` happens by
    default, without the programmer needing to even consider it.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: Rust 是一种低级语言，不会向你隐藏协程的复杂性。这与像 Go 这样的语言相反，后者默认情况下发生`async`，程序员甚至无需考虑它。
- en: Smart programmers try to avoid complexity. So, they see the extra complexity
    in `async`/`await` and question why it is needed. This question is especially
    pertinent when considering that a reasonable alternative exists in OS threads.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 聪明的程序员试图避免复杂性。因此，他们看到`async`/`await`中的额外复杂性，质疑为什么需要它。当考虑到操作系统线程中存在一个合理的替代方案时，这个问题尤为重要。
- en: Let’s take a mind-journey through `async` and see how it stacks up.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过`async`来进行一次思维之旅，看看它如何堆叠。
- en: Background Blitz
  id: totrans-split-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 背景闪电战
- en: 'Rust is a low-level language. Normally, code is linear; one thing runs after
    another. It looks like this:'
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: Rust 是一种低级语言。通常，代码是线性的；一件事情接着一件事情发生。看起来像这样：
- en: '[PRE0]'
  id: totrans-split-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Nice and simple, right?
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 简单明了，对吧？
- en: 'However, sometimes you will want to run many things at once. The canonical
    example for this is a web server. Consider the following written in linear code:'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 但有时你会希望同时运行许多事情。这个典型的例子是 web 服务器。考虑以下线性代码的例子：
- en: '[PRE1]'
  id: totrans-split-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Imagine if `handle_client` takes a few milliseconds, and two clients try to
    connect to your webserver at the same time. You’ll run into a serious problem!
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，如果`handle_client`需要几毫秒，并且两个客户端同时尝试连接到你的 web 服务器。你会遇到严重的问题！
- en: 'Client #1 connects to the webserver, and is accepted by the `accept()` function.
    It starts running `handle_client()`.'
  id: totrans-split-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '客户端 #1 连接到 web 服务器，并被`accept()`函数接受。它开始运行`handle_client()`。'
- en: 'Client #2 connects to the webserver. However, since `accept()` is not currently
    running, we have to wait for `handle_client()` for Client #1 to finish running.'
  id: totrans-split-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '客户端 #2 连接到 web 服务器。然而，由于当前未运行`accept()`，我们必须等待客户端 #1 的`handle_client()`运行完毕。'
- en: 'After waiting a few milliseconds, we get back to `accept()`. Client #2 can
    connect.'
  id: totrans-split-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '等待几毫秒后，我们回到`accept()`。客户端 #2 可以连接。'
- en: Now imagine that instead of two clients, there are two million simultaneous
    clients. At the end of the queue, you’ll have to wait several minutes before the
    web server can help you. It becomes un-scalable very quickly.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在想象一下，不是两个客户端，而是两百万个同时的客户端。在队列的末尾，你将不得不等待几分钟，然后 web 服务器才能帮助你。这很快就变得不可伸缩。
- en: Obviously, the embryonic web tried to solve this problem. The original solution
    was to introduce threading. By saving the value of some registers and the program’s
    stack into memory, the operating system can stop a program, run another program
    in its place, then resume running that program later. Essentially, it allows for
    multiple routines (or “threads”, or “processes”) to run on the same CPU.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，最初的网络尝试解决这个问题。最初的解决方案是引入线程。通过将一些寄存器的值和程序的堆栈保存到内存中，操作系统可以停止一个程序，运行另一个程序，然后稍后继续运行该程序。本质上，它允许多个例程（或“线程”或“进程”）在同一CPU上运行。
- en: 'Using threads, we can rewrite the above code as follows:'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线程，我们可以将上述代码重写如下：
- en: '[PRE2]'
  id: totrans-split-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Now, the client is being handled by a separate thread than the one handling
    waiting for new connections. Great! This avoids the problem by allowing concurrent
    thread access.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，客户端被一个与等待新连接处理的线程分开处理。太棒了！这通过允许并发线程访问避免了问题。
- en: 'Client #1 is `accept`ed by the server. The server spawns a thread that calls
    `handle_client`.'
  id: totrans-split-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '客户端 #1 被服务器`accept`。服务器生成一个调用`handle_client`的线程。'
- en: 'Client #2 tries to connect to the server.'
  id: totrans-split-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '客户端 #2 试图连接服务器。'
- en: 'Eventually, `handle_client` blocks on something. The OS saves the thread handling
    Client #1 and brings back the main thread.'
  id: totrans-split-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '最终，`handle_client`在某些事情上阻塞。操作系统保存处理客户端 #1 的线程，并恢复主线程。'
- en: 'The main thread `accept`s Client #2\. It spawns a separate thread to handle
    Client #2\. With only a few microseconds of delay, Client #1 and Client #2 are
    run in parallel.'
  id: totrans-split-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主线程 `accept` 客户端#2。它启动一个单独的线程来处理客户端#2。只有几微秒的延迟，客户端#1和客户端#2并行运行。
- en: Threads work especially well when you consider that production-grade web servers
    have dozens of CPU cores. It’s not just that the OS can give the *illusion* that
    all of these threads run at the same time; it’s that the OS can *actually* make
    them all run at once.
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当考虑到生产级别的 Web 服务器拥有数十个 CPU 内核时，线程特别有效。重要的不仅仅是操作系统可以给出这些线程同时运行的*假象*；重要的是操作系统*实际上*可以使它们全部同时运行。
- en: Eventually, for reasons I’ll elaborate later, programmers wanted to bring this
    concurrency out of the OS space and into the user space. There are many different
    models for userspace concurrency. There is event-driven programming, actors, and
    coroutines. The one Rust settled on is `async`/`await`.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，出于稍后我将详细说明的原因，程序员们希望将这种并发性从操作系统空间带入用户空间。有许多不同的用户空间并发模型。有事件驱动编程、actors 和协程。Rust
    选择的是 `async`/`await`。
- en: 'To oversimplify, you compile the program as a grab-bag of state machines that
    can all be run independently of another. Rust itself provides a mechanism for
    creating state machines; the mechanism of `async` and `await`. The above program
    in terms of `async`/`await` would look like this, written using [`smol`](https://crates.io/crates/smol):'
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，您将程序编译为一组可以彼此独立运行的状态机。Rust 本身提供了创建状态机的机制；`async` 和 `await` 的机制。以上程序在 `async`/`await`
    方面将如下所示，使用 [`smol`](https://crates.io/crates/smol) 编写：
- en: '[PRE3]'
  id: totrans-split-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The main function is preceded with the `async` keyword. This means that it is
    not a traditional function, but one that returns a state machine. Roughly, the
    function’s contents correspond to that state machine.
  id: totrans-split-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主函数前面带有 `async` 关键字。这意味着它不是传统的函数，而是返回一个状态机。大致上，函数内容对应于该状态机。
- en: '`await` includes another state machine as a part of the currently running state
    machine. For `accept()`, it means that the state machine will include it as a
    step.'
  id: totrans-split-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`await` 包含另一个状态机作为当前运行状态机的一部分。对于 `accept()` 来说，这意味着状态机将其作为一个步骤包含在内。'
- en: Eventually, one of the inner functions will *yield*, or give up control. For
    example, when `accept()` waits for a new connection. At this point the entire
    state machine will yield its execution to the higher-level executor. For us, that
    is `smol::Executor`.
  id: totrans-split-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最终，其中一个内部函数会*让步*，或放弃控制。例如，当 `accept()` 等待新连接时。此时整个状态机将将执行让给更高级别的执行器。对于我们来说，那就是
    `smol::Executor`。
- en: Once execution is yielded, the `Executor` will replace the current state machine
    with another one that is running concurrently, spawned through the `spawn` function.
  id: totrans-split-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦执行被让步，`Executor` 将用 `spawn` 函数并发运行另一个当前状态机来替换当前状态机。
- en: We pass an `async` block to the `spawn` function. This block represents an entire
    new state machine, independent of the one created by the `main` function. All
    this state machine does is run the `handle_client` function.
  id: totrans-split-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将一个 `async` 块传递给 `spawn` 函数。此块表示一个全新的状态机，独立于 `main` 函数创建的状态机。此状态机的唯一功能是运行
    `handle_client` 函数。
- en: Once `main` yields, one of the clients is selected to run in its place. Once
    that client yields, the cycle repeats.
  id: totrans-split-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦 `main` 让步，会选择一个客户端来替代它运行。一旦该客户端让步，循环重复。
- en: You can now handle millions of simultaneous clients.
  id: totrans-split-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现在，您可以处理数百万个同时客户端。
- en: Of course, user-space concurrency like this introduces an uptick in complexity.
    When you’re using threads, you don’t have to deal with executors and tasks and
    state machines and all.
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，像这样的用户空间并发引入了复杂性上升。当您使用线程时，您不必处理执行器、任务、状态机等。
- en: If you’re a reasonable person, you might be asking “why do we need to do all
    of this? Threads work well; for 99% of programs, we don’t need to involve any
    kind of user-space concurrency. Introducing new complexity is technical debt,
    and technical debt costs us time and money.
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一个合理的人，你可能会问：“为什么我们需要做所有这些呢？线程运行良好；对于99%的程序，我们不需要涉及任何用户空间并发。引入新的复杂性是技术债务，技术债务会浪费我们的时间和金钱。”
- en: “So why wouldn’t we use threads?”
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: “那么为什么我们不使用线程呢？”
- en: Timeout Trouble
  id: totrans-split-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超时问题
- en: Perhaps one of Rust’s biggest strengths is *composability*. It provides a set
    of abstractions that can be nested, built upon, put together, and expanded upon.
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: Rust 的一个最大优势之一是*可组合性*。它提供了一组可以嵌套、构建、组合和扩展的抽象。
- en: I recall that *the* thing that made me stick with Rust is the [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html)
    trait. It blew my mind that you could make something an [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html),
    apply a handful of different combinators, then pass the resulting [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html)
    into any function that took an [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html).
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我记得让我坚持使用 Rust 的*东西*是 [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html)
    trait。让我震惊的是，你可以将某物变成 [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html)，应用一些不同的组合器，然后将结果
    [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html) 传递给任何接受 [`Iterator`](https://doc.rust-lang.org/std/iter/trait.Iterator.html)
    的函数。
- en: It continues to impress me how powerful it is. Let’s say you want to receive
    a list of integers from another thread, only take the ones that are immediately
    available, discard any integers that aren’t even, add one to all of them, then
    push them onto a new list.
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: 它继续让我印象深刻。假设你想从另一个线程接收一个整数列表，仅获取即时可用的整数，丢弃任何不是偶数的整数，对所有整数加一，然后将它们推送到一个新列表中。
- en: 'That would be fifty lines and a helper function in some other languages. In
    Rust it can be done in five:'
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他语言中，这可能需要五十行代码和一个辅助函数。但在 Rust 中，只需五行代码即可完成：
- en: '[PRE4]'
  id: totrans-split-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The best thing about `async`/`await` is that it lets you apply this composability
    to I/O-bound functions. Let’s say you have a new client requirement; you want
    to add a timeout to your above function. Assume that our `handle_client` above
    function looks like this:'
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`async`/`await` 最好的一点是，它让你将这种可组合性应用于 I/O 绑定的函数。假设你有一个新的客户端需求；你想给上面的函数添加超时。假设我们的上面的
    `handle_client` 函数看起来像这样：'
- en: '[PRE5]'
  id: totrans-split-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If we want to add, say, a three-second timeout, we can combine two combinators
    to do that:'
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想添加，比如，三秒的超时，我们可以组合两个组合器来实现：
- en: The [`race`](https://docs.rs/smol/latest/smol/future/fn.race.html) function
    takes two futures and runs them at the same time.
  id: totrans-split-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`race`](https://docs.rs/smol/latest/smol/future/fn.race.html) 函数同时运行两个 futures。'
- en: The [`Timer`](https://docs.rs/smol/latest/smol/struct.Timer.html) future waits
    for some time before returning.
  id: totrans-split-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[`Timer`](https://docs.rs/smol/latest/smol/struct.Timer.html) future 在返回之前等待一段时间。'
- en: 'Here is what the final code looks like:'
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最终代码如下所示：
- en: '[PRE6]'
  id: totrans-split-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: I find this to be a very easy process. All you have to do is wrap your existing
    code in an `async` block and race it against another future.
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现这是一个非常简单的过程。你所需做的就是在 `async` 块中包装你现有的代码，并与另一个 future 竞争。
- en: An added bonus of this approach is that it works with any kind of stream. Here,
    we use a `TcpStream`. However we can easily replace it with anything that implements
    `impl AsyncRead + AsyncWrite`. It could be a GZIP stream on top of the normal
    stream, or a Unix socket, or a file. `async` just slides into whatever pattern
    you need from it.
  id: totrans-split-58
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法的额外好处是它适用于任何类型的流。在这里，我们使用了 `TcpStream`。然而，我们可以轻松地用任何实现了 `impl AsyncRead
    + AsyncWrite` 的东西替换它。它可以是普通流上面的 GZIP 流，或者是 Unix 套接字，或者是文件。`async` 只是按照你从中需要的任何模式滑入。
- en: Thematic Threads
  id: totrans-split-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主题线程
- en: What if we wanted to implement this in our threaded example above?
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想在上面的线程示例中实现这个，我们会怎么做呢？
- en: '[PRE7]'
  id: totrans-split-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Well, it’s not easy. Generally, you can’t interrupt the `read` or `write` system
    calls in blocking code, without doing something catastrophic like closing the
    file descriptor (which can’t be done in Rust).
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，这并不容易。通常情况下，在阻塞代码中，你不能中断 `read` 或 `write` 系统调用，而不做一些像关闭文件描述符（在 Rust 中无法做到的事情）那样灾难性的事情。
- en: Thankfully, [`TcpStream`](https://doc.rust-lang.org/std/net/struct.TcpStream.html)
    has two functions [`set_read_timeout`](https://doc.rust-lang.org/std/net/struct.TcpStream.html#method.set_read_timeout)
    and [`set_write_timeout`](https://doc.rust-lang.org/std/net/struct.TcpStream.html#method.set_write_timeout)
    that can be used to set the timeouts for reading and writing, respectively. However,
    we can’t just use it naively. Imagine a client that sends one byte every 2.9 seconds,
    just to reset the timeout.
  id: totrans-split-63
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，[`TcpStream`](https://doc.rust-lang.org/std/net/struct.TcpStream.html)
    有两个函数 [`set_read_timeout`](https://doc.rust-lang.org/std/net/struct.TcpStream.html#method.set_read_timeout)
    和 [`set_write_timeout`](https://doc.rust-lang.org/std/net/struct.TcpStream.html#method.set_write_timeout)，可以用来设置读取和写入的超时时间。然而，我们不能简单地朴素地使用它。想象一个客户端，每
    2.9 秒发送一个字节，只是为了重置超时。
- en: So we have to program a little defensively here. Due to the power of Rust combinators,
    we can write our own type wrapping around the [`TcpStream`](https://doc.rust-lang.org/std/net/struct.TcpStream.html)
    to program the timeout.
  id: totrans-split-64
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们必须在这里稍微防御性地编程。由于 Rust 组合器的强大功能，我们可以编写自己的类型包装，围绕 [`TcpStream`](https://doc.rust-lang.org/std/net/struct.TcpStream.html)
    来编程超时。
- en: '[PRE8]'
  id: totrans-split-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: On one hand, it could be argued that this is elegant. We used Rust’s capabilities
    to solve the problem with a relatively simple combinator. I’m sure it would work
    well enough.
  id: totrans-split-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一方面，可以说这很优雅。我们利用 Rust 的能力用一个相对简单的组合器解决了问题。我相信这足够好用了。
- en: On the other hand, it’s definitely hacky.
  id: totrans-split-67
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，这显然是一种破解方式。
- en: We’ve locked ourselves into using [`TcpStream`](https://doc.rust-lang.org/std/net/struct.TcpStream.html).
    There’s no trait in Rust to abstract over using the [`set_read_timeout`](https://doc.rust-lang.org/std/net/struct.TcpStream.html#method.set_read_timeout)
    and [`set_write_timeout`](https://doc.rust-lang.org/std/net/struct.TcpStream.html#method.set_write_timeout)
    types. So it would take a lot of additional work to make it use any kind of writer.
  id: totrans-split-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们已经锁定自己使用 [`TcpStream`](https://doc.rust-lang.org/std/net/struct.TcpStream.html)。在
    Rust 中没有抽象使用 [`set_read_timeout`](https://doc.rust-lang.org/std/net/struct.TcpStream.html#method.set_read_timeout)
    和 [`set_write_timeout`](https://doc.rust-lang.org/std/net/struct.TcpStream.html#method.set_write_timeout)
    类型的特性。因此，如果要使用任何类型的写入器，需要进行大量的额外工作。
- en: It involves an extra system call for setting the timeout.
  id: totrans-split-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它涉及一个额外的系统调用来设置超时。
- en: I imagine this type is much more unwieldy to use for the kinds of actual logic
    that web servers demand.
  id: totrans-split-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我想象这种类型对于网络服务器所需的实际逻辑使用起来更加笨拙。
- en: If I saw this code in production, I would ask the author why they avoided using
    `async`/`await` to solve this problem. This is the phenomenon I was describing
    in my post “[Why you might actually want async in your project](/why-you-want-async/)”.
    Quite frequently I encounter a pattern where synchronous code can’t be used without
    contortion, so I have to rewrite it in `async`.
  id: totrans-split-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我在生产环境中看到这段代码，我会问作者为什么避免使用 `async`/`await` 来解决这个问题。这就是我在文章 “[为什么你实际上可能想在项目中使用
    async](/why-you-want-async/)” 中描述的现象。我经常遇到这样一种模式，同步代码无法在不扭曲的情况下使用，所以我不得不将其重写为
    `async`。
- en: Async Success Stories
  id: totrans-split-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Async 成功故事
- en: There’s a reason why the HTTP ecosystem has adopted `async`/`await` as its primary
    runtime mechanism, even for clients. You can take any function that makes an HTTP
    call, and make it fit whatever hole or use case you want it to.
  id: totrans-split-73
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP 生态系统之所以将 `async`/`await` 作为其主要运行时机制，甚至用于客户端，这并非没有原因。你可以拿任何进行 HTTP 调用的函数，使其适应你想要的任何空白或使用案例。
- en: '[`tower`](https://crates.io/crates/tower) is probably the best example of this
    phenomenon I can think of, and it’s really *the* thing that made me realize how
    powerful `async`/`await` can be. If you implement your service as an `async` function,
    you get timeouts, rate limiting, load balancing, [hedging](https://docs.rs/tower/0.4.13/tower/hedge/index.html)
    and back-pressure handling. All of that for free.'
  id: totrans-split-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[`tower`](https://crates.io/crates/tower) 可能是我能想到的这种现象的最佳例子，它真正地展示了 `async`/`await`
    的强大之处。如果你将服务实现为一个 `async` 函数，你将获得超时、速率限制、负载均衡、[hedging](https://docs.rs/tower/0.4.13/tower/hedge/index.html)
    和反压处理。所有这些功能都是免费的。'
- en: It doesn’t matter what runtime you used, or what you’re actually doing in your
    service. You can throw [`tower`](https://crates.io/crates/tower) at it to make
    it more robust.
  id: totrans-split-75
  prefs: []
  type: TYPE_NORMAL
  zh: 不管你使用什么运行时，或者你的服务实际在做什么，你都可以投入 [`tower`](https://crates.io/crates/tower) 来使其更加健壮。
- en: '[`macroquad`](https://docs.rs/macroquad) is a miniature Rust game engine that
    aims to make game development as easy as possible. Its main function uses `async`/`await`
    in order to run its engine. This is because `async`/`await` is really the best
    way in Rust to express a linear function that needs to be stopped in order to
    wait for something else.'
  id: totrans-split-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[`macroquad`](https://docs.rs/macroquad) 是一个迷你的 Rust 游戏引擎，旨在尽可能简化游戏开发。它的主要功能使用
    `async`/`await` 来运行引擎。这是因为 `async`/`await` 真的是 Rust 中表达需要停止以等待其他东西的线性函数的最佳方式。'
- en: In practice, this can be extremely powerful. Imagine simultaneously polling
    a network connection to your game server and your GUI framework, on the same thread.
    The possibilities are endless.
  id: totrans-split-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，这可能非常强大。想象一下同时轮询游戏服务器和 GUI 框架的网络连接，使用同一个线程。这种可能性是无限的。
- en: Improving Async’s Image
  id: totrans-split-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 改善 Async 的形象
- en: I don’t think the issue is that some people think threads are better than `async`.
    I think the issue is that the benefits of `async` aren’t widely broadcast. This
    leads some people to be misinformed about the benefits of `async`.
  id: totrans-split-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为问题不在于有些人认为线程比 `async` 更好。我认为问题在于 `async` 的好处没有广泛传播。这导致一些人对 `async` 的好处存在误解。
- en: If this is an educational problem, I think it’s worth taking a look at the educational
    material. Here’s what the [Rust Async Book](https://rust-lang.github.io/async-book/01_getting_started/02_why_async.html)
    says when comparing `async`/`await` to operating system threads.
  id: totrans-split-80
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这是一个教育问题，我认为值得查看教育资料。这是[Rust Async Book](https://rust-lang.github.io/async-book/01_getting_started/02_why_async.html)在比较`async`/`await`与操作系统线程时的说法。
- en: '**OS threads** don’t require any changes to the programming model, which makes
    it very easy to express concurrency. However, synchronizing between threads can
    be difficult, and the performance overhead is large. Thread pools can mitigate
    some of these costs, but not enough to support massive IO-bound workloads.'
  id: totrans-split-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**操作系统线程**不需要对编程模型进行任何更改，这使得表达并发非常容易。然而，在线程之间进行同步可能很困难，并且性能开销很大。线程池可以缓解部分成本，但无法完全支持大规模的
    IO 密集型工作负载。'
- en: '*- [Rust Async Book](https://rust-lang.github.io/async-book/01_getting_started/02_why_async.html),
    various authors*'
  id: totrans-split-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*- [Rust Async Book](https://rust-lang.github.io/async-book/01_getting_started/02_why_async.html)，各位作者*'
- en: I think this is a consistent problem throughout the `async` community. When
    someone asks the question of “why do we want to use this over OS threads”, people
    have a tendency to kind of wave their hand and say “`async` has less overhead.
    Other than that, everything’s the same.”
  id: totrans-split-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这是整个`async`社区中的一个一贯问题。当有人问“为什么我们要用这个而不是操作系统线程”时，人们往往会有点挥手说“`async`的开销更小。除此之外，一切都一样”。
- en: This is the reason why web server authors switched to `async`/`await`. It’s
    how they solved the [C10k problem](https://en.wikipedia.org/wiki/C10k_problem).
    But, it’s not going to be the reason why everyone else switches to `async`/`await`.
  id: totrans-split-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么 Web 服务器作者转向`async`/`await`的原因。这是他们解决[C10k 问题](https://en.wikipedia.org/wiki/C10k_problem)的方式。但这并不是所有人都转向`async`/`await`的原因。
- en: Performance gains are fickle and can disappear in the wrong circumstances. There
    are plenty of cases where a threaded workflow can be faster than an equivalent
    `async` workflow (mostly, in the case of CPU bound tasks). I think that we, as
    a community, have over-emphasized the ephemeral performance benefits of `async`
    Rust while downplaying its semantic benefits.
  id: totrans-split-85
  prefs: []
  type: TYPE_NORMAL
  zh: 性能增益是善变的，在错误的情况下可能会消失。有很多情况下，线程化的工作流程可能比等效的`async`工作流程更快（主要是在 CPU 绑定任务的情况下）。我认为作为一个社区，我们过分强调了`async`
    Rust的短暂性能优势，而淡化了其语义上的好处。
- en: In the worst case, it leads to people shrugging off `async`/`await` as “[a weird
    thing that you resort to for niche use cases](https://shnatsel.medium.com/smoke-testing-rust-http-clients-b8f2ee5db4e6)”.
    It should be seen as a powerful programming model that lets you succinctly express
    patterns that can’t be expressed in synchronous Rust without dozens of threads
    and channels.
  id: totrans-split-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在最坏的情况下，它会导致人们将`async`/`await`视为“[一种奇怪的东西，只用于小众用例](https://shnatsel.medium.com/smoke-testing-rust-http-clients-b8f2ee5db4e6)”而不予理会。它应该被视为一种强大的编程模型，可以让您简洁地表达那些在同步
    Rust 中无法用几十个线程和通道表达的模式。
- en: I also think there’s a tendency to try to make `async` Rust “just like sync
    Rust” in a way that encourages negative comparison. By “tendency”, I mean that
    it’s [the stated roadmap for the Rust project](https://blog.rust-lang.org/inside-rust/2022/02/03/async-in-2022.html),
    saying that “that writing async Rust code should be as easy as writing sync code,
    apart from the occasional `async` and `await` keyword.”.
  id: totrans-split-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我也认为有一种倾向是试图使`async` Rust在某种程度上“就像同步 Rust 一样”，这种做法促使负面比较。我所说的“倾向”，是指这是[Rust
    项目的官方路线图](https://blog.rust-lang.org/inside-rust/2022/02/03/async-in-2022.html)，称“编写`async`
    Rust 代码应该与编写同步代码一样简单，除了偶尔需要用到的`async`和`await`关键字”。
- en: I reject this framing because it’s fundamentally impossible. It’s like trying
    to host a pizza party on a ski slope. Sure, you can probably get 99% of the way
    there, especially if you’re really talented. But there are differences that the
    average bear *will* notice, no matter how good you are.
  id: totrans-split-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我反对这种表述，因为这从根本上是不可能的。这就像在滑雪场举办披萨派对一样。当然，如果你真的很有天赋，你可能会完成99%的工作。但平均人会注意到一些差异，无论你多么优秀。
- en: We shouldn’t be trying to force our model into unfriendly idioms to appease
    programmers who refuse to adopt another type of pattern. We should be trying to
    highlight the strengths of Rust’s `async`/`await` ecosystem; its composability
    and its power. We should be trying to make it so `async`/`await` is the *default*
    choice whenever a programmer reaches for concurrency. Rather than trying to make
    sync Rust and `async` Rust the same, we should embrace the differences.
  id: totrans-split-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不应该试图通过迎合拒绝采纳另一种模式的程序员而将我们的模型强加于不友好的习语中。我们应该试图突显Rust的`async`/`await`生态系统的优势；其可组合性和强大性。我们应该努力使得在程序员追求并发时，`async`/`await`成为*默认*选择。与其试图让同步Rust和`async`
    Rust变得相同，我们应该拥抱它们的差异。
- en: In short, we shouldn’t be using technical reasons to argue for a semantic model.
    We should be using semantic reasons.
  id: totrans-split-90
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，我们不应该使用技术原因来为语义模型辩护。我们应该使用语义原因。
