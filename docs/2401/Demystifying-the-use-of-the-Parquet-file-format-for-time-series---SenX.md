<!--yml

类别：未分类

日期：2024-05-27 14:52:14

-->

# 解密用于时间序列的 Parquet 文件格式 - SenX

> 来源：[`blog.senx.io/demystifying-the-use-of-the-parquet-file-format-for-time-series/`](https://blog.senx.io/demystifying-the-use-of-the-parquet-file-format-for-time-series/)

作为 [Warp 10](https://warp10.io/) 的开发者，最先进的时间序列平台，我们经常与存储时间序列数据已经相当长时间的人联系。他们所采用的技术的多样性会让你感到惊讶。在这些技术中，我们经常遇到通常被选择*因为它是列式格式，因此对于时间序列数据而言性能良好*的[Parquet](https://parquet.apache.org)文件格式。当我们进一步询问以更好地了解采用的架构，这些文件的使用方式以及它们允许的存储和访问性能时，答案通常显示 Parquet 格式的工作方式并不是很好理解。本文旨在让您更好地了解 Parquet 格式的内部结构以及其适用于时间序列数据的性能。

## Parquet 文件格式

### 历史

在 2010 年的[VLDB 会议](https://vldb.org/)上，[Google](https://google.com/) 的人员发表了一篇论文，题为[Dremel: Web 规模数据的交互式分析](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36632.pdf)，描述了一种名为[*Dremel*](https://en.wikipedia.org/wiki/Dremel_(software))的内部工具以及它组织数据的方式。

在 2012 年夏天，[Julien Le Dem](https://twitter.com/J_) 当时在 Twitter 工作，[发推文](https://twitter.com/J_/status/239247373581316096)说他在 Dremel 论文中发现了一个错误，原因是他开始着手开发一个用于 Hadoop 中的 Dremel 使用的嵌套记录格式的开源实现，这个项目稍后会成为[Parquet](https://web.archive.org/web/20130415111841/http://parquet.io/)。

### 基础知识

在 *Dremel* 论文中描述的新奇之处是一种巧妙的方法，可以将复杂记录存储在列式格式中。

列式格式背后的理念是，通过将数据分组到*列*而不是*行*中，相似的值会聚在一起，导致更好的压缩，在检索时，如果不需要所有列，则只需读取所需数据。诸如[HBase](https://hbbase.apache.org)之类的系统长期以来一直在使用列式格式范例。

但是，如果列式格式非常适用于*类似表格*的数据，那么对于嵌套数据结构来说就不适用，因为这些数据结构通常会最终汇聚在单个列中，因此如果只需要此类结构的特定字段，则会消除列式格式的好处。

这就是 Dremel 论文解决的问题，并通过一种巧妙的机制来描述字段如何嵌套和重复进行了解决。我们让您深入阅读原始 Dremel 论文第四部分，以了解记录如何在列中分割的内在机制。

### 实现

Parquet 实现采用了在 Dremel 论文中描述的*展平*原则，并按以下方式组织文件：

一个*文件*被划分为包含在*列块*中存储的各列值的*行组*。实际数据被打包在这些列块内的*页*中。页使用适应其存储值类型的机制进行压缩。文件末尾的*页脚*包含各种信息，如文件架构、行组和列块的索引以及每个列块的统计信息。

从 Parquet 文件读取数据时，会读取页脚以识别可以读取列块的偏移量，然后访问与请求数据匹配的块，并从各个列的数据重构记录。

Parquet 读取 API 中的谓词下推机制可以利用文件页脚中的统计信息，仅读取包含与谓词匹配值的行组。

### 核心要点

Parquet 格式是一种智能的*列式*格式，具有存储复杂嵌套或重复数据结构作为列的能力。简而言之，存储的数据结构中的每个字段或重复字段的每个元素最终都以自己的列形式存在。这是理解 Parquet 中存储时间序列时的基础，对于存储时间序列具有重要的影响。

## 在 Parquet 文件中存储时间序列

存储时间序列选用 Parquet 格式的动机可能是需要使用诸如[Spark](https://spark.apache.org/)这样的并行处理框架处理这些数据，需要由查询引擎（如[Impala](https://impala.apache.org)或[Drill](https://drill.apache.org)）读取，或者考虑将 Parquet 作为[下一次重写](https://www.influxdata.com/blog/announcing-influxdb-iox/)时间序列数据库或[云服务](https://docs.microsoft.com/en-us/azure/time-series-insights/concepts-storage#parquet-file-format-and-folder-structure)的存储层。

### 数据模型

在实际存储数据到 Parquet 文件之前，您需要清楚地了解如何对数据建模，因为这个模型将直接反映在将要存储的记录结构中。

当处理时间序列时，基本上有两种方法来建模数据。第一种，即最灵活的方法，是将系列视为独立实体，它们将被独立处理，但可以与其他系列一起进行操作。第二种方法，更为天真，是将系列视为表的列。因此，存储的记录实际上是在给定时间戳下包含各列数值的行。这是 IT 监控用例中的典型模型，其中每个记录都是几个指标的快照。对于物联网用例来说，这种模型不太适用，因为传感器可能因设备而异，采样频率也可能因传感器而异。

时间序列的*表*模型自然地映射到了一个 Parquet 架构，每个系列对应一个字段，一个字段对应时间戳，可能还有一组用于元数据的字段，*即*为系列添加上下文的键/值对。有时这个模型也被称为*观察*模型，因为每条记录只是一个在给定时间戳下的一组观察。

*系列*模型的不同之处在于每个系列或系列的时间段位于一行中。Parquet 将创建的列将成为时间戳和值的出现次数。这一方法在 [一章](http://what-when-how.com/Tutorial/topic-406tdru0g/Time-Series-Databases-32.html) 以及 [时间序列书](https://apprize.best/data/series/4.html) 中有描述，作者是 [特德·邓宁](https://twitter.com/ted_dunning) 和 [埃伦·弗里德曼](https://twitter.com/Ellen_Friedman)。

我们注意到，在这两种情况下，如果要存储多个系列（在表模型中）或多个数据点（在系列模型中），则列的数量可能会激增。在后一种情况下，压缩很可能也会相当差，因为给定的列（第 i 个刻度或第 i 个数值）与下一个系列中的相同刻度没有任何相似之处。

### 性能

使用 Parquet 文件时需要考虑两个性能方面。第一个是数据压缩的效率。正如我们刚才所见，*表*模型比*序列*方法具有更好的压缩性能。

要考虑的第二个性能方面是数据检索的速度。正如我们之前提到的，Parquet 具有 *谓词推送* 的功能，其中对数据的谓词用于确定要读取的数据。Parquet 格式在 *列块* + *行组* 级别执行此操作，并独立考虑列。也就是说，对列的谓词将使用列的统计信息来确定给定行组是否包含符合谓词的列的有效数据。如果推送多个谓词，将选择所有谓词都匹配的行组。这似乎对性能来说是一种胜利，但不幸的是，唯一的保证是所选的行组包含符合各列谓词的数据，但不能保证这些列的匹配值属于相同的行。因此，您可能会读取许多最终会丢弃的数据。幸运的是，Parquet 在重新组装时会在最终不验证推送下的谓词的列时删除记录，但这并不能阻止您支付传输这些无用数据的费用。

值的谓词在时间序列中很少使用，但时间戳和元数据（标签）的谓词非常常见。想象一下，您已经将以下数据存储在您的 Parquet 文件中：

| row group | timestamp | room | house | temperature | humidity |
| --- | --- | --- | --- | --- | --- |
| 0 | 10:00:00Z | `kitchen` | `main` | 20.0 | 75.0 |
| 0 | 10:00:00Z | `kitchen` | `vacation` | 15.0 | 50.1 |
| 1 | 10:01:00Z | `bathroom` | `main` | 20.1 | 80.0 |
| 1 | 10:01:10Z | `den` | `vacation` | 17.0 | 60.0 |

假设您想要在 10:00:00Z 到 10:01:00Z 之间的假期房屋数据，您会发现匹配的行是第二行，位于行组 `0` 中，但由于列的独立性，两个行组都会匹配，因为它们包含请求范围内的时间戳 **和** 在 *house* 列中出现 `vacation`。因此，尽管第二行组不包含符合您条件的数据，您最终将读取第二行组。

减轻这种情况需要创建定制的行组，理想情况下每个行组存储一个单一系列，以确保行组选择不会导致读取多余的数据。这将在大多数情况下创建小的行组，这与行组的目的相反。这相当繁琐，但不幸的是这是唯一的解决方案，因为 Parquet 格式缺乏为了有效随机访问特定行而索引 Parquet 文件内容的规定。还要注意，谓词不能应用于嵌套结构，因此在 *MAP* 列中分组标签无法提高选择匹配行的效率。

我们曾简要提及的另一个问题是列数的激增。在 Parquet 文件中拥有过多列并不明智，因为这会导致页脚的增长相当大，并且可能会出现一些与客户端执行代码生成相关的问题。这不仅限制了*表格*和*系列*方法的列数，还限制了时间块的大小。

*还可阅读 [使用 Warp 10 从 TCP 流到仪表盘构建完整应用程序](https://blog.senx.io/complete-application-warp-10-tcp-stream-dashboard/)*

## 结论

尽管 Parquet 是一个非常好的格式，但是当涉及到时间序列数据时，它提供的列式方法可能并不是非常适用，并且 Parquet 爱好者所宣传的访问性能在某些情况下可能并不存在。Parquet 文件中需要固定的模式也限制了可以存储在单个文件中的时间序列的种类。在选择 Parquet 或使用它来交互方式访问时间序列数据的工具时，请记住这一点。

在 SenX，几年前我们就得出了这个结论，并且设计了一种在文件中存储时间序列的方式，使得极端压缩和访问速度成为可能。这些文件可以在诸如[Spark](https://spark.apache.org)和[Flink](https://flink.apache.org/)之类的工具中读取，但更重要的是，它们可以在 Warp 10 实例中挂载，以便其中包含的数据几乎可以像在 Warp 10 存储引擎中存储一样进行`FETCH`。这些文件也可以存储在云对象存储服务中。

在某些情况下，我们经历过接近 1:40 的压缩比，每个时间戳和值占用少于 0.4 个字节，并且在单个线程上每秒读取数亿个数据点的性能。

这种称为*History File Stores*的方法也非常适合分发数据集。例如，来自[AISHub](https://www.aishub.net/)的[船舶自动识别系统数据](https://blog.senx.io/ais-data-made-easy/)的完整年度数据集可以容纳在小于 100Gb 的单个文件中，其中包括船舶运动的[时空索引](https://blog.senx.io/spatio-temporal-indexing-in-warp-10/)，这个单个文件可以由 Warp 10 实例提供，并且应用程序可以以极快的性能与该数据交互。

History File Store 格式目前通过我们的*技术预览*计划提供，请不要犹豫，如果您感兴趣，请联系我们。
