<!--yml

分类：未分类

日期：2024-05-27 15:22:41

-->

# DeepSeek Coder

> 来源：[https://deepseekcoder.github.io/](https://deepseekcoder.github.io/)

DeepSeek Coder包括一系列从头开始训练的代码语言模型，这些模型在英语和中文的87％代码和13％自然语言上都进行了预训练，每个模型都在2T标记上进行了预训练。我们提供各种大小的代码模型，从1B到33B版本不等。每个模型都是通过使用16K的窗口大小和额外的填空任务在repo级代码语料库上进行预训练的，从而得到基础模型（DeepSeek-Coder-Base）。我们进一步使用2B标记的指令数据对基础模型进行微调，以获得指令调整模型，即DeepSeek-Coder-Instruct。

+   Pretrained on **2 Trillion** tokens over more than 80 programming languages.

+   各种模型大小（**1.3B**，**5.7B**，**6.7B**和**33B**）以支持不同的需求。

+   支持**项目级**代码完成和填充的**16K窗口大小**。

+   在开放代码模型中具有**最先进**的性能。

+   **开源且可供研究和商业使用**。
