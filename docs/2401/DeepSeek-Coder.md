<!--yml

分类：未分类

日期：2024-05-27 15:22:41

-->

# DeepSeek Coder

> 来源：[`deepseekcoder.github.io/`](https://deepseekcoder.github.io/)

DeepSeek Coder 包括一系列从头开始训练的代码语言模型，这些模型在英语和中文的 87％代码和 13％自然语言上都进行了预训练，每个模型都在 2T 标记上进行了预训练。我们提供各种大小的代码模型，从 1B 到 33B 版本不等。每个模型都是通过使用 16K 的窗口大小和额外的填空任务在 repo 级代码语料库上进行预训练的，从而得到基础模型（DeepSeek-Coder-Base）。我们进一步使用 2B 标记的指令数据对基础模型进行微调，以获得指令调整模型，即 DeepSeek-Coder-Instruct。

+   Pretrained on **2 Trillion** tokens over more than 80 programming languages.

+   各种模型大小（**1.3B**，**5.7B**，**6.7B**和**33B**）以支持不同的需求。

+   支持**项目级**代码完成和填充的**16K 窗口大小**。

+   在开放代码模型中具有**最先进**的性能。

+   **开源且可供研究和商业使用**。
