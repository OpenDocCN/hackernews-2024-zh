<!--yml

category: 未分类

date: 2024-05-27 14:43:40

-->

# 复制危机是否可复制？- Ben Recht

> 来源：[`www.argmin.net/p/is-the-reproducibility-crisis-reproducible`](https://www.argmin.net/p/is-the-reproducibility-crisis-reproducible)

在我冬季休假前不久，[Andrew Gelman 和他的合作者们发表了一篇论文，声称大多数临床试验的功效不足](https://statmodeling.stat.columbia.edu/2023/12/23/bayesians-moving-from-defense-to-offense-i-really-think-its-kind-of-irresponsible-now-not-to-use-the-information-from-all-those-thousands-of-medical-trials-that-came-before-is-that-very/)，引起了社交媒体的轰动。在一篇 *[NEJM Evidence](https://evidence.nejm.org/doi/full/10.1056/EVIDoa2300003)* 的论文中，他们把目光投向了每个人都喜欢批评的总结统计量，即 p 值。Gelman 将这篇论文称为“贝叶斯人由防守转向进攻”。合作者包括经济学诺贝尔奖获得者 Guido Imbens 和多产的流行病学家 Sander Greenland。论文中包含了诸如以下的声明：

> “在相同方向上，复制研究得到 P<0.05 的概率很小，即使在从 0.005 到 0.001 的层面上。因此，复制研究中得到 P>0.05 并不意味着原始发现是偶然的，至少不是在历史临床试验的背景下，就像原始研究中的 P<0.05 并不意味着最初的结论是正确的，特别是当 P 接近 0.05 时。”

当然，复制危机的支持者们喜欢说这样的话。我们都喜欢用“科学是错误的，不可复制的”这样的说法来吓唬我们的学生，因为我们的同行们不够严谨。但这篇新论文是否提供了这样严厉警告的良好证据呢？

让我们深入研究吧！他们到底做了什么？这篇论文从一开始就激怒了我，因为它触发了我最大的方法论怨恨之一。他们的目标是通过进行一项深度混杂的观察性研究来证明所有随机实验都是错误的。噢！但事情的细节证明比那更糟糕。

让我们从作者试图阐明他们的论点的最高水平开始。我需要在描述中准确地给出一个技术上令人讨厌的统计学方面：这篇论文得出了有关临床试验中结果的 z 分数模型的结论。什么是 z 分数？这是一种在道德上等同于 p 值的量。我不想在这里深入讨论 p 值的细节，因为这很烦人并且会分散注意力。以下内容足以。随机试验中的每个结果都会被标记为 p 值。 p 值越小，我们就越相信两组之间测量差异是由于治疗而不是将人们随机分配到两组中。你可以报告 z 分数而不是 p 值。有一个公式可以让你从一个到另一个转换。z 分数越大，p 值越小，反之亦然。这篇论文使用 z 分数而不是 p 值进行工作，因为出于技术原因，z 分数在数学上更容易处理。作者的目标是显示他们的临床试验 z 分数模型显示出一些令人担忧的特性，这些特性将暗示着复制危机。

在这篇论文中，提出的方法是：

1.  收集来自 Cochrane 数据库的随机对照试验的 z 分数的大型数据集

1.  构建这些 z 分数的统计模型

1.  从这个统计模型中，抽取一堆样本来模拟预期的可重现性率或主要效应大小的错误估计。

这里的一切都取决于第一步。他们的 z 分数数据集是否合法地代表了医学中所有临床试验？结果表明，这篇 *NEJM Evidence* 论文根本没有进行第一步。事实上，这篇论文直接从第三步开始！他们直接从 [2021 年](https://onlinelibrary.wiley.com/doi/full/10.1002/sim.9173) 的 *[Statistics in Medicine](https://onlinelibrary.wiley.com/doi/full/10.1002/sim.9173)* 论文中的 van Zwet、Schwab 和 Senn 那里拿了一个模型。这个较早的模型将四个零均值的高斯分布混合拟合到了他们抓取的一些试验的 z 分数的对称集合上。为什么一个临床试验中的 z 分数是从高斯混合分布中抽取的样本是可信的？并不是。这太荒谬了。但我甚至不想深入讨论模型，因为我仍然想专注于数据的来源。

van Zwet、Schwab 和 Senn 的 2021 年论文没有代码，但它链接到了他们的 [数据集](https://osf.io/xjv9g/)。他们声称他们将他们的模型拟合到了数据集中的 23,551 个随机试验中。我下载了数据并统计了 34,836 个唯一的试验。剩下的 11,285 个发生了什么？没有人知道。我决定深入挖掘，看看能不能找到答案。

van Zwet、Schwab 和 Senn 坚称 [Schwab、Kreiliger 和 Held 最初在 2019 年收集和处理了这些数据。](https://osf.io/preprints/metaarxiv/t6cjx/) 我查看了这篇 2019 年的论文，并发现了一个令人震惊的段落：

> “需要对各医学专业的主要研究报告中报告的效应大小进行比较。我们使用 R 包 metafor 中的 escalc() 重新计算了所有主要研究的效应大小。对于连续结果，使用了 SMD（Hedges' g），对于二分结果，使用了几率比。几率比被转换为 Hedges' g，然后再转换为 Pearson's r。统计显著性是通过 Wald 检验计算的，该检验是在 CDSR（例如，风险比、风险比等）中报告的原始效应度量上进行的；对于均值差异，我们应用了两个样本的学生 t 检验。”

等等，等一下。这些 z 分数不是从 RCTs 报告的 p 值中导出的？它们是其他元科学家为另一个项目计算的 p 值。这太奇怪了！在《NEJM 证据》文章中，范·兹维特等人声称：“我们已经收集了所有这些 RCT 的主要疗效结果的绝对 z 统计量。”但这至多是误导性的。这些不是报告的 z 统计量，而是其他作者方法导出的 z 统计量。我们看的是与作者让我们相信的不同的东西。在这种情况下，我们不应该相信《NEJM 证据》论文中的任何结论。

这就是为什么你不应该根据“大数据抓取”形成“先验”。当你编写脚本来处理成千上万的试验报告，并且你不看其中任何一个时，没有人知道所有这些数据的内容或价值是什么。有人只是给你展示一个单变量直方图，希望你相信它是真实的。但你不应该相信任何东西。特别是来自于无法复制的网络爬取过程的东西。让我重申一下：*这篇关于可复制性的论文本身就是不可复制的*。

埃里克·范·兹维特声称：“我真的认为现在不利用所有那些之前的成千上万个医学试验的信息有点不负责任。这很激进吗？”但我们如何利用过去试验的信息很重要。用 R 脚本抓取所有试验，并盲目地拼凑出一个 p 值的表格，而不看任何试验报告，这是激进的。这是一条通向知识建构的荒谬之路。《NEJM 证据》文章的作者得出结论称他们能够解释复制危机，我感到吃惊吗？不。和所有观察性研究一样，作者找到了他们寻找的东西。但结论是否由“数据”支持？没有。证据很薄弱。

我尊重作者们试图做的事情，我也是他们很多工作的粉丝！我写这篇博客只是作为一个警告：严格遵守元科学界认为能够修复科学的严谨规则是非常困难的。而且我实际上认为更多统计数据和方法学的限制提议不会解决问题。

相反，解决的方法是停止这种大数据挖掘，回归基础。擅长阅读临床试验的专家知道，p 值只是整个 puzzle 中的一小部分。实际上，在临床试验中从未需要 p 值。临床试验使用最基本的测试来比较结果，而 p 值只是总结与结果相关的三个数字的一种方式。任何结果都有治疗组中的不良事件数量、对照组中的不良事件数量以及研究中的患者数量。根据这三个数字，你可以计算出一个 p 值。但这里的 p 值只是作为一个合理性检查，以确认干预措施的测量效应是否足够大。之后，你必须查看试验实施是否存在其他偏见以及可能的不同组间差异的潜在替代解释。阅读试验报告需要建立很多直觉，学习需要时间来了解需要关注的内容。但如果你想修复临床医学中的实验，这就是你开始的地方。严格的贝叶斯统计模型中的 p 值将根本不是你过程的一部分。
