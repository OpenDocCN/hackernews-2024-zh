- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 15:12:47'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 15:12:47'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Essays: Don’t Talk to People Like They’re Chatbots - Schneier on Security'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 文章：不要像对待聊天机器人一样与人交谈 - Schneier on Security
- en: 来源：[https://www.schneier.com/essays/archives/2024/01/dont-talk-to-people-like-theyre-chatbots.html](https://www.schneier.com/essays/archives/2024/01/dont-talk-to-people-like-theyre-chatbots.html)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.schneier.com/essays/archives/2024/01/dont-talk-to-people-like-theyre-chatbots.html](https://www.schneier.com/essays/archives/2024/01/dont-talk-to-people-like-theyre-chatbots.html)
- en: Don’t Talk to People Like They’re Chatbots
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不要像对待聊天机器人一样与人交谈
- en: AI could make our human interactions blander, more biased, or ruder.
  id: totrans-7
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: AI可能会使我们的人际交往变得更加平淡、更有偏见或更加粗鲁。
- en: For most of history, communicating with a computer has not been like communicating
    with a person. In their earliest years, computers required carefully constructed
    instructions, delivered through punch cards; then came a command-line interface,
    followed by menus and options and text boxes. If you wanted results, you needed
    to learn the computer’s language.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在大部分历史中，与计算机交流不像与人交流。在它们最早的年代，计算机需要通过穿孔卡仔细构造的指令来运行；然后是命令行界面，接着是菜单、选项和文本框。如果你想得到结果，你需要学会计算机的语言。
- en: 'This is beginning to change. Large language models—the technology undergirding
    modern chatbots—allow users to interact with computers through natural conversation,
    an innovation that introduces some baggage from human-to-human exchanges. Early
    on in our respective explorations of ChatGPT, the two of us found ourselves typing
    a word that we’d never said to a computer before: “Please.” The syntax of civility
    has crept into nearly every aspect of our encounters; we speak to this algebraic
    assemblage as if it were a person—even when we know that [it’s not](https://www.belfercenter.org/publication/ai-and-trust).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况正在发生改变。大型语言模型——现代聊天机器人的技术基础——允许用户通过自然对话与计算机进行交互，这一创新引入了一些来自人与人之间交流的包袱。在我们各自探索ChatGPT的早期阶段，我们发现自己在向计算机输入一个词，这是我们以前从未对计算机说过的：“请”。礼貌的语法已经渗入我们的每一个交流方面；我们对这个代数组合说话，就好像它是一个人一样——即使我们知道[它不是](https://www.belfercenter.org/publication/ai-and-trust)。
- en: Right now, this sort of interaction is a novelty. But as chatbots become a ubiquitous
    element of modern life and permeate many of our human-computer interactions, they
    have the potential to subtly reshape how we think about both computers and our
    fellow human beings.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 就目前而言，这种交互方式是一种新奇。但随着聊天机器人成为现代生活中无处不在的一个元素，并且渗透到我们许多人机交互中，它们有潜力在微妙地重塑我们对计算机和我们的人类同伴的看法。
- en: 'One direction that these chatbots may lead us in is toward a society where
    we ascribe humanity to AI systems, whether abstract chatbots or more physical
    robots. Just as we are [biologically primed](https://www.bbc.com/future/article/20140730-why-do-we-see-faces-in-objects)
    to see faces in objects, we imagine intelligence in anything that can hold a conversation.
    (This isn’t new: People projected intelligence and empathy onto the very primitive
    1960s chatbot, [Eliza](https://www.theatlantic.com/ideas/archive/2022/06/google-lamda-chatbot-sentient-ai/661322/).)
    We say “please” to LLMs because it feels wrong not to.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这些聊天机器人可能引导我们朝着一个将人性赋予AI系统的社会发展，无论是抽象的聊天机器人还是更具体的机器人。正如我们在物体中[生物学上被激发出](https://www.bbc.com/future/article/20140730-why-do-we-see-faces-in-objects)看到面孔，我们在任何能进行对话的东西中都想象出智能。（这并不新鲜：人们曾把智能和同理心投射到非常原始的60年代聊天机器人[Eliza](https://www.theatlantic.com/ideas/archive/2022/06/google-lamda-chatbot-sentient-ai/661322/)上。）我们对LLM说“请”，是因为不这样做感觉不对。
- en: Chatbots are growing only more common, and there is reason to believe they will
    become [ever more intimate parts of our lives](https://www.theatlantic.com/podcasts/archive/2023/08/are-ai-relationships-real/674965/).
    The market for AI companions, ranging from friends to romantic partners, is already
    crowded. Several companies are working on AI assistants, akin to secretaries or
    butlers, that will [anticipate and satisfy our needs](https://www.cbsnews.com/news/walmart-artificial-intelligence-retail/#:~:text=Called%20%22InHome%20Replenishment%2C%22%20the,%2C%20monthly%20schedule%2C%20for%20example.).
    And other companies are working on AI therapists, mediators, and life coaches—even
    simulacra of our dead relatives. More generally, chatbots will likely become the
    interface through which we interact with all sorts of computerized processes—an
    AI that responds to our style of language, every nuance of emotion, even tone
    of voice.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[聊天机器人](https://www.theatlantic.com/podcasts/archive/2023/08/are-ai-relationships-real/674965/)越来越普遍，有理由相信它们将成为我们生活中[越来越亲密的一部分](https://www.theatlantic.com/podcasts/archive/2023/08/are-ai-relationships-real/674965/)。从朋友到恋人等各种AI伴侣的市场已经相当拥挤。有几家公司正在研发类似秘书或男仆的AI助手，它们将[预测并满足我们的需求](https://www.cbsnews.com/news/walmart-artificial-intelligence-retail/#:~:text=Called%20%22InHome%20Replenishment%2C%22%20the,%2C%20monthly%20schedule%2C%20for%20example.)。其他公司正在研发AI心理医生、调解员和生活教练，甚至是我们已故亲属的仿真。更一般地说，聊天机器人很可能成为我们与各种计算机化流程交互的界面——一种响应我们语言风格、每一丝情感细微差别甚至语调的AI。'
- en: 'Many users will be primed to think of these AIs as friends, rather than the
    corporate-created systems that they are. The internet already spies on us through
    systems such as Meta’s advertising network, and LLMs will likely join in: OpenAI’s
    [privacy policy](https://openai.com/policies/privacy-policy), for example, already
    outlines the many different types of personal information the company collects.
    The difference is that the chatbots’ natural-language interface will make them
    feel more humanlike—reinforced with every politeness on both sides—and we could
    easily miscategorize them in our minds.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 许多用户将被引导将这些AI视为朋友，而不是它们实际上是的企业创建的系统。互联网已经通过Meta的广告网络等系统对我们进行监视，LLM很可能也会加入其中：例如，OpenAI的[隐私政策](https://openai.com/policies/privacy-policy)已经概述了公司收集的许多不同类型的个人信息。不同之处在于，聊天机器人的自然语言界面会让它们感觉更像人类——在双方的每一次礼貌交流中得到强化——我们很容易在心中错误分类它们。
- en: Major chatbots do not yet alter how they communicate with users to satisfy their
    parent company’s business interests, but market pressure might push things in
    that direction. Reached for comment about this, a spokesperson for OpenAI pointed
    to a section of the privacy policy noting that the company does not currently
    sell or share personal information for “cross-contextual behavioral advertising,”
    and that the company does not “process sensitive Personal Information for the
    purposes of inferring characteristics about a consumer.” In an interview with
    [*Axios*](https://www.axios.com/2024/01/17/sam-altman-davos-ai-future-interview)
    earlier today, OpenAI CEO Sam Altman said future generations of AI may involve
    “quite a lot of individual customization,” and “that’s going to make a lot of
    people uncomfortable.”
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 主要的聊天机器人目前还没有改变它们与用户交流的方式来满足其母公司的商业利益，但市场压力可能会推动事情朝着这个方向发展。OpenAI的发言人在被问及此事时指出了隐私政策中的一节，该节指出公司目前不出售或分享个人信息进行“跨上下文行为广告”，并且公司不会“处理敏感个人信息以推断有关消费者的特征”。在今天早些时候的[*Axios*](https://www.axios.com/2024/01/17/sam-altman-davos-ai-future-interview)采访中，OpenAI首席执行官Sam
    Altman表示，未来的AI可能会涉及“相当多的个性化定制”，“这将让很多人感到不舒服”。
- en: Other computing technologies have been shown to shape our cognition. Studies
    indicate that autocomplete on websites and in word processors can dramatically
    reorganize our writing. Generally, these recommendations result in blander, [more
    predictable](https://www.eecs.harvard.edu/~kgajos/papers/2020/arnold20predictive.pdf)
    prose. And where autocomplete systems give biased prompts, they result in biased
    writing. In one [benign experiment](https://www.eecs.harvard.edu/~kgajos/papers/2018/arnold18sentiment.pdf),
    positive autocomplete suggestions led to more positive restaurant reviews, and
    negative autocomplete suggestions led to the reverse. The effects could go far
    beyond tweaking our writing styles to affecting our mental health, just as with
    the potentially depression- and anxiety-inducing social-media platforms [of today](https://mitsloan.mit.edu/ideas-made-to-matter/study-social-media-use-linked-to-decline-mental-health).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 其他计算技术已经被证明可以塑造我们的认知。研究表明，在网站和文字处理器上的自动补全功能可以极大地重新组织我们的写作。一般来说，这些建议导致[更加平淡](https://www.eecs.harvard.edu/~kgajos/papers/2020/arnold20predictive.pdf)、更加可预测的散文。而当自动补全系统给出偏见提示时，它们会导致有偏见的写作。在一个[良性实验](https://www.eecs.harvard.edu/~kgajos/papers/2018/arnold18sentiment.pdf)中，积极的自动补全建议导致更多积极的餐厅评论，而消极的自动补全建议则导致相反的效果。其影响可能远远超出调整我们的写作风格，影响我们的心理健康，就像今天的社交媒体平台可能导致抑郁和焦虑一样。
- en: 'The other direction these chatbots may take us is even more disturbing: into
    a world where our conversations with them result in our treating our fellow human
    beings with the apathy, disrespect, and incivility we more typically show machines.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这些聊天机器人可能带领我们朝着另一个更加令人不安的方向发展：一个世界，在这个世界里，我们与它们的对话导致我们对待我们的人类同伴的冷漠、不尊重和不文明的方式更典型。
- en: 'Today’s chatbots perform best when instructed with a level of precision that
    would be appallingly rude in human conversation, stripped of any conversational
    pleasantries that the model could misinterpret: “Draft a 250-word paragraph in
    my typical writing style, detailing three examples to support the following point
    and cite your sources.” Not even the most detached corporate CEO would likely
    talk this way to their assistant, but it’s common with chatbots.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 今天的聊天机器人在表现最佳时需要以一种对话礼貌度而言会令人震惊的精度指令，剥夺了模型可能会误解的任何对话礼貌用语：“用我的典型写作风格起草一个250字的段落，详细说明三个支持以下观点的例子，并引用你的来源。”即使是最超然的公司CEO也不太可能这样对待他们的助手，但这在与聊天机器人交流中很常见。
- en: If chatbots truly become the dominant daily conversation partner for some people,
    there is an acute risk that these users will adopt a lexicon of AI commands even
    when talking to other humans. Rather than speaking with empathy, subtlety, and
    nuance, we’ll be trained to speak with the cold precision of a programmer talking
    to a computer. The colorful aphorisms and anecdotes that give conversations their
    inherently human quality, but that often confound large language models, could
    begin to vanish from the human discourse.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果聊天机器人真的成为某些人每天的主要对话伙伴，那么这些用户存在一个严重的风险，即当他们与其他人交谈时也会采用AI命令的词汇。与其说是用同理心、微妙和细微差别说话，我们更可能被训练成用程序员与计算机交谈的冷酷精确。给对话赋予其本质人类品质的丰富警句和轶事，但这些警句和轶事经常会让大型语言模型感到困惑，可能会开始从人类话语中消失。
- en: For precedent, one need only look at the ways that bot accounts already degrade
    digital discourse on social media, inflaming passions with crudely programmed
    responses to deeply emotional topics; they [arguably](https://www.cjr.org/the_media_today/nature_study_trump_bots_twitter.php)
    played a role in sowing discord and polarizing voters in the 2016 election. But
    AI companions are likely to be a far larger part of some users’ social circle
    than the bots of today, potentially having a much larger impact on how those people
    use language and navigate relationships. What is unclear is whether this will
    negatively affect one user in a billion or a large portion of them.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 以先例为例，我们只需看看机器人账户如何在社交媒体上已经破坏了数字化话语，通过对深情话题的粗略编程响应来激起激情；它们[可以说](https://www.cjr.org/the_media_today/nature_study_trump_bots_twitter.php)在2016年选举中起到了播下不和与极端化选民的作用。但人工智能伴侣很可能成为某些用户社交圈的一个更大的组成部分，比起今天的机器人，它们可能对这些人如何使用语言和建立关系产生更大的影响。不清楚的是这是否会对十亿分之一的用户产生负面影响，还是对其中大部分产生负面影响。
- en: Such a shift is unlikely to transform human conversations into cartoonishly
    robotic recitations overnight, but it could subtly and meaningfully reshape colloquial
    conversation over the course of years, just as the character limits of text messages
    affected so much of colloquial writing, turning terms such as *LOL*, *IMO*, and
    *TMI* into everyday vernacular.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的转变不太可能一夜之间将人类的对话转变为卡通般的机器化复述，但它可能在多年的过程中悄然而有意义地改变口头交流，就像短信的字符限制影响了口语写作的许多方面一样，将诸如*LOL*、*IMO*和*TMI*之类的术语变成了日常用语。
- en: AI chatbots are always there when you need them to be, for whatever you need
    them for. People aren’t like that. Imagine a future filled with people who have
    spent years conversing with their AI friends or romantic partners. Like a person
    whose only sexual experiences have been mediated by pornography or erotica, they
    could have unrealistic expectations of human partners. And the more ubiquitous
    and lifelike the chatbots become, the greater the impact could be.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能聊天机器人总是在你需要的时候出现，无论你需要什么。人们并非如此。想象一下充满了与他们的人工智能朋友或爱人交谈多年的人的未来。就像那些唯一性经历被色情片或情色文学中介的人一样，他们可能对人类伴侣有不切实际的期望。而且，聊天机器人变得越来越普遍和逼真，影响可能会越来越大。
- en: More generally, AI might accelerate the disintegration of institutional and
    social trust. Technologies such as Facebook were supposed to bring the world together,
    but in the intervening years, the public has become more and more suspicious of
    the people around them and less trusting of civic institutions. AI may drive people
    further toward isolation and suspicion, always unsure whether the person they’re
    chatting with is actually a machine, and treating them as inhuman regardless.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 更普遍地说，人工智能可能加速了机构和社会信任的瓦解。像Facebook这样的技术本应将世界联系在一起，但在过去的几年中，公众对周围的人越来越怀疑，对公民制度的信任也在减少。人工智能可能会进一步推动人们走向孤立和怀疑，总是不确定他们正在聊天的人是否真的是一个机器，并且对待他们视为非人类。
- en: Of course, history is replete with people claiming that the digital sky is falling,
    bemoaning each new invention as the end of civilization as we know it. In the
    end, LLMs may be little more than the word processor of tomorrow, a handy innovation
    that makes things a little easier while leaving most of our lives untouched. Which
    path we take depends on how we train the chatbots of tomorrow, but it also depends
    on whether we invest in strengthening the bonds of civil society today.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，历史上充斥着人们声称数字天空将坠落的说法，为每一项新发明而哀叹，称其为我们所知的文明的终结。最终，大型语言模型可能只是明天的文字处理器，一种方便的创新，使事情变得更容易，同时让我们生活的大部分内容保持不变。我们选择的道路取决于我们如何训练明天的聊天机器人，但也取决于我们是否投资于今天加强公民社会联系。
- en: 'Categories: [AI and Large Language Models](https://www.schneier.com/essays/ai-and-large-language-models/),
    [Internet and Society](https://www.schneier.com/essays/society/)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：[人工智能和大型语言模型](https://www.schneier.com/essays/ai-and-large-language-models/)，[互联网与社会](https://www.schneier.com/essays/society/)
- en: 'Tags: [Atlantic](https://www.schneier.com/essays/atlantic/)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 标签：[大西洋](https://www.schneier.com/essays/atlantic/)
