["```\nimport transformers \nimport torch\nimport torch.nn as nn\nimport onnx\nfrom transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n\nclass LlamaModel(nn.Module):\n    def __init__(self, model):\n        super(LlamaModel, self).__init__()\n        self.model = model\n    def forward(self, input_ids, attention_mask, position_ids,\n                pkv0, pkv1, pkv2, pkv3, pkv4, pkv5, pkv6, pkv7, pkv8, pkv9, pkv10,\n                pkv11, pkv12, pkv13, pkv14, pkv15, pkv16, pkv17, pkv18, pkv19, pkv20,\n                pkv21, pkv22, pkv23, pkv24, pkv25, pkv26, pkv27, pkv28, pkv29, pkv30,\n                pkv31, pkv32, pkv33, pkv34, pkv35, pkv36, pkv37, pkv38, pkv39, pkv40,\n                pkv41, pkv42, pkv43, pkv44, pkv45, pkv46, pkv47, pkv48, pkv49, pkv50,\n                pkv51, pkv52, pkv53, pkv54, pkv55, pkv56, pkv57, pkv58, pkv59, pkv60,\n                pkv61, pkv62, pkv63):\n        past_key_values = (\n            (pkv0, pkv1), (pkv2, pkv3), (pkv4, pkv5), (pkv6, pkv7), (pkv8, pkv9), (pkv10,\n            pkv11), (pkv12, pkv13), (pkv14, pkv15), (pkv16, pkv17), (pkv18, pkv19), (pkv20,\n            pkv21), (pkv22, pkv23), (pkv24, pkv25), (pkv26, pkv27), (pkv28, pkv29), (pkv30,\n            pkv31), (pkv32, pkv33), (pkv34, pkv35), (pkv36, pkv37), (pkv38, pkv39), (pkv40,\n            pkv41), (pkv42, pkv43), (pkv44, pkv45), (pkv46, pkv47), (pkv48, pkv49), (pkv50,\n            pkv51), (pkv52, pkv53), (pkv54, pkv55), (pkv56, pkv57), (pkv58, pkv59), (pkv60,\n            pkv61), (pkv62, pkv63))\n        o = self.model(use_cache=True, return_dict=True,\n            input_ids=input_ids, attention_mask=attention_mask, position_ids=position_ids, past_key_values=past_key_values)\n        pkv = o.past_key_values\n        return [o.logits,\n               pkv[0][0], pkv[0][1], pkv[1][0], pkv[1][1], pkv[2][0], pkv[2][1], pkv[3][0], pkv[3][1], pkv[4][0], pkv[4][1],\n               pkv[5][0], pkv[5][1], pkv[6][0], pkv[6][1], pkv[7][0], pkv[7][1], pkv[8][0], pkv[8][1], pkv[9][0], pkv[9][1],\n               pkv[10][0], pkv[10][1], pkv[11][0], pkv[11][1], pkv[12][0], pkv[12][1], pkv[13][0], pkv[13][1], pkv[14][0], pkv[14][1],\n               pkv[15][0], pkv[15][1], pkv[16][0], pkv[16][1], pkv[17][0], pkv[17][1], pkv[18][0], pkv[18][1], pkv[19][0], pkv[19][1],\n               pkv[20][0], pkv[20][1], pkv[21][0], pkv[21][1], pkv[22][0], pkv[22][1], pkv[23][0], pkv[23][1], pkv[24][0], pkv[24][1],\n               pkv[25][0], pkv[25][1], pkv[26][0], pkv[26][1], pkv[27][0], pkv[27][1], pkv[28][0], pkv[28][1], pkv[29][0], pkv[29][1],\n               pkv[30][0], pkv[30][1], pkv[31][0], pkv[31][1] ]\n\nwith torch.no_grad():\n\n    dummy_input = (torch.tensor([[1, 2, 3]], dtype=torch.int64),\n                  torch.tensor([[1, 1, 1, 1, 1, 1]], dtype=torch.int64),\n                  torch.tensor([[3, 4, 5]], dtype=torch.int64))\n    for i in range(64):\n        dummy_input += (torch.randn(1, 8, 3, 128),)\n    input_names = [ \"input_ids\", \"attention_mask\", \"position_ids\",\n                \"pkv0\", \"pkv1\", \"pkv2\", \"pkv3\", \"pkv4\", \"pkv5\", \"pkv6\", \"pkv7\", \"pkv8\", \"pkv9\", \"pkv10\",\n                \"pkv11\", \"pkv12\", \"pkv13\", \"pkv14\", \"pkv15\", \"pkv16\", \"pkv17\", \"pkv18\", \"pkv19\", \"pkv20\",\n                \"pkv21\", \"pkv22\", \"pkv23\", \"pkv24\", \"pkv25\", \"pkv26\", \"pkv27\", \"pkv28\", \"pkv29\", \"pkv30\",\n                \"pkv31\", \"pkv32\", \"pkv33\", \"pkv34\", \"pkv35\", \"pkv36\", \"pkv37\", \"pkv38\", \"pkv39\", \"pkv40\",\n                \"pkv41\", \"pkv42\", \"pkv43\", \"pkv44\", \"pkv45\", \"pkv46\", \"pkv47\", \"pkv48\", \"pkv49\", \"pkv50\",\n                \"pkv51\", \"pkv52\", \"pkv53\", \"pkv54\", \"pkv55\", \"pkv56\", \"pkv57\", \"pkv58\", \"pkv59\", \"pkv60\",\n                \"pkv61\", \"pkv62\", \"pkv63\" ]\n\n    output_names = [ \"logits\",\n                    \"opkv0\", \"opkv1\", \"opkv2\", \"opkv3\", \"opkv4\", \"opkv5\", \"opkv6\", \"opkv7\", \"opkv8\", \"opkv9\", \"opkv10\",\n                    \"opkv11\", \"opkv12\", \"opkv13\", \"opkv14\", \"opkv15\", \"opkv16\", \"opkv17\", \"opkv18\", \"opkv19\", \"opkv20\",\n                    \"opkv21\", \"opkv22\", \"opkv23\", \"opkv24\", \"opkv25\", \"opkv26\", \"opkv27\", \"opkv28\", \"opkv29\", \"opkv30\",\n                    \"opkv31\", \"opkv32\", \"opkv33\", \"opkv34\", \"opkv35\", \"opkv36\", \"opkv37\", \"opkv38\", \"opkv39\", \"opkv40\",\n                    \"opkv41\", \"opkv42\", \"opkv43\", \"opkv44\", \"opkv45\", \"opkv46\", \"opkv47\", \"opkv48\", \"opkv49\", \"opkv50\",\n                    \"opkv51\", \"opkv52\", \"opkv53\", \"opkv54\", \"opkv55\", \"opkv56\", \"opkv57\", \"opkv58\", \"opkv59\", \"opkv60\",\n                    \"opkv61\", \"opkv62\", \"opkv63\" ]\n\n    torch.onnx.export(LlamaModel(model), dummy_input, \"/Users/Vito/Desktop/Mistral7BInst/model.onnx\", verbose=False,\n        input_names=input_names, output_names=output_names,\n        opset_version=14, do_constant_folding=True, export_params=True,\n        dynamic_axes={\n                'input_ids': {1: 'dim0'},\n                'attention_mask': {1: 'dim1'},\n                'position_ids': {1: 'dim2'},\n                'pkv0': {2: 'dim3'}, 'pkv1': {2: 'dim3'}, 'pkv2': {2: 'dim3'}, 'pkv3': {2: 'dim3'}, 'pkv4': {2: 'dim3'},\n                'pkv5': {2: 'dim3'}, 'pkv6': {2: 'dim3'}, 'pkv7': {2: 'dim3'}, 'pkv8': {2: 'dim3'}, 'pkv9': {2: 'dim3'},\n                'pkv10': {2: 'dim3'}, 'pkv11': {2: 'dim3'}, 'pkv12': {2: 'dim3'}, 'pkv13': {2: 'dim3'}, 'pkv14': {2: 'dim3'},\n                'pkv15': {2: 'dim3'}, 'pkv16': {2: 'dim3'}, 'pkv17': {2: 'dim3'}, 'pkv18': {2: 'dim3'}, 'pkv19': {2: 'dim3'},\n                'pkv20': {2: 'dim3'}, 'pkv21': {2: 'dim3'}, 'pkv22': {2: 'dim3'}, 'pkv23': {2: 'dim3'}, 'pkv24': {2: 'dim3'},\n                'pkv25': {2: 'dim3'}, 'pkv26': {2: 'dim3'}, 'pkv27': {2: 'dim3'}, 'pkv28': {2: 'dim3'}, 'pkv29': {2: 'dim3'},\n                'pkv30': {2: 'dim3'}, 'pkv31': {2: 'dim3'}, 'pkv32': {2: 'dim3'}, 'pkv33': {2: 'dim3'}, 'pkv34': {2: 'dim3'},\n                'pkv35': {2: 'dim3'}, 'pkv36': {2: 'dim3'}, 'pkv37': {2: 'dim3'}, 'pkv38': {2: 'dim3'}, 'pkv39': {2: 'dim3'},\n                'pkv40': {2: 'dim3'}, 'pkv41': {2: 'dim3'}, 'pkv42': {2: 'dim3'}, 'pkv43': {2: 'dim3'}, 'pkv44': {2: 'dim3'},\n                'pkv45': {2: 'dim3'}, 'pkv46': {2: 'dim3'}, 'pkv47': {2: 'dim3'}, 'pkv48': {2: 'dim3'}, 'pkv49': {2: 'dim3'},\n                'pkv50': {2: 'dim3'}, 'pkv51': {2: 'dim3'}, 'pkv52': {2: 'dim3'}, 'pkv53': {2: 'dim3'}, 'pkv54': {2: 'dim3'},\n                'pkv55': {2: 'dim3'}, 'pkv56': {2: 'dim3'}, 'pkv57': {2: 'dim3'}, 'pkv58': {2: 'dim3'}, 'pkv59': {2: 'dim3'},\n                'pkv60': {2: 'dim3'}, 'pkv61': {2: 'dim3'}, 'pkv62': {2: 'dim3'}, 'pkv63': {2: 'dim3'},\n        })\n```"]