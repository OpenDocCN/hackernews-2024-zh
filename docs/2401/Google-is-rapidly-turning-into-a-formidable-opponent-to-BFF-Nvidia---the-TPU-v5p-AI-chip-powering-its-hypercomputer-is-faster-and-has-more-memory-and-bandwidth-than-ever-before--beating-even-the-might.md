<!--yml

category: 未分类

date: 2024-05-27 15:10:50

-->

# Google 正迅速成为 BFF Nvidia 的强大竞争对手 — TPU v5p AI 芯片驱动其超级计算机的速度更快，内存和带宽比以往任何时候都多，甚至超过了强大的 H100 | TechRadar

> 来源：[https://www.techradar.com/pro/google-is-rapidly-turning-into-a-formidable-opponent-to-bff-nvidia-the-tpu-v5p-ai-chip-powering-its-hypercomputer-is-faster-and-has-more-memory-and-bandwidth-than-ever-before-beating-even-the-mighty-h100](https://www.techradar.com/pro/google-is-rapidly-turning-into-a-formidable-opponent-to-bff-nvidia-the-tpu-v5p-ai-chip-powering-its-hypercomputer-is-faster-and-has-more-memory-and-bandwidth-than-ever-before-beating-even-the-mighty-h100)

[Google](https://www.techradar.com/sg/tag/google) 伴随着其 [Gemini](https://www.techradar.com/computing/artificial-intelligence/what-is-google-gemini) AI 模型的最新推出，发布了其旗舰张量处理单元（TPU）的最新版本，用于 AI 训练和推理，似乎是试图挑战 Nvidia 自己的市场领先的 GPU。

TPU v5p — Google 最强大的定制 AI 加速器 — 已经部署用于驱动公司的“AI 超级计算机”。这是一个专门用于运行 AI 应用程序的超级计算机架构，而不是通常运行科学工作负载的超级计算机，因为 TPU 不适合这种用途。

Google 的最新 TPU 版本每个 Pod（组成系统的部分）有 8,960 个芯片，而 v4 中有 4,096 个，就每个 Pod 的 FLOPs 总可用性而言，可扩展性提高了四倍。这些新的 Pod 提供了 4,800Gbps 的吞吐量。新的 Pod 还有 95GB 的高带宽内存（HBM），而 TPU v4 中只有 32GB HBM RAM。

## Nvidia H100 vs Google TPU v5p: 哪个更快？

不同于 Nvidia 将其 GPU 提供给其他公司购买，Google 的定制 TPU 仍然是公司内部使用，用于其自己的产品和服务。长期以来，Google 的 TPU 一直用于支持其包括 Gmail、YouTube 和 Android 在内的服务，最新版本也用于训练 Gemini。

Google 的 v5p TPU 在训练大型语言模型方面比 TPU v4 快 2.8 倍，并且性价比提高了 2.1 倍。尽管今年早些时候发布的中间版本 TPU v5e 在所有三款产品中性价比最高，但它只比 TPU v4 快 1.9 倍，使得 TPU v5p 成为最强大的产品。

它甚至强大到可以与 Nvidia 广受欢迎的 H100 GPU 相媲美，后者是最佳图形卡之一，用于 AI 工作负载。根据公司自己的数据，这个组件在训练工作负载方面比 Nvidia 的 A100 GPU 快四倍。

与此同时，据[其于四月发布的研究](https://arxiv.org/abs/2304.01433)显示，谷歌的 TPU v4 估计比 A100 快 1.2 到 1.7 倍。令人难以置信的粗略计算表明，因此 TPU v5p 大约比 A100 快 3.4 到 4.8 倍 - 这使其与 H100 不相上下，尽管在得出任何结论之前需要进行更详细的基准测试。

订阅 TechRadar Pro 通讯，获取您的企业成功所需的所有头条新闻、观点、特色和指导！

### 更多来自 TechRadar Pro
