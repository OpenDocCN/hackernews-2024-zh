- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:28:53'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: 'SIEVE is simpler than LRU - SIEVE: an Efficient Turn-Key Eviction Algorithm
    for Web Caches'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://cachemon.github.io/SIEVE-website/blog/2023/12/17/sieve-is-simpler-than-lru/](https://cachemon.github.io/SIEVE-website/blog/2023/12/17/sieve-is-simpler-than-lru/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: SIEVE is simpler than LRU
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Caching is a method of storing temporary data for quick access to keep the
    online world running smoothly. But with limited space comes a critical decision:
    what to keep and discard. This is where **eviction algorithms** come into play.
    Our team recently designed a new cache eviction algorithm called **SIEVE**: it
    is very effective and simple with just one queue.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: '***Updates***: *The original writing style attracted considerable attention.
    We have updated the blog post for greater clarity and straightforwardness.* We
    also include an easy-to-reproduce result at [https://observablehq.com/@1a1a11a/sieve-miss-ratio-plots](https://observablehq.com/@1a1a11a/sieve-miss-ratio-plots).'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: The Importance of Simplicity
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is important to keep cache eviction algorithms simple. Complex algorithms
    can bring headaches from time to time. For example, they can be tricky to debug
    and analyze when the miss ratio is high. Moreover, complexity means CPU cycles
    are needed to make the decisions.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: On the flip side, simpler eviction methods usually do an excellent job of providing
    good predictability and throughput. For example, the Apache traffic server uses
    FIFO, [MemC3](https://www.usenix.org/conference/nsdi13/technical-sessions/presentation/fan)
    uses CLOCK, and [Segcache](https://www.usenix.org/conference/nsdi21/presentation/yang-juncheng)
    uses FIFO-Merge eviction algorithms. It's crucial to note that while these approaches
    excel in throughput, some compromise on cache efficiency.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: Meet SIEVE
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SIEVE is a cache eviction algorithm that decides what to keep in the cache and
    what to discard. It achieves both simplicity and efficiency.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Design
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Data structure.** SIEVE requires only one queue and one pointer called "hand".
    **The queue maintains the insertion order between objects**. Each object in the
    queue uses one bit to track the visited/non-visited status. The hand points to
    the next eviction candidate in the cache and moves from the tail to the head.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '**SIEVE operations.** A cache hit changes the visited bit of the accessed object
    to 1\. SIEVE does not need to perform any operation for a popular object whose
    visited bit is already set. During a cache miss, SIEVE examines the object pointed
    by the hand. If it has been visited, the visited bit is reset, and the hand moves
    to the next position (the retained object stays in the original position of the
    queue). It continues this process until it encounters an object with the visited
    bit being 0 and evicts it. After the eviction, the hand points to the next position
    (the previous object in the queue). While an evicted object is in the middle of
    the queue most of the time, a new object is always inserted into the head of the
    queue.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: An illustration of SIEVE
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '**SIEVE vs. CLOCK** At first glance, SIEVE is similar to CLOCK/Second Chance/FIFO-Reinsertion
    - *Note that they are different implementations of the same eviction algorithm*.
    Each algorithm maintains a queue in which each object is associated with a visited
    bit to track its access status. Visited objects are retained (also called "survived")
    during an eviction. Notably, new objects are inserted at the head of the queue
    in both SIEVE and FIFO-Reinsertion. However, the hand in SIEVE moves from the
    tail to the head over time, whereas the hand in FIFO-Reinsertion stays at the
    tail. *The key difference is where a retained object is kept.* SIEVE keeps it
    in the old position, while FIFO-Reinsertion inserts it at the head, together with
    newly inserted objects.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: SIEVE vs. FIFO-Reinsertion
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: See the [sieve cache implementation code](#sieve-cache-code) at the end of this
    blog post for a detailed example.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: Performance
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We evaluate SIEVE to answer the following questions:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Does SIEVE have higher efficiency than state-of-the-art cache eviction algorithms?
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is SIEVE simpler than other algorithms?
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can SIEVE improve a cache's throughput and scalability?
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this blog post, we only show part of our evaluation results. If you're interested
    in the full evaluation, please refer to [our paper](https://yazhuozhang.com/assets/pdf/nsdi24-sieve.pdf).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Efficiency
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Our evaluation, involving over 1559 traces from diverse datasets containing
    247,017 million requests to 14,852 million objects, shows that SIEVE outperforms
    all state-of-the-art eviction algorithms on more than 45% of the traces.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: The following figure shows the miss ratio reduction (from FIFO) of different
    algorithms across traces. The whiskers on the boxplots are defined using p10 and
    p90, allowing us to disregard extreme data and concentrate on the typical cases.
    SIEVE demonstrates the most significant reductions across nearly all percentiles.
    For example, SIEVE reduces FIFO's miss ratio by more than 42% on 10% of the traces
    (top whisker), with a mean of 21% on one of the largest CDN datasets. As a comparison,
    all other algorithms have smaller reductions on this dataset. Compared to advanced
    algorithms, e.g., ARC, SIEVE reduces ARC miss ratio by up to 63.2% with a mean
    of 1.5%.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了不同算法在跟踪数据中错失率（与 FIFO 相比）的减少。箱线图上的须根据 p10 和 p90 进行定义，使我们能够忽略极端数据并集中在典型情况上。SIEVE
    在几乎所有百分位数上都显示出最显著的减少。例如，SIEVE 在 10% 的跟踪数据上（顶部须）将 FIFO 的错失率减少了超过 42%，在最大的 CDN 数据集中的平均值为
    21%。相比之下，其他所有算法在此数据集上的减少都较小。与先进算法相比，例如 ARC，SIEVE 的错失率最多可以减少 63.2%，平均值为 1.5%。
- en: Simplicity
  id: totrans-30
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 简单性
- en: 'SIEVE is very simple. We delved into the most popular cache libraries and systems
    across five diverse programming languages: C++, Go, JavaScript, Python, and Rust.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: SIEVE 非常简单。我们深入研究了五种不同编程语言中最流行的缓存库和系统：C++、Go、JavaScript、Python 和 Rust。
- en: Despite the varied ways LRU is implemented across these libraries - some opt
    for doubly-linked lists, others for arrays - integrating SIEVE was easy. As illustrated
    in the Table, the required code changes to replace LRU with SIEVE were minimal.
    In all cases, it took no more than 21 lines of code modifications (tests not included).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在这些库中实现 LRU 的方式各不相同 - 有些选择双链表，其他选择数组 - 但集成 SIEVE 很容易。正如表中所示，将 LRU 替换为 SIEVE
    所需的代码修改量很小。在所有情况下，代码修改量都不超过 21 行（不包括测试）。
- en: Throughput
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 吞吐量
- en: Besides efficiency, throughput is the other important metric for caching systems.
    Although we have implemented SIEVE in five different libraries, we focus on Cachelib's
    results.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 除了效率之外，吞吐量是缓存系统的另一个重要指标。虽然我们已经在五种不同的库中实现了 SIEVE，但我们专注于 Cachelib 的结果。
- en: Compared to these LRU-based algorithms, SIEVE does not require "promotion" at
    each cache hit. Therefore, it is faster and more scalable. At a single thread,
    SIEVE is 16% (17%) faster than the optimized LRU (TwoQ) and on the tested traces.
    At 16 threads, SIEVE shows more than 2× higher throughput than the optimized LRU
    and TwoQ.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 与基于 LRU 的算法相比，SIEVE 不需要在每次缓存命中时进行 "提升"。因此，它更快速、更可伸缩。在单线程上，SIEVE 比经过优化的 LRU（TwoQ）快
    16%（17%），并且在测试的跟踪数据上。在 16 个线程上，SIEVE 的吞吐量比经过优化的 LRU 和 TwoQ 高出 2 倍以上。
- en: SIEVE is beyond an eviction algorithm
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SIEVE 超越了一种淘汰算法。
- en: Beyond being a cache eviction algorithm, SIEVE can serve as a cache primitive
    for designing more advanced eviction policies. As a cache primitive, SIEVE can
    facilitate the design of more advanced eviction algorithms.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 除了作为缓存淘汰算法之外，SIEVE 还可以作为设计更先进的淘汰策略的缓存原语。作为缓存原语，SIEVE 可以促进更先进的淘汰算法的设计。
- en: We've plugged SIEVE into [LeCaR](https://www.usenix.org/conference/hotstorage18/presentation/vietri),
    [TwoQ](https://www.vldb.org/conf/1994/P439.PDF), [ARC](https://www.usenix.org/conference/fast-03/arc-self-tuning-low-overhead-replacement-cache),
    and [S3-FIFO](https://dl.acm.org/doi/10.1145/3600006.3613147), swapping out their
    LRU or FIFO queue for a SIEVE one.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经将 SIEVE 插入到 [LeCaR](https://www.usenix.org/conference/hotstorage18/presentation/vietri)，[TwoQ](https://www.vldb.org/conf/1994/P439.PDF)，[ARC](https://www.usenix.org/conference/fast-03/arc-self-tuning-low-overhead-replacement-cache)
    和 [S3-FIFO](https://dl.acm.org/doi/10.1145/3600006.3613147) 中，用 SIEVE 一个替换它们的
    LRU 或 FIFO 队列。
- en: Compared to SIEVE, LeCaR has much lower efficiency; however, when replacing
    the LRU in LeCaR with SIEVE, it significantly reduces LeCaR's miss ratio by 4.5%
    on average. TwoQ and ARC achieve efficiency close to SIEVE; however, when replacing
    the LRU with SIEVE, the efficiency of both algorithms gets boosted. These results
    highlight the potential of SIEVE as a powerful cache primitive for designing advanced
    cache eviction algorithms.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 与 SIEVE 相比，LeCaR 的效率要低得多；然而，当将 LeCaR 中的 LRU 替换为 SIEVE 时，平均减少了 4.5% 的 LeCaR 的错失率。TwoQ
    和 ARC 的效率接近 SIEVE；然而，当将 LRU 替换为 SIEVE 时，两个算法的效率都得到了提升。这些结果突显了 SIEVE 作为强大的缓存原语设计高级缓存淘汰算法的潜力。
- en: SIEVE is not scan-resistant
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SIEVE 不是防扫描的。
- en: Besides web cache workloads, we evaluated SIEVE on some old block cache workloads.
    However, SIEVE sometimes shows a miss ratio higher than LRU. The primary reason
    for this discrepancy is that SIEVE is not scan-resistant. In block cache workloads,
    which frequently feature scans, popular objects often intermingle with objects
    from scans. Consequently, both objects are rapidly evicted after insertion. Note
    that we made a mistake and used "scan-resistant" to mean something else. For the
    traditional sense of scans (larger than cache size), SIEVE is scan-resistant.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 Web 缓存工作负载外，我们还对一些旧的块缓存工作负载进行了评估。然而，SIEVE 有时会显示比 LRU 更高的未命中比例。造成这种差异的主要原因是
    SIEVE 不具备抗扫描性。在块缓存工作负载中，频繁出现扫描，流行对象通常与扫描对象混合在一起。因此，插入后两个对象都会被迅速逐出。请注意，我们犯了一个错误，并将“抗扫描”用于表示其他含义。对于传统意义上的扫描（大于缓存大小），SIEVE
    是抗扫描的。
- en: Since SIEVE does not use a ghost cache — a shadow cache that keeps track of
    recently evicted items to make smarter future eviction decisions — it cannot recognize
    the popular objects when they are requested again. This problem is less severe
    on the large cache size, but when the cache size is small, we observe that having
    a ghost is critical to be scan-resistant.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 SIEVE 不使用幽灵缓存——一个跟踪最近被逐出项的影子缓存，以便做出更智能的未来逐出决策——当流行对象再次被请求时，它无法识别。在缓存大小较大时，这个问题不太严重，但是当缓存大小较小时，我们观察到拥有幽灵是抗扫描的关键。
- en: '[Marc''s latest blog post](https://brooker.co.za/blog/2023/12/15/sieve.html)
    explored making sieve scan-resistant by adding a small counter for each item.
    It shows some wins and losses on different workloads.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[马克最新的博客文章](https://brooker.co.za/blog/2023/12/15/sieve.html)探讨了通过为每个项目添加一个小计数器来使筛选器抗扫描的方法。它展示了在不同工作负载下的一些收益和损失。'
- en: We'd Love to Hear from you
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们期待听到您的声音
- en: As we wrap up this blog post, we would like to give a big shoutout to the people
    and organizations that open-sourced and shared the traces. SIEVE presents an intriguing
    opportunity to explore and enhance the efficiency of web caching. **If you have
    questions or thoughts or have given SIEVE a try, we're eager to hear from you!
    Don't hesitate to get in touch :-)**
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们完成这篇博客文章，我们想要向开源和共享迹象的人们和组织致以最诚挚的感谢。SIEVE 提供了一个引人入胜的机会来探索和增强网络缓存的效率。**如果您有问题或想法，或者已经尝试过
    SIEVE，请务必与我们联系：）**
- en: Appendix
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录
- en: SIEVE Python Implementation
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: SIEVE Python 实现
- en: '[PRE0]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
