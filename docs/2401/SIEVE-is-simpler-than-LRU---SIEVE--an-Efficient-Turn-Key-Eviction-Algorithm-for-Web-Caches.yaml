- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:28:53'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'SIEVE is simpler than LRU - SIEVE: an Efficient Turn-Key Eviction Algorithm
    for Web Caches'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://cachemon.github.io/SIEVE-website/blog/2023/12/17/sieve-is-simpler-than-lru/](https://cachemon.github.io/SIEVE-website/blog/2023/12/17/sieve-is-simpler-than-lru/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: SIEVE is simpler than LRU
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Caching is a method of storing temporary data for quick access to keep the
    online world running smoothly. But with limited space comes a critical decision:
    what to keep and discard. This is where **eviction algorithms** come into play.
    Our team recently designed a new cache eviction algorithm called **SIEVE**: it
    is very effective and simple with just one queue.'
  prefs: []
  type: TYPE_NORMAL
- en: '***Updates***: *The original writing style attracted considerable attention.
    We have updated the blog post for greater clarity and straightforwardness.* We
    also include an easy-to-reproduce result at [https://observablehq.com/@1a1a11a/sieve-miss-ratio-plots](https://observablehq.com/@1a1a11a/sieve-miss-ratio-plots).'
  prefs: []
  type: TYPE_NORMAL
- en: The Importance of Simplicity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is important to keep cache eviction algorithms simple. Complex algorithms
    can bring headaches from time to time. For example, they can be tricky to debug
    and analyze when the miss ratio is high. Moreover, complexity means CPU cycles
    are needed to make the decisions.
  prefs: []
  type: TYPE_NORMAL
- en: On the flip side, simpler eviction methods usually do an excellent job of providing
    good predictability and throughput. For example, the Apache traffic server uses
    FIFO, [MemC3](https://www.usenix.org/conference/nsdi13/technical-sessions/presentation/fan)
    uses CLOCK, and [Segcache](https://www.usenix.org/conference/nsdi21/presentation/yang-juncheng)
    uses FIFO-Merge eviction algorithms. It's crucial to note that while these approaches
    excel in throughput, some compromise on cache efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Meet SIEVE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SIEVE is a cache eviction algorithm that decides what to keep in the cache and
    what to discard. It achieves both simplicity and efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Design
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Data structure.** SIEVE requires only one queue and one pointer called "hand".
    **The queue maintains the insertion order between objects**. Each object in the
    queue uses one bit to track the visited/non-visited status. The hand points to
    the next eviction candidate in the cache and moves from the tail to the head.'
  prefs: []
  type: TYPE_NORMAL
- en: '**SIEVE operations.** A cache hit changes the visited bit of the accessed object
    to 1\. SIEVE does not need to perform any operation for a popular object whose
    visited bit is already set. During a cache miss, SIEVE examines the object pointed
    by the hand. If it has been visited, the visited bit is reset, and the hand moves
    to the next position (the retained object stays in the original position of the
    queue). It continues this process until it encounters an object with the visited
    bit being 0 and evicts it. After the eviction, the hand points to the next position
    (the previous object in the queue). While an evicted object is in the middle of
    the queue most of the time, a new object is always inserted into the head of the
    queue.'
  prefs: []
  type: TYPE_NORMAL
- en: An illustration of SIEVE
  prefs: []
  type: TYPE_NORMAL
- en: '**SIEVE vs. CLOCK** At first glance, SIEVE is similar to CLOCK/Second Chance/FIFO-Reinsertion
    - *Note that they are different implementations of the same eviction algorithm*.
    Each algorithm maintains a queue in which each object is associated with a visited
    bit to track its access status. Visited objects are retained (also called "survived")
    during an eviction. Notably, new objects are inserted at the head of the queue
    in both SIEVE and FIFO-Reinsertion. However, the hand in SIEVE moves from the
    tail to the head over time, whereas the hand in FIFO-Reinsertion stays at the
    tail. *The key difference is where a retained object is kept.* SIEVE keeps it
    in the old position, while FIFO-Reinsertion inserts it at the head, together with
    newly inserted objects.'
  prefs: []
  type: TYPE_NORMAL
- en: SIEVE vs. FIFO-Reinsertion
  prefs: []
  type: TYPE_NORMAL
- en: See the [sieve cache implementation code](#sieve-cache-code) at the end of this
    blog post for a detailed example.
  prefs: []
  type: TYPE_NORMAL
- en: Performance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We evaluate SIEVE to answer the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Does SIEVE have higher efficiency than state-of-the-art cache eviction algorithms?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is SIEVE simpler than other algorithms?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can SIEVE improve a cache's throughput and scalability?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this blog post, we only show part of our evaluation results. If you're interested
    in the full evaluation, please refer to [our paper](https://yazhuozhang.com/assets/pdf/nsdi24-sieve.pdf).
  prefs: []
  type: TYPE_NORMAL
- en: Efficiency
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Our evaluation, involving over 1559 traces from diverse datasets containing
    247,017 million requests to 14,852 million objects, shows that SIEVE outperforms
    all state-of-the-art eviction algorithms on more than 45% of the traces.
  prefs: []
  type: TYPE_NORMAL
- en: The following figure shows the miss ratio reduction (from FIFO) of different
    algorithms across traces. The whiskers on the boxplots are defined using p10 and
    p90, allowing us to disregard extreme data and concentrate on the typical cases.
    SIEVE demonstrates the most significant reductions across nearly all percentiles.
    For example, SIEVE reduces FIFO's miss ratio by more than 42% on 10% of the traces
    (top whisker), with a mean of 21% on one of the largest CDN datasets. As a comparison,
    all other algorithms have smaller reductions on this dataset. Compared to advanced
    algorithms, e.g., ARC, SIEVE reduces ARC miss ratio by up to 63.2% with a mean
    of 1.5%.
  prefs: []
  type: TYPE_NORMAL
- en: Simplicity
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'SIEVE is very simple. We delved into the most popular cache libraries and systems
    across five diverse programming languages: C++, Go, JavaScript, Python, and Rust.'
  prefs: []
  type: TYPE_NORMAL
- en: Despite the varied ways LRU is implemented across these libraries - some opt
    for doubly-linked lists, others for arrays - integrating SIEVE was easy. As illustrated
    in the Table, the required code changes to replace LRU with SIEVE were minimal.
    In all cases, it took no more than 21 lines of code modifications (tests not included).
  prefs: []
  type: TYPE_NORMAL
- en: Throughput
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Besides efficiency, throughput is the other important metric for caching systems.
    Although we have implemented SIEVE in five different libraries, we focus on Cachelib's
    results.
  prefs: []
  type: TYPE_NORMAL
- en: Compared to these LRU-based algorithms, SIEVE does not require "promotion" at
    each cache hit. Therefore, it is faster and more scalable. At a single thread,
    SIEVE is 16% (17%) faster than the optimized LRU (TwoQ) and on the tested traces.
    At 16 threads, SIEVE shows more than 2× higher throughput than the optimized LRU
    and TwoQ.
  prefs: []
  type: TYPE_NORMAL
- en: SIEVE is beyond an eviction algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Beyond being a cache eviction algorithm, SIEVE can serve as a cache primitive
    for designing more advanced eviction policies. As a cache primitive, SIEVE can
    facilitate the design of more advanced eviction algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: We've plugged SIEVE into [LeCaR](https://www.usenix.org/conference/hotstorage18/presentation/vietri),
    [TwoQ](https://www.vldb.org/conf/1994/P439.PDF), [ARC](https://www.usenix.org/conference/fast-03/arc-self-tuning-low-overhead-replacement-cache),
    and [S3-FIFO](https://dl.acm.org/doi/10.1145/3600006.3613147), swapping out their
    LRU or FIFO queue for a SIEVE one.
  prefs: []
  type: TYPE_NORMAL
- en: Compared to SIEVE, LeCaR has much lower efficiency; however, when replacing
    the LRU in LeCaR with SIEVE, it significantly reduces LeCaR's miss ratio by 4.5%
    on average. TwoQ and ARC achieve efficiency close to SIEVE; however, when replacing
    the LRU with SIEVE, the efficiency of both algorithms gets boosted. These results
    highlight the potential of SIEVE as a powerful cache primitive for designing advanced
    cache eviction algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: SIEVE is not scan-resistant
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Besides web cache workloads, we evaluated SIEVE on some old block cache workloads.
    However, SIEVE sometimes shows a miss ratio higher than LRU. The primary reason
    for this discrepancy is that SIEVE is not scan-resistant. In block cache workloads,
    which frequently feature scans, popular objects often intermingle with objects
    from scans. Consequently, both objects are rapidly evicted after insertion. Note
    that we made a mistake and used "scan-resistant" to mean something else. For the
    traditional sense of scans (larger than cache size), SIEVE is scan-resistant.
  prefs: []
  type: TYPE_NORMAL
- en: Since SIEVE does not use a ghost cache — a shadow cache that keeps track of
    recently evicted items to make smarter future eviction decisions — it cannot recognize
    the popular objects when they are requested again. This problem is less severe
    on the large cache size, but when the cache size is small, we observe that having
    a ghost is critical to be scan-resistant.
  prefs: []
  type: TYPE_NORMAL
- en: '[Marc''s latest blog post](https://brooker.co.za/blog/2023/12/15/sieve.html)
    explored making sieve scan-resistant by adding a small counter for each item.
    It shows some wins and losses on different workloads.'
  prefs: []
  type: TYPE_NORMAL
- en: We'd Love to Hear from you
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we wrap up this blog post, we would like to give a big shoutout to the people
    and organizations that open-sourced and shared the traces. SIEVE presents an intriguing
    opportunity to explore and enhance the efficiency of web caching. **If you have
    questions or thoughts or have given SIEVE a try, we're eager to hear from you!
    Don't hesitate to get in touch :-)**
  prefs: []
  type: TYPE_NORMAL
- en: Appendix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SIEVE Python Implementation
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
