- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:51:12'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Seeing a Rose in Five Thousand Ways
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://cs.stanford.edu/~yzzhang/projects/rose/](https://cs.stanford.edu/~yzzhang/projects/rose/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <main class="main">
  prefs: []
  type: TYPE_NORMAL
- en: Seeing a Rose in Five Thousand Ways
  prefs: []
  type: TYPE_NORMAL
- en: Stanford University
  prefs: []
  type: TYPE_NORMAL
- en: University of Oxford
  prefs: []
  type: TYPE_NORMAL
- en: Cornell Tech, Cornell University
  prefs: []
  type: TYPE_NORMAL
- en: Stanford University
  prefs: []
  type: TYPE_NORMAL
- en: '*People where you live ... grow five thousand roses in one garden ... And yet
    what they’re looking for could be found in a single rose.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*--- "The Little Prince" by Antoine de Saint-Exupery*'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs: []
  type: TYPE_NORMAL
- en: What is a rose, visually? A rose comprises its intrinsics, including the distribution
    of geometry, texture, and material specific to its object category. With knowledge
    of these intrinsic properties, we may render roses of different sizes and shapes,
    in different poses, and under different lighting conditions. In this work, we
    build a generative model that learns to capture such object intrinsics from a
    single image, such as a photo of a bouquet. Such an image includes multiple instances
    of an object type. These instances all share the same intrinsics, but appear different
    due to a combination of variance within these intrinsics and differences in extrinsic
    factors, such as pose and illumination. Experiments show that our model successfully
    learns object intrinsics (distribution of geometry, texture, and material) for
    a wide range of objects, each from a single Internet image. Our method achieves
    superior results on multiple downstream tasks, including intrinsic image decomposition,
    shape and image generation, view synthesis, and relighting.
  prefs: []
  type: TYPE_NORMAL
- en: Learning from Internet Images
  prefs: []
  type: TYPE_NORMAL
- en: After training on a single Internet image containing a group of similar objects,
    our method can robustly recover the geometry and texture of the object class,
    and capture the variation among the observed instances. Note that our method has
    no access to camera intrinsic or extrinsic parameters, object poses, or illumination
    conditions.
  prefs: []
  type: TYPE_NORMAL
- en: The first column below shows training inputs. The second and third columns show
    rendered results and corresponding geometry.
  prefs: []
  type: TYPE_NORMAL
- en: 'Try it yourself: Move the slider to change viewpoints, lighting, and identities.'
  prefs: []
  type: TYPE_NORMAL
- en: BibTeX
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Acknowledgement
  prefs: []
  type: TYPE_NORMAL
- en: 'We would like to thank Angjoo Kanazawa and Josh Tenenbaum for detailed comments
    and feedbacks, thank Ruocheng Wang and Kai Zhang for insightful discussions, and
    thank Yiming Dou and Koven Yu for their advice in data collection. This work is
    supported in part by the Stanford Institute for Human-Centered AI (HAI), NSF CCRI
    #2120095, NSF RI #2211258, ONR MURI N00014-22-1-2740, Amazon, Bosch, Ford, Google,
    and Samsung.'
  prefs: []
  type: TYPE_NORMAL
- en: The website design is adapted from [SunStage](https://grail.cs.washington.edu/projects/sunstage/).
    The template source code for this webpage is available [here](https://github.com/zzyunzhi/template).
  prefs: []
  type: TYPE_NORMAL
- en: </main>
  prefs: []
  type: TYPE_NORMAL
