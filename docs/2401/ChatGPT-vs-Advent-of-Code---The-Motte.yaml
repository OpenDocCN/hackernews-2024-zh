- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-27 14:48:42'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-27 14:48:42
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: ChatGPT vs Advent of Code - The Motte
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT vs Advent of Code - The Motte
- en: 来源：[https://www.themotte.org/post/797/chatgpt-vs-advent-of-code](https://www.themotte.org/post/797/chatgpt-vs-advent-of-code)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.themotte.org/post/797/chatgpt-vs-advent-of-code](https://www.themotte.org/post/797/chatgpt-vs-advent-of-code)
- en: ChatGPT does Advent of Code 2023
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: ChatGPT参加Advent of Code 2023
- en: LLM are all the rage and people are worried that they will soon replace programmers
    (or, indeed, every possible office job) so I decided to do an experiment to see
    how well ChatGPT-4 does against Advent of Code 2023.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: LLM风头正劲，人们担心它们很快就会取代程序员（或者说是每一个可能的办公室工作），所以我决定进行一个实验，看看ChatGPT-4在Advent of Code
    2023中的表现如何。
- en: What is Advent of Code
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是Advent of Code
- en: Advent of Code (henceforth AoC) is an annual programming "event", held by [Eric
    Wastl](https://twitter.com/ericwastl), that takes place during the first 25 days
    of december. Each day at midnight a problem unlocks, consisting of an input file
    and a description of the required solution (either a number or a sequence of letters
    and numbers) to be determined by processing the input file. To solve the problem
    you have to submit to the website the correct solution. Once you do part 2 of
    the problem unlocks, usually a harder version of the problem in part 1. You don't
    have to submit any code so, in theory, you could solve everything by hand, however,
    usually, this is intractable and writing a program to do the work for you is the
    only easy way to solve the problem.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[Advent of Code](https://twitter.com/ericwastl)（以下简称AoC）是由[Eric Wastl](https://twitter.com/ericwastl)举办的年度编程“事件”，在每年的12月的头25天举行。每天午夜，一个问题解锁，包括一个输入文件和对所需解决方案的描述（可以是一个数字或一个字母和数字的序列），需要通过处理输入文件来确定。要解决问题，您必须向网站提交正确的解决方案。一旦您完成了问题的第2部分，通常是问题第1部分的更难的版本就会解锁。理论上，您不必提交任何代码，因此您可以通过手工解决所有问题，然而，通常情况下这是不可行的，编写一个程序来为您完成工作是解决问题的唯一简单方法。'
- en: There's also a leaderboard where participants are scored based on how fast they
    submitted a solution.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个排行榜，参与者根据提交解决方案的速度得分。
- en: 'Problems start very easy on day 1 (sometimes as easy as just asking for a program
    that sums all numbers in the input) and progress towards more difficult ones,
    but they never get very hard: a CS graduate should be able to solve all problems,
    except maybe 1 or 2, in a couple of hours each.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 问题从第1天开始非常简单（有时仅仅是要求编写一个程序来对输入中的所有数字求和），并逐渐进展到更困难的问题，但它们从来没有变得非常困难：一个计算机科学专业的毕业生应该能够在几个小时内解决所有问题，也许除了1或2个例外。
- en: Prior history
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 先前历史
- en: This isn't the first time ChatGPT (or LLMs) was used to participate in Advent
    of Code. In fact last year (2022) it was big news that users of ChatGPT were able,
    in multiple days, to reach the top of the global leaderboard. And this was enough
    of a concern that Eric explicitly banned ChatGPT users from submitting solutions
    before the global leaderboard was full (of course he also doesn't have any way
    to actually enforce this ban). [Some people](https://old.reddit.com/r/adventofcode/comments/18515qh/2023_the_year_of_gpt/)
    even expected GPT-4 to finish the whole year.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是ChatGPT（或LLMs）第一次参加Advent of Code。事实上，去年（2022年），ChatGPT的用户能够在多个日子里达到全球排行榜的顶端，这成为了一个大新闻。这引起了一些担忧，以至于Eric明确禁止ChatGPT用户在全球排行榜填满之前提交解决方案（当然，他也没有任何办法来实际执行这个禁令）。[一些人](https://old.reddit.com/r/adventofcode/comments/18515qh/2023_the_year_of_gpt/)甚至预期GPT-4能完成整个一年的挑战。
- en: A lot of noise was made of GPT-3.5 performance in AoC last year but the actual
    results were quite modest and LLM enthusiasts behaved in a very unscientific way,
    by boasting successes but becoming very quiet when it started to fail. In fact
    ChatGPT [struggled to get through day 3 and 5 and probably couldn't solve anything
    after day 5](https://archive.is/BtuOG).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 去年GPT-3.5在AoC中的表现引起了很多关注，但实际结果却相当平平，LLM（大型语言模型）爱好者表现得非常不科学，夸耀成功的时候，却在它开始失败时变得非常安静。事实上，ChatGPT在第3天和第5天开始遇到困难，可能在第5天之后无法解决任何问题。
- en: Why do AoC with GPT?
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么要使用GPT来解决AoC问题？
- en: I think it's as close to the perfect benchmark as you can get. The problems
    are roughly in order of increasing difficulty so you can see where it stops being
    able to solve. Since almost all of the problems in any given year are solvable
    by a CS graduate in a couple of hours is a good benchmark for AGI. And since all
    of the problems are novel the solutions can't come from overfitting.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这是最接近完美基准的方法。问题大致按照难度递增的顺序排列，因此你可以看到它在哪里无法解决。因为几乎每年的问题都可以在几个小时内由计算机科学毕业生解决，所以这是
    AGI 的一个很好的基准。由于所有问题都是新颖的，所以解决方案不能来自过拟合。
- en: Also around release people tried GPT-4 on AoC 2022 and [found that it performed
    better](https://twitter.com/geoffreylitt/status/1635757456377917440) so it would
    be interesting to see how much of the improvement was overfitting vs actual improvement
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在发布时，人们尝试了 GPT-4 在 AoC 2022 上，并 [发现它的性能更好](https://twitter.com/geoffreylitt/status/1635757456377917440)，因此很有趣看到改进有多少来自过拟合而不是实际改进
- en: Methodology
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 方法论
- en: 'I don''t pay for ChatGPT Plus, I only have a paid API key so I used instead
    a command line client, [chatgpt-cli](https://github.com/marcolardera/chatgpt-cli/)
    and manually ran the output programs. The prompt I used for part 1 was:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我没有购买 ChatGPT Plus，我只有一个付费的 API 密钥，所以我使用了一个命令行客户端 [chatgpt-cli](https://github.com/marcolardera/chatgpt-cli/)
    并手动运行了输出的程序。我用于第一部分的提示是：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: followed by the copypasted text of the problem. I manually removed from the
    prompt all the story fluff that Eric wrote, which constitutes a small amount of
    help for ChatGPT. If the output had trivial syntax mistakes I fixed them manually.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是问题的复制文本。我手动从提示中删除了所有 Eric 写的故事性内容，这对于 ChatGPT 来说是一些小帮助。如果输出有微不足道的语法错误，我会手动修复它们。
- en: I gave up on a solution if it didn't terminate within 15 minutes, and let ChatGPT
    fail 3 times before giving up. A failure constitutes either an invalid program
    or a program that runs to completion but returns the wrong output value.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果程序在 15 分钟内未终止，我就放弃了解决方案，并让 ChatGPT 失败 3 次后放弃。失败包括无效的程序或运行到完成但返回错误输出值的程序。
- en: 'If the program ran to completion with the wrong answer I used the following
    prompt:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果程序运行到完成但答案错误，我使用以下提示：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: If the program ran into an error I would say so and copy the error message.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果程序遇到错误，我会指出并复制错误消息。
- en: 'If the first part was solved correctly the prompt for the second part would
    be:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 如果第一部分正确解决，则第二部分的提示将是：
- en: '[PRE2]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: I decided I would stop the experiment after 4 consecutive days where ChatGPT
    was unable to solve part 1.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我决定在 ChatGPT 连续 4 天无法解决第一部分后停止实验。
- en: ChatGPT Plus
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ChatGPT Plus
- en: Because I was aware of the possibility that ChatGPT Plus would be better I supplemented
    my experiment with two other sources. The first one is the [Youtube channel of
    Martin Zikmund](https://youtube.com/@mzikmund) (hencefort "youtuber") who did
    videos on how to solve the problems in C# as well as trying to solve them using
    ChatGPT (with a Plus account).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我意识到 ChatGPT Plus 可能会更好，所以我用另外两个来源补充了我的实验。第一个是 [Martin Zikmund 的 Youtube 频道](https://youtube.com/@mzikmund)（以下简称
    "youtuber"），他在视频中讲解了如何用 C# 解决问题，以及如何使用 ChatGPT（使用 Plus 帐户）尝试解决问题。
- en: The second one was the blog of a ChatGPT enthusiast ["Advent of AI"](https://medium.com/@dretyr)
    (henceforth enthusiast) who tried to solve the problems using ChatGPT Plus and
    then also wrote a blog about it using ChatGPT Plus. Since the blog is generated
    by ChatGPT it's absolute shit and potentially contains hallucinations, however
    the [github repo with the transcripts](https://github.com/dretyr/adventofai) is
    valuable.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个是 ChatGPT 爱好者的博客 ["Advent of AI"](https://medium.com/@dretyr)（以下简称爱好者），他尝试使用
    ChatGPT Plus 解决问题，然后还用 ChatGPT Plus 写了一篇关于此的博客。由于博客是由 ChatGPT 生成的，所以它的质量很差，可能含有幻觉，然而
    [带有转录的 github 仓库](https://github.com/dretyr/adventofai) 是有价值的。
- en: 'The enthusiast turned out to be completely useless: it resorted often to babystepping
    ChatGPT through to the result and he stopped on day 6 anyway.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 结果表明爱好者完全无用：它经常通过逐步引导 ChatGPT 到结果来解决问题，而且他在第 6 天就放弃了。
- en: The youtuber was much more informative, for the most part he stuck to letting
    ChatGPT solve the problem on its own. However he did give it, on a few occasions,
    some big hints, either by debugging ChatGPT's solution for it or explaining it
    how to solve the problem. I have noted this in the results.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: youtuber 提供了更多的信息，大部分时间他坚持让 ChatGPT 自己解决问题。然而，他有时会给出一些重要提示，要么通过调试 ChatGPT 的解决方案，要么解释给它如何解决问题。我已在结果中备注了这一点。
- en: Results
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结果
- en: '|  | part 1 | part 2 | notes |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '|  | 第一部分 | 第二部分 | 注释 |'
- en: '| day 1 | OK | FAIL |  |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 第一天 | 通过 | 失败 |  |'
- en: '| day 2 | OK | OK |  |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 第2天 | OK | OK |  |'
- en: '| day 3 | FAIL | N/A |  |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 第3天 | FAIL | N/A |  |'
- en: '| day 4 | OK | OK | Uses brute force solution for part 2 |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 第4天 | OK | OK | 用蛮力方法解决了第2部分 |'
- en: '| day 5 | OK | FAIL |  |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 第5天 | OK | FAIL |  |'
- en: '| day 6 | FAIL | N/A | ChatGPT Plus solves both parts |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 第6天 | FAIL | N/A | ChatGPT Plus 解决了两部分 |'
- en: '| day 7 | FAIL | N/A |  |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 第7天 | FAIL | N/A |  |'
- en: '| day 8 | OK | FAIL | ChatGPT Plus solves part 2 if you tell it what the solution
    is |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| 第8天 | OK | FAIL | ChatGPT Plus如果你告诉它解决方案，它就解决了第2部分 |'
- en: '| day 9 | FAIL | N/A | ChatGPT Plus solves both parts |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 第9天 | FAIL | N/A | ChatGPT Plus 解决了两部分 |'
- en: '| day 10 | FAIL | N/A |  |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 第10天 | FAIL | N/A |  |'
- en: '| day 11 | FAIL | N/A | ChatGPT Plus could solve part 1 with a big hint |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 第11天 | FAIL | N/A | ChatGPT Plus 能够用一个重要的提示解决第1部分 |'
- en: '| day 12 | FAIL | N/A |  |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 第12天 | FAIL | N/A |  |'
- en: The perofrmance of GPT-4 this year was *a bit worse* than GPT-3.5 last year.
    Last year GPT-3.5 could solve 3 days on its own (1, 2 and 4) while GPT-4 this
    year could only solve 2 full days (2 and 4).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 今年 GPT-4 的性能比去年的 GPT-3.5 差了*一点*。去年 GPT-3.5 能够自己解决 3 天（1、2 和 4），而今年 GPT-4 只能解决
    2 天（2 和 4）。
- en: ChatGPT Plus however did *a bit better*, solving on its own 4 days (2, 4, 6
    and 9). This is probably down to its ability to see the problem input (as an attachment),
    rather than just the problem prompt and the example input to better sytem prompts
    and to just being able to do more round-trips through the code interpreter (I
    gave up after 3~4 errors / wrong outputs).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 但是 ChatGPT Plus 做得*稍微好一些*，自己解决了4天（2、4、6 和 9）。这可能是因为它能够看到问题输入（作为附件），而不仅仅是问题提示和示例输入，以更好地系统提示，并能够通过代码解释器进行更多次的往返（我在3~4个错误/错误输出后放弃了）。
- en: One shouldn't read too much on its ability to solve day 9, the problem difficulty
    doesn't increase monotonically and day 9 just happened to be very easy.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一个人不应该过分看重它解决第9天问题的能力，问题难度并不是单调递增的，第9天恰巧非常容易。
- en: Conclusions
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Overall my subjective impression is that not much has changed, it can't solve
    anything that requires something more complicated than just following instructions
    and its bad at following instructions unless they are very simple.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我的主观印象是并没有太多改变，它解决不了任何需要比只是遵循指示更复杂的东西，而且它很擅长遵循简单的指示。
- en: It could be that LLMs have reached their plateau. Or maybe Q* or Bard Ultra
    or Grok Extra will wipe the floor next year, like GPT-4 was supposed to do this
    year. It's hard not to feel jaded about the hype cycle.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 可能是语言模型已经达到了它们的顶峰。或者也许明年 Q* 或 Bard Ultra 或 Grok Extra 会像今年应该由 GPT-4 做的那样。很难不对炒作周期感到厌倦。
- en: I have a bunch of observations about the performance of ChatGPT on AoC which
    I will report here in no particular order.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我对 ChatGPT 在 AoC 上的表现有一些观察，我会无序地在这里报告。
- en: Debugging / world models
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 调试/世界模型
- en: Most humans are incapable of solving AoC problems on the first try without making
    mistakes so I wouldn't expect a human-level AI to be able to do it either (if
    it could it would be by definition super-human).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数人在第一次尝试解决 AoC 问题时都无法做到没有错误，所以我也不指望人类水平的 AI 能够做到（如果它能够做到，那就是超人类定义的）。
- en: Some of my prompting strategy went into the direction of trying to get ChatGPT
    to debug its flawed solution. I was asking it to add debug prints to figure out
    where the logic of the solution went wrong.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我的一些提示策略是朝着让 ChatGPT 调试其有缺陷的解决方案的方向发展的。我要求它添加调试打印以找出解决方案的逻辑出了什么问题。
- en: 'ChatGPT *never* did this: its debugging skills are completely non-existent.
    If it encounters an error it will simply rewrite entire functions, or more often
    the entire program, from scratch.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT *从未*做到过这一点：它的调试技能完全不存在。如果它遇到错误，它会简单地重写整个函数，或者更常见的是整个程序，从头开始。
- en: This is drastically different from what programmers.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这与程序员的观点截然不同。
- en: This is interesting because debugging techniques aren't really taught. By and
    large programming textbooks teach you to program, not how to fix errors you wrote.
    And yet people do pick up debugging skills, implicitly.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这很有趣，因为调试技术实际上并没有被教授。总的来说，编程教科书教你如何编程，而不是如何修复你写的错误。然而，人们确实会隐含地掌握调试技巧。
- en: ChatGPT has the same access to programming textbooks that humans have and yet
    it does not learn to debug. I think this points to the fact that ChatGPT hasn't
    really learned to program, that it doesn't have a "world model", a logical understanding
    of what it is doing when it's programming.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 具有与人类相同的编程教科书访问权限，但它却不学习调试。我认为这表明了 ChatGPT 实际上还没有学会编程，它没有“世界模型”，也就是在编程时它并不理解自己在做什么。
- en: The bruteforce way to get ChatGPT to learn debugging I think would be to scrape
    hundreds of hours of programming livestreams from twitch and feed it to the training
    program after doing OCR on the videos and speech-to-text on the audio. That's
    the only source of massive amounts of worked out debugging examples that I can
    think of.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让 ChatGPT 学习调试的蛮力方式我认为是从 twitch 上抓取数百小时的编程直播，并在视频上进行 OCR 和音频上进行语音转文字，然后将其馈送给训练程序。这是我能想到的唯一大量调试示例的来源。
- en: Difficulty
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 难度
- en: Could it be that this year of AoC was just harder than last year's and that's
    why GPT-4 didn't do well? Maybe.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 这一届 AoC 是不是比去年的难度更大，这就是为什么 GPT-4 表现不佳的原因？也许吧。
- en: 'Difficulty is very hard to gauge objectively. There''s [scatter plots](https://aoc-stats.fastbee.box.ca/)
    for leaderboard fill-up time but time-to-complete isn''t necessarily equivalent
    difficulty and the difference between this year and last year isn''t big anyway
    (note: the scatter plots aren''t to scale unfortunately).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 难度很难客观评估。排行榜填充时间有 [散点图](https://aoc-stats.fastbee.box.ca/)，但是完成时间不一定等同于难度，而且今年和去年的差异也不大（注意：散点图不是按比例绘制的，很遗憾）。
- en: My own subjective impression is also that this year (so far) was not harder.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我个人的主观印象也是，今年（迄今为止）并没有更困难。
- en: The best evidence for an increase in difficulty is day 1 part 2, which contained
    a small trap in which both human participants and ChatGPT fell.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 增加难度的最佳证据是第 1 天的第 2 部分，其中包含一个小陷阱，人类参与者和 ChatGPT 都掉进了。
- en: 'I think this points to a problem with this AIs trained with enormous amounts
    of training data: you can''t really tell how much better they are. Ideally you
    would just test GPT-4 on AoC 2022, but GPT-4 training set *contains* many copies
    of AoC 2022''s solutions so it''s not really a good benchmark anymore.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这指向了一个问题，那就是用大量训练数据训练的 AI 存在问题：你无法真正判断它们到底有多好。理想情况下，你会在 AoC 2022 上测试 GPT-4，但
    GPT-4 的训练集 *包含* 了大量 AoC 2022 的解决方案的副本，所以它实际上已经不再是一个好的基准了。
- en: Normally you would take out a portion of the training set to use as test set
    but with massive training set this is impossible, nobody knows what's in them
    and so nobody knows how many times each individual training example is replicated
    in them.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 通常你会从训练集中取出一部分作为测试集，但是对于大规模的训练集来说，这是不可能的，因为没有人知道其中包含什么，也没有人知道每个单独的训练示例在其中被复制了多少次。
- en: I wonder if OpenAI has a secret test dataset that they don't put on the internet
    anywhere to avoid training set contamination.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我想知道 OpenAI 是否有一个秘密的测试数据集，他们不会在任何地方放在互联网上以避免训练集污染。
- en: '[Some people](https://news.ycombinator.com/item?id=38483271#38488265) have
    even speculated that the problems this year were deliberately formulated to foil
    ChatGPT, but Eric actually [denied that this is the case](https://old.reddit.com/r/adventofcode/comments/18bp8id/why_does_aoc_care_about_llms/kc646i4/).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '[有人](https://news.ycombinator.com/item?id=38483271#38488265) 甚至推测今年的问题是故意设计的，以阻止
    ChatGPT，但 Eric 实际上 [否认了这一点](https://old.reddit.com/r/adventofcode/comments/18bp8id/why_does_aoc_care_about_llms/kc646i4/)。'
- en: Overfitting
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 过拟合
- en: GPT 4 is 10x larger than GPT 3.5 and it does much better on a bunch of standard
    tests, for example the [bar exam](https://law.stanford.edu/2023/04/19/gpt-4-passes-the-bar-exam-what-that-means-for-artificial-intelligence-tools-in-the-legal-industry/).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: GPT 4 比 GPT 3.5 大 10 倍，它在许多标准测试中表现更好，例如 [司法考试](https://law.stanford.edu/2023/04/19/gpt-4-passes-the-bar-exam-what-that-means-for-artificial-intelligence-tools-in-the-legal-industry/)。
- en: Why did it not do much better on AoC? If it isn't difficulty it could be overfitting.
    It has simply memorized the answers to a bunch of standardized tests.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么在 AoC 上表现并不好？如果不是因为难度，那可能是过拟合。它简单地记住了一堆标准化测试的答案。
- en: Is this the case? My experience with AoC day 7 points towards this. The problem
    asks to write a custom string ordering function, the strings in questions represent
    hands of cards (A25JQ is ace, 2, 5 jack and queen) and the order it asks for is
    *similar* to Poker scoring. However it is *not* Poker.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 是这样吗？我的 AoC 第 7 天的经历支持这一点。该问题要求编写一个自定义字符串排序函数，问题中的字符串代表卡牌的手（A25JQ 是 A、2、5、J
    和 Q），它所要求的顺序与扑克牌得分 *类似*。但这 *不是* 扑克牌。
- en: This is a really simple day and I expected ChatGPT would be able to solve it
    without problems, since you just have to follow instructions. And yet it couldn't
    it was inesorably pulled towards writing a solution for Poker rather than for
    this problem.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个非常简单的一天，我以为 ChatGPT 能够毫无问题地解决它，因为你只需按照说明操作。但是它却不能，它不可避免地被拉向了为扑克而写解决方案，而不是为这个问题而写。
- en: My guess is that this is an example of overfitting in action. It's seen too
    many examples of poker in its training set to be able to solve this quasi-poker
    thing.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我猜测这是过拟合的一个例子。它在训练集中看到了太多扑克的例子，以至于无法解决这个类似扑克的事物。
