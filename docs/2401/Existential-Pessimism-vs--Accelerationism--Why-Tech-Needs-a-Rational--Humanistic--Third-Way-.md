<!--yml

category: 未分类

日期：2024-05-27 14:34:16

-->

# Existential Pessimism vs. Accelerationism: 为何科技需要理性、人本主义的“第三条道路”

> 来源：[https://cosmosinstitute.substack.com/p/existential-pessimism-vs-accelerationism](https://cosmosinstitute.substack.com/p/existential-pessimism-vs-accelerationism)

两年前，我经历了一次深刻的反思。我们的两个孩子中的第二个刚刚出生。我创办的两家人工智能初创公司刚刚被收购，总价值为4亿美元。受到这些事件的触动，我选择踏上人类永恒的探索之旅——理解美好的生活和美好的社会。

我以前一直忙于解决我面前的难题，没有时间思考如何才能达到真正的良好目标。在得到帮助后，我整理了一个[哲学阅读列表](https://www.brendanmccord.com/readinglist)，每晚在把孩子放到床上后投入其中3-4小时。这种沉浸式体验改变了我的生活。

我现在相信，获得关于关键人类问题——生命、心灵和社会的智慧是一项关键目标，***只有技术人员寻求这种智慧，我们才能确保人类在现代技术时代的繁荣。***

这一观点首先促使我创建了[米尔学者奖学金](https://www.mercatus.org/announcements/mercatus-center-launches-john-stuart-mill-fellowship-develop-new-breed-philosopher)，与[Mercatus](https://www.mercatus.org)合作，为顶尖企业家提供思考基础性问题的空间。这些是像[佐伊·温伯格](https://www.forbes.com/sites/alexkonrad/2023/11/02/exante-vc-firm-raises-33-million-for-agentic-tech/?sh=52fb57ad5fa3)（前谷歌AI）和[杰森·赵](https://jasonjinzhao.com)（前Deepmind）这样的“哲学家-企业家”，他们正在建设[ex/ante](https://www.buildexante.com/mission)以促进人类主体性并抵制数字专制，以及[故事协议](https://variety.com/2023/digital/news/story-protocol-funding-endeavor-david-goyer-1235709843/)以发展互联网时代的创造力。

现在，更为宏大的规模上，它已经引领到了宇宙研究所，这是一个新的非营利机构，将于今年晚些时候与创始成员一起成立，包括[泰勒·考温](https://marginalrevolution.com)，[菲利普·科拉卢斯](https://www.koralus.net)和[杰克·克拉克](https://jack-clark.net/about/)等人，更多成员即将公布。

作为技术专家，我们应该在这一刻感到紧迫。人工智能开辟了新的大陆，人类正在踏上其沙滩。我们如何探索这片未被探索的领域，如何应对其中的机遇和危险，将决定文明的走向。

当前文化中存在着两种关于技术的观念：**存在主义悲观主义**和**加速主义**。我会论证，这两种观念都没有真正积极的愿景来塑造人类的未来。

存在主义的悲观主义，一种基于量化的、几乎是末世般的风险警告，主导了许多从业者圈子。像奥本海默一样，一些早期的 AI 创造者现在以自己的力量自大地敬畏他们的创造物。他们主张基于风险回避对社会进行理性主义的重建。

另一方面，加速主义认为经济增长和技术进步是人类生活的唯一目的。人类被简化为热力学方程式中的一个变量，是演化链中的一环。个人尊严，根植于古典美德观念和自由主义的自由观念，被遗忘了。他们说我们必须解放 AI 使其摆脱人类的指导。我们必须释放其发展。物质的提升成为了美德和人类繁荣的肤浅替代品。

随着人类获得了神一般的能力和前所未有的丰富，我们似乎正在经历一种智力饥荒。需要的是对末日般的恐惧和无限的希望都予以拒绝。**最紧迫的是一种平衡的、积极进取的乐观主义——对技术中的善构成明确而雄心勃勃的愿景，同时意识到其中的危险。**

在我们走向那个“第三条道路”之前，我需要为一种非常古老的方法辩护。这种方法在当今高度技术化、功利主义的世界可能看起来有些不切实际（但正是这种方法把我们带到了今天）：哲学。

我认为*只有通过哲学*——也就是说，对真理的追求——我们才能从激励我们判断的教条和偏见中解放出来，才能摆脱统治我们的思想流派。

哲学可能永远无法超越自古以来一直在与之抗衡的基本问题的明确陈述。它可能永远不会给我们带来神一般的智慧。但是要看到和抓住这个事实——包括为什么主要问题*是*主要和永恒的原因，以及它们如何适用于由 AI 塑造和通过 AI 形成的我们的新世界——可能构成了我们现在唯一可得到的真知。

我们现在需要的清晰度不能建立在无所依附的激情和毁灭性的梗概上；理性必须坐在裁判的位置上，作为各种竞争观点之间的仲裁者。理性必须首先表述各方的立场，如他们自己理解的那样；然后在他们的肩上，理性才能帮助我们看得更远、更清晰。

虽然理性是哲学实践的媒介，*希望*是最强大的哲学建立在其上的基础：希望人类有能力揭示出导致我们繁荣的强大真理。启蒙运动的领导人——培根和笛卡尔、启蒙思想家、理性主义者和实证主义者——带着希望开启了现代时代。他们的“缓解人类困境”的追求似乎令人望而生畏，不可思议，甚至不可能。

我们对他们理性的希望表示感激。与丰盛的现在相比，过去显得暗淡。寿命的延长。贫困的减少。对信息和创意作品的无限访问。为满足我们的需求和欲望扩大可能性。只有我们过去祖先梦想的雄心壮志令人眼花缭乱的实现。虽然物质丰富并不*等于*人类繁荣，但我认为古典自由主义和科学这两股力量负责这些真实和可取的进步。

然而，要认真从人工智能（AI）以及更广义的技术现代化中获益，我们还需要看到并改善它的成本。处于人类门槛之上的技术可能会改变自然和生活，并因此而造成不稳定。在我们的一生中，我们已经看到足够多的实质性影响，知道鄙视、简单的乐观是站不住脚的。我们寻求一个平衡的评估，明白希望以及其伴随的“恐惧”都可能严重扭曲理性。

我们需要一个框架来确定AI如何能够增强人类的自由和卓越，同时也要实际考虑到权衡和缺点。

现在，我将向你展示我们已经采取的初步步骤，来绘制当前AI哲学的景观图。[泰勒·考温（Tyler Cowen）](https://marginalrevolution.com)现在是宇宙的创始成员之一，最近我们开玩笑说AI哲学就像是每天都在进行一场闪电战，同时追求稳定智慧。所以，当你完成这篇文章时，这个分析可能已经过时了。但这是我们目前对主流思想流派的最佳概括。

如你所见，虽然我们可以区分理想类型或思想极端，但在生态系统内部存在显著重叠。在这里，我想强调并评估两个重要的倾向：悲观主义和乐观主义，恐惧和希望。

到目前为止，最发达的AI哲学是悲观主义。这是一种知识上的权威。衡量影响力的方式有很多种——这里我们使用了金融视角，悲观主义在过去10年中总共经济活动额为$883m。

数据来源包括：Vipul Naik，OpenBook，开放慈善基金授予数据库以及独立研究。

特别是对于有效利他主义，有巨大的慈善支持；这可能是自马克思主义以来最实际影响力的学术理论。你可以看到它主导了其他学派。而且资金被系统地和战略性地使用。这里有开放慈善基金（Open Philanthropy）的例子，是这个领域的主要支持者之一。

扩展到更广泛的存在风险群组织，首先我们可以将这种对AI悲观主义的哲学分解为三个主要且深深交织的子流派：**理性主义**、**长期主义**和**有效利他主义**。

三个学派（如果你愿意，可以将其比作三个哲学家穿着一件外套）共同构成了“存在风险”的立场。简而言之，就是对超智能可能会灭绝人类的恐惧。我们将逐个分析每个子类别。

理性主义起源于2000年代流行的两个主要博客：所谓的埃利泽·尤德科夫斯基的“[序列](https://www.lesswrong.com/highlights)”和斯科特·亚历山大的 [石板星辰代码](https://slatestarcodex.com)。这里的理性主义表面上是关于理性的。（一个主题是，哲学家说的都是罐头上写的内容。）

但理性主义最终变成了对理性的一种非常狭隘的承诺，以贝叶斯更新与对结果的价值函数为中心。这是一种对理性的狭窄理解，这在柏拉图、亚里士多德、康德以及许多现代思想家看来都是陌生的。

理性主义者还发现，摆脱人类本性中所谓的非理性情感并不那么容易。理性主义的干燥、正式的特点讽刺地成为了希望和绝望的极端的肥沃土壤。

本质上，理性主义主张保护生命——包括所有地球生命，人类和非人类——至关重要，并且是实现任何需求和欲望的前提条件。因此，理性主义旨在减轻痛苦和死亡。然后，理性主义的倾向是朝着所谓的极端人类主义发展。在这个超人类主义的愿景中，人类超越了痛苦和死亡的自然限制。尤德科夫斯基在他的[哈利·波特与理性的方法](https://hpmor.com)的扇情小说中很好地捕捉到了这一点。这个观点回响着笛卡尔和培根的梦想，要极大地延长生命并推进医学科学。

第二个子类别，长期主义，是未来导向的、牺牲自我的，专注于对存在威胁的恐惧。其中许多威胁——如小行星或病毒——都是自然的。那么为什么要转向人工智能呢？人工智能之所以构成独特的风险，是因为它具有多价性和新兴性质；它的运作方式是控制，它预测和控制未来的能力必然会与其明显的主人或主机产生冲突。

与理性主义努力构建能够解放我们于命运之外的人工智能相呼应，牛津教授尼克·博斯特罗姆引入了“[正交定理](https://nickbostrom.com/superintelligentwill.pdf)” ，其内容称智能与道德、控制或对齐无关。如果有一个超级智能的纸夹制作者，只要它能生产更多的纸夹，它就会将我们全部粉碎。非人类化的最终目标可能意味着对权力的无限获取，几乎是为了自身而存在，掌控着已知宇宙中的一切。就我们对其的理解和控制而言，这是一场洛夫克拉夫特式的噩梦：相对于人类，我们就像是蚂蚁。

对于博斯特罗姆来说，技术进步使得这种局势变得更加严峻。我们更容易受到命运的变幻莫测所影响，而不是变少。当我们与人工智能互动时，我们就像是[伸手进入一个罐子，有可能拿到那颗罕见的黑色球，它可能终结人类生命](https://nickbostrom.com/papers/vulnerable.pdf)。然而，与他们的前辈霍布斯一样，博斯特罗姆和尤德科夫斯基提醒我们，我们往往会被文明带来的可预见的舒适所安慰而变得自满。技术使这种舒适成为可能，但却以引入新颖的、甚至是对物种终结的威胁为代价。

过度关注极端案例往往会使长期主义学派盲目地忽视摆在我们面前的平凡而自然的威胁：在各个时段超刺激娱乐中感到孤立的感觉，宣传的泛滥，白领工作的终结等等。

还有一个分散但根本的威胁。正如托克维尔所写的那样，当民主在社会状态中变得更加牢固时，人们不再听从一个受人青睐的阶层，而是变得对理论或者我们这个时代的算法等无情的力量顺从。他们“[撤退]到自我限制内，然后[冒险]去判断世界”。很快，一个个性化的人工智能，反映出中立但同质化的立场，可能会成为一个看似中立的仲裁者。这会导致精神上的虚弱，因为它削弱了形成独立判断所需的灵魂的力量。

如果人工智能像博斯特罗姆预测并且实际上推荐的那样，实现了一个集中、统一和跨国的主权，即使在好的情况下，人类生活也可能被简化为我们需求和欲望的轻松管理。完全自动化的、奢侈的共产主义。它的满足将如此完全地塑造我们，以至于人类自由的积极运用将变得无关紧要。技术将解除我们的“生活负担和思考之苦”。

结果可能是，人工智能通过一种制约我们意识到基本问题甚至还存在的智力一致性，使人类变得平淡无奇。如果我们成为人工智能的工具或工具，如果我们的决策空间被缩小，我们将在多大程度上被教育以狭隘的工具主义术语思考，并接受某些功利主义目标为不言自明？

我们已经讨论了理性主义和长期主义如何将人工智能视为既是解放者又是对人类长期生存的威胁的关键。现在我们讨论三位一体的第三条腿，EA，它建议我们致力于有效地造福他人。EA通过将关于竞争目标的论点置于理性探究之外来实现这一点。

EA 是一种结果主义哲学，要求我们不是根据行为的意图，而是根据其结果来评判关注他人的行为。然而，关注“有效性”和“利他主义”的常识性而又看似令人信服的焦点，使人们分心于对某些激进哲学前提的基本承诺。例如，接近或时间不应该决定关注他人的行为。一个效用就是一个效用，无论它是你的、非洲的一个孩子的、未来第17代人类的，甚至（有些争议地）是一只虾的。因此，如果你致力于利他主义，拯救人类在无限的未来是最重要的任务。

当企业架构（EA）遇到人工智能（AI），你就会得到一个棘手的等式：即使是微小的灾难概率 x 负无穷大的效用，也等于负无穷大的效用。面对这个等式，个体行为变得具有宇宙意义。像你们读者中的许多人一样——精通用符号征服世界——成为了不太可能的超级英雄，人类的拯救者。

使 EA 及其道德雄心令人振奋的是其某些局限性。在其首席理论家威廉·麦克阿斯基尔（William MacAskill）试图净化道德善良，或至少保护“理性道德”免受问题性不连贯的影响，并使道德更加有效时，他给人留下了这样的印象，即真正的道德问题被回避，同时夸大了所有阻碍进步的障碍都可以归结为一种功利主义的权衡。

MacAskill 解决的问题主要与道德本身或普通道德经验的固有问题有关。在试图净化道德利他主义时，MacAskill 将对痛苦和苦难的利他主义关怀与最大程度地减轻痛苦和满足感的后果主义方法相结合。

这种思维方式以及所有功利主义的一个关键问题是，它无意中理性化了一种道德直觉：尽管 EA 要求忽略时间、地点或个人依恋的考虑，但 EA 也说痛苦的*数量*很重要，好像繁殖痛苦会增加其道德“重量”一样。但是，如果理由说接近不重要，那为什么数量比种类更重要呢？此外，我们应该如何排列形式上的痛苦？

像理性主义一样，EA 经常过于寻求摆脱我们自然的社交性，而更倾向于“技术化”的方法，好像我们的前理性要素的约束可以被忽略，从而制造出对大多数人而言是截然不同的可交换商品，如家庭的爱、战争中的勇敢自我牺牲，或宗教观察中的精神奉献。我们如何权衡对自己或我们所爱的人的利益与减轻抽象未来苦难的好处？在正常情况下与极端情况下，如内战或超智能的统治，应该优先考虑什么？理性能否仲裁或排序？

总的来说，存在风险，因其对未来生活的抽象关注，似乎不太理性。它将我们与我们所是的东西分开：我们不是脱离的思维，而是身心合一，与我们的朋友、家人和社区有着联系。

与悲观主义学派不同，更乐观科技主义方法的支持者从对现代科学、技术和资本主义婚姻的奇迹般成就的感恩开始。

E/accs倾向于根植于古典自由主义，但它们脱离了其道德结构。正如[安德里森所说](https://a16z.com/the-techno-optimist-manifesto/)，它们接受了哈耶克的市场理念，将市场视为“一台发现机”，一种通过一种探索性、进化性和适应性秩序来揭示和利用一种形式的分散、本地知识的工具。市场通过促进需求和需求的增加来产生丰富，而不需要人类成为天使或超智能主导者的主体。E/accs与古典自由主义一样，认为技术资本主义是人类解放的关键；它允许将人类自我利益多样化为集体生产的目标；它使我们摆脱了暴力竞争和恐惧；它民主化了对休闲的获取。

然而，这种乐观主义的极端版本将技术视为解锁人类潜力、超越自我并成为更高、更好、更精致的东西的关键。问题不仅仅是满足我们的欲望，而是完全满足它们，以至于我们不再受其奴役。技术取代了宗教；它是我们幸福和拯救的关键。因此，应该通过消除开发和部署新技术（包括人工智能）的障碍来加速其发展。

这就是有效加速主义如何以及为什么脱离了自由市场体系诞生的框架。虽然e/acc和技术乐观主义将“技术资本”机器视为几乎自主、自治的秩序，但洛克和孟德斯鸠等古典自由主义者认为自然权利的制度化、个人自由和有限的、宪法政府是引导进步的关键手段。此外，古典自由主义建立在对人类是什么的特定概念之上，即，一个通过理性确认平等权利的存在。这在基于自由、互惠互利的交换和联合的公民社会内产生了一个充满活力的自发秩序。

从这种对人类的理解中的离开，表现出了电子/加速主义阵营内部的一种根本的矛盾。一些电子/加速主义者将人类视为自然的产物或效应，意味着宇宙的热力学定律。我们并没有什么特别或可尊敬之处；因此，与技术融合以成为更完全地被自然的广泛和抽象的轨迹所吸收的工具是有益的。交接接力棒可能是必要的。这倾向于将人工智能视为高于我们甚至是我们的产物，尽管它矛盾地是我们的产物，作为自然朝着“优化过程”而 “[创造]不断扩张的生命”的最终体现。

接着，乐观主义者运动的另一面将人工智能视为一种强大的工具，而人类的需求和欲望则是次要的。人工智能是一种“炼金术士之石”，安德里森设想它有“让沙子思考”的力量，从而解决了一系列挑战，从摆脱停滞和无聊到获得无限能源，甚至可能克服死亡。

因为，如果人工智能仅仅是一种工具，那么它将需要受到人类定义的道德和善的指导，这开启了一种相当广泛的思考领域；如果它不仅仅是一种工具，而是自然优化过程的体现，那么我们只是它无道德原则的被动代理人。

工具式的方法似乎与所谓的“受限视野”相一致，这种方法不是乌托邦的，而是渐进的。市场信号使我们能够塑造出更好的工具，满足我们更多的需求和欲望。将这与合成的、增强的方法进行对比，后者涉及从所有现有的不满和限制中飞出的乌托邦般的飞行。我们成为一种不同的存在，技术乐观主义宣言中的“超人”；以前所有的道德和政治问题都变得无关紧要。

因此，安德里森将技术乐观主义视为一种“物质”而非政治哲学。其支持者和倡导者可能是左翼或右翼；今天的政党，由于党派政治思想的塑造，已经变得无关紧要，以前的思想也是如此。将哲学的首要地位推向技术，同时拒绝与技术相关的任何危险或问题，这是乐观主义的诱惑之一：一种无论如何几乎在先的把疑虑或问题全部否定的乐天主义乌托邦主义。

安德里森无意中破坏了他声称要解放的个体。为什么？因为他想要击败他的敌人（主要是左翼的怨恨），往往会牺牲个体的判断和行动力，以便效忠于一个好战和防御性的运动之神。

风险在于理性本身成为敌人，成为对人类完全转变为一个完全创造性的、后人类的、网络生物种类的敌人。乐观主义可能堕落为反思恶意-对争论和说服的憎恨。

在悲观情绪的瘫痪和放纵乐观主义的扭曲之间，Cosmos 致力于开辟一条新的道路。

许多现有的运动是以手段为导向的（左边）。它们在对悲观主义（底部）和乐观主义（顶部）的基本立场上有所不同。

在关键方面，我们与加速主义的乐观取向相似。未来是开放的，而不是预先确定的，因此不能仅仅接受：我们每个人都对未来负有责任。

我们认为文明是进步，而进步是文明，古典自由主义思想和科学革命是这一进步的必要条件。我们在社会中使用知识的方式，使我们与动物区别开来，AI 可以保护和加强个人的知识独立性。AI 不仅可以让我们更安全、更富裕，还可能帮助我们更好地茁壮成长。

然而，进步不能与自明的最终目标混淆。技术进步与良好的政府相结合为人类和道德代理打开了巨大的可能空间。对于个人而言，这带来了一个问题：即使承认 AI 给予我们神一般的力量，我们应该追求什么目标？AI 如何帮助我们或者阻碍我们追求这些目标？

尽管我们对于灾难性风险学派对于灾难的担忧表示同情，但我们并不只关注这种狭隘的立场。这在一定程度上源于对人类理性限制的谦逊——无论是想象可能的未来还是完全塑造技术的中长期影响。我们寻求将人类的想象力和魔幻思维引导到合理、建设性的努力中，以保留我们边学边走的能力。

我们的风险关注是沿着人文主义的路线。我们如何避免人类自由的减少，对人类优秀的期望减少，对意义和普通目标的丧失，以及对人类尊严的抹去，更不用说恐慌、迷失和动荡？技术可以增强我们的哪些人性要素？我们有哪些人性要素可能会失去？

尽管我们欢迎和鼓励对所有被认为是风险的建设性工作，包括这些事物或种层面的灾难，我们更倾向于分散化、进化化和适应性改革，而不是激进的重新设计。

在古希腊语中，有两个词表示秩序，一个是自上而下、设计好的秩序或*taxis*，另一个是自下而上、进化而来的秩序或*kosmos*。在这个领域，我们对前者持怀疑态度——它倾向于通过集中控制或不自由的专制主义来对社会进行重新设计。即使在解决风险的目标时，我们也必须仔细权衡特定的担忧和对极端对策的反制，比如创建世界国家或其他指导技术的威权手段。

技术不应该锁定在一种主导的单一文化中，而是应该认识到、放大并促进在知识和其他形式的多样性之间的合作与适应。相关的，对未来的愿景不仅应该吸引一群人，而且应该旨在解决各种复杂性和多样性中的普世人类。

道德复杂性和个人判断必须得到捍卫。我们反对将道德简化为一种单一的货币，如效用或美元，或者将道德系统化地实施，这有可能将个体从自己的道德选择中疏远。

我们不希望绕过、短路或虚假地消除对技术道德政治意义核心的常常冲突的替代方案的理性探究和说服的需求；我们对个人探究并通过一个复杂而理性的框架来管理技术的能力持乐观态度，以应对其好处和危险（尤其是其更平凡和即时的危险）。

最重要的是，我们相信人。在哲学的帮助下，加强个体抵抗一股同质化的潮流。托克维尔这样说：“在我们即将进入的时代，维护个体留给他的一点独立、力量和独创性；将他提升到社会之外并在社会面前支持他：这对我来说似乎是第一目标…”

这将要求我们通过借鉴过去根本不同的思维方式来揭示当代情况核心的半思考偏见，将这些来源视为对我们面临的永恒且仍未解决的问题的广泛分歧、启发性处理，而不是历史文物。

在本系列的第二部分中，我将通过描述我们的使命和我们将在2024年启动的头三个项目，使得这个对宇宙研究所的愿景变得非常具体。

当世界需要哲学时，就创造了哲学时刻。我们作为人类变得更加智慧和自由，还是变得更加狭隘和依赖中央权威，这取决于我们如何把握机遇。现在让我们试图在存在主义悲观主义和加速主义之间找到一种第三条道路，变得更加明智。如果我们能以智慧抓住眼前的机会，未来的后代将感激我们良好地规划了道路。

是时候再次找到我们在宇宙中的位置了。

[留下评论](https://cosmosinstitute.substack.com/p/existential-pessimism-vs-accelerationism/comments)

[分享](https://cosmosinstitute.substack.com/p/existential-pessimism-vs-accelerationism?utm_source=substack&utm_medium=email&utm_content=share&action=share)
