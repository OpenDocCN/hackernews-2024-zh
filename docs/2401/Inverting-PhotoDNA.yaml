- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 14:32:35'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 14:32:35'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Inverting PhotoDNA
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 反转PhotoDNA
- en: 来源：[https://anishathalye.com/inverting-photodna/](https://anishathalye.com/inverting-photodna/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://anishathalye.com/inverting-photodna/](https://anishathalye.com/inverting-photodna/)
- en: 'Microsoft [PhotoDNA](https://www.microsoft.com/en-us/photodna) creates a “unique
    digital signature” of an image which can be matched against a database containing
    signatures of previously identified illegal images like CSAM. The technology is
    [used](https://www.makeuseof.com/what-is-photodna-how-does-it-work/) by companies
    including Google, Facebook, and Twitter. Microsoft says:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 微软的[PhotoDNA](https://www.microsoft.com/en-us/photodna)为图像创建了一个“独特的数字签名”，可以与包含先前识别的非法图像（如CSAM）签名的数据库进行匹配。该技术被包括谷歌、Facebook和Twitter在内的公司[使用](https://www.makeuseof.com/what-is-photodna-how-does-it-work/)。微软表示：
- en: A PhotoDNA hash is not reversible, and therefore cannot be used to recreate
    an image.
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: PhotoDNA哈希是不可逆的，因此无法用于重新创建图像。
- en: '[Ribosome](https://github.com/anishathalye/ribosome) inverts PhotoDNA hashes
    using machine learning.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ribosome](https://github.com/anishathalye/ribosome)使用机器学习反转PhotoDNA哈希。'
- en: 'This demonstration uses provocative images to make a point: rough body shapes
    and faces can be recovered from the PhotoDNA hash. The image in the top row is
    from Sports Illustrated, and the image in the bottom row is [not a real person](https://thispersondoesnotexist.com/).
    The first column shows a portion of the 144-byte PhotoDNA hash, and the center
    column shows the image that can be reconstructed from this hash using Ribosome.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这个演示使用挑衅性的图像来说明一个观点：可以从PhotoDNA哈希中恢复粗糙的身体形状和面部特征。顶部行中的图像来自《体育画报》，底部行中的图像是[虚构的人物](https://thispersondoesnotexist.com/)。第一列显示了144字节的PhotoDNA哈希的一部分，中间列显示了使用Ribosome可以从此哈希中重建的图像。
- en: Like any other lossy function, the PhotoDNA hash is not perfectly invertible,
    but the hash leaks plenty of information about the original input, as evidenced
    by these image recreations.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 像任何其他有损函数一样，PhotoDNA哈希并非完全可逆，但哈希泄漏了大量关于原始输入的信息，正如这些图像重建所证明的那样。
- en: Neither details of the PhotoDNA algorithm nor an implementation is officially
    available to the public, but the algorithm has been [reverse-engineered](https://hackerfactor.com/blog/index.php?/archives/931-PhotoDNA-and-Limitations.html)
    based on public documents, and a [compiled library](https://github.com/jankais3r/pyPhotoDNA)
    for computing PhotoDNA hashes has been leaked around the time [collisions](https://github.com/anishathalye/neural-hash-collider)
    were found in Apple’s NeuralHash algorithm.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: PhotoDNA算法的详细信息和实现都没有正式向公众公开，但该算法已经根据公开文件进行了[逆向工程](https://hackerfactor.com/blog/index.php?/archives/931-PhotoDNA-and-Limitations.html)，并且在发现苹果的NeuralHash算法存在[碰撞](https://github.com/anishathalye/neural-hash-collider)时，一种用于计算PhotoDNA哈希的[编译库](https://github.com/jankais3r/pyPhotoDNA)在此前已经泄露。
- en: Likely due to the closed-source nature of PhotoDNA, there has not been much
    work studying the hash function. In 2019, [Nadeem et al.](https://kar.kent.ac.uk/77165/)
    in collaboration with Microsoft investigated the privacy protection capability
    of PhotoDNA by testing it against ML classification. The paper claimed that “PhotoDNA
    is resistant to machine-learning-based classification attacks”. More recently,
    in November 2021, [Prokos et al.](https://eprint.iacr.org/2021/1531) performed
    targeted second-preimage attacks on PhotoDNA.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由于PhotoDNA的闭源性质，对哈希函数的研究工作并不多。2019年，[Nadeem等人](https://kar.kent.ac.uk/77165/)与微软合作，通过对其进行ML分类测试，调查了PhotoDNA的隐私保护能力。该论文声称“PhotoDNA对基于机器学习的分类攻击具有抵抗力”。最近，在2021年11月，[Prokos等人](https://eprint.iacr.org/2021/1531)对PhotoDNA执行了有针对性的第二预影像攻击。
- en: Ribosome is an inversion attack on the PhotoDNA hash function and investigates
    the claim that a PhotoDNA hash “cannot be used to recreate an image.”
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Ribosome是对PhotoDNA哈希函数的反向攻击，并调查了PhotoDNA哈希“无法用于重新创建图像”的说法。
- en: Ribosome treats PhotoDNA as a black box and attacks the hash function using
    machine learning. Because an implementation of PhotoDNA has been [leaked](https://github.com/jankais3r/pyPhotoDNA),
    it is possible to produce a dataset of image/hash pairs. Ribosome trains a neural
    net on such a dataset to learn to synthesize an image given its hash.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Ribosome将PhotoDNA视为黑盒，并使用机器学习攻击哈希函数。由于PhotoDNA的[实现被泄露](https://github.com/jankais3r/pyPhotoDNA)，因此可以生成图像/哈希对的数据集。Ribosome在这样的数据集上训练神经网络，以学习如何根据其哈希合成图像。
- en: PhotoDNA hashes are 144-element vectors of bytes. Ribosome uses a neural network
    similar to the [DCGAN](https://arxiv.org/pdf/1511.06434/) generator and the [Fast
    Style Transfer](https://cs.stanford.edu/people/jcjohns/papers/fast-style/fast-style-supp.pdf)
    network, using residual blocks followed by fractionally-strided convolutions for
    learned upscaling, to turn this into a 100x100 image.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: PhotoDNA哈希是144个字节向量。Ribosome使用类似于[DCGAN](https://arxiv.org/pdf/1511.06434/)生成器和[快速风格转换](https://cs.stanford.edu/people/jcjohns/papers/fast-style/fast-style-supp.pdf)网络的神经网络，使用残差块后跟分数步长的卷积进行学习，以将其转换为100x100的图像。
- en: The choice of dataset used to train the model affects the results. Ideally,
    the images in the dataset should be drawn from the same distribution as the images
    whose hashes are being inverted. For example, when inverting a hash of an image
    that is expected to contain a person, training the model on the [Places](http://places.csail.mit.edu/)
    dataset may not produce optimal results.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 选择用于训练模型的数据集会影响结果。理想情况下，数据集中的图像应该来自于与要反转哈希的图像相同的分布。例如，当反转预期包含人物的图像的哈希时，训练模型在[Places](http://places.csail.mit.edu/)数据集上可能不会产生最佳结果。
- en: 'Ribosome can produce good results even when the exact distribution that the
    image is drawn from is not known. The following figure illustrates hash inversions
    computed by models trained on different test sets:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 即使不知道图像所绘制的确切分布，Ribosome也可以产生良好的结果。下图说明了由在不同测试集上进行训练的模型计算得出的哈希反转：
- en: In the above figure, held-out test images from each of the datasets, plus an
    extra image from the internet, are hashed and then reproduced using Ribosome models
    trained on different datasets. Training datasets include [CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html),
    [COCO](https://cocodataset.org/), and a dataset of 100K images scraped from SFW
    and NSFW subreddits. A fourth dataset was created by combining images from the
    three datasets (taking only 40K images from CelebA).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在上图中，来自每个数据集的保留测试图像以及来自互联网的额外图像经过哈希处理，然后使用在不同数据集上进行训练的Ribosome模型进行复制。训练数据集包括[CelebA](https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)、[COCO](https://cocodataset.org/)和从SFW和NSFW子版块抓取的10万张图像数据集。第四个数据集是通过将三个数据集的图像组合而成的（从CelebA中仅取4万张图像）。
- en: 'The figure illustrates some interesting phenomena:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图中展示了一些有趣的现象：
- en: Using a large and diverse dataset allows the model to produce good reproductions
    from a PhotoDNA hash (fourth column)
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用大型且多样化的数据集允许模型从PhotoDNA哈希中生成良好的复制品（第四列）。
- en: The better the prior, the better the result, e.g. reproducing a face with a
    model trained on CelebA (first column, second row)
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 先验条件越好，结果就越好，例如利用CelebA训练的模型重现面部（第一列，第二行）。
- en: Ribosome can handle some distribution shift, e.g. reproducing a face when trained
    on COCO (second column, second row)
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ribosome可以处理一些分布变化，例如在COCO上进行训练时重现面部（第二列，第二行）。
- en: Unsurprisingly, training the model on a narrowly-scoped dataset gives it a strong
    bias towards producing images like those in that dataset, e.g. training on CelebA
    biases the model to produce images containing faces (first column)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 毫不奇怪，将模型训练在一个范围较窄的数据集上会导致其对于生成类似该数据集中的图像具有较强的偏好，例如在CelebA上进行训练会导致模型生成包含面部的图像（第一列）。
- en: The model learns to recolor the image (PhotoDNA converts the image to greyscale
    before processing it)
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型学会重新着色图像（PhotoDNA在处理之前将图像转换为灰度）。
- en: The model sometimes has amusing failure behaviors, e.g. the Reddit dataset was
    not carefully curated and had many “image unavailable” images, and artifacts from
    this are visible in some of the results (third column)
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型有时会有有趣的失败行为，例如Reddit数据集未经精心筛选，其中有许多“图片不可用”的图像，这些现象在一些结果中可见（第三列）。
- en: 'The images above are manually selected examples, chosen for the quality of
    the result, diversity of images (e.g. different poses), and being SFW. The reconstruction
    is not always perfect. To give a sense of how the model works on average, here
    are 5 randomly-selected test datapoints from COCO shown along with their original
    images:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的图像是手动选择的示例，根据结果的质量、图像的多样性（例如不同的姿势）和符合工作场所的性质进行选择。重建并不总是完美的。为了让你了解模型的平均工作方式，这里展示了5个随机选择的COCO测试数据点及其原始图像：
- en: Ribosome shows that PhotoDNA does not perfectly hide information about the source
    image used to compute the signature, and that in fact, a PhotoDNA hash can be
    used to produce thumbnail-quality reproductions of the original image.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Ribosome 表明 PhotoDNA 并未完全隐藏有关用于计算签名的源图像的信息，事实上，可以使用 PhotoDNA 哈希来生成原始图像的缩略图质量的复制品。
- en: Code and pre-trained models are available on [GitHub](https://github.com/anishathalye/ribosome).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 代码和预训练模型可在 [GitHub](https://github.com/anishathalye/ribosome) 上找到。
