<!--yml

category: 未分类

date: 2024-05-27 14:45:03

-->

# **通用机器人大脑计划** - IEEE Spectrum

> 来源：[`spectrum.ieee.org/global-robotic-brain`](https://spectrum.ieee.org/global-robotic-brain)

**生成式人工智能革命**体现在诸如[ChatGPT](https://chat.openai.com/)、[Midjourney](https://www.midjourney.com/)等工具中，其核心基于一个简单的公式：利用一个非常庞大的神经网络，在从网络上抓取的大量数据集上进行训练，然后使用它来满足广泛的用户请求。大型语言模型([LLM](https://spectrum.ieee.org/tag/llms))可以回答问题、编写代码和吟诗作对，而图像生成系统可以创建逼真的洞穴壁画或当代艺术作品。

那么为什么这些惊人的人工智能能力没有转化为科幻小说中所见的那种有用和广泛使用的机器人呢？那些可以清理桌子、折叠衣服和为你做早餐的机器人在哪里？

不幸的是，高度成功的生成式人工智能公式——在大量互联网数据上训练的大模型——并不容易转化为[机器人技术](https://spectrum.ieee.org/topic/robotics/)，因为互联网并不像文本和图像那样充满机器人交互数据。机器人需要机器人数据进行学习，而这些数据通常由研究人员在实验室环境中缓慢而费力地创建，用于非常具体的任务。尽管机器人学习算法取得了巨大进步，但没有丰富的数据，我们仍然无法使机器人在实验室外执行现实任务（比如做早餐）。最令人印象深刻的结果通常只在单个实验室、单个机器人上工作，并且通常只涉及少量行为。

如果每个机器人的能力都受到手动教导它执行新任务所需的时间和精力的限制，那么如果我们将许多机器人的经验汇集起来，使一个新机器人可以同时从所有这些经验中学习呢？我们决定试一试。2023 年，我们在[Google](https://spectrum.ieee.org/tag/google)和加州大学伯克利分校的实验室与北美、欧洲和亚洲的其他 32 个机器人实验室一起，开始了[RT-X 项目](https://robotics-transformer-x.github.io/)，旨在整合数据、资源和代码，使通用目的的机器人成为现实。

这是我们从这一努力的第一阶段中学到的内容。

## 如何创建通用机器人

人类在这种学习方面要好得多。经过一点练习，我们的大脑可以处理基本上是对我们身体结构的改变，当我们拿起工具、骑自行车或开车时就会发生这种情况。也就是说，我们的“体现”会改变，但我们的大脑会适应。RT-X 的目标是使机器人实现类似的功能：启用一个单一的深度神经网络来控制许多不同类型的[机器人](https://robotsguide.com/learn/types-of-robots)，这种能力称为跨体现。问题在于，一个经过足够多不同机器人数据训练的深度神经网络是否能够学会“驾驶”所有这些机器人，甚至是外观、物理特性和功能非常不同的机器人。如果是这样，这种方法可能会解锁机器学习的大型数据集的潜力。

这个项目的规模非常大，因为必须如此。RT-X 数据集目前包含了近百万次针对 22 种不同类型机器人的试验，其中包括市场上许多常用的机器人臂。这个数据集中的机器人执行着各种各样的行为，包括拾取和放置物体、装配以及诸如电缆布线等专业任务。总共有大约 500 种不同的技能和与数千种不同物体的交互。这是现有的最大的开源真实机器人动作数据集。

令人惊讶的是，我们发现我们的多机器人数据可以使用相对简单的机器学习方法，只要我们遵循使用大型神经网络模型和大型数据集的配方。利用类似于当前 LLMs（如[ChatGPT](https://spectrum.ieee.org/tag/chatgpt)）中使用的模型，我们能够训练出不需要任何特殊特征进行跨体现的机器人控制算法。就像一个人可以使用同一大脑驾驶汽车或骑自行车一样，一个在 RT-X 数据集上训练的模型可以简单地从机器人自己的摄像头观察中识别出它正在控制的是什么类型的机器人。如果机器人的摄像头看到一个[UR10 工业机械臂](https://www.universal-robots.com/products/ur10-robot/)，模型会发送适用于 UR10 的命令。如果模型看到一个低成本的[WidowX 爱好者机械臂](https://www.trossenrobotics.com/widowxrobotarm)，模型会相应地移动它。

为了测试我们模型的能力，RT-X 合作中的五个实验室各自对其进行了与各自为其自己的机器人开发的最佳控制系统进行对比的头对头比较测试。每个实验室的测试都涉及到其自己研究中使用的任务，其中包括拾取和移动物体、打开门以及通过夹子进行电缆布线等事项。值得注意的是，这个单一的统一模型在每个实验室自己的最佳方法上提供了更好的性能，平均成功率提高了大约 50%。

尽管这个结果可能看起来令人惊讶，但我们发现 RT-X 控制器可以利用其他机器人的多样经验来提高在不同环境下的稳健性。即使在同一个实验室内，每次机器人尝试一个任务，它都会处于稍微不同的情境中，所以借鉴其他机器人在其他情境中的经验有助于 RT-X 控制器处理自然变异和边缘情况。以下是一些这些任务范围的例子：

## 建造能够推理的机器人

鼓舞着我们成功地将许多[机器人类型](https://robotsguide.com/learn/types-of-robots)的数据结合起来，接下来我们寻求调查如何将这些数据纳入具有更深层次推理能力的系统中。从仅有机器人数据学习复杂的语义推理是困难的。虽然机器人数据可以提供一系列*物理*能力，但像“将苹果从罐头移到橙子之间”这样的更复杂任务还需要理解图像中物体之间的语义关系，基本常识以及其他与机器人的物理能力无直接关联的符号知识。

因此，我们决定将另一个大规模数据源添加到混合中：互联网规模的图像和文本数据。我们使用了一个现有的大型视觉语言模型，该模型已经擅长于许多需要一定程度理解自然语言与图像之间关联的任务。该模型类似于公开可用的模型，如 ChatGPT 或 [Bard](https://bard.google.com/chat)。这些模型经过训练，以响应包含图像的提示输出文本，使它们能够解决诸如视觉问答、字幕制作和其他开放式视觉理解任务等问题。我们发现这样的模型可以被调整为适应机器人控制，只需训练它们也以机器人命令的形式框架的提示输出机器人动作（例如“将香蕉放在盘子上”）。我们将这种方法应用于来自 RT-X 合作的机器人数据。

RT-X 模型使用特定机器人手臂的图像或文本描述来输出一系列离散动作，从而使任何机器人手臂能够执行这些任务。通过收集来自世界各地机器人实验室的许多机器人执行许多任务的数据，我们正在构建一个可以用来教导机器人成为普遍有用的开源数据集。Chris Philpot

为了评估因特网获取的智能和多机器人数据的组合，我们使用谷歌的移动操纵机器人测试了我们的 RT-X 模型。我们对其进行了最难的泛化基准测试。机器人必须识别对象并成功操纵它们，还必须通过进行逻辑推理来回应复杂的文本命令，这需要整合来自文本和图像的信息。后者是使人类成为如此优秀的泛化者之一的原因。我们能否给我们的机器人至少一点这样的能力的暗示呢？

我们进行了两组评估。 作为基准，我们使用了一个模型，该模型排除了所有不涉及谷歌机器人的泛化多机器人 RT-X 数据。 实际上，谷歌的机器人特定数据集是 RT-X 数据集的最大部分，拥有超过 100,000 个演示，因此是否所有其它多机器人数据实际上会在这种情况下有所帮助这个问题是非常值得商榷的。 然后我们再次尝试包含所有多机器人数据。

在最困难的评估场景之一中，谷歌机器人需要完成一个涉及推理空间关系（“将苹果移动到罐子和橙子之间”）的任务； 在另一个任务中，它必须解决基本的数学问题（“将一个物体放在解答‘2+3’的纸上”）。 这些挑战旨在测试推理和得出结论的关键能力。

在这种情况下，推理能力（例如“之间”和“在……上面”的含义）来自训练视觉语言模型的 Web 规模数据，而将推理输出与机器人行为（实际上将机器人手臂移动到正确位置的命令）联系起来的能力来自 RT-X 的跨体现机器人数据的训练。 我们要求机器人执行其训练数据中未包含的任务的一个示例评估在下面的视频中显示。

即使没有特定的训练，这个谷歌研究机器人也能够遵循“将苹果移动到罐子和橙子之间”的指令。 这一能力是由 RT-X 提供的，这是一个大型的机器人操纵数据集，也是通往通用机器人大脑的第一步。

尽管对于人类来说，这些任务是基本的，但对于通用用途的机器人来说，它们构成了一个重大挑战。 没有清晰地说明诸如“之间”、“附近”和“在……上面”等概念的机器人示范数据，即使是在许多不同机器人的数据上训练过的系统也无法弄清楚这些命令的含义。 通过将视觉语言模型的 Web 规模知识与其它数据集集成，我们的完整系统能够解决这些任务，从互联网规模的训练中得出语义概念（在这种情况下，是空间关系），并从多机器人 RT-X 数据中得出物理行为（拾起和移动物体）。 令我们惊讶的是，我们发现多机器人数据的加入使 Google 机器人的泛化能力提高了三倍。 这一结果表明，多机器人 RT-X 数据不仅对于获得各种物理技能有用，而且还有助于更好地将这些技能与视觉语言模型中的语义和符号知识联系起来。 这些联系赋予了机器人一定程度的常识，这可能有一天使机器人能够理解像“把我的早餐给我拿来”这样的复杂而微妙的用户命令，同时执行使之发生的操作。

## RT-X 的下一步

RT-X 项目展示了当机器人学习社区共同行动时可能实现的成果。由于这种跨机构的努力，我们能够汇集多样化的机器人数据集，并进行全面的多机器人评估，这是任何单一机构都无法做到的。由于机器人学界不能依赖于从互联网上获取训练数据，我们需要自己创建这些数据。我们希望更多的研究人员能将他们的数据贡献给[RT-X 数据库](https://robotics-transformer-x.github.io/)并加入这一合作努力。我们也希望提供工具、模型和基础设施来支持跨载体研究。我们计划超越跨实验室共享数据，希望 RT-X 能发展成一个协作的努力，以开发数据标准、可重用模型以及新的技术和算法。

我们的早期结果暗示了大型跨载体机器人模型如何改变该领域。就像大型语言模型掌握了各种基于语言的任务一样，在未来我们可能会使用同样的基础模型作为许多实际机器人任务的基础。也许新的机器人技能可以通过微调或甚至提示预训练的基础模型来实现。类似于您如何提示 ChatGPT 来讲述一个故事，而无需首先对它进行特定故事的训练，您可以要求一个机器人在蛋糕上写“生日快乐”，而无需告诉它如何使用裱花袋或手写文本是什么样子。当然，这种通用能力的实现需要进行更多的研究，因为我们的实验主要集中在带有两指夹具的单臂进行简单操作任务上。

随着越来越多的实验室参与跨载体研究，我们希望进一步推动单个神经网络控制多个机器人的可能性的前沿。这些进展可能包括添加来自生成环境的多样化模拟数据，处理具有不同数量臂或手指的机器人，使用不同的传感器套件（例如深度摄像头和触觉传感），甚至结合操作和运动行为。RT-X 打开了这样的工作大门，但最令人兴奋的技术发展仍在前方。

这只是个开始。我们希望通过这一步，我们能共同创造机器人技术的未来：通用机器人大脑可以驱动任何机器人，并受益于全球所有机器人共享的数据。

*本文于 2024 年 2 月印刷版上发表，标题为“创建通用机器人大脑的全球项目”。*

来自您站点的文章

相关文章周围的网络
