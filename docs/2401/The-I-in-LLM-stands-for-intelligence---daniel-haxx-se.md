<!-- yml

类别：未分类

日期：2024-05-27 14:25:48

-->

# LLM中的I代表智能|daniel.haxx.se

> 来源：[https://daniel.haxx.se/blog/2024/01/02/the-i-in-llm-stands-for-intelligence/](https://daniel.haxx.se/blog/2024/01/02/the-i-in-llm-stands-for-intelligence/)

我一直没有写关于人工智能或者我们（不）如何在卷曲工厂使用人工智能进行开发的任何东西，现在我再也忍不住了。让我展示给你截止到今日人工智能对卷曲的最显著影响 - 并举例说明。

## 漏洞赏金

拥有[漏洞赏金](https://curl.se/docs/bugbounty.html)意味着我们向报告安全问题的黑客提供真正的奖金。金钱的吸引力吸引了一定数量的“运气寻找者”。基本上只是在源代码中查找模式或者在最好的情况下运行一些基本安全扫描器，然后报告他们的发现，希望能赚到一些奖金。

到目前为止，我们已经运行了一些年头的赏金，垃圾报告的比率从来不是一个大问题。此外，垃圾报告通常也很容易和快速检测出来并丢弃掉。它们很少引起真正的问题或浪费我们太多时间。有点像最愚蠢的垃圾邮件。

我们的漏洞赏金到目前为止已支付了超过70,000美元的奖励。我们收到了415份漏洞报告。其中，64份最终确认为安全问题。77份报告是 *informativ*，意味着它们通常是错误或类似的问题。其中66%的报告既不是安全问题也不是常规错误。

## 更好的垃圾更糟

当报告被*修饰*得更好，*看上去*具有一定意义时，我们需要更长时间来研究并最终丢弃它。每个安全报告都需要一个人花时间去查看并评估其含义。

垃圾越好，我们花在报告上的时间越长，消耗的精力就越大，直至我们关闭它。垃圾报告对项目没有任何帮助，相反，它占用开发人员的时间和精力，而这些时间和精力原本可以用在一些有意义的事情上。部分因为安全工作被认为是最重要的领域，因此它往往能战胜几乎其他所有事情。

一个安全报告可能会使开发人员无法修复一个非常恼人的错误。因为安全问题总是比其他错误更重要。如果报告被证明是垃圾，我们没有提高安全性，我们浪费了时间去修复错误或开发新功能。更不用说处理垃圾会耗费你的精力。

## 人工智能生成的安全报告

我意识到人工智能 *可以* 做很多好事。就像任何通用工具一样，它也可以被用来做错事。我也相信人工智能 *可以* 被训练，最终甚至用于以更有效的方式找到和报告安全问题，但到目前为止我们还没有找到真正的例子。

目前，用户似乎热衷于使用当前的一组LLM，将一些curl代码传递给它们，然后将输出作为安全漏洞报告传递下去。使其稍微难以检测的原因当然是用户复制和粘贴并包含他们自己的语言。整个事情并不完全是AI说的话，但报告仍然是垃圾。

## 检测人工智能垃圾

记者们通常并非完全精通英语，有时候他们的确切意图很难一下子理解，可能需要几次来回沟通直到事情正确地揭示出来——当然这完全是可以接受的。语言和文化障碍是真实存在的事物。

有时记者会使用人工智能或其他工具来帮助他们表达自己或翻译他们想要说的话。作为在外语中更好地沟通的辅助工具，我找不到任何问题。即使不精通英语的记者也可以找到并报告安全问题。

因此：仅仅有一些明显的迹象表明文本的部分内容是由人工智能或类似工具生成的，并不是立即的红旗。它仍然可能包含真相并且是一个有效的问题。这也是为什么一个形式良好的垃圾报告更难丢弃并且需要更长时间的原因之一。

## 证据A：代码变更被公开

在2023年秋天，我提醒社区即将披露[CVE-2023-38545](https://curl.se/docs/CVE-2023-38545.html)的漏洞，我们将其评为严重程度高。

在该问题即将发布的前一天，一位用户在[Hackerone上提交了这个报告](https://hackerone.com/reports/2199174)：Curl CVE-2023-38545漏洞代码变更已在互联网上公开披露。

这听起来相当糟糕，如果它真的是真的话，那就是个问题。

但是报告充斥着典型的人工智能风格幻觉：它混合和匹配来自旧安全问题的事实和细节，创造并编造了与现实无关的新事物。**变更并未在互联网上披露**。实际上已经披露的更改是为了以前的、更旧的问题。就像预期的那样。

在这份特别的报告中，用户友好地告诉我们他们使用了巴德来发现这个问题。巴德是一个谷歌生成的人工智能东西。这让我们更容易意识到疯狂，关闭报告并继续前进。正如报告日志所显示的，我们不必花费太多时间进行研究。

## 证据B：缓冲区溢出漏洞

更复杂的问题，不那么明显，做得更好但仍然饱受幻觉困扰。展示了当工具被更好地使用并更好地融入沟通时问题变得更糟的情况。

在2023年12月28日早上，一位用户在[Hackerone上提交了这个报告](https://hackerone.com/reports/2298307)：WebSocket处理中的缓冲区溢出漏洞。无论如何，那时是我所在时区的早晨。

再次，仅从标题看，这听起来很糟糕。由于我们的WebSocket代码仍处于试验阶段，因此不在我们的漏洞赏金计划范围之内，当我开始查看此报告时，它帮助我保持放松的态度。这是一个我以前从未见过的用户提交的，但他们在Hackerone上的“声誉”还算可以——这不是他们的第一个安全报告。

报告文件得相当整洁。它包含了细节，并用正确的英语编写。它还包含了一个建议的修复方案。对我来说，它并没有显得错误或不好。看起来像是这个用户已经发现了一些不好的东西，并且这个用户理解了这个问题，以至于还能提出解决方案。就安全报告而言，这看起来比平均第一篇帖子要好。

在报告中，您可以看到我的第一个模板响应，通知用户他们的报告已收到，并且我们将调查此案。当我发布时，我还不知道问题会有多么复杂或简单。

十九分钟后，我查看了代码，没有发现任何问题，再次阅读了代码，然后再次。*在地球上，记者说这里存在缓冲区溢出？*然后，我发布了第一个问题，询问清楚这个溢出会发生在哪里和如何发生。

经过反复提问和许多幻觉后，我意识到这并不是一个真正的问题，在同一天的下午，我将问题关闭为不适用。**没有缓冲区溢出**。

我不确定用户的这组回复是否由LLM生成，但它具有几个迹象。

## 禁止这些报告者

在Hackerone上，没有明确的“禁止报告者与我们的项目进一步沟通”的功能。如果存在，我会使用它。研究人员的“声誉”会降低，然后我们将问题关闭为不适用，但仅在单个项目中执行一次时，这只是一个非常小的推动。

我已经要求Hackerone提供更好的支持。**更新：**这个功能*存在*，我只是没有在正确的地方找到它……

## 未来

随着这类报告随着时间的推移变得越来越普遍，我怀疑我们可能会更好地触发*由AI生成*的信号并且忽略基于这些信号的报告。当然，当AI用于适当的任务时，例如翻译或仅语言表达帮助时，这将是不幸的。

我相信未来会出现使用人工智能进行此目的的工具，至少在某些时候，这些工具会比较（更好）地工作，因此我不能也不会说寻找安全问题的人工智能必定是一个坏主意。

我确实怀疑，如果您只是在混合中添加一个微小的（智能的）人类检查，这样的工具的使用和结果将变得更好。我怀疑这将在未来很长一段时间内都是如此。

我毫不怀疑，人们将来也会不断寻找捷径。我相信他们会一直试图赚取那些快速的奖励金钱。就像对于垃圾邮件发送者来说，这样做的成本最终是由接收方承担的。强大的语言模型的易用性和广泛访问性实在是太诱人了。我强烈怀疑我们的Hackerone邮箱里会越来越多地收到由语言模型生成的垃圾邮件。

## 讨论

[Hacker news](https://news.ycombinator.com/item?id=38845878)

## 鸣谢

图片来自[Pixabay](https://pixabay.com//?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=8331364)的[海德尔·马哈茂德](https://pixabay.com/users/haidermah-38208306/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=8331364)
