<!--yml

类别：未分类

日期：2024-05-27 15:01:08

-->

# 我们如何构建一个公平的多租户队列系统 - Inngest 博客

> 来源：[https://www.inngest.com/blog/building-the-inngest-queue-pt-i-fairness-multi-tenancy](https://www.inngest.com/blog/building-the-inngest-queue-pt-i-fairness-multi-tenancy)

在软件开发中，队列系统对于可靠性至关重要，而且很难构建。关于如何构建队列系统存在大量争论 —— [Postgres](https://news.ycombinator.com/item?id=35526846) 和 [SKIP LOCKED](https://news.ycombinator.com/item?id=37636841) 总是被讨论得沸沸扬扬。

我们花了很长时间研究和构建我们自己的分布式队列系统，在这篇文章中，我们将解释其中的挑战是什么，为什么我们需要构建它，以及它是如何工作的。

## 构建队列系统的挑战

我们将 Inngest 构建为现代应用程序的可靠性层。它使开发人员能够通过将持久执行、事件流和队列组合到一个无服务器平台中，以代码形式编写声明性步函数。

Inngest 在平台内管理事件流、队列和状态。环境被创建，并且函数会自动部署到 [您代码库的每个分支](/blog/branch-environments)。团队可能会在 Inngest 上部署 *数百* 个函数，跨越数十个分支，导致数千个函数对事件实时响应（在约 10-100 毫秒内）。

当我们扩展到**数千名触发了数十亿次函数运行的用户**时，我们对在队列构建的平台上开发的挑战有了很多了解。

尝试使用任何现成的队列系统构建这样的系统很快就会变得困难。以下是您将遇到的一些关键挑战：

+   **公平性**。你每秒发送 5,000 个事件。管理起来并不困难，但在一个单一队列中，你的作业会阻塞其他用户的工作运行。这不公平。一个用户不应该能够阻止另一个用户的工作。

+   **多租户**。大多数队列都采用“工作者”模型：您指定工作者应该监听哪些队列，以及该工作者可以处理多少作业。为每个函数启动新的工作者是乏味且繁琐的。考虑到开发分支是短暂且突发性的，情况变得更糟。

+   **竞争**。随着成千上万的客户运行包含并行步骤的数千个步函数，在任何给定时间都有数百万个可用于工作的作业。在典型的队列系统中，工作者们会争抢最早可用的工作，导致大量的自旋和浪费的努力。

+   **并发性**。在其他队列系统中，跨分布式工作者自定义并发性是不可能的。通常，并发性管理是在工作者轮询逻辑内实现的。在 Inngest 内，您可以使用一行代码在单个函数上设置多个并发设置。这创建了用于管理运行的虚拟队列。

+   **读写负载**。每秒处理数万个作业会导致每秒数十万次的请求：入队、"锁定"（我们会解释），出队都会对运行队列的基础设施产生沉重的负载。

+   **基础设施**。队列需要可靠和容错，这意味着我们需要构建分布式系统（这也会影响延迟）。

+   **可观测性**。大多数队列都是不透明的，开箱即用的观测性很少或基本。很难为步骤函数构建超越积压的实时可观测性：例如，等待其他事件的函数数量，或者墙上时间与执行时间的直方图。

+   **可定制性**。要扩展基本队列系统的高级功能是困难的且耗时极大的。定制包括：逐个更改退避，基于作业数据取消积压，批处理，去抖动，智能索引和步骤函数并行处理。

为了解决所有这些问题，我们为 Inngest 从头开始开发了一个全新的队列。它是一个公平的、低延迟的、多租户队列，它通过多个共享无状态的 worker 以 (几乎) 无争用的方式声明作业。

在这一系列的博客文章中，我们将解释队列系统的工作原理以及解决这些问题的设计决策。

## 可靠性层如何使用队列

为了设置上下文，让我们通过一个示例函数配置来讲解 Inngest 如何使用队列，我们使用了我们的 [TS SDK](/docs/reference/typescript)（[Go](https://pkg.go.dev/github.com/inngest/inngestgo) 和 [Python](/docs/reference/python) SDK 也可用，[更多即将推出](https://roadmap.inngest.com/roadmap)）：

```
tsx

inngest.createFunction(

 {

 id:  "update-user",  // Unique function ID

 concurrency:  15,  // Concurrency controls per function (https://innge.st/concurrency)

 debounce: { // Debounce management (https://innge.st/debounce)

 period:  "5s",

 timeout:  "20s",

 }

 },

 { event:  "clerk/user.created" },

  async ({ event, step }) => {

  const  user  =  await  step.run("Load user info",  async () => {

  return  await  clerk.users.getUser(event.data.userId);

 });

  return  await  step.run("Update DB",  async () => {

  const  updates  =  userFields(user); // grab fields from clerk

  return  await  db.users.where({ clerk_id:  user.id }).update(updates);

 });

 }

);

```

如果你熟悉步骤函数，你可能已经看到这里发生了什么。这段代码创建了一个函数，当通过 Clerk 的 Webhooks 接收到 `clerk/user.created` 事件时，它会自动运行。这是一个使用 [持久化执行](/blog/how-durable-workflow-engines-work) 来可靠运行代码的步骤函数。这意味着每个步骤都是由自己的队列作业支持的代码级事务。如果步骤失败，它会自动重试。从步骤返回的任何数据都会自动捕获到函数运行状态中，并在每次步骤调用时注入。

还有一些额外的细微差别。函数指定了自己的并发限制以及一个去抖动。并发限制防止超过 15 个步骤同时运行。去抖动安排一个函数运行 5 秒钟，如果在此期间收到任何其他匹配事件，则 Inngest 会将函数重新安排在另外 5 秒后运行（直到最大超时时间过去为止）。

所有这些都是自动发生的，无需预配队列或基础设施，基于我们的队列系统。以下是发生的情况：

+   当接收到事件时，我们*[幂等地](/docs/guides/handling-idempotency)*排队一个作业，该作业调用函数处理程序。这必须是幂等的，因为[事件流至少是*一次*](/blog/message-bus-vs-queues)，我们希望一个事件只对应一个函数运行。

+   防抖会使运行函数变得复杂：作业会被安排在 5 秒延迟（或者函数配置中的任何时间）之后，并且任何额外的事件都会再次延迟该作业。

+   当作业变得“可见”时，我们确保函数没有超出其并发限制，并通过使用传入的事件数据调用函数开始工作。

+   一旦函数运行一步，我们就会将步骤的结果存储在函数运行的状态中，并且（在最坏的情况下）为下一步*再次*排队一个作业。对于长时间运行的服务器，这里有一些细微差别，不过我们将在执行深入探讨中另行讨论。

从本质上讲，*一切*都会影响队列。可靠地运行一个函数必须使用一个队列。并发、防抖和批处理都会对队列在个别作业级别上的工作产生影响。

有了这个背景，让我们谈谈在多租户环境中如何运作，同时有成千上万的用户同时运行数百万个函数。

## 经典队列中的不公平性

大多数队列都**不是**多租户的。

以 SQS 为例。通常，您会创建一个队列来处理代码中的特定作业。该队列在系统中的每个用户中都会使用。如果你的一个用户（比如，Mallory）一次发送了 5000 条消息，然后 Alice 将一些东西排队，那么在我们处理 Alice 的单个任务之前，我们必须处理完 Mallory 的 5000 个作业。这是*不公平的*。

对于经典的排队系统来说，这几乎不可能轻松解决。在几个队列之间随机分片会降低阻塞发生的机会，但保证最终它仍然会发生。您可以尝试在队列之外进行一些簿记，并在作业到达时手动重新排队作业，但这会增加延迟、成本、流动性，并且不提供实际的公平性（以及编写起来非常困难、容易出错和令人讨厌）。

简而言之，要使像 SQS、BullMQ 或 Graphile 这样的东西在多租户环境中良好运行是*非常困难*的。围绕公平性的各种妥协成本很高，增加了延迟，并且没有*非常复杂的基础设施*来为每个租户分配资源，实际上并没有解决问题。

那么，我们如何解决公平性呢？

## 构建一个公平的多租户队列

在理想的情况下，公平性发生在函数级别*和*帐户级别。假设您通过 Inngest 运行了 100 个函数，并向一个特定函数推送了一百万个作业。这些作业不应该阻塞您帐户中的其他函数运行。

**这导致了第一个要求：每添加一个函数都必须有自己的队列，以最大程度地提高公平性。**

这引出了一些问题。我们如何才能让队列足够便宜，以便为每个函数在代码的每个分支中创建队列？以及，工作人员如何订阅在任何时候创建的队列，而无需重新启动或启动新进程？几乎每个现有的队列都需要你运行订阅特定队列的工作人员：

```
ts

// ❌ classic queue workers aren't compatible with multi-tenant queues,

// or > 1 custom concurrency limits per function

worker.concurrency =  100;

worker.run(["queue:1",  "queue:2"], () => {

  // run jobs in queue 1 and 2

})

```

如果你向 Inngest 添加一个新函数，我们无法动态重建工作人员。这会使我们的代码和基础设施*非常*混乱，最坏的情况下可能意味着工作人员每秒循环一次，因为添加了新函数。

**我们还有另一个要求：延迟必须尽可能低。**

这给系统增加了一些需求。我们必须有一个工作人员池，能够自动扩展，以确保我们尽可能快地运行作业。我们不能在添加新队列时随时重新启动工作人员。

考虑到所有这些要求，我们需要：

+   编写自动发现可用函数的工作人员

+   使工作人员自动从每个函数获取工作

+   并且*无需争用*

**我们的第三个要求：处理争用。**

争用是公平性的另一个关键部分：两个工作人员不应该为相同的函数竞争。但与此同时，我们又不能将函数分配给*特定*的工作人员，因为它们可能随时死掉。解决方案是创建分层队列系统。

1.  每个函数都有自己的未完成工作队列。

1.  我们创建*另一个*更高级别的队列，记录每个函数的最早可用作业。

1.  所有工作人员都会扫描此队列以发现可用工作。

这给了我们一个可用的工作子集：`[Function A，Function B，Function C]`等，按*延迟*顺序排列，最旧的作业优先。这解决了*多租户*问题，但即使有了这个列表，我们仍然需要处理公平性和争用。扫描作业的100个独立工作人员将按相同的顺序获取相同的列表，导致100个工作人员尝试运行函数 A 的作业。这既不公平，也争用太高。

解决这个问题我们有几种策略。其中一个关键部分是，每个工作优先级都会将预览的作业按照加权随机顺序洗牌，考虑到延迟、容量、免费与付费等因素。洗牌后，工作人员就会声明函数的作业队列来运行工作。这确保了每个函数都能独立运行，并保证公平性。它还能最小化延迟，因为优先级洗牌仍然会优先处理较早的工作。

## 结论

队列有很多微妙之处，尽管在高层次上，这解决了所有关键要求：争用、公平性和延迟。这种模型的一个巨大优势是：队列变得非常便宜。这是让您为每个功能创建队列的神奇之处，也是*让我们为每个功能添加多个并发级别的虚拟队列的一部分*。这种方法已经让我们以可靠、高性能和可扩展的方式为所有用户创建了一个带有内置流控功能的队列。我们对这个解决方案*非常*满意，认为它有很大的发展空间。

尽管队列在我们的工作方式中是基础性的，但我们认为像Inngest这样的可靠性层意味着您实际上永远不需要实现队列，甚至不需要考虑它是如何工作的。系统通过代码以声明方式为您抽象了一切，所以即使是最新入职的工程师也能够有效地构建可靠的系统。

如果您发现这个有趣，或者您想要在这样的系统上工作，请通过[email](/contact)，[Twitter](https://twitter.com/inngest)，或者我们的[Discord](/discord)联系我们。我们很乐意听听您的想法，而且[我们正在招聘](/careers)！
