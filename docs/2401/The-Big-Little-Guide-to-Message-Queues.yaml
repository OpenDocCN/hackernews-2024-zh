- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: æœªåˆ†ç±»'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: ç±»åˆ«ï¼šæœªåˆ†ç±»
- en: 'date: 2024-05-27 15:18:28'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: æ—¥æœŸï¼š2024-05-27 15:18:28
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: The Big Little Guide to Message Queues
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯é˜Ÿåˆ—çš„ä¸€æœ¬å°æŒ‡å—
- en: æ¥æºï¼š[https://sudhir.io/the-big-little-guide-to-message-queues](https://sudhir.io/the-big-little-guide-to-message-queues)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: æ¥æºï¼š[https://sudhir.io/the-big-little-guide-to-message-queues](https://sudhir.io/the-big-little-guide-to-message-queues)
- en: The Big Little Guide to Message Queues
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯é˜Ÿåˆ—çš„ä¸€æœ¬å°æŒ‡å—
- en: A guide to the fundamental concepts that underlie message queues, and how they
    apply to popular queueing systems available today.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯é˜Ÿåˆ—çš„åŸºæœ¬æ¦‚å¿µæŒ‡å—ï¼Œä»¥åŠå®ƒä»¬å¦‚ä½•åº”ç”¨äºä»Šå¤©æµè¡Œçš„é˜Ÿåˆ—ç³»ç»Ÿã€‚
- en: Message Queues are now fairly prevalentâ€”there are so many of them showing up
    so fast you'd think they were [rabbits](https://www.rabbitmq.com) with an unlimited
    supply of [celery](https://docs.celeryproject.org/en/stable/), resulting in an
    [kafkaesque](https://kafka.apache.org) situation where making a decision is like
    trying to catch a [stream](https://redis.io/topics/streams-intro) in your hands.
    If only there were fewer [simple](https://aws.amazon.com/sns) [services](https://aws.amazon.com/sqs/)
    that could help with [publishing and subscribing](https://cloud.google.com/pubsub),
    it would be so much easier to make a [zero-effort](https://zeromq.org) choice
    ğŸ˜•
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯é˜Ÿåˆ—ç°åœ¨ç›¸å½“æ™®éâ€”â€”å®ƒä»¬å¦‚æ­¤å¿«é€Ÿåœ°å‡ºç°ï¼Œä»¥è‡³äºä½ ä¼šè®¤ä¸ºå®ƒä»¬å°±åƒæ˜¯ğŸ‡[å…”å­](https://www.rabbitmq.com)ï¼Œæ‹¥æœ‰ğŸ¥¦[æ— é™ä¾›åº”çš„èŠ¹èœ](https://docs.celeryproject.org/en/stable/)ï¼Œå¯¼è‡´äº†ğŸ§Ÿä¸€ä¸ª[å¡å¤«å¡å¼](https://kafka.apache.org)çš„æƒ…å†µï¼Œåšå‡ºå†³å®šå°±åƒè¯•å›¾ç”¨æ‰‹æ¥ä½ä¸€æ¡[æ²³æµ](https://redis.io/topics/streams-intro)ã€‚å¦‚æœåªæœ‰æ›´å°‘çš„[ç®€å•](https://aws.amazon.com/sns)[æœåŠ¡](https://aws.amazon.com/sqs/)å¯ä»¥å¸®åŠ©è¿›è¡Œ[å‘å¸ƒå’Œè®¢é˜…](https://cloud.google.com/pubsub)ï¼Œé‚£ä¹ˆåšä¸€ä¸ª[é›¶å·¥ä½œ](https://zeromq.org)çš„é€‰æ‹©å°†ä¼šæ›´å®¹æ˜“
    ğŸ˜•
- en: Whether we use them by themselves as-is to move data between parts of our application,
    or as an integral part of the architecture (like event driven systems), message
    queues are here to stay. In a way, they've been here all alongâ€”just without as
    many names. But what are they? Why are they useful? And how do we use them effectively?
    Which implementation do we pick? Does it even matter which one we use? And do
    we need to learn each of them individually, or are there more general concepts
    that apply to all message queues?
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: æ— è®ºæˆ‘ä»¬æ˜¯å°†å®ƒä»¬å•ç‹¬ä½¿ç”¨æ¥åœ¨åº”ç”¨ç¨‹åºçš„å„éƒ¨åˆ†ä¹‹é—´ä¼ è¾“æ•°æ®ï¼Œè¿˜æ˜¯å°†å®ƒä»¬ä½œä¸ºæ¶æ„çš„ä¸€ä¸ªç»„æˆéƒ¨åˆ†ï¼ˆæ¯”å¦‚äº‹ä»¶é©±åŠ¨ç³»ç»Ÿï¼‰ï¼Œæ¶ˆæ¯é˜Ÿåˆ—éƒ½ä¼šå­˜åœ¨ã€‚ä»æŸç§ç¨‹åº¦ä¸Šæ¥è¯´ï¼Œå®ƒä»¬ä¸€ç›´éƒ½åœ¨â€”â€”åªæ˜¯æ²¡æœ‰é‚£ä¹ˆå¤šçš„åå­—ã€‚ä½†æ˜¯å®ƒä»¬æ˜¯ä»€ä¹ˆï¼Ÿä¸ºä»€ä¹ˆå®ƒä»¬æœ‰ç”¨ï¼Ÿæˆ‘ä»¬å¦‚ä½•æœ‰æ•ˆåœ°ä½¿ç”¨å®ƒä»¬ï¼Ÿæˆ‘ä»¬è¦é€‰æ‹©å“ªç§å®ç°ï¼Ÿæˆ‘ä»¬é€‰æ‹©ä½¿ç”¨å“ªä¸€ç§å®ç°çœŸçš„é‡è¦å—ï¼Ÿæˆ‘ä»¬éœ€è¦å•ç‹¬å­¦ä¹ æ¯ç§å®ç°ï¼Œè¿˜æ˜¯æœ‰æ›´ä¸€èˆ¬çš„è§‚å¿µé€‚ç”¨äºæ‰€æœ‰æ¶ˆæ¯é˜Ÿåˆ—ï¼Ÿ
- en: 'In this guide, we''ll talk about:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æœ¬æŒ‡å—ä¸­ï¼Œæˆ‘ä»¬å°†è®¨è®ºï¼š
- en: What message queues are and their history.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯é˜Ÿåˆ—æ˜¯ä»€ä¹ˆåŠå…¶å†å²ã€‚
- en: Why they're useful and what mental models to use when reasoning about them.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºä½•å®ƒä»¬æœ‰ç”¨ä»¥åŠæ¨ç†æ—¶ä½¿ç”¨çš„å¿ƒæ™ºæ¨¡å‹ã€‚
- en: Delivery guarantees that the queuing systems make (at-least-once, at-most-once,
    and exactly-once semantics).
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: é˜Ÿåˆ—ç³»ç»Ÿæä¾›çš„ä¼ é€’ä¿è¯ï¼ˆè‡³å°‘ä¸€æ¬¡ã€è‡³å¤šä¸€æ¬¡å’Œæ­£å¥½ä¸€æ¬¡è¯­ä¹‰ï¼‰ã€‚
- en: Ordering and FIFO guarantees and how they effect sequencing, parallelism and
    performance.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ’åºå’ŒFIFOä¿è¯ä»¥åŠå®ƒä»¬å¯¹æ’åºã€å¹¶è¡Œå’Œæ€§èƒ½çš„å½±å“ã€‚
- en: 'Patterns for fan-out and fan-in: delivering one message to many systems or
    messages from many systems into one.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ‰‡å‡ºå’Œæ‰‡å…¥æ¨¡å¼ï¼šå°†ä¸€ä¸ªæ¶ˆæ¯ä¼ é€’ç»™å¤šä¸ªç³»ç»Ÿï¼Œæˆ–å°†æ¥è‡ªå¤šä¸ªç³»ç»Ÿçš„æ¶ˆæ¯ä¼ é€’åˆ°ä¸€ä¸ªç³»ç»Ÿä¸­ã€‚
- en: Notes on the pros and cons of many popular systems available today.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å…³äºä»Šå¤©è®¸å¤šæµè¡Œç³»ç»Ÿçš„ä¼˜ç¼ºç‚¹çš„ç¬”è®°ã€‚
- en: What are message queues?
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä»€ä¹ˆæ˜¯æ¶ˆæ¯é˜Ÿåˆ—ï¼Ÿ
- en: Message Queues are a way to transfer information between two systems. This informationâ€”a
    messageâ€”can be data, metadata, signals, or a combination of all three. The systems
    that are sending and receiving messages could be processes on the same computer,
    modules of the same application, services that might be running on different computers
    or technology stacks, or entirely different kinds of systems altogetherâ€”like transferring
    information from your software into an email or an SMS on the cellphone network.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯é˜Ÿåˆ—æ˜¯åœ¨ä¸¤ä¸ªç³»ç»Ÿä¹‹é—´ä¼ é€’ä¿¡æ¯çš„ä¸€ç§æ–¹å¼ã€‚è¿™ä¸ªä¿¡æ¯â€”â€”ä¸€æ¡æ¶ˆæ¯â€”â€”å¯ä»¥æ˜¯æ•°æ®ã€å…ƒæ•°æ®ã€ä¿¡å·ï¼Œæˆ–è€…ä»¥ä¸Šä¸‰è€…çš„ç»„åˆã€‚å‘é€å’Œæ¥æ”¶æ¶ˆæ¯çš„ç³»ç»Ÿå¯ä»¥æ˜¯åŒä¸€å°è®¡ç®—æœºä¸Šçš„è¿›ç¨‹ã€åŒä¸€ä¸ªåº”ç”¨ç¨‹åºçš„æ¨¡å—ã€åœ¨ä¸åŒè®¡ç®—æœºæˆ–æŠ€æœ¯æ ˆä¸Šè¿è¡Œçš„æœåŠ¡ï¼Œæˆ–è€…å®Œå…¨ä¸åŒç±»å‹çš„ç³»ç»Ÿâ€”â€”æ¯”å¦‚å°†ä¿¡æ¯ä»æ‚¨çš„è½¯ä»¶ä¼ é€’åˆ°ç”µå­é‚®ä»¶æˆ–æ‰‹æœºç½‘ç»œä¸Šçš„çŸ­ä¿¡ã€‚
- en: The idea of a messaging system has been around a very long time, from the message
    boxes used for moving information between people or office departments (literally
    where the words *inbox* and *outbox* come from), to telegrams, to your local postal
    or courier service. The messaging systems in the physical world that come closest
    to what we have in computing are probably the [pnuematic](https://en.wikipedia.org/wiki/Pneumatic_tube)
    [tubes](https://www.google.com/search?q=pneumatic+tubes&source=lnms&tbm=isch&sa=X&biw=2560&bih=1366)
    that moved messages through buildings and cities using compressed air until a
    few decades ago (and are still used in some places today).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯ç³»ç»Ÿçš„æ¦‚å¿µå·²ç»å­˜åœ¨äº†å¾ˆé•¿æ—¶é—´ï¼Œä»ç”¨äºåœ¨äººä»¬æˆ–åŠå…¬å®¤éƒ¨é—¨ä¹‹é—´ä¼ é€’ä¿¡æ¯çš„æ¶ˆæ¯ç®±ï¼ˆæ–‡å­—*æ”¶ä»¶ç®±*å’Œ*å‘ä»¶ç®±*çš„æ¥æºï¼‰ï¼Œåˆ°ç”µæŠ¥ï¼Œå†åˆ°æ‚¨å½“åœ°çš„é‚®æ”¿æˆ–å¿«é€’æœåŠ¡ã€‚åœ¨ç‰©ç†ä¸–ç•Œä¸­ï¼Œä¸æˆ‘ä»¬åœ¨è®¡ç®—ä¸­æ‹¥æœ‰çš„æœ€æ¥è¿‘çš„æ¶ˆæ¯ç³»ç»Ÿå¯èƒ½æ˜¯å‡ åå¹´å‰ï¼ˆä»Šå¤©ä»ç„¶åœ¨ä¸€äº›åœ°æ–¹ä½¿ç”¨ï¼‰é€šè¿‡å‹ç¼©ç©ºæ°”åœ¨å»ºç­‘ç‰©å’ŒåŸå¸‚ä¹‹é—´ä¼ é€’æ¶ˆæ¯çš„[æ°”åŠ¨ç®¡](https://en.wikipedia.org/wiki/Pneumatic_tube)
    [ç®¡é“](https://www.google.com/search?q=pneumatic+tubes&source=lnms&tbm=isch&sa=X&biw=2560&bih=1366)ã€‚
- en: The kinds of messages we transfer today might be a note that something technical
    happened, like CPU usage exceeding a limit; or a business event of interest, like
    a customer placing an order; or a signal, like a command that tells another service
    to do something. The contents of each message will be driven entirely by the architecture
    of your application and its purposesâ€”so for the rest of this guide, we don't need
    to be concerned about what's inside a messageâ€”we're more concerned with how the
    message gets from the system where it originates (the *producer*, *source, publisher*
    or *sender*) to the system where's it's supposed to go (the *consumer*, *subscriber*,
    *destination* or *receiver*).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ä»Šå¤©æˆ‘ä»¬ä¼ è¾“çš„æ¶ˆæ¯å¯èƒ½æ˜¯ä¸€æ¡æŒ‡å‡ºå‘ç”Ÿäº†æŸä¸ªæŠ€æœ¯äº‹ä»¶çš„æ³¨é‡Šï¼Œä¾‹å¦‚ CPU ä½¿ç”¨é‡è¶…è¿‡äº†é™åˆ¶ï¼›æˆ–è€…æ˜¯ä¸€æ¡å•†ä¸šäº‹ä»¶ï¼Œä¾‹å¦‚å®¢æˆ·ä¸‹è®¢å•ï¼›æˆ–è€…æ˜¯ä¸€ä¸ªä¿¡å·ï¼Œä¾‹å¦‚å‘Šè¯‰å¦ä¸€ä¸ªæœåŠ¡æ‰§è¡ŒæŸäº›æ“ä½œçš„å‘½ä»¤ã€‚æ¯æ¡æ¶ˆæ¯çš„å†…å®¹å®Œå…¨ç”±æ‚¨çš„åº”ç”¨ç¨‹åºåŠå…¶ç›®çš„çš„æ¶æ„é©±åŠ¨â€”â€”å› æ­¤ï¼Œåœ¨æœ¬æŒ‡å—çš„å…¶ä½™éƒ¨åˆ†ï¼Œæˆ‘ä»¬ä¸éœ€è¦å…³å¿ƒæ¶ˆæ¯å†…éƒ¨çš„å†…å®¹â€”â€”æˆ‘ä»¬æ›´å…³å¿ƒçš„æ˜¯æ¶ˆæ¯å¦‚ä½•ä»å…¶äº§ç”Ÿçš„ç³»ç»Ÿï¼ˆ*ç”Ÿäº§è€…*ã€*æ¥æºã€å‘å¸ƒè€…*æˆ–*å‘é€è€…*ï¼‰ä¼ é€’åˆ°å…¶åº”è¯¥åˆ°è¾¾çš„ç³»ç»Ÿï¼ˆ*æ¶ˆè´¹è€…*ã€*è®¢é˜…è€…*ã€*ç›®çš„åœ°*æˆ–*æ¥æ”¶è€…*ï¼‰ã€‚
- en: And Why Do We Need Them?
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦å®ƒä»¬å‘¢ï¼Ÿ
- en: We need message queues because no system exists or works in isolationâ€”all systems
    need to communicate with other systems in structured ways that they both can understand,
    and at a controlled speed that they both can handle. Any non-trivial process needs
    a way to move information between each stage of the process; any workflow needs
    a way to move the intermediate product between the stages of that workflow. Message
    queues are a great way to handle this movement. There are plenty of ways of getting
    these messages around using API calls, file systems, or many other abuses of the
    natural order of things; but all of these are ad-hoc implementations of the message
    queue that we sometimes refuse to acknowledge we need.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬éœ€è¦æ¶ˆæ¯é˜Ÿåˆ—ï¼Œå› ä¸ºæ²¡æœ‰ä»»ä½•ç³»ç»Ÿå­˜åœ¨æˆ–ç‹¬ç«‹è¿è¡Œâ€”â€”æ‰€æœ‰ç³»ç»Ÿéƒ½éœ€è¦ä»¥å®ƒä»¬éƒ½èƒ½ç†è§£çš„ç»“æ„åŒ–æ–¹å¼ä¸å…¶ä»–ç³»ç»Ÿé€šä¿¡ï¼Œå¹¶ä»¥å®ƒä»¬éƒ½èƒ½å¤„ç†çš„å—æ§é€Ÿåº¦é€šä¿¡ã€‚ä»»ä½•éå¹³å‡¡çš„è¿‡ç¨‹éƒ½éœ€è¦ä¸€ç§æ–¹æ³•åœ¨æ¯ä¸ªè¿‡ç¨‹é˜¶æ®µä¹‹é—´ä¼ é€’ä¿¡æ¯ï¼›ä»»ä½•å·¥ä½œæµéƒ½éœ€è¦ä¸€ç§æ–¹æ³•åœ¨è¯¥å·¥ä½œæµçš„å„ä¸ªé˜¶æ®µä¹‹é—´ä¼ é€’ä¸­é—´äº§å“ã€‚æ¶ˆæ¯é˜Ÿåˆ—æ˜¯å¤„ç†æ­¤ç§»åŠ¨çš„ç»ä½³æ–¹å¼ã€‚æœ‰è®¸å¤šæ–¹æ³•å¯ä»¥ä½¿ç”¨
    API è°ƒç”¨ã€æ–‡ä»¶ç³»ç»Ÿæˆ–è®¸å¤šå…¶ä»–è¿åè‡ªç„¶ç§©åºçš„æ–¹å¼å°†è¿™äº›æ¶ˆæ¯ä¼ é€’è¿‡å»ï¼›ä½†æ‰€æœ‰è¿™äº›éƒ½æ˜¯æ¶ˆæ¯é˜Ÿåˆ—çš„ç‰¹å®šå®ç°ï¼Œæˆ‘ä»¬æœ‰æ—¶æ‹’ç»æ‰¿è®¤æˆ‘ä»¬éœ€è¦å®ƒä»¬ã€‚
- en: 'The simplest mental model for a message queue is a very long tube that you
    can roll a ball into. You write your message on a ball, roll it into the tube,
    and someone or something else receives it at the other end. There are a lot of
    interesting benefits with this model, some of which are:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯é˜Ÿåˆ—çš„æœ€ç®€å•å¿ƒæ™ºæ¨¡å‹æ˜¯ä¸€ä¸ªéå¸¸é•¿çš„ç®¡é“ï¼Œæ‚¨å¯ä»¥å°†çƒæ»šå…¥å…¶ä¸­ã€‚æ‚¨åœ¨çƒä¸Šå†™ä¸Šæ‚¨çš„æ¶ˆæ¯ï¼Œå°†å…¶æ»šå…¥ç®¡é“ï¼Œç„¶åå¦ä¸€ä¸ªäººæˆ–ç‰©ä½“ä¼šåœ¨å¦ä¸€ç«¯æ¥æ”¶åˆ°å®ƒã€‚è¿™ä¸ªæ¨¡å‹æœ‰å¾ˆå¤šæœ‰è¶£çš„å¥½å¤„ï¼Œå…¶ä¸­ä¸€äº›æ˜¯ï¼š
- en: We don't need to worry about *who or what* is going to receive the message â€“
    that's one less responsibility for the sender to be concerned about.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸éœ€è¦æ‹…å¿ƒ*è°æˆ–ä»€ä¹ˆ*ä¼šæ¥æ”¶æ¶ˆæ¯â€”â€”è¿™å‡è½»äº†å‘é€è€…çš„ä¸€ä¸ªè´£ä»»ã€‚
- en: We don't need to worry about *when* the receiver is going to pick up the message.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä¸éœ€è¦æ‹…å¿ƒ*æ¥æ”¶è€…*ä½•æ—¶æ”¶åˆ°æ¶ˆæ¯ã€‚
- en: We can put *as many* messages as we want into the tube (let's assume we have
    a infinitely long tube) at whatever *speed* is comfortable to us.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬å¯ä»¥å°†*ä»»æ„æ•°é‡*çš„æ¶ˆæ¯æ”¾å…¥ç®¡é“ä¸­ï¼ˆå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæ— é™é•¿çš„ç®¡é“ï¼‰ï¼Œä»¥æˆ‘ä»¬èˆ’é€‚çš„*é€Ÿåº¦*ã€‚
- en: The receiver will *never be impacted* by our actionsâ€”they will pull out as many
    messages as they want at whatever rate is comfortable to them.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¥æ”¶è€…å°†*æ°¸è¿œä¸ä¼šå—åˆ°*æˆ‘ä»¬è¡ŒåŠ¨çš„å½±å“â€”â€”ä»–ä»¬ä¼šä»¥ä»–ä»¬èˆ’é€‚çš„é€Ÿåº¦æ‹‰å‡ºä»–ä»¬æƒ³è¦çš„ä»»æ„æ•°é‡çš„æ¶ˆæ¯ã€‚
- en: Neither the sender nor the receiver are concerned with *how* the other works.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‘é€è€…å’Œæ¥æ”¶è€…éƒ½ä¸å…³å¿ƒ*å¯¹æ–¹*å¦‚ä½•å·¥ä½œã€‚
- en: Neither the sender nor the receiver are concerned with the *capacity or load*
    of the other.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‘é€è€…å’Œæ¥æ”¶è€…éƒ½ä¸å…³å¿ƒå¯¹æ–¹çš„*å®¹é‡æˆ–è´Ÿè½½*ã€‚
- en: Neither system is concerned with *where* the other one is â€“ they may or many
    not reside on the same computer, network, continent or even the same planet.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸¤ä¸ªç³»ç»Ÿéƒ½ä¸å…³å¿ƒå¦ä¸€ä¸ªç³»ç»Ÿåœ¨*å“ªé‡Œ*â€”â€”å®ƒä»¬å¯èƒ½åœ¨åŒä¸€å°è®¡ç®—æœºã€ç½‘ç»œã€å¤§é™†ç”šè‡³åŒä¸€é¢—è¡Œæ˜Ÿä¸Šï¼Œä¹Ÿå¯èƒ½ä¸åœ¨ã€‚
- en: Each of these advantages (and this isn't even an exhaustive list) has very important
    benefits in software developmentâ€”what they all have in common is *decoupling*.
    One system is decoupled from the other in terms of responsibility, time, bandwidth,
    internal workings, load and geography. And decoupling is a very desirable part
    of any distributed or complex systemâ€”the more decoupled the parts of the system
    are, the easier it is to independently build, test, run, maintain and scale them.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›ä¼˜åŠ¿ä¸­çš„æ¯ä¸€ä¸ªï¼ˆè¿™ç”šè‡³ä¸æ˜¯ä¸€ä¸ªè¯¦å°½çš„åˆ—è¡¨ï¼‰åœ¨è½¯ä»¶å¼€å‘ä¸­éƒ½æœ‰ç€éå¸¸é‡è¦çš„å¥½å¤„â€”â€”å®ƒä»¬æ‰€æœ‰çš„å…±åŒç‚¹éƒ½æ˜¯*è§£è€¦*ã€‚ä¸€ä¸ªç³»ç»Ÿä¸å¦ä¸€ä¸ªç³»ç»Ÿåœ¨è´£ä»»ã€æ—¶é—´ã€å¸¦å®½ã€å†…éƒ¨å·¥ä½œã€è´Ÿè½½å’Œåœ°ç†ä½ç½®æ–¹é¢éƒ½æ˜¯è§£è€¦çš„ã€‚è§£è€¦æ˜¯ä»»ä½•åˆ†å¸ƒå¼æˆ–å¤æ‚ç³»ç»Ÿä¸­éå¸¸ç†æƒ³çš„éƒ¨åˆ†â€”â€”ç³»ç»Ÿçš„å„ä¸ªéƒ¨åˆ†è§£è€¦å¾—è¶Šå¤šï¼Œå°±è¶Šå®¹æ˜“ç‹¬ç«‹åœ°æ„å»ºã€æµ‹è¯•ã€è¿è¡Œã€ç»´æŠ¤å’Œæ‰©å±•å®ƒä»¬ã€‚
- en: Most systems interact with other outside or third-party systems as wellâ€”if we
    build a shopping site we might interact with a payment processor, and letâ€™s say
    we attempt to directly communicate with the payment processor on each user click.
    If our system is under heavy load, we're also subjecting the other system to the
    same load. And vice versaâ€”if our payment provider needs to send us millions of
    pieces of information about our past payment statuses, our system better be ready.
    The two systems are now *coupled*. The decisions and actions made by one system
    have a significant impact on the other, so the needs of both need to be taken
    into account while making every decision. Add enough other systems into the mix,
    like logistics or delivery systems, and we quickly have a paralysing mess that
    makes it difficult to decide anything at all. If one system goes down, the other
    systems have effectively gone down as well, for no fault of their own.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°ç³»ç»Ÿè¿˜ä¸å…¶ä»–å¤–éƒ¨æˆ–ç¬¬ä¸‰æ–¹ç³»ç»Ÿè¿›è¡Œäº¤äº’â€”â€”å¦‚æœæˆ‘ä»¬å»ºç«‹ä¸€ä¸ªè´­ç‰©ç½‘ç«™ï¼Œæˆ‘ä»¬å¯èƒ½ä¼šä¸æ”¯ä»˜å¤„ç†å™¨è¿›è¡Œäº¤äº’ï¼Œå‡è®¾æˆ‘ä»¬å°è¯•åœ¨æ¯æ¬¡ç”¨æˆ·ç‚¹å‡»æ—¶ç›´æ¥ä¸æ”¯ä»˜å¤„ç†å™¨è¿›è¡Œé€šä¿¡ã€‚å¦‚æœæˆ‘ä»¬çš„ç³»ç»Ÿè´Ÿè½½è¿‡é‡ï¼Œæˆ‘ä»¬ä¹Ÿä¼šè®©å…¶ä»–ç³»ç»Ÿæ‰¿å—ç›¸åŒçš„è´Ÿè½½ã€‚åä¹‹äº¦ç„¶â€”â€”å¦‚æœæˆ‘ä»¬çš„æ”¯ä»˜æä¾›å•†éœ€è¦å‘æˆ‘ä»¬å‘é€æ•°ç™¾ä¸‡æ¡å…³äºè¿‡å»æ”¯ä»˜çŠ¶æ€çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬çš„ç³»ç»Ÿæœ€å¥½å‡†å¤‡å¥½äº†ã€‚è¿™ä¸¤ä¸ªç³»ç»Ÿç°åœ¨æ˜¯*è€¦åˆ*çš„ã€‚ä¸€ä¸ªç³»ç»Ÿçš„å†³ç­–å’Œè¡ŒåŠ¨å¯¹å¦ä¸€ä¸ªç³»ç»Ÿæœ‰ç€é‡å¤§å½±å“ï¼Œå› æ­¤åœ¨åšå‡ºæ¯ä¸ªå†³å®šæ—¶éƒ½éœ€è¦è€ƒè™‘åˆ°åŒæ–¹çš„éœ€æ±‚ã€‚å¦‚æœå°†è¶³å¤Ÿå¤šçš„å…¶ä»–ç³»ç»ŸåŠ å…¥åˆ°æ··åˆä¸­ï¼Œæ¯”å¦‚ç‰©æµæˆ–äº¤ä»˜ç³»ç»Ÿï¼Œæˆ‘ä»¬å¾ˆå¿«å°±ä¼šé™·å…¥ä¸€ä¸ªè®©äººéš¾ä»¥å†³ç­–çš„æ··ä¹±å±€é¢ã€‚å¦‚æœä¸€ä¸ªç³»ç»Ÿå´©æºƒäº†ï¼Œå…¶ä»–ç³»ç»Ÿä¹Ÿä¼šæ— æ•…å´©æºƒã€‚
- en: Weâ€™re also in trouble if we want to switch out any one of these systems for
    another one, like a new payment processor or delivery system. Weâ€™d have to make
    deep changes in multiple places in our application, and itâ€™s even more difficult
    to build code to split our messages between multiple providersâ€”we may want to
    use a ratio to load balance them or split them by geography; or dynamically switch
    between them based on each providerâ€™s availability or cost.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬æƒ³è¦å°†å…¶ä¸­ä»»ä½•ä¸€ä¸ªç³»ç»Ÿæ›¿æ¢ä¸ºå¦ä¸€ä¸ªç³»ç»Ÿï¼Œæ¯”å¦‚ä¸€ä¸ªæ–°çš„æ”¯ä»˜å¤„ç†å™¨æˆ–äº¤ä»˜ç³»ç»Ÿï¼Œæˆ‘ä»¬å°±ä¼šé‡åˆ°éº»çƒ¦ã€‚æˆ‘ä»¬å°†ä¸å¾—ä¸åœ¨æˆ‘ä»¬çš„åº”ç”¨ç¨‹åºçš„å¤šä¸ªåœ°æ–¹è¿›è¡Œæ·±å±‚æ¬¡çš„æ›´æ”¹ï¼Œè€Œä¸”åœ¨æ„å»ºä»£ç ä»¥åœ¨å¤šä¸ªæä¾›å•†ä¹‹é—´åˆ†å‰²æˆ‘ä»¬çš„æ¶ˆæ¯æ—¶æ›´åŠ å›°éš¾â€”â€”æˆ‘ä»¬å¯èƒ½æƒ³è¦ä½¿ç”¨æ¯”ä¾‹æ¥å¹³è¡¡è´Ÿè½½ï¼Œæˆ–è€…æ ¹æ®æ¯ä¸ªæä¾›å•†çš„å¯ç”¨æ€§æˆ–æˆæœ¬åŠ¨æ€åœ°åœ¨å®ƒä»¬ä¹‹é—´è¿›è¡Œåˆ‡æ¢ã€‚
- en: Message queues offer the decoupling that solves a lot of these problems. If
    we set up a queue between two systems that need to communicate with each other,
    they can now go about their work without having to worry about each other at allâ€”we
    put our messages aimed at any system into a queue, and we expect information from
    the other system to come to us through another queue as well. We now have clear
    points at which we can add rules or make the changes we require, without either
    system knowing or caring about what's different.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯é˜Ÿåˆ—æä¾›äº†è§£è€¦çš„è§£å†³æ–¹æ¡ˆï¼Œè§£å†³äº†è®¸å¤šè¿™äº›é—®é¢˜ã€‚å¦‚æœæˆ‘ä»¬åœ¨éœ€è¦ç›¸äº’é€šä¿¡çš„ä¸¤ä¸ªç³»ç»Ÿä¹‹é—´è®¾ç½®ä¸€ä¸ªé˜Ÿåˆ—ï¼Œå®ƒä»¬ç°åœ¨å¯ä»¥åœ¨å®Œå…¨ä¸å¿…æ‹…å¿ƒå½¼æ­¤çš„æƒ…å†µä¸‹è¿›è¡Œå·¥ä½œâ€”â€”æˆ‘ä»¬å°†é’ˆå¯¹ä»»ä½•ç³»ç»Ÿçš„æ¶ˆæ¯æ”¾å…¥ä¸€ä¸ªé˜Ÿåˆ—ä¸­ï¼Œæˆ‘ä»¬ä¹ŸæœŸæœ›ä»å¦ä¸€ä¸ªé˜Ÿåˆ—ä¸­å¾—åˆ°æ¥è‡ªå¦ä¸€ä¸ªç³»ç»Ÿçš„ä¿¡æ¯ã€‚ç°åœ¨æˆ‘ä»¬æœ‰äº†æ˜ç¡®çš„ç‚¹ï¼Œåœ¨è¿™äº›ç‚¹ä¸Šæˆ‘ä»¬å¯ä»¥æ·»åŠ è§„åˆ™æˆ–è¿›è¡Œæˆ‘ä»¬éœ€è¦çš„æ›´æ”¹ï¼Œè€Œä¸éœ€è¦ä»»ä½•ä¸€ä¸ªç³»ç»ŸçŸ¥é“æˆ–å…³å¿ƒæœ‰ä»€ä¹ˆä¸åŒã€‚
- en: So what's the catch?
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: é‚£ä¹ˆé—®é¢˜æ¥äº†ï¼Œæœ‰ä»€ä¹ˆé™åˆ¶å—ï¼Ÿ
- en: Are message queues the holy grail of computing, though? Do they solve all the
    world's problems? No, of course not. There are plenty of situations where we might
    not want to use them. And we certainly don't want to use a queue just because
    we have one easily available and think it might be fun. There are some systems
    that are really simple that just don't require itâ€”a message queue is a way to
    reduce complexity of communicating systems, but two communicating systems will
    always be more complex than one system that doesn't have to communicate. If you
    have a system thatâ€™s simple enough to not require communication with any others,
    there simply isn't any reason to reach for a queue.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯é˜Ÿåˆ—æ˜¯è®¡ç®—çš„åœ£æ¯å—ï¼Ÿå®ƒä»¬è§£å†³äº†æ‰€æœ‰ä¸–ç•Œçš„é—®é¢˜å—ï¼Ÿå½“ç„¶ä¸æ˜¯ã€‚æœ‰å¾ˆå¤šæƒ…å†µä¸‹æˆ‘ä»¬å¯èƒ½ä¸æƒ³ä½¿ç”¨å®ƒä»¬ã€‚æˆ‘ä»¬å½“ç„¶ä¹Ÿä¸å¸Œæœ›ä»…ä»…å› ä¸ºæœ‰ä¸€ä¸ªæ˜“äºä½¿ç”¨çš„é˜Ÿåˆ—å¹¶ä¸”è®¤ä¸ºä½¿ç”¨å®ƒå¯èƒ½å¾ˆæœ‰è¶£è€Œä½¿ç”¨é˜Ÿåˆ—ã€‚æœ‰ä¸€äº›ç³»ç»Ÿéå¸¸ç®€å•ï¼Œæ ¹æœ¬ä¸éœ€è¦å®ƒâ€”â€”æ¶ˆæ¯é˜Ÿåˆ—æ˜¯å‡å°‘é€šä¿¡ç³»ç»Ÿå¤æ‚æ€§çš„ä¸€ç§æ–¹æ³•ï¼Œä½†æ˜¯ä¸¤ä¸ªé€šä¿¡ç³»ç»Ÿæ€»æ˜¯æ¯”ä¸€ä¸ªä¸éœ€è¦é€šä¿¡çš„ç³»ç»Ÿæ›´å¤æ‚ã€‚å¦‚æœæ‚¨æœ‰ä¸€ä¸ªç®€å•åˆ°ä¸éœ€è¦ä¸ä»»ä½•å…¶ä»–ç³»ç»Ÿé€šä¿¡çš„ç³»ç»Ÿï¼Œé‚£ä¹ˆæ ¹æœ¬æ²¡æœ‰ç†ç”±å»ä½¿ç”¨é˜Ÿåˆ—ã€‚
- en: There are also systems that communicate with each other, but where the complexity
    added by that communication added is insignificant and not worth worrying about.
    Or more often the systems are already coupled, in the sense that they all need
    to work together to function. A really common example is an application server
    and a data service (in an *OLTP* system). There's not much point in decoupling
    them with a queue, because neither can do anything useful without the direct involvement
    of the other.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: è¿˜æœ‰ä¸€äº›ç³»ç»Ÿå½¼æ­¤é€šä¿¡ï¼Œä½†é€šä¿¡å¢åŠ çš„å¤æ‚æ€§å¾®ä¸è¶³é“ï¼Œä¸å€¼å¾—æ‹…å¿ƒã€‚æˆ–è€…æ›´å¸¸è§çš„æƒ…å†µæ˜¯ç³»ç»Ÿå·²ç»è€¦åˆåœ¨ä¸€èµ·ï¼Œä»åŠŸèƒ½ä¸Šæ¥è¯´å®ƒä»¬éƒ½éœ€è¦ä¸€èµ·å·¥ä½œã€‚ä¸€ä¸ªéå¸¸å¸¸è§çš„ä¾‹å­æ˜¯åº”ç”¨ç¨‹åºæœåŠ¡å™¨å’Œæ•°æ®æœåŠ¡ï¼ˆåœ¨*OLTP*ç³»ç»Ÿä¸­ï¼‰ã€‚ä½¿ç”¨é˜Ÿåˆ—è§£è€¦å®ƒä»¬å¹¶æ²¡æœ‰å¤šå¤§æ„ä¹‰ï¼Œå› ä¸ºæ²¡æœ‰ä¸€ä¸ªå¯ä»¥åœ¨æ²¡æœ‰ç›´æ¥å‚ä¸å¦ä¸€ä¸ªçš„æƒ…å†µä¸‹æ‰§è¡Œä»»ä½•æœ‰ç”¨çš„æ“ä½œã€‚
- en: Then there's performance to consider as wellâ€”the whole point of decoupling two
    systems with regards to time and load is so that they can each process information
    at their own paceâ€”but we certainly would *not* want this to happen in performance
    sensitive applications or real-time systems. A queue might help us process more
    work at the same time (the receiver might have many processes working in parallel
    on the messages you send) but will remove any guarantees we need about the exact
    time taken for each piece of work. If predictability is more important than throughput,
    we're better off without a queue.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ç„¶åè¿˜è¦è€ƒè™‘æ€§èƒ½â€”â€”è§£è€¦ä¸¤ä¸ªç³»ç»Ÿçš„æ•´ä¸ªç›®çš„æ˜¯ä½¿å®ƒä»¬å¯ä»¥æŒ‰ç…§è‡ªå·±çš„èŠ‚å¥å¤„ç†ä¿¡æ¯ï¼Œä½†æ˜¯æˆ‘ä»¬è‚¯å®šä¸å¸Œæœ›è¿™ç§æƒ…å†µå‘ç”Ÿåœ¨å¯¹æ€§èƒ½æ•æ„Ÿçš„åº”ç”¨ç¨‹åºæˆ–å®æ—¶ç³»ç»Ÿä¸­ã€‚é˜Ÿåˆ—å¯èƒ½ä¼šå¸®åŠ©æˆ‘ä»¬åŒæ—¶å¤„ç†æ›´å¤šçš„å·¥ä½œï¼ˆæ¥æ”¶è€…å¯èƒ½æœ‰è®¸å¤šè¿›ç¨‹å¹¶è¡Œå¤„ç†æ‚¨å‘é€çš„æ¶ˆæ¯ï¼‰ï¼Œä½†ä¼šæ¶ˆé™¤æˆ‘ä»¬å¯¹æ¯ä¸ªå·¥ä½œæ—¶é—´çš„å‡†ç¡®æ€§æ‰€éœ€çš„ä»»ä½•ä¿è¯ã€‚å¦‚æœå¯é¢„æµ‹æ€§æ¯”ååé‡æ›´é‡è¦ï¼Œæˆ‘ä»¬æœ€å¥½ä¸è¦ä½¿ç”¨é˜Ÿåˆ—ã€‚
- en: Using a queue might increase the time taken to process each *individual* message,
    but will allow you process many more messages at the same time across different
    computersâ€”so your total number of messages processed per minute or hour, or *throughput*,
    will increase.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: ä½¿ç”¨é˜Ÿåˆ—å¯èƒ½ä¼šå¢åŠ å¤„ç†æ¯ä¸ª*å•ç‹¬*æ¶ˆæ¯æ‰€éœ€çš„æ—¶é—´ï¼Œä½†ä¼šå…è®¸æ‚¨åŒæ—¶åœ¨ä¸åŒè®¡ç®—æœºä¸Šå¤„ç†æ›´å¤šçš„æ¶ˆæ¯â€”â€”å› æ­¤æ‚¨æ¯åˆ†é’Ÿæˆ–æ¯å°æ—¶å¤„ç†çš„æ¶ˆæ¯æ€»æ•°ï¼Œæˆ–*ååé‡*ï¼Œå°†å¢åŠ ã€‚
- en: If we do have multiple systems that need to communicate, and that communication
    needs to be *durable* (if weâ€™ve put a message into a queue, we want to be sure
    that the messaging system isnâ€™t going to â€˜forgetâ€™ about it) and decoupled, a message
    queue is indispensable.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæˆ‘ä»¬æœ‰å¤šä¸ªéœ€è¦é€šä¿¡çš„ç³»ç»Ÿï¼Œå¹¶ä¸”é€šä¿¡éœ€è¦æ˜¯*æŒä¹…*çš„ï¼ˆå¦‚æœæˆ‘ä»¬æŠŠæ¶ˆæ¯æ”¾å…¥é˜Ÿåˆ—ï¼Œæˆ‘ä»¬å¸Œæœ›æ¶ˆæ¯ç³»ç»Ÿä¸ä¼šâ€˜å¿˜è®°â€™å®ƒï¼‰ï¼Œå¹¶ä¸”è§£è€¦ï¼Œé‚£ä¹ˆæ¶ˆæ¯é˜Ÿåˆ—æ˜¯ä¸å¯æˆ–ç¼ºçš„ã€‚
- en: Arguing Semantics
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: è¾©è®ºè¯­ä¹‰
- en: 'There''s simply no way to learn about message queues without reading and/or
    arguing about delivery guarantees and semantics, so we might as well get to that
    quickly. People who build message queues will claim that their system offers one
    of three delivery guaranteesâ€”that each message you put into the queue will be
    delivered:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: æ²¡æœ‰åŠæ³•å­¦ä¹ æœ‰å…³æ¶ˆæ¯é˜Ÿåˆ—è€Œä¸é˜…è¯»å’Œ/æˆ–è¾©è®ºäº¤ä»˜ä¿è¯å’Œè¯­ä¹‰ï¼Œæ‰€ä»¥æˆ‘ä»¬æœ€å¥½å¿«ç‚¹åšè¿™ä¸ªã€‚æ„å»ºæ¶ˆæ¯é˜Ÿåˆ—çš„äººä¼šå£°ç§°ä»–ä»¬çš„ç³»ç»Ÿæä¾›äº†ä¸‰ç§äº¤ä»˜ä¿è¯ä¹‹ä¸€ï¼šä½ æ”¾å…¥é˜Ÿåˆ—çš„æ¯æ¡æ¶ˆæ¯éƒ½ä¼šè¢«ä¼ é€’ï¼š
- en: '*at-least* once.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*è‡³å°‘*ä¸€æ¬¡ã€‚'
- en: '*at-most* once.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*æœ€å¤š*ä¸€æ¬¡ã€‚'
- en: '*exactly* once.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ç¡®åˆ‡*ä¸€æ¬¡ã€‚'
- en: Which guarantees we're using will have a massive impact on the design and working
    of our system, so let's unpack each of them one by one.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: æˆ‘ä»¬ä½¿ç”¨çš„ä¿è¯å°†å¯¹æˆ‘ä»¬ç³»ç»Ÿçš„è®¾è®¡å’Œå·¥ä½œäº§ç”Ÿå·¨å¤§å½±å“ï¼Œå› æ­¤è®©æˆ‘ä»¬é€ä¸€æ‹†åˆ†å®ƒä»¬ã€‚
- en: At-Least Once
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è‡³å°‘ä¸€æ¬¡
- en: This is the most common delivery mechanism, and it's the simplest to reason
    about and implement. If I have a message for you, I will read it to you, and keep
    doing so again and again until you acknowledge it. That's it. In a system which
    works on an at-least-once basis, this means that when you receive a message from
    the queue and don't delete/acknowledge it, you will receive it again in the future,
    and will keep receiving it until you explicitly delete/acknowledge it.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æœ€å¸¸è§çš„ä¼ é€’æœºåˆ¶ï¼Œä¹Ÿæ˜¯æœ€å®¹æ˜“ç†è§£å’Œå®ç°çš„ã€‚å¦‚æœæˆ‘æœ‰ä¸€æ¡æ¶ˆæ¯è¦ä¼ é€’ç»™ä½ ï¼Œæˆ‘ä¼šè¯»ç»™ä½ å¬ï¼Œä¸€éåˆä¸€éï¼Œç›´åˆ°ä½ ç¡®è®¤æ¥æ”¶åˆ°ä¸ºæ­¢ã€‚å°±æ˜¯è¿™æ ·ã€‚åœ¨ä¸€ä¸ªè‡³å°‘ä¸€æ¬¡çš„åŸºç¡€ä¸Šå·¥ä½œçš„ç³»ç»Ÿä¸­ï¼Œè¿™æ„å‘³ç€å½“ä½ ä»é˜Ÿåˆ—æ¥æ”¶åˆ°ä¸€æ¡æ¶ˆæ¯å¹¶ä¸”æ²¡æœ‰åˆ é™¤/ç¡®è®¤å®ƒæ—¶ï¼Œä½ å°†åœ¨æœªæ¥å†æ¬¡æ”¶åˆ°å®ƒï¼Œå¹¶ä¸”ä¼šä¸€ç›´æ”¶åˆ°ç›´åˆ°ä½ æ˜ç¡®åˆ é™¤/ç¡®è®¤å®ƒã€‚
- en: The reason this is the most common guarantee is that it's simple and gets the
    job done 100% of the timeâ€”there's no edge case in which the message gets lost.
    Even if the receiver crashes before acknowledging the message, it will simply
    receive the same message again. The flip side is that you as the receiver need
    to plan on receiving the same message multiple timesâ€”even if you haven't necessarily
    experienced a crash. This is because offering at-least-once is the simplest way
    to protect the queueing service from missing out messages as wellâ€”if your acknowledgement
    doesn't reach the queueing system over the network, the message will be sent again.
    If there's a problem persisting your acknowledgement, the message will be sent
    again. If the queuing system restarts before it can properly keep track of what's
    been sent to you, the message will be sent again. This simple remedy of sending
    the message again in case of any problem on any side is what makes this guarantee
    so reliable.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ä¹‹æ‰€ä»¥è¿™æ˜¯æœ€å¸¸è§çš„ä¿è¯ï¼Œæ˜¯å› ä¸ºå®ƒç®€å•ä¸”ç™¾åˆ†ä¹‹ç™¾å®Œæˆå·¥ä½œâ€”â€”æ²¡æœ‰æ¶ˆæ¯ä¸¢å¤±çš„è¾¹ç¼˜æƒ…å†µã€‚å³ä½¿æ¥æ”¶è€…åœ¨ç¡®è®¤æ¶ˆæ¯ä¹‹å‰å´©æºƒï¼Œå®ƒä¹Ÿä¼šç®€å•åœ°å†æ¬¡æ¥æ”¶ç›¸åŒçš„æ¶ˆæ¯ã€‚å¦ä¸€æ–¹é¢ï¼Œä½œä¸ºæ¥æ”¶è€…çš„ä½ éœ€è¦å‡†å¤‡å¤šæ¬¡æ¥æ”¶ç›¸åŒçš„æ¶ˆæ¯â€”â€”å³ä½¿ä½ å¹¶æ²¡æœ‰å¿…è¦ç»å†å´©æºƒã€‚è¿™æ˜¯å› ä¸ºæä¾›è‡³å°‘ä¸€æ¬¡æ˜¯ä¿æŠ¤é˜Ÿåˆ—æœåŠ¡ä¸ä¼šé”™è¿‡æ¶ˆæ¯çš„æœ€ç®€å•æ–¹å¼â€”â€”å¦‚æœä½ çš„ç¡®è®¤æœªèƒ½é€šè¿‡ç½‘ç»œåˆ°è¾¾é˜Ÿåˆ—ç³»ç»Ÿï¼Œé‚£ä¹ˆæ¶ˆæ¯å°†è¢«å†æ¬¡å‘é€ã€‚å¦‚æœå­˜åœ¨æŒç»­å­˜å‚¨ä½ çš„ç¡®è®¤çš„é—®é¢˜ï¼Œæ¶ˆæ¯å°†è¢«å†æ¬¡å‘é€ã€‚å¦‚æœé˜Ÿåˆ—ç³»ç»Ÿåœ¨æ­£ç¡®è·Ÿè¸ªå‘é€ç»™ä½ çš„å†…å®¹ä¹‹å‰é‡æ–°å¯åŠ¨ï¼Œæ¶ˆæ¯å°†è¢«å†æ¬¡å‘é€ã€‚åœ¨ä»»ä½•ä¸€æ–¹å‡ºç°é—®é¢˜æ—¶ï¼Œç®€å•çš„å†æ¬¡å‘é€æ¶ˆæ¯çš„æ–¹æ³•æ˜¯ä½¿å¾—æ­¤ä¿è¯å¦‚æ­¤å¯é çš„åŸå› ã€‚
- en: But is message duplication/repetition a problem? That's really up to you and
    your application or use-case. If the message is a timestamp and a measurement,
    for example, there's no problem with receiving a million duplicates. But if you're
    moving money based on the messages, it definitely is a problem. In these cases
    you'll need to have a transactional (ACID) database at the receiving end, and
    maybe record the message ID in a unique index so that it can't be repeated. This
    is called using an *idempotency token* or _tombstoneâ€”_when you act on a message
    you store a unique permanent marker to keep track of your actions, often in the
    same database transaction as taking the action itself. The prevents you from repeating
    that action again even if the message is duplicated.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ä½†æ˜¯æ¶ˆæ¯çš„é‡å¤/é‡å¤æ˜¯ä¸€ä¸ªé—®é¢˜å—ï¼Ÿè¿™çœŸçš„å–å†³äºä½ å’Œä½ çš„åº”ç”¨ç¨‹åºæˆ–ç”¨ä¾‹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ¶ˆæ¯æ˜¯ä¸€ä¸ªæ—¶é—´æˆ³å’Œä¸€ä¸ªæµ‹é‡å€¼ï¼Œé‚£ä¹ˆæ¥æ”¶åˆ°ä¸€ç™¾ä¸‡ä¸ªå‰¯æœ¬æ˜¯æ²¡æœ‰é—®é¢˜çš„ã€‚ä½†æ˜¯å¦‚æœä½ æ˜¯æ ¹æ®æ¶ˆæ¯æ¥è½¬ç§»èµ„é‡‘ï¼Œé‚£è‚¯å®šæ˜¯ä¸ªé—®é¢˜ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œä½ å°†éœ€è¦åœ¨æ¥æ”¶ç«¯ä½¿ç”¨äº‹åŠ¡æ€§ï¼ˆACIDï¼‰æ•°æ®åº“ï¼Œå¹¶ä¸”å¯èƒ½ä¼šå°†æ¶ˆæ¯IDè®°å½•åœ¨å”¯ä¸€ç´¢å¼•ä¸­ï¼Œä»¥ä¾¿å®ƒä¸èƒ½é‡å¤ã€‚è¿™å°±æ˜¯ä½¿ç”¨*å¹‚ç­‰ä»¤ç‰Œ*æˆ–_å¢“ç¢‘_â€”â€”å½“ä½ å¯¹æ¶ˆæ¯è¿›è¡Œæ“ä½œæ—¶ï¼Œä½ ä¼šå­˜å‚¨ä¸€ä¸ªå”¯ä¸€çš„æ°¸ä¹…æ ‡è®°æ¥è·Ÿè¸ªä½ çš„æ“ä½œï¼Œé€šå¸¸ä¸æ‰§è¡Œæ“ä½œæœ¬èº«åœ¨åŒä¸€ä¸ªæ•°æ®åº“äº‹åŠ¡ä¸­ã€‚å³ä½¿æ¶ˆæ¯é‡å¤ï¼Œä¹Ÿä¼šé˜»æ­¢ä½ å†æ¬¡æ‰§è¡Œè¯¥æ“ä½œã€‚
- en: If you handle duplication, or if your messages are naturally resistant to duplication,
    your systems are said to be *idempotent*. This means you can safely handle receiving
    the same message multiple times, without corrupting your work. It also often means
    you can tolerate the sender sending the same message multiple timesâ€”remember that
    senders will usually operate on the at-least-once principle when sending messages
    as well. If senders are unable to record the fact that they've sent a particular
    message, they'll simply send it again. The senders are then responsible for making
    sure that they use the same tombstone or idempotency token if and when they re-send
    messages.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ å¤„ç†äº†é‡å¤ï¼Œæˆ–è€…ä½ çš„æ¶ˆæ¯è‡ªç„¶æŠµåˆ¶é‡å¤ï¼Œé‚£ä¹ˆä½ çš„ç³»ç»Ÿå°±è¢«ç§°ä¸º*å¹‚ç­‰*ã€‚è¿™æ„å‘³ç€ä½ å¯ä»¥å®‰å…¨åœ°å¤„ç†å¤šæ¬¡æ¥æ”¶ç›¸åŒçš„æ¶ˆæ¯ï¼Œè€Œä¸ä¼šç ´åä½ çš„å·¥ä½œã€‚è¿™é€šå¸¸ä¹Ÿæ„å‘³ç€ä½ å¯ä»¥å®¹å¿å‘é€è€…å¤šæ¬¡å‘é€ç›¸åŒçš„æ¶ˆæ¯â€”â€”è¯·è®°ä½ï¼Œå‘é€è€…å‘é€æ¶ˆæ¯æ—¶é€šå¸¸ä¹Ÿä¼šéµå¾ªè‡³å°‘ä¸€æ¬¡çš„åŸåˆ™ã€‚å¦‚æœå‘é€è€…æ— æ³•è®°å½•ä»–ä»¬å·²ç»å‘é€äº†ç‰¹å®šçš„æ¶ˆæ¯ï¼Œä»–ä»¬å°†ç®€å•åœ°é‡æ–°å‘é€ã€‚ç„¶åå‘é€è€…è´Ÿè´£ç¡®ä¿ä»–ä»¬åœ¨é‡æ–°å‘é€æ¶ˆæ¯æ—¶ä½¿ç”¨ç›¸åŒçš„å¢“ç¢‘æˆ–å¹‚ç­‰ä»¤ç‰Œã€‚
- en: At Most Once
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æœ€å¤šä¸€æ¬¡
- en: This is a pretty rare semantic, used for messages where duplication is so horribly
    explosive (or the message so utterly unimportant) that we'd prefer not to send
    the message at all, rather than send it twice. At-most-once once implies that
    the queuing system will attempt to deliver the message to you once, but that's
    it. If you receive and acknowledge the message all is well, but if you don't,
    or anything goes wrong, that message will be lost foreverâ€”either because the queuing
    system has taken great pains to record the delivery to you before attempting to
    send it (in case the message is horribly explosive), or has not even bothered
    to record the message at all, and is just passing it on like a router passes on
    a UDP packet.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ä¸€ç§éå¸¸ç½•è§çš„è¯­ä¹‰ï¼Œç”¨äºé‚£äº›é‡å¤æ€§éå¸¸ç³Ÿç³•ï¼ˆæˆ–æ¶ˆæ¯éå¸¸ä¸é‡è¦ï¼‰çš„æ¶ˆæ¯ï¼Œæˆ‘ä»¬å®æ„¿ä¸å‘é€æ¶ˆæ¯ï¼Œè€Œä¸æ˜¯å‘é€ä¸¤æ¬¡ã€‚è‡³å¤šä¸€æ¬¡æ„å‘³ç€æ’é˜Ÿç³»ç»Ÿå°†å°è¯•å°†æ¶ˆæ¯ä¼ é€’ç»™æ‚¨ä¸€æ¬¡ï¼Œä½†ä»…æ­¤è€Œå·²ã€‚å¦‚æœæ‚¨æ”¶åˆ°å¹¶ç¡®è®¤äº†æ¶ˆæ¯ï¼Œåˆ™ä¸€åˆ‡éƒ½å¾ˆå¥½ï¼Œä½†å¦‚æœæ‚¨æ²¡æœ‰æ”¶åˆ°ï¼Œæˆ–è€…å‡ºç°ä»»ä½•é—®é¢˜ï¼Œè¯¥æ¶ˆæ¯å°†æ°¸è¿œä¸¢å¤±â€”â€”è¦ä¹ˆæ˜¯å› ä¸ºæ’é˜Ÿç³»ç»Ÿåœ¨å°è¯•å‘é€æ¶ˆæ¯ä¹‹å‰è´¹å°½å¿ƒæ€è®°å½•äº†ä¼ é€’ç»™æ‚¨çš„æƒ…å†µï¼ˆä»¥é˜²æ¶ˆæ¯çˆ†ç‚¸ï¼‰ï¼Œè¦ä¹ˆæ ¹æœ¬æ²¡æœ‰è®°å½•æ¶ˆæ¯ï¼Œè€Œåªæ˜¯åƒè·¯ç”±å™¨ä¼ é€’UDPæ•°æ®åŒ…ä¸€æ ·ä¼ é€’æ¶ˆæ¯ã€‚
- en: This semantic usually comes into play for messaging systems that are either
    acting as stateless information routers; or in those cases where a repeat message
    is so destructive that an investigation or reconciliation is necessary in case
    there's any failure.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ç§è¯­ä¹‰é€šå¸¸é€‚ç”¨äºé‚£äº›ä½œä¸ºæ— çŠ¶æ€ä¿¡æ¯è·¯ç”±å™¨çš„æ¶ˆæ¯ç³»ç»Ÿï¼›æˆ–è€…åœ¨é‡å¤æ¶ˆæ¯å¦‚æ­¤ç ´åæ€§åœ°æ—¶å¿…é¡»è¿›è¡Œè°ƒæŸ¥æˆ–åè°ƒçš„æƒ…å†µä¸‹ã€‚
- en: Exactly Once
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ç²¾ç¡®ä¸€æ¬¡
- en: This is the holy grail of messaging, and also the fountain of a lot of snake-oil.
    It implies that every message is guaranteed to be delivered and processed exactly
    once, no more and no less. Everyone who builds or uses distributed systems has
    a point in their lives where they think â€œhow hard can this be?â€, and then they
    either (1) learn why it's impossible, figure out idempotency, and use at-least-once,
    or (2) they try to build a half-assed â€œexactly-onceâ€ system and sell it for lots
    of money to those who haven't figured out (1) yet.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯æ¶ˆæ¯ä¼ é€’çš„åœ£æ¯ï¼Œä¹Ÿæ˜¯è®¸å¤šä¼ªç§‘å­¦çš„æºæ³‰ã€‚è¿™æ„å‘³ç€æ¯æ¡æ¶ˆæ¯éƒ½ä¿è¯å‡†ç¡®åœ°ä¼ é€’å’Œå¤„ç†ä¸€æ¬¡ï¼Œä¸å¤šä¸å°‘ã€‚æ¯ä¸ªæ„å»ºæˆ–ä½¿ç”¨åˆ†å¸ƒå¼ç³»ç»Ÿçš„äººç”Ÿéƒ½æœ‰ä¸€ä¸ªæ—¶åˆ»ï¼Œä»–ä»¬ä¼šæƒ³â€œè¿™æœ‰å¤šéš¾ï¼Ÿâ€ï¼Œç„¶åä»–ä»¬è¦ä¹ˆï¼ˆ1ï¼‰å­¦ä¼šä¸ºä»€ä¹ˆè¿™æ˜¯ä¸å¯èƒ½çš„ï¼Œæ‰¾å‡ºå¹‚ç­‰æ€§ï¼Œå¹¶ä½¿ç”¨è‡³å°‘ä¸€æ¬¡ï¼Œè¦ä¹ˆï¼ˆ2ï¼‰ä»–ä»¬è¯•å›¾æ„å»ºä¸€ä¸ªåŠåŠå­çš„â€œç²¾ç¡®ä¸€æ¬¡â€ç³»ç»Ÿï¼Œå¹¶å°†å…¶å–ç»™é‚£äº›è¿˜æ²¡æœ‰å¼„æ¸…æ¥šï¼ˆ1ï¼‰çš„äººã€‚
- en: 'The impossibility of exactly-once delivery arises from two basic facts:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: ç²¾ç¡®ä¸€æ¬¡ä¼ é€’çš„ä¸å¯èƒ½æ€§æºäºä¸¤ä¸ªåŸºæœ¬äº‹å®ï¼š
- en: senders and receivers are imperfect
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‘é€æ–¹å’Œæ¥æ”¶æ–¹éƒ½æ˜¯ä¸å®Œç¾çš„
- en: networks are imperfect
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ç½‘ç»œæ˜¯ä¸å®Œç¾çš„
- en: 'If you think about the problem deeply, there are a lot of things that can go
    wrong:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‚¨æ·±æ€ç†Ÿè™‘è¿™ä¸ªé—®é¢˜ï¼Œæœ‰å¾ˆå¤šäº‹æƒ…å¯èƒ½ä¼šå‡ºé”™ï¼š
- en: a sender might be unable to record (they *forget*) that they've sent the message
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‘é€æ–¹å¯èƒ½æ— æ³•è®°å½•ï¼ˆä»–ä»¬*å¿˜è®°*ï¼‰å·²å‘é€æ¶ˆæ¯
- en: the network call to send the message might fail
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‘é€æ¶ˆæ¯çš„ç½‘ç»œè°ƒç”¨å¯èƒ½ä¼šå¤±è´¥
- en: the messaging systemâ€™s database might not be able to record the message
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯ç³»ç»Ÿçš„æ•°æ®åº“å¯èƒ½æ— æ³•è®°å½•æ¶ˆæ¯
- en: the acknowledgement that the messaging system has recorded the message might
    not reach the sender over the network
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯ç³»ç»Ÿè®°å½•æ¶ˆæ¯çš„ç¡®è®¤å¯èƒ½æ— æ³•é€šè¿‡ç½‘ç»œåˆ°è¾¾å‘é€æ–¹
- en: the sender might not be able to record the acknowledgement that the messaging
    system has received the message
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å‘é€æ–¹å¯èƒ½æ— æ³•è®°å½•æ¶ˆæ¯ç³»ç»Ÿå·²æ¥æ”¶åˆ°æ¶ˆæ¯çš„ç¡®è®¤ã€‚
- en: 'Let''s say all goes well while sending the messageâ€”when the messaging system
    tries to deliver the message to the receiver:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: å‡è®¾åœ¨å‘é€æ¶ˆæ¯æ—¶ä¸€åˆ‡é¡ºåˆ©â€”â€”å½“æ¶ˆæ¯ç³»ç»Ÿå°è¯•å°†æ¶ˆæ¯ä¼ é€’ç»™æ¥æ”¶è€…æ—¶ï¼š
- en: the message might not reach the receiver over the network
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯å¯èƒ½æ— æ³•é€šè¿‡ç½‘ç»œåˆ°è¾¾æ¥æ”¶æ–¹
- en: the receiver might not be able to record the message in its database
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¥æ”¶æ–¹å¯èƒ½æ— æ³•å°†æ¶ˆæ¯è®°å½•åœ¨å…¶æ•°æ®åº“ä¸­
- en: the acknowledgement from the receiver might not reach the messaging system over
    the network
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¥æ”¶è€…çš„ç¡®è®¤å¯èƒ½æ— æ³•é€šè¿‡ç½‘ç»œåˆ°è¾¾æ¶ˆæ¯ç³»ç»Ÿ
- en: the messaging systemâ€™s database might not be able to record that the message
    has been delivered
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯ç³»ç»Ÿçš„æ•°æ®åº“å¯èƒ½æ— æ³•è®°å½•æ¶ˆæ¯å·²è¢«ä¼ é€’
- en: Given all the things that can go wrong, it's impossible for any messaging system
    to guarantee exactly-once delivery. Even if the messaging system is godlike in
    its perfection, most of the things that can go wrong are outside of it or in the
    interconnecting networks. Some systems do attempt to use the phrase â€œexactly onceâ€
    anyway, usually because they claim their implementation will never have any of
    the messaging system problems mentioned aboveâ€”but that doesn't mean the whole
    system is magically blessed with exactly-once semantics, even if the claims are
    actually true. It usually means that the queuing system has some form of ordering,
    locking, hashing, timers and idempotency tokens that will ensure it never re-delivers
    a messsage that's already been deleted/acknowledgedâ€”but this doesn't mean that
    the whole system including publisher + queue + subscriber has gained full exactly-once
    guarantees.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: è€ƒè™‘åˆ°å¯èƒ½å‡ºç°çš„æ‰€æœ‰é—®é¢˜ï¼Œä»»ä½•æ¶ˆæ¯ç³»ç»Ÿéƒ½ä¸å¯èƒ½ä¿è¯ç²¾ç¡®ä¸€æ¬¡çš„äº¤ä»˜ã€‚å³ä½¿æ¶ˆæ¯ç³»ç»Ÿåœ¨å®Œç¾æ€§ä¸Šç±»ä¼¼ç¥ä¸€èˆ¬ï¼Œå¤§å¤šæ•°å¯èƒ½å‡ºç°é—®é¢˜çš„æƒ…å†µéƒ½åœ¨å…¶ä¹‹å¤–æˆ–åœ¨äº’è¿ç½‘ç»œä¸­ã€‚ä¸€äº›ç³»ç»Ÿç¡®å®å°è¯•ä½¿ç”¨â€œç²¾ç¡®ä¸€æ¬¡â€è¿™ä¸ªè¯ç»„ï¼Œé€šå¸¸æ˜¯å› ä¸ºå®ƒä»¬å£°ç§°å®ƒä»¬çš„å®ç°æ°¸è¿œä¸ä¼šå‡ºç°ä¸Šè¿°ä»»ä½•æ¶ˆæ¯ç³»ç»Ÿçš„é—®é¢˜â€”â€”ä½†è¿™å¹¶ä¸æ„å‘³ç€æ•´ä¸ªç³»ç»Ÿä¼šç¥å¥‡åœ°å…·æœ‰ç²¾ç¡®ä¸€æ¬¡çš„è¯­ä¹‰ï¼Œå³ä½¿è¿™äº›å£°æ˜å®é™…ä¸Šæ˜¯çœŸçš„ã€‚è¿™é€šå¸¸æ„å‘³ç€æ’é˜Ÿç³»ç»Ÿå…·æœ‰æŸç§å½¢å¼çš„æ’åºã€é”å®šã€æ•£åˆ—ã€å®šæ—¶å™¨å’Œå¹‚ç­‰ä»¤ç‰Œï¼Œå¯ä»¥ç¡®ä¿å®ƒæ°¸è¿œä¸ä¼šé‡æ–°äº¤ä»˜å·²ç»è¢«åˆ é™¤/ç¡®è®¤çš„æ¶ˆæ¯â€”â€”ä½†è¿™å¹¶ä¸æ„å‘³ç€æ•´ä¸ªç³»ç»Ÿï¼ŒåŒ…æ‹¬å‘å¸ƒè€…
    + é˜Ÿåˆ— + è®¢é˜…è€…ï¼Œéƒ½è·å¾—äº†å®Œå…¨çš„ç²¾ç¡®ä¸€æ¬¡ä¿è¯ã€‚
- en: 'Most good messaging system engineers understand this and will [explain](https://www.lightbend.com/blog/how-akka-works-exactly-once-message-delivery)
    to their users why this semantic is unworkable. The simpler and more reliable
    way to handle messages is go back to the basics and embrace at-least-once with
    idempotency measures at every point on the sending, receiving and queuing process:
    if at first you don''t succeed, retry, retry, retry...'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°ä¼˜ç§€çš„æ¶ˆæ¯ç³»ç»Ÿå·¥ç¨‹å¸ˆéƒ½æ˜ç™½è¿™ä¸€ç‚¹ï¼Œå¹¶ä¼šå‘ä»–ä»¬çš„ç”¨æˆ·[è§£é‡Š](https://www.lightbend.com/blog/how-akka-works-exactly-once-message-delivery)ä¸ºä»€ä¹ˆè¿™ç§è¯­ä¹‰æ˜¯è¡Œä¸é€šçš„ã€‚å¤„ç†æ¶ˆæ¯çš„æ›´ç®€å•ã€æ›´å¯é çš„æ–¹æ³•æ˜¯å›å½’åŸºç¡€ï¼Œå¹¶åœ¨å‘é€ã€æ¥æ”¶å’Œæ’é˜Ÿè¿‡ç¨‹çš„æ¯ä¸ªç¯èŠ‚é‡‡å–è‡³å°‘ä¸€æ¬¡çš„å¹‚ç­‰æ€§æªæ–½ï¼šå¦‚æœä¸€å¼€å§‹å¤±è´¥äº†ï¼Œé‡è¯•ï¼Œé‡è¯•ï¼Œé‡è¯•...
- en: Ordering vs Parallelism
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: é¡ºåº vs å¹¶è¡Œism
- en: After delivery semantics, another common question on peoplesâ€™ minds is â€œwhy
    canâ€™t we just process messages in parallel while also making sure we process them
    in order?â€. Unfortunately this is another tradeoff imposed on us by the tyranny
    of logic. Doing work in a sequence and doing multiple pieces of work at the same
    time are always at conflict with each other. Most message queue systems will ask
    you to pick oneâ€”AWS SQS started by prioritising parallelism over strict ordering;
    but recently introduced a separate FIFO (first in, first out) queuing system as
    well, which maintains strict sequential ordering. Before making a choice between
    the two, letâ€™s go over what the difference is and why there needs to be a difference
    at all.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨äº¤ä»˜è¯­ä¹‰ä¹‹åï¼Œäººä»¬å¿ƒä¸­å¦ä¸€ä¸ªå¸¸è§çš„é—®é¢˜æ˜¯â€œä¸ºä»€ä¹ˆæˆ‘ä»¬ä¸èƒ½åŒæ—¶å¹¶è¡Œå¤„ç†æ¶ˆæ¯ï¼ŒåŒæ—¶åˆç¡®ä¿æŒ‰é¡ºåºå¤„ç†å®ƒä»¬ï¼Ÿâ€ä¸å¹¸çš„æ˜¯ï¼Œè¿™åˆæ˜¯é€»è¾‘æš´æ”¿å¼ºåŠ ç»™æˆ‘ä»¬çš„å¦ä¸€ä¸ªæƒè¡¡ã€‚æŒ‰é¡ºåºå®Œæˆå·¥ä½œå’ŒåŒæ—¶å®Œæˆå¤šé¡¹å·¥ä½œæ€»æ˜¯ç›¸äº’å†²çªçš„ã€‚å¤§å¤šæ•°æ¶ˆæ¯é˜Ÿåˆ—ç³»ç»Ÿä¼šè¦æ±‚ä½ é€‰æ‹©å…¶ä¸­ä¹‹ä¸€â€”â€”AWS
    SQSæœ€åˆä¼˜å…ˆè€ƒè™‘äº†å¹¶è¡Œæ€§è€Œä¸æ˜¯ä¸¥æ ¼çš„é¡ºåºï¼›ä½†æœ€è¿‘è¿˜å¼•å…¥äº†ä¸€ä¸ªå•ç‹¬çš„ FIFOï¼ˆå…ˆè¿›å…ˆå‡ºï¼‰æ’é˜Ÿç³»ç»Ÿï¼Œå®ƒä¿æŒä¸¥æ ¼çš„é¡ºåºã€‚åœ¨åšå‡ºé€‰æ‹©ä¹‹å‰ï¼Œè®©æˆ‘ä»¬äº†è§£ä¸€ä¸‹ä¸¤è€…çš„åŒºåˆ«ä»¥åŠä¸ºä»€ä¹ˆéœ€è¦æœ‰åŒºåˆ«ã€‚
- en: Returning to our earlier metaphor for a queueâ€”a long tube into which we roll
    messages written on a ballâ€”we probably imagined the tube to be just a little wider
    than a single ball. There's really no way the balls could overtake or pass each
    other inside the tube, so the only way a receiver could get these messages out
    is one-by-one, in the order they were put in. This guarantees strict ordering,
    but places strong limitations on our receiver. There can *only be one* *agent*
    on the receiver side that's processing each messageâ€”if there was more than one,
    there would be no guarantee that the messages were processed in order. Because
    each new agent could processes each message independently, they could each finish
    and start on the next message at any time. If the are two agents, A & B, and Agent
    A receives the first message and Agent B the second; Agent B could finish processing
    the second message and start on the third message even before Agent A is finished
    processing the first message. Though the messages were *received from the queue*
    strictly in the order that they were put in, if there are multiple receiving agents
    thereâ€™s no way to say the messages will *be processed in that order*.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: å›åˆ°æˆ‘ä»¬å¯¹é˜Ÿåˆ—çš„æ—©æœŸéšå–»â€”â€”ä¸€ä¸ªé•¿é•¿çš„ç®¡é“ï¼Œæˆ‘ä»¬åœ¨å…¶ä¸­æ»šåŠ¨å†™åœ¨çƒä¸Šçš„æ¶ˆæ¯â€”â€”æˆ‘ä»¬å¯èƒ½æƒ³è±¡ç®¡é“åªæ¯”ä¸€ä¸ªçƒç¨å¾®å®½ä¸€ç‚¹ã€‚åœ¨ç®¡é“å†…ï¼Œçƒå®é™…ä¸Šæ— æ³•è¶…è¶Šæˆ–ç›¸äº’é€šè¡Œï¼Œæ‰€ä»¥æ¥æ”¶è€…å”¯ä¸€èƒ½å–å‡ºè¿™äº›æ¶ˆæ¯çš„æ–¹å¼æ˜¯ä¸€ä¸ªæ¥ä¸€ä¸ªåœ°æŒ‰ç…§æ”¾å…¥çš„é¡ºåºã€‚è¿™ä¿è¯äº†ä¸¥æ ¼çš„é¡ºåºï¼Œä½†å¯¹æˆ‘ä»¬çš„æ¥æ”¶è€…æ–½åŠ äº†ä¸¥æ ¼çš„é™åˆ¶ã€‚æ¥æ”¶æ–¹åªèƒ½æœ‰*ä¸€ä¸ª*ä»£ç†äººåœ¨å¤„ç†æ¯æ¡æ¶ˆæ¯â€”â€”å¦‚æœæœ‰å¤šä¸ªä»£ç†äººï¼Œå°±æ— æ³•ä¿è¯æ¶ˆæ¯æŒ‰é¡ºåºå¤„ç†ã€‚å› ä¸ºæ¯ä¸ªæ–°ä»£ç†äººéƒ½å¯ä»¥ç‹¬ç«‹å¤„ç†æ¯æ¡æ¶ˆæ¯ï¼Œä»–ä»¬å¯ä»¥éšæ—¶å®Œæˆå¹¶å¼€å§‹ä¸‹ä¸€æ¡æ¶ˆæ¯ã€‚å¦‚æœæœ‰ä¸¤ä¸ªä»£ç†äººï¼ŒAå’ŒBï¼Œä»£ç†äººAæ¥æ”¶ç¬¬ä¸€æ¡æ¶ˆæ¯ï¼Œä»£ç†äººBæ¥æ”¶ç¬¬äºŒæ¡æ¶ˆæ¯ï¼›ä»£ç†äººBå¯ä»¥åœ¨ä»£ç†äººAå®Œæˆå¤„ç†ç¬¬ä¸€æ¡æ¶ˆæ¯ä¹‹å‰å®Œæˆå¤„ç†ç¬¬äºŒæ¡æ¶ˆæ¯å¹¶å¼€å§‹å¤„ç†ç¬¬ä¸‰æ¡æ¶ˆæ¯ã€‚å°½ç®¡æ¶ˆæ¯æ˜¯æŒ‰ç…§æ”¾å…¥çš„é¡ºåº*ä»é˜Ÿåˆ—æ¥æ”¶*çš„ï¼Œä½†å¦‚æœæœ‰å¤šä¸ªæ¥æ”¶ä»£ç†äººï¼Œåˆ™æ— æ³•ä¿è¯æ¶ˆæ¯*æŒ‰ç…§é‚£ä¸ªé¡ºåºè¢«å¤„ç†*ã€‚
- en: The agents could use a [distributed](https://redis.io/topics/distlock) [lock](https://www.postgresql.org/docs/current/explicit-locking.html#ADVISORY-LOCKS)
    of some kind to co-ordinate with each other, but this is basically the same as
    having only one agentâ€”the lock would only allow one agent to work at any given
    time. This also means that one agent crashing would result in a *deadlock* with
    no work being done.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ä»£ç†äººå¯ä»¥ä½¿ç”¨æŸç§[åˆ†å¸ƒå¼](https://redis.io/topics/distlock) [é”](https://www.postgresql.org/docs/current/explicit-locking.html#ADVISORY-LOCKS)æ¥åè°ƒå½¼æ­¤ï¼Œä½†è¿™åŸºæœ¬ä¸Šä¸åªæœ‰ä¸€ä¸ªä»£ç†äººç›¸åŒâ€”â€”é”åªå…è®¸ä¸€ä¸ªä»£ç†äººåœ¨ä»»ä½•ç»™å®šæ—¶é—´å·¥ä½œã€‚è¿™ä¹Ÿæ„å‘³ç€ä¸€ä¸ªä»£ç†äººå´©æºƒå°†å¯¼è‡´*æ­»é”*ï¼Œæ²¡æœ‰ä»»ä½•å·¥ä½œè¢«å®Œæˆã€‚
- en: One way for the messaging system to guarantee order would be for the tube to
    refuse to give out the next ball until and unless the last ball that was received
    has been destroyed (the last message has been deleted/acknowledged). This is what
    FIFO queues in general will doâ€”they'll provide the next message only after the
    last one has been acknowledged or deletedâ€”but this means that only one agent can
    possibly be working at a time, even if there are *N* agents waiting to receive
    messages from the queue.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: æ¶ˆæ¯ç³»ç»Ÿä¿è¯é¡ºåºçš„ä¸€ç§æ–¹æ³•æ˜¯ï¼Œç®¡é“æ‹’ç»åœ¨æœ€åä¸€ä¸ªæ¥æ”¶åˆ°çš„çƒè¢«é”€æ¯ï¼ˆæœ€åä¸€æ¡æ¶ˆæ¯è¢«åˆ é™¤/ç¡®è®¤ï¼‰ä¹‹å‰ï¼Œæä¾›ä¸‹ä¸€ä¸ªçƒã€‚è¿™å°±æ˜¯ä¸€èˆ¬æƒ…å†µä¸‹FIFOé˜Ÿåˆ—æ‰€åšçš„â€”â€”åªæœ‰åœ¨æœ€åä¸€ä¸ªæ¶ˆæ¯è¢«ç¡®è®¤æˆ–åˆ é™¤ä¹‹åæ‰ä¼šæä¾›ä¸‹ä¸€æ¡æ¶ˆæ¯â€”â€”ä½†è¿™æ„å‘³ç€å³ä½¿æœ‰*N*ä¸ªä»£ç†äººç­‰å¾…ä»é˜Ÿåˆ—æ¥æ”¶æ¶ˆæ¯ï¼Œåªèƒ½æœ‰ä¸€ä¸ªä»£ç†äººå¯èƒ½åœ¨å·¥ä½œã€‚
- en: Sometimes, this is exactly what we want. Some operations are easier to control
    effectively when we only have to deal with a single agent, like enforcing rules
    on financial transactions; respecting [rate limits](https://redis.io/commands/incr#pattern-rate-limiter);
    or generally processing messages whose formats have been designed assuming they
    would always be processed in order. But a lot of these â€œbenefitsâ€ are not really
    coming from the decision to use FIFO orderingâ€”any scenario where we have *N* receivers
    that must somehow co-ordinate their work with each other will benefit from the
    special case of *N = 1*. The key takeaway is that requiring a guaranteed order
    means we have to process messages sequentially on only one receiver at a time.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: æœ‰æ—¶ï¼Œè¿™æ­£æ˜¯æˆ‘ä»¬æƒ³è¦çš„ã€‚æœ‰äº›æ“ä½œåªæ¶‰åŠä¸€ä¸ªå•ä¸€ä»£ç†äººæ—¶æ›´å®¹æ˜“æœ‰æ•ˆæ§åˆ¶ï¼Œæ¯”å¦‚å¼ºåˆ¶æ‰§è¡Œé‡‘èäº¤æ˜“è§„åˆ™ï¼›å°Šé‡[é€Ÿç‡é™åˆ¶](https://redis.io/commands/incr#pattern-rate-limiter)ï¼›æˆ–è€…é€šå¸¸å¤„ç†å‡è®¾æ€»æ˜¯æŒ‰é¡ºåºå¤„ç†çš„æ¶ˆæ¯æ ¼å¼ã€‚ä½†æ˜¯å¾ˆå¤šè¿™äº›â€œå¥½å¤„â€å¹¶ä¸æ˜¯çœŸæ­£æ¥è‡ªäºä½¿ç”¨FIFOæ’åºçš„å†³å®šâ€”â€”ä»»ä½•æˆ‘ä»¬å¿…é¡»ä»¥æŸç§æ–¹å¼åè°ƒå½¼æ­¤å·¥ä½œçš„*N*æ¥æ”¶è€…çš„åœºæ™¯éƒ½ä¼šä»*N
    = 1*çš„ç‰¹æ®Šæƒ…å†µä¸­å—ç›Šã€‚å…³é”®æ˜¯ï¼Œè¦æ±‚æœ‰ä¿è¯çš„é¡ºåºæ„å‘³ç€æˆ‘ä»¬å¿…é¡»ä¸€æ¬¡åªèƒ½åœ¨ä¸€ä¸ªæ¥æ”¶è€…ä¸Šé¡ºåºå¤„ç†æ¶ˆæ¯ã€‚
- en: This restriction also places severe pressure on the queuing system, so you'll
    find that FIFO queues are often more expensive and have less capacity than their
    parallel counterparts. This is because the same logical limits apply to the internal
    implementation of queuing system as wellâ€”most work needs to be constrained to
    a single agent or server, and that system needs to be kept reliable. Any effort
    to add redundancy requires synchronous co-ordination between the master and the
    backup services in order to maintain the ordering guarantees. In AWS SQS, the
    FIFO queues are about 2X more expensive than the parallel queues, and are constrained
    to a few hundred messages per second when strict FIFO ordering is required.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸€é™åˆ¶ä¹Ÿç»™é˜Ÿåˆ—ç³»ç»Ÿå¸¦æ¥äº†ä¸¥é‡å‹åŠ›ï¼Œå› æ­¤ä½ ä¼šå‘ç° FIFO é˜Ÿåˆ—é€šå¸¸æ¯”å…¶å¹¶è¡Œå¯¹åº”ç‰©æ›´æ˜‚è´µï¼Œå®¹é‡æ›´å°ã€‚è¿™æ˜¯å› ä¸ºç›¸åŒçš„é€»è¾‘é™åˆ¶ä¹Ÿé€‚ç”¨äºé˜Ÿåˆ—ç³»ç»Ÿçš„å†…éƒ¨å®ç°â€”â€”å¤§å¤šæ•°å·¥ä½œéƒ½éœ€è¦å—é™äºå•ä¸ªä»£ç†æˆ–æœåŠ¡å™¨ï¼Œå¹¶ä¸”è¯¥ç³»ç»Ÿéœ€è¦ä¿æŒå¯é æ€§ã€‚ä»»ä½•å¢åŠ å†—ä½™çš„åŠªåŠ›éƒ½éœ€è¦ä¸»æœåŠ¡å’Œå¤‡ä»½æœåŠ¡ä¹‹é—´çš„åŒæ­¥åè°ƒï¼Œä»¥ä¿æŒæ’åºä¿è¯ã€‚åœ¨
    AWS SQS ä¸­ï¼ŒFIFO é˜Ÿåˆ—æ¯”å¹¶è¡Œé˜Ÿåˆ—è´µçº¦ 2 å€ï¼Œå¹¶ä¸”åœ¨éœ€è¦ä¸¥æ ¼ FIFO æ’åºæ—¶å—åˆ°å‡ ç™¾æ¡æ¶ˆæ¯æ¯ç§’çš„é™åˆ¶ã€‚
- en: So the only way to move forward with a FIFO message queue is to accept that
    the entire message processing architecture is going to have an intrinsic speed
    limit. Many systems will support [group headings](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/using-messagegroupid-property.html)
    inside the queue to denote what messages we want strict ordering onâ€”we might say
    that all messages under the heading â€œpaymentsâ€ need to be FIFO, and all the messages
    under â€œordersâ€ need to be FIFO, but they don't need to be FIFO with respect to
    each other. This allows some parallelisation inside the queue (like having two
    FIFO tubes instead of one), but we need to remember that the message bandwidth
    inside each group heading will still be limited.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: å› æ­¤ï¼Œç»§ç»­ä½¿ç”¨ FIFO æ¶ˆæ¯é˜Ÿåˆ—çš„å”¯ä¸€æ–¹æ³•å°±æ˜¯æ¥å—æ•´ä¸ªæ¶ˆæ¯å¤„ç†æ¶æ„å°†å…·æœ‰å†…åœ¨é€Ÿåº¦é™åˆ¶çš„äº‹å®ã€‚è®¸å¤šç³»ç»Ÿå°†æ”¯æŒé˜Ÿåˆ—å†…çš„[ç»„æ ‡é¢˜](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/using-messagegroupid-property.html)ï¼Œä»¥æŒ‡ç¤ºæˆ‘ä»¬å¸Œæœ›åœ¨å“ªäº›æ¶ˆæ¯ä¸Šä¸¥æ ¼æ’åºâ€”â€”æˆ‘ä»¬å¯èƒ½ä¼šè¯´æ‰€æœ‰å±äºâ€œä»˜æ¬¾â€çš„æ¶ˆæ¯éƒ½éœ€è¦
    FIFOï¼Œè€Œæ‰€æœ‰å±äºâ€œè®¢å•â€çš„æ¶ˆæ¯éƒ½éœ€è¦ FIFOï¼Œä½†å®ƒä»¬ä¸éœ€è¦åœ¨å½¼æ­¤ä¹‹é—´æ˜¯ FIFOã€‚è¿™å…è®¸é˜Ÿåˆ—å†…éƒ¨è¿›è¡Œä¸€äº›å¹¶è¡ŒåŒ–ï¼ˆæ¯”å¦‚æœ‰ä¸¤ä¸ª FIFO ç®¡é“è€Œä¸æ˜¯ä¸€ä¸ªï¼‰ï¼Œä½†æˆ‘ä»¬éœ€è¦è®°ä½æ¯ä¸ªç»„æ ‡é¢˜å†…çš„æ¶ˆæ¯å¸¦å®½ä»ç„¶ä¼šå—åˆ°é™åˆ¶ã€‚
- en: Parallel != Random
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: å¹¶è¡Œ != éšæœº
- en: Does that mean that the ordering in parallel queues is completely random? Sometimes,
    yes, but most often no. In SQS, the analogy is more that instead of having one
    tube from the sender to receiver, there are multiple tubes. They might also branch
    or join each other along the way. This doesn't mean that the order of the messages
    you roll in are intentionally randomised in any wayâ€”across a large number of messages
    you'd still expect that earlier messages are generally received before the later
    ones. This is more a *best-effort* ordering, where some effort is make to keep
    the ordering intact, but because it's already logically impossible, it's simply
    not a big priority for the system. This also allows a messaging system like SQS
    to scale up to nearly infinite capacityâ€”because if you're rolling in a lot of
    messages the queueing system can simply add more tubes. And as you can imagine,
    this will support any number of receivers at the same time, and any number of
    senders as well. This simplicity is what allows SQS to scale to mind-boggling
    numbers, including a case where [there was a queue](https://twitter.com/timbray/status/1246157403663388672)
    with over 250 billion messages waiting to be consumed, with the receiver reading
    and acknowledging over a million messages a second. And thatâ€™s just one queue
    operated by one customer.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯å¦æ„å‘³ç€å¹¶è¡Œé˜Ÿåˆ—ä¸­çš„é¡ºåºå®Œå…¨æ˜¯éšæœºçš„ï¼Ÿæœ‰æ—¶æ˜¯ï¼Œä½†å¤§å¤šæ•°æƒ…å†µä¸‹ä¸æ˜¯ã€‚åœ¨ SQS ä¸­ï¼Œç±»æ¯”æ›´åƒæ˜¯ï¼Œä¸å…¶ä»å‘é€æ–¹åˆ°æ¥æ”¶æ–¹æœ‰ä¸€ä¸ªç®¡é“ï¼Œä¸å¦‚è¯´æœ‰å¤šä¸ªç®¡é“ã€‚å®ƒä»¬å¯èƒ½åœ¨é€”ä¸­åˆ†æ”¯æˆ–æ±‡åˆã€‚è¿™å¹¶ä¸æ„å‘³ç€ä½ æ»šå…¥çš„æ¶ˆæ¯çš„é¡ºåºæ˜¯æœ‰æ„éšæœºåŒ–çš„â€”â€”åœ¨å¤§é‡æ¶ˆæ¯ä¸­ï¼Œä½ ä»ç„¶å¯ä»¥é¢„æœŸè¾ƒæ—©çš„æ¶ˆæ¯é€šå¸¸ä¼šåœ¨åæ¥çš„æ¶ˆæ¯ä¹‹å‰æ”¶åˆ°ã€‚è¿™æ›´åƒæ˜¯ä¸€ç§*å°½åŠ›è€Œä¸º*çš„æ’åºï¼Œå³å°½æœ€å¤§åŠªåŠ›ä¿æŒæ’åºå®Œæ•´æ€§ï¼Œä½†ç”±äºé€»è¾‘ä¸Šå·²ç»ä¸å¯èƒ½ï¼Œå› æ­¤å®ƒå¹¶ä¸æ˜¯ç³»ç»Ÿçš„é‡è¦ä¼˜å…ˆçº§ã€‚è¿™ä¹Ÿå…è®¸åƒ
    SQS è¿™æ ·çš„æ¶ˆæ¯ç³»ç»Ÿæ‰©å±•åˆ°å‡ ä¹æ— é™çš„å®¹é‡â€”â€”å› ä¸ºå¦‚æœä½ æ»šå…¥äº†å¤§é‡æ¶ˆæ¯ï¼Œé˜Ÿåˆ—ç³»ç»Ÿå¯ä»¥ç®€å•åœ°æ·»åŠ æ›´å¤šçš„ç®¡é“ã€‚æ­£å¦‚ä½ æ‰€èƒ½æƒ³è±¡çš„ï¼Œè¿™å°†æ”¯æŒåŒæ—¶ä»»æ„æ•°é‡çš„æ¥æ”¶è€…ï¼Œä»¥åŠä»»æ„æ•°é‡çš„å‘é€è€…ã€‚è¿™ç§ç®€å•æ€§æ˜¯
    SQS èƒ½å¤Ÿæ‰©å±•åˆ°ä»¤äººéš¾ä»¥ç½®ä¿¡çš„æ•°é‡çš„åŸå› ï¼Œå…¶ä¸­ä¸€ä¸ªæ¡ˆä¾‹æ˜¯[æœ‰ä¸€ä¸ªé˜Ÿåˆ—](https://twitter.com/timbray/status/1246157403663388672)ç­‰å¾…æ¶ˆè´¹è¶…è¿‡
    2500 äº¿æ¡æ¶ˆæ¯ï¼Œæ¥æ”¶è€…æ¯ç§’è¯»å–å¹¶ç¡®è®¤è¶…è¿‡ä¸€ç™¾ä¸‡æ¡æ¶ˆæ¯ã€‚è€Œè¿™ä»…ä»…æ˜¯ä¸€ä¸ªå®¢æˆ·æ“ä½œçš„ä¸€ä¸ªé˜Ÿåˆ—ã€‚
- en: Most problems that seem like they have a hard FIFO requirement can often lend
    themselves to parallelism and out-of-order delivery with a little bit of creativity.
    The sender adding a timestamp into the message is one way to help with this, like
    in the case where the messages are measurements where only the last one matters.
    In a more transactional system, the sender can often add a [monotonically increasing
    counter](https://www.postgresql.org/docs/current/functions-sequence.html) into
    the messages. If that's impossible, we might be able to handle this based on the
    contents of the messageâ€”if we're messaging the percentage of a file downloaded,
    for example, seeing 41%, 42% and 43% always means that the current value is 43%â€”even
    if we see them out of order as 41%, 43% and 42%.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: å¤§å¤šæ•°çœ‹ä¼¼æœ‰ä¸¥æ ¼å…ˆè¿›å…ˆå‡ºï¼ˆFIFOï¼‰è¦æ±‚çš„é—®é¢˜é€šå¸¸éƒ½å¯ä»¥é€šè¿‡ä¸€ç‚¹åˆ›æ„è½¬åŒ–ä¸ºå¹¶è¡Œæ€§å’Œæ— åºä¼ é€’ã€‚å‘é€è€…å°†æ—¶é—´æˆ³æ·»åŠ åˆ°æ¶ˆæ¯ä¸­æ˜¯å¸®åŠ©è§£å†³æ­¤é—®é¢˜çš„ä¸€ç§æ–¹æ³•ï¼Œå°±åƒåœ¨åªæœ‰æœ€åä¸€ä¸ªæ¶ˆæ¯é‡è¦çš„æµ‹é‡æ¶ˆæ¯çš„æƒ…å†µä¸‹ä¸€æ ·ã€‚åœ¨æ›´å…·äº‹åŠ¡æ€§çš„ç³»ç»Ÿä¸­ï¼Œå‘é€è€…é€šå¸¸å¯ä»¥å°†ä¸€ä¸ª[å•è°ƒé€’å¢çš„è®¡æ•°å™¨](https://www.postgresql.org/docs/current/functions-sequence.html)æ·»åŠ åˆ°æ¶ˆæ¯ä¸­ã€‚å¦‚æœè¿™æ˜¯ä¸å¯èƒ½çš„ï¼Œæˆ‘ä»¬å¯èƒ½å¯ä»¥æ ¹æ®æ¶ˆæ¯çš„å†…å®¹æ¥å¤„ç†æ­¤é—®é¢˜â€”â€”ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æ­£åœ¨å‘é€æ–‡ä»¶ä¸‹è½½çš„ç™¾åˆ†æ¯”ï¼Œé‚£ä¹ˆçœ‹åˆ°41%ï¼Œ42%å’Œ43%æ€»æ˜¯æ„å‘³ç€å½“å‰å€¼ä¸º43%â€”â€”å³ä½¿æˆ‘ä»¬ä»¥41%ï¼Œ43%å’Œ42%çš„é¡ºåºçœ‹åˆ°å®ƒä»¬ã€‚
- en: While it's often a bad idea to change our systems to accommodate the tools we
    use, designing our messages to allow for out-of-order delivery and idempotency
    makes the system more resilient in general, while also letting use more parallel
    messaging systemsâ€”often saving time, money and a lot of operational work.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: è™½ç„¶æ ¹æ®æˆ‘ä»¬ä½¿ç”¨çš„å·¥å…·æ¥æ”¹å˜ç³»ç»Ÿé€šå¸¸ä¸æ˜¯ä¸€ä¸ªå¥½ä¸»æ„ï¼Œä½†è®¾è®¡æˆ‘ä»¬çš„æ¶ˆæ¯ä»¥å…è®¸æ— åºä¼ é€’å’Œå¹‚ç­‰æ€§ä¼šä½¿ç³»ç»Ÿåœ¨ä¸€èˆ¬æƒ…å†µä¸‹æ›´å…·å¼¹æ€§ï¼ŒåŒæ—¶ä¹Ÿå…è®¸æˆ‘ä»¬ä½¿ç”¨æ›´å¤šå¹¶è¡Œæ¶ˆæ¯ç³»ç»Ÿâ€”â€”é€šå¸¸èŠ‚çœæ—¶é—´ã€é‡‘é’±å’Œå¤§é‡è¿è¥å·¥ä½œã€‚
- en: Fan Out / In
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Fan Out / In**'
- en: When building a distributed system there's often a need to have the same message
    sent to multiple receiversâ€”besides the usual receiver of the message, we also
    often want the same message sent to other places, like an archive, an audit log
    (for compliance and security checks) or an analyzer for our dashboards. If you're
    using an event driven architecture with many services, you might want to use a
    single *event bus* in your application, where all the messages posted into this
    event bus are automatically sent to all of your services. This is called a *fan-out*
    problem, where a message from one producer needs to reach many consumers.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨æ„å»ºåˆ†å¸ƒå¼ç³»ç»Ÿæ—¶ï¼Œé€šå¸¸éœ€è¦å°†ç›¸åŒçš„æ¶ˆæ¯å‘é€åˆ°å¤šä¸ªæ¥æ”¶è€…â€”â€”é™¤äº†é€šå¸¸æ¥æ”¶æ¶ˆæ¯çš„æ¥æ”¶è€…å¤–ï¼Œæˆ‘ä»¬è¿˜ç»å¸¸å¸Œæœ›å°†ç›¸åŒçš„æ¶ˆæ¯å‘é€åˆ°å…¶ä»–ä½ç½®ï¼Œä¾‹å¦‚å­˜æ¡£ã€å®¡æ ¸æ—¥å¿—ï¼ˆç”¨äºåˆè§„æ€§å’Œå®‰å…¨æ£€æŸ¥ï¼‰æˆ–æˆ‘ä»¬ä»ªè¡¨æ¿çš„åˆ†æå™¨ã€‚å¦‚æœæ‚¨æ­£åœ¨ä½¿ç”¨å…·æœ‰å¤šä¸ªæœåŠ¡çš„äº‹ä»¶é©±åŠ¨æ¶æ„ï¼Œæ‚¨å¯èƒ½å¸Œæœ›åœ¨æ‚¨çš„åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨å•ä¸€çš„*äº‹ä»¶æ€»çº¿*ï¼Œè¯¥äº‹ä»¶æ€»çº¿ä¸­çš„æ‰€æœ‰å‘å¸ƒåˆ°æ­¤äº‹ä»¶æ€»çº¿çš„æ¶ˆæ¯éƒ½ä¼šè‡ªåŠ¨å‘é€åˆ°æ‚¨çš„æ‰€æœ‰æœåŠ¡ã€‚è¿™ç§°ä¸º*æ‰‡å‡º*é—®é¢˜ï¼Œå…¶ä¸­æ¥è‡ªä¸€ä¸ªç”Ÿäº§è€…çš„æ¶ˆæ¯éœ€è¦åˆ°è¾¾å¤šä¸ªæ¶ˆè´¹è€…ã€‚
- en: The inverse problem, where a single receiver is tasked with reading the messages
    posted to multiple queues is also commonâ€”in the example we considered above, a
    receiver that was archiving all messages or creating an audit log would probably
    receive all the messages generated in an organisation, on every queue. It's also
    common in service architectures to have a function like notifications handled
    separatelyâ€”so a notification system might need to receive messages about a new
    confirmed orders, failed payments, successful shipping and many more. This is
    a *fan-in* problem, where the messages from many producers need to reach the same
    consumer.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: åå‘é—®é¢˜ï¼Œå³ä¸€ä¸ªå•ä¸€çš„æ¥æ”¶å™¨è¢«åˆ†é…äº†ä»å¤šä¸ªé˜Ÿåˆ—ä¸­è¯»å–æ¶ˆæ¯çš„ä»»åŠ¡ä¹Ÿå¾ˆå¸¸è§â€”â€”åœ¨ä¸Šé¢è€ƒè™‘çš„ä¾‹å­ä¸­ï¼Œä¸€ä¸ªå°†æ‰€æœ‰æ¶ˆæ¯å­˜æ¡£æˆ–åˆ›å»ºå®¡æ ¸æ—¥å¿—çš„æ¥æ”¶å™¨å¯èƒ½ä¼šæ¥æ”¶ç»„ç»‡ä¸­ç”Ÿæˆçš„æ‰€æœ‰æ¶ˆæ¯ï¼Œä½äºæ¯ä¸ªé˜Ÿåˆ—ä¸Šã€‚åœ¨æœåŠ¡ä½“ç³»ç»“æ„ä¸­ï¼Œå°†é€šçŸ¥å¤„ç†åˆ†å¼€å¤„ç†ä¹Ÿå¾ˆå¸¸è§â€”â€”å› æ­¤ï¼Œé€šçŸ¥ç³»ç»Ÿå¯èƒ½éœ€è¦æ¥æ”¶æœ‰å…³æ–°ç¡®è®¤è®¢å•ã€ä»˜æ¬¾å¤±è´¥ã€æˆåŠŸå‘è´§ç­‰çš„æ¶ˆæ¯ã€‚è¿™æ˜¯ä¸€ä¸ª*æ‰‡å…¥*é—®é¢˜ï¼Œå…¶ä¸­æ¥è‡ªè®¸å¤šç”Ÿäº§è€…çš„æ¶ˆæ¯éœ€è¦åˆ°è¾¾ç›¸åŒçš„æ¶ˆè´¹è€…ã€‚
- en: If all the producers are putting their messages directly into queues, this would
    be a really difficult problem to solveâ€”we'd have to somehow intercept our queues,
    and reliably copy the messages into multiple queues. Building, configuring and
    maintaining this switchboard simply isn't worth the time or the effortâ€”especially
    when we could just use *topics* instead.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœæ‰€æœ‰çš„ç”Ÿäº§è€…éƒ½ç›´æ¥å°†å®ƒä»¬çš„æ¶ˆæ¯æ”¾å…¥é˜Ÿåˆ—ï¼Œé‚£ä¹ˆè¿™å°†æ˜¯ä¸€ä¸ªéå¸¸å›°éš¾çš„é—®é¢˜è¦è§£å†³â€”â€”æˆ‘ä»¬å¿…é¡»ä»¥æŸç§æ–¹å¼æ‹¦æˆªæˆ‘ä»¬çš„é˜Ÿåˆ—ï¼Œå¹¶å¯é åœ°å°†æ¶ˆæ¯å¤åˆ¶åˆ°å¤šä¸ªé˜Ÿåˆ—ä¸­ã€‚æ„å»ºã€é…ç½®å’Œç»´æŠ¤è¿™ä¸ªäº¤æ¢æœºæ ¹æœ¬ä¸å€¼å¾—æ—¶é—´å’Œç²¾åŠ›â€”â€”å°¤å…¶æ˜¯å½“æˆ‘ä»¬å¯ä»¥ä½¿ç”¨*ä¸»é¢˜*æ—¶ã€‚
- en: One way to think about topics is that they're similar to the headings you'd
    see on a notice board at a school or an office. Producers post messages under
    a specific topic on a board, and everyone interested in that topic will see the
    message. The most common way messaging systems send the messages to interested
    receivers is an HTTP(S) request, sometimes also called a *webhook*. In a push-based
    system like a HTTP request, the message is pushed into the receiver whether it's
    ready or not. This re-introduces the coupling that we talked about earlier which
    we want to avoidâ€”we don't want a situation where our receiver collapses under
    the crushing load of tens / hundreds / thousands / millions of webhooks over a
    short span of time. The answer here, again, is to just use a message queue to
    soak up the messages from the topics at whatever rate they're generated. The receivers
    can then process them at their own pace.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: æƒ³åˆ°ä¸»é¢˜çš„ä¸€ç§æ–¹å¼æ˜¯ï¼Œå®ƒä»¬ç±»ä¼¼äºæ‚¨åœ¨å­¦æ ¡æˆ–åŠå…¬å®¤çš„å…¬å‘Šæ¿ä¸Šçœ‹åˆ°çš„æ ‡é¢˜ã€‚ç”Ÿäº§è€…åœ¨å…¬å‘Šæ¿ä¸Šçš„ç‰¹å®šä¸»é¢˜ä¸‹å‘å¸ƒæ¶ˆæ¯ï¼Œå¯¹è¯¥ä¸»é¢˜æ„Ÿå…´è¶£çš„æ‰€æœ‰äººéƒ½å°†çœ‹åˆ°è¯¥æ¶ˆæ¯ã€‚æ¶ˆæ¯ç³»ç»Ÿå‘é€æ¶ˆæ¯åˆ°æ„Ÿå…´è¶£çš„æ¥æ”¶è€…æœ€å¸¸è§çš„æ–¹å¼æ˜¯HTTP(S)è¯·æ±‚ï¼Œæœ‰æ—¶ä¹Ÿç§°ä¸º*webhook*ã€‚åœ¨åƒHTTPè¯·æ±‚è¿™æ ·çš„æ¨é€å¼ç³»ç»Ÿä¸­ï¼Œæ— è®ºæ¥æ”¶è€…æ˜¯å¦å‡†å¤‡å¥½ï¼Œæ¶ˆæ¯éƒ½ä¼šè¢«æ¨é€åˆ°æ¥æ”¶è€…ã€‚è¿™é‡æ–°å¼•å…¥äº†æˆ‘ä»¬ä¹‹å‰è°ˆåˆ°çš„è€¦åˆï¼Œæˆ‘ä»¬å¸Œæœ›é¿å…â€”â€”æˆ‘ä»¬ä¸å¸Œæœ›æˆ‘ä»¬çš„æ¥æ”¶è€…åœ¨çŸ­æ—¶é—´å†…å› ä¸ºæ•°å/æ•°ç™¾/æ•°åƒ/æ•°ç™¾ä¸‡ä¸ªwebhookçš„å‹åŠ›è€Œå´©æºƒã€‚è¿™é‡Œçš„ç­”æ¡ˆå†æ¬¡æ˜¯åªéœ€ä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—ä»¥ä»»ä½•é€Ÿç‡ä»ä¸»é¢˜ä¸­å¸æ”¶æ¶ˆæ¯ã€‚ç„¶åï¼Œæ¥æ”¶è€…å¯ä»¥ä»¥è‡ªå·±çš„é€Ÿåº¦å¤„ç†å®ƒä»¬ã€‚
- en: Automatically copying a message from one topic into one or more queues isn't
    strictly a message queue feature, but it is complementaryâ€”most full-featured messaging
    systems will offer a way to do this. Producers will still continue to put messages
    into a single place as usual, but this will be a topic, and internally the messages
    will be copied to multiple queues, each of which will be read by their respective
    receivers.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: å°†æ¶ˆæ¯ä»ä¸€ä¸ªä¸»é¢˜è‡ªåŠ¨å¤åˆ¶åˆ°ä¸€ä¸ªæˆ–å¤šä¸ªé˜Ÿåˆ—å¹¶ä¸ä¸¥æ ¼å±äºæ¶ˆæ¯é˜Ÿåˆ—åŠŸèƒ½ï¼Œä½†å®ƒæ˜¯äº’è¡¥çš„â€”â€”å¤§å¤šæ•°åŠŸèƒ½é½å…¨çš„æ¶ˆæ¯ä¼ é€’ç³»ç»Ÿéƒ½ä¼šæä¾›è¿™æ ·çš„æ–¹æ³•ã€‚ç”Ÿäº§è€…ä»ç„¶ä¼šåƒå¾€å¸¸ä¸€æ ·å°†æ¶ˆæ¯æ”¾å…¥ä¸€ä¸ªåœ°æ–¹ï¼Œä½†è¿™å°†æ˜¯ä¸€ä¸ªä¸»é¢˜ï¼Œè€Œæ¶ˆæ¯å°†åœ¨å†…éƒ¨å¤åˆ¶åˆ°å¤šä¸ªé˜Ÿåˆ—ä¸­ï¼Œæ¯ä¸ªé˜Ÿåˆ—éƒ½å°†ç”±å…¶å„è‡ªçš„æ¥æ”¶è€…è¯»å–ã€‚
- en: In AWS, the service that provides topic based messaging is the Simple Notification
    Service ([SNS](https://aws.amazon.com/sns/)). Here you create a topic and publish
    messages into itâ€”the API to publish a message into an SNS topic is very similar
    to that of publishing a message into an SQS queue, and most producers don't have
    to care about the difference. SNS then has options available to publish that message
    into any number of *subscribed* SQS queues (at no extra charge). Each of these
    subscribed SQS queues would then be processed by their respective receivers.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨AWSä¸­ï¼Œæä¾›åŸºäºä¸»é¢˜çš„æ¶ˆæ¯ä¼ é€’çš„æœåŠ¡æ˜¯ç®€å•é€šçŸ¥æœåŠ¡ï¼ˆ[SNS](https://aws.amazon.com/sns/)ï¼‰ã€‚åœ¨è¿™é‡Œï¼Œæ‚¨åˆ›å»ºä¸€ä¸ªä¸»é¢˜å¹¶å°†æ¶ˆæ¯å‘å¸ƒåˆ°å…¶ä¸­â€”â€”å‘å¸ƒæ¶ˆæ¯åˆ°SNSä¸»é¢˜çš„APIä¸å°†æ¶ˆæ¯å‘å¸ƒåˆ°SQSé˜Ÿåˆ—éå¸¸ç›¸ä¼¼ï¼Œå¤§å¤šæ•°ç”Ÿäº§è€…ä¸å¿…å…³å¿ƒå…¶ä¸­çš„åŒºåˆ«ã€‚ç„¶åSNSæœ‰å¯ç”¨é€‰é¡¹å°†è¯¥æ¶ˆæ¯å‘å¸ƒåˆ°ä»»æ„æ•°é‡çš„*è®¢é˜…*çš„SQSé˜Ÿåˆ—ï¼ˆä¸æ”¶å–é¢å¤–è´¹ç”¨ï¼‰ã€‚ç„¶åï¼Œè¿™äº›è®¢é˜…çš„SQSé˜Ÿåˆ—å°†ç”±å„è‡ªçš„æ¥æ”¶è€…å¤„ç†ã€‚
- en: If you're working with a different system like Apache Kafka, you'll see similar
    concepts there as well - you'll have *topics* that you publish messages into,
    and any number of consumers can each read all the messages in a topic. Google's
    Pub/Sub system integrates topics and queues as well.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ æ­£åœ¨ä½¿ç”¨ç±»ä¼¼Apache Kafkaä¹‹ç±»çš„ä¸åŒç³»ç»Ÿï¼Œä½ ä¹Ÿä¼šåœ¨é‚£é‡Œçœ‹åˆ°ç±»ä¼¼çš„æ¦‚å¿µâ€”â€”ä½ å°†ä¼šæœ‰*ä¸»é¢˜*ï¼Œä½ å¯ä»¥å‘å…¶ä¸­å‘å¸ƒæ¶ˆæ¯ï¼Œè€Œä»»æ„æ•°é‡çš„æ¶ˆè´¹è€…å¯ä»¥åˆ†åˆ«è¯»å–ä¸»é¢˜ä¸­çš„æ‰€æœ‰æ¶ˆæ¯ã€‚Googleçš„Pub/Subç³»ç»Ÿä¹Ÿé›†æˆäº†ä¸»é¢˜å’Œé˜Ÿåˆ—ã€‚
- en: 'This combination of these scenarios is common enough that there''s a simple
    well established pattern to handle it:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›åœºæ™¯çš„ç»„åˆæ˜¯è¶³å¤Ÿå¸¸è§çš„ï¼Œä»¥è‡³äºæœ‰ä¸€ä¸ªç®€å•è€Œæˆç†Ÿçš„æ¨¡å¼æ¥å¤„ç†å®ƒï¼š
- en: Publish every message to one appropriate topic.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ¯æ¡æ¶ˆæ¯å‘å¸ƒåˆ°ä¸€ä¸ªé€‚å½“çš„ä¸»é¢˜ã€‚
- en: Create a queue for each receiver.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ä¸ºæ¯ä¸ªæ¥æ”¶è€…åˆ›å»ºä¸€ä¸ªé˜Ÿåˆ—ã€‚
- en: Link up each receiver's queue to the topics that the receiver is interested
    in.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: å°†æ¯ä¸ªæ¥æ”¶è€…çš„é˜Ÿåˆ—ä¸æ¥æ”¶è€…æ„Ÿå…´è¶£çš„ä¸»é¢˜é“¾æ¥èµ·æ¥ã€‚
- en: Since it's usually possible to subscribe a queue to any number of topics, there's
    no extra plumbing required at a receiver to process messages from multiple topics.
    And of course, it's possible to have any number of message queues subscribed to
    a single topic. This kind of setup supports both fan-out as well as fan-in, and
    keeps your architecture open to expansion and changes in the future.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: ç”±äºé€šå¸¸å¯ä»¥å°†é˜Ÿåˆ—è®¢é˜…åˆ°ä»»æ„æ•°é‡çš„ä¸»é¢˜ï¼Œå› æ­¤åœ¨æ¥æ”¶è€…ç«¯å¤„ç†æ¥è‡ªå¤šä¸ªä¸»é¢˜çš„æ¶ˆæ¯ä¸éœ€è¦é¢å¤–çš„ç®¡é“å·¥ä½œã€‚å½“ç„¶ï¼Œä¹Ÿå¯ä»¥å°†ä»»æ„æ•°é‡çš„æ¶ˆæ¯é˜Ÿåˆ—è®¢é˜…åˆ°å•ä¸ªä¸»é¢˜ã€‚è¿™ç§è®¾ç½®æ”¯æŒæ‰‡å‡ºå’Œæ‰‡å…¥ï¼Œå¹¶ä¸”ä½¿æ‚¨çš„æ¶æ„èƒ½å¤Ÿåœ¨æœªæ¥è¿›è¡Œæ‰©å±•å’Œæ›´æ”¹ã€‚
- en: Poison Pills & Dead Letters
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: æ¯’ä¸¸ï¼ˆPoison Pillsï¼‰å’Œæ­»ä¿¡ï¼ˆDead Lettersï¼‰
- en: As morbid as that sounds, when setting up systems to talk to multiple other
    systems there are bound to be mistakes that happen. The usual problem is that
    a subscriber is hooked up to receive messages from a topic it knows nothing about
    in a message format it doesn't understand. What happens? Does the subscriber ignore
    the message? Or does it acknowledge/delete it? Wouldn't be wrong for it to ignore
    it, because the message would just keep coming back again and again in an at-least-once
    system? But isn't it worse to delete/acknowledge a message that we aren't handling?
    Before we reach for philosophy books made from trees fallen in the woods, we might
    want to configure a *dead letter queue* on our queue. This is a feature that many
    queue systems give us, where if the system sees a message being sent out for processing
    repeatedly, unsuccessfully each time, it'll move it out into a special queue called
    a *dead letter queue*. We'd want to hook this queue up to an alarm of some sort,
    so we'll quickly know something weird is going on.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: å°½ç®¡å¬èµ·æ¥å¾ˆé˜´æ£®ï¼Œä½†åœ¨è®¾ç½®ç³»ç»Ÿä¸å¤šä¸ªå…¶ä»–ç³»ç»Ÿè¿›è¡Œé€šä¿¡æ—¶ï¼Œè‚¯å®šä¼šå‘ç”Ÿé”™è¯¯ã€‚é€šå¸¸çš„é—®é¢˜æ˜¯ï¼Œä¸€ä¸ªè®¢é˜…è€…è¢«è¿æ¥åˆ°æ¥æ”¶æ¥è‡ªä¸€ä¸ªå®ƒä¸€æ— æ‰€çŸ¥çš„ä¸»é¢˜çš„æ¶ˆæ¯ï¼Œä»¥ä¸€ç§å®ƒä¸ç†è§£çš„æ¶ˆæ¯æ ¼å¼ã€‚å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿè®¢é˜…è€…å¿½ç•¥æ¶ˆæ¯å—ï¼Ÿè¿˜æ˜¯ç¡®è®¤/åˆ é™¤å®ƒï¼Ÿå¿½ç•¥å®ƒä¸ä¼šé”™ï¼Œå› ä¸ºæ¶ˆæ¯ä¼šä¸€æ¬¡åˆä¸€æ¬¡åœ°è¿”å›åœ¨è‡³å°‘ä¸€æ¬¡çš„ç³»ç»Ÿä¸­ï¼Ÿä½†æ˜¯åˆ é™¤/ç¡®è®¤æˆ‘ä»¬ä¸å¤„ç†çš„æ¶ˆæ¯æ›´ç³Ÿç³•å—ï¼Ÿåœ¨æˆ‘ä»¬ä¼¸æ‰‹æ‹¿ç€ç”±å€’ä¸‹çš„æ ‘æœ¨åˆ¶æˆçš„å“²å­¦ä¹¦ä¹‹å‰ï¼Œæˆ‘ä»¬å¯èƒ½æƒ³è¦åœ¨æˆ‘ä»¬çš„é˜Ÿåˆ—ä¸Šé…ç½®ä¸€ä¸ª*æ­»ä¿¡é˜Ÿåˆ—*ã€‚è¿™æ˜¯è®¸å¤šé˜Ÿåˆ—ç³»ç»Ÿç»™æˆ‘ä»¬çš„ä¸€ä¸ªç‰¹æ€§ï¼Œå¦‚æœç³»ç»Ÿçœ‹åˆ°ä¸€ä¸ªæ¶ˆæ¯è¢«é‡å¤åœ°å‘é€å‡ºå»è¿›è¡Œå¤„ç†ï¼Œæ¯æ¬¡éƒ½ä¸æˆåŠŸï¼Œå®ƒå°±ä¼šå°†å…¶ç§»å‡ºåˆ°ä¸€ä¸ªç‰¹æ®Šçš„é˜Ÿåˆ—ï¼Œç§°ä¸º*æ­»ä¿¡é˜Ÿåˆ—*ã€‚æˆ‘ä»¬å¸Œæœ›å°†è¿™ä¸ªé˜Ÿåˆ—è¿æ¥åˆ°æŸç§è­¦æŠ¥ä¸Šï¼Œè¿™æ ·æˆ‘ä»¬å°±ä¼šå¾ˆå¿«çŸ¥é“å‘ç”Ÿäº†ä¸€äº›å¥‡æ€ªçš„äº‹æƒ…ã€‚
- en: A much worse scenario is one in which the message is explosive in some wayâ€”maybe
    it's formatted in XML instead of JSON, or contains user generated content carrying
    a malformed input attack that causes your parsing code to crash... your subscriber
    has just swallowed a *poison pill*. What happens when this pill reaches the subscriber
    is heavily dependent on your technology stack, so needless to say you want to
    think carefully about error handling and exceptions in the subscriber code. The
    good news is that if you've configured a *dead letter queue*, just failing silently
    can be a fine option. The poison pill will eventually show up in the *dead letter
    queue* and can be examined. Even if the poison message is crashing your subscriber,
    running an automated restart with a process manager is often enough to retry the
    message so many times that it moves it to the dead letter queue. You do need to
    make sure there are no security implications, though, and remember that this is
    an easy [DoS attack](https://en.wikipedia.org/wiki/Denial-of-service_attack).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: æ›´ç³Ÿç³•çš„æƒ…å†µæ˜¯ï¼Œæ¶ˆæ¯ä»¥æŸç§æ–¹å¼çˆ†ç‚¸æ€§åœ°å‘ˆç°â€”â€”ä¹Ÿè®¸å®ƒæ˜¯ç”¨ XML æ ¼å¼åŒ–è€Œä¸æ˜¯ JSONï¼Œæˆ–è€…åŒ…å«ç€ç”¨æˆ·ç”Ÿæˆçš„å†…å®¹ï¼Œå…¶ä¸­æºå¸¦äº†ä¸€ä¸ªæ ¼å¼é”™è¯¯çš„è¾“å…¥æ”»å‡»ï¼Œå¯¼è‡´ä½ çš„è§£æä»£ç å´©æºƒ...
    ä½ çš„è®¢é˜…è€…åˆšåˆšåä¸‹äº†ä¸€é¢—*æ¯’ä¸¸*ã€‚å½“è¿™é¢—æ¯’ä¸¸åˆ°è¾¾è®¢é˜…è€…æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼Œè¿™åœ¨å¾ˆå¤§ç¨‹åº¦ä¸Šå–å†³äºä½ çš„æŠ€æœ¯å †æ ˆï¼Œæ‰€ä»¥ä¸ç”¨è¯´ä½ è¦ä»”ç»†è€ƒè™‘è®¢é˜…è€…ä»£ç ä¸­çš„é”™è¯¯å¤„ç†å’Œå¼‚å¸¸ã€‚å¥½æ¶ˆæ¯æ˜¯ï¼Œå¦‚æœä½ é…ç½®äº†ä¸€ä¸ª*æ­»ä¿¡é˜Ÿåˆ—*ï¼Œé‚£ä¹ˆé»˜é»˜å¤±è´¥å¯èƒ½æ˜¯ä¸€ä¸ªä¸é”™çš„é€‰æ‹©ã€‚æ¯’ä¸¸æœ€ç»ˆä¼šå‡ºç°åœ¨*æ­»ä¿¡é˜Ÿåˆ—*ä¸­ï¼Œå¹¶ä¸”å¯ä»¥è¢«æ£€æŸ¥ã€‚å³ä½¿æ¯’æ¶ˆæ¯æ­£åœ¨å´©æºƒä½ çš„è®¢é˜…è€…ï¼Œä½¿ç”¨è¿›ç¨‹ç®¡ç†å™¨è¿›è¡Œè‡ªåŠ¨é‡å¯é€šå¸¸è¶³ä»¥é‡è¯•æ¶ˆæ¯ï¼Œä»¥è‡³äºå°†å…¶ç§»åŠ¨åˆ°æ­»ä¿¡é˜Ÿåˆ—ã€‚ä½†æ˜¯ä½ ç¡®å®éœ€è¦ç¡®ä¿æ²¡æœ‰å®‰å…¨é—®é¢˜ï¼Œå¹¶è®°ä½è¿™æ˜¯ä¸€ç§ç®€å•çš„[æ‹’ç»æœåŠ¡æ”»å‡»](https://en.wikipedia.org/wiki/Denial-of-service_attack)ã€‚
- en: Remember to always verify your incoming messages, both in terms of whether the
    message is structured the way you expect it to be, and if you're the intended
    recipient.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: è®°å¾—è¦å§‹ç»ˆéªŒè¯ä½ æ”¶åˆ°çš„æ¶ˆæ¯ï¼Œæ— è®ºæ˜¯æ¶ˆæ¯æ˜¯å¦æŒ‰ç…§ä½ æœŸæœ›çš„æ–¹å¼ç»“æ„åŒ–ï¼Œè¿˜æ˜¯ä½ æ˜¯å¦æ˜¯é¢„æœŸçš„æ¥æ”¶è€…ã€‚
- en: The Q-List
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Q åˆ—è¡¨
- en: Here's a list of some of the more popular message queuing systems available
    right now, with a list of how the concepts we've seen so far apply to each of
    them. This isn't an exhaustive list of course, so let me know [@sudhirj](https://twitter.com/sudhirj)
    if you think there are any that are missing or misrepresented.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™æ˜¯ç›®å‰ä¸€äº›æ›´æµè¡Œçš„æ¶ˆæ¯é˜Ÿåˆ—ç³»ç»Ÿçš„åˆ—è¡¨ï¼Œå…¶ä¸­åˆ—å‡ºäº†æˆ‘ä»¬åˆ°ç›®å‰ä¸ºæ­¢æ‰€è§è¿‡çš„æ¦‚å¿µå¦‚ä½•é€‚ç”¨äºæ¯ä¸ªç³»ç»Ÿã€‚å½“ç„¶ï¼Œè¿™å¹¶ä¸æ˜¯ä¸€ä¸ªè¯¦å°½çš„åˆ—è¡¨ï¼Œæ‰€ä»¥å¦‚æœä½ è®¤ä¸ºæœ‰ä»»ä½•é—æ¼æˆ–è¯¯ä¼ çš„åœ°æ–¹ï¼Œè¯·å‘Šè¯‰æˆ‘[@sudhirj](https://twitter.com/sudhirj)ã€‚
- en: AWS SNS & SQS
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AWS SNS & SQS
- en: AWS runs two services that integrate with each other to provide full message
    queuing functions. The [SQS](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html)
    service is a pure message queueâ€”it allows you to create a queue, send a message,
    and receive a message. That's it. The [`ReceiveMessage`](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API_ReceiveMessage.html)
    API on on SQS queue is pull-only, so you'll need to call it whenever your receiver
    is ready to process a message. There's a `WaitTimeSeconds` option to block on
    the call wait for a message for up to 20 seconds, so an effective pattern is to
    poll the `ReceiveMessage` API in an infinite loop with the 20 second wait turned
    on.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: AWS è¿è¡Œä¸¤ä¸ªç›¸äº’é›†æˆçš„æœåŠ¡ï¼Œæä¾›å®Œæ•´çš„æ¶ˆæ¯é˜Ÿåˆ—åŠŸèƒ½ã€‚[SQS](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/welcome.html)
    æœåŠ¡æ˜¯ä¸€ä¸ªçº¯æ¶ˆæ¯é˜Ÿåˆ—â€”â€”å®ƒå…è®¸æ‚¨åˆ›å»ºé˜Ÿåˆ—ã€å‘é€æ¶ˆæ¯å’Œæ¥æ”¶æ¶ˆæ¯ã€‚å°±æ˜¯è¿™æ ·ã€‚SQS é˜Ÿåˆ—ä¸Šçš„ [`ReceiveMessage`](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/APIReference/API_ReceiveMessage.html)
    API ä»…æ”¯æŒæ‹‰å–ï¼Œå› æ­¤æ‚¨éœ€è¦åœ¨æ¥æ”¶æ–¹å‡†å¤‡å¤„ç†æ¶ˆæ¯æ—¶è°ƒç”¨å®ƒã€‚æœ‰ä¸€ä¸ª `WaitTimeSeconds` é€‰é¡¹ï¼Œç”¨äºåœ¨è°ƒç”¨ç­‰å¾…æ¶ˆæ¯æ—¶é˜»å¡ï¼Œæœ€å¤šç­‰å¾… 20 ç§’ï¼Œå› æ­¤ä¸€ä¸ªæœ‰æ•ˆçš„æ¨¡å¼æ˜¯ä½¿ç”¨
    20 ç§’ç­‰å¾…åœ¨æ— é™å¾ªç¯ä¸­è½®è¯¢ `ReceiveMessage` APIã€‚
- en: The topics and fan-out / fan-in functions come with the integration of [SNS](https://docs.aws.amazon.com/sns/latest/dg/sns-sqs-as-subscriber.html),
    which works on the construct of a *topic*. This allows a message to be posted
    into a topic, as opposed to a queue. You can then subscribe any number of SQS
    queues into a topic, so messages published to the topic are copied to all subscribed
    queues quickly at no additional cost. You'll want to turn on Â the [*raw message*](https://docs.aws.amazon.com/sns/latest/dg/sns-large-payload-raw-message-delivery.html)
    option, which makes posting a message into an SNS topic effectively equivalent
    to posting it into an SQS queueâ€”no transformations or packaging of any sort will
    be applied onto the message.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: ä¸»é¢˜å’Œæ‰‡å‡º/æ‰‡å…¥åŠŸèƒ½é€šè¿‡ [SNS](https://docs.aws.amazon.com/sns/latest/dg/sns-sqs-as-subscriber.html)
    çš„é›†æˆæä¾›ï¼Œå®ƒå·¥ä½œåœ¨*ä¸»é¢˜*çš„æ„é€ ä¸Šã€‚è¿™å…è®¸å°†æ¶ˆæ¯å‘å¸ƒåˆ°ä¸»é¢˜ï¼Œè€Œä¸æ˜¯é˜Ÿåˆ—ã€‚ç„¶åï¼Œæ‚¨å¯ä»¥è®¢é˜…ä»»æ„æ•°é‡çš„ SQS é˜Ÿåˆ—åˆ°ä¸€ä¸ªä¸»é¢˜ä¸­ï¼Œå› æ­¤å‘å¸ƒåˆ°ä¸»é¢˜çš„æ¶ˆæ¯ä¼šç«‹å³å…è´¹å¤åˆ¶åˆ°æ‰€æœ‰è®¢é˜…çš„é˜Ÿåˆ—ã€‚æ‚¨å°†æƒ³è¦å¯ç”¨
    [*raw message*](https://docs.aws.amazon.com/sns/latest/dg/sns-large-payload-raw-message-delivery.html)
    é€‰é¡¹ï¼Œè¿™ä½¿å¾—å°†æ¶ˆæ¯å‘å¸ƒåˆ° SNS ä¸»é¢˜å®é™…ä¸Šç­‰åŒäºå°†å…¶å‘å¸ƒåˆ° SQS é˜Ÿåˆ—ä¸­â€”â€”ä¸ä¼šå¯¹æ¶ˆæ¯è¿›è¡Œä»»ä½•å½¢å¼çš„è½¬æ¢æˆ–æ‰“åŒ…ã€‚
- en: SQS & SNS are both fully managed services, so there are no servers to maintain
    or software to install. You're charged based on the number of messages you send
    and receive, and AWS handles scaling to any load.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: SQS å’Œ SNS éƒ½æ˜¯å®Œå…¨æ‰˜ç®¡çš„æœåŠ¡ï¼Œå› æ­¤æ— éœ€ç»´æŠ¤æœåŠ¡å™¨æˆ–å®‰è£…è½¯ä»¶ã€‚æ‚¨æ ¹æ®å‘é€å’Œæ¥æ”¶æ¶ˆæ¯çš„æ•°é‡æ”¶è´¹ï¼Œè€Œ AWS å¤„ç†ä»»ä½•è´Ÿè½½çš„æ‰©å±•ã€‚
- en: FIFO options are available on [SNS](https://aws.amazon.com/blogs/aws/introducing-amazon-sns-fifo-first-in-first-out-pub-sub-messaging/)
    and [SQS](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html),
    with different pricing and capacity guarantees. AWS uses the term *message group
    ID* to denote a group heading under which all messages are FIFO. Messages inside
    a group heading are delivered in order by not giving out the next message until
    the previous message is deleted.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: åœ¨ [SNS](https://aws.amazon.com/blogs/aws/introducing-amazon-sns-fifo-first-in-first-out-pub-sub-messaging/)
    å’Œ [SQS](https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/FIFO-queues.html)
    ä¸Šéƒ½æä¾›äº† FIFO é€‰é¡¹ï¼Œå…·æœ‰ä¸åŒçš„å®šä»·å’Œå®¹é‡ä¿è¯ã€‚AWS ä½¿ç”¨æœ¯è¯­*æ¶ˆæ¯ç»„ ID*æ¥è¡¨ç¤ºä¸€ä¸ªç»„æ ‡é¢˜ï¼Œè¯¥ç»„æ ‡é¢˜ä¸‹çš„æ‰€æœ‰æ¶ˆæ¯å‡ä¸º FIFOã€‚ç»„æ ‡é¢˜ä¸­çš„æ¶ˆæ¯æŒ‰é¡ºåºä¼ é€’ï¼Œç›´åˆ°å‰ä¸€ä¸ªæ¶ˆæ¯è¢«åˆ é™¤æ‰ä¼šå‘é€ä¸‹ä¸€æ¡æ¶ˆæ¯ã€‚
- en: Google Pub/Sub
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: è°·æ­Œ Pub/Sub
- en: Google provides the [Pub/Sub](https://cloud.google.com/pubsub/docs/overview)
    service as part of their cloud platform to handle message queues and topics in
    an integrated service. The concept of topics exists as you'd expect it, while
    a queue is called a *subscription*. As expected, associating multiple subscriptions
    with a topic will copy the message to all associated subscriptions. Besides allowing
    subscribers to poll, or *pull*, messages from the subscription, Pub/Sub can also
    do a [*webhook*](https://cloud.google.com/pubsub/docs/push) style POST of the
    message to your server, letting you acknowledge it with a success return status
    code.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: è°·æ­Œæä¾› [Pub/Sub](https://cloud.google.com/pubsub/docs/overview) æœåŠ¡ä½œä¸ºå…¶äº‘å¹³å°çš„ä¸€éƒ¨åˆ†ï¼Œç”¨äºå¤„ç†é›†æˆæœåŠ¡ä¸­çš„æ¶ˆæ¯é˜Ÿåˆ—å’Œä¸»é¢˜ã€‚ä¸»é¢˜çš„æ¦‚å¿µå­˜åœ¨å¦‚æ‚¨æ‰€é¢„æœŸçš„é‚£æ ·ï¼Œè€Œé˜Ÿåˆ—è¢«ç§°ä¸º*è®¢é˜…*ã€‚æŒ‰é¢„æœŸï¼Œå°†å¤šä¸ªè®¢é˜…ä¸ä¸€ä¸ªä¸»é¢˜å…³è”å°†æ¶ˆæ¯å¤åˆ¶åˆ°æ‰€æœ‰å…³è”çš„è®¢é˜…ã€‚é™¤äº†å…è®¸è®¢é˜…è€…ä»è®¢é˜…ä¸­æ‹‰å–æ¶ˆæ¯å¤–ï¼ŒPub/Sub
    è¿˜å¯ä»¥é€šè¿‡ [*webhook*](https://cloud.google.com/pubsub/docs/push) æ ·å¼çš„ POST å°†æ¶ˆæ¯å‘é€åˆ°æ‚¨çš„æœåŠ¡å™¨ï¼Œè®©æ‚¨ä½¿ç”¨æˆåŠŸè¿”å›çŠ¶æ€ä»£ç è¿›è¡Œç¡®è®¤ã€‚
- en: This is also a fully managed system, like AWS. You're charged based on the number
    of messages you send, and Google handles scaling the system to whatever capacity
    you need. It also has a few features that aren't available in the SNS+SQS combo,
    like allowing you to look into your historical record using timestamps and [replay
    messages](https://cloud.google.com/pubsub/docs/replay-overview).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¹Ÿæ˜¯ä¸€ä¸ªå®Œå…¨æ‰˜ç®¡çš„ç³»ç»Ÿï¼Œå°±åƒ AWS ä¸€æ ·ã€‚æ‚¨æ ¹æ®å‘é€çš„æ¶ˆæ¯æ•°é‡æ”¶è´¹ï¼Œè°·æ­Œä¼šå¤„ç†ç³»ç»Ÿçš„æ‰©å±•ï¼Œä»¥æ»¡è¶³æ‚¨éœ€è¦çš„ä»»ä½•å®¹é‡ã€‚å®ƒè¿˜å…·æœ‰ä¸€äº› SNS+SQS ç»„åˆä¸­ä¸å¯ç”¨çš„åŠŸèƒ½ï¼Œä¾‹å¦‚å…è®¸æ‚¨ä½¿ç”¨æ—¶é—´æˆ³æŸ¥çœ‹å†å²è®°å½•å¹¶è¿›è¡Œ[é‡æ”¾æ¶ˆæ¯](https://cloud.google.com/pubsub/docs/replay-overview)ã€‚
- en: '[FIFO functionality](https://cloud.google.com/pubsub/docs/ordering) exists
    inside the context of an *ordering key*, which allows you to ensure that messages
    inside an ordering key are processed in sequence by not giving you the next message
    until the previous one has been acknowledged.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[FIFO åŠŸèƒ½](https://cloud.google.com/pubsub/docs/ordering)å­˜åœ¨äº*æ’åºé”®*çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œè¿™å…è®¸æ‚¨ç¡®ä¿åœ¨æ’åºé”®å†…çš„æ¶ˆæ¯æŒ‰é¡ºåºå¤„ç†ï¼Œç›´åˆ°ä¸Šä¸€ä¸ªæ¶ˆæ¯è¢«ç¡®è®¤ä¹‹å‰ï¼Œä¸ä¼šç»™å‡ºä¸‹ä¸€ä¸ªæ¶ˆæ¯ã€‚'
- en: AWS EventBridge
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AWS EventBridge
- en: A new offering from AWS, [EventBridge](https://aws.amazon.com/eventbridge/)
    offers a fully managed *event bus*â€”this is a varition on the concept of queues
    and topics, where all messages are posted into a single bus with no visible topic
    separation. Instead, every message needs to be structured according to a standard
    format that has information about the message topic inside it. The bus will then
    read the message, and route it to whichever subscribers have expressed an interest
    in receiving the messages about that topic. The actual delivery mechanism from
    the bus to the subscriber can be an SQS queue, webhooks, or many other platform
    specific options. This makes it easy to manage the event bus as a separately configurable
    rule-based switchboard, while also allowing easy plugins for archival, auditing,
    monitoring, alerting, replay, etc.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: AWS çš„ä¸€ä¸ªæ–°äº§å“ï¼Œ[EventBridge](https://aws.amazon.com/eventbridge/)æä¾›äº†ä¸€ä¸ªå®Œå…¨æ‰˜ç®¡çš„*äº‹ä»¶æ€»çº¿*â€”è¿™æ˜¯å¯¹é˜Ÿåˆ—å’Œä¸»é¢˜æ¦‚å¿µçš„å˜ç§ï¼Œå…¶ä¸­æ‰€æœ‰æ¶ˆæ¯éƒ½å‘å¸ƒåˆ°ä¸€ä¸ªå•ä¸€çš„æ€»çº¿ä¸­ï¼Œæ²¡æœ‰å¯è§çš„ä¸»é¢˜åˆ†ç¦»ã€‚ç›¸åï¼Œæ¯æ¡æ¶ˆæ¯éƒ½éœ€è¦æŒ‰ç…§ä¸€ä¸ªæ ‡å‡†æ ¼å¼è¿›è¡Œç»“æ„åŒ–ï¼Œå…¶ä¸­åŒ…å«æœ‰å…³æ¶ˆæ¯ä¸»é¢˜çš„ä¿¡æ¯ã€‚æ€»çº¿ç„¶åä¼šè¯»å–æ¶ˆæ¯ï¼Œå¹¶å°†å…¶è·¯ç”±åˆ°å·²è¡¨ç¤ºæœ‰å…´è¶£æ¥æ”¶æœ‰å…³è¯¥ä¸»é¢˜çš„æ¶ˆæ¯çš„è®¢é˜…è€…ã€‚æ€»çº¿åˆ°è®¢é˜…è€…çš„å®é™…äº¤ä»˜æœºåˆ¶å¯ä»¥æ˜¯
    SQS é˜Ÿåˆ—ã€Webhooks æˆ–è®¸å¤šå…¶ä»–å¹³å°ç‰¹å®šé€‰é¡¹ã€‚è¿™ä½¿å¾—å¾ˆå®¹æ˜“å°†äº‹ä»¶æ€»çº¿ç®¡ç†ä¸ºä¸€ä¸ªå•ç‹¬å¯é…ç½®çš„åŸºäºè§„åˆ™çš„äº¤æ¢æœºï¼ŒåŒæ—¶ä¹Ÿå…è®¸æ˜“äºæ’ä»¶åŒ–çš„å­˜æ¡£ã€å®¡è®¡ã€ç›‘è§†ã€è­¦æŠ¥ã€é‡æ”¾ç­‰åŠŸèƒ½ã€‚
- en: Redis Streams
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Redis Streams
- en: Redis has a relatively new [Streams](https://redis.io/topics/streams-intro)
    feature that works great for message queues. It works by creating topics on the
    fly and adding messages to them with the `XADD` command. Reading the messages
    directly off the topic is possible with `XREAD`, so each subscriber can maintain
    its own state (the last read offset) to read through the messages. To avoid each
    subscriber having to maintain its current state, it makes more sense to create
    *consumer groups* using `XGROUP CREATE`, which are the equivalents of queues.
    Each message sent to a topic becomes available independently in each consumer
    group, which can then be subscribed to with `XREADGROUP`. Messages can be acknowledged
    with `XACK`.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Redis å…·æœ‰ä¸€ä¸ªç›¸å¯¹è¾ƒæ–°çš„[Streams](https://redis.io/topics/streams-intro)åŠŸèƒ½ï¼Œéå¸¸é€‚ç”¨äºæ¶ˆæ¯é˜Ÿåˆ—ã€‚å®ƒé€šè¿‡åŠ¨æ€åˆ›å»ºä¸»é¢˜å¹¶ä½¿ç”¨`XADD`å‘½ä»¤å‘å…¶æ·»åŠ æ¶ˆæ¯æ¥å·¥ä½œã€‚é€šè¿‡`XREAD`å¯ä»¥ç›´æ¥ä»ä¸»é¢˜ä¸­è¯»å–æ¶ˆæ¯ï¼Œå› æ­¤æ¯ä¸ªè®¢é˜…è€…éƒ½å¯ä»¥ç»´æŠ¤è‡ªå·±çš„çŠ¶æ€ï¼ˆæœ€åè¯»å–çš„åç§»é‡ï¼‰ä»¥è¯»å–æ¶ˆæ¯ã€‚ä¸ºäº†é¿å…æ¯ä¸ªè®¢é˜…è€…éƒ½å¿…é¡»ç»´æŠ¤å…¶å½“å‰çŠ¶æ€ï¼Œä½¿ç”¨`XGROUP
    CREATE`åˆ›å»º*æ¶ˆè´¹è€…ç»„*æ›´åˆç†ï¼Œå®ƒä»¬æ˜¯é˜Ÿåˆ—çš„ç­‰ä»·ç‰©ã€‚å‘é€åˆ°ä¸»é¢˜çš„æ¯æ¡æ¶ˆæ¯åœ¨æ¯ä¸ªæ¶ˆè´¹è€…ç»„ä¸­éƒ½ç‹¬ç«‹å¯ç”¨ï¼Œç„¶åå¯ä»¥ä½¿ç”¨`XREADGROUP`è®¢é˜…ã€‚å¯ä»¥ä½¿ç”¨`XACK`ç¡®è®¤æ¶ˆæ¯ã€‚
- en: The Redis Streams are automatically FIFO ordered using a timestamp that can
    either be auto-generated or manually set. This also means that messages can only
    be processed by one consumer agent at a time. To get around this limitation and
    work with many consumer agents in parallel, there's a separate non-streams-based
    pattern described in the documentation for `[RPOPLPUSH](https://redis.io/commands/rpoplpush#pattern-reliable-queue)`â€”basically
    `LPUSH` messages into a topic, and then `RPOPLPUSH` them into other lists, each
    representing a queue, or more accurately its work in progress. `LREM` works to
    delete/acknowledge the message.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Redis Streams ä½¿ç”¨æ—¶é—´æˆ³è‡ªåŠ¨è¿›è¡Œ FIFO æ’åºï¼Œè¯¥æ—¶é—´æˆ³å¯ä»¥è‡ªåŠ¨ç”Ÿæˆæˆ–æ‰‹åŠ¨è®¾ç½®ã€‚è¿™ä¹Ÿæ„å‘³ç€æ¶ˆæ¯ä¸€æ¬¡åªèƒ½ç”±ä¸€ä¸ªæ¶ˆè´¹è€…ä»£ç†å¤„ç†ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé™åˆ¶å¹¶ä¸è®¸å¤šæ¶ˆè´¹è€…ä»£ç†å¹¶è¡Œå·¥ä½œï¼Œæ–‡æ¡£ä¸­æè¿°äº†ä¸€ä¸ªå•ç‹¬çš„éæµå¼æ¨¡å¼ï¼ŒåŸºæœ¬ä¸Šæ˜¯å°†æ¶ˆæ¯`LPUSH`åˆ°ä¸€ä¸ªä¸»é¢˜ä¸­ï¼Œç„¶åå°†å®ƒä»¬`RPOPLPUSH`åˆ°å…¶ä»–åˆ—è¡¨ä¸­ï¼Œæ¯ä¸ªåˆ—è¡¨ä»£è¡¨ä¸€ä¸ªé˜Ÿåˆ—ï¼Œæˆ–æ›´å‡†ç¡®åœ°è¯´æ˜¯å…¶è¿›è¡Œä¸­çš„å·¥ä½œã€‚`LREM`ç”¨äºåˆ é™¤/ç¡®è®¤æ¶ˆæ¯ã€‚
- en: Redis is an open source system that you can install and maintain yourself or
    find managed hosting for. Depending on how durable you need the system to be you
    might want to figure out the best [persistence](https://redis.io/topics/persistence)
    mechanism to use.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Redis æ˜¯ä¸€ä¸ªå¼€æºç³»ç»Ÿï¼Œæ‚¨å¯ä»¥è‡ªè¡Œå®‰è£…å’Œç»´æŠ¤ï¼Œæˆ–æ‰¾åˆ°æ‰˜ç®¡æœåŠ¡æä¾›å•†ã€‚æ ¹æ®æ‚¨éœ€è¦ç³»ç»ŸæŒä¹…æ€§çš„ç¨‹åº¦ï¼Œæ‚¨å¯èƒ½éœ€è¦ç¡®å®šæœ€ä½³çš„[æŒä¹…æ€§](https://redis.io/topics/persistence)æœºåˆ¶ã€‚
- en: Apache Kafka
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Apache Kafka
- en: '[Kakfa](https://kafka.apache.org/documentation/) is a popular message broker
    that works on the concepts of *producers* publishing messages, called *events*,
    to *topics*. The events in a topic are split into *partitions*, using a partition
    key inside of the topic, and FIFO ordering is maintained inside every partition.
    Events can be streamed to *consumers* over a socket, or queried by the consumers
    for a more decoupled approach. For consumers that don''t want to maintain state,
    the concept of a *consumer group* applies, same as Redis Streams. A *consumer
    group* is effectively a queue, where every event posted to a topic is available
    for processing in every associated *consumer group*.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '[Kafka](https://kafka.apache.org/documentation/) æ˜¯ä¸€æ¬¾æµè¡Œçš„æ¶ˆæ¯ä»£ç†ï¼Œå…¶å·¥ä½œåŸç†åŸºäº *ç”Ÿäº§è€…* å‘å¸ƒæ¶ˆæ¯ï¼ˆç§°ä¸º
    *äº‹ä»¶*ï¼‰åˆ° *ä¸»é¢˜*ã€‚ä¸»é¢˜ä¸­çš„äº‹ä»¶æ ¹æ®ä¸»é¢˜å†…çš„åˆ†åŒºé”®åˆ†æˆ *åˆ†åŒº*ï¼Œæ¯ä¸ªåˆ†åŒºå†…ä¿æŒ FIFO æ’åºã€‚äº‹ä»¶å¯ä»¥é€šè¿‡å¥—æ¥å­—æµå¼ä¼ è¾“ç»™ *æ¶ˆè´¹è€…*ï¼Œæˆ–è€…ç”±æ¶ˆè´¹è€…æŸ¥è¯¢ä»¥å®ç°æ›´è§£è€¦çš„æ–¹æ³•ã€‚å¯¹äºä¸å¸Œæœ›ç»´æŠ¤çŠ¶æ€çš„æ¶ˆè´¹è€…ï¼Œ*æ¶ˆè´¹è€…ç»„*
    çš„æ¦‚å¿µé€‚ç”¨ï¼Œä¸ Redis Streams ç›¸åŒã€‚*æ¶ˆè´¹è€…ç»„* å®é™…ä¸Šæ˜¯ä¸€ä¸ªé˜Ÿåˆ—ï¼Œä¸»é¢˜ä¸­å‘å¸ƒçš„æ¯ä¸ªäº‹ä»¶éƒ½å¯ä»¥åœ¨ä¸ä¹‹å…³è”çš„æ¯ä¸ª *æ¶ˆè´¹è€…ç»„* ä¸­è¿›è¡Œå¤„ç†ã€‚'
- en: Kafka is open source, but is a complicated to install and maintain, which makes
    it suitable for larger projects and teams. It scales based on how well you split
    your events in to partitionsâ€”the more partitions you have the more Kafka can distribute
    work, and each partition has only as much capacity as the server that's in charge
    of managing it. Managed hosting options are avaiable, but they tend to have high
    base costs compared to managed services like SNS+SQS, Pub/Sub or RabbitMQ.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Kafka æ˜¯å¼€æºçš„ï¼Œä½†æ˜¯å®‰è£…å’Œç»´æŠ¤èµ·æ¥ç›¸å¯¹å¤æ‚ï¼Œè¿™ä½¿å¾—å®ƒé€‚ç”¨äºæ›´å¤§çš„é¡¹ç›®å’Œå›¢é˜Ÿã€‚å®ƒæ ¹æ®ä½ å¦‚ä½•å°†äº‹ä»¶æ‹†åˆ†æˆåˆ†åŒºæ¥æ‰©å±•â€”â€”åˆ†åŒºè¶Šå¤šï¼ŒKafka åˆ†å‘å·¥ä½œçš„èƒ½åŠ›å°±è¶Šå¼ºï¼Œæ¯ä¸ªåˆ†åŒºçš„å®¹é‡ä»…å–å†³äºè´Ÿè´£ç®¡ç†å®ƒçš„æœåŠ¡å™¨ã€‚æœ‰æ‰˜ç®¡é€‰é¡¹å¯ç”¨ï¼Œä½†ä¸åƒ
    SNS+SQSã€Pub/Sub æˆ– RabbitMQ è¿™æ ·çš„æ‰˜ç®¡æœåŠ¡ç›¸æ¯”ï¼Œå®ƒä»¬å¾€å¾€å…·æœ‰è¾ƒé«˜çš„åŸºæœ¬æˆæœ¬ã€‚
- en: RabbitMQ
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RabbitMQ
- en: RabbitMQ is a popular open source message broker that supports a variety of
    [protocols](https://www.rabbitmq.com/protocols.html), with [direct support](https://www.rabbitmq.com/tutorials/tutorial-five-python.html)
    for the concepts of topics and queues. RabbitMQ operates under both *at-most-once*
    and *at-least-once* modes, with *at-most-once* being a fast memory based mode
    that occasionally writes messages to the disk if necessary (you can choose between
    pesisted or transient queues). If you want a more reliable, but slower, at-least-once
    system, you can use the operations described in the [reliability guide](https://www.rabbitmq.com/reliability.html)
    to ask for *confirmations* when publishing messages, and require mandatory *acknowledgements*
    when reading them. Queues are FIFO by default, with the option to enforce sequential
    processing with acknowledgements.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: RabbitMQ æ˜¯ä¸€æ¬¾æµè¡Œçš„å¼€æºæ¶ˆæ¯ä»£ç†ï¼Œæ”¯æŒå„ç§[åè®®](https://www.rabbitmq.com/protocols.html)ï¼Œå¹¶ç›´æ¥æ”¯æŒä¸»é¢˜å’Œé˜Ÿåˆ—çš„æ¦‚å¿µã€‚RabbitMQ
    åœ¨ *è‡³å¤šä¸€æ¬¡* å’Œ *è‡³å°‘ä¸€æ¬¡* ä¸¤ç§æ¨¡å¼ä¸‹è¿è¡Œï¼Œå…¶ä¸­ *è‡³å¤šä¸€æ¬¡* æ˜¯ä¸€ç§å¿«é€Ÿçš„åŸºäºå†…å­˜çš„æ¨¡å¼ï¼Œå¦‚æœéœ€è¦ï¼Œå¶å°”ä¼šå°†æ¶ˆæ¯å†™å…¥ç£ç›˜ï¼ˆæ‚¨å¯ä»¥åœ¨æŒä¹…åŒ–æˆ–ç¬æ€é˜Ÿåˆ—ä¹‹é—´è¿›è¡Œé€‰æ‹©ï¼‰ã€‚å¦‚æœæ‚¨å¸Œæœ›è·å¾—æ›´å¯é ä½†é€Ÿåº¦è¾ƒæ…¢çš„è‡³å°‘ä¸€æ¬¡ç³»ç»Ÿï¼Œå¯ä»¥ä½¿ç”¨[å¯é æ€§æŒ‡å—](https://www.rabbitmq.com/reliability.html)ä¸­æè¿°çš„æ“ä½œåœ¨å‘å¸ƒæ¶ˆæ¯æ—¶è¯·æ±‚
    *ç¡®è®¤*ï¼Œå¹¶åœ¨è¯»å–æ—¶è¦æ±‚å¼ºåˆ¶æ€§çš„ *ç¡®è®¤*ã€‚é˜Ÿåˆ—é»˜è®¤ä¸º FIFOï¼Œå¯ä»¥é€‰æ‹©ä½¿ç”¨ç¡®è®¤å¼ºåˆ¶é¡ºåºå¤„ç†ã€‚
- en: NSQ
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NSQ
- en: The first truly distributed message queue in this list, [NSQ](https://nsq.io)
    is interesting because it's built from the group up to be decentralized. There's
    no single point to connect to to publish or subscribe to messagesâ€”every NSQ node
    is effectively a full server and talks to every other node. The nodes allow you
    to publish messages to *topics*, and each topic can be linked to one or more *channels*â€”which
    are the equivalent of queues. Every message published to a topic is available
    in all its linked *channels*.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™ä¸ªåˆ—è¡¨ä¸­ç¬¬ä¸€ä¸ªçœŸæ­£åˆ†å¸ƒå¼çš„æ¶ˆæ¯é˜Ÿåˆ—æ˜¯ [NSQ](https://nsq.io)ï¼Œå®ƒå¾ˆæœ‰è¶£ï¼Œå› ä¸ºå®ƒä»ä¸€å¼€å§‹å°±æ˜¯åˆ†æ•£å¼æ„å»ºçš„ã€‚æ²¡æœ‰å•ä¸€ç‚¹å¯ä»¥è¿æ¥åˆ°ä»¥å‘å¸ƒæˆ–è®¢é˜…æ¶ˆæ¯â€”â€”æ¯ä¸ª
    NSQ èŠ‚ç‚¹å®é™…ä¸Šéƒ½æ˜¯ä¸€ä¸ªå®Œæ•´çš„æœåŠ¡å™¨ï¼Œå¹¶ä¸æ¯ä¸ªå…¶ä»–èŠ‚ç‚¹é€šä¿¡ã€‚èŠ‚ç‚¹å…è®¸æ‚¨å°†æ¶ˆæ¯å‘å¸ƒåˆ° *ä¸»é¢˜*ï¼Œå¹¶ä¸”æ¯ä¸ªä¸»é¢˜å¯ä»¥é“¾æ¥åˆ°ä¸€ä¸ªæˆ–å¤šä¸ª *é€šé“* â€”â€” è¿™ç›¸å½“äºé˜Ÿåˆ—ã€‚å‘å¸ƒåˆ°ä¸»é¢˜çš„æ¯æ¡æ¶ˆæ¯éƒ½å¯åœ¨å…¶æ‰€æœ‰é“¾æ¥çš„
    *é€šé“* ä¸­ä½¿ç”¨ã€‚
- en: NSQ is [defaults](https://nsq.io/overview/features_and_guarantees.html) to non-durable,
    at-least-once, un-ordered messaging, but has a few configuration options to tweak
    things. It's specially worth considering if your servers are highly networked
    with each other and you want a system without a single point of failure.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: NSQé»˜è®¤ä¸ºéæŒä¹…åŒ–ã€è‡³å°‘ä¸€æ¬¡ã€æ— åºçš„æ¶ˆæ¯ä¼ é€’ï¼Œä½†æœ‰ä¸€äº›é…ç½®é€‰é¡¹å¯ä»¥è°ƒæ•´ã€‚å¦‚æœä½ çš„æœåŠ¡å™¨å½¼æ­¤é«˜åº¦è”ç½‘ï¼Œå¹¶ä¸”ä½ å¸Œæœ›ä¸€ä¸ªæ²¡æœ‰å•ç‚¹æ•…éšœçš„ç³»ç»Ÿï¼Œé‚£ä¹ˆè€ƒè™‘NSQæ˜¯ç‰¹åˆ«å€¼å¾—çš„ã€‚
- en: NATS
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: NATS
- en: '[NATS](https://docs.nats.io/) is a high performance distributed messaging system
    that''s made for fast in-memory messaging. It supports topic based [broadcast](https://docs.nats.io/nats-concepts/pubsub)
    (topics are called *subjects*), where all messages sent to the *subject* are sent
    to all subscriber agents; and [distributed queues](https://docs.nats.io/nats-concepts/queue),
    where each message in the queue is sent to any one subscriber agent. There isn''t
    a built-in way to have topics linked to queues, but that should be possible to
    do programmatically.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[NATS](https://docs.nats.io/)æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„åˆ†å¸ƒå¼æ¶ˆæ¯ç³»ç»Ÿï¼Œä¸“ä¸ºå¿«é€Ÿå†…å­˜æ¶ˆæ¯ä¼ é€’è€Œè®¾è®¡ã€‚å®ƒæ”¯æŒåŸºäºä¸»é¢˜çš„[å¹¿æ’­](https://docs.nats.io/nats-concepts/pubsub)ï¼ˆä¸»é¢˜ç§°ä¸º*ä¸»é¢˜*ï¼‰ï¼Œå…¶ä¸­æ‰€æœ‰å‘é€åˆ°*ä¸»é¢˜*çš„æ¶ˆæ¯éƒ½å‘é€åˆ°æ‰€æœ‰è®¢é˜…ä»£ç†ï¼›ä»¥åŠ[åˆ†å¸ƒå¼é˜Ÿåˆ—](https://docs.nats.io/nats-concepts/queue)ï¼Œé˜Ÿåˆ—ä¸­çš„æ¯æ¡æ¶ˆæ¯éƒ½å‘é€åˆ°ä»»ä½•ä¸€ä¸ªè®¢é˜…ä»£ç†ã€‚è™½ç„¶æ²¡æœ‰å†…ç½®çš„æ–¹æ³•å°†ä¸»é¢˜é“¾æ¥åˆ°é˜Ÿåˆ—ï¼Œä½†åº”è¯¥å¯ä»¥é€šè¿‡ç¼–ç¨‹æ–¹å¼å®ç°ã€‚'
- en: NATS supports both *at-most-once* and *at-least-once* delivery, and by providing
    a [streaming system](https://docs.nats.io/nats-streaming-concepts/intro) and an
    [experimental persistence system](https://github.com/nats-io/jetstream). It also
    has support for subscribing to multiple topics based on subject name patterns,
    which makes it easier to do fan-in and multi-tenancy.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: NATS æ”¯æŒ*è‡³å¤šä¸€æ¬¡*å’Œ*è‡³å°‘ä¸€æ¬¡*äº¤ä»˜ï¼Œå¹¶æä¾›äº†ä¸€ä¸ª[æµç³»ç»Ÿ](https://docs.nats.io/nats-streaming-concepts/intro)å’Œä¸€ä¸ª[å®éªŒæ€§æŒä¹…åŒ–ç³»ç»Ÿ](https://github.com/nats-io/jetstream)ã€‚å®ƒè¿˜æ”¯æŒæ ¹æ®ä¸»é¢˜åç§°æ¨¡å¼è®¢é˜…å¤šä¸ªä¸»é¢˜ï¼Œè¿™ä½¿å¾—è¿›è¡Œæ‰‡å…¥å’Œå¤šç§Ÿæˆ·å˜å¾—æ›´å®¹æ˜“ã€‚
- en: NATS works great when you need a high throughput distributed systemâ€”it's also
    pretty easy to run, and supports complex network topology, like having regional
    clusters with connections between them.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: NATS åœ¨éœ€è¦é«˜ååé‡åˆ†å¸ƒå¼ç³»ç»Ÿæ—¶æ•ˆæœå¾ˆå¥½â€”â€”è€Œä¸”è¿è¡Œèµ·æ¥ä¹Ÿç›¸å½“å®¹æ˜“ï¼Œå¹¶æ”¯æŒå¤æ‚çš„ç½‘ç»œæ‹“æ‰‘ç»“æ„ï¼Œæ¯”å¦‚åœ¨åŒºåŸŸé›†ç¾¤ä¹‹é—´å»ºç«‹è¿æ¥ã€‚
- en: The Tail Message
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: å°¾æ¶ˆæ¯
- en: These are just a few of the options available right now, and still more are
    being developed as distributed computing develops and cloud providers grow. I've
    found that the important thing when evaluating or using queueing systems is to
    understand the semantics & guarantees they offer. I do this by reading their architectural
    overviews to get rough idea of how they're implemented. Beneath the surface, the
    same concepts apply to all of them, just under different name and configuration
    options.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: è¿™äº›åªæ˜¯å½“å‰å¯ç”¨çš„ä¸€äº›é€‰é¡¹ï¼Œéšç€åˆ†å¸ƒå¼è®¡ç®—çš„å‘å±•å’Œäº‘æä¾›å•†çš„å¢é•¿ï¼Œè¿˜ä¼šæœ‰æ›´å¤šçš„é€‰é¡¹æ­£åœ¨è¢«å¼€å‘ã€‚æˆ‘å‘ç°åœ¨è¯„ä¼°æˆ–ä½¿ç”¨é˜Ÿåˆ—ç³»ç»Ÿæ—¶ï¼Œé‡è¦çš„æ˜¯è¦ç†è§£å®ƒä»¬æä¾›çš„è¯­ä¹‰å’Œä¿è¯ã€‚æˆ‘é€šè¿‡é˜…è¯»å®ƒä»¬çš„æ¶æ„æ¦‚è¿°æ¥äº†è§£å®ƒä»¬æ˜¯å¦‚ä½•å®ç°çš„ã€‚åœ¨è¡¨é¢ä¹‹ä¸‹ï¼Œæ‰€æœ‰è¿™äº›ç³»ç»Ÿéƒ½é€‚ç”¨ç›¸åŒçš„æ¦‚å¿µï¼Œåªæ˜¯åœ¨ä¸åŒçš„åç§°å’Œé…ç½®é€‰é¡¹ä¸‹ã€‚
- en: If you're running your workloads in a particular cloud provider, the default
    topic/queue system they offer will usually work fine, as long as you understand
    what semantics they're offering in each mode. If you're managing your own installation
    of a queue system, the same thing appliesâ€”except you need to be a lot more concerned
    about the limit imposed by the operating decisions you're making, like how many
    nodes you're running, failover configuration, drive space, etc.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: å¦‚æœä½ åœ¨ç‰¹å®šçš„äº‘æä¾›å•†ä¸Šè¿è¡Œå·¥ä½œè´Ÿè½½ï¼Œä»–ä»¬æä¾›çš„é»˜è®¤ä¸»é¢˜/é˜Ÿåˆ—ç³»ç»Ÿé€šå¸¸ä¼šå¾ˆå¥½åœ°å·¥ä½œï¼Œåªè¦ä½ äº†è§£æ¯ç§æ¨¡å¼æä¾›çš„è¯­ä¹‰ã€‚å¦‚æœä½ ç®¡ç†è‡ªå·±çš„é˜Ÿåˆ—ç³»ç»Ÿå®‰è£…ï¼Œæƒ…å†µä¹Ÿæ˜¯ä¸€æ ·çš„â€”â€”åªæ˜¯ä½ éœ€è¦æ›´åŠ å…³æ³¨ä½ æ‰€åšæ“ä½œå†³ç­–æ‰€æ–½åŠ çš„é™åˆ¶ï¼Œæ¯”å¦‚è¿è¡Œçš„èŠ‚ç‚¹æ•°é‡ã€æ•…éšœè½¬ç§»é…ç½®ã€é©±åŠ¨å™¨ç©ºé—´ç­‰ç­‰ã€‚
- en: Thanks for reading, reach out to me [@sudhirj](https://twitter.com/sudhirj)
    or join the discussion on [Hacker News](https://news.ycombinator.com/item?id=25591492)
    if you have questions or disagree with anything.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: æ„Ÿè°¢é˜…è¯»ï¼Œè¯·é€šè¿‡[@sudhirj](https://twitter.com/sudhirj)ä¸æˆ‘è”ç³»ï¼Œæˆ–åœ¨[Hacker News](https://news.ycombinator.com/item?id=25591492)ä¸Šå‚ä¸è®¨è®ºï¼Œå¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–ä¸åŒæ„ä»€ä¹ˆã€‚
- en: Special thanks to [@svethacvl](https://twitter.com/svethacvl) for proofreading,
    and [@wallyqs](https://twitter.com/wallyqs) for notes on NATS.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: ç‰¹åˆ«æ„Ÿè°¢[@svethacvl](https://twitter.com/svethacvl)è¿›è¡Œæ ¡å¯¹ï¼Œä»¥åŠ[@wallyqs](https://twitter.com/wallyqs)æä¾›å…³äºNATSçš„ç¬”è®°ã€‚
