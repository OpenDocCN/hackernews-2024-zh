- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 15:13:05'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Are we at peak vector database?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://softwaredoug.com/blog/2024/01/24/are-we-at-peak-vector-db](https://softwaredoug.com/blog/2024/01/24/are-we-at-peak-vector-db)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As both a search person and something of a veteran of the NoSQL days, I wonder
    to myself, often, “how can so many vector databases need to exist?”.
  prefs: []
  type: TYPE_NORMAL
- en: Even in our current AI age, where everyone and their mom is trying to build
    the next chat / AI powered whatever. Even today when it seems everyone is putting
    vectors somewhere to retrieve them…
  prefs: []
  type: TYPE_NORMAL
- en: I have to ask the tough question - when have we reached peak vector DB? Do we
    have enough choices for the specific task of storing and retrieving vectors?
  prefs: []
  type: TYPE_NORMAL
- en: 'Just on cursory listing, I can think of the following vector databases, libraries,
    whatever:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pure Vector DBs**'
  prefs: []
  type: TYPE_NORMAL
- en: Pinecone
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: QDrant
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Milvus / Zilliz
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weaviate
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Turbopuffer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MyScale
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Open Source search engines**'
  prefs: []
  type: TYPE_NORMAL
- en: Solr
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elasticsearch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenSearch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vespa
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Libraries**'
  prefs: []
  type: TYPE_NORMAL
- en: Annoy,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: FAISS,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NMSLib
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HNSWLib
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lucene
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chroma
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (a million others)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Open Source DBs**'
  prefs: []
  type: TYPE_NORMAL
- en: Redis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PGVector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cassandra, Mongo, etc etc (every DB seems to be getting its vector index :wink:
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud solutions**'
  prefs: []
  type: TYPE_NORMAL
- en: Google Vertex
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure AI Search
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (more at [awesome vector search](https://github.com/currentslab/awesome-vector-search))
  prefs: []
  type: TYPE_NORMAL
- en: If we take vector search as one type of data store in the NoSQL paradigm, we
    might put it in its own category. We would say Mongo is a document database alongside
    CouchDB and pals. We would say Cassandra is a columnar data store, alongside the
    Scylla or HBase.
  prefs: []
  type: TYPE_NORMAL
- en: So in each category, we have a handful (2-3). Yet in vector search, we have
    dozens upon dozens of options. As a “customer” of such options, the field becomes
    overwhelming.
  prefs: []
  type: TYPE_NORMAL
- en: And vector retrieval increasingly isn’t the problem. The hard problems of solving
    real-world retrieval are not related to just getting vectors, it’s everything
    around it
  prefs: []
  type: TYPE_NORMAL
- en: Intent classification - given a “query” how do I know whether I can solve the
    problem or not (RAG) or how to route the query to the correct place Inference
    and reranking - given a “query”, and some candidate retrieved vectors / items,
    how do I perform inference on say, an arbitrary tensorflow model, to give the
    most relevant items? Diversity - given a “query” how do I broaden the candidate
    pool to more than just “similar to vectors” - to get at not just one intent, but
    all possible intents Lexical retrieval / hybrid search - given natural language,
    how do I use direct lexical signals (boring old BM25, just filtering, whatever)
    to give relevant results
  prefs: []
  type: TYPE_NORMAL
- en: OK and that’s just the lexical side. We’re inventing new ways of interacting
    with data. Nobody I talk to has really created a robust way to evaluate quality
    of context for RAG. There’s new UX paradigms out there - chat and chat-adjacent
    - that we’re experimenting with.
  prefs: []
  type: TYPE_NORMAL
- en: The challenge being, the world is wide open for experimentation, yet on first
    blush, all the money is being concentrated in one part of the stack. We’re not
    looking at the problem holistically.
  prefs: []
  type: TYPE_NORMAL
- en: Why we’re not at peak vector DB
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: OK, that’s one argument, sure.
  prefs: []
  type: TYPE_NORMAL
- en: Here’s the other point of view.
  prefs: []
  type: TYPE_NORMAL
- en: There needs to be a place to focus on, and rethink, retrieval problems. In the
    same way NoSQL forced us to rethink databases. Capital and brainpower need a place
    to zero in on how to solve this next generation of retrieval + relevance problems.
  prefs: []
  type: TYPE_NORMAL
- en: So the old, curmudgeonly search person in me would say “well whatever, people
    realize they need search engines and use Solr / Elasticsearch anyway”.
  prefs: []
  type: TYPE_NORMAL
- en: But that’s not good enough. These search tools feel esoteric, in the average
    “AI Engineers” mind, they will think first of vector retrieval, then stumble into
    all the problems I list above. They’ll learn they need to care about all the things
    beyond ANN, but only after their app is stood up. In the same way the search engineers
    of yore backed into all kinds of problems only after comitting to a big Solr or
    Elasticsearch installation.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, I suspect, more and more surfaces will be driven by some retrieval-ish
    thing. Search-but-not-search. Real-time recommendations, but driven by vector
    (and other kinds of) retrieval that looks more like a search engine - not batch
    computed, nightly jobs common these days. I wrote about the coming revolution
    of “Relevance Driven Applications” in 2016, and now, its happening - not with
    boring old search engines as I once thought - but by reinventing our whole notion
    of the retrieval layer that drives user experiences.
  prefs: []
  type: TYPE_NORMAL
- en: So, I suspect the smart people at these companies will branch out beyond “making
    ANN better / more scalable” to building complete retrieval and ranking systems
    solving a tremendous array of problems. The money and effort will flow to where
    the customers see the problem.
  prefs: []
  type: TYPE_NORMAL
- en: In the end, like in NoSQL, we may end up with SQL again (but with all the NoSQL
    innovations). Or, in other words, we may end up with these vendors building a
    full blown “search engine”. Yet these new search engines will have many more batteries
    included the AI/Chat/RAG/whatever experiences people increasingly reach for.
  prefs: []
  type: TYPE_NORMAL
