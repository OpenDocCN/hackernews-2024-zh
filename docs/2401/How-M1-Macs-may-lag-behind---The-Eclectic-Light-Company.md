<!--yml

类别：未分类

日期：2024 年 05 月 27 日 14:45:24

-->

# M1 Mac 可能会落后 - 《The Eclectic Light Company》

> 来源：[`eclecticlight.co/2024/01/13/how-m1-macs-may-lag-behind/`](https://eclecticlight.co/2024/01/13/how-m1-macs-may-lag-behind/)

不管你喜欢还是讨厌，AI 似乎已经来了，并且以机器学习（ML）的形式已经改变了我们的 Mac。使用 Spotlight、Siri、文字自动补全或任何图像处理工具，你都会受益于它们。苹果硅片芯片在其 GPU 和 ANE 中包含了对 AI 和 ML 的复杂硬件支持，ANE 是专用的神经引擎。虽然后者目前可能是芯片中使用最少的部分，但这一情况正在迅速改变，而且苹果计划在不久的将来发布更多的支持。一个线索出现在 Sonoma 14.2 中的一个名为 DeepThought 的新私有框架中。

但并非所有的 M 系列芯片在这方面都是相等的：M1 芯片对最近的 AI/ML 功能的支持更有限，包括已成为近乎普遍的浮点数格式，bfloat16。没有这个，搭载 M1 芯片的 Mac 在运行 AI 和 ML 功能时很可能仍然处于显著劣势。

在计算机使用的二进制格式中表示整数（整数）相对简单：位数越多，可以表示的数字越大。用一个十六进制数位，你可以得到 0-15 的十进制数；将两个十六进制数位加倍，范围就从 0 到 255。如果你想要负数，那么只需设置一个位来指示，范围可以从-128 到+127。

表示浮点数的最常见方法是将它们表示为类似于十进制科学或工程格式的格式。后者使用一个符号（+或-）、一个小数部分和一个指数。例如，数字-1,234,567.89 可以表示为 1.23456789 x 10⁶（10 的六次方）带有负号：这个数的小数部分为 1.23456789，指数为 6。由于是计算机，因此不是使用十的幂作为指数，而是使用二的幂。

最常见的浮点数格式是 IEEE 754 标准的格式，其中单精度 32 位浮点数有一个符号位，一个 8 位的指数，和 23 位用于包含小数部分。允许的指数大小确定了该格式中可以表示的浮点数的范围，而允许的小数部分大小确定了任何数字可以有多精确。

随着人工智能和机器学习的最新快速发展，出现了几种新的浮点数格式，其中包括被称为 bfloat16 的格式，它具有一个符号位，一个 8 位的指数，与单精度 32 位浮点数一样，但只有 7 位用于包含小数部分。与 32 位标准相比，在半数的比特数中，bfloat16 数字以较低的精度覆盖相同的范围。据称，这对于人工智能、机器学习和智能传感器技术的使用是理想的。

bfloat16 是作为谷歌 Brain 项目的一部分开发的，在过去几年里迅速被 Intel、AMD 和 Arm 处理器广泛采用，并且在用于人工智能和机器学习的工具和库中得到广泛支持。至于苹果的 M 系列芯片，M2 和 M3 CPU 支持 ARMv8.6A 指令集，其中包括 bfloat16 支持，但 M1 只支持 ARMv8.5A，不包括此支持。GPU 和苹果的神经引擎（ANE）对 bfloat16 的支持程度不太清楚，尽管[M1 ANE 的工作](https://github.com/hollance/neural-engine/blob/master/docs/16-bit.md)表明它全程使用 float16（可能是 IEEE 半精度 16 位浮点数）。考虑到 2020 年底首批 M1 芯片已交付至 M1 Mac，苹果很可能无法在设计中加入对 bfloat16 的支持。

如果 bfloat16 的使用像通常所宣称的那样有优势，那么 M1 Mac 与 M2 及更高型号相比仍然存在显著劣势。随着苹果和第三方推出更多以人工智能和机器学习为核心的产品，如果它们在 M1 Mac 上的性能与其 M2 和 M3 后继机型相比令人失望，那也不足为奇。

与此相比，英特尔的 Mac 则更为严峻，因为它们缺乏任何硬件支持人工智能和机器学习的功能，并且已经被淘汰。

**参考**

[维基百科](https://en.wikipedia.org/wiki/Bfloat16_floating-point_format)
