- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:58:43'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'DeepMind Founder at Davos: AI Is Fundamentally a "Labor Replacing Tool"'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://gizmodo.com/deepmind-founder-ai-davos-mustafa-suleyman-openai-jobs-1851176340](https://gizmodo.com/deepmind-founder-ai-davos-mustafa-suleyman-openai-jobs-1851176340)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Welcome to AI This Week, Gizmodo’s weekly deep dive on what’s been happening
    in artificial intelligence.*'
  prefs: []
  type: TYPE_NORMAL
- en: Why is Everyone Suing AI Companies? | Future Tech
  prefs: []
  type: TYPE_NORMAL
- en: <track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/20725.vtt"
    srclang="en">
  prefs: []
  type: TYPE_NORMAL
- en: 'For months, I’ve been [harping](https://gizmodo.com/chatgpt-ai-buzzfeed-news-journalism-existential-threat-1849869364)
    on a particular point, which is that artificial intelligence tools—as they’re
    currently being deployed—are mostly good at one thing: Replacing human employees.
    The [“AI revolution”](https://www.ft.com/content/f84bd56f-484d-4393-bafc-4428da6a7873)
    has mostly been a corporate one, an insurrection against the rank-and-file that
    leverages new technologies to reduce a company’s overall headcount. The biggest
    sellers of AI have been [very open about this](https://www.cnbc.com/2023/08/22/ibm-ceo-says-ai-will-impact-white-collar-jobs-first.html#:~:text=create%20more%20GDP.-,We%20should%20all%20feel%20better%20about%20it%2C%E2%80%9D%20said%20Krishna.,won''t%20kill%20jobs%20completely.)—admitting
    time and again that new forms of automation will allow human jobs to be repurposed
    as software.'
  prefs: []
  type: TYPE_NORMAL
- en: We got another dose of that this week, when the founder of Google’s DeepMind,
    Mustafa Suleyman, sat down for [an interview](https://www.youtube.com/watch?v=Go_6UldZL50)
    with CNBC. Suleyman was in Davos, Switzerland, for the World Economic Forum’s
    [annual get-together](https://gizmodo.com/sam-altman-openai-davos-wef-ai-needs-to-go-nuclear-1851173201),
    where AI was [reportedly](https://www.axios.com/2024/01/19/davos-2024-wef-ai-artificial-intelligence)
    the most popular topic of conversation. During his interview, Suleyman was asked
    by news anchor Rebecca Quirk whether AI was “going to replace humans in the workplace
    in massive amounts.”
  prefs: []
  type: TYPE_NORMAL
- en: 'The tech CEO’s answer was this: “I think in the long term—over many decades—we
    have to think very hard about how we integrate these tools because, left completely
    to the market...these are fundamentally labor replacing tools.”'
  prefs: []
  type: TYPE_NORMAL
- en: And there it is. Suleyman makes this sound like some foggy future hypothetical
    but it’s obvious that said “labor replacement” is already happening. The tech
    and media industries—which [are uniquely exposed](https://www.cnbc.com/2023/10/27/ai-exposure-is-new-buzz-term-for-softening-talk-about-job-losses.html)
    to the threat of AI-related job losses—saw huge layoffs last year, right as AI
    was “coming online.” In only the first few weeks of January, well-established
    companies like Google, Amazon, YouTube, Salesforce, and others have announced
    more aggressive layoffs that have been [explicitly linked](https://www.axios.com/2024/01/18/tech-layoffs-ai-2024-google-amazon)
    to greater AI deployment.
  prefs: []
  type: TYPE_NORMAL
- en: The [general consensus](https://www.axios.com/2024/01/18/tech-layoffs-ai-2024-google-amazon)
    in corporate America seems to be that companies should use AI to operate leaner
    teams, the likes of which can be bolstered by small groups of AI-savvy professionals.
    These AI professionals will become an increasingly sought after class of worker,
    as they’ll offer the opportunity to reorganize corporate structures around automation,
    thus making them more “efficient.”
  prefs: []
  type: TYPE_NORMAL
- en: For companies, the benefits of this are obvious. You don’t have to pay a software
    program, nor do you have to supply it with health benefits. It won’t get pregnant
    and have to take six months off to care for its newborn child, nor will it ever
    become disgruntled with its working conditions and try to start a union drive
    in the break room.
  prefs: []
  type: TYPE_NORMAL
- en: The billionaires who are marketing this technology have made vague rhetorical
    gestures to things like universal basic income as a cure for the inevitable worker
    displacements that are going to happen, but only a fool would think those are
    anything other than empty promises designed to stave off some sort of underclass
    uprising. The truth is that AI is a technology that was made by and for the managers
    of the world. The frenzy in Davos this week—where the world’s wealthiest fawned
    over it like Greek peasants discovering Promethean fire—is only the latest reminder
    of that.
  prefs: []
  type: TYPE_NORMAL
- en: 'Photo: Stefan Wermuth/Bloomberg (Getty Images)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Question of the day: What’s OpenAI’s excuse for becoming a defense contractor?'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The short answer to that question is: Not a very good one. This week, it was
    revealed that the influential AI organization [was working with the Pentagon](https://www.bloomberg.com/news/articles/2024-01-16/openai-working-with-us-military-on-cybersecurity-tools-for-veterans?embedded-checkout=true&sref=P6Q0mxvj)
    to develop new cybersecurity tools. OpenAI had previously promised not to join
    the defense industry. Now, after a quick edit to its terms of service, the company
    is charging full-steam ahead with the development of new toys for the world’s
    most powerful military. After getting confronted about this pretty drastic pivot,
    the company’s response was basically: **¯\_(ツ)_/¯** ...“Because we previously
    had what was essentially a blanket prohibition on military, many people thought
    that would prohibit many of these use cases, which people think are very much
    aligned with what we want to see in the world,” a company spokesperson told Bloomberg.
    I’m not sure what the hell that means but it doesn’t sound particularly convincing.
    Of course, OpenAI is not alone. Many companies are currently rushing to market
    their AI services to the defense community. It only makes sense that a technology
    that [has been referred](https://www.wsj.com/articles/bill-gates-says-artificial-intelligence-is-the-most-revolutionary-technology-in-decades-75fb8562)
    to as the “most revolutionary technology” seen in decades would inevitably get
    sucked up into America’s military industrial complex. Given what other countries
    [are already doing](https://www.npr.org/2023/12/14/1218643254/israel-is-using-an-ai-system-to-find-targets-in-gaza-experts-say-its-just-the-st)
    with AI, I’d imagine this is only the beginning.'
  prefs: []
  type: TYPE_NORMAL
- en: More headlines this week
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**The FDA has approved a new AI-fueled device helps doctors hunt for signs
    of skin cancer**. The Food and Drug Administration has given its [approval](https://www.reuters.com/business/healthcare-pharmaceuticals/us-fda-clears-dermasensors-ai-powered-skin-cancer-detecting-device-2024-01-17/)
    to something called a DermaSensor, a [unique hand-held device](https://www.dermasensor.com/)
    that doctors can use to scan patients for signs of skin cancer; the device leverages
    AI to conduct “rapid assessments” of skin legions and assess whether they look
    healthy or not. While there are a lot of dumb uses for AI floating around out
    there, experts [contend that](https://www.capradio.org/articles/2024/01/16/researchers-hopeful-ai-could-help-diagnose-extremely-sick-patients/)
    AI could actually prove quite useful in the medical field.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**OpenAI is establishing ties to higher education**. OpenAI has been trying
    to reach its tentacles into every strata of society and the latest sector to be
    breached is higher education. This week, the organization [announced that](https://www.cnbc.com/2024/01/18/openai-announces-first-partnership-with-a-university.html)
    it had forged a partnership with Arizona State University. As part of the partnership,
    ASU will get full-access to ChatGPT Enterprise, the company’s business-level version
    of the chatbot. ASU also plans to build a “personalized AI tutor” that students
    can use to assist them with their schoolwork. The university is also planning
    a “prompt engineering course” which, I am guessing, will help students learn how
    to ask a chatbot a question. Useful stuff!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The internet is already infested with AI-generated crap**. A [new report](https://www.404media.co/google-news-is-boosting-garbage-ai-generated-articles/)
    from 404 Media shows that Google is algorithmically boosting AI-generated content
    from a host of shady websites. Those websites, the report shows, are designed
    to hoover up content from other, legitimate websites and then repackage them using
    algorithms. The whole scheme revolves around automating content output to generate
    advertising revenue. This regurgitated crap is then getting promoted by Google’s
    News algorithm to appear in search results. Joseph Cox writes that the “presence
    of AI-generated content on Google News signals” how “Google may not be ready for
    moderating its News service in the age of consumer-access AI.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
