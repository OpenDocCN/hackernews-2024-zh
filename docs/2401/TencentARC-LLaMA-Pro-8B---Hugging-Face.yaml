- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:33:03'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: TencentARC/LLaMA-Pro-8B · Hugging Face
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://huggingface.co/TencentARC/LLaMA-Pro-8B](https://huggingface.co/TencentARC/LLaMA-Pro-8B)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[](#llama-pro-8b-model-card)LLaMA-Pro-8B Model Card'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[](#model-description)Model Description'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLaMA-Pro is a progressive version of the original LLaMA model, enhanced by
    the addition of Transformer blocks. It specializes in integrating both general
    language understanding and domain-specific knowledge, particularly in programming
    and mathematics.
  prefs: []
  type: TYPE_NORMAL
- en: '[](#development-and-training)Development and Training'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Developed by Tencent's ARC Lab, LLaMA-Pro is an 8.3 billion parameter model.
    It's an expansion of LLaMA2-7B, further trained on code and math corpora totaling
    80 billion tokens.
  prefs: []
  type: TYPE_NORMAL
- en: '[](#intended-use)Intended Use'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This model is designed for a wide range of NLP tasks, with a focus on programming,
    mathematics, and general language tasks. It suits scenarios requiring integration
    of natural and programming languages.
  prefs: []
  type: TYPE_NORMAL
- en: '[](#performance)Performance'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLaMA-Pro demonstrates advanced performance across various benchmarks. It outperforms
    existing models in the LLaMA series in handling diverse tasks, showcasing its
    capability as an intelligent language agent.
  prefs: []
  type: TYPE_NORMAL
- en: '[](#overall-performance-on-languages-math-and-code-tasks)Overall Performance
    on Languages, math and code tasks'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Model | ARC | Hellaswag | MMLU | TruthfulQA | Winogrande | GSM8K | GSM8K-PoT
    | HumanEval | MBPP | Avg |'
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |'
  prefs: []
  type: TYPE_TB
- en: '| LLAMA PRO (8B) | 54.10 | 77.94 | 47.88 | 39.04 | 73.95 | 17.89 | 25.42 |
    28.66 | 33.20 | 44.2 |'
  prefs: []
  type: TYPE_TB
- en: '| LLaMA2-7B | 53.07 | 78.59 | 46.87 | 38.76 | 74.03 | 14.48 | 17.68 | 13.05
    | 20.09 | 39.62 |'
  prefs: []
  type: TYPE_TB
- en: '| CodeLLaMA-7B | 39.93 | 60.80 | 31.12 | 37.82 | 64.01 | 5.16 | 25.20 | 33.50
    | 41.40 | 37.66 |'
  prefs: []
  type: TYPE_TB
- en: '| LLAMA PRO-INSTRUCT | 52.30 | 76.88 | 52.57 | 48.80 | 72.53 | 43.59 | 55.61
    | 44.51 | 37.88 | 53.8 |'
  prefs: []
  type: TYPE_TB
- en: '[](#performance-on-gpt4-evaluation)Performance on GPT4 Evaluation'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Model | MT Bench |'
  prefs: []
  type: TYPE_TB
- en: '| :-: | :-: |'
  prefs: []
  type: TYPE_TB
- en: '| Alpaca-13B | 4.53 |'
  prefs: []
  type: TYPE_TB
- en: '| CodeLLaMA-7B-Instruct | 5.71 |'
  prefs: []
  type: TYPE_TB
- en: '| Vicuna-7B | 6.17 |'
  prefs: []
  type: TYPE_TB
- en: '| LLaMA2-7B-Chat | 6.27 |'
  prefs: []
  type: TYPE_TB
- en: '| LLAMA PRO-INSTRUCT | 6.32 |'
  prefs: []
  type: TYPE_TB
- en: '[](#limitations)Limitations'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While LLaMA-Pro addresses some limitations of previous models in the series,
    it may still encounter challenges specific to highly specialized domains or tasks.
  prefs: []
  type: TYPE_NORMAL
- en: '[](#ethical-considerations)Ethical Considerations'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Users should be aware of potential biases in the model and use it responsibly,
    considering its impact on various applications.
  prefs: []
  type: TYPE_NORMAL
