<!--yml
category: 未分类
date: 2024-05-27 15:22:24
-->

# Is it possible to hold truly contradictory beliefs together? | Aeon Essays

> 来源：[https://aeon.co/essays/is-it-possible-to-hold-truly-contradictory-beliefs-together](https://aeon.co/essays/is-it-possible-to-hold-truly-contradictory-beliefs-together)

I hate going to the mall. When I visit, I’m filled with a sense of existential dread. I’m overwhelmed by the sheer number of products, left with a sense that I should buy either all of them or none of them – somehow, it seems that there is no practicable way to select just one or two. A few years ago, I decided: enough. I formed the intention never to visit the mall again. From then on, it was to be only online ordering for me – never mind the number of returns I’d have to make when it turned out that I’d guessed wrong *again* about whether to order a sweater in a medium or a large.

Soon afterward, I was invited to a wedding. After that early-thirties phase when it seemed like all my partner and I did on the weekends was attend weddings, the stream of invites had dried up somewhat, and I was excited to have a chance to leave our kid with the grandparents, drink one too many glasses of Prosecco, and hit the dancefloor when those first few bars of ‘Hey Ya!’ inevitably sounded. Thinking of that dancefloor, my mind turned to my lone pair of battered old dress shoes. The left shoe had a weird stain on top, subtle enough to be unapparent to a casual observer, but noticeable enough to bother me whenever I looked down. It was time for a new pair, and I formed the intention to buy some for the wedding.

Time passed, and something else always seemed more pressing, until suddenly it was the day of our flight, and I realised something with horror: it was too late for an online order. If I was going to get the shoes, I was going to have to go to the mall.

At that moment, I was in an uncomfortable position. I intended – or had intended, until then – to buy a new pair of shoes. And I believed that the only way to buy them was to visit the mall. But I also intended – or had intended, until then – never to visit the mall again. *Something had to give*. I needed to either give up my intention to buy a new pair of shoes, or give up my intention never to visit the mall again (unless I could think of some way to get the shoes without visiting the mall after all). My mind immediately turned to deciding which was the lesser of the two evils: going without new shoes, or paying a visit to the dreaded mall.

There’s nothing very remarkable about the story I just told. But now suppose that my reaction to my realisation had been different. Suppose I’d said to my partner: ‘I acknowledge that, to get the shoes, I must go to the mall. And I do intend to get the shoes. But I have no intention whatsoever to go to the mall.’ If I said this, and if it really were a sincere, accurate report of my state of mind – more on that later – there would be something deeply wrong with me. The mental states I’ve just reported, to put it mildly, do not sit well together. The combination is *incoherent*.

Philosophers call the kind of incoherence that’s involved in these states *means-end* incoherence – I intend an *end* (getting new shoes), believe that a *means* (going to the mall) is necessary for that end, but do not intend the means. There are many other kinds of incoherence. For example, it’s incoherent to have ‘cyclical’ preferences – say, to prefer chocolate ice cream to vanilla, prefer vanilla to strawberry, but prefer strawberry to chocolate. And it’s incoherent to have beliefs that are straightforwardly logically inconsistent – say, to believe that great cooks never overcook eggs, believe that you are a great cook, but also believe that you have overcooked the eggs.

As these examples show, incoherence can hold between mental states of various types: for example, between beliefs, preferences, intentions, or mixtures of more than one of these types. In all cases, though, it’s crucial that the defect is in the combination of states, not necessarily in any of them taken individually. There’s nothing wrong with preferring chocolate ice cream to vanilla, or preferring vanilla to strawberry, or preferring strawberry to chocolate; but there is something very strange about having all of these preferences together. Similarly, there might be nothing wrong either with intending to buy new shoes, or with intending not to visit the mall, or with believing that the only way to buy new shoes is to visit the mall; what’s defective is the combination of all three. Even when it comes to the inconsistent beliefs (that great cooks never overcook eggs, that you are a great cook, and that you have overcooked the eggs), none of these are on their own *obviously* unreasonable; again, it’s the combination that’s most obviously defective.

I’ve been using the vague term ‘defective’ to indicate that there’s some kind of flaw in incoherent combinations. But a natural, more specific term to reach for in characterising the defect is ‘irrational’. Indeed, there’s a long philosophical tradition of viewing incoherence as the paradigm case of irrationality.

To see the appeal of this, it helps to contrast being incoherent with merely being *unreasonable*. Consider someone – call him Derek – who believes that the 2020 US presidential election was stolen for Joe Biden, and that in reality Donald Trump received far more votes. For my money, these beliefs are not supported by the available evidence, and are thus unreasonable. But, for all that, Derek might have a totally coherent worldview. His beliefs certainly could be logically consistent: there’s some imaginable situation (in philosophers’ lingo, a ‘possible world’) in which all of them are true. Moreover, Derek might *think* that his beliefs are well supported by the available evidence, thinking that the information provided on QAnon message boards, by One America News, and by Trump himself is extremely weighty evidence, and that information provided by the mainstream media is entirely unreliable. Like many conspiracy theorists, Derek might [dismiss](https://philpapers.org/rec/NAPCTA) the evidence against his views by saying that it has been fabricated by malicious actors.

Consequently, although I think that Derek’s beliefs are unreasonable, this is hard to demonstrate conclusively in a way that’s neutral on the weighty disagreements that Derek and I have. I can point to my trusted sources of information – mainstream media outlets, those who reviewed the votes, members of state election boards – that say I’m right and he’s wrong. But Derek rejects those sources as biased or shills or dupes. So he won’t be impressed by my arguments that his beliefs are unreasonable. And, indeed, there’s a way in which it makes sense, given his worldview, for him not to be impressed.

The incoherent person is irrational in a *deeper* way than the unreasonable person

What’s enticing about charges of incoherence, by contrast, is that they seem to skirt these kinds of disputes. If I can show that Derek’s worldview doesn’t make sense from the *inside* – that it doesn’t even hang together coherently – then, the thought is, I can show that he’s being irrational without having to settle which sources of information are reliable, or what counts as good evidence for what. This, I think, is part of what makes us inclined to reach for charges of incoherence (or inconsistency) in political debate. When we reveal incoherence in someone’s political beliefs, we’re tempted to think, *then we’ve really got ’em*. Or, at least, then we’ve really shown that they are being irrational.

Derek’s case concerns the evaluation of *beliefs* as rational or irrational. Similar issues arise with intentions. Suppose a politician intends to do whatever would benefit small businesses in his constituency. But he also plans to vote against a bill that will make legal immigration easier, despite knowing that making legal immigration easier would benefit small businesses in his constituency (by increasing their labour pool). By pointing out that this combination is incoherent, I can show that the politician is being irrational while skirting various weighty disagreements we might have. I may disagree both with the politician’s plan to vote against the bill *and* with the importance he attaches to helping small businesses at whatever cost. Perhaps I support the bill for reasons having nothing to do with small businesses – say, because I think we have a moral duty to prospective immigrants to make legal immigration easier and safer – that the politician would, in turn, reject. But showing the politician’s views about these issues to be unreasonable would be very hard: these disputes turn on difficult, hard-to-settle contentions about morality and value. Pointing out that a vote against the bill would knowingly frustrate the politician’s own goals is both an easier way to show the irrationality of his intentions, and more likely (though far from certain) to be effective in changing his mind.

As well as illustrating how charges of irrationality are usually easier to vindicate when someone is incoherent than when they’re merely unreasonable, these cases also bring out the thought that the incoherent person is irrational in a *deeper* way than the unreasonable person. If Derek’s beliefs aren’t supported by the evidence, he’s less than ideal, but if his beliefs don’t even hang together coherently, he’s *really* screwed up. Indeed, [some](https://philpapers.org/rec/BRODRC) deny that mental states that are merely unreasonable merit the label ‘irrational’, wanting to apply that label only to incoherence. Ultimately, I think this goes too far. Just as Derek can be unreasonable yet coherent, so can those with progressively wackier views – climate-change deniers, flat-Earthers, people who are convinced that fairies live in their gardens. It’s overwhelmingly natural to describe at least the most delusional of these beliefs as irrational, no matter how internally coherent they are. With this in mind, some philosophers – including me, along with my sometime co-author Daniel Fogal – have suggested we use the label ‘substantive rationality’ to refer to reasonableness, and ‘structural rationality’ to refer to coherence. Whatever labels we use, though, the key point is that reasonableness and coherence are two quite different things.

It’s a truism of contemporary middlebrow discourse that human beings are deeply irrational. According to a simplified but not entirely fabricated popular narrative, classical economists naively assumed that individuals are perfectly rational, before contemporary psychology (and ‘behavioural economics’) came along to burst their bubble by experimentally demonstrating the depths of human irrationality. Irrationality-talk in public discourse got another boost from the advent of Trumpist politics, with academic [books](https://www.abc-clio.com/products/a5383c/) and newspaper op-eds frequently using the word in characterising Trump and his devotees. It’s striking, though, that many of the loudest voices professing the magnitude of human irrationality tend not to say what understanding of irrationality they’re employing – in particular, where their notion of (ir)rationality is substantive or structural.

If we’re employing a substantive notion of rationality, it’s hard to contest that human beings are very often irrational. We often have beliefs that are not well supported by evidence – the climate-change deniers, flat-Earthers and fairy-believers just discussed are cases in point. And we often do things that there’s very strong reason not to do, as when we engage in behaviours very harmful to our health, lash out at others intemperately, or fall victim to scams and hucksters.

A more difficult question is how widespread *structural* irrationality – incoherence – is. It’s not unusual to hear it said that we’re very incoherent (or, more colloquially, inconsistent). But, on reflection, there’s a way in which paradigm cases of incoherence are not just irrational but borderline unintelligible. Return to the shoes/mall example, and my hypothetical pronouncement: ‘I acknowledge that, in order to get the shoes, I have to go to the mall. And I do intend to get the shoes. But I have no intention whatsoever to go to the mall!’ If I cheerily announced this to you, you might not just think that I’m irrational, but struggle to even make sense of how I could really be in the state of mind that I claim to be in. (Am I joking?) You might think: ‘If he knows that the only way to get the shoes is to go to the mall, and he doesn’t intend to go to the mall, then that shows that he doesn’t intend to get the shoes after all. Maybe he’d *like* to have the shoes, but if he really *intended* to get the shoes, he’d plan on going to the mall.’

We think that part of what it is to believe that it’s raining is to deny claims like ‘it’s not raining’

I think this reaction is on to something. In more general terms, the thought is this: it’s part of what it *is* to intend to do something that, when you believe that doing some second thing is necessary for doing the first thing, you’ll at least tend to come to intend to do the second thing as well. If you don’t have this tendency, then you don’t really count as intending to do the first thing after all. And that puts limits on the extent to which your intentions can really be incoherent.

Similar points hold in the most egregious cases of incoherent beliefs. If someone announces: ‘I believe that great cooks never overcook eggs, and I believe that I am a great cook, but I believe that I have overcooked the eggs,’ the most natural way to hear this is as a joke. If they really do believe they’ve overcooked the eggs, they either don’t really believe that great cooks *never* overcook eggs, or don’t really believe they’re a genuinely great cook. Or so it’s very tempting to say.

Philosophers writing about irrationality – including, on occasion, myself – sometimes overlook this, breezily describing cases of outrageous incoherence as if there’s nothing puzzling about them. They write things like: ‘Imagine Jack, who believes that it’s raining and also believes that it’s not raining.’ If we slow down and take a reality check, though, it’s not clear *how* to go about imagining Jack. And that’s because it’s not clear what kind of state of mind Jack could be in that would make it correct to describe him both as believing that it’s raining and believing that it’s not raining. Normally, we think that part of what it is to believe that it’s raining is to deny claims like ‘it’s not raining’, and vice versa. Many philosophers also think that believing something involves tending to act as if it’s the case. But what would it be to act as if it’s raining *and* as if it’s not raining?

A puzzle has emerged. On the one hand, it’s highly compelling that we sometimes – often? – *are* incoherent: our mental states surely don’t fit together perfectly. On the other hand, when we reach for paradigm examples of incoherence, they seem to come apart in our hands: it starts to seem like the kinds of beliefs and intentions described aren’t just irrational but *impossible* to have simultaneously. The puzzle is how to do justice to both these thoughts.

In my view – which I defend in my [book](https://global.oup.com/academic/product/fitting-things-together-9780197608142?cc=us&lang=en&) *Fitting Things Together* (2021) – the key to solving this puzzle can be found by paying attention to the difference between cases in which our mental states are *transparent* to us and those in which they aren’t. Roughly, mental states are transparent to us when we are fully and consciously aware of having them. As many [psychologists](https://www.hup.harvard.edu/catalog.php?isbn=9780674013827) and [philosophers](https://www.jstor.org/stable/40606018) have argued in recent decades, our mental states are often not transparent to us: we can be unaware of, or deceived about, what we believe, desire, intend, hope and fear. My contention is that the cases where people most clearly have incoherent mental states are those in which their mental states are not perfectly transparent to them. It’s not particularly hard to make sense of incoherence in these cases; what’s harder to make sense of is incoherence that persists even when the incoherent states in question are brought to the attention of the person who has them.

Examples will help. Consider someone – call her Julie – who professes that all Trump supporters are morally bad people: only a morally bad person, she says, could still support Trump after his demeaning comments about women, record of cruelty toward immigrants, and mocking of the disabled. But suppose Julie also knows that Brenda, the bartender at her local, is a Trump supporter. And suppose that if she were asked, outside of any discussion of Trump, whether Brenda is a morally bad person, she would say that she is not.

Julie has a set of beliefs – that all Trump supporters are morally bad people, that Brenda is a Trump supporter, and that Brenda is not a morally bad person – that are incoherent. She can sustain these beliefs, I think, if she never thinks about all of them at once. But if someone were to point out to Julie that she holds all three beliefs, we’d expect her to immediately revise one of them. She might say something like: ‘OK, OK, not *all* Trump supporters are morally bad people – not *Brenda*.’ Or, perhaps: ‘Oh yeah, Brenda’s a Trump supporter. Well, I guess she is a morally bad person after all.’ What would be downright bizarre is if she just continued to confidently affirm all three claims – that all Trump supporters are morally bad people, that Brenda is a Trump supporter, and that Brenda is not a morally bad person – together. If she did that, we’d suspect she was confused (‘she can’t really mean *all*’) or insincere. This suggests that what’s hard to make sense of is not incoherence as such – Julie can manage that – but *transparent* incoherence.

Reporting one’s own incoherent states aloud in speech seems a lot stranger than merely *being* incoherent

Many of us are like Julie: we hold incoherent beliefs, but never think about them together, and that’s how we manage to sustain the incoherence. The point is even clearer when it comes to other kinds of incoherence, like cyclical preferences. Suppose I have three options for what to do this afternoon: finishing that article I’ve been working on, volunteering at the homeless shelter, or binge-watching the latest season of my favourite Netflix show. When thinking only about the options of finishing the article and volunteering at the homeless shelter, finishing the article seems like an important project that I can justifiably pick over volunteering, that also allows me to stay home in my PJs and not have to interact with anyone: I prefer finishing the article to volunteering. When thinking only about the options of volunteering at the homeless shelter and binge-watching Netflix, choosing to do something so trivial as watching TV rather than volunteering seems callous: I prefer volunteering to binge-watching. But when thinking only about the options of binge-watching Netflix and finishing the article, finishing the article seems difficult and energy-consuming, and Netflix seems much more enticing: I prefer binge-watching to finishing the article. These preferences are cyclical. Again, I can sustain them if I never think about them all at once. What would be bizarre would be my transparently declaring all three preferences together.

Why is transparent incoherence bizarre? In my view, it’s because to count as genuinely having a certain mental state (an intention, a belief, a preference, etc), you need to have some tendency to make your other mental states coherent with it, when your mental states are transparent to you. For example, I suggested earlier that to count as genuinely intending to wear new shoes to the wedding, I need to have some tendency to also form intentions to do whatever I believe is necessary for this – for example, to go to the mall to buy some. We can now qualify this in a subtle but crucial way: I need to have some tendency to form the intention to go to the mall – when my intention to wear new shoes and my belief that to do this I must go to the mall are both transparent to me.

This is a conceptual point, not an experimentally demonstrable one: if I don’t have that tendency, I just don’t *count* as intending to wear new shoes to the wedding. Nevertheless, the view that I’m suggesting here fits with a lot of what we know from both science and our own experience. It fits with the way that psychologists can exploit ordering and framing effects in surveys to elicit responses that seem so utterly incoherent that practically no one would ever give all of them at once: plausibly, this is possible because the participants don’t consider all of their responses together at once. It fits with the fact that reporting one’s own incoherent states aloud in speech seems a lot stranger than merely *being* incoherent: this is because reporting the state aloud in speech requires bringing all the states to one’s conscious attention, making them transparent. And it explains why, when our incoherence is brought to our attention, we scramble to revise or reinterpret our mental states to make them coherent: ‘When I said “all”, I didn’t really mean *all*’; ‘I’ll do anything to help small businesses *within reason*’; and so on.

We’re often incoherent through inattention to our mental states, through failure to put them together to draw the obvious conclusions. Still, the fact that we do tend to revise our states to make them coherent *when they’re brought to our attention* suggests that there is a kind of rationality – structural, rather than substantive, rationality – that we at least tend to approximate. We may not be very reasonable creatures a lot of the time. But we are coherent creatures, to some degree, and under certain conditions. For this baseline level of coherence is built into what it is to even have beliefs, intentions, preferences and the whole gamut of human responses to the world.