<!--yml

category: 未分类

date: 2024-05-27 14:51:46

-->

# 大型世界模型

> 来源：[https://largeworldmodel.github.io/](https://largeworldmodel.github.io/)

当前的语言模型在理解那些难以用语言描述的世界方面存在不足，并且在处理复杂的长篇任务时也面临困难。视频序列提供了语言和静态图像所没有的宝贵时间信息，因此与语言联合建模变得非常吸引人。这样的模型可以发展对人类文本知识和物理世界的理解，从而扩展AI在帮助人类方面的能力。然而，从数百万标记的视频和语言序列中学习面临记忆限制、计算复杂性和有限数据集等挑战。为了应对这些挑战，我们策划了一个包含各种视频和书籍的大型数据集，利用分块环注意力技术来可伸缩地训练长序列，并逐步增加上下文大小从4K到1M标记。本文的主要贡献如下：(a) 最大上下文大小的神经网络：我们训练了一个在长视频和语言序列上拥有最大上下文大小的Transformer模型，在困难的检索任务和长视频理解方面设立了新的基准。(b) 解决视觉语言训练挑战的方案，包括使用掩码序列包装以混合不同长度的序列、损失加权以平衡语言和视觉、以及使用模型生成的QA数据集进行长序列对话。(c) 通过RingAttention、分块Transformer、掩码序列包装和其他关键特性，在百万级多模态序列上进行训练的高度优化实现。(d) 完全开源的一系列7B参数模型，能够处理超过1M标记的长文档（LWM-Text、LWM-Text-Chat）和视频（LWM、LWM-Chat）。这项工作为训练大规模视频和语言数据集，以发展对人类知识和多模态世界的理解以及更广泛能力铺平了道路。
