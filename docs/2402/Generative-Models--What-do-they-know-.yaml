- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-29 13:18:41'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-29 13:18:41'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Generative Models: What do they know?'
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成模型：它们究竟知道什么？
- en: 来源：[https://intrinsic-lora.github.io/](https://intrinsic-lora.github.io/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://intrinsic-lora.github.io/](https://intrinsic-lora.github.io/)
- en: Generative models have been shown to be capable of synthesizing highly detailed
    and realistic images. It is natural to suspect that they implicitly learn to model
    some image intrinsics such as surface normals, depth, or shadows. In this paper,
    we present compelling evidence that generative models indeed internally produce
    high-quality scene intrinsic maps. We introduce INTRINSIC LoRA (I-LoRA), a universal,
    plug-and-play approach that transforms any generative model into a scene intrinsic
    predictor, capable of extracting intrinsic scene maps directly from the original
    generator network without needing additional decoders or fully fine-tuning the
    original network. Our method employs a Low-Rank Adaptation (LoRA) of key feature
    maps, with newly learned parameters that make up less than 0.6% of the total parameters
    in the generative model. Optimized with a small set of labeled images, our model-agnostic
    approach adapts to various generative architectures, including Diffusion models,
    GANs, and Autoregressive models. We show that the scene intrinsic maps produced
    by our method compare well with, and in some cases surpass those generated by
    leading supervised techniques.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型已经被证明能够合成高度详细和逼真的图像。人们自然而然地怀疑它们隐含地学习了一些图像内在特性，比如表面法线、深度或阴影。在本文中，我们提供了有力的证据表明，生成模型确实能够内部产生高质量的场景内在地图。我们引入了INTRINSIC
    LoRA（I-LoRA），这是一种通用的即插即用方法，将任何生成模型转化为场景内在预测器，能够直接从原始生成网络中提取内在场景地图，而无需额外的解码器或完全微调原始网络。我们的方法采用了关键特征图的低秩适应（LoRA），新学习的参数仅占生成模型总参数的不到0.6%。通过少量标记图像的优化，我们这种与模型无关的方法适应各种生成架构，包括扩散模型、GAN和自回归模型。我们展示了我们方法生成的场景内在地图与领先的监督技术生成的地图相比表现良好，并且在某些情况下超过了它们。
