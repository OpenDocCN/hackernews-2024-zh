- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-27 14:51:19'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024年05月27日 14:51:19
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Your AI Girlfriend Is a Data-Harvesting Horror Show
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你的人工智能女友是个数据收割的恐怖秀
- en: 来源：[https://gizmodo.com/your-ai-girlfriend-is-a-data-harvesting-horror-show-1851253284](https://gizmodo.com/your-ai-girlfriend-is-a-data-harvesting-horror-show-1851253284)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 出处：[https://gizmodo.com/your-ai-girlfriend-is-a-data-harvesting-horror-show-1851253284](https://gizmodo.com/your-ai-girlfriend-is-a-data-harvesting-horror-show-1851253284)
- en: Lonely on Valentine’s Day? AI can help. At least, that’s what a number of companies
    hawking “romantic” chatbots will tell you. But as your robot love story unfolds,
    there’s a tradeoff you may not realize you’re making. According to a new study
    from Mozilla’s *Privacy Not Included project, [AI girlfriends and boyfriends](https://gizmodo.com/sam-altman-says-chatgpt-can-t-be-your-girlfriend-1851181240)
    harvest shockingly personal information, and almost all of them sell or share
    the data they collect.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 情人节孤单？人工智能可以帮助。至少，这是一些兜售“浪漫”聊天机器人的公司告诉你的。但当您的机器人爱情故事展开时，您可能没有意识到您正在做出的权衡。根据Mozilla的新研究，的*隐私不包括*项目的[人工智能女友和男友](https://gizmodo.com/sam-altman-says-chatgpt-can-t-be-your-girlfriend-1851181240)收集了令人震惊的个人信息，几乎所有这些信息都被出售或分享了。
- en: Like It or Not, Your Doctor Will Use AI | AI Unlocked
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你喜欢与否，你的医生将使用人工智能| 破解人工智能
- en: <track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/21541.vtt"
    srclang="en">
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: <track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/21541.vtt"
    srclang="en">
- en: “To be perfectly blunt, AI girlfriends and boyfriends are not your friends,”
    said Misha Rykov, a Mozilla Researcher, in a press statement. “Although they are
    marketed as something that will enhance your mental health and well-being, they
    specialize in delivering dependency, loneliness, and toxicity, all while prying
    as much data as possible from you.”
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: “坦率地说，人工智能女友和男友并不是你的朋友，”Mozilla研究员米莎·里科夫在一份新闻稿中表示。“虽然它们被宣传为能增强您的心理健康和幸福感，但它们专门提供依赖感、孤独感和毒性，并同时尽可能多地向您探寻数据。”
- en: AI Girlfriends Aren’t All Bad | AI Unlocked
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能女友并非都糟糕| 破解人工智能
- en: <track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/22134.vtt"
    srclang="en">
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: <track kind="captions" label="中文" src="https://kinja.com/api/videoupload/caption/22134.vtt"
    srclang="en">
- en: AI Girlfriends Aren’t All Bad | AI Unlocked
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能女友并非都糟糕| 破解人工智能
- en: Mozilla dug into [11 different AI romance chatbots](https://foundation.mozilla.org/en/privacynotincluded/eva-ai-chat-bot-soulmate/),
    including popular apps such as Replika, Chai, Romantic AI, EVA AI Chat Bot & Soulmate,
    and CrushOn.AI. Every single one earned the Privacy Not Included label, putting
    these chatbots among the worst categories of products Mozilla has ever reviewed.
    The apps mentioned in this story didn’t immediately respond to requests for comment.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: Mozilla调查了[11个不同的人工智能浪漫聊天机器人](https://foundation.mozilla.org/en/privacynotincluded/eva-ai-chat-bot-soulmate/)，包括Replika、Chai、Romantic
    AI、EVA AI Chat Bot & Soulmate和CrushOn.AI等热门应用。每个聊天机器人都获得了Privacy Not Included标签，将这些聊天机器人列为Mozilla有史以来审查的最糟糕的产品类别之一。本文中提到的应用程序未立即回应置评请求。
- en: You’ve heard stories about data problems before, but according to Mozilla, AI
    girlfriends violate your privacy in “disturbing new ways.” For example, CrushOn.AI
    collects details including information about sexual health, use of medication,
    and gender-affirming care. 90% of the apps may sell or share user data for targeted
    ads and other purposes, and more than half won’t let you delete the data they
    collect. Security was also a problem. Only one app, Genesia AI Friend & Partner,
    met Mozilla’s minimum security standards.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 关于数据问题，你以前听过故事，但根据Mozilla的说法，人工智能女友以“令人不安的新方式”侵犯您的隐私。例如，CrushOn.AI收集的细节包括性健康信息、药物使用和性别确认护理。90%的应用程序可能出售或分享用户数据以进行定向广告和其他目的，超过一半的应用程序不允许您删除所收集的数据。安全性也是一个问题。只有一个应用程序Genesia
    AI Friend & Partner符合Mozilla的最低安全标准。
- en: One of the more striking findings came when Mozilla counted the trackers in
    these apps, little bits of code that collect data and share them with other companies
    for advertising and other purposes. Mozilla found the AI girlfriend apps used
    an average of 2,663 trackers per minute, though that number was driven up by Romantic
    AI, which called a whopping 24,354 trackers in just one minute of using the app.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的发现之一是当Mozilla统计这些应用中的跟踪器时，这些小部分代码收集数据并与其他公司分享以进行广告和其他目的。Mozilla发现人工智能女友应用程序每分钟使用平均2,663个跟踪器，尽管这个数字被Romantic
    AI推高，该应用在仅使用一分钟的时间内就调用了惊人的24,354个跟踪器。
- en: The privacy mess is even more troubling because the apps actively encourage
    you to share details that are far more personal than the kind of thing you might
    enter into a typical app. EVA AI Chat Bot & Soulmate pushes users to “share all
    your secrets and desires,” and specifically asks for photos and voice recordings.
    It’s worth noting that EVA was the only chatbot that didn’t get dinged for how
    it uses that data, though the app did have security issues.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 隐私问题更加令人担忧，因为这些应用积极鼓励您分享比您可能在典型应用中输入的更加个人化的细节。EVA AI Chat Bot & Soulmate推动用户“分享所有的秘密和愿望”，并专门要求提供照片和语音录音。值得注意的是，尽管该应用存在安全问题，但EVA是唯一一款在使用这些数据方面没有受到批评的聊天机器人。
- en: Data issues aside, the apps also made some questionable claims about what they’re
    good for. EVA AI Chat Bot & Soulmate bills itself as “a provider of software and
    content developed to improve your mood and well-being.” Romantic AI says it’s
    “here to maintain your MENTAL HEALTH.” When you read the company’s terms and services
    though, they go out of their way to distance themselves from their own claims.
    Romantic AI’s policies, for example, say it is “neither a provider of healthcare
    or medical Service nor providing medical care, mental health Service, or other
    professional Service.”
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 除了数据问题之外，这些应用还对它们的用途做出了一些有争议的声明。EVA AI Chat Bot & Soulmate自称为“提供开发的软件和内容，旨在改善您的情绪和健康。”
    Romantic AI则表示它“在这里维护您的心理健康。”然而，当你阅读公司的条款和服务时，它们都力图与自己的声明保持距离。例如，Romantic AI的政策表示它“既不提供医疗保健或医疗服务，也不提供心理健康服务或其他专业服务。”
- en: That’s probably important legal ground to cover, given these app’s history.
    Replika reportedly encouraged a man’s attempt to [assassinate the Queen of England](https://gizmodo.com/man-sentenced-ai-girlfriend-assassinate-queen-1850904625).
    A Chai chatbot allegedly [encouraged a user to commit suicide](https://www.vice.com/en/article/pkadgm/man-dies-by-suicide-after-talking-with-ai-chatbot-widow-says).
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于这些应用的历史，这可能是重要的法律问题。据报道，Replika鼓励一名男子试图[刺杀英国女王](https://gizmodo.com/man-sentenced-ai-girlfriend-assassinate-queen-1850904625)。据称，一款名为Chai的聊天机器人还[鼓励用户自杀](https://www.vice.com/en/article/pkadgm/man-dies-by-suicide-after-talking-with-ai-chatbot-widow-says)。
