- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 14:58:06'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 14:58:06'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Improving LoRA: Implementing Weight-Decomposed Low-Rank Adaptation (DoRA) from
    Scratch'
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进 LoRA：从头开始实现权重分解低秩适应（DoRA）
- en: 来源：[https://magazine.sebastianraschka.com/p/lora-and-dora-from-scratch](https://magazine.sebastianraschka.com/p/lora-and-dora-from-scratch)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://magazine.sebastianraschka.com/p/lora-and-dora-from-scratch](https://magazine.sebastianraschka.com/p/lora-and-dora-from-scratch)
- en: Low-rank adaptation (LoRA) is a machine learning technique that modifies a pretrained
    model (for example, an LLM or vision transformer) to better suit a specific, often
    smaller, dataset by adjusting only a small, low-rank subset of the model's parameters.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 低秩适应（LoRA）是一种机器学习技术，通过调整模型参数的一个小而低秩的子集（例如，预训练的 LLM 或视觉变换器），从而更好地适应特定的、通常是更小的数据集。
- en: This approach is important because it allows for efficient finetuning of large
    models on task-specific data, significantly reducing the computational cost and
    time required for finetuning.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法很重要，因为它允许在特定任务数据上高效微调大型模型，显著降低微调所需的计算成本和时间。
- en: 'Last week, researchers proposed [DoRA: Weight-Decomposed Low-Rank Adaptation](https://arxiv.org/abs/2402.09353),
    a new alternative to LoRA, which may outperform LoRA by a large margin.'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: '上周，研究人员提出了 [DoRA: 权重分解低秩适应](https://arxiv.org/abs/2402.09353)，这是 LoRA 的一个新的替代方法，可能在很大程度上优于
    LoRA。'
- en: To understand how these methods work, we will implement both LoRA and DoRA in
    PyTorch from scratch in this article!
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这些方法的工作原理，我们将在本文中从头开始用 PyTorch 实现 LoRA 和 DoRA ！
- en: Before we dive into DoRA, here's a brief recap of how [LoRA](https://arxiv.org/abs/2106.09685)
    works.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入讨论 DoRA 之前，让我们简要回顾一下 [LoRA](https://arxiv.org/abs/2106.09685) 的工作原理。
- en: Since LLMs are large, updating all model weights during training can be expensive
    due to GPU memory limitations. Suppose we have a large weight matrix ***W*** for
    a given layer. During backpropagation, we learn a ***ΔW*** matrix, which contains
    information on how much we want to update the original weights to minimize the
    loss function during training.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 LLM 很大，在训练过程中更新所有模型权重可能会因 GPU 内存限制而变得昂贵。假设我们有一个给定层的大权重矩阵 ***W***。在反向传播过程中，我们学习一个
    ***ΔW*** 矩阵，其中包含了我们在训练过程中希望更新原始权重以最小化损失函数的信息。
- en: 'In regular training and finetuning, the weight update is defined as follows:'
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在常规训练和微调中，权重更新定义如下：
- en: '***W[updated] = W + ΔW***'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: '***W[更新] = W + ΔW***'
- en: 'The LoRA method proposed by [Hu](https://arxiv.org/abs/2106.09685) *[et al.](https://arxiv.org/abs/2106.09685)*
    offers a more efficient alternative to computing the weight updates ***ΔW*** by
    learning an approximation of it, ***ΔW ≈ AB***. In other words, in LoRA, we have
    the following, where ***A*** and ***B*** are two small weight matrices:'
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 由 [Hu](https://arxiv.org/abs/2106.09685) *[等人](https://arxiv.org/abs/2106.09685)*
    提出的 LoRA 方法提供了一个更有效的替代方案，用于计算权重更新 ***ΔW*** 的近似值 ***ΔW ≈ AB***。换句话说，在 LoRA 中，我们有以下形式，其中
    ***A*** 和 ***B*** 是两个小的权重矩阵：
- en: '***W[updated] = W + A.B***'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: '***W[更新] = W + A.B***'
- en: (The "**.**" in "***A.B***" stands for matrix multiplication.)
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: （在 "***A.B***" 中的 "***.***" 表示矩阵乘法。）
- en: The figure below illustrates these formulas for full finetuning and LoRA side
    by side.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了全面微调和 LoRA 两者并列的公式。
- en: '*Figure: An illustration of regular finetuning (left) and LoRA finetuning (right).*'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: '*图：全面微调（左）和 LoRA 微调（右）的示意图。*'
- en: How does LoRA save GPU memory? If a pretrained weight matrix ***W*** is a 1,000×1,000
    matrix, then the weight update matrix ***ΔW*** in regular finetuning is a 1,000×1,000
    matrix as well. In this case, ***ΔW*** has 1,000,000 parameters. If we consider
    a LoRA rank of 2, then ***A*** is a 1000×2 matrix, and ***B*** is a 2×1000 matrix,
    and we only have 2×2×1,000 = 4,000 parameters that we need to update when using
    LoRA. In the previous example, with a rank of 2, that's 250 times fewer parameters.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: LoRA 如何节省 GPU 内存？如果预训练的权重矩阵 ***W*** 是一个 1000×1000 的矩阵，那么在常规微调中，权重更新矩阵 ***ΔW***
    也是一个 1000×1000 的矩阵。在这种情况下，***ΔW*** 有 1000000 个参数。如果我们考虑 LoRA 排名为 2，则 ***A*** 是一个
    1000×2 的矩阵，***B*** 是一个 2×1000 的矩阵，当使用 LoRA 时，我们只需要更新 2×2×1000 = 4000 个参数。在前面的例子中，排名为
    2 时，这是少了 250 倍的参数。
- en: Of course, ***A*** and ***B*** can't capture all the information that ***ΔW***
    could capture, but this is by design. When using LoRA, we hypothesize that the
    model requires *W* to be a large matrix with full rank to capture all the knowledge
    in the pretraining dataset. However, when we finetune an LLM, we don't need to
    update all the weights and capture the core information for the adaptation in
    a smaller number of weights than ***ΔW*** would; hence, we have the low-rank updates
    via ***AB***.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，***A*** 和 ***B*** 不能捕捉到 ***ΔW*** 能捕捉到的所有信息，但这是有意设计的。在使用LoRA时，我们假设模型需要一个完整排名的大矩阵
    *W* 来捕获预训练数据集中的所有知识。然而，当我们对LLM进行微调时，我们不需要更新所有权重，只需在比 ***ΔW*** 更少的权重中捕捉适应的核心信息；因此，我们通过
    ***AB*** 进行低秩更新。
- en: 'If you paid close attention, the full finetuning and LoRA depictions in the
    figure above look slightly different from the formulas I have shown earlier. That''s
    due to the distributive law of matrix multiplication: we don''t have to add the
    weights with the updated weights but can keep them separate. For instance, if
    ***x*** is the input data, then we can write the following for regular finetuning:'
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您仔细观察，上述图中的完整微调和LoRA描述与我之前展示的公式略有不同。这是由于矩阵乘法的分配法则：我们不必将权重与更新后的权重相加，而可以保持它们分开。例如，如果
    ***x*** 是输入数据，则对于常规微调，我们可以写如下内容：
- en: '***x.(W+ΔW) = x.W + x.ΔW***'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: '***x.(W+ΔW) = x.W + x.ΔW***'
- en: 'Similarly, we can write the following for LoRA:'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，我们可以为LoRA编写以下内容：
- en: '***x.(W+A.B)** = **x.W + x.A.B***'
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: '***x.(W+A.B)** = **x.W + x.A.B***'
- en: The fact that we can keep the LoRA weight matrices separate makes LoRA especially
    attractive. In practice, this means that we don't have to modify the weights of
    the pretrained model at all, as we can apply the LoRA matrices on the fly. This
    is especially useful if you are considering hosting a model for multiple customers.
    Instead of having to save the large updated models for each customer, you only
    have to save a small set of LoRA weights alongside the original pretrained model.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以保持LoRA权重矩阵分开的事实使LoRA特别吸引人。在实践中，这意味着我们根本不需要修改预训练模型的权重，因为我们可以在运行时应用LoRA矩阵。如果考虑为多个客户托管模型，这将特别有用。与必须为每个客户保存大型更新模型不同，您只需保存一小组LoRA权重以及原始预训练模型。
- en: To make this less abstract and to provide additional intuition, we will implement
    LoRA in code from scratch in the next section.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使这个过程更加具体并提供额外的直觉，我们将在下一节从头开始用代码实现LoRA。
- en: We begin by initializing a `LoRALayer` that creates the matrices A and B, along
    with the alpha scaling hyperparameter and the rank hyperparameters. This layer
    can accept an input and compute the corresponding output, as illustrated in the
    figure below.
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先通过初始化一个 `LoRALayer` 来创建矩阵A和B，以及alpha缩放超参数和排名超参数。这一层可以接受输入并计算相应的输出，如下图所示。
- en: Illustration of the LoRA matrices A and B with rank *r*.
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 展示了LoRA矩阵A和B的排名 *r*。
- en: 'In code, this LoRA layer depicted in the figure above looks like as follows:'
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，上述在图中描述的LoRA层如下所示：
- en: '[PRE0]'
  id: totrans-split-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In the code above, `rank` is a hyperparameter that controls the inner dimension
    of the matrices *A* and *B*. In other words, this parameter controls the number
    of additional parameters introduced by LoRA and is a key factor in determining
    the balance between model adaptability and parameter efficiency.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，`rank` 是控制矩阵 *A* 和 *B* 内部维度的超参数。换句话说，此参数控制LoRA引入的额外参数数量，并且是决定模型适应性与参数效率平衡的关键因素。
- en: The second hyperparameter, `alpha`, is a scaling hyperparameter applied to the
    output of the low-rank adaptation. It essentially controls the extent to which
    the adapted layer's output is allowed to influence the original output of the
    layer being adapted. This can be seen as a way to regulate the impact of the low-rank
    adaptation on the layer's output.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个超参数 `alpha` 是应用于低秩适应输出的缩放超参数。它实质上控制适应层输出对被适应层原始输出的影响程度。这可以看作是调节低秩适应对层输出影响的一种方式。
- en: 'So far, the `LoRALayer` class we implemented above allows us to transform the
    layer inputs `x`. However, in LoRA, we are usually interested in replacing existing
    `Linea`r layers so that the weight update is applied to the existing pretrained
    weights, as shown in the figure below:'
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们上面实现的 `LoRALayer` 类允许我们转换层输入 `x`。然而，在LoRA中，我们通常有兴趣替换现有的线性层，以便将权重更新应用于现有的预训练权重，如下图所示：
- en: '*LoRA applied to an existing linear layer*'
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*应用于现有线性层的LoRA*'
- en: 'To incorporate the original Linear layer weights as shown in the figure above,
    we will implement a `LinearWithLoRA` layer that uses the previously implemented
    `LoRALayer` and can be used to replace existing `Linea`r layers in a neural network,
    for example, the self-attention module or feed forward modules in an LLM:'
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了像上图所示那样融入原始的 Linear 层权重，我们将实现一个 `LinearWithLoRA` 层，它使用先前实现的 `LoRALayer`，并可以用来替换神经网络中现有的
    `Linea`r 层，例如，LLM 中的自注意模块或前馈模块：
- en: '[PRE1]'
  id: totrans-split-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note that since we initialize the weight matrix B (`self.B` in `LoraLayer`)
    with zero values in the LoRA layer, the matrix multiplication between *A* and
    *B* results in a matrix consisting of 0's and doesn't affect the original weights
    (since adding 0 to the original weights does not modify them).
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于在 LoRA 层中用零值初始化权重矩阵 B（`LoraLayer` 中的 `self.B`），矩阵 *A* 和 *B* 的乘积结果是一个由
    0 组成的矩阵，并且不影响原始权重（因为将 0 加到原始权重上不会修改它们）。
- en: 'Let''s try out LoRA on a small neural network layer represented by a single
    `Linear` layer:'
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在一个由单个 `Linear` 层表示的小神经网络层上尝试 LoRA：
- en: '**In:**'
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入：**'
- en: '[PRE2]'
  id: totrans-split-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Out:**'
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE3]'
  id: totrans-split-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, applying LoRA to the `Linea`r layer, we see that the results are the same
    since we haven''t trained the LoRA weights yet. In other words, everything works
    as expected:'
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将 LoRA 应用于 `Linea`r 层，我们看到结果与之前相同，因为我们还没有训练 LoRA 权重。换句话说，一切都如预期地工作：
- en: '**In:**'
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入：**'
- en: '[PRE4]'
  id: totrans-split-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Out:**'
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE5]'
  id: totrans-split-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Earlier, I mentioned the distributive law of matrix multiplication:'
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我提到了矩阵乘法的分配律：
- en: '***x.(W+A.B)** = **x.W + x.A.B***.'
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: '***x.(W+A.B)** = **x.W + x.A.B***。'
- en: 'Here, this means that we can also combine or merge the LoRA matrices and original
    weights, which should result in an equivalent implementation. In code, this alternative
    implementation to the `LinearWithLoRA` layer looks as follows:'
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着我们可以将 LoRA 矩阵和原始权重合并或合并，这应该会得到一个等效的实现。在代码中，这种对 `LinearWithLoRA` 层的替代实现如下所示：
- en: '[PRE6]'
  id: totrans-split-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In short, `LinearWithLoRAMerged` computes the left side of the equation ***x.(W+A.B)**
    = **x.W + x.A.B*** whereas `LinearWithLoRA` computes the right side -- both are
    equivalent.
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，`LinearWithLoRAMerged` 计算方程左侧 ***x.(W+A.B)** = **x.W + x.A.B***，而 `LinearWithLoRA`
    计算右侧 -- 两者等价。
- en: 'We can verify that this results in the same outputs as before via the following
    code:'
  id: totrans-split-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下代码验证这与之前的输出相同：
- en: '**In:**'
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入：**'
- en: '[PRE7]'
  id: totrans-split-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**Out:**'
  id: totrans-split-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE8]'
  id: totrans-split-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Now that we have a working LoRA implementation let's see how we can apply it
    to a neural network in the next section.
  id: totrans-split-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个可行的 LoRA 实现，让我们看看如何在下一节将其应用于神经网络。
- en: Why did we implement LoRA in the manner described above using PyTorch modules?
    This approach enables us to easily replace a `Linear` layer in an existing neural
    network (for example, the feed forward or attention modules of a Large Language
    Model) with our new `LinearWithLoRA` (or `LinearWithLoRAMerged`) layers.
  id: totrans-split-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我们要以上述方式使用 PyTorch 模块实现 LoRA？这种方法使我们能够轻松地用我们的新 `LinearWithLoRA`（或 `LinearWithLoRAMerged`）层替换现有神经网络中的
    `Linear` 层（例如，大语言模型的前馈或注意模块）。
- en: 'For simplicity, let''s focus on a small 3-layer multilayer perceptron instead
    of an LLM for now, which is illustrated in the figure below:'
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为简单起见，我们现在专注于一个小的3层多层感知器，而不是LLM，如下图所示：
- en: A simple 3-layer multilayer perceptron
  id: totrans-split-61
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的3层多层感知器
- en: 'In code, we can implement the multilayer perceptron, shown above, as follows:'
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，我们可以将上述显示的多层感知器实现如下：
- en: '**In:**'
  id: totrans-split-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入：**'
- en: '[PRE9]'
  id: totrans-split-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '**Out:**'
  id: totrans-split-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE10]'
  id: totrans-split-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Using `LinearWithLora`, we can then add the LoRA layers by replacing the original
    `Linear` layers in the multilayer perceptron model:'
  id: totrans-split-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `LinearWithLora`，我们可以通过在多层感知器模型中替换原始的 `Linear` 层来添加 LoRA 层：
- en: '**In:**'
  id: totrans-split-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入：**'
- en: '[PRE11]'
  id: totrans-split-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '**Out:**'
  id: totrans-split-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE12]'
  id: totrans-split-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then, we can freeze the original `Linear` layers and only make the `LoRALaye`r
    layers trainable, as follows:'
  id: totrans-split-72
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以冻结原始的 `Linear` 层，并且只让 `LoRALaye`r 层可训练，如下所示：
- en: '**In:**'
  id: totrans-split-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入：**'
- en: '[PRE13]'
  id: totrans-split-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '**Out:**'
  id: totrans-split-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出：**'
- en: '[PRE14]'
  id: totrans-split-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Based on the `True` and `False` values above, we can visually confirm that only
    the LoRA layers are trainable now (`True` means trainable, `False` means frozen).
    In practice, we would then train the network with this LoRA configuration on a
    new dataset or task.
  id: totrans-split-77
  prefs: []
  type: TYPE_NORMAL
  zh: 基于上述 `True` 和 `False` 的值，我们可以直观地确认现在只有 LoRA 层是可训练的（`True` 表示可训练，`False` 表示冻结）。在实践中，我们将使用这种
    LoRA 配置在新的数据集或任务上训练网络。
- en: 'To avoid making this a very long article, I am skipping over the boilerplate
    code to train this model. But if you are interested in the full code, you can
    find a standalone code notebook here: [https://github.com/rasbt/dora-from-scratch](https://github.com/rasbt/dora-from-scratch).'
  id: totrans-split-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免使本文变得过长，我跳过了用于训练此模型的样板代码。但如果您对完整的代码感兴趣，可以在这里找到一个独立的代码笔记本：[https://github.com/rasbt/dora-from-scratch](https://github.com/rasbt/dora-from-scratch)。
- en: Furthermore, if you are interested in a LoRA from scratch explanation and application
    to an LLM, also check out my Lightning Studio [LoRA From Scratch – Implement Low-Rank
    Adaptation for LLMs in PyTorch](https://lightning.ai/lightning-ai/studios/code-lora-from-scratch).
  id: totrans-split-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果您对从头开始的LoRA解释和应用于LLM的LoRA感兴趣，请还查看我Lightning Studio的[《LoRA从零开始 - 在PyTorch中实现LLM的低秩适应》](https://lightning.ai/lightning-ai/studios/code-lora-from-scratch)。
- en: You may have noticed that we spent a lot of time implementing and talking about
    LoRA. That's because DoRA ([Weight-Decomposed Low-Rank Adaptation](https://arxiv.org/abs/2402.09353))
    can be seen as an improvement or extension of LoRA that is built on top of it,
    and we can now easily adapt some of our previous code to implement DoRA.
  id: totrans-split-80
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到，我们花了很多时间实施和讨论LoRA。这是因为DoRA（[Weight-Decomposed Low-Rank Adaptation](https://arxiv.org/abs/2402.09353)）可以被看作是在LoRA基础上构建的改进或扩展，我们现在可以轻松地调整之前的一些代码来实现DoRA。
- en: DoRA can be described in two steps, where the first step is to decompose a pretrained
    weight matrix into a magnitude vector (***m***) and a directional matrix (***V***).
    The second step is applying LoRA to the directional matrix ***V*** and training
    the magnitude vector ***m*** separately.
  id: totrans-split-81
  prefs: []
  type: TYPE_NORMAL
  zh: DoRA可以用两步来描述，其中第一步是将预训练的权重矩阵分解为幅度向量(***m***)和方向矩阵(***V***）。第二步是将LoRA应用于方向矩阵***V***并分别训练幅度向量***m***。
- en: The decomposition into magnitude and directional components is inspired by the
    mathematical principle that any vector can be represented as the product of its
    magnitude (a scalar value indicating its length) and its direction (a unit vector
    indicating its orientation in space).
  id: totrans-split-82
  prefs: []
  type: TYPE_NORMAL
  zh: 将向量分解为幅度和方向两个部分的方法灵感来自数学原理，即任何向量都可以表示为其幅度（表示其长度的标量值）和其方向（表示其在空间中方向的单位向量）的乘积。
- en: Illustration of the direction and magnitude of a single vector. For example,
    if have a 2D vector [1, 2], we can decompose it into a magnitude 2.24 and a directional
    vector [0.447, 0.894]. Then 2.24 * [0.447, 0.894] = [1, 2].
  id: totrans-split-83
  prefs: []
  type: TYPE_NORMAL
  zh: 单个向量的方向和幅度的示意图。例如，如果有一个二维向量[1, 2]，我们可以将其分解为幅度2.24和方向向量[0.447, 0.894]。然后，2.24
    * [0.447, 0.894] = [1, 2]。
- en: In DoRA, we apply the decomposition into magnitude and directional components
    to a whole pretrained weight matrix ***W*** instead of a vector, where each column
    (vector) of the weight matrix corresponds to the weights connecting all inputs
    to a particular output neuron.
  id: totrans-split-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在DoRA中，我们将预训练的整个权重矩阵***W***分解为幅度和方向两个部分，其中权重矩阵的每列（向量）对应于连接所有输入到特定输出神经元的权重。
- en: So, the result of decomposing ***W*** is a magnitude vector ***m*** that represents
    the scale or length of each column vector in the weight matrix, as illustrated
    in the figure below.
  id: totrans-split-85
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，分解***W***的结果是一个表示权重矩阵中每个列向量的规模或长度的幅度向量***m***，如下图所示。
- en: Illustration of the weight matrix decomposition in DoRA
  id: totrans-split-86
  prefs: []
  type: TYPE_NORMAL
  zh: DoRA中权重矩阵分解的示意图
- en: 'Then, DoRA takes the directional matrix ***V*** and applies standard LoRA,
    for instance:'
  id: totrans-split-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，DoRA使用方向矩阵***V***并应用标准LoRA，例如：
- en: '***W'' = m (V + ΔV)/norm = m (W + AB)/norm***'
  id: totrans-split-88
  prefs: []
  type: TYPE_NORMAL
  zh: '***W'' = m (V + ΔV)/norm = m (W + AB)/norm***'
- en: 'The normalization, which I abbreviated as "norm" to not further complicate
    things in this overview, is based on the weight normalization method proposed
    in Saliman''s and Kingma''s 2016 [Weight Normalization: A Simple Reparameterization
    to Accelerate Training of Deep Neural Networks paper](https://arxiv.org/abs/1602.07868).'
  id: totrans-split-89
  prefs: []
  type: TYPE_NORMAL
  zh: '归一化，我在这个概述中简称为"norm"，是基于Saliman和Kingma在2016年提出的《[Weight Normalization: A Simple
    Reparameterization to Accelerate Training of Deep Neural Networks](https://arxiv.org/abs/1602.07868)》论文中提出的权重归一化方法。'
- en: The DoRA two-step process (decomposing a pretrained weight matrix and applying
    LoRA to the directional matrix) is further illustrated in the figure from the
    DoRA paper below.
  id: totrans-split-90
  prefs: []
  type: TYPE_NORMAL
  zh: DoRA的两步过程（将预训练的权重矩阵分解并将LoRA应用于方向矩阵）在下面的DoRA论文中的图表中进一步说明。
- en: The motivation for developing DoRA is based on analyzing and comparing the LoRA
    and full finetuning learning patterns. The DoRA authors found that LoRA either
    increases or decreases magnitude and direction updates proportionally but seems
    to lack the capability to make only subtle directional changes as found in full
    finetuning. Hence, the researchers propose the decoupling of magnitude and directional
    components.
  id: totrans-split-91
  prefs: []
  type: TYPE_NORMAL
  zh: 开发 DoRA 的动机基于分析和比较 LoRA 和完全微调学习模式。DoRA 的作者发现，LoRA 可能会等比例增加或减少大小和方向更新，但似乎缺乏在完全微调中发现的仅进行细微方向更改的能力。因此，研究人员提出了大小和方向分量的解耦。
- en: In other words, their DoRA method aims to apply LoRA only to the directional
    component, ***V***, while also allowing the magnitude component, ***m***, to be
    trained separately.
  id: totrans-split-92
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，他们的 DoRA 方法旨在仅对方向分量 ***V*** 应用 LoRA，同时允许大小分量 ***m*** 分别进行训练。
- en: Introducing the magnitude vector m adds 0.01% more parameters if DoRA is compared
    to LoRA. However, across both LLM and vision transformer benchmarks, they found
    that DoRA even outperforms LoRA if the DoRA rank is halved, for instance, when
    DoRA only uses half the parameters of regular LoRA, as shown in the performance
    comparison below.
  id: totrans-split-93
  prefs: []
  type: TYPE_NORMAL
  zh: 引入大小向量 ***m*** 如果与 LoRA 相比，DoRA 将增加 0.01% 的参数。然而，在 LLM 和视觉变换器基准测试中，他们发现，即使将
    DoRA 的秩减半，例如当 DoRA 仅使用正常 LoRA 参数的一半时，DoRA 的性能仍然优于 LoRA，如下面的性能比较所示。
- en: 'As I wrote in another article a few months ago, LoRA requires careful tuning
    of the rank to optimize performance: [Practical Tips for Finetuning LLMs Using
    LoRA (Low-Rank Adaptation](https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms)). However,
    DoRA seems to be much more robust to changes in rank, as shown in the comparison
    below.'
  id: totrans-split-94
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我几个月前在另一篇文章中所写的，LoRA 需要精心调整秩以优化性能：[使用 LoRA（低秩适应）进行微调LLM的实用技巧](https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms-using-lora)。然而，DoRA
    在秩的变化上似乎更加稳健，如下面的比较所示。
- en: The possibility to successfully use DoRA with relatively small ranks makes this
    method even more parameter-efficient than LoRA.
  id: totrans-split-95
  prefs: []
  type: TYPE_NORMAL
  zh: 成功使用较小秩的 DoRA 的可能性使得这种方法比 LoRA 更加参数高效。
- en: Overall, I am quite impressed by the results, and it should not be too big of
    a lift to upgrade a LoRA implementation to DoRA, which we will do in the next
    section.
  id: totrans-split-96
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我对结果印象深刻，并且将 LoRA 实现升级为 DoRA 应该不会太困难，我们将在下一节中完成。
- en: 'In this section, we will see what DoRA looks like in code. Previously, we said
    that we can initialize a pretrained weight ***W[0]*** with magnitude ***m*** and
    directional component ***V***. For instance, we have the following equation:'
  id: totrans-split-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将看到 DoRA 在代码中的实现。之前我们说过，我们可以使用大小 ***m*** 和方向分量 ***V*** 初始化预训练权重 ***W[0]***。例如，我们有以下方程：
- en: \(W_0 = m \frac{V}{||V||_c} \)
  id: totrans-split-98
  prefs: []
  type: TYPE_NORMAL
  zh: \(W_0 = m \frac{V}{||V||_c} \)
- en: 'where ||***V***||[c] is the vector-wise norm of ***V***. Then we can write
    DoRA including the LoRA weight update ***BA*** as shown below:'
  id: totrans-split-99
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ||***V***||[c] 是向量 ***V*** 的向量范数。然后我们可以像下面这样编写包括 LoRA 权重更新 ***BA*** 的 DoRA：
- en: \(W^{\prime}=m \frac{V+BA}{\|V+BA\|_c}\)
  id: totrans-split-100
  prefs: []
  type: TYPE_NORMAL
  zh: \(W^{\prime}=m \frac{V+BA}{\|V+BA\|_c}\)
- en: 'Now, in the DoRA paper, the authors formulate DoRA as follows, where they use
    the initial pretrained weights *W[0]* as the directional component directly and
    learn magnitude vector ***m*** during training:'
  id: totrans-split-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在 DoRA 论文中，作者将 DoRA 阐述如下，他们在训练期间使用初始预训练权重 *W[0]* 作为方向分量，并学习大小向量 ***m***：
- en: \(W^{\prime}={m} \frac{V+\Delta V}{\|V+\Delta V\|_c}={m} \frac{W_0+{B A}}{\left\|W_0+{B
    A}\right\|_c}\)
  id: totrans-split-102
  prefs: []
  type: TYPE_NORMAL
  zh: \(W^{\prime}={m} \frac{V+\Delta V}{\|V+\Delta V\|_c}={m} \frac{W_0+{B A}}{\left\|W_0+{B
    A}\right\|_c}\)
- en: Here, ***ΔV*** is the update to the directional component, matrix ***V***.
  id: totrans-split-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，***ΔV*** 是方向分量矩阵 ***V*** 的更新。
- en: While the original authors haven't released the official implementation yet,
    you can find an independent implementation [here](https://github.com/catid/dora/blob/main/dora.py),
    which loosely inspired my implementation below
  id: totrans-split-104
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然原始作者尚未发布官方实现，但你可以在[这里](https://github.com/catid/dora/blob/main/dora.py)找到一个独立的实现，这个实现粗略地启发了我下面的实现。
- en: 'Taking our previous `LinearWithLoRAMerged` implementation, we can upgrade it
    to DoRA as follows:'
  id: totrans-split-105
  prefs: []
  type: TYPE_NORMAL
  zh: 利用我们之前的 `LinearWithLoRAMerged` 实现，我们可以将其升级为 DoRA，如下所示：
- en: '[PRE15]'
  id: totrans-split-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The `LinearWithDoRAMerged` class is different from our previous `LinearWithLoRAMerged`
    class in several key aspects, primarily in how it modifies and applies the weights
    of the Linear layer. However, both classes integrate a `LoRALayer` to augment
    the original linear layer's weights, but DoRA adds weight normalization and adjustment.
  id: totrans-split-107
  prefs: []
  type: TYPE_NORMAL
  zh: '`LinearWithDoRAMerged` 类在几个关键方面与我们之前的 `LinearWithLoRAMerged` 类不同，主要体现在如何修改和应用线性层权重上。然而，两个类都整合了
    `LoRALayer` 来增强原始线性层的权重，但是DoRA添加了权重归一化和调整。'
- en: 'The figure below shows a file-diff of both classes side by side:'
  id: totrans-split-108
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了两个类的文件差异并排显示：
- en: File-diff between `LinearWithLoRAMerged` and `LinearWithDoRAMerged`
  id: totrans-split-109
  prefs: []
  type: TYPE_NORMAL
  zh: '`LinearWithLoRAMerged` 和 `LinearWithDoRAMerged` 的文件差异'
- en: As we can see in the figure above, `LinearWithDoRAMerged` introduces an additional
    step involving dynamic normalization of the augmented weights.
  id: totrans-split-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如上图所示，`LinearWithDoRAMerged` 引入了一个额外步骤，涉及对增强权重进行动态归一化。
- en: After combining the original weights with the LoRA-adjusted weights (`self.linear.weight
    + self.lora.alpha*lora.T`), it calculates the norm of these combined weights across
    columns (`column_norm`). Then, it normalizes the combined weights by dividing
    them by their norms (`V = combined_weight / column_norm`). This step ensures that
    each column of the combined weight matrix has a unit norm, which can help stabilize
    the learning process by maintaining the scale of weight updates.
  id: totrans-split-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在将原始权重与LoRA调整后的权重（`self.linear.weight + self.lora.alpha*lora.T`）合并后，计算这些组合权重在列方向上的范数（`column_norm`）。然后，通过将它们除以它们的范数来对组合权重进行归一化（`V
    = combined_weight / column_norm`）。这一步确保了组合权重矩阵的每列具有单位范数，从而通过保持权重更新的规模来稳定学习过程。
- en: DoRA also introduces a learnable vector `self.m`, which represents the magnitude
    of each column of the normalized weight matrix. This parameter allows the model
    to dynamically adjust the scale of each weight vector in the combined weight matrix
    during training. This additional flexibility can help the model better capture
    the importance of different features.
  id: totrans-split-112
  prefs: []
  type: TYPE_NORMAL
  zh: DoRA还引入了一个可学习的向量 `self.m`，表示归一化权重矩阵每列的大小。该参数允许模型在训练过程中动态调整组合权重矩阵中每个权重向量的比例。这种额外的灵活性有助于模型更好地捕捉不同特征的重要性。
- en: In summary, `LinearWithDoRAMerged` extends the concept of `LinearWithLoRAMerged`
    by incorporating dynamic weight normalization and scaling to improve the training
    performance.
  id: totrans-split-113
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，`LinearWithDoRAMerged` 通过引入动态权重归一化和调整来扩展了 `LinearWithLoRAMerged` 的概念，从而提高了训练性能。
- en: 'In practice, considering the multilayer perceptron from earlier, we can simply
    swap existing Linear layers with our `LinearWithDoRAMerged` layers as follows:'
  id: totrans-split-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，考虑到之前的多层感知机，我们可以简单地将现有的线性层替换为我们的 `LinearWithDoRAMerged` 层，如下所示：
- en: '**In:**'
  id: totrans-split-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入:**'
- en: '[PRE16]'
  id: totrans-split-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '**Out:**'
  id: totrans-split-117
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出:**'
- en: '[PRE17]'
  id: totrans-split-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Before we finetune the model, we can reuse the `freeze_linear_layers` function
    we implemented earlier to only make the LoRA weights and magnitude vectors trainable:'
  id: totrans-split-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调模型之前，我们可以重用之前实现的 `freeze_linear_layers` 函数，仅使LoRA权重和幅度向量可训练：
- en: '**In:**'
  id: totrans-split-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**输入:**'
- en: '[PRE18]'
  id: totrans-split-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '**Out:**'
  id: totrans-split-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**输出:**'
- en: '[PRE19]'
  id: totrans-split-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '**The full code example, including model training, is available in my GitHub
    repo here: [https://github.com/rasbt/dora-from-scratch](https://github.com/rasbt/dora-from-scratch).**'
  id: totrans-split-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**包括模型训练的完整代码示例可在我的GitHub仓库中找到：[https://github.com/rasbt/dora-from-scratch](https://github.com/rasbt/dora-from-scratch).**'
- en: In my opinion, DoRA seems like a logical, effective, and promising extension
    of LoRA, and I am excited to try it in real-world LLM finetuning contexts.
  id: totrans-split-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在我看来，DoRA似乎是LoRA的一个逻辑、有效和有前景的扩展，我很兴奋地想在真实的LLM微调环境中尝试它。
- en: In the meantime, I also added the DoRA implementation above to the [LoRA From
    Scratch – Implement Low-Rank Adaptation for LLMs in PyTorch](https://lightning.ai/lightning-ai/studios/code-lora-from-scratch)
    Lightning Studio to finetune a DistilBERT language model (see `bonus_02_finetune-with-dora.ipynb`).
    Even without hyperparameter tuning, I already saw a >1% prediction accuracy improvement
    over LoRA.
  id: totrans-split-126
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，我还将上述的DoRA实现添加到[LoRA从零开始 - 在PyTorch中为LLM实现低秩适应](https://lightning.ai/lightning-ai/studios/code-lora-from-scratch)
    Lightning Studio，用于微调DistilBERT语言模型（参见 `bonus_02_finetune-with-dora.ipynb`）。即使没有超参数调整，我已经看到比LoRA更高超过1%的预测准确率提升。
- en: '* * *'
  id: totrans-split-127
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: '*This magazine is personal passion project that does not offer direct compensation.
    However, for those who wish to support me, please consider purchasing a copy of
    [one of my books](https://sebastianraschka.com/books). If you find them insightful
    and beneficial, please feel free to recommend them to your friends and colleagues.*'
  id: totrans-split-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*这本杂志是我个人的热情项目，不提供直接的报酬。但是，对于那些希望支持我的人，请考虑购买一本[我的书籍之一](https://sebastianraschka.com/books)。如果你觉得它们有见地且有益，请随时向你的朋友和同事推荐。*'
- en: '**Your support means a great deal! Thank you!**'
  id: totrans-split-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**你的支持对我意义重大！谢谢！**'
