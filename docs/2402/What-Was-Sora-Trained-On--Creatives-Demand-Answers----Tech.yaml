- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 15:04:12'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: What Was Sora Trained On? Creatives Demand Answers. - Tech
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://in.mashable.com/tech/69813/what-was-sora-trained-on-creatives-demand-answers](https://in.mashable.com/tech/69813/what-was-sora-trained-on-creatives-demand-answers)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: On Thursday, OpenAI once again shook up the AI world with a video generation
    model called Sora.
  prefs: []
  type: TYPE_NORMAL
- en: The demos showed photorealistic videos with crisp detail and complexity, based
    off of simple text prompts. A [video](https://twitter.com/heyBarsee/status/1758377540870160442)
    based on the prompt "Reflections in the window of a train traveling through the
    Tokyo suburbs" looked like it was filmed on a phone, shaky camera work and reflections
    of train passengers included. No weird distorted hands in sight.
  prefs: []
  type: TYPE_NORMAL
- en: A video from the prompt, "A movie trailer featuring the adventures of the 30
    year old space man wearing a red wool knitted motorcycle helmet, blue sky, salt
    desert, cinematic style, shot on 35mm film, vivid colors" looked like a Christopher
    Nolan-Wes Anderson hybrid.
  prefs: []
  type: TYPE_NORMAL
- en: Another of golden retriever puppies playing in the snow rendered soft fur and
    fluffy snow so realistic you could reach out and touch it.
  prefs: []
  type: TYPE_NORMAL
- en: The 7 trillion dollar question is, how did OpenAI achieve this? We don't actually
    know because OpenAI has barely shared anything about its training data. But in
    order to create a model this advanced, Sora needed lots of video data, so we can
    assume it was trained on video data scraped from all corners of the internet.
    And some are speculating that training data included copyrighted works. OpenAI
    did not immediately respond to request for comment on Sora's training data.
  prefs: []
  type: TYPE_NORMAL
- en: 'In OpenAI''s [technical paper](https://openai.com/research/video-generation-models-as-world-simulators)
    it largely focuses on the method for achieving these results: Sora is a diffusion
    model that turns visual data into "patches" or pieces of data that the model can
    understand. But there''s scant mention of where the visual data came from.'
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI says it “take[s] inspiration from large language models which acquire
    generalist capabilities by training on internet-scale data.” The incredibly vague
    “taking inspiration” part is the only evasive reference to the source of Sora’s
    training data. Further down in the paper, OpenAI says, “training text-to-video
    generation systems requires a large amount of videos with corresponding text captions.”
    The only source of a massive amount of visual data can be found on the internet,
    another hint at where Sora comes from.
  prefs: []
  type: TYPE_NORMAL
- en: The legal and ethical issue of how training data is acquired for AI models has
    been around ever since OpenAI launched ChatGPT. Both [OpenAI](https://mashable.com/article/openai-chatgpt-class-action-lawsuit)
    and [Google](/tech/56360/google-slapped-with-a-lawsuit-for-secretly-stealing-data-to-train-bard)
    have been accused of “stealing” data to train their language models, in other
    words using data scraped from social media, online forums like Reddit and Quora,
    Wikipedia, databases of private books, and news sites.
  prefs: []
  type: TYPE_NORMAL
- en: Until now the rationale for scraping the entirety of the internet for training
    data is that it's publicly-available. But publicly-available [doesn't always translate](https://x.com/ednewtonrex/status/1758259614414770626?s=20)
    to public domain. Case in point, the *New York Times* is [suing](/tech/66470/the-new-york-times-sues-openai-and-microsoft-for-copyright-infringement)
    OpenAI and Microsoft for copyright infringement, alleging OpenAI's models used
    the *Times*' works word for word or incorrectly cited the stories.
  prefs: []
  type: TYPE_NORMAL
- en: Now it looks like OpenAI is doing the same thing, but with video. If this is
    the case, you can expect heavy-hitters in the entertainment industry to have something
    to say about it.
  prefs: []
  type: TYPE_NORMAL
- en: 'But the problem remains: We still don''t know the source of Sora''s training
    data. "The company (despite its name) has been characteristically close-lipped
    about what they have trained the models on," [wrote](https://garymarcus.substack.com/p/soras-surreal-physics)
    Gary Marcus, an AI expert who testified at the U.S. Senate AI Oversight Committee
    hearing. " Many people have [speculated] that there’s probably a lot of stuff
    in there that is generated from game engines like Unreal. I would not at all be
    surprised if there also had been lots of training on YouTube visited, and various
    copyrighted materials," said Marcus, before adding, "Artists are presumably getting
    really screwed here."'
  prefs: []
  type: TYPE_NORMAL
- en: Despite OpenAI's refusal to divulge its secrets, artists and creatives are assuming
    the worst. Justine Bateman, a filmmaker and SAG-AFTRA generative AI advisor didn't
    mince words. "Every nanosecond of this [#AI](https://twitter.com/hashtag/AI?src=hashtag_click)
    garbage is trained on stolen work by real artists," [posted](https://x.com/JustineBateman/status/1758220737675145553?s=20)
    Bateman on X. "Repulsive," she added.
  prefs: []
  type: TYPE_NORMAL
- en: Others in creative industries are concerned about how the rise of Sora and video
    generating models will affect their jobs. "I work in film vfx, practically everyone
    I know is doom and gloom, panicking about what to do now," [posted](https://twitter.com/jimmylanceworth/status/1758445030736285961)
    @jimmylanceworth.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI didn't completely ignore the explosive impact Sora might have. But that's
    largely focused on potential harms involving deepfakes and misinformation. It
    is currently in red-teaming phase, which means it's being stress-tested for inappropriate
    and harmful content. Towards the end of its announcement, OpenAI said it will
    be "engaging policymakers, educators and artists around the world to understand
    their concerns and to identify positive use cases for this new technology."
  prefs: []
  type: TYPE_NORMAL
- en: But that doesn't address the harms that may have already occurred by making
    Sora in the first place.
  prefs: []
  type: TYPE_NORMAL
