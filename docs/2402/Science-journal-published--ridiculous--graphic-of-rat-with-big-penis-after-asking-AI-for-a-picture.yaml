- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 15:00:41'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: Science journal published 'ridiculous' graphic of rat with big penis after asking
    AI for a picture
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://www.telegraph.co.uk/news/2024/02/16/journal-published-graphic-rat-with-giant-penis-asking-ai/](https://www.telegraph.co.uk/news/2024/02/16/journal-published-graphic-rat-with-giant-penis-asking-ai/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It might be considered an AI cock-up on a massive scale.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: A scientific paper purporting to show the signalling pathway of sperm stem cells
    has met with widespread ridicule after it depicted a rodent with an anatomically
    eye-watering appendage and four giant testicles.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: The creature, labelled “rat”, was also sitting upright in the manner of a squirrel,
    while the graphic was littered with nonsensical words such as “dissilced”, “testtomcels”
    and “senctolic”.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: A cut-away image showed “sterrn cells” in a Petri dish being picked up with
    a spoon.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
- en: It appeared in the journal Frontiers in Cell and Development Biology this week
    alongside several other absurd graphics that had been [generated by the AI tool
    Midjourney.](https://www.telegraph.co.uk/films/0/ai-fake-movies-midjourney-hollywood/)
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
- en: They included a multicoloured JAK-STAT signalling pathway diagram which experts
    likened to “some crazy level of Candy Crush” and said was not grounded in “any
    known biology”.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
- en: The paper, written by researchers at the Honghui Hospital in China, has since
    been retracted by the journal, which issued an apology and said it was working
    to “correct the record”.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
- en: Dangers of faked research
  id: totrans-split-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: But several scientists have expressed concern as to how it was published in
    the first place, and warn it heralds a dangerous era of researchers [faking their
    work using AI](https://www.telegraph.co.uk/business/2023/10/01/news-publishers-warn-ai-will-pollute-human-knowledge/).
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
- en: 'Adrian Liston, professor of pathology at Cambridge University and editor of
    the journal Immunology & Cell Biology, said: “Generative AI is very good at making
    things that sound like they come from a human being. It doesn’t check whether
    those things are correct.'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
- en: “It is like an actor playing a doctor on a TV show – they look like a doctor,
    they sound like a doctor, they even use words that a doctor would use. But you
    wouldn’t want to get medical advice from the actor.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
- en: “The JAK figure is even worse than the rat figure, in my opinion. There are
    simply meaningless connections and lines that don’t associate with any known biology.”
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
- en: 'He added: “The problem for real journals is getting harder, because [generative
    AI](https://www.telegraph.co.uk/business/2023/07/03/ai-chatgpt-chatbots-spam-fake-images-lives-worse/)
    makes it easier for cheats.'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
- en: “It used to be really obvious to tell cheat papers at a glance. It is getting
    harder, and a lot of people in scientific publishing are getting genuinely concerned
    that we will reach a tipping point where we won’t be able to manually tell whether
    an article is genuine or a fraud.”
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
- en: Other scientists took to social media to describe the graphics as “absolutely
    shameful” and “devastating”, while some said they didn’t know “whether to laugh
    or cry”.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 其他科学家纷纷在社交媒体上将这些图形描述为“绝对令人羞耻”和“毁灭性”，而有些人表示他们不知道“是该笑还是哭”。
- en: Prof John Tregoning, of Imperial College London, said the graphics were “objectively
    funny” but “have no place in science journals”.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 伦敦帝国学院的John Tregoning教授说这些图形“在客观上很滑稽”，但“在科学期刊中没有存在的必要”。
- en: A good laugh
  id: totrans-split-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一阵大笑
- en: 'Writing on the Science Integrity Digest, [Dr Elisabeth Bik, the Dutch microbiologist
    who works spotting manipulation in scientific papers](https://www.telegraph.co.uk/health-fitness/doctors-diary/covid-unleashed-tsunami-bad-science/),
    said: “Of course, we can have a good laugh at these figures, and wonder how on
    earth the handling editor and the two peer reviewers didn’t catch this.'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在《科学诚信简报》上写道，[荷兰微生物学家Elisabeth Bik博士，致力于发现科学论文中的操纵行为](https://www.telegraph.co.uk/health-fitness/doctors-diary/covid-unleashed-tsunami-bad-science/)，她说：“当然，我们可以对这些数据笑个痛快，不禁要问编辑和两位同行评审怎么会漏掉这一点。”
- en: “But the paper is actually a sad example of how scientific journals, editors,
    and peer reviewers can be naive in terms of accepting and publishing AI-generated
    crap.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: “但这篇文章实际上是科学期刊、编辑和同行评审在接受和发表由人工智能生成的垃圾方面的一个悲哀的例子。”
- en: “These figures are clearly not scientifically correct, but if such botched illustrations
    can pass peer review so easily, more realistic-looking AI-generated figures have
    likely already infiltrated the scientific literature.”
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: “这些数据显然在科学上不正确，但如果这样的糟糕插图可以轻易通过同行评审，看起来更真实的AI生成的数据很可能已经渗透到科学文献中。”
- en: Dr Bik has identified more than 1,000 papers which have fraudulent imagery,
    most of which she believes was generated by AI.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: Bik博士已经确认超过1,000篇具有欺诈性图像的论文，其中大部分据信是由AI生成的。
- en: Companies are [attempting to develop software that will detect AI-generated
    content](https://www.telegraph.co.uk/business/2023/05/15/google-tools-spot-fake-ai-images-pope-puffer-jacket/)
    and in the future it may be watermarked, but currently there is no way to spot
    it unless it is glaringly wrong.
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 公司正在[尝试开发软件来检测由AI生成的内容](https://www.telegraph.co.uk/business/2023/05/15/google-tools-spot-fake-ai-images-pope-puffer-jacket/)，未来可能会加水印，但目前除非显著错误，否则无法发现。
- en: 'A spokesman for Frontiers in Cell and Development Biology said: “We thank the
    readers for their scrutiny of our articles: when we get it wrong, the crowdsourcing
    dynamic of open science means that community feedback helps us to quickly correct
    the record.”'
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 发表在《细胞与发育生物学前沿》的一位发言人表示：“我们感谢读者对我们文章的审查：当我们犯错时，开放科学的众包动态意味着社区反馈帮助我们迅速纠正记录。”
- en: The Telegraph has approached the authors for comment.
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 电讯报已联系作者进行评论。
