- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:41:05'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Implementing System-Versioned Tables in Postgres
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://hypirion.com/musings/implementing-system-versioned-tables-in-postgres](https://hypirion.com/musings/implementing-system-versioned-tables-in-postgres)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I like Postgres, but there are things I really wish they would implement. For
    example, the [SQL:2011](https://en.wikipedia.org/wiki/SQL:2011) spec adds support
    for system-versioned tables. Unfortunately, Postgres and SQLite are basically
    the only SQL databases that don’t yet support it. While it has been discussed
    in length at the [postgreqsl-hackers’ mailing list](https://www.postgresql.org/message-id/flat/CALAY4q-cXCD0r4OybD%3Dw7Hr7F026ZUY6%3DLMsVPUe6yw_PJpTKQ%40mail.gmail.com),
    it seems like the discussion and implementation efforts have been silent in all
    of 2023.
  prefs: []
  type: TYPE_NORMAL
- en: Now, there are extensions out there that implement versioning – [`temporal_tables`](https://clarkdave.net/2015/02/historical-records-with-postgresql-and-temporal-tables-and-sql-2011/)
    being the most popular I think – but none are supported for managed Postgres instances
    on e.g. Azure or AWS. This means that if we want system-versioned tables, we’re
    forced to make it ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: I’m not going to spend paragraph after paragraph explaining why I want temporal
    tables before we go to the actual implementation, but I’d like to note that I
    want to use these tables primarily for user data, generated by users when they
    click/type something on a webpage. They can be used for other things, but if you
    have time series, want to do event sourcing or online analytical processing, you
    should probably pick some technology suited for that task instead of throwing
    temporal tables at it.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re only after the end result, feel free to go to my GitHub repository
    [time-travelling-todo-lists-in-postgres](https://github.com/hypirion/time-travelling-todo-lists-in-postgres).
    It is a todo list app with time-travelling capabilities, using the implementation
    described here. There you’ll have information on how to use it yourself, how to
    query the past, as well as gotchas and common pitfalls.
  prefs: []
  type: TYPE_NORMAL
- en: The Implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The implementation I’ve decided on consists of two tables for every table I
    want version controlled: A snapshot table for the current state, and a history
    table.'
  prefs: []
  type: TYPE_NORMAL
- en: <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 116.798 35.169"><text xml:space="preserve"
    x="30.997" y="45.291" transform="translate(-19.358 -27.08)"><tspan x="30.997"
    y="45.291">Snapshot</tspan><tspan x="30.997" y="50.582">Table</tspan></text><text
    xml:space="preserve" x="103.227" y="45.729" transform="translate(-19.358 -27.08)"><tspan
    x="103.227" y="45.729">History</tspan><tspan x="103.227" y="51.021">Table</tspan></text><text
    xml:space="preserve" x="69.26" y="33.634" transform="translate(-19.358 -27.08)"><tspan
    x="69.26" y="33.634">Inserts</tspan><tspan x="69.26" y="37.603">Updates</tspan><tspan
    x="69.26" y="41.572">Deletes</tspan></text></svg>
  prefs: []
  type: TYPE_NORMAL
- en: 'The snapshot table is the one used for the current state of the world and is
    the one you’ll usually work with: This works exactly like any other mutable in-place
    table you’re familiar with. The history table is the one you’ll use when you want
    to query through history.'
  prefs: []
  type: TYPE_NORMAL
- en: 'First off, we define the tables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The history table contains the exact same fields as the snapshot table, but
    the first two columns in the table are a `history_id` field and the system time
    (`systime`) it was active. `lower(systime)` is when this version of the record
    was initially stored, and `upper(systime)` is when this record was no longer valid.
    When `upper(systime)` is infinity, the record has not yet been deleted. The interval
    can’t be empty obviously, as that wouldn’t match any time interval.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we have a GiST index, which prevents us from having overlapping time intervals
    for the same primary key, and also speeds up queries on the history. You may want
    to add some more indices on the history table, depending on what kind of queries
    you want to do on it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we set up triggers for insert, update and delete:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This is… long, to put it mildly, so let’s go through some common tricks all
    the three triggers (ab)use, and then go over some design decisions I’ve decided
    on for updates and deletes. We’ll get around to shortening it at the end.
  prefs: []
  type: TYPE_NORMAL
- en: Column Order Matters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Whenever we insert new data into the history table, it will always be on this
    form:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'There are two parts of Postgres we abuse here. If we look at [the docs for
    INSERT](https://www.postgresql.org/docs/16/sql-insert.html), we’ll see the following
    paragraph:'
  prefs: []
  type: TYPE_NORMAL
- en: The target column names can be listed in any order. If no list of column names
    is given at all, the default is all the columns of the table in their declared
    order; or the first ***N*** column names, if there are only ***N*** columns supplied
    by the `VALUES` clause or ***`query`***. The values supplied by the `VALUES` clause
    or ***`query`*** are associated with the explicit or implicit column list left-to-right.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The other is that `NEW.*` expands in the exact same order. In our case, `NEW.*`
    will expand into `NEW.mytable_id, NEW.data`, and that means it fits perfectly
    with the rows of `mytable_history`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This is pretty clever, but it’s also hacky. For this to work, there are two
    things you have to get right:'
  prefs: []
  type: TYPE_NORMAL
- en: Column order MUST be identical after the `history_id` and `systime` columns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whenever you add new columns, you MUST add them in the same order to both tables.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you don’t do so, you will end up with broken inserts in the history table.
    Those will at best give you an error, but they can also silently corrupt your
    data.
  prefs: []
  type: TYPE_NORMAL
- en: I don’t like that, but there’s a reason why I don’t do
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: and that’s because it creates **a lot** of effort when you want to remove, rename
    or add a new column to the table. By omitting the list of target column names
    and expanding `NEW.*`, the query will automatically work whenever I decide to
    add, update or remove columns – provided I do it for both tables.
  prefs: []
  type: TYPE_NORMAL
- en: On System Time
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you haven’t worked with Postgres ranges before, the range queries may look
    a bit cryptic. The Postgres docs have an excellent description of [range types](https://www.postgresql.org/docs/16/rangetypes.html)
    and [range functions](https://www.postgresql.org/docs/16/functions-range.html),
    which should cover essentially everything related to them. I don’t use much of
    it though, so since I guess you don’t want to go through it all, I’ll just list
    up what the different parts do.
  prefs: []
  type: TYPE_NORMAL
- en: The expression
  prefs: []
  type: TYPE_NORMAL
- en: 'creates the timestamptz range `[a, b)`: from *a*, up to and excluding *b*.
    If either *a* or *b* are `NULL`, then they are infinitely far in the past or future,
    respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: '`lower(x)` returns the lower bound of the range, and `upper_inf(x)` returns
    true if the upper bound is infinite.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, `systime @> NOW()` checks if `systime` contains `NOW()` – you can think
    of it as `a <= NOW() AND NOW() < b`.
  prefs: []
  type: TYPE_NORMAL
- en: The reason for using ranges isn’t primarily because I want to use these functions,
    but rather because the GiST index ensures no overlap and makes me less worried
    that my queries will be super slow by accident.
  prefs: []
  type: TYPE_NORMAL
- en: Inserts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With those two things described, inserts are more or less described in their
    entirety: We insert the row into the history table, saying it’s valid from the
    transaction start time until forever.'
  prefs: []
  type: TYPE_NORMAL
- en: Updates
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The update trigger looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: It is set up so that multiple updates in the same transaction will only produce
    a single history row. That’s intentional, because otherwise ordering would be
    harder to implement.
  prefs: []
  type: TYPE_NORMAL
- en: If you need multiple versions in the same transaction, you’ll have to replace
    the half-open interval (the default `[)`) with a closed one (`[]`). If not, you’ll
    end up with empty intervals, which aren’t tied to any timestamps. But now you
    have to handle identical states at a single timestamp, as multiple records can
    get the `[NOW(), NOW()]` interval. If the ordering matters in that case, you’ll
    have to add another ordering ID to get rows back in the inserted order.
  prefs: []
  type: TYPE_NORMAL
- en: I don’t need that, it’s complicated, and I don’t think it makes sense to have
    multiple states at a single point in time anyway. If you need that, you’re probably
    interested in an event table or something else instead.
  prefs: []
  type: TYPE_NORMAL
- en: Deletions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: When it comes to atomicity, deletions are somewhat of an outlier. If you update
    and then delete something in the same transaction, what should you do? And uh..
    why would you do that in the first place?
  prefs: []
  type: TYPE_NORMAL
- en: '“Update and delete” seems quite handy if you want to write down who deleted
    the object, in which case the deletion will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '… however, it leaves you with an annoying record: The “delete” record, which
    isn’t really part of the history, but only contains some information about the
    deletion itself.'
  prefs: []
  type: TYPE_NORMAL
- en: 'I think it’s better to make a little bit of effort for these, even if you don’t
    have an immediate need for a changelog/audit log: Store the deletion information
    in a table. You could create one for all tables, or just one for everything depending
    on how lazy you are:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: I can’t make a trigger out of this easily (or maybe not at all), because `deleted_by`
    is information we’ll have to pass down into the database somehow.
  prefs: []
  type: TYPE_NORMAL
- en: Annoying Conflicts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While the triggers themselves don’t impact what you can and cannot do, the
    GiST index will blow up most attempts at concurrently updating the same item:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This will even fail if you do `SELECT .. FOR UPDATE`. When you have two transactions
    A and B coming in, if the transaction with the most recent `NOW()` timestamp gets
    the lock first, the second transaction will fail because `systime` ends up as
    an empty interval.
  prefs: []
  type: TYPE_NORMAL
- en: It’s annoying, but not a big deal for me at least. The tables where I need history
    usually never need write concurrency on the same ID. And if they do, it’s not
    hard to add a retry loop around the writes… though of course, it adds a pitfall
    you need to be aware of.
  prefs: []
  type: TYPE_NORMAL
- en: 'Trying to fix this by using `CLOCK_TIMESTAMP()` instead of `NOW()` will only
    make things worse in my opinion. If you desire to insert multiple items at the
    same time, usually none of them will have the same timestamp. That makes certain
    queries on the history table technically wrong:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine you have a list and list element table, and a user creates a new list
    with 10 elements. With `CLOCK_TIMESTAMP()`, you now end up with 11 different timestamps:
    One for the list root, and 10 for each list element. If you wondered what the
    list looked like when it was first created, you’d first have to fetch the list
    root. Then you have to fetch all elements that were in the list, say, as of 1
    second after it was created, to be relatively sure all the list elements are also
    returned. But any attempt at recreating the state at some arbitrary time in the
    past may end up with partial/corrupt results. For that reason, I highly recommend
    avoiding this, and rather using some other method to persist history if you really
    need it.'
  prefs: []
  type: TYPE_NORMAL
- en: Alternatives
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A trigger-based model seems to me like the best one if you have to use Postgres,
    but there are some alternatives you may want to consider.
  prefs: []
  type: TYPE_NORMAL
- en: Do You Need The History?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There is added complexity here, and there is an increased chance of transactions
    failing because of overlapping timestamps that you can’t really prevent. That
    begs the question: Do you really need the history?'
  prefs: []
  type: TYPE_NORMAL
- en: 'My “controversial” opinion is that, in this day and age, I feel the true question
    is really a matter of whether you can afford it performance-wise, and not whether
    it’s too complex. This particular implementation of persisting history is probably
    not very fast, but it is conceptually simple: Whenever you do something to a table,
    that action is stored in a history table. The original table is intentionally
    identical to what you’re used to. If you really don’t like the potential GiST
    conflicts, you can relax the constraints to get identical behaviour to what you’re
    used to. In that case, the only difference is the insert/delete/update performance.'
  prefs: []
  type: TYPE_NORMAL
- en: Yes, there are many cases where it’s clearly bonkers to retain the history,
    but I also think many people assume storing the history is costlier than it actually
    is^(. If you’re not sure, try it and see how it goes. Since your original table
    will be untouched, it’s not hard to roll back.)
  prefs: []
  type: TYPE_NORMAL
- en: 'For me, there are two reasons I think you should consider it, even if you have
    no immediate plans to expose this to your users:'
  prefs: []
  type: TYPE_NORMAL
- en: First, there will be a time when a specific customer needs their data rolled
    back to an earlier version. That could either be because of accidental deletes,
    rogue actors, or even a bad deployment that corrupted data for certain customers.
    While this doesn’t replace backups by a long shot, it’s a lot faster and easier
    to do
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It will of course end up being a little more complex than that in practice,
    depending on the data model and how fine-grained you want to be. But it’s less
    effort than setting up the backup server, bridging it with a foreign data wrapper,
    and then finally doing the inserts in exactly the same manner as above, before
    cleaning up the backup server afterwards.
  prefs: []
  type: TYPE_NORMAL
- en: There are other cases too, like debugging a transient issue one of your users
    had. I could go on, but it feels like repeating the sales pitch for [Datomic](https://www.datomic.com/).
  prefs: []
  type: TYPE_NORMAL
- en: 'The second reason relates to the gut reaction of saying “We don’t need it”:
    If you don’t have time travel abilities readily available, you can’t explore and
    play with them. This, in turn, means you won’t really think of them when developing
    new functionality for your customers. At the risk of sounding like a techbro:
    I think it stifles innovation. Do you *really* think there’s no value for it somewhere
    in your system in the future?'
  prefs: []
  type: TYPE_NORMAL
- en: Yeah, yeah, this sounds a lot like future-proofing. To be clear, YAGNI isn’t
    wrong, but I only think it only applies when there’s either
  prefs: []
  type: TYPE_NORMAL
- en: significant overhead (either in terms of implementation complexity or system
    performance)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: something that can be retroactively implemented (i.e. no data loss)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: and system-versioned tables are neither.
  prefs: []
  type: TYPE_NORMAL
- en: '… well, uh, let me clarify here. The current implementation I’ve shown you
    requires a lot of work when you make new tables. Which is a good transition to
    my next point:'
  prefs: []
  type: TYPE_NORMAL
- en: Use a Database Suited for the Task
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Writing all of these long triggers yourself just because Postgres doesn’t support
    it is a bit stupid. If you want an open-source alternative, perhaps MariaDB isn’t
    too bad? It supports [SQL:2011](https://mariadb.com/kb/en/system-versioned-tables/)
    and even has support for bitemporality if you want to go even further.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, I’d be amiss if I didn’t mention [Datomic](https://www.datomic.com/).
    It is a great database, although not open-source, and language support is rather
    limited (only Java/Clojure officially). For the ones in Microsoft land, [SQL Server](https://learn.microsoft.com/en-us/sql/relational-databases/tables/temporal-tables?view=sql-server-ver16)
    has great support for SQL:2011 as well, from what I gather.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned, this is aimed at user data generated by someone clicking or typing
    around on a webpage, mutating some content of theirs. But for IoT data, you’d
    like some other tool than temporal tables, and if you’re big enough, you probably
    want to use an OLAP database for OLAP stuff.
  prefs: []
  type: TYPE_NORMAL
- en: Sloppy-Paste or Eldritch Horrors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I am stuck with Postgres, both because that’s what I already got, but also because
    I heavily use PostGIS. Migrating away is simply not an option, so I have to make
    do with what I have.
  prefs: []
  type: TYPE_NORMAL
- en: What I like about the trigger solution is that it is – aside from the column
    expansion hack – not terribly hard to understand. The problem is that it’s very
    verbose, and after being burnt from a couple of copy-paste mistakes in the past,
    I’d rather have a single trigger for every table if possible.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is possible… though it does not look pretty. Here’s what the update trigger
    looks like after we make the history table and ID field into input parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: (The insert and update triggers are similar, so I won’t go over them here.)
  prefs: []
  type: TYPE_NORMAL
- en: 'To factor out the history table and ID field, we have to use [`EXECUTE`](https://www.postgresql.org/docs/16/plpgsql-statements.html#PLPGSQL-STATEMENTS-EXECUTING-DYN),
    which makes the entire thing feel even more hacky. It looks ugly, and if you’re
    not familiar with `EXECUTE` or the previously mentioned column expansion magic,
    it may feel outright eldritch. However, I think this is better than the first
    attempt at the trigger implementation for one big reason. And that is best shown
    by using it in practice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This is much less verbose to use if you want to retain history for multiple
    tables!
  prefs: []
  type: TYPE_NORMAL
- en: While it’s true that the query can’t be type-checked ahead of time, the original
    trigger won’t be either. *We have to run them to verify that they don’t refer
    to wrong tables or ids*. If that’s the case, then we should pick the alternative
    that reduces the chance of a sloppy search-replace.
  prefs: []
  type: TYPE_NORMAL
- en: 'And this new implementation does that! This trigger has the history table and
    the ID field in only two locations – the input arguments, whereas the original
    trigger implementation had them spread out all around in 7 different locations.
    Also, let’s face it: copy-pasting some big triggers for every single table we
    want system versioned just wouldn’t feel right.'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The full implementation is over in the [time-travelling-todo-lists-in-postgres](https://github.com/hypirion/time-travelling-todo-lists-in-postgres)
    repository, and the triggers are in the migration file [`migrations/001_history_triggers.up.sql`](https://github.com/hypirion/time-travelling-todo-lists-in-postgres/blob/main/migrations/001_history_triggers.up.sql).
  prefs: []
  type: TYPE_NORMAL
- en: 'As I mentioned, this isn’t perfect: You have some big pitfalls related to table
    modifications, it adds a risk of having concurrent updates break, and other databases
    should have a much better implementation than my three triggers. It’s probably
    not suitable for large databases either.'
  prefs: []
  type: TYPE_NORMAL
- en: But if you’re stuck with Postgres, I think this is fine. However, I think you
    should be aware of how the implementation works in detail, as there are a couple
    of ways to shoot yourself in the foot. And if you’ve come this far down, you hopefully
    do!
  prefs: []
  type: TYPE_NORMAL
