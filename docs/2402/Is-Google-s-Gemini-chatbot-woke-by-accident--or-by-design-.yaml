- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-29 13:26:54'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-29 13:26:54'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Is Google’s Gemini chatbot woke by accident, or by design?
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 谷歌的Gemini聊天机器人是偶然还是设计成“觉醒”的？
- en: 来源：[https://www.economist.com/united-states/2024/02/28/is-googles-gemini-chatbot-woke-by-accident-or-design](https://www.economist.com/united-states/2024/02/28/is-googles-gemini-chatbot-woke-by-accident-or-design)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.economist.com/united-states/2024/02/28/is-googles-gemini-chatbot-woke-by-accident-or-design](https://www.economist.com/united-states/2024/02/28/is-googles-gemini-chatbot-woke-by-accident-or-design)
- en: 'IT ALL STARTED with black Vikings and Asian Nazis. Users of Google Gemini,
    the tech giant’s [artificial-intelligence](https://www.economist.com/topics/artificial-intelligence)
    model, recently noticed that asking it to create images of Vikings, German soldiers
    from 1943 or America’s Founding Fathers produced surprising results: hardly any
    of the people depicted were white. Gemini had been programmed to show a range
    of ethnicities. Other image-generation tools have been criticised because they
    tend to show white men when asked for images of entrepreneurs or doctors. [Google](https://www.economist.com/science-and-technology/2023/11/29/a-google-ai-has-discovered-22m-materials-unknown-to-science)
    wanted Gemini to avoid this trap; instead, it fell into another one, depicting
    George Washington as black and the pope as an Asian woman.'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都始于黑人维京人和亚洲纳粹。最近，谷歌的[人工智能](https://www.economist.com/topics/artificial-intelligence)模型Gemini的用户注意到，要求它创建维京人、1943年的德国士兵或美国的开国元勋的图像时，结果出乎意料：几乎没有被描绘的人是白人。Gemini被编程为展示一系列的种族。其他图像生成工具因为在要求企业家或医生的图像时倾向于展示白人男性而受到批评。[谷歌](https://www.economist.com/science-and-technology/2023/11/29/a-google-ai-has-discovered-22m-materials-unknown-to-science)希望Gemini避免这一陷阱；然而，它却陷入了另一个陷阱，把乔治·华盛顿描绘成黑人，把教皇描绘成亚洲女性。
- en: Some observers likened Gemini’s ahistorical diversity to “Hamilton” or “Bridgerton”.
    It seemed that Google had merely made a well-meaning mistake. But it was a gift
    to the tech industry’s right-wing critics. On February 22nd Google said it would
    halt the generation of images of people while it rejigged Gemini. But by then
    attention had moved on to the chatbot’s text responses, which turned out to be
    just as surprising.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 一些观察家将Gemini的非历史性多样性比作“汉密尔顿”或“布里奇顿”。看起来谷歌只是犯了一个好心的错误。但这成了科技行业右翼批评者的一大礼物。谷歌于2月22日表示将暂停生成人物图像，同时重新调整Gemini。但是，此时注意力已转向聊天机器人的文本回应，结果同样让人意外。
