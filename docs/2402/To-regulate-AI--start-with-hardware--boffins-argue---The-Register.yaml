- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 15:02:18'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 15:02:18'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: To regulate AI, start with hardware, boffins argue • The Register
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为了规范AI，从硬件入手，研究人员主张 • The Register
- en: 来源：[https://www.theregister.com/2024/02/16/boffins_propose_regulating_ai_hardware/](https://www.theregister.com/2024/02/16/boffins_propose_regulating_ai_hardware/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.theregister.com/2024/02/16/boffins_propose_regulating_ai_hardware/](https://www.theregister.com/2024/02/16/boffins_propose_regulating_ai_hardware/)
- en: In our quest to limit the destructive potential of artificial intelligence,
    a paper out of the University of Cambridge has suggested baking in remote kill
    switches and lockouts, like those developed to stop the unauthorized launch of
    nuclear weapons, into the hardware that powers it.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们努力限制人工智能的破坏潜力时，剑桥大学的一篇论文建议在驱动它的硬件中加入遥控杀死开关和锁定功能，类似于用于阻止未经授权发射核武器的技术。
- en: The paper [[PDF](https://www.cser.ac.uk/media/uploads/files/Computing-Power-and-the-Governance-of-AI.pdf)],
    which includes voices from numerous academic institutions and several from OpenAI,
    makes the case that regulating the hardware these models rely on may be the best
    way to prevent its misuse.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 该论文[[PDF](https://www.cser.ac.uk/media/uploads/files/Computing-Power-and-the-Governance-of-AI.pdf)]包括来自多所学术机构和几家开放AI机构的声音，论证了规范这些模型依赖的硬件可能是防止其滥用的最佳途径。
- en: '"AI-relevant compute is a particularly effective point of intervention: It
    is detectable, excludable, and quantifiable, and is produced via an extremely
    concentrated supply chain," the researchers argue.'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: “与AI相关的计算是干预的一个特别有效点：它是可检测的、可排除的和可量化的，并且是通过极度集中的供应链生产的，”研究人员辩称。
- en: 'Training the most prolific models, believed to exceed a trillion parameters,
    requires immense physical infrastructure: Tens of thousands of GPUs or accelerators
    and weeks or even months of processing time. This, the researchers say, makes
    the existence and relative performance of these resources difficult to hide.'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 训练被认为超过一万亿参数的最常见模型需要庞大的物理基础设施：数以万计的GPU或加速器以及数周甚至数月的处理时间。研究人员表示，这使得这些资源的存在和相对性能难以隐藏。
- en: What's more, the most advanced chips used to train these models are produced
    by a relatively small number of companies, like Nvidia, AMD, and Intel, allowing
    policymakers to restrict the sale of these goods to persons or countries of concern.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，用于训练这些模型的最先进芯片由少数公司生产，例如英伟达、AMD和英特尔，这使得政策制定者可以限制将这些产品销售给关注对象的个人或国家。
- en: These factors, along with others like supply chain constraints on semiconductor
    manufacturing, offer policymakers the means to better understand how and where
    AI infrastructure is deployed, who is and isn't allowed to access it, and enforce
    penalties for its misuse, the paper contends.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这些因素，与半导体制造供应链限制等因素一起，为政策制定者提供了更好地了解人工智能基础设施部署情况的手段，以及谁有权访问以及谁无权访问它，并对其滥用实施处罚的途径，该论文提出。
- en: Controlling the infrastructure
  id: totrans-split-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 控制基础设施
- en: The paper highlights numerous ways policymakers might approach AI hardware regulation.
    Many of the suggestions – including those designed to improve visibility and limit
    the sale of AI accelerators – are already playing out at a national level.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 该论文强调了政策制定者可能采取的多种方法来处理AI硬件的规范。许多建议（包括旨在改善可见性并限制AI加速器销售的建议）已在国家层面得到实施。
- en: Last year US president Joe Biden put forward an [executive order](https://www.theregister.com/2023/10/30/us_president_to_sign_new/)
    aimed at identifying companies developing large dual-use AI models as well as
    the infrastructure vendors capable of [training them](https://www.theregister.com/2023/11/05/biden_ai_reporting_thresholds/).
    If you're not familiar, "dual-use" refers to technologies that can serve double
    duty in civilian and military applications.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 去年，美国总统乔·拜登提出了一项旨在识别开发大型双用途AI模型的公司以及能够对其进行训练的基础设施供应商的行政命令。如果您不熟悉，“双用途”指的是在民用和军事应用中都能发挥作用的技术。
- en: More recently, the US Commerce Department [proposed](https://www.theregister.com/2024/01/29/us_raimondo_ai_cloud_kyc/)
    regulation that would require American cloud providers to implement more stringent
    "know-your-customer" policies to prevent persons or countries of concern from
    getting around export restrictions.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 更近期，美国商务部提出了一项[建议](https://www.theregister.com/2024/01/29/us_raimondo_ai_cloud_kyc/)的规定，要求美国云服务提供商实施更严格的“了解您的客户”政策，以防止关注对象绕过出口限制。
- en: This kind of visibility is valuable, researchers note, as it could help to avoid
    another arms race, like the one triggered by the missile gap controversy, where
    erroneous reports led to massive build up of ballistic missiles. While valuable,
    they warn that executing on these reporting requirements risks invading customer
    privacy and even lead to sensitive data being leaked.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员指出，这种可见性是有价值的，因为它可以帮助避免另一场类似于导弹缺口争议引发的军备竞赛，当时错误的报告导致大规模的弹道导弹建造。尽管有价值，他们警告称执行这些报告要求会侵犯客户隐私，甚至可能导致敏感数据泄露。
- en: Meanwhile, on the trade front, the Commerce Department has continued to [step
    up](https://www.theregister.com/2023/10/19/china_biden_ai/) restrictions, limiting
    the performance of accelerators sold to China. But, as we've previously reported,
    while these efforts have made it harder for countries like China to get their
    hands on American chips, they are far from perfect.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，在贸易方面，商务部继续加强了[限制措施](https://www.theregister.com/2023/10/19/china_biden_ai/)，限制向中国出售的加速器的性能。但正如我们之前报道的，尽管这些努力使得像中国这样的国家更难获取美国芯片，它们远非完美。
- en: To address these limitations, the researchers have proposed implementing a global
    registry for AI chip sales that would track them over the course of their lifecycle,
    even after they've left their country of origin. Such a registry, they suggest,
    could incorporate a unique identifier into each chip, which could help to combat
    [smuggling](https://www.theregister.com/2024/02/05/smuggling_ai_chips/) of components.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些限制，研究人员建议实施一个全球AI芯片销售注册表，跟踪它们在生命周期中的使用情况，即使它们已经离开其原产国。他们建议这样的注册表可以在每个芯片中包含一个唯一标识符，这可以帮助打击[走私](https://www.theregister.com/2024/02/05/smuggling_ai_chips/)的组件。
- en: At the more extreme end of the spectrum, researchers have suggested that kill
    switches could be baked into the silicon to prevent their use in malicious applications.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在极端情况下，研究人员建议在硅中嵌入“杀死开关”，以防止它们在恶意应用中被使用。
- en: 'Here''s how they put it:'
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 他们这样表达：
- en: 'They further expanded on that mechanism, and to us it sounds as though they
    are suggesting the accelerators could self-disable or be remotely disabled by
    watchdogs:'
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 他们进一步扩展了这种机制，对我们来说，听起来他们建议加速器可以自行失效或由监管机构远程禁用：
- en: 'The academics are clearer elsewhere in their study, proposing that processor
    functionality could be switched off or dialed down by regulators remotely using
    digital licensing:'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 学术界在其研究中在其他地方表达得更清楚，建议处理器功能可以通过数字许可证远程关闭或减弱：
- en: In theory, this could allow watchdogs to respond faster to abuses of sensitive
    technologies by cutting off access to chips remotely, but the authors warn that
    doing so isn't without risk. The implication being, if implemented incorrectly,
    that such a kill switch could become a target for cybercriminals to exploit.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，这可以让监管机构更快地响应对敏感技术的滥用，通过远程切断对芯片的访问，但作者警告说这样做并非没有风险。这意味着，如果实施不当，这样的杀死开关可能成为网络犯罪分子利用的目标。
- en: Another proposal would require multiple parties to sign off on potentially risky
    AI training tasks before they can be deployed at scale. "Nuclear weapons use similar
    mechanisms called permissive action links," they wrote.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个提议是，在大规模部署潜在风险的AI训练任务之前，需要多方签署批准。他们写道：“核武器使用类似的机制称为许可行动链”。
- en: For nuclear weapons, these security locks are designed to prevent one person
    from going rogue and launching a first strike. For AI however, the idea is that
    if an individual or company wanted to train a model over a certain threshold in
    the cloud, they'd first need to get authorization to do so.
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对于核武器，这些安全锁设计旨在防止个人单方面发动第一次袭击。然而对于人工智能而言，想法是如果个人或公司希望在云中训练一个模型超过某个阈值，他们首先需要获得授权才能这样做。
- en: Though a potent tool, the researchers observe that this could backfire by preventing
    the development of desirable AI. The argument seems to be that while the use of
    nuclear weapons has a pretty clear-cut outcome, AI isn't always so black and white.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是一个强大的工具，研究人员观察到这可能会适得其反，阻碍了可期望的人工智能的发展。论点似乎是，虽然使用核武器有一个相当明确的结果，但人工智能并非总是那么黑白分明。
- en: But if this feels a little too dystopian for your tastes, the paper dedicates
    an entire section to reallocating AI resources for the betterment of society as
    a whole. The idea being that policymakers could come together to make AI compute
    more accessible to groups unlikely to use it for evil, a concept described as
    "allocation."
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果这让你感觉有点过于反乌托邦，那么该论文专门为将AI资源重新配置以促进整个社会的改善而设立了一个完整的章节。其核心思想是决策者可以联合起来，使AI计算能力更易于那些不太可能用于恶意目的的群体使用，这一概念被描述为“分配”。
- en: What's wrong with regulating AI development?
  id: totrans-split-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对AI发展进行监管有什么问题呢？
- en: Why go to all this trouble? Well, the paper's authors posit that physical hardware
    is inherently easier to control.
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么要费这么大劲呢？好吧，文章的作者认为，物理硬件本质上更容易控制。
- en: Compared to hardware, "other inputs and outputs of AI development – data, algorithms,
    and trained models – are easily shareable, non-rivalrous intangible goods, making
    them inherently difficult to control," the paper reads.
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: 与硬件相比，“AI发展的其他输入和输出——数据、算法和训练模型——是易于共享的非竞争性无形商品，这使得它们本质上难以控制，”文章中写道。
- en: The argument being that once a model is published, either in the open or leaked,
    there is no putting genie back in the bottle and stopping its spread across the
    net.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 论点是，一旦模型发布，无论是公开还是泄露，就无法将精灵重新装回瓶子，阻止其在网络上的传播。
- en: Researchers also highlighted that efforts to prevent the misuse of models have
    proven unreliable. In one example, the authors highlighted the ease with which
    researchers were able to dismantle safeguards in Meta's Llama 2 meant to prevent
    the model from generating offensive language.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员还指出，防止模型被滥用的努力已经被证明是不可靠的。举一个例子，作者们突出了研究人员如何轻松地拆除Meta的Llama 2中旨在防止模型生成冒犯性语言的保障措施。
- en: Taken to the extreme, it is feared that a sufficiently advanced dual-use model
    could be employed to accelerate the [development](https://www.theregister.com/2023/07/28/ai_senate_bioweapon/)
    of chemical or biological weapons.
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果被极端利用，有人担心，一个足够先进的双用途模型可能被用来加速化学或生物武器的开发。
- en: The paper concedes that AI hardware regulation isn't a silver bullet and doesn't
    eliminate the need for regulation in other aspects of the industry.
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 文章承认，AI硬件监管并非灵丹妙药，并不能消除对行业其他方面监管的需求。
- en: However, the participation of several OpenAI researchers is hard to ignore considering
    CEO Sam Altman's [attempts](https://www.theregister.com/2023/05/17/ai_oversight_hearing/)
    to control the narrative around AI regulation. ®
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，考虑到OpenAI几位研究人员的参与，很难忽视CEO Sam Altman在AI监管话题上试图控制叙述的努力。 ®
