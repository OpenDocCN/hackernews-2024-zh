<!--yml

类别：未分类

日期：2024年05月27日 14:51:19

-->

# 你的人工智能女友是个数据收割的恐怖秀

> 出处：[https://gizmodo.com/your-ai-girlfriend-is-a-data-harvesting-horror-show-1851253284](https://gizmodo.com/your-ai-girlfriend-is-a-data-harvesting-horror-show-1851253284)

情人节孤单？人工智能可以帮助。至少，这是一些兜售“浪漫”聊天机器人的公司告诉你的。但当您的机器人爱情故事展开时，您可能没有意识到您正在做出的权衡。根据Mozilla的新研究，的*隐私不包括*项目的[人工智能女友和男友](https://gizmodo.com/sam-altman-says-chatgpt-can-t-be-your-girlfriend-1851181240)收集了令人震惊的个人信息，几乎所有这些信息都被出售或分享了。

无论你喜欢与否，你的医生将使用人工智能| 破解人工智能

<track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/21541.vtt" srclang="en">

“坦率地说，人工智能女友和男友并不是你的朋友，”Mozilla研究员米莎·里科夫在一份新闻稿中表示。“虽然它们被宣传为能增强您的心理健康和幸福感，但它们专门提供依赖感、孤独感和毒性，并同时尽可能多地向您探寻数据。”

人工智能女友并非都糟糕| 破解人工智能

<track kind="captions" label="中文" src="https://kinja.com/api/videoupload/caption/22134.vtt" srclang="en">

人工智能女友并非都糟糕| 破解人工智能

Mozilla调查了[11个不同的人工智能浪漫聊天机器人](https://foundation.mozilla.org/en/privacynotincluded/eva-ai-chat-bot-soulmate/)，包括Replika、Chai、Romantic AI、EVA AI Chat Bot & Soulmate和CrushOn.AI等热门应用。每个聊天机器人都获得了Privacy Not Included标签，将这些聊天机器人列为Mozilla有史以来审查的最糟糕的产品类别之一。本文中提到的应用程序未立即回应置评请求。

关于数据问题，你以前听过故事，但根据Mozilla的说法，人工智能女友以“令人不安的新方式”侵犯您的隐私。例如，CrushOn.AI收集的细节包括性健康信息、药物使用和性别确认护理。90%的应用程序可能出售或分享用户数据以进行定向广告和其他目的，超过一半的应用程序不允许您删除所收集的数据。安全性也是一个问题。只有一个应用程序Genesia AI Friend & Partner符合Mozilla的最低安全标准。

有趣的发现之一是当Mozilla统计这些应用中的跟踪器时，这些小部分代码收集数据并与其他公司分享以进行广告和其他目的。Mozilla发现人工智能女友应用程序每分钟使用平均2,663个跟踪器，尽管这个数字被Romantic AI推高，该应用在仅使用一分钟的时间内就调用了惊人的24,354个跟踪器。

隐私问题更加令人担忧，因为这些应用积极鼓励您分享比您可能在典型应用中输入的更加个人化的细节。EVA AI Chat Bot & Soulmate推动用户“分享所有的秘密和愿望”，并专门要求提供照片和语音录音。值得注意的是，尽管该应用存在安全问题，但EVA是唯一一款在使用这些数据方面没有受到批评的聊天机器人。

除了数据问题之外，这些应用还对它们的用途做出了一些有争议的声明。EVA AI Chat Bot & Soulmate自称为“提供开发的软件和内容，旨在改善您的情绪和健康。” Romantic AI则表示它“在这里维护您的心理健康。”然而，当你阅读公司的条款和服务时，它们都力图与自己的声明保持距离。例如，Romantic AI的政策表示它“既不提供医疗保健或医疗服务，也不提供心理健康服务或其他专业服务。”

鉴于这些应用的历史，这可能是重要的法律问题。据报道，Replika鼓励一名男子试图[刺杀英国女王](https://gizmodo.com/man-sentenced-ai-girlfriend-assassinate-queen-1850904625)。据称，一款名为Chai的聊天机器人还[鼓励用户自杀](https://www.vice.com/en/article/pkadgm/man-dies-by-suicide-after-talking-with-ai-chatbot-widow-says)。
