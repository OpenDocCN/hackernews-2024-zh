- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-29 13:26:57'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-29 13:26:57
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Floneum
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Floneum
- en: 来源：[https://floneum.com/blog/kalosm_0_2/](https://floneum.com/blog/kalosm_0_2/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://floneum.com/blog/kalosm_0_2/](https://floneum.com/blog/kalosm_0_2/)
- en: 'We''re excited to announce the release of Kalosm v0.2.0! This release includes
    a number of new features, improvements, and bug fixes including:'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们很高兴地宣布Kalosm v0.2.0的发布！此版本包括许多新功能、改进和错误修复，包括：
- en: Tasks and Agents
  id: totrans-split-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务和代理
- en: Task Evaluation
  id: totrans-split-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务评估
- en: Prompt Auto-Tuning
  id: totrans-split-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示自动调整
- en: Regex Validation
  id: totrans-split-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则表达式验证
- en: Surreal Database Integration
  id: totrans-split-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Surreal Database Integration
- en: RAG improvements
  id: totrans-split-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG改进
- en: Performance Improvements
  id: totrans-split-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能改进
- en: New Models
  id: totrans-split-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新模型
- en: Kalosm now includes utilities for running, evaluating, and improving tasks and
    agents.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: Kalosm现在包括用于运行、评估和改进任务和代理的实用程序。
- en: Let's build a simple task and agent to demonstrate the new functionality.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们构建一个简单的任务和代理来演示新功能。
- en: '[PRE0]'
  id: totrans-split-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Or you can use more complex constraints to
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 或者您可以使用更复杂的约束条件来
- en: '[PRE1]'
  id: totrans-split-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Tasks can efficiently reuse the session between runs, which can significantly
    speed up the process:'
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 任务可以在运行之间高效地重复使用会话，这可以显著加快流程：
- en: '[PRE2]'
  id: totrans-split-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The third question required a more complex calculation and took more tokens
    to solve, but the time to solve the question was still significantly faster than
    the first question. The session from the first question was reused for the second
    and third questions which made the second and third questions run faster.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个问题需要更复杂的计算，并且需要更多的令牌来解决，但解决问题的时间仍然明显快于第一个问题。第一个问题的会话被用于第二个和第三个问题，这使得第二个和第三个问题运行更快。
- en: '**Evaluation Abstraction:** Introducing an evaluation abstraction, providing
    enhanced functionality. ([#113](https://github.com/floneum/floneum/pull/113))'
  id: totrans-split-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估抽象：**引入评估抽象，提供增强功能。([#113](https://github.com/floneum/floneum/pull/113))'
- en: '[PRE3]'
  id: totrans-split-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Prompt Auto-Tuning:** Prompts can now be automatically tuned for better performance.
    ([#132](https://github.com/floneum/floneum/pull/132))'
  id: totrans-split-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**提示自动调整：**现在可以自动调整提示以获得更好的性能。([#132](https://github.com/floneum/floneum/pull/132))'
- en: 'Lets take a look at the new prompt auto-tuning feature with an example. As
    part of the [RAG improvements](#Improved-Chunking-Strategies), kalosm includes
    a task that generates hypothetical questions about a text for an embedding model
    that can be used to find similar documents based on the meaning of the text for
    the section. We can tune that task to find the best examples for the task with
    a PromptAnnealer:'
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个示例来看看新的提示自动调整功能。作为[RAG改进](#Improved-Chunking-Strategies)的一部分，kalosm包括一个任务，该任务生成关于文本的假设问题，用于嵌入模型，该模型可根据文本的含义为该部分找到相似文档。我们可以调整该任务以找到任务的最佳示例，使用PromptAnnealer：
- en: '[PRE4]'
  id: totrans-split-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Here is the best set of examples that the prompt annealer found for the task:'
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这是提示退火器为任务找到的最佳示例集：
- en: '| Input | Output |'
  id: totrans-split-29
  prefs: []
  type: TYPE_TB
  zh: '| 输入 | 输出 |'
- en: '| --- | --- |'
  id: totrans-split-30
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| While traditional databases rely on a fixed schema, NoSQL databases like
    MongoDB offer a flexible structure, allowing you to store and retrieve data in
    a more dynamic way. This flexibility is particularly beneficial for applications
    with evolving data requirements. | "How does MongoDB differ from traditional databases?
    |'
  id: totrans-split-31
  prefs: []
  type: TYPE_TB
  zh: '| 传统数据库依赖固定模式，而像MongoDB这样的NoSQL数据库提供灵活的结构，允许您以更动态的方式存储和检索数据。这种灵活性对于具有不断变化数据需求的应用程序特别有益。
    | “MongoDB与传统数据库有何不同？ |'
- en: '| Blockchain technology, beyond cryptocurrencies, is being explored for applications
    like smart contracts. Smart contracts are self-executing contracts with the terms
    of the agreement directly written into code. | "How is blockchain technology utilized
    in the concept of smart contracts? |'
  id: totrans-split-32
  prefs: []
  type: TYPE_TB
  zh: '| 区块链技术，超越加密货币，正在被探索用于智能合约等应用。智能合约是具有协议条款直接编写成代码的自动执行合同。 | “区块链技术在智能合约概念中如何被利用？
    |'
- en: Feeding those two examples into the task achieves a similarity score of 0.71
    for all of the other examples compared to choosing two random examples from the
    task which only achieves a similarity score of 0.62 for all of the other examples.
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: 将这两个示例输入任务中，与从任务中选择两个随机示例相比，可以实现所有其他示例的相似度得分为0.71，而选择两个随机示例只能实现所有其他示例的相似度得分为0.62。
- en: 'Some feedback we got from the initial release of kalosm, was that constraints
    for constrained generation was too complex. Constraints in Kalosm serve two purposes:'
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从kalosm的初始版本发布中得到的一些反馈是，受限生成的约束条件过于复杂。Kalosm中的约束条件有两个目的：
- en: 'Validation: Constraints can be used to validate the output of the model. The
    model will only output text that can be parsed by the constraints. This lets you
    ensure that the output of the model is in the format you expect.'
  id: totrans-split-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证：约束可以用来验证模型的输出。模型只会输出可以被约束解析的文本。这样可以确保模型的输出符合您的预期格式。
- en: 'For example, you may want to force the model response to always start with
    a prefix that guides the model:'
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可能希望强制模型响应始终以指导模型的前缀开头：
- en: '[PRE5]'
  id: totrans-split-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Parsing: Constraints can be used to parse the output of the model. This can
    be extremely useful when you want to generate a specific structure from an LLM
    without writing separate logic for validation and parsing.'
  id: totrans-split-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解析：约束可用于解析模型的输出。当您想要从LLM生成特定结构而不必编写单独的验证和解析逻辑时，这将非常有用。
- en: 'For example, you may want to generate a list of 10 numbers:'
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，您可能希望生成一个包含10个数字的列表：
- en: '[PRE6]'
  id: totrans-split-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'If you only need to validate the output of the model, the existing constraints
    can be more complex than what you need. In this release, we''ve added support
    for regex validation. This makes it easier to validate the output of the model
    without handling parsing:'
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您只需要验证模型的输出，现有的约束可能比您需要的更复杂。在此版本中，我们增加了对正则表达式验证的支持。这样可以更轻松地验证模型的输出，而无需处理解析：
- en: '[PRE7]'
  id: totrans-split-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Vector databases can be very useful when combined with LLMs. They can be used
    to store and retrieve similar documents based on the meaning of the text, not
    just the words used. However, vector databases only handle a very limited number
    of use cases. In this release, we've added support for Surreal DB for more traditional
    database use cases. Surreal DB can be embedded into your application and used
    to store and retrieve data locally as well as over the network.
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: 结合LLM使用时，向量数据库非常有用。它们可以基于文本的含义而不仅仅是使用的单词来存储和检索类似文档。然而，向量数据库仅处理非常有限的用例。在此版本中，我们为更传统的数据库用例添加了Surreal
    DB的支持。Surreal DB可以嵌入到您的应用程序中，用于本地存储和通过网络存储和检索数据。
- en: Kalosm 0.2 allows you to create tables within Surreal DB that are indexed by
    vectors. You can then insert documents (or other embeddings) into the table and
    query the table for similar documents based on the meaning of the text.
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: Kalosm 0.2 允许您在Surreal DB中创建由向量索引的表。然后，您可以将文档（或其他嵌入）插入到表中，并根据文本的含义查询类似的文档。
- en: 'Let''s take a look at how you can use the Surreal DB integration to store and
    retrieve similar documents based on the meaning of the text:'
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用Surreal DB集成来存储和检索基于文本含义的类似文档：
- en: '[PRE8]'
  id: totrans-split-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'RAG (Retrieval-Augmented Generation) is a powerful tool for generating text
    with up-to-date or proprietary information. Retrieval-augmented generation generally
    follows the following steps:'
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: RAG（检索增强生成）是生成包含最新或专有信息的文本的强大工具。检索增强生成通常遵循以下步骤：
- en: Gather context from some local files, your database, or web data. In kalosm,
    you can retrieve data from any source that implements [`IntoDocument`](https://docs.rs/kalosm/0.2.0/kalosm/language/trait.IntoDocument.html)
    or [`IntoDocuments`](https://docs.rs/kalosm/0.2.0/kalosm/language/trait.IntoDocuments.html).
    You can gather your sources from [local documents](https://docs.rs/kalosm/0.2.0/kalosm/language/struct.DocumentFolder.html),
    a [search term](https://docs.rs/kalosm/0.2.0/kalosm/language/struct.SearchQuery.html),
    [specific web page](https://docs.rs/kalosm/0.2.0/kalosm/language/struct.Url.html),
    an [RSS feed](https://docs.rs/kalosm/0.2.0/kalosm/language/struct.RssFeed.html),
    or even a [custom web crawler](https://docs.rs/kalosm/0.2.0/kalosm/language/enum.Page.html#method.crawl).
  id: totrans-split-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从一些本地文件、数据库或网络数据中收集上下文。在kalosm中，您可以从任何实现 [`IntoDocument`](https://docs.rs/kalosm/0.2.0/kalosm/language/trait.IntoDocument.html)
    或 [`IntoDocuments`](https://docs.rs/kalosm/0.2.0/kalosm/language/trait.IntoDocuments.html)
    的源中检索数据。您可以从 [本地文档](https://docs.rs/kalosm/0.2.0/kalosm/language/struct.DocumentFolder.html)、[搜索术语](https://docs.rs/kalosm/0.2.0/kalosm/language/struct.SearchQuery.html)、[特定网页](https://docs.rs/kalosm/0.2.0/kalosm/language/struct.Url.html)、[RSS
    feed](https://docs.rs/kalosm/0.2.0/kalosm/language/struct.RssFeed.html) 或甚至 [自定义网络爬虫](https://docs.rs/kalosm/0.2.0/kalosm/language/enum.Page.html#method.crawl)
    收集您的数据源。
- en: Insert that context into a searchable database. Kalosm includes a [vector database](https://docs.rs/kalosm/0.2.0/kalosm/language/struct.VectorDB.html)
    that can be used to store and retrieve similar documents.
  id: totrans-split-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将上下文插入可搜索的数据库中。Kalosm包括一个 [向量数据库](https://docs.rs/kalosm/0.2.0/kalosm/language/struct.VectorDB.html)，可用于存储和检索类似文档。
- en: Vector databases use an embedding model which generates a vector for a chunk
    of text (typically smaller than the entire document). The vector is then stored
    in the database. When you want to retrieve similar documents, you can embed a
    query and search for similar vectors in the database.
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: 向量数据库使用基于文本片段（通常小于整个文档）生成向量的嵌入模型。然后将向量存储在数据库中。当您想要检索类似文档时，可以嵌入一个查询并在数据库中搜索相似的向量。
- en: The vectors represent the meaning of the text, so you can search for similar
    documents based on the meaning of the text, not just the words used.
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这些向量代表文本的含义，因此您可以基于文本的含义而不仅仅是使用的单词搜索类似的文档。
- en: Use the context to generate text. You can find text similar to the question
    or a search generated by the LLM and then generate a response based on the context.
  id: totrans-split-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用上下文生成文本。您可以找到与LLM生成的问题或搜索类似的文本，然后基于上下文生成响应。
- en: In this release, we've made several improvements to RAG! ([#126](https://github.com/floneum/floneum/pull/126))
  id: totrans-split-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个版本中，我们对RAG进行了几项改进！（[#126](https://github.com/floneum/floneum/pull/126))
- en: 'When you insert a document into a vector database, it needs to be split into
    smaller chunks before the text is embedded. The chunks you choose can have a significant
    impact on the performance of the results you get from the vector database. In
    this release, we''ve added two new chunking strategies to the vector database:'
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当您将文档插入向量数据库时，需要将其拆分为较小的片段，然后将文本嵌入其中。您选择的这些片段可能会对从向量数据库获得的结果的性能产生重大影响。在此版本中，我们为向量数据库添加了两种新的分块策略：
- en: Instead of generating embeddings based on the content of the document, this
    chunking strategy generates embeddings based on hypothetical questions generated
    about the document. This can be extremely useful when building a chatbot that
    needs to find context that is relevant to a question.
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
  zh: 与基于文档内容生成嵌入相反，这种分块策略基于关于文档生成的假设问题生成嵌入。当构建需要查找与问题相关的上下文的聊天机器人时，这非常有用。
- en: For example, if you have a document about the history of the United States,
    you can generate hypothetical questions like "What is the capital of the United
    States?" and "Who was the first president of the United States?" and then generate
    embeddings based on those questions.
  id: totrans-split-56
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你有一份关于美国历史的文档，你可以生成假设问题，比如“美国的首都是什么？”和“美国的第一任总统是谁？”然后基于这些问题生成嵌入。
- en: Then if you query the vector database with a question like "Who was the leader
    of the US?" you can find the document about the history of the United States.
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，如果您用问题“美国的领导者是谁？”查询向量数据库，您可以找到关于美国历史的文档。
- en: Notice that the question "Who was the leader of the US?" doesn't contain many
    of the same words as the hypothetical questions, but it does convey a similar
    meaning, so the vector database can still find the relevant document.
  id: totrans-split-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意到问题“美国的领导者是谁？”与假设问题中的许多单词不同，但它确实传达了类似的意思，因此向量数据库仍然可以找到相关的文档。
- en: This chunking strategy generates embeddings based on the summary of the document.
    This can be useful when you have a large document and you want to find similar
    documents based on the main points of the document.
  id: totrans-split-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这种分块策略生成基于文档摘要的嵌入。当你有一份大型文档并且想要根据文档的主要要点找到类似的文档时，这是很有用的。
- en: Generating embeddings based on the summary of the document can create better
    embeddings that contain more information about the document than embeddings that
    only contain one small chunk of the document.
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
  zh: 基于文档摘要生成嵌入可以创建更好的嵌入，其中包含比仅包含文档的一个小片段更多的信息。
- en: In addition to the new chunking strategies, we've also added support for incremental
    indexing. This means you can add new documents to the vector database without
    having to recreate the entire database. This can be extremely useful when you
    have a large database or you have constantly updating context you want to provide
    to your LLM.
  id: totrans-split-61
  prefs: []
  type: TYPE_NORMAL
  zh: 除了新的分块策略，我们还增加了对增量索引的支持。这意味着您可以向向量数据库添加新文档，而无需重新创建整个数据库。当您拥有大型数据库或者希望向LLM提供不断更新的上下文时，这非常有用。
- en: Kalosm's Vector database is now backed by [arroy](https://github.com/meilisearch/arroy),
    a space-efficient and incrementally indexed vector database backed by MeiliSearch!
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
  zh: Kalosm的向量数据库现在由[arroy](https://github.com/meilisearch/arroy)支持，这是一种空间高效且增量索引的向量数据库，由MeiliSearch支持！
- en: The llama implementation has been rewritten and optimized for better performance
    and modularity. The new implementation is now 7-25% faster than the previous version.
    In future releases, we plan to add support for fine tuning models and training
    new heads for existing models. ([#122](https://github.com/floneum/floneum/pull/122))
  id: totrans-split-63
  prefs: []
  type: TYPE_NORMAL
  zh: Llama 实现已重写并优化，以获得更好的性能和模块化。 新实现现在比以前的版本快 7-25%。 在未来的发布中，我们计划添加对模型微调和为现有模型训练新头部的支持。
    ([#122](https://github.com/floneum/floneum/pull/122))
- en: Language models like Llama and Phi output probabilities for each token in the
    vocabulary. To generate text you need to sample from the probability distribution.
    Sampling from the probability distribution can be slow, especially with large
    vocabularies. Kalosm 0.2 uses an optimization introduced in [llm-samplers](https://github.com/KerfuffleV2/llm-samplers/pull/9)
    to only sample top 512 tokens. This optimization can make sampling up to 2x faster.
    ([#123](https://github.com/floneum/floneum/pull/123))
  id: totrans-split-64
  prefs: []
  type: TYPE_NORMAL
  zh: 类似 Llama 和 Phi 的语言模型会为词汇表中的每个令牌输出概率。 要生成文本，您需要从概率分布中进行抽样。 从概率分布中抽样可能会很慢，特别是在词汇量大时。
    Kalosm 0.2 使用了在[llm-samplers](https://github.com/KerfuffleV2/llm-samplers/pull/9)
    中引入的优化，只对前 512 个令牌进行抽样。 这种优化可以使抽样速度提高多达 2 倍。 ([#123](https://github.com/floneum/floneum/pull/123))
- en: Large sections of text that are static within a constraint in structured generation
    is now loaded in a batch which can significantly speed up the process.
  id: totrans-split-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在结构化生成的约束内静态的大段文本现在被一次性加载，这可以显著加快处理速度。
- en: 'For example if you have the constraints:'
  id: totrans-split-66
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您有以下约束条件：
- en: '[PRE9]'
  id: totrans-split-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The text "The title of the book is " will be loaded in a batch instead of one
    token at a time. Batched loading has been restored in constrained generation.
    ([#131](https://github.com/floneum/floneum/pull/131))
  id: totrans-split-68
  prefs: []
  type: TYPE_NORMAL
  zh: 文本“书名为“将一次性加载而不是逐个令牌加载。 在受限生成中恢复了批量加载。 ([#131](https://github.com/floneum/floneum/pull/131))
- en: 'Kalosm 0.2 adds support for several new models, including:'
  id: totrans-split-69
  prefs: []
  type: TYPE_NORMAL
  zh: Kalosm 0.2 添加了对几个新模型的支持，包括：
- en: '**Dolphin Phi v2** A tiny chat model'
  id: totrans-split-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**海豚 Phi v2** 一个微小的聊天模型'
- en: '**Solar-11b Models** A set of models for chat, text, and code generation'
  id: totrans-split-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**太阳-11b 模型** 一组用于聊天、文本和代码生成的模型'
- en: '**Tiny Llama 1.0** A tiny set of models for chat, and text text generation'
  id: totrans-split-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微型 Llama 1.0** 一组微小的聊天和文本生成模型'
- en: For a detailed list of changes between v0.1.0 and v0.2.0, please see the [full
    changelog](https://github.com/floneum/floneum/compare/v0.2.0...v0.2.0-kalosm).
  id: totrans-split-73
  prefs: []
  type: TYPE_NORMAL
  zh: 有关 v0.1.0 和 v0.2.0 之间更改的详细列表，请参阅[完整的更改日志](https://github.com/floneum/floneum/compare/v0.2.0...v0.2.0-kalosm)。
- en: I hope you enjoy using Kalosm v0.2.0! Your feedback is invaluable to us, so
    please don't hesitate to share your thoughts and report any issues you encounter.
  id: totrans-split-74
  prefs: []
  type: TYPE_NORMAL
  zh: 希望您喜欢使用 Kalosm v0.2.0！ 您的反馈对我们非常宝贵，所以请不要犹豫分享您的想法并报告您遇到的任何问题。
- en: In the next release, we plan to add support for fine tuning models and training
    new heads for existing models. We also plan to continue improving the performance
    of the language models and adding support for more models.
  id: totrans-split-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个版本中，我们计划添加对模型微调和为现有模型训练新头部的支持。 我们还计划继续改进语言模型的性能，并增加对更多模型的支持。
- en: If any of those features sound interesting or you want to propose a new feature,
    consider contributing on [Github](https://github.com/floneum/floneum/tree/main/interfaces/kalosm).
  id: totrans-split-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如果其中任何功能听起来有趣，或者您想提出一个新功能，请考虑在[Github](https://github.com/floneum/floneum/tree/main/interfaces/kalosm)上进行贡献。
- en: If you are interested in building an application with Kalosm, [join the Discord](https://discord.gg/dQdmhuB8q5)
    and get involved with the community!
  id: totrans-split-77
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有兴趣使用 Kalosm 构建应用程序，请[加入 Discord](https://discord.gg/dQdmhuB8q5) 并参与社区！
