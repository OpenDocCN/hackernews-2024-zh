- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 14:38:51'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 14:38:51'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: 'Chris''s Wiki :: blog/sysadmin/TrackingMachineImportance'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 'Chris''s Wiki :: blog/sysadmin/TrackingMachineImportance'
- en: 来源：[https://utcc.utoronto.ca/~cks/space/blog/sysadmin/TrackingMachineImportance](https://utcc.utoronto.ca/~cks/space/blog/sysadmin/TrackingMachineImportance)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://utcc.utoronto.ca/~cks/space/blog/sysadmin/TrackingMachineImportance](https://utcc.utoronto.ca/~cks/space/blog/sysadmin/TrackingMachineImportance)
- en: Today [we had a significant machine room air conditioning failure in our main
    machine room](https://mastodon.social/@cks/111881322231361439), one that certainly
    couldn't be fixed on the spot ('glycol all over the roof' is not a phrase you
    really want to hear about your AC's chiller). To keep the machine room's temperature
    down, we had to power off as many machines as possible without too badly affecting
    the services we offer to people here, [which are rather varied](/~cks/space/blog/sysadmin/OurDifferentSysadminEnvironment).
    Some choices were obvious; all of [our SLURM nodes](/~cks/space/blog/sysadmin/SlurmHowWeUseIt)
    that were in the main machine room got turned off right away. But others weren't
    things we necessarily remembered right away or we weren't clear if they were safe
    to turn off and what effects it would have. In the end we took several rounds
    of turning servers off, looking at what was left, spotting remaining machines,
    and turning more things off, and we're probably not done yet.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 今天[我们的主要机房发生了重大的空调故障](https://mastodon.social/@cks/111881322231361439)，这显然不能立即修复（“甘醇洒遍屋顶”不是你真的想听到的空调制冷机的词语）。为了保持机房的温度，我们必须尽可能关闭尽可能多的机器，而不会严重影响我们向这里的人们提供的服务，[这些服务相当多样化](/~cks/space/blog/sysadmin/OurDifferentSysadminEnvironment)。有些选择是显而易见的；所有位于主要机房的[我们的SLURM节点](/~cks/space/blog/sysadmin/SlurmHowWeUseIt)立即被关闭了。但其他一些并不是我们马上记得的事情，或者我们不确定它们是否安全关闭以及会产生什么影响。最后，我们进行了数轮关闭服务器，查看剩余的内容，发现剩余的机器，并关闭更多内容，而且我们可能还没有完成。
- en: (We have secondary machine room space and we're probably going to have to evacuate
    servers into it, too.)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: （我们有备用机房空间，我们可能也会被迫将服务器迁移到其中。）
- en: One thing we could do to avoid this flailing in the future is to explicitly
    (try to) keep track of which machines are important and which ones aren't, to
    pre-plan which machines we could shut down if we had a limited amount of cooling
    or power. If we documented this, we could avoid having to wrack our brains at
    the last minute and worry about dependencies or uses that we'd forgotten. Of course
    documentation isn't free; there's an ongoing amount of work to write it and keep
    it up to date. But possibly we could do this work as part of deploying machines
    or changing their configurations.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免将来出现这种摸索情况，我们可以明确地（尝试）跟踪哪些机器是重要的，哪些不是，预先规划如果我们的制冷或电力有限，可以关闭哪些机器。如果我们记录了这一点，就可以避免在最后一刻绞尽脑汁，担心我们忘记的依赖关系或用途。当然，文档并不是免费的；编写和保持更新是一项持续的工作。但可能我们可以将这项工作作为部署机器或更改其配置的一部分来完成。
- en: (This would also help identify machines that we didn't need any more but hadn't
    gotten around to taking out of service, which we found a couple of in this iteration.)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: （这也有助于识别我们不再需要但尚未停止使用的机器，我们在这次迭代中发现了几个。）
- en: Writing all of this just in case of further AC failures is probably not all
    that great a choice of where to spend our time. But writing down this sort of
    thing can often help to clarify how your environment is connected together in
    general, including things like what will probably break or have problems if a
    specific machine (or service) is out, and perhaps which people depend on what
    service. This can be valuable information in general. The machine room archaeology
    of 'what is this machine, why is it on, and who is using it' can be fun occasionally,
    but you probably don't want to do it regularly.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止进一步的空调故障，写下所有这些可能并不是花时间的好选择。但写下这类事情通常可以帮助澄清你的环境如何一般连接在一起，包括诸如如果特定机器（或服务）不可用，则可能会破坏或出现问题的事物，以及可能是谁依赖于什么服务。这些信息通常很有价值。机房考古学中的“这是什么机器，为什么要打开它，谁在使用它”的情况偶尔会有趣，但你可能不想经常这样做。
- en: (Will we actually do this? I suspect not. When we deploy and start using a machine
    its purpose and so on feel obvious, because we have all of the context.)
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: （我们实际会这样做吗？我怀疑不会。当我们部署并开始使用一台机器时，它的用途等等似乎是显而易见的，因为我们有所有的上下文。）
