- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-29 13:23:45'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024年5月29日13:23:45
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Au Large | Mistral AI | Frontier AI in your hands
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Au Large | Mistral AI | 您手中的Frontier AI
- en: 来源：[https://mistral.ai/news/mistral-large/](https://mistral.ai/news/mistral-large/)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://mistral.ai/news/mistral-large/](https://mistral.ai/news/mistral-large/)
- en: We are releasing *Mistral Large*, our latest and most advanced language model.
    *Mistral Large* is available through la Plateforme. We are also making it available
    through Azure, our first distribution partner.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发布了* Mistral Large*，我们最新和最先进的语言模型。 *Mistral Large*可以通过la Plateforme使用。 我们还通过Azure，我们的第一个分销合作伙伴，将其获得。
- en: Mistral Large, our new flagship model
  id: totrans-7
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Mistral Large，我们的新旗舰模型
- en: Mistral Large is our new cutting-edge text generation model. It reaches top-tier
    reasoning capabilities. It can be used for complex multilingual reasoning tasks,
    including text understanding, transformation, and code generation.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**Mistral Large**是我们的新一代文本生成模型。 它具有顶尖的推理能力。 它可以用于复杂的多语言推理任务，包括文本理解，转换和代码生成。'
- en: Mistral Large achieves strong results on commonly used benchmarks, making it
    the world's second-ranked model generally available through an API (next to GPT-4)
    [see below for details on benchmarks].
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Mistral Large在常用的基准测试上取得了良好的结果，使其成为除GPT-4之外通常可用的模型的全球第二名（有关基准测试的详细信息，请参见下文）。
- en: 'Figure 1: Comparison of GPT-4, Mistral Large (pre-trained), Claude 2, Gemini
    Pro 1.0, GPT 3.5 and LLaMA 2 70B on MMLU (Measuring massive multitask language
    understanding).'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：市场上顶尖LLM模型GPT-4、Mistral Large（预训练）、Claude 2、Gemini Pro 1.0、GPT 3.5和LLaMA
    2 70B在MMLU（大规模多任务语言理解）上的性能比较。
- en: 'Mistral Large comes with new capabilities and strengths:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Mistral Large具有新的功能和优势：
- en: It is **natively fluent in English, French, Spanish, German, and Italian,**
    with a nuanced understanding of grammar and cultural context.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它在英语、法语、西班牙语、德语和意大利语中**具有本地流利**，并且对语法和文化背景有细致的理解。
- en: Its **32K tokens context window** allows precise information recall from large
    documents.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其**32K个标记上下文窗口**允许从大文档中精确地回忆信息。
- en: Its **precise instruction-following** enables developers to design their **moderation
    policies** – we used it to set up the system-level moderation of le Chat.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它的**精确的指令遵循**使开发人员能够设计他们的**审查政策** - 我们使用它来设置le Chat的系统级审查。
- en: '**It is natively capable of function calling.** This, along with constrained
    output mode, implemented on la Plateforme, enables application development and
    tech stack modernisation at scale.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**它本能地具有功能调用的能力**。 这与在la Plateforme上实现的约束输出模式一起，使得应用程序的开发和技术架构现代化规模化。'
- en: '**Partnering with Microsoft to provide our models on Azure**'
  id: totrans-16
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 与微软合作，在Azure上提供我们的模型
- en: 'At Mistral, our mission is to make frontier AI ubiquitous. This is why we’re
    announcing today that we’re bringing our open and commercial models to Azure.
    Microsoft’s trust in our model is a step forward in our journey! Our models are
    now available through:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在Mistral，我们的使命是使前沿AI普及化。 这就是为什么今天我们宣布我们将把我们的开放和商业模型带到Azure。 微软对我们模型的信任是我们旅程的一大步！
    我们的模型现在可以通过以下方式获得：
- en: '**La Plateforme**: safely hosted on Mistral’s infrastructure in Europe, this
    access point enables developers to create applications and services across our
    comprehensive range of models.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**la Plateforme**：安全托管在欧洲Mistral的基础设施上，这个接入点使开发人员可以跨越我们的全面模型范围创建应用程序和服务。'
- en: '**Azure:** Mistral Large is available through [Azure AI Studio and Azure Machine
    Learning](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/mistal-large-mistral-ai-s-flagship-llm-debuts-on-azure-ai-models/ba-p/4066996),
    with as seamless a user experience as our APIs. Beta customers have used it with
    [significant success](/business/).'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Azure：** Mistral Large可以通过[Azure AI Studio和Azure Machine Learning](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/mistal-large-mistral-ai-s-flagship-llm-debuts-on-azure-ai-models/ba-p/4066996)获得，在用户体验方面与我们的API一样无缝。
    Beta客户已成功使用它进行[重大成功](/business/)。'
- en: '**Self-deployment**: our models can be deployed on your environment for the
    most sensitive use cases with access to our model weights; Read success stories
    on this kind of deployment, and [contact our team](https://mistral.ai/contact/)
    for further details.'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**自部署**：我们的模型可以部署在您的环境中，适用于最敏感的使用案例，并可以访问我们的模型权重；阅读这种部署的成功案例，并[联系我们的团队](https://mistral.ai/contact/)获取更多详细信息。'
- en: '**Mistral Large capacities**'
  id: totrans-21
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**Mistral Large能力**'
- en: We compare Mistral Large's performance to the top-leading LLM models on commonly
    used benchmarks.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 我们比较了Mistral Large在常用基准测试中与顶级LLM模型的性能。
- en: '**Reasoning and knowledge**'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**推理和知识**'
- en: Mistral Large shows powerful reasoning capabilities. In the following figure,
    we report the performance of the pretrained models on standard benchmarks.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Mistral Large显示出强大的推理能力。 在下图中，我们报告了预训练模型在标准基准上的性能。
- en: 'Figure 2: Performance on widespread common sense, reasoning and knowledge benchmarks
    of the top-leading LLM models on the market: MMLU (Measuring massive multitask
    language in understanding), HellaSwag (10-shot), Wino Grande (5-shot), Arc Challenge
    (5-shot), Arc Challenge (25-shot), TriviaQA (5-shot) and TruthfulQA.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：市场上顶尖LLM模型在广泛的常识、推理和知识基准上的表现：MMLU（大规模多任务语言理解）、HellaSwag（10-shot）、Wino Grande（5-shot）、Arc
    Challenge（5-shot）、Arc Challenge（25-shot）、TriviaQA（5-shot）和TruthfulQA。
- en: '**Multi-lingual capacities**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**多语言能力**'
- en: Mistral Large has native multi-lingual capacities. It strongly outperforms LLaMA
    2 70B on HellaSwag, Arc Challenge and MMLU benchmarks in French, German, Spanish
    and Italian.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Mistral Large具有本地多语言能力。 在法语、德语、西班牙语和意大利语的HellaSwag、Arc Challenge和MMLU基准上，其性能远远超过LLaMA
    2 70B。
- en: 'Figure 3: Comparison of Mistral Large, Mixtral 8x7B and LLaMA 2 70B on HellaSwag,
    Arc Challenge and MMLU in French, German, Spanish and Italian.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：Mistral Large、Mixtral 8x7B和LLaMA 2 70B在法语、德语、西班牙语和意大利语的HellaSwag、Arc Challenge和MMLU比较。
- en: '**Maths & Coding**'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**数学和编码**'
- en: Mistral Large shows top performance in coding and math tasks. In the table below,
    we report the performance across a suite of popular benchmarks to evaluate the
    coding and math performance for some of the top-leading LLM models.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: Mistral Large 在编码和数学任务方面表现出色。在下表中，我们报告了一系列流行基准测试的性能，以评估一些领先的LLM模型的编码和数学性能。
- en: 'Figure 4: Performance on popular coding and math benchmarks of the leading
    LLM models on the market: HumanEval pass@1, MBPP pass@1, Math maj@4, GSM8K maj@8
    (8-shot) and GSM8K maj@1 (5 shot).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：市场上领先的LLM模型在流行编码和数学基准测试中的表现：HumanEval pass@1、MBPP pass@1、Math maj@4、GSM8K
    maj@8（8-shot）和GSM8K maj@1（5 shot）。
- en: '**A new Mistral Small, optimised for low latency workloads**'
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**新的 Mistral Small，针对低延迟工作负载进行优化**'
- en: Alongside Mistral Large, we’re releasing a new optimised model, Mistral Small,
    optimised for latency and cost. Mistral Small outperforms Mixtral 8x7B and has
    lower latency, which makes it a refined intermediary solution between our open-weight
    offering and our flagship model.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 Mistral Large，我们还发布了一个针对延迟和成本进行优化的新模型，Mistral Small。Mistral Small优于Mixtral
    8x7B，并具有较低的延迟，使其成为我们开放权重方案和旗舰模型之间的精致中间解决方案。
- en: Mistral Small benefits from the same innovation as Mistral Large regarding RAG-enablement
    and function calling.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Mistral Small 受益于与 Mistral Large 相同的创新，包括RAG启用和函数调用。
- en: 'We’re simplifying our endpoint offering to provide the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在简化我们的端点提供，以提供以下内容：
- en: Open-weight endpoints with competitive pricing. This comprises `open-mistral-7B`
    and `open-mixtral-8x7b`.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有竞争性定价的开放权重端点。包括`open-mistral-7B`和`open-mixtral-8x7b`。
- en: New optimised model endpoints, `mistral-small-2402` and `mistral-large-2402`.
    We’re maintaining `mistral-medium`, which we are not updating today.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新的优化模型端点，`mistral-small-2402` 和 `mistral-large-2402`。我们将保留 `mistral-medium`，但今天不进行更新。
- en: Our [benchmarks](https://docs.mistral.ai/platform/endpoints/) give a comprehensive
    view of performance/cost tradeoffs.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的[基准测试](https://docs.mistral.ai/platform/endpoints/)提供了性能/成本权衡的全面视图。
- en: Beyond the new model offering, we’re allowing organisation management multi-currency
    pricing and have updated service tiers on la Plateforme. We have also made a lot
    of progress in reducing the latency of all our endpoints.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 除了新的模型，我们还允许组织管理多种货币定价，并已更新了 la Plateforme 上的服务等级。我们在降低所有端点的延迟方面取得了许多进展。
- en: '**JSON format and function calling**'
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**JSON 格式和函数调用**'
- en: JSON format mode forces the language model output to be valid JSON. This functionality
    enables developers to interact with our models more naturally to extract information
    in a structured format that can be easily used in the remainder of their pipelines.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: JSON格式模式将语言模型输出强制为有效的JSON格式。此功能使开发人员可以更自然地与我们的模型交互，以便在其余的流程中轻松使用结构化格式中提取出的信息。
- en: Function calling lets developers interface Mistral endpoints with a set of their
    own tools, enabling more complex interactions with internal code, APIs or databases.
    You will learn more in our [function calling guide](https://docs.mistral.ai/guides/function-calling).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 函数调用让开发人员能够使用自己的一组工具与 Mistral 端点进行交互，实现与内部代码、API或数据库更复杂的交互。您可以在我们的[函数调用指南](https://docs.mistral.ai/guides/function-calling)中了解更多。
- en: Function calling and JSON format are only available on mistral-small and mistral-large.
    We will be adding formatting to all endpoints shortly, as well as enabling more
    fine-grained format definitions.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 函数调用和 JSON 格式仅在 mistral-small 和 mistral-large 上可用。我们将很快为所有端点添加格式，以及启用更精细的格式定义。
- en: '**Try Mistral Large and Mistral Small today**'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**立即尝试 Mistral Large 和 Mistral Small**'
- en: Mistral Large is available on La Plateforme and Azure as of today. Mistral Large
    is also exposed on our beta assistant demonstrator, [le Chat](https://chat.mistral.ai/).
    As always, we’re eager to have your feedback!
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 从今天起，在 La Plateforme 和 Azure 上都可以使用 Mistral Large。Mistral Large 也在我们的 beta 助手演示者[le
    Chat](https://chat.mistral.ai/)上公开。我们一直渴望听到您的反馈！
