- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-29 13:27:48'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-29 13:27:48'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: EMO
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: EMO
- en: 来源：[https://humanaigc.github.io/emote-portrait-alive/](https://humanaigc.github.io/emote-portrait-alive/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://humanaigc.github.io/emote-portrait-alive/](https://humanaigc.github.io/emote-portrait-alive/)
- en: We proposed EMO, an expressive audio-driven portrait-video generation framework.
    Input a single reference image and the vocal audio, e.g. talking and singing,
    our method can generate vocal avatar videos with expressive facial expressions,
    and various head poses, meanwhile, we can generate videos with any duration depending
    on the length of input video.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了EMO，一种表现力十足的音频驱动肖像视频生成框架。输入单张参考图像和语音音频，例如说话和唱歌，我们的方法可以生成具有表情丰富的面部表情和各种头部姿势的语音化身视频，同时，我们可以根据输入视频的长度生成任意时长的视频。
