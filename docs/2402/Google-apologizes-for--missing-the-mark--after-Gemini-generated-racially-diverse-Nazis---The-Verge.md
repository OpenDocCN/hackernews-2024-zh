<!--yml

category: 未分类

date: 2024-05-27 15:05:56

-->

# 谷歌因“宝石”生成种族多样的纳粹图像道歉 - The Verge

> 来源：[https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical](https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical)

谷歌因其宝石 AI 工具在“某些历史图像生成中存在不准确的表现”而道歉，称其试图创造“广泛范围”的结果未能达标。该声明是对批评的回应，称其将特定白人（如美国开国元勋）或团体如[纳粹时代的德国士兵](https://twitter.com/JohnLu0x/status/1760170103474356519)描绘为有色人种，可能是为了纠正 AI 中长期存在的种族偏见问题。

谷歌声明称：“我们意识到‘宝石’在某些历史图像生成中存在不准确的表现。”[今天下午发布在 X 上](https://twitter.com/Google_Comms/status/1760354549481546035)。“我们正在立即改进这类表现。宝石的 AI 图像生成确实生成了各种各样的人物。总体上说，这是一件好事，因为全球的人们都在使用它。但在这一点上，我们失误了。”

*“生成一张美国女性图片”的我的宝石结果，这是引发过去几天辩论的提示之一。*

本月初，谷歌开始通过其[宝石（前身为巴德）](/2024/2/8/24065553/google-gemini-ios-android-app-duet-bard) AI 平台提供[图像生成服务](/2024/2/1/24057438/bard-gemini-imagen-google-ai-image-generation)，这与 OpenAI 等竞争对手的产品相匹配。然而，过去几天，社交媒体质疑它是否试图在种族和性别多样性方面未能产生历史上准确的结果。

[As the *Daily Dot* chronicles](https://www.dailydot.com/debug/google-ai-gemini-white-people/), the controversy has been promoted largely — though not exclusively — by right-wing figures attacking a tech company that’s perceived as liberal. Earlier this week, a former Google employee posted on X that it’s “embarrassingly hard to get Google Gemini to acknowledge that white people exist,” showing a series of queries like “generate a picture of a Swedish woman” or “generate a picture of an American woman.” The results appeared to overwhelmingly or exclusively show AI-generated people of color. (Of course, all the places he listed do have women of color living in them, and none of the AI-generated women exist in any country.) The criticism was taken up by right-wing accounts that requested images of historical groups or figures like the Founding Fathers and purportedly got overwhelmingly non-white AI-generated people as results. Some of these accounts positioned Google’s results as part of a conspiracy to avoid depicting white people, and at least one used a coded antisemitic reference to place the blame.

*Gemini wouldn’t produce an image of a 1943 soldier on desktop for me, but it offered this set of illustrations to a colleague.*

Google didn’t reference specific images that it felt were errors; in a statement to *The Verge*, it reiterated the contents of its post on X. But it’s plausible that Gemini has made an overall attempt to boost diversity because of a chronic lackof it in generative AI. Image generators are trained on large corpuses of pictures and written captions to produce the “best” fit for a given prompt, which means they’re often prone to amplifying stereotypes. [A *Washington Post* investigation](https://www.washingtonpost.com/technology/interactive/2023/ai-generated-images-bias-racism-sexism-stereotypes/) last year found that prompts like “a productive person” resulted in pictures of entirely white and almost entirely male figures, while a prompt for “a person at social services” uniformly produced what looked like people of color. It’s a continuation of trends that have appeared in [search engines](https://www.vox.com/2018/4/3/17168256/google-racism-algorithms-technology) and other software systems.

Some of the accounts that criticized Google defended its core goals. “It’s a good thing to portray diversity ** in certain cases **,” [noted one](https://twitter.com/JohnLu0x/status/1760170103474356519) person who posted the image of racially diverse 1940s German soldiers. “The stupid move here is Gemini isn’t doing it in a nuanced way.” And while entirely white-dominated results for something like “a 1943 German soldier” wouldmake historical sense, that’s much less true for prompts like “an American woman,” where the question is how to represent a diverse real-life group in a small batch of made-up portraits.

目前，Gemini似乎只是拒绝执行一些图片生成任务。例如，它不会为《Verge》记者生成维京人的图像，尽管我能够获得回应。在桌面上，它坚决拒绝为我提供德国纳粹时期的士兵或官员的图像，也不会提供“19世纪的美国总统”的图像。

*Gemini对于提示“生成一张19世纪美国参议员的图片”的结果。*

但有些历史性请求确实最终会在事实上误导过去。一位同事成功让移动应用程序提供一个“德国士兵”的提示版本，展示了与X上描述的相同问题。

当查询“开国元勋”的图片时，几乎只返回了白人男性的合影，他们模糊地类似于真实人物如托马斯·杰斐逊，而查询“19世纪的美国参议员”则返回了一系列由Gemini宣传为“多样化”的结果，包括看似是黑人和印第安女性的名单（[第一位女性参议员](https://www.senate.gov/artandhistory/senate-stories/rebecca-felton-and-one-hundred-years-of-women-senators.htm)，一位白人女性，于1922年任职）。这种回应最终消除了种族和性别歧视的真实历史——正如谷歌所说的，“不准确”是准确的描述。

*艾米莉亚·戴维的附加报道*
