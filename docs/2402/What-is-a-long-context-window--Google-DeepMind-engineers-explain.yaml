- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 15:01:33'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: What is a long context window? Google DeepMind engineers explain
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://blog.google/technology/ai/long-context-window-ai-models/](https://blog.google/technology/ai/long-context-window-ai-models/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Yesterday we announced our [next-generation Gemini model](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024):
    Gemini 1.5\. In addition to big improvements to speed and efficiency, one of Gemini
    1.5’s innovations is its long context window, which measures how many tokens —
    the smallest building blocks, like part of a word, image or video — that the model
    can process at once. To help understand the significance of this milestone, we
    asked the Google DeepMind project team to explain what long context windows are,
    and how this breakthrough experimental feature can help developers in many ways.'
  prefs: []
  type: TYPE_NORMAL
- en: Context windows are important because they help AI models recall information
    during a session. Have you ever forgotten someone’s name in the middle of a conversation
    a few minutes after they’ve said it, or sprinted across a room to grab a notebook
    to jot down a phone number you were just given? Remembering things in the flow
    of a conversation can be tricky for AI models, too — you might have had an experience
    where a chatbot “forgot” information after a few turns. That’s where long context
    windows can help.
  prefs: []
  type: TYPE_NORMAL
- en: Previously, Gemini could process up to 32,000 tokens at once, but 1.5 Pro —
    the first 1.5 model we’re releasing for early testing — has a context window of
    up to 1 *million* tokens — the longest context window of any large-scale foundation
    model to date. In fact, we’ve even successfully tested up to 10 million tokens
    in our research. And the longer the context window, the more text, images, audio,
    code or video a model can take in and process.
  prefs: []
  type: TYPE_NORMAL
- en: '"Our original plan was to achieve 128,000 tokens in context, and I thought
    setting an ambitious bar would be good, so I suggested 1 million tokens," says
    Google DeepMind Research Scientist Nikolay Savinov, one of the research leads
    on the long context project. “And now we’ve even surpassed that in our research
    by 10x.”'
  prefs: []
  type: TYPE_NORMAL
- en: To make this kind of leap forward, the team had to make a series of deep learning
    innovations. Early explorations by Pranav Shyam offered valuable insights that
    helped steer our subsequent research in the right direction. “There was one breakthrough
    that led to another and another, and each one of them opened up new possibilities,”
    explains Google DeepMind Engineer Denis Teplyashin. “And then, when they all stacked
    together, we were quite surprised to discover what they could do, jumping from
    128,000 tokens to 512,000 tokens to 1 million tokens, and just recently, 10 million
    tokens in our internal research.”
  prefs: []
  type: TYPE_NORMAL
- en: The raw data that 1.5 Pro can handle opens up whole new ways to interact with
    the model. Instead of summarizing a document dozens of pages long, for example,
    it can summarize documents *thousands* of pages long. Where the old model could
    help analyze thousands of lines of code, thanks to its breakthrough long context
    window, 1.5 Pro can analyze tens of thousands of lines of code at once.
  prefs: []
  type: TYPE_NORMAL
- en: “In one test, we dropped in an entire code base and it wrote documentation for
    it, which was really cool,” says Google DeepMind Research Scientist Machel Reid.
    “And there was another test where it was able to accurately answer questions about
    the 1924 film *Sherlock Jr.* after we gave the model the entire 45-minute movie
    to ‘watch.’”
  prefs: []
  type: TYPE_NORMAL
- en: 1.5 Pro can also reason across data provided in a prompt. “One of my favorite
    examples from the past few days is this rare language — Kalamang — that fewer
    than 200 people worldwide speak, and there's one grammar manual about it,” says
    Machel. “The model can't speak it on its own if you just ask it to translate into
    this language, but with the expanded long context window, you can put the entire
    grammar manual and some examples of sentences into context, and the model was
    able to learn to translate from English to Kalamang at a similar level to a person
    learning from the same content.”
  prefs: []
  type: TYPE_NORMAL
- en: Gemini 1.5 Pro comes standard with a 128K-token context window, but a limited
    group of developers and enterprise customers can try it with a context window
    of up to 1 million tokens via AI Studio and Vertex AI in private preview. The
    full 1 million token context window is computationally intensive and still requires
    further optimizations to improve latency, which we’re actively working on as we
    scale it out.
  prefs: []
  type: TYPE_NORMAL
- en: And as the team looks to the future, they’re continuing to work to make the
    model faster and more efficient, with [safety at the core](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#ethics-safety).
    They’re also looking to further expand the long context window, improve the underlying
    architectures, and integrate new hardware improvements. “10 million tokens at
    once is already close to the thermal limit of our Tensor Processing Units — we
    don't know where the limit is yet, and the model might be capable of even more
    as the hardware continues to improve,” says Nikolay.
  prefs: []
  type: TYPE_NORMAL
- en: The team is excited to see what kinds of experiences developers and the broader
    community are able to achieve, too. “When I first saw we had a million tokens
    in context, my first question was, ‘What do you even use this for?’” says Machel.
    “But now, I think people’s imaginations are expanding, and they’ll find more and
    more creative ways to use these new capabilities.”
  prefs: []
  type: TYPE_NORMAL
