- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-05-27 15:01:33'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-27 15:01:33
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: What is a long context window? Google DeepMind engineers explain
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是长上下文窗口？谷歌 DeepMind 工程师解释
- en: 来源：[https://blog.google/technology/ai/long-context-window-ai-models/](https://blog.google/technology/ai/long-context-window-ai-models/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://blog.google/technology/ai/long-context-window-ai-models/](https://blog.google/technology/ai/long-context-window-ai-models/)
- en: 'Yesterday we announced our [next-generation Gemini model](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024):
    Gemini 1.5\. In addition to big improvements to speed and efficiency, one of Gemini
    1.5’s innovations is its long context window, which measures how many tokens —
    the smallest building blocks, like part of a word, image or video — that the model
    can process at once. To help understand the significance of this milestone, we
    asked the Google DeepMind project team to explain what long context windows are,
    and how this breakthrough experimental feature can help developers in many ways.'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 昨天，我们宣布了我们的[下一代 Gemini 模型](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024)：Gemini
    1.5\. 除了速度和效率大幅提升外，Gemini 1.5 的一个创新之处在于其长上下文窗口，这是指模型可以一次处理的标记数量 —— 这些标记是最小的构建单元，例如词的一部分、图像或视频的一部分。为了帮助理解这一里程碑的重要性，我们请谷歌
    DeepMind 项目团队解释长上下文窗口是什么，以及这一突破性实验性功能如何在许多方面帮助开发者。
- en: Context windows are important because they help AI models recall information
    during a session. Have you ever forgotten someone’s name in the middle of a conversation
    a few minutes after they’ve said it, or sprinted across a room to grab a notebook
    to jot down a phone number you were just given? Remembering things in the flow
    of a conversation can be tricky for AI models, too — you might have had an experience
    where a chatbot “forgot” information after a few turns. That’s where long context
    windows can help.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文窗口对于帮助 AI 模型在会话中回忆信息非常重要。你有没有在别人说完名字几分钟后就忘记他们的名字，或者跑到房间另一头拿笔记本记下刚给你的电话号码？在对话中记住事物对
    AI 模型也可能很棘手 —— 也许你曾经遇到过聊天机器人在几轮对话后“忘记”信息的情况。这就是长上下文窗口能帮助的地方。
- en: Previously, Gemini could process up to 32,000 tokens at once, but 1.5 Pro —
    the first 1.5 model we’re releasing for early testing — has a context window of
    up to 1 *million* tokens — the longest context window of any large-scale foundation
    model to date. In fact, we’ve even successfully tested up to 10 million tokens
    in our research. And the longer the context window, the more text, images, audio,
    code or video a model can take in and process.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 以前，Gemini 一次最多可以处理 32,000 个标记，但我们正在早期测试发布的首个 1.5 Pro 模型的上下文窗口可以达到 1 *百万* 个标记
    —— 这是迄今为止任何大规模基础模型的最长上下文窗口。事实上，我们甚至已经成功测试了达到 10 百万个标记的情况。而上下文窗口越长，模型可以接收和处理的文本、图像、音频、代码或视频就越多。
- en: '"Our original plan was to achieve 128,000 tokens in context, and I thought
    setting an ambitious bar would be good, so I suggested 1 million tokens," says
    Google DeepMind Research Scientist Nikolay Savinov, one of the research leads
    on the long context project. “And now we’ve even surpassed that in our research
    by 10x.”'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: '"我们最初的计划是在上下文中实现 128,000 个标记，我认为设定一个雄心勃勃的目标是件好事，所以我建议 1 百万个标记，" 谷歌 DeepMind
    研究科学家 Nikolay Savinov 之一在长上下文项目的研究负责人说道。"而现在，在我们的研究中，我们甚至已经超过了这个目标 10 倍。"'
- en: To make this kind of leap forward, the team had to make a series of deep learning
    innovations. Early explorations by Pranav Shyam offered valuable insights that
    helped steer our subsequent research in the right direction. “There was one breakthrough
    that led to another and another, and each one of them opened up new possibilities,”
    explains Google DeepMind Engineer Denis Teplyashin. “And then, when they all stacked
    together, we were quite surprised to discover what they could do, jumping from
    128,000 tokens to 512,000 tokens to 1 million tokens, and just recently, 10 million
    tokens in our internal research.”
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现这种飞跃，团队必须进行一系列深度学习创新。Pranav Shyam 的早期探索提供了宝贵的见解，帮助我们将后续的研究引向正确方向。"一次突破导致另一次突破，每一个都开辟了新的可能性，"
    谷歌 DeepMind 工程师Denis Teplyashin 解释道。"然后，当它们全部叠加在一起时，我们非常惊讶地发现它们能做到什么，从 128,000
    个标记跳跃到 512,000 个标记，最近甚至在我们的内部研究中达到了 10 百万个标记。"
- en: The raw data that 1.5 Pro can handle opens up whole new ways to interact with
    the model. Instead of summarizing a document dozens of pages long, for example,
    it can summarize documents *thousands* of pages long. Where the old model could
    help analyze thousands of lines of code, thanks to its breakthrough long context
    window, 1.5 Pro can analyze tens of thousands of lines of code at once.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 1.5 Pro 能处理的原始数据打开了与模型交互的全新方式。例如，它不再只是总结几十页长的文档，而是可以总结*数千*页长的文档。旧模型可以帮助分析数千行代码，而得益于突破性的长上下文窗口，1.5
    Pro 可以一次分析数万行代码。
- en: “In one test, we dropped in an entire code base and it wrote documentation for
    it, which was really cool,” says Google DeepMind Research Scientist Machel Reid.
    “And there was another test where it was able to accurately answer questions about
    the 1924 film *Sherlock Jr.* after we gave the model the entire 45-minute movie
    to ‘watch.’”
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: “在一个测试中，我们放入了一个完整的代码库，它为其编写了文档，这真的很酷，” Google DeepMind 的研究科学家 Machel Reid 说。“还有另一个测试，我们给模型整个
    45 分钟的电影 *《神探福尔摩斯》* 来‘观看’后，它能准确回答有关1924年电影《神探福尔摩斯少爷》的问题。”
- en: 1.5 Pro can also reason across data provided in a prompt. “One of my favorite
    examples from the past few days is this rare language — Kalamang — that fewer
    than 200 people worldwide speak, and there's one grammar manual about it,” says
    Machel. “The model can't speak it on its own if you just ask it to translate into
    this language, but with the expanded long context window, you can put the entire
    grammar manual and some examples of sentences into context, and the model was
    able to learn to translate from English to Kalamang at a similar level to a person
    learning from the same content.”
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 1.5 Pro 还能推理出在提示中提供的数据。“在过去几天里，我最喜欢的一个例子是这种罕见的语言 —— 卡拉曼语 —— 全球仅有不到 200 人说得流利，关于它只有一本语法手册，”
    Machel 说。“如果你只是让模型翻译成这种语言，它不能独立说出来，但通过扩展的长上下文窗口，你可以将整个语法手册以及一些例句放入上下文中，模型能够学会从英语翻译成卡拉曼语，达到与从相同内容学习的人类类似的水平。”
- en: Gemini 1.5 Pro comes standard with a 128K-token context window, but a limited
    group of developers and enterprise customers can try it with a context window
    of up to 1 million tokens via AI Studio and Vertex AI in private preview. The
    full 1 million token context window is computationally intensive and still requires
    further optimizations to improve latency, which we’re actively working on as we
    scale it out.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: Gemini 1.5 Pro 标配128K令牌上下文窗口，但一小部分开发人员和企业客户可以通过AI Studio和Vertex AI在私人预览中尝试使用长达一百万令牌的上下文窗口。完整的一百万令牌上下文窗口计算密集型，仍需进一步优化以改进延迟，我们正在积极推进扩展。
- en: And as the team looks to the future, they’re continuing to work to make the
    model faster and more efficient, with [safety at the core](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#ethics-safety).
    They’re also looking to further expand the long context window, improve the underlying
    architectures, and integrate new hardware improvements. “10 million tokens at
    once is already close to the thermal limit of our Tensor Processing Units — we
    don't know where the limit is yet, and the model might be capable of even more
    as the hardware continues to improve,” says Nikolay.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 随着团队展望未来，他们继续努力使模型更快、更高效，以[安全为核心](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/#ethics-safety)。他们还在努力扩展长上下文窗口，改进底层架构，并整合新的硬件改进。“一次处理一千万个令牌已接近我们张贴的张贴限制，我们还不知道极限在哪里，而且随着硬件的不断改进，模型可能还能做得更多，”
    Nikolay 说。
- en: The team is excited to see what kinds of experiences developers and the broader
    community are able to achieve, too. “When I first saw we had a million tokens
    in context, my first question was, ‘What do you even use this for?’” says Machel.
    “But now, I think people’s imaginations are expanding, and they’ll find more and
    more creative ways to use these new capabilities.”
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 团队对开发人员和更广泛社区能够实现的体验充满期待。“当我第一次看到我们在上下文中有一百万个令牌时，我的第一个问题是，‘你究竟要用这个做什么？’” Machel
    说。“但现在，我认为人们的想象力在扩展，他们将会找到越来越多创造性的方式来利用这些新能力。”
