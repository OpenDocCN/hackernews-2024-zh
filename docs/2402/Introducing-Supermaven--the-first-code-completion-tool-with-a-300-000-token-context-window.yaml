- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 15:04:34'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 15:04:34'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Introducing Supermaven, the first code completion tool with a 300,000-token
    context window
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍Supermaven，第一个具有300,000个标记上下文窗口的代码完成工具
- en: 来源：[https://supermaven.com/blog/introducing-supermaven](https://supermaven.com/blog/introducing-supermaven)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://supermaven.com/blog/introducing-supermaven](https://supermaven.com/blog/introducing-supermaven)
- en: '| Tool | Frames | Latency (ms) |'
  id: totrans-split-6
  prefs: []
  type: TYPE_TB
  zh: '| 工具 | 帧 | 延迟（毫秒） |'
- en: '| --- | --- | --- |'
  id: totrans-split-7
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Supermaven | 15 | 250 |'
  id: totrans-split-8
  prefs: []
  type: TYPE_TB
  zh: '| Supermaven | 15 | 250 |'
- en: '| Copilot | 47 | 783 |'
  id: totrans-split-9
  prefs: []
  type: TYPE_TB
  zh: '| Copilot | 47 | 783 |'
- en: '| Codeium | 53 | 883 |'
  id: totrans-split-10
  prefs: []
  type: TYPE_TB
  zh: '| Codeium | 53 | 883 |'
- en: '| Tabnine | 50 | 833 |'
  id: totrans-split-11
  prefs: []
  type: TYPE_TB
  zh: '| Tabnine | 50 | 833 |'
- en: '| Cursor | 113 | 1,883 |'
  id: totrans-split-12
  prefs: []
  type: TYPE_TB
  zh: '| Cursor | 113 | 1,883 |'
- en: '*See below for details.*'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*详细信息见下文。*'
- en: Code completion has come a long way. When I created TabNine in 2018, the first
    tool to use deep learning for code completion, there were few developer tools
    that used AI. The models were small, the capabilities were limited, and people
    were skeptical that the tools were useful enough to be worth paying for.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 代码完成已经走过了一段很长的路程。当我在2018年创建了TabNine，这是第一个使用深度学习进行代码补全的工具时，几乎没有开发人员工具使用AI。那时的模型很小，功能有限，人们怀疑这些工具是否足够有用，值得付费。
- en: 'Since then, AI coding tools have been widely adopted: GitHub recently [announced](https://www.theinformation.com/briefings/microsoft-github-copilot-revenue-100-million-ARR-ai)
    that its tool Copilot had reached $100 million in annual recurring revenue. Millions
    of developers now use AI tools every day. This adoption is driven by the deployment
    of large models with tens of billions of parameters that are much more useful
    than the models of 2018.'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 此后，AI编码工具已被广泛采用：GitHub最近[宣布](https://www.theinformation.com/briefings/microsoft-github-copilot-revenue-100-million-ARR-ai)，其工具Copilot年收入达到1亿美元。现在，数百万开发人员每天都在使用AI工具。这种采用是由于部署了具有数十亿参数的大模型，这些模型比2018年的模型更加实用。
- en: 'Given that code completion has "gone mainstream", given the growing size of
    the largest language models, and given the enormous costs involved in training
    the largest models, it raises the question: is there still room for small startups?
    Has code completion become the exclusive province of large players like Microsoft
    or Google?'
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于代码完成已经“普及化”，最大语言模型的规模不断增长，并且训练最大模型的巨大成本，这引发了一个问题：小型初创公司还有空间吗？代码完成是否成为微软或谷歌等大公司的专属领域？
- en: At Supermaven we believe the question is not yet settled. The reason is the
    high serving costs of large models. While a model like GPT-4 offers unmatched
    suggestion quality, it's impossible to run on every keystroke (unless you charge
    users $1,000/month). Today, the deployment of an AI coding tool is limited just
    as much by the cost of the GPUs to run the tool as by the cost to develop the
    tool itself. That's why Copilot has [made efforts](https://thakkarparth007.github.io/copilot-explorer/posts/copilot-internals.html#preventing-poor-requests-via-contextual-filter)
    to reduce costs by limiting the contexts in which they offer suggestions.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在Supermaven，我们认为这个问题还没有最终解决。原因在于大型模型的高成本服务。虽然像GPT-4这样的模型提供了无与伦比的建议质量，但不可能在每次按键时运行它（除非向用户收取每月1000美元）。如今，AI编码工具的部署受到运行工具所需的GPU成本的限制，同样也受到开发工具本身成本的限制。这就是为什么Copilot通过[限制提供建议的上下文](https://thakkarparth007.github.io/copilot-explorer/posts/copilot-internals.html#preventing-poor-requests-via-contextual-filter)来减少成本的原因。
- en: 'The high cost of serving a code completion tool levels the playing field: it
    means that everyone, whether a small startup or Microsoft, must use a small model
    to remain profitable. The best product is the one which uses a small model most
    effectively.'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 服务代码完成工具的高成本使竞争变得公平：这意味着每个人，无论是小型初创公司还是微软，都必须使用小型模型来保持盈利。最佳产品是能够最有效地使用小型模型的产品。
- en: So how is Supermaven different?
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: Supermaven 有何不同？
- en: 300,000-token context window
  id: totrans-split-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 300,000-token 上下文窗口
- en: The context window of a code completion model determines how much of your code
    it can take into account when making its suggestions. A long context window is
    crucial to delivering good completions - that's why Copilot [recently expanded](https://github.blog/changelog/2023-08-28-github-copilot-august-28th-update/#expanding-copilots-context-window-to-8k)
    its context window to 8,192 tokens.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 代码完成模型的上下文窗口确定了它在提出建议时能够考虑的代码量。长期的上下文窗口对提供良好的补全至关重要——这就是为什么Copilot最近将其上下文窗口扩展到8,192个标记的原因。
- en: At Supermaven we've developed and trained from scratch a new neural network
    architecture which is more efficient than a Transformer (the current standard
    architecture) at integrating information across a long context window. This allows
    us to offer a 300,000-token context window while keeping the cost and latency
    the same as a Transformer with a 4,000-token context window.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在Supermaven，我们从头开始开发和训练了一种新的神经网络架构，比Transformer（当前标准架构）在整合长上下文窗口中的信息方面更高效。这使我们能够在保持成本和延迟与具有4,000令牌上下文窗口的Transformer相同的情况下，提供一个30万令牌的上下文窗口。
- en: 'As a user, that means that after Supermaven spends 10-20 seconds processing
    your repository, it will become familiar with your APIs and the unique conventions
    of your codebase. That fixes one of the most common complaints about Copilot:
    that while it''s great at working with well-known APIs and libraries that have
    good coverage in the training data, it struggles with the large, idiosyncratic
    codebases that you get when using it for real work.'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 作为用户，这意味着在Supermaven花费10-20秒处理您的代码库后，它将熟悉您的API和代码库的独特约定。这解决了Copilot最常见的抱怨之一：尽管它在处理覆盖率高的知名API和库时表现出色，但在处理实际工作中使用时所遇到的大型、特异的代码库时则显得力不从心。
- en: Here's a simple example of the difference that a 300,000-token context window
    makes. In this example, I ran Supermaven and Copilot on the same code and asked
    them to generate a function called `doubleIndentation` taking a value of type
    `Indentation`. Because the `Indentation` struct isn't defined or used anywhere
    in the file, Copilot doesn't have any information about it in context, so it generates
    code that doesn't compile. Supermaven generates correct code because its context
    window is large enough to fit the entire 50,000-token repository.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个简单的例子，说明了一个30万令牌上下文窗口的差异。在这个例子中，我在同一段代码上运行了Supermaven和Copilot，并要求它们生成一个名为`doubleIndentation`的函数，其参数类型为`Indentation`。由于文件中未定义或使用`Indentation`结构体，Copilot在上下文中没有任何关于它的信息，因此生成的代码不能编译通过。而Supermaven生成了正确的代码，因为它的上下文窗口足够大，可以包含整个5万令牌的代码库。
- en: <https://cdn.supermaven.com/video/longdef.mp4>
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: <https://cdn.supermaven.com/video/longdef.mp4>
- en: Speed
  id: totrans-split-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 速度
- en: 'Supermaven is fast: we''ve built custom infrastructure to keep it responsive
    while working with the long prompts that come with large codebases.'
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: Supermaven速度很快：我们建立了定制的基础设施，使其在处理大型代码库的长提示时保持响应性。
- en: 'I designed a simple test to compare Supermaven to the competition. To ensure
    each tool has the prompt in cache, I started with a context where every tool agrees
    the most likely completion is `for (let i`. Then I typed `for (let j`, forcing
    each tool to generate a new completion, and measured the number of frames between
    the appearance of ''j'' on the screen and the appearance of the completion. Here
    are the results:'
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我设计了一个简单的测试来比较Supermaven和其他竞争对手。为了确保每个工具都在缓存中有提示信息，我从一个上下文开始，其中每个工具都同意最可能的完成是`for
    (let i`。然后我键入了`for (let j`，强制每个工具生成一个新的完成，并测量了在屏幕上出现'j'和完成出现之间的帧数。以下是结果：
- en: '| Tool | Frames | Latency (ms) |'
  id: totrans-split-29
  prefs: []
  type: TYPE_TB
  zh: '| Tool | Frames | Latency (ms) |'
- en: '| --- | --- | --- |'
  id: totrans-split-30
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Supermaven | 15 | 250 |'
  id: totrans-split-31
  prefs: []
  type: TYPE_TB
  zh: '| Supermaven | 15 | 250 |'
- en: '| Copilot | 47 | 783 |'
  id: totrans-split-32
  prefs: []
  type: TYPE_TB
  zh: '| Copilot | 47 | 783 |'
- en: '| Codeium | 53 | 883 |'
  id: totrans-split-33
  prefs: []
  type: TYPE_TB
  zh: '| Codeium | 53 | 883 |'
- en: '| Tabnine | 50 | 833 |'
  id: totrans-split-34
  prefs: []
  type: TYPE_TB
  zh: '| Tabnine | 50 | 833 |'
- en: '| Cursor | 113 | 1,883 |'
  id: totrans-split-35
  prefs: []
  type: TYPE_TB
  zh: '| Cursor | 113 | 1,883 |'
- en: <https://cdn.supermaven.com/video/speed_comparison.mp4>
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: <https://cdn.supermaven.com/video/speed_comparison.mp4>
- en: Trained on edit sequences, not just files
  id: totrans-split-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 培训基于编辑序列，而不仅仅是文件
- en: 'Unlike most code assistants, Supermaven doesn''t see your code as a sequence
    of files. Instead, Supermaven sees the sequence of edits you''ve made to your
    codebase - similar to what you''d see if you ran `git diff`. This helps Supermaven
    quickly understand what you''re trying to accomplish, and it''s great for refactoring.
    Here are some examples:'
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数代码助手不同，Supermaven不将您的代码视为一系列文件。相反，Supermaven看到您对代码库进行的编辑序列 - 类似于运行`git diff`后看到的内容。这有助于Supermaven快速理解您试图完成的任务，并非常适合重构。以下是一些示例：
- en: <https://cdn.supermaven.com/video/edit_sequence.mp4>
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: <https://cdn.supermaven.com/video/edit_sequence.mp4>
- en: Try it now
  id: totrans-split-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 现在就试试吧
- en: '[Download Supermaven](/download) to try it for yourself. We''re excited to
    see what you think of it.'
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: '[下载 Supermaven](/download) 体验一下。我们很期待您的反馈。'
- en: If you don't use VS Code, [follow us on Twitter](https://twitter.com/SupermavenAI)
    to find out when Supermaven is ready for your preferred editor.
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不使用VS Code，请[关注我们的Twitter](https://twitter.com/SupermavenAI)，了解Supermaven何时适用于您喜欢的编辑器。
