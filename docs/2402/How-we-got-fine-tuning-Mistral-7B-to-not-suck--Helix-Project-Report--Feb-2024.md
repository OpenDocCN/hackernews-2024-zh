<!--yml

类别：未分类

日期：2024年05月27日14:43:03

-->

# 我们是如何精调Mistral-7B以避免失败的：螺旋计划报告，2024年2月

> 来源：[https://helixml.substack.com/p/how-we-got-fine-tuning-mistral-7b](https://helixml.substack.com/p/how-we-got-fine-tuning-mistral-7b)

大家好，

距[Helix v0.1发布](https://www.producthunt.com/products/helix-5)已经过去一个多月了，今天我很高兴地宣布[Helix v0.5](https://github.com/helixml/helix/releases)的可用性。[在您自己的安全私人基础设施上运行](https://docs.helix.ml/docs/controlplane)或者[在我们的SaaS上试用](https://app.tryhelix.ai)吧：

除了全新的闪亮UI（你可以在我们的[第一篇文章](https://helixml.substack.com/p/building-a-generative-ai-platform)中找到比较的截图），我们一直在极力提高文本精调的质量。

当我们首次推出Helix时，Mistral-7B-Instruct语言模型的文本精调是基于[这篇LlamaIndex文档页面](https://docs.llamaindex.ai/en/latest/examples/finetuning/knowledge/finetune_knowledge.html)。是的，我们基本上决定围绕这本LlamaIndex笔记开展整个业务。

不幸的是，当时我甚至没有看到来自LlamaIndex文档父页面的链接，上面写着“WIP：这还不太好”。哎呀。

当然，因为Helix的目标是完全在本地运行，所以我们在精调时使用[Mistral-7B与axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)，而不是使用GPT-3.5 API，但原理相同。思路是将文档分块，然后要求语言模型生成问答对（这是您需要提供给精调过程的训练数据的形式）。您使用LLM来自动化生成用于精调另一个LLM的训练数据。原始提示看起来像这样：

行得通吗？有点行，但有点糟糕。就像LlamaIndex说的那样。

我们能够为其提供[复杂的技术论文](https://docs.helix.ml/docs/papers)，它能够回答与它们有关的技术问题。但是在一些更基本的任务上失败了。

例如这篇新闻文章：[英格兰的初级医生因薪酬问题将再次举行罢工](https://www.theguardian.com/society/2023/dec/05/junior-doctors-in-england-to-stage-more-strikes)。这篇文章在我生活中成为了一段时间的噩梦 😂

为什么？因为当我们首次询问文本精调模型一个简单的问题时：

> 什么？！你是从那篇文章中获取的信息进行精调的。你为什么要谈论精调？！
> 
> –我

好吧，结果还是相当简单的。为了告诉用户“精调完成”，其中一个文本元素也被发送回模型，就好像用户真的说了这句话。现在，模型得到的唯一上下文就是精调的概念。我们解决了这个问题。很酷，让我们再试一次：

> 哦我的天啊，认真的吗？你一定知道医生们正在威胁要罢工。标题上不就写着吗！愚蠢的微调，也许永远不会奏效。🤬
> 
> –我

但我们坚持下来了。好吧，为什么模型不能回答关于文章基本背景的问题呢？嗯，这是因为提示生成的问答对不是关于文档标题的简单问题形式。解决方案是，不是单一的问答对生成提示，我们必须实现一个*套件*，从各种不同的角度提取文档的上下文：文档中的实体是什么，它们之间如何关联？文档的简短、中等和长篇摘要是什么？谁/什么/在哪里的问题等等。[在此处查看完整列表](https://github.com/helixml/helix/blob/main/api/pkg/dataprep/qapairs/qapair_config.yaml)。

结果表明，当我们精心构建了这一系列提示时，最终我们能够让模型回答关于“医生们将要做什么？”的基本问题。哎呀！😅

我们的另一个发现是，通过为每个文档生成一个内容寻址的哈希，我们还可以教会模型关于单个文档的ID，以及文档组的ID。

然后我们可以将这些ID映射回模型进行微调的文档。例如：[在这个会话中](https://app.tryhelix.ai/session/4d769c7c-b9a1-4fc4-b5c9-d277fc59ed1b)，模型能够告诉您它所学到的是在给定的文档中，并将用户链接回该文档。我还觉得这次交流挺搞笑的：

尽管也许这更多地反映了我的幽默感而已。

然后，我们添加了一个系统提示，告诉模型只参考它训练过的特定文档ID，而不参考背景知识。你知道吗，这行得通了！

到目前为止，我们根据“氛围”调整了这个LLM应用的提示和系统。也就是说，尝试一些东西，通过眼睛评估，然后进行修改。问题是，氛围无法扩展。

正在进行一个端到端的“评估”框架，以便我们可以自动建立一个好和坏会话的库，然后每次我们改变提示、代码、模型等，重新运行整个库中的所有会话的微调，然后进行评分。我们甚至可能会使用LLM来自动评分它们 :-)

请通过点击您会话底部的新的点赞和点踩按钮来帮助我们！我们将使用这些作为改进产品的输入。

哦，相信我，我们已经谈论过了。我们暂时坚持微调，因为：

+   微调可以记忆的信息远远超过你可以在单个提示中适合的信息。

+   通过不需要在提示中塞入任何自定义知识，您可以获得更好的延迟。

+   微调更擅长复制风格（我们计划为此准备问题对）。

+   微调更擅长理解大量背景知识（“领域”），并且在构建答案时能够利用所有这些知识。

+   经过微调的模型更容易在边缘运行，无需将向量存储的基础设施靠近模型

+   您可以使用比通用模型加RAG更小的微调模型。对于可以在任何CPU上运行的Phi-2微调模型，您可以做什么？

+   我们让它工作了！！

我们错了吗？[来Discord上吐槽我们吧](https://discord.gg/VJftd844GE)!

我们现在有一个兼容OpenAI的API。例如，在这里我正在配置Flowise与我的私有Helix部署集成，例如：

只需设置：

+   **模型名称：** mistralai/Mistral-7B-Instruct-v0.1

+   **连接凭证：** 您的API密钥来自[https://app.tryhelix.ai/account](https://app.tryhelix.ai/account)

+   **BasePath（附加参数下）：** https://app.tryhelix.ai/v1

就是这样！您会注意到，通过Helix进行的API调用会显示为您账户中的会话，这样您就可以免费记录它们 :-)

一旦提取了问答对，我们将自动微调模型，完成后会通过电子邮件通知您。我们希望这样做能鼓励更多人，在等待花费10-15分钟来训练自己的AI后，重新投入应用程序。

感谢阅读！很快我将在我们的路线图上写更多，关于我们在看到显著商业吸引力的本地使用案例，以及我们的秘密。订阅并保持关注 :-)
