<!--yml

分类：未分类

日期：2024-05-27 14:44:50

-->

# 七个理由，世界为何应对**Sam Altman**说不

> 来源：[https://garymarcus.substack.com/p/seven-reasons-why-the-world-should](https://garymarcus.substack.com/p/seven-reasons-why-the-world-should)

给我一个理由留在这里

我会立即回过头来

——Tracy Chapman

“七个理由，世界必须学会对Sam Altman要求的7T说不”，正如Bing所示

昨天X上最佳的梗图描绘了Idris Elba，咳嗽并几乎被弄得难以置信，眼神表示“你真是在开玩笑吧”。

在这里观看完整视频[here](https://x.com/danielmerja/status/1755969763132445037?s=61)。

我观看了[视频](https://x.com/danielmerja/status/1755969763132445037?s=61)（抱歉我只能嵌入一个静态图像），大约看了10次，但停不下来笑。在要求7万亿美元的时候，对大多数人来说Sam Altman已经[过于极端](https://en.wikipedia.org/wiki/Jumping_the_shark)。

§

以下是我们应当聚集在一起，告诉这位有抱负的年轻CEO，世界并不——也不应——围绕他转的七个理由：

+   **能源与气候**：$7万亿的AI基础设施满负荷运转将消耗（精确的技术术语）大量能源。让我们不要自欺欺人，认为这些能源全部是“可再生的”。某人在X上将GenAI目前的需求与整个德国的能源消耗进行了比较。我猜这实际上是一个非常保守的估计，特别是如果模型继续变得更大、训练成本更高的趋势继续下去的话。*现在*已经有压力要求GenAI继续[保留煤电厂](https://news.bloomberglaw.com/esg/ai-needs-so-much-power-that-old-coal-plants-are-sticking-around)。不用说——哦不，我猜我还是得说——使用这么多能源绝非轻易之举。到目前为止，GenAI大多数是承诺，而非交付。尚无论据表明这实际上值得破坏地球。

+   **自然资源**：延续上述观点，ML研究员Sasha Luccioni向VentureBeat的Sharon Goldman[透露](https://x.com/sharongoldman/status/1756039645677113618?s=61)：

    你确实应该阅读整个故事，但这里还有进一步的摘录：

    > 作为对比，在2023年9月，[财富杂志报道](https://fortune.com/2023/09/09/ai-chatgpt-usage-fuels-spike-in-microsoft-water-consumption/)称AI工具导致了微软水消耗的34%增长；Meta的Llama 2模型[据报道](https://www.businessinsider.com/meta-llama2-ai-uses-almost-twice-water-as-llama-2023-7)比Llama 1多消耗了一倍的水；而一项[2023年的研究发现](https://interestingengineering.com/innovation/training-chatgpt-consumes-water)OpenAI的GPT-3训练消耗了70万升水。

    对于GPT-4，OpenAI从未披露过这些数字；我几乎无法想象GPT-5的数据会是什么样子。

+   **经济资源**：7万亿美元几乎是美国一年在学校上花费的十倍，根据下面的图表，是终结全球饥饿成本的21倍。金钱并非无限，不可避免地存在[机会成本](https://en.wikipedia.org/wiki/Opportunity_cost)。我知道这里的幻想是生成式AI将使整个饼变得更大，据我所知，其运行成本如此之高，以至于OpenAI甚至还没有盈利。投资7万亿美元的十分之一，全都交给一个从未成功退出过自己公司的家伙，全靠承诺？谁在愚弄谁？

    刚才把它放在X上，“想象我们可以用7万亿美元说“是”接受所有边界理念！我们现在不能这样做的原因之一是所有这些资源都被投入到聊天机器人中去了。”

+   **金融风险**：一个耗资7万亿美元的项目必然会被视为[太大以至于不能倒闭](https://en.wikipedia.org/wiki/Too_big_to_fail)。任何救助行动都可能轻易地摧毁世界经济。即使AI并不像一些人担心的那样直接杀死我们大多数人，一个耗资7万亿美元的项目的崩溃可能会引发比[2007-2008年次贷危机](https://en.wikipedia.org/wiki/2007%E2%80%932008_financial_crisis)更严重、全球性的经济萧条。目前正在拖累中国的[破灭的房地产泡沫](https://www.businessinsider.com/chinas-economy-housing-market-imf-real-estate-investors-forecast-finance-2024-2?op=1)应被视为建设基础设施过快所可能带来的警示。但这可能会更糟糕。

+   **人类智力资本**。OpenAI认为，如果没有豁免版权的豁免权，他们实际上无法建造他们正在建造的东西，这将对艺术家、音乐家、作家和其他创作者造成严重打击。

+   **负面外部性**，OpenAI基本上没有吸收，如误导和虚假信息的成本、网络犯罪和最新的虚假书籍骗局，这种骗局最近至少已经伤害了我认识的三位作者。最新报告，这次来自著名音乐作家泰德·吉奥亚，昨天关于一本由“弗兰克”·吉奥亚写的假书：

现在大型语言模型已经让这种事情变得很容易；更糟糕的是，像 OpenAI 这样的公司似乎乐意让社会承担所有成本，就像一些粗心的工业厂一样，随意排放有毒化学物质。甚至战争也不是不可能的。正如 Sharon Goldman 昨天所指出的，“稀土矿物如镓和锗的短缺甚至加剧了与中国的[全球芯片战争](https://cepa.org/article/china-gallium-and-germanium-the-minerals-inflaming-the-global-chip-war/)”。如果资源争夺的战斗变得足够激烈，实际战争可能随之而来。而且，说实话，"对齐问题"远未解决。许多人工智能领域的领导者签署了一封信，表示这种技术可能会危及我们所有人的生命。我们为什么如此急于一时？

§

谈到不急于求成，作为CEO和风险投资家多年的 Phil Libin 给我发来了另一个极好的观点：

> 这样的投资现在还为时过早，因为我们还不知道实际上会需要什么样的专用芯片和专用生产线。这个领域发展得太快，真正的用例尚未被证明。我们应该先找到一些实际的东西，然后再进行扩展。幸好 Sony 没有说服世界将7万亿美元（相当于1977年的1.33万亿美元）投入到 Betamax 工厂。

让我们绝不放弃对人工智能的研究，但现在我们应该主要关注*safety*和创新的新方法，而不是急于扩展现有和问题极大的架构，以至于难以预料的后果。

正如 Libin 指出的那样，“一个7万亿美元的巨大失败项目可能会使合法的人工智能发展再次倒退十年。”

Libin 继续说道，“Worldcom … 在没有任何人需要之前，就把几十亿美元投入到光纤项目中，这引发了一场相当大的丑闻和经济震荡。这次事件……规模大了1000倍。”

如果你想走得快，好吧；如果你想疯狂地走得更快，你就有可能[搞砸了](https://en.wiktionary.org/wiki/screw_the_pooch)，甚至可能整个人工智能领域也会随之受到影响。即使所谓的[有效加速主义者](https://en.wikipedia.org/wiki/Effective_accelerationism)也应该怀疑 Sam 是否正确地打出了他的牌。

§

在技术领袖能够有力地证明这种技术已经足够成熟，能够显著产生巨大净利益之前，我们应该坚决反对鲁莽的人工智能扩张主义。

凭借模糊的推测冒着破坏社会和环境的真正风险是毫无道理的。

**Gary Marcus** 已经厌倦了硅谷的自恋现象。

考虑分享这篇文章，提高公众对利害关系的意识

[分享](https://garymarcus.substack.com/p/seven-reasons-why-the-world-should?utm_source=substack&utm_medium=email&utm_content=share&action=share)
