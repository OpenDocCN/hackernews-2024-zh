<!--yml

category: 未分类

date: 2024-05-27 14:43:43

-->

# 伦敦地铁正在测试实时AI监控工具以便发现犯罪 | WIRED

> 来源：[https://www.wired.com/story/london-underground-ai-surveillance-documents/](https://www.wired.com/story/london-underground-ai-surveillance-documents/)

对于WIRED的信息自由请求，TfL表示他们使用现有的闭路电视图像、AI算法和“多种检测模型”来检测行为模式。“通过向车站工作人员提供关于客户移动和行为的见解和通知，他们希望能够更快地应对任何情况”，回应中说道。他还表示，该试验提供了有助于他们“未来方法和干预”的逃票信息，并且收集的数据符合其[数据政策](https://tfl.gov.uk/corporate/privacy-and-cookies/privacy-and-data-protection-policy)。

在本文发布后发送的一份声明中，TfL的政策与社区安全负责人曼迪·麦克格雷格表示，试验结果仍在继续分析，并补充道：“从试验收集的数据中没有证据表明存在偏见。” 麦克格雷格表示，在试验期间，车站没有任何标志提及AI监控工具的测试。

“我们目前正在考虑试验第二阶段的设计和范围。目前没有其他关于扩展此技术使用范围的决定，无论是扩展到其他车站还是增加功能。” 麦克格雷格说。“除了在当地社区和其他相关利益相关者，包括领域专家进行全面磋商之外，任何技术的更广泛推广都将取决于咨询。”

计算机视觉系统（如测试中所用的系统）的工作原理是通过尝试在图像和视频中检测物体和人物。在伦敦的试验中，训练用于检测特定行为或动作的算法与地铁站20年历史的闭路电视摄像头拍摄的图像结合——每0.1秒分析一次图像。当系统检测到被定义为问题的11种行为或事件之一时，它会向车站工作人员的iPad或计算机发出警报。文件显示，TfL工作人员共收到19,000个潜在行动警报，并进一步保留了25,000个以供分析。

系统试图识别的类别包括：人群移动、未经授权进入、保护、移动协助、犯罪和反社会行为、铁路上的人物、受伤或不适的人员、垃圾或地板湿滑等危险、无人看管物品、滞留客户和逃票行为。每种类别都有多个子类别。

Daniel Leufer，数字权利组织Access Now的高级政策分析师，表示每当他看到任何进行此类监控的系统时，他首先要查看的是它是否试图识别攻击性或犯罪行为。“摄像头将通过识别身体语言和行为来实现这一点，”他说。“你会拥有怎样的数据集来训练这样的系统呢？”

TfL关于试验的报告称其“希望包括攻击行为”，但发现“无法成功检测”它们。报告补充说缺乏训练数据，其他不包括攻击行为的原因被涂黑。相反，当有人举起双臂时，系统会发出警报，文件中描述这种行为为“与攻击行为相关的常见行为”。

“训练数据总是不足的，因为这些事情可以说过于复杂和微妙，难以在必要的数据集中正确捕捉到其中的细微差别，”Leufer说道，并指出TfL承认其缺乏足够的训练数据是积极的。“我对机器学习系统能够可靠地检测攻击行为的能力非常怀疑，因为这种方式很可能只是在复制现有的社会偏见，即公共空间中哪种行为是可以接受的。”根据WIRED收到的文件，共有66次攻击性行为的警报，包括测试数据。
