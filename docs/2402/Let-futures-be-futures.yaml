- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 14:33:32'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 14:33:32'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Let futures be futures
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 让 futures 成为 futures
- en: 来源：[https://without.boats/blog/let-futures-be-futures/](https://without.boats/blog/let-futures-be-futures/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://without.boats/blog/let-futures-be-futures/](https://without.boats/blog/let-futures-be-futures/)
- en: In the early-to-mid 2010s, there was a renaissance in languages exploring new
    ways of doing concurrency. In the midst of this renaissance, one abstraction for
    achieving concurrent operations that was developed was the “future” or “promise”
    abstraction, which represented a unit of work that will maybe eventually complete,
    allowing the programmer to use this to manipulate control flow in their program.
    Building on this, syntactic sugar called “async/await” was introduced to take
    futures and shape them into the ordinary, linear control flow that is most common.
    This approach has been adopted in many mainstream languages, a series of developments
    that has been controversial among practitioners.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在2010年代初至中期，有一场语言复兴探索新的并发处理方式。在这场复兴的中心，开发出了一种用于实现并发操作的抽象化，称为“future”或“promise”抽象化，它代表了一个将来可能完成的工作单元，允许程序员使用它来操纵程序中的控制流。基于此，引入了称为“async/await”的语法糖，将
    futures 转换为最常见的普通线性控制流。这种方法已经在许多主流语言中得到采用，这一系列发展在从业者中引起了争议。
- en: 'There are two excellent posts from that period which do a very good job of
    making the case for the two sides of the argument. I couldn’t more strongly recommend
    reading each these posts in full:'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在那段时间有两篇优秀的帖子，非常好地说明了争论的双方。我强烈推荐每篇帖子都全文阅读：
- en: 'The thesis of Eriksen’s post is that futures provide a fundamentally different
    model of concurrency from threads. Threads provide a model in which all operations
    occur “synchronously,” because the execution of the program is modeled as a stack
    of function calls, which block when they need to wait for concurrently executing
    operations to complete. In contrast, by representing concurrent operations as
    asynchronously completing “futures,” the futures model enabled several advantages
    cited by Eriksen. These are the ones I find particularly compelling:'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: Eriksen 的帖子的论点是，futures 提供了一种与线程 fundamentally 不同的并发模型。线程提供了一个模型，其中所有操作都是“同步”进行的，因为程序的执行被建模为一堆函数调用，当它们需要等待并发执行的操作完成时会阻塞。相反地，通过将并发操作表示为异步完成的“futures”，futures
    模型使得 Eriksen 引用的几个优势成为可能。以下是我认为特别有说服力的几点：
- en: A function performing asynchronous operations has a different type from a “pure”
    function, because it must return a future instead of just a value. This distinction
    is useful because it lets you know if a function is performing IO or just pure
    computation, with far-reaching implications.
  id: totrans-split-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行异步操作的函数与“纯”函数的类型不同，因为它必须返回一个 future 而不仅仅是一个值。这种区别很有用，因为它可以让您知道函数是执行 IO 还是纯计算，对程序有深远的影响。
- en: Because they create a direct representation of the unit of work to be performed,
    futures can be composed in multiple ways, both sequentially and concurrently.
    Blocking function calls can only be composed sequentially without starting a new
    thread.
  id: totrans-split-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为它们创建了要执行的工作单元的直接表示，所以 futures 可以以多种方式进行组合，包括顺序和并发。阻塞函数调用只能按顺序组合，而不能启动新线程。
- en: Because futures can be composed concurrently, concurrent code can be written
    which more directly expresses the logic of what is occurring. Abstractions can
    be written which represent particular patterns of concurrency, allowing business
    logic to be lifted from the machinery of scheduling work across threads. Eriksen
    gives examples like a `flatMap` operator to chain many concurrent network requests
    after one initial network request.
  id: totrans-split-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为 futures 可以并发组合，所以可以编写更直接表达发生逻辑的并发代码。可以编写抽象化的内容，代表并发模式，允许将业务逻辑从跨线程调度工作的机制中提取出来。Eriksen
    提供了一些示例，比如一个 `flatMap` 操作符，在初始网络请求之后链接多个并发网络请求。
- en: Nystrom takes the counter-position. He starts by imagining a language in which
    all functions are “colored,” either `BLUE` or `RED` . In his imaginary language,
    the important difference between the two colors of function is that `RED` functions
    can only be called from other `RED` functions. He posits this distinction as a
    great frustration for users of the language, because having to track two different
    kinds of functions is annoying and in his language `RED` functions must be called
    using an annoyingly baroque syntax. Of course, what he’s referring to is the difference
    between synchronous functions and asynchronous functions. Exactly what Eriksen
    cites as an advantage of futures - that functions returning futures are different
    from functions that don’t return futures - is for Nystrom it’s greatest weakness.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: Nystrom 持相反的观点。他首先设想了一种所有函数都“着色”的语言，颜色为蓝色（BLUE）或红色（RED）。在他的想象语言中，两种颜色的函数之间的重要区别是红色（RED）函数只能从其他红色（RED）函数中调用。他假设这种区分为语言用户带来巨大的困惑，因为需要跟踪两种类型的不同函数很烦人。在他语言中，红色（RED）函数必须使用令人痛苦的繁复语法来调用。当然，他指的是一些在线性函数与异步函数之间的区别。Eriksen
    引用为 futures 优势之一的“函数返回 futures 与零返回 futures”的差异，对 Nystrom 来说却是最薄弱的环节。
- en: 'Some of the remarks Nystrom makes are not relevant to async Rust. For example,
    he says that if you call a function of one color as if it were a function of the
    other, dreadful things could happen:'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一些 Nystrom 的评论与异步 Rust 不相关。例如，他说如果您将颜色为一的函数误认为是另一种颜色的函数调用，则可能会发生可怕的事情：
- en: When calling a function, you need to use the call that corresponds to its color.
    If you get it wrong &mldr; it does something bad. Dredge up some long-forgotten
    nightmare from your childhood like a clown with snakes for arms hiding under your
    bed. That jumps out of your monitor and sucks out your vitreous humour.
  id: totrans-split-14
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 调用函数时，需要使用与函数颜色对应的调用。如果出错&hellip;会发生糟糕的事情。将您童年的噩梦捞起，就像躲在床下的小丑，手中有蛇。它会跳出您的监视器，榨干您的玻璃体。
- en: This is plausibly true of JavaScript, an untyped language with [famously ridiculous](https://www.destroyallsoftware.com/talks/wat)
    semantics, but in a statically typed language like Rust, you’ll get a compiler
    error which you can fix and move on.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这在类型未指派语言（如 JavaScript）中可能是真实的，该语言具有[臭名昭著的荒谬](https://www.destroyallsoftware.com/talks/wat)语义，但在类型静态语言（如
    Rust）中，您会获得编译器错误，您可以解决并继续前进。
- en: 'One of his main points is also that calling a `RED` function is much more “painful”
    than calling a `BLUE` function. As Nystrom later elaborates in his post, he is
    referring to the callback-based API commonly used in JavaScript in 2015, and he
    says that async/await syntax resolves this problem:'
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 他主要的观点之一是调用红色（RED）函数远比调用蓝色（BLUE）函数更加“痛苦”。正如 Nystrom 在后续的帖子中进一步阐述的那样，他指的是 2015
    年 JavaScript 中常用的回调式 API，并说异步 - 等待语法解决了这个问题：
- en: '[Async/await] lets you make asynchronous calls just as easily as you can synchronous
    ones, with the tiny addition of a cute little keyword. You can nest `await` calls
    in expressions, use them in exception handling code, stuff them inside control
    flow.'
  id: totrans-split-17
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[异步 - 等待] 让您以与同步调用相同的方式轻松执行异步调用，只需添加一个可爱的关键词。您可以将 await 调用嵌入到表达式中，将其用于异常处理代码中，将它们放在控制流中。'
- en: 'Of course, he also says this, which is the crux of the argument about the “function
    coloring problem”:'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，他也会这么说，这是围绕“函数着色问题”争论的中心：
- en: '*But…* you still have divided the world in two. Those async functions are easier
    to write, but *they’re still async functions.*'
  id: totrans-split-19
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*但&hellip;* 你仍然将世界分为两部分。这些异步函数更容易编写，但 *它们依然是异步函数*。'
- en: 'You’ve still got two colors. Async-await solves annoying rule #4: they make
    red functions not much worse to call than blue ones. But all of the other rules
    are still there.'
  id: totrans-split-20
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 您仍然有两种颜色。异步 - 等待解决了恼人的规则#4：它们使红色函数的调用与蓝色函数的调用几乎一样糟糕。但所有的其他规则仍然存在。
- en: Futures represent asynchronous operations differently from synchronous operations.
    For Eriksen, this provides additional affordances which are the key advantage
    of futures. For Nystrom, this is just an another hurdle to calling functions which
    return futures instead of blocking.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 未来代表异步操作与同步操作有所不同。对于 Eriksen 来说，这提供了额外的优势，是 futures 的关键优点。对于 Nystrom 来说，这纯粹是调用返回
    futures 的函数而不是阻塞的函数的额外障碍。
- en: As you might expect if you’re familiar with this blog, I fall pretty firmly
    on the side of Eriksen. So it has not been easy on me to find that Nystrom’s views
    have been much more popular with the sort of people who comment on Hacker News
    or write angry, over-confident rants on the internet. A few months ago I wrote
    a [post](/blog/why-async-rust) exploring the history of how Rust came to have
    the futures abstraction and async/await syntax on top of that, as well as a follow-up
    [post](/blog/a-four-year-plan) describing the features I would like to see added
    to async Rust to make it easier to use.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能期待的那样，如果你熟悉这个博客，我对Eriksen的立场非常坚定。所以对我来说并不容易发现，Nystrom的观点在像评论Hacker News的人群或在互联网上写愤怒、过于自信的
    rant 文章的人中更受欢迎。几个月前，我写了一篇[文章](/blog/why-async-rust)，探讨了Rust如何在 futures 抽象和 async/await
    语法的基础上发展的历史，以及后续的[文章](/blog/a-four-year-plan)描述了我希望在 async Rust 中添加的功能。
- en: Now I would like to take a step back and re-examine the design of async Rust
    in the context of this question about the utility of the futures model of concurrency.
    What has the use of futures actually gotten us in async Rust? I would like us
    to imagine that there could be a world in which the difficulties of using futures
    have been mitigated or resolved & the additional affordances they provide make
    async Rust not only just as easy to use as non-async Rust, but actually a *better*
    experience overall.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我想退一步，重新审视 async Rust 的设计，考虑 futures 并发模型的实用性问题。在 async Rust 中，futures 的使用实际上给我们带来了什么？我希望我们可以想象一个世界，在这个世界中，使用
    futures 的困难已经得到缓解或解决，而它们提供的额外功能不仅使 async Rust 的使用变得像非 async Rust 一样简单，而且实际上提供了一个*更好的*体验。
- en: Async tasks aren’t ersatz threads
  id: totrans-split-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 异步任务并不是伪线程。
- en: 'Usually the benefit of futures is explained to users in terms of a performance
    improvement: starting threads is expensive and so is switching between them, so
    being able to multiplex many concurrent operations on a single thread will allow
    you to perform more concurrent operations on a machine. Like Eriksen, I think
    this focus on the dichotomy of performance between “thread-based IO” and “event-based
    IO” is a red herring. All of Eriksen’s points about the benefits of futures for
    structuring your code hold true for Rust as well.'
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: 通常将 futures 的好处解释给用户时，会涉及到性能改进：启动线程是昂贵的，而在它们之间切换也是昂贵的，因此能够在单个线程上多路复用许多并发操作，将允许您在机器上执行更多并发操作。与Eriksen一样，我认为这种关注“基于线程
    IO”和“基于事件 IO”的性能二分法是一个红色假设。所有关于使用 futures 来结构化代码的好处，对于 Rust 也同样适用。
- en: 'Eriksen was writing in the context of languages which use continuation-passing
    style as the underlying basis for their future abstraction. As I wrote in my post
    on the history of async Rust, this is not the approach that Rust took. Uniquely,
    Rust adopted a system based on inversion of the continuation based approach: instead
    of futures calling a continuation when they finish, they are externally polled
    to completion. To understand the relevance of this point, we will need to take
    a step back and talk about “tasks.”'
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: Eriksen在编写时考虑了使用 continuation-passing style 作为其未来抽象的基础的语言背景。正如我在关于 async Rust
    历史的文章中所写的那样，这并不是 Rust 采取的方法。独特地，Rust 采用了一种基于反转续传基于方法的系统：而不是在完成时 future 调用一个继续函数，它们是通过外部轮询来完成的。为了理解这一点的相关性，我们需要退后一步来谈论“任务”。
- en: When I write task I don’t just mean “a unit of work.” In async Rust, “task”
    is a specific term of art. The fundamental abstraction for async work is a future,
    a type that implements the [Future](https://doc.rust-lang.org/std/future/trait.Future.html)
    trait, which is most often implemented with an async function or an async block.
    But in order to execute any asynchronous code, we also need to use an “executor”
    which can execute “tasks.” Usually, this is provided for us by a “runtime,” which
    also provides other things like types for doing asynchronous IO. The most widely
    used runtime is [tokio](https://tokio.rs).
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 当我提到任务时，并不仅仅是指“一个工作单元”。在 async Rust 中，“任务”是一个特定的艺术术语。异步工作的基本抽象是 future，这是一种实现[Future](https://doc.rust-lang.org/std/future/trait.Future.html)
    trait 的类型，通常通过 async 函数或 async 块实现。但是，为了执行任何异步代码，我们还需要使用“执行器”，它可以执行“任务”。通常情况下，这由“运行时”为我们提供，还提供了用于执行异步
    IO 等其他类型的工具。最广泛使用的运行时是[tokio](https://tokio.rs)。
- en: 'These definitions are a bit winding. A “task” is just any future that has been
    scheduled on an executor. Most executors, like tokio’s, can run multiple tasks
    concurrently. They might use one thread to do it, or they use more than one and
    balance the tasks between those threads (which to prefer has been the subject
    of [some additional controversy](/blog/thread-per-core)). Executors that can run
    multiple tasks at once usually expose an API with a name like `spawn`, which “spawns
    a task.” Other executors exist which only run a single task at a time (like [pollster](https://crates.io/crates/pollster)):
    these usually expose an API with a name like `block_on`.'
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这些定义有点复杂。一个“任务”只是已在执行器上调度的任何 future。大多数执行器，如 tokio，可以同时运行多个任务。它们可能使用一个线程来完成，或者使用多个线程并在这些线程之间平衡任务（哪种方式更好一直是一些额外争议的主题）。能够同时运行多个任务的执行器通常会公开类似
    `spawn` 的 API，用于“生成任务”。还存在其他执行器，一次只运行一个任务（如 [pollster](https://crates.io/crates/pollster)）：这些通常会公开类似
    `block_on` 的 API。
- en: 'All tasks are futures, but not all futures are tasks. Futures *become* tasks
    when they are passed to an executor to execute. Most often, a task will be composed
    of many smaller futures combined together: when you `await` a future inside of
    an async scope, the state of the awaited future is combined directly into the
    future that the async scope evaluates to. Normally, you’ll do this many more times
    than you’ll use spawn, so most of your futures will not be tasks in the sense
    that I mean. But there’s no type-level distinction between a future and a task:
    any future can be made into a task by running it on an executor.'
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 所有任务都是 futures，但并非所有 futures 都是任务。当将 futures 传递给执行器以执行时，futures 就变成了任务。大多数情况下，一个任务将由许多较小的
    futures 组合在一起：当在异步范围内等待一个 future 时，被等待的 future 的状态直接合并到异步范围评估的 future 中。通常情况下，你会做这样的操作比使用
    spawn 要多得多，因此大多数 futures 并不是我所说的任务。但是在类型级别上，future 和任务之间没有区别：任何 future 都可以通过在执行器上运行来转变为任务。
- en: The important thing about this distinction between futures and tasks is that
    all of the state needed to execute a task will be allocated as a single object,
    laid out together in memory; each individual future used within a task will not
    require a separate allocation. We’ve often described this state machine as the
    “perfectly sized stack” of the task; it is exactly large enough to contain all
    of the state this task could ever need when it yields.
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在理解 futures 和 tasks 之间的区别时，重要的一点是：执行任务所需的所有状态将作为一个单独的对象分配，并且在内存中紧密排列在一起；任务中使用的每个单独的
    future 不需要单独的分配。我们经常将这个状态机描述为任务的“完美大小的堆栈”；它恰好足够大，可以包含任务在 yield 时可能需要的所有状态。
- en: (One other implication of this design is that it’s not possible to write a recursive
    async function without explicitly boxing the recursive call. This is for the same
    reason it’s not possible to write a recursive struct definition without boxing
    the recursively embedded type.)
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: （此设计的另一个影响是，不可能编写递归的异步函数而不显式地对递归调用进行封箱。这与不可能编写递归结构定义而不封箱递归嵌入类型的原因相同。）
- en: 'This all has some interesting implications for representing concurrent operations
    in async Rust. I want to introduce a distinction between two kinds of concurrency
    that can be achieved with the task model: *multi-task concurrency*, in which concurrent
    operations are represented as separate tasks, and *intra-task concurrency*, in
    which a single task performs multiple operations concurrently.'
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于在异步 Rust 中表示并发操作有一些有趣的影响。我想引入一种区分任务模型中可以实现的两种并发类型的方法：*多任务并发*，其中并发操作被表示为单独的任务；以及*任务内并发*，其中一个单一任务同时执行多个操作。
- en: Multi-task concurrency
  id: totrans-split-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多任务并发
- en: If you want two operations to occur concurrently, one way to implement this
    is to spawn a separate task for each operation. This is “multi-task concurrency,”
    concurrency achieved by using multiple concurrent tasks.
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果希望两个操作同时进行，一种实现方法是为每个操作生成一个单独的任务。这就是“多任务并发”，通过使用多个并发任务实现的并发。
- en: For many users, multi-task concurrency is the most accessible approach to concurrency
    in async Rust, because it is the most similar to thread-based concurrency approaches.
    Just like how you can spawn threads for concurrency in non-async Rust, in async
    Rust you can spawn tasks. This makes it very familiar to users who are already
    used to concurrency with threads.
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对许多用户来说，多任务并发是异步Rust中最易于接触的并发方式，因为它与基于线程的并发方式最为相似。就像在非异步Rust中可以为并发生成线程一样，在异步Rust中可以生成任务。这使得对于已经习惯于使用线程进行并发的用户来说非常熟悉。
- en: 'Once you have multiple asynchronous tasks, you probably need some way to transfer
    information between them. This sort of “inter-task communication” is achieved
    by using some sort of synchronization primitive, such as a lock or a channel.
    For async tasks, there is an asynchronous equivalent of every sort of blocking
    synchronization primitive available: an async `Mutex`, an async `RwLock`, an async
    `mpsc` channel, and so on. Many runtimes even provide async synchronization primitives
    without an analog in the standard library. When an analog does exist though, there
    is usually a very strong similarly between the interface of the two primitives:
    in terms of affordance, an async `Mutex` is really just like a blocking `Mutex`,
    except that the lock method is async, instead of blocking. This was the conceptual
    basis for the [async-std](https://async.rs) runtime.'
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了多个异步任务，可能需要一些方法在它们之间传输信息。这种“任务间通信”通过使用某种同步原语（例如锁或通道）来实现。对于异步任务，每种阻塞同步原语都有对应的异步版本可用：异步`Mutex`、异步`RwLock`、异步`mpsc`通道等等。许多运行时甚至提供了标准库中没有的异步同步原语。尽管存在类似物，但两种原语的接口通常非常相似：就功能而言，异步`Mutex`与阻塞`Mutex`非常相似，只是其锁方法是异步的，而不是阻塞的。这是[async-std](https://async.rs)运行时的概念基础。
- en: 'It’s worth noting, however, that the implementations of each of these things
    are completely different. The code that runs when you spawn an async task is nothing
    like spawning a thread, and the definition and implementation (for example) of
    an async lock is very different from a blocking lock: usually they will use an
    atomics-based lock under the hood with the addition of a queue of tasks that are
    waiting for the lock. Instead of blocking the thread, they put this task into
    that queue and yield; when the lock is freed, they wake the first task in the
    queue to allow it to take the lock again.'
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，值得注意的是，这些东西的实现完全不同。当你生成一个异步任务时运行的代码与生成线程时完全不同，例如异步锁的定义和实现非常不同于阻塞锁：通常它们会在底层使用基于原子操作的锁，并且还会有一个任务队列，等待该锁的任务。它们不会阻塞线程，而是将任务放入队列并让出执行；当锁被释放时，它们唤醒队列中的第一个任务，以允许其再次获取锁。
- en: For *users* of these APIs, multi-task concurrency is very similar to multi-threaded
    concurrency. However, it is not the only kind of concurrency enabled by the futures
    abstraction.
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些API的*用户*来说，多任务并发与多线程并发非常相似。然而，这并不是futures抽象能够实现的唯一并发形式。
- en: Intra-task concurrency
  id: totrans-split-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 内任务并发
- en: 'While multi-task concurrency has the same API surface as multi-threaded concurrency
    (modulo the scattering of async & await keywords), the futures abstraction also
    enables another kind of concurrency that has no analog in the context of threads:
    “intra-task concurrency.” This means that the same task is concurrently performing
    multiple asynchronous operations. Rather than having to allocate separate tasks
    for each of your concurrent operations, you can perform those operations using
    the same task object, improving memory locality, saving allocation overhead &
    increasing the opportunity for optimization.'
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然多任务并发与多线程并发有相同的API表面（除了散布的async & await关键字），但是futures抽象还可以实现一种在线程上下文中没有类似物的并发：“内任务并发”。这意味着同一任务可以同时执行多个异步操作。与为每个并发操作分配单独任务不同，你可以使用同一任务对象执行这些操作，提高内存局部性，节省分配开销，并增加优化机会。
- en: 'To be concrete about this, what I mean is that when you use an intra-task concurrency
    primitive (like `select!` for example), the state of two futures being operated
    on will be embedded directly in the parent future which is operating on them.
    The set of widely known intra-task concurrency primitives corresponds to the table
    of async primitives I’ve discussed in previous posts: they are select and join
    for `Future` and merge and zip for `AsyncIterator`:'
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我指的是当您使用任务内并发原语（例如 `select!`）时，正在操作的两个 Futures 的状态将直接嵌入操作它们的父 Future 中。广为人知的任务内并发原语集合对应于我之前讨论过的异步原语表：它们是
    `Future` 的 `select` 和 `join`，以及 `AsyncIterator` 的 `merge` 和 `zip`。
- en: '[PRE0]'
  id: totrans-split-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: With threads, you can provide APIs like this, but only by spawning new threads
    and using channels or join handles to communicate their result back to the parent
    thread. This introduces a lot of overhead, whereas the intra-task implementation
    of these primitives is as cheap as possible in Rust.
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: 使用线程，您可以提供这样的 API，但只能通过生成新线程并使用通道或 join 句柄将其结果返回给父线程来实现。这引入了大量的开销，而这些原语的任务内实现在
    Rust 中尽可能廉价。
- en: In fact, eliminating the overhead of these combinators was the entire reason
    that Rust moved from a continuation-passing style to a readiness-based approach
    for the Future abstraction. When Aaron Turon [wrote](http://aturon.github.io/tech/2016/09/07/futures-design/)
    about futures that would need a heap allocation in a continuation-passing style,
    it is not a coincidence that his example was `join`. It is exactly those futures
    which embed concurrent operations which would need shared ownership of the continuation
    (to call the continuation whenever any of the concurrent operations completes
    as necessary). So it is exactly these combinators for intra-task concurrency that
    readiness-based futures were designed to optimize.
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，消除这些组合器的开销正是 Rust 从传递续风格转向基于 readiness 的 Future 抽象的主要原因。当 Aaron Turon 在
    [写到](http://aturon.github.io/tech/2016/09/07/futures-design/) 需要在传递续风格中进行堆分配的
    Future 时，他举的例子是 `join`，这并非巧合。正是那些嵌入并发操作的 Future 需要共享续体的所有权（在任何并发操作完成时调用续体）。因此，正是这些用于任务内并发的组合器，是为了优化基于
    readiness 的 Futures 而设计的。
- en: As Rain has compellingly [argued](https://sunshowers.io/posts/nextest-and-tokio/#what-are-heterogenous-selects)
    in the past, “heterogeneous select is the point of async Rust.” Specifically,
    the fact that you can select a variety of futures of different types and await
    whichever of them finishes first & from within a single task, without additional
    allocations, is a unique property of async Rust compared to non-async Rust & one
    of it’s most powerful features.
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: 正如 Rain 在过去所 [争辩的](https://sunshowers.io/posts/nextest-and-tokio/#what-are-heterogenous-selects)，"异构选择是异步
    Rust 的要点。" 具体来说，您可以选择多种不同类型的 Futures，并等待它们中的任何一个首先完成，并且从单个任务中进行，而无需额外的分配，这是异步
    Rust 相对于非异步 Rust 的独特属性之一，也是其最强大的特性之一。
- en: A common architecture for an async Rust server is to spawn a task for each socket.
    These tasks often internally multiplex inbound and outbound reads and writes over
    that socket along with messages from other tasks intended for the service on the
    other end of the socket. To do so, they might select between some futures or merge
    streams of events together, depending on the exact details of their life cycle.
    This can have a very high-level appearance, and in many ways it resembles the
    actor model for asynchronous concurrency, but thanks to intra-task concurrency
    it will compile into a single state machine per socket, which is a runtime representation
    very similar to hand-written asynchronous servers in a language like C.
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: 异步 Rust 服务器的常见架构是为每个套接字生成一个任务。这些任务通常在套接字上内部复用入站和出站读写以及其他任务发送到套接字另一端服务的消息。为此，它们可能会在准确细节的生命周期中选择某些
    Futures 或将事件流合并在一起。这可以具有非常高层次的外观，在许多方面它类似于异步并发的 actor 模型，但由于任务内并发，它将编译成每个套接字的单个状态机，这种运行时表示与类似于
    C 语言中手写异步服务器非常相似。
- en: 'This architecture (and others like it) combines multi-task concurrency for
    the situation in which it is most appropriate & intra-task concurrency for the
    situation in which it is the better approach. Recognizing the difference between
    these scenarios is a key skill for mastering async Rust. There are a few limitations
    to intra-task concurrency: if your algorithm can abide these limitations, it is
    probably a good fit.'
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构（以及类似的其他架构）结合了多任务并发，适合最适当的情况和任务内并发，适合更好的情况。认识到这些场景之间的差异是掌握异步 Rust 的关键技能。任务内并发存在一些限制：如果你的算法可以遵守这些限制，那它可能非常合适。
- en: 'The first limitation is that it is only possible to achieve a static arity
    of concurrency with intra-task concurrency. That is, you cannot join (or select,
    etc) an arbitrary number of futures with intra-task concurrency: the number must
    be fixed at compile time. This is because the compiler needs to be able to lay
    out the state of each concurrent future in the state of the parent future, and
    each future needs to have a statically determined maximum size. This is really
    exactly the same as how you can’t have a dynamically sized collection of objects
    on the stack, but need to use something like a heap allocated `Vec` to have a
    dynamic number of objects.'
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个限制是，只能通过任务内并发实现静态并发度。也就是说，你不能在编译时加入（或选择等）任意数量的 future，数量必须在编译时确定。这是因为编译器需要能够在父
    future 的状态中布局每个并发 future 的状态，并且每个 future 都需要具有静态确定的最大大小。这实际上与在堆栈上不能有动态大小的对象集合相同，但需要使用像堆分配的`Vec`这样的东西来拥有动态数量的对象。
- en: 'The second limitation is that these concurrent operations do not execute independently
    of one another or of their parent that is awaiting them. By this I mean two things.
    First, intra-task concurrency achieves no parallelism: there is ultimately a single
    task, with a single poll method, and multiple threads cannot poll that task concurrently.   (All
    the widely used async runtimes are also a poor fit for compute-bound work; I don’t
    think this is essential to the async model, but it is a fact about the libraries
    currently available for using async.) Secondly, if the user cancels interest in
    this task, all child operations are necessarily canceled, because they were all
    part of the same task. So if you want these operations to continue even if this
    work gets canceled, they must be separately spawned tasks.'
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个限制是，这些并发操作不会独立执行，也不会独立于等待它们的父任务执行。我的意思是两件事情。首先，任务内并发不会实现并行：最终只有一个任务，有一个单一的轮询方法，多个线程不能同时轮询该任务。
    （所有广泛使用的异步运行时对计算密集型工作也不太适合；我认为这并不是异步模型的核心，但这是目前可用于使用异步的库的事实。）其次，如果用户取消对此任务的兴趣，所有子操作必然取消，因为它们都是同一个任务的一部分。因此，如果希望这些操作即使在工作被取消时也继续，它们必须成为单独的分开任务。
- en: The function non-coloring problem
  id: totrans-split-50
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 函数非着色问题
- en: I want to diverge for a moment to return to Nystrom’s post, and introduce a
    completely different thread to this discussion. I promise these threads will be
    re-joined in the future & I even hope that they will cohere.
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我想偏离一会儿，回到 Nystrom 的帖子，引入一个完全不同的线程到这个讨论中。我保证这些线程将来会重新连接，并且我甚至希望它们会连贯起来。
- en: I propose that we continue the thought experiment of the language with colored
    functions & imagine that the designer of the language has read Nystrom’s critique
    and tried to mitigate the pain of `RED` and `BLUE` functions. In the classic tendency
    of language designers who don’t know when to stop, they’ve added a third color
    of functions called `GREEN` functions, which they hope will end everyone’s complaints.
    Of course, these come with their own set of rules.
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议我们继续以带有彩色功能的语言的思维实验，并想象语言的设计者已经阅读了 Nystrom 的批评，并试图缓解`RED`和`BLUE`函数的问题。在不知道何时停止的语言设计师的经典倾向下，他们添加了第三种颜色的函数，称为`GREEN`函数，他们希望这将终结所有人的抱怨。当然，这些也带来了他们自己的一套规则。
- en: 1\. `GREEN` functions can be called like `BLUE` functions.
  id: totrans-split-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 1\. `GREEN`函数可以像`BLUE`函数一样被调用。
- en: 'Unlike `RED` functions, there’s no special syntax for `GREEN` functions: you
    can call them anywhere using exactly the same syntax as `BLUE` functions. In fact,
    from looking at their signature and how they’re used, there’s no way to tell that
    there’s any difference at all. There will just be a note in the documentation
    that the function is `GREEN` , or maybe not if the author didn’t think to include
    this information.'
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: 与`RED`函数不同，`GREEN`函数没有特殊的语法：您可以使用与`BLUE`函数完全相同的语法在任何地方调用它们。实际上，从它们的签名和使用方式来看，根本无法分辨出任何区别。文档中可能会有关于该函数是`GREEN`的说明，或者如果作者没有考虑到这些信息，也可能没有。
- en: This is great! No longer do you have to worry about what color a function is,
    as long as you stick to `BLUE` and `GREEN` functions, it’s all the same to you.
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了！只要坚持使用`BLUE`和`GREEN`函数，您就不必再担心函数的颜色。
- en: 2\. There is a `GREEN` equivalent for every primitive `RED` function.
  id: totrans-split-56
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2\. 每个原始`RED`函数都有对应的`GREEN`等效函数。
- en: Of course, to actually achieve that, you’ll need to be able to implement your
    program without calling `RED` functions. So the language authors have added to
    their standard library a `GREEN` function for each operation that otherwise would
    only have been available with a `RED` function.
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，要实现这一点，您需要能够在不调用`RED`函数的情况下编写程序。因此，语言作者在其标准库中为每个操作添加了一个`GREEN`函数，否则只能通过`RED`函数获得。
- en: The implementations differ in some way having something to do with performance,
    which may or may not be material to your use case, but we’ve decided to ignore
    things like the actual semantics of our code in this thought experience so at
    least for now we won’t dwell on this.
  id: totrans-split-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些与性能有关的方面，这些实现有所不同，这可能与您的用例有关系，但我们决定在这个思想实验中忽略代码的实际语义之类的东西，至少现在我们不会深入探讨这些。
- en: 3\. There is a `GREEN` function that wraps any `RED` function and calls it.
  id: totrans-split-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3\. 存在一个`GREEN`函数，用于包装任何`RED`函数并调用它。
- en: 'Despite the existence of `GREEN` functions in the standard library, users could
    still encounter libraries that are written using `RED` functions. So the language
    designers cleverly came up with a a workaround for this: there is a higher-order
    `GREEN` function that takes a `RED` function as an argument. It basically just
    calls the `RED` function, technical details notwithstanding. Because `GREEN` functions
    can be called from anywhere, it resolves the problem of not being able to call
    `RED` functions from inside `BLUE` ones.'
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管标准库中存在`GREEN`函数，用户仍然可能遇到使用`RED`函数编写的库。因此，语言设计者巧妙地想出了一个解决方法：有一种高阶`GREEN`函数，它以`RED`函数作为参数。它基本上只是调用`RED`函数，尽管有技术细节不容忽视。因为`GREEN`函数可以从任何地方调用，这解决了无法从`BLUE`函数内部调用`RED`函数的问题。
- en: 4\. Calling a `GREEN` function from inside a `RED` function is very bad.
  id: totrans-split-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4\. 在`RED`函数内部调用`GREEN`函数非常糟糕。
- en: Of course, there always has to be a downside. You should never call a `GREEN`
    function from inside a `RED` function. It’s not “nasal demons” undefined behavior
    bad, or even “clowns with snakes for arms” JavaScript bad, but it will certainly
    slow down your program and in the worst cause it could even cause a deadlock.
    Users absolutely should not do this. Programmers who are happy using `RED` functions
    must avoid `GREEN` functions at all cost.
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，总会有一些不利因素。绝对不应该从`RED`函数内部调用`GREEN`函数。这并不是“鼻子魔鬼”未定义行为糟糕，甚至不是“手臂上有蛇的小丑”JavaScript糟糕，但它肯定会减慢程序运行速度，最糟糕的情况下甚至可能导致死锁。用户绝对不应该这样做。喜欢使用`RED`函数的程序员必须不惜一切避免`GREEN`函数。
- en: 'But here’s the problem with how this language added these functions: because
    they’re identical to `BLUE` functions, there’s no way to tell when you call them!
    You just have to know from the documentation what all of the `GREEN` functions
    are, and you must make sure never to call them from within a `RED` function.'
  id: totrans-split-63
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这种语言如何添加这些函数也存在问题：因为它们与`BLUE`函数完全相同，所以当您调用它们时无法分辨！您必须从文档中了解所有`GREEN`函数，并确保从`RED`函数内部永远不要调用它们。
- en: Blocking functions have no color
  id: totrans-split-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 阻塞函数没有颜色
- en: 'Now that I’ve lit my blog up like a Christmas tree, let’s talk about Rust again.
    Probably you’ve guessed what `GREEN` functions are: green functions are any function
    that blocks the current thread. There’s no special syntax or types to distinguish
    a thread which blocks waiting for something to concurrently occur: this is exactly
    what Nystrom argues is so great about blocking functions. Unlike many languages
    with asynchronous functions, Rust supports blocking functions as well: there’s
    an API to perform any kind of IO or thread synchronization by blocking the thread,
    and there’s a `block_on` API that takes any `Future` and blocks this thread until
    it is ready, so you can call asynchronous libraries as if they were blocking.'
  id: totrans-split-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我已经像圣诞树一样点亮了我的博客，让我们再谈谈Rust。你可能已经猜到`GREEN`函数是什么：绿色函数是任何阻塞当前线程的函数。没有特殊的语法或类型来区分一个阻塞等待某事同时发生的线程：这正是Nystrom认为阻塞函数如此出色之处。与许多支持异步函数的语言不同，Rust也支持阻塞函数：有一个API可以通过阻塞线程执行任何类型的IO或线程同步，还有一个`block_on`API，它接受任何`Future`并阻塞该线程直到准备就绪，因此你可以像阻塞调用异步库一样调用它们。
- en: 'Languages that don’t support blocking operations don’t have this problem: instead,
    they have the problem that Nystrom complained about that you have to know the
    difference between asynchronous and non-asynchronous functions. But since in Rust
    all things are possible, users who don’t want to use futures can avoid them almost
    entirely: their only problem is that sometimes open source libraries (provided
    to them without charge or warranty!) will use async Rust, and they will need to
    use `block_on` to work with them from their code. Some will still complain frequently
    and fervently about this state of affairs.'
  id: totrans-split-66
  prefs: []
  type: TYPE_NORMAL
  zh: 不支持阻塞操作的语言没有这个问题：相反，它们有Nystrom抱怨的问题，即您必须知道异步和非异步函数之间的区别。但由于在Rust中一切皆有可能，不想使用未来的用户几乎可以完全避开它们：他们唯一的问题是有时候开源库（免费提供给他们并且没有保修！）会使用async
    Rust，并且他们需要使用`block_on`来与其代码中的这些库一起使用。有些人仍然经常并且热切地抱怨这种情况。
- en: The people who get the worst end of the deal here are the users of async Rust,
    who not only have to deal with async Rust, but also have to deal with the fact
    that they must never call a blocking function inside their async code. Yet blocking
    functions are completely indistinguishable from normal functions! That’s what’s
    supposed to be so good about them, according to Nystrom.
  id: totrans-split-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这里最糟糕的是async Rust的用户，他们不仅必须处理async Rust，还必须处理绝不能在其async代码中调用阻塞函数的事实。然而，阻塞函数与普通函数完全无法区分！这正是Nystrom认为它们如此出色的原因。
- en: A long time ago (right after async/await came out), I [proposed](https://internals.rust-lang.org/t/warning-when-calling-a-blocking-function-in-an-async-context/11440)
    adding an attribute that could be put on blocking functions to try to introduce
    some sort of linting against calling them in async context, helping users catch
    any mistakes of this nature. This idea has not been pursued by the Rust project,
    for reasons I do not know. I would love to see more done to help users catch this
    error.
  id: totrans-split-68
  prefs: []
  type: TYPE_NORMAL
  zh: 很久以前（就在async/await推出后不久），我[提议](https://internals.rust-lang.org/t/warning-when-calling-a-blocking-function-in-an-async-context/11440)在阻塞函数上添加一个属性，试图引入一些针对在异步上下文中调用它们的警告，帮助用户捕捉此类错误。出于我不知道的原因，Rust项目并没有追求这个想法。我希望能看到更多的工作来帮助用户捕捉这种错误。
- en: 'The most insidious of the blocking APIs for async IO is the blocking `Mutex`.
    Using a blocking `Mutex` inside an async function is fine under some specific
    but still quite common circumstances:'
  id: totrans-split-69
  prefs: []
  type: TYPE_NORMAL
  zh: 用于async IO中最阴险的阻塞API之一是阻塞`Mutex`。在某些特定但仍然非常普遍的情况下，在async函数中使用阻塞`Mutex`是可以的：
- en: It is only ever locked for brief periods of time in all of its use cases.
  id: totrans-split-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在其所有用例中，它只会被锁定很短的时间。
- en: It is never held over an `await` point.
  id: totrans-split-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它从未持有在`await`点上。
- en: However, and here is where it gets really bad, if a `Mutex` is held over an
    `await` point, it could easily deadlock your thread as other tasks running on
    the same thread try to take the lock while a pending task is holding it (the standard
    library `Mutex` is not re-entrant). This means its both perfectly fine to use
    sometimes, and not just bad but absolutely devastating to use other times. Not
    a great outcome!
  id: totrans-split-72
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，问题就在这里，如果在`await`点上持有`Mutex`，当同一线程上运行的其他任务尝试获取锁时，可能会导致线程死锁（标准库的`Mutex`不是可重入的）。这意味着有时候可以使用它完全没有问题，但有时候不仅仅是坏，而且绝对是灾难性的。这并不是一个好的结果！
- en: “I don’t want fast threads, I want futures”
  id: totrans-split-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: “我不想要快速线程，我想要未来”
- en: 'The previous two sections explore two fairly independent ideas:'
  id: totrans-split-74
  prefs: []
  type: TYPE_NORMAL
  zh: 前两节探讨了两个相当独立的思想：
- en: In the first, Rust’s futures model enables a specific kind of highly optimal
    “intra-task concurrency” not enabled by the thread model.
  id: totrans-split-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第一点，Rust 的 futures 模型使得一种特定的高度优化的“任务内并发”成为可能，而这是线程模型无法实现的。
- en: In the second, blocking functions are insidiously indistinguishable from normal
    functions, causing problems for async Rust.
  id: totrans-split-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在第二点，阻塞函数和普通函数几乎无法区分，这给异步 Rust 带来了问题。
- en: 'What unites these two discussions is the fact that the difference between async
    functions and blocking functions is *the additional affordance of the Future trait*.
    This is what allows an asynchronous task to perform multiple operations concurrently,
    whereas a thread cannot. And it’s the lack of this affordance that makes blocking
    functions problematic to call from async code, because they cannot yield, they
    can only block. My design principle for async Rust is this: we implemented this
    affordance for a very good reason & should leverage it to its full potential.
    As Henry de Valence [wrote](https://twitter.com/hdevalence/status/1665867608741011456)
    on Twitter: “I don’t want fast threads, I want futures.”'
  id: totrans-split-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这两个讨论的共同点在于异步函数和阻塞函数之间的差异是*Future trait 的额外支持*。这使得异步任务能够同时执行多个操作，而线程则不能。正是因为缺乏这种支持，阻塞函数在异步代码中调用时会导致问题，因为它们不能让步，只能阻塞。我的异步
    Rust 设计原则是：我们实现这种支持有着非常充分的理由，应该充分利用它。正如 Henry de Valence 在 Twitter 上所说：“我不需要快速线程，我需要
    futures。”（原文链接：[https://twitter.com/hdevalence/status/1665867608741011456](https://twitter.com/hdevalence/status/1665867608741011456)）
- en: 'This idea is not new at all. In the [RFC](https://rust-lang.github.io/rfcs/0230-remove-runtime.html)
    that removed the green threading library from Rust, Aaron Turon argued that trying
    to make the API for asynchronous IO and blocking IO the same limited the potential
    of async Rust:'
  id: totrans-split-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法并不新鲜。在删除 Rust 中的 green threading 库的 RFC 中，Aaron Turon 认为试图使异步 IO 和阻塞 IO
    的 API 相同限制了异步 Rust 的潜力。（原文链接：[https://rust-lang.github.io/rfcs/0230-remove-runtime.html](https://rust-lang.github.io/rfcs/0230-remove-runtime.html)）
- en: With today’s design, the green and native threading models must provide the
    same I/O API at all times. But there is functionality that is only appropriate
    or efficient in one of the threading models.
  id: totrans-split-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 采用今天的设计，绿色线程和本地线程模型必须始终提供相同的 I/O API。但有些功能只适合或者在某种线程模型下更为高效。
- en: For example, the lightest-weight M:N task models are essentially just collections
    of closures, and do not provide any special I/O support. This style of lightweight
    tasks is used in Servo, but also shows up in java.util.concurrent’s executors
    and Haskell’s par monad, among many others. These lighter weight models do not
    fit into the current runtime system.
  id: totrans-split-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 例如，最轻量级的 M:N 任务模型本质上只是闭包的集合，并不提供任何特殊的 I/O 支持。这种轻量级任务的风格被用在 Servo 中，也出现在 java.util.concurrent
    的执行器和 Haskell 的 par monad 中，以及许多其他地方。这些更轻量的模型不适合于当前的运行时系统。
- en: Turon went on to develop the readiness based futures API that exists in Rust
    today, and the origins of it can be seen in these remarks. I think as we layered
    async/await syntax on top of the future abstraction (and also as contributors
    to Rust churned) this idea has been de-emphasized and somewhat lost. Now, the
    thinking goes, async Rust and blocking Rust should be as alike as possible. But
    this abandons async Rust’s extra affordance, except in terms of a possible performance
    improvement from userspace scheduling.
  id: totrans-split-81
  prefs: []
  type: TYPE_NORMAL
  zh: Turon 接着开发了基于就绪状态的 futures API，这是 Rust 当今存在的基础。它的起源可以从这些言论中看出。我认为随着我们在 future
    抽象上添加 async/await 语法（以及 Rust 贡献者的努力），这个想法已经被淡化并且有些失落。现在的思路是，异步 Rust 和阻塞 Rust 应尽可能相似。但这意味着异步
    Rust 放弃了它的额外支持，除非用户空间调度可以提供潜在的性能改进。
- en: It’s important to understand how async/await fits into this world & that it
    isn’t the whole picture. Futures give the option, but not the requirement, to
    multiplex concurrent operations within a task. This option is critical for the
    few times you need to exercise it, but most of the time you are happy to let your
    code proceed, “one damn thing after another.” The await operator lets you do exactly
    that, without highly nested callbacks or combinator chaining. This reduces the
    cost of paying for the optionality of Futures to the fact that they divide the
    world into asynchronous and non-asynchronous functions, without the additional
    difficulties of use. But it’s exactly those points where you *do* exercise that
    option - where you *don’t* await a future - that matter the most!
  id: totrans-split-82
  prefs: []
  type: TYPE_NORMAL
  zh: 理解异步/等待如何适应这个世界以及它并不是全部。Futures提供了一个选择，但不是一个要求，在一个任务内多路复用并发操作。这种选择在你需要时非常关键，但大多数时候你乐意让你的代码继续“一件该死的事情接着一件事情来”。等待操作符允许你做到这一点，而不需要高度嵌套的回调或组合器链。这降低了付出Futures选择性代价的成本，因为它们将世界分为异步和非异步函数，而不增加额外的使用困难。但正是那些你**确实**行使该选项的地方
    - 你**不**等待未来的地方 - 才是最重要的地方！
- en: Futures give you the ability to multiplex arbitrarily many perfectly-sized tasks
    on a single thread and to multiplex a static number of concurrent operations within
    a single task. In doing so they enable users to structure concurrent code logically
    instead of everwhere needing to include concurrency-related boilerplate about
    spawning threads. And they do so with much better performance characteristics,
    which can be critical in scenarios with a very high degree of concurrency. This
    alone would be worth the price of admission in my view, but we can also imagine
    other advantages.
  id: totrans-split-83
  prefs: []
  type: TYPE_NORMAL
  zh: Futures使您能够在单个线程上多路复用任意数量的完全大小的任务，并在单个任务内多路复用静态数量的并发操作。通过这样做，它们使用户能够在逻辑上结构化并发代码，而无需到处包含关于生成线程的并发相关样板。它们具有更好的性能特征，这在具有非常高并发度的场景中可能至关重要。在我看来，这一点单独就足以抵消入场费，但我们也可以想象其他优势。
- en: 'Let’s return to the problem of holding locks over await points. One pattern
    some users will use is to make sure they give up the lock before they perform
    any potentially long-running asynchronous operation like IO, so that other concurrent
    operations can take the lock instead of waiting. (This requires care: you need
    to ensure that your code is resilient to potential changes to the protected state
    that occurs while you were performing IO.) Async/await already makes this easier
    than blocking IO, because the points at which your task could be performing long-running
    work are marked by the `await` keyword. For blocking IO, nothing syntactically
    indicates blocking, making it easier to miss a point the lock needs to be given
    up. But async Rust could do even better than that.'
  id: totrans-split-84
  prefs: []
  type: TYPE_NORMAL
  zh: 返回到在等待点持有锁的问题。一些用户可能会使用的一种模式是，在执行任何可能耗时的异步操作（如IO）之前，确保他们放弃锁，这样其他并发操作可以取得锁而不是等待。（这需要小心：您需要确保您的代码能够抵御在执行IO时发生的保护状态潜在更改。）异步/等待已经比阻塞IO更容易，因为任务可能在`await`关键字标记的点执行长时间工作。对于阻塞IO，没有任何语法上表明阻塞，这样更容易忽略需要放弃锁的点。但是异步Rust可以做得比这更好。
- en: 'David Barsky has proposed what he calls a [“lifecycle”](https://internals.rust-lang.org/t/pre-rfc-lifecycle-trait/12311)
    trait: an interface analogous to `Drop`, but which executes when the future holding
    the object yields and resumes. He was interested in this concept specifically
    for [tracing](https://crates.io/crates/tracing), which includes information about
    the task being executed in all log messages and therefore needs to know when that
    changes. It could also be used to enable a locking primitive which automatically
    gives up its lease whenever the future yields control, and re-takes it whenever
    it restarts. This would ensure a user never accidentally fails to give up the
    lock when awaiting, and it would even be more optimal than the manual version:
    when your task doesn’t actually yield (because the future was immediately ready),
    you wouldn’t need to give up the lock and re-take it.'
  id: totrans-split-85
  prefs: []
  type: TYPE_NORMAL
  zh: 大卫·巴斯基（David Barsky）提出了他所称的[“生命周期”](https://internals.rust-lang.org/t/pre-rfc-lifecycle-trait/12311)
    trait：类似于`Drop`的接口，但是在包含该对象的未来产生和恢复时执行。他特别对这个概念感兴趣，因为它能够在所有日志消息中包含执行任务的信息，并且需要知道何时发生更改。它还可以用于启用一个锁原语，该原语在未来产生控制权时自动放弃其租约，并在重新启动时重新获取租约。这将确保用户在等待时不会意外地未释放锁，甚至比手动版本更为高效：当您的任务实际上不会产生控制权（因为未来立即准备就绪）时，您无需放弃锁并重新获取。
- en: '`maybe(async)`'
  id: totrans-split-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`maybe(async)`'
- en: 'I would be remiss if I didn’t mention one feature that’s been under discussion
    within the Rust project which I think runs completely counter to my line of thinking
    here: the idea of `maybe(async)`. This is a feature (syntax to be determined)
    for writing code which is abstract over whether or not it is async. In other words,
    any `maybe(async)` function could be instantiated to two variants: one in which
    it is async (and awaits all futures within it) and one in which it is not async
    (and presumably those functions which return futures in the async version would
    instead block).'
  id: totrans-split-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我不提到Rust项目内部正在讨论的一个与我这里的思路完全相反的特性，我会觉得过意不去：`maybe(async)`的想法。这是一个（语法尚待确定）用于编写代码的特性，其抽象是否是异步的。换句话说，任何`maybe(async)`函数都可以实例化为两个变体：一个是异步的（并在其中等待所有未来），另一个则不是异步的（并且可能这些在异步版本中返回未来的函数将会阻塞）。
- en: The biggest problem with this idea is that it could only work for multi-task
    concurrency. As I’ve already written, there is a direct analogy between code written
    with multi-task concurrency and code written with multi-threaded concurrency.
    But intra-task concurrency has no equivalent in thread-based concurrency systems,
    because it depends on the futures affordance. Thus, any attempt to use `maybe(async)`
    would be limited to the sections of code which strictly use multi-task concurrency.
    The problem is that for any sufficiently significant piece of code, there will
    be key sections which take advantage of intra-task concurrency, and which therefore
    would not be suitable for abstraction with `maybe(async)`.
  id: totrans-split-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法的最大问题在于它只适用于多任务并发。如我之前所述，使用多任务并发编写的代码与使用多线程并发编写的代码之间存在直接类比。但是，在任务内并发在基于线程的并发系统中没有等价物，因为它依赖于未来的特性。因此，任何试图使用`maybe(async)`的尝试将仅限于严格使用多任务并发的代码段。问题在于，对于任何足够重要的代码片段，都会存在利用任务内并发的关键部分，因此不适合使用`maybe(async)`进行抽象化。
- en: Recently, Mario Ortiz Manero [wrote](https://nullderef.com/blog/rust-async-sync/)
    about the difficulty of trying to write a library which supports usage either
    with blocking or asynchronous IO. This blog post seems to me to be the strongest
    case I could think of for `maybe(async)`, so I want to analyze it more thoroughly.
  id: totrans-split-89
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Mario Ortiz Manero在[这篇文章](https://nullderef.com/blog/rust-async-sync/)中讨论了尝试编写同时支持阻塞和异步IO的库的困难性。这篇博文对我来说似乎是我能想到的最为强有力的`maybe(async)`的案例，因此我想更深入地分析它。
- en: Their use case was a wrapper which translates Rust method calls into HTTP requests
    to the Spotify API. They want to support both blocking and asynchronous versions
    of their library from the same source code, using [reqwest](https://github.com/seanmonstar/reqwest)
    as an asynchronous HTTP client and [ureq](https://github.com/algesten/ureq) as
    a blocking HTTP client. They wrote about how difficult this is right now, which
    is certainly true.
  id: totrans-split-90
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的用例是一个包装器，将Rust方法调用转换为对Spotify API的HTTP请求。他们希望从相同的源代码支持其库的阻塞和异步版本，使用[reqwest](https://github.com/seanmonstar/reqwest)作为异步HTTP客户端，以及[ureq](https://github.com/algesten/ureq)作为阻塞HTTP客户端。他们讨论了目前这种做法的困难性，这显然是正确的。
- en: 'First, it’s interesting to note that the reqwest library actually contains
    its own blocking HTTP client as well as its asynchronous one. To implement this,
    it spawns a background thread on which all requests to that client will be made
    asynchronously, multiplexing them on the same thread. Ortiz Manero rejected this
    approach for this reason:'
  id: totrans-split-91
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，有趣的是注意到 reqwest 库实际上包含其自己的阻塞式 HTTP 客户端以及其异步客户端。为了实现这一点，它会在一个后台线程上生成所有对该客户端的请求，使它们在同一个线程上进行多路复用。奥尔蒂兹·马内罗因此拒绝了这种方法：
- en: Unfortunately, this solution still has quite the overhead. You pull in large
    dependencies like `futures` or `tokio`, and include them in your binary. All of
    that, in order to&mldr; actually end up writing blocking code. So not only is
    it a cost at runtime, but also at compile time. It just feels wrong to me.
  id: totrans-split-92
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不幸的是，这种解决方案仍然有相当大的开销。您会引入像 `futures` 或 `tokio` 这样的大型依赖，并将它们包含在您的二进制文件中。所有这些，都是为了&mldr;
    最终写出阻塞代码。因此，这不仅仅是运行时的成本，而且还是编译时的成本。这种感觉对我来说不太对劲。
- en: Here, by “overhead,” Ortiz Manero seems to mean the build-time overhead of these
    dependencies, and not runtime overhead. But we should ask why reqwest pull in
    these dependencies, even if it “feels wrong”? In blocking reqwest, tokio is used
    to multiplex all requests to the same client on a single thread. This architectural
    difference between blocking reqwest and ureq (which instead performs blocking
    IO from the thread that makes the request) seems more important to me than the
    fact that one depends on tokio and one does not. I’d like to see benchmarks comparing
    the two approaches for different workloads, rather than excluding one just because
    of what’s in its dependency tree.
  id: totrans-split-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，奥尔蒂兹·马内罗似乎是指这些依赖的构建时开销，而不是运行时开销。但我们应该问一下为什么 reqwest 要引入这些依赖，即使它“感觉不对劲”？在阻塞式
    reqwest 中，tokio 用于在同一线程上复用所有对同一客户端的请求。对我来说，这两种方法之间的这种架构差异比起一个依赖于 tokio 而另一个不依赖于它更为重要。我想看到针对不同工作负载的两种方法之间的基准测试，而不是仅仅因为其依赖树中的内容而排除其中一种。
- en: One feature that reqwest supports and ureq does not is HTTP/2\. HTTP/2 is designed
    to allow users to multiplex different requests over the same TCP connection. ureq
    by contrast provides only (non-pipelined) HTTP/1\. And it has no way of supporting
    this with its current architecture, because whenever a user makes a request over
    a TCP connection, it blocks the thread until that request completes. Thus, with
    ureq the number of concurrent network requests you can make to a service is limited
    by the number of open TCP connections that service will allow you to make, and
    for each new connection you’ll need to perform a new TCP (and probably TLS) handshake.
  id: totrans-split-94
  prefs: []
  type: TYPE_NORMAL
  zh: reqwest 支持但 ureq 不支持的一个特性是 HTTP/2。HTTP/2 的设计允许用户在同一 TCP 连接上复用不同的请求。相比之下，ureq
    只提供了（非管线化的）HTTP/1。根据其当前的架构，它无法支持这一点，因为每当用户在 TCP 连接上发出请求时，它会阻塞线程直到该请求完成。因此，使用 ureq，您可以向服务发送的并发网络请求数量受限于该服务允许您建立的开放
    TCP 连接的数量，并且对于每个新连接，您将需要执行新的 TCP（和可能是 TLS）握手。
- en: If ureq wanted to support HTTP/2 and its multiplexing, it would find it needs
    to implement that multiplexing over a single TCP connection somehow. It might
    not do so using async Rust, but if it wanted to use blocking IO for this & still
    provide an API like the one it has now, it would still need to run a background
    thread and channels so that concurrent requests from multiple threads can be multiplexed
    over a single TCP connection. In other words, the architecture would come to look
    just like the architecture that reqwest has. By using async Rust, reqwest is more
    easily able to abstract over the difference between multiplexing requests to multiple
    connections with HTTP/1 and multiplexing requests to the same connection with
    HTTP/2\. This is a huge advantage, since users frequently don’t know whether the
    service they want to communicate with supports HTTP/2.
  id: totrans-split-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 ureq 想要支持 HTTP/2 及其复用功能，它会发现需要在单个 TCP 连接上实现该复用。它可能不会使用异步 Rust 来做到这一点，但如果它希望在此基础上使用阻塞
    IO，并且仍然提供与现有 API 相似的接口，那么它仍然需要运行一个后台线程和通道，以便多个线程的并发请求可以在单个 TCP 连接上进行复用。换句话说，这种架构将变得与
    reqwest 的架构一样。通过使用异步 Rust，reqwest 更容易地在多个连接上多路复用 HTTP/1 的请求和在同一连接上多路复用 HTTP/2
    的请求之间进行抽象。这是一个巨大的优势，因为用户经常不知道他们想要通信的服务是否支持 HTTP/2。
- en: Even still, you might say that `maybe(async)` would have some utility to this
    author even if they switched from ureq to reqwest’s blocking API, because it would
    allow them to save the boilerplate of implementing the async version of their
    library and a blocking API on top of it. But because of the limitations of what
    can be abstracted by `maybe(async)`, this is really only true for a specific kind
    of library which is strictly a stateless “mapping” over the semantics of a lower-level
    library. This could be, as in this example, a library that translates HTTP RPC
    calls into Rust objects & methods, or it could be a library that defines a wire
    protocol in terms of a bytewise interface like TCP. As soon as the library has
    its own evolving state to manage (as the HTTP or IO libraries underneath them
    do), the two implementations would meaningfully diverge and no longer be implementable
    from the same source with `maybe(async)`.
  id: totrans-split-96
  prefs: []
  type: TYPE_NORMAL
  zh: 即便如此，您可能会说 `maybe(async)` 对于本文作者来说仍然有一些效用，即使他们从 ureq 切换到 reqwest 的阻塞 API，因为它可以帮助他们省去实现库的异步版本和其阻塞
    API 的样板文件。但由于 `maybe(async)` 能够抽象的内容有限，这仅对严格的无状态“映射”另一个底层库语义的库来说才是真实的。例如，这可能是一个将
    HTTP RPC 调用转换为 Rust 对象和方法的库，或者可能是一个根据字节接口（如 TCP）定义的线路协议库。一旦库有了自己的不断发展的状态管理（正如它们下面的
    HTTP 或 IO 库所做的那样），这两种实现就会有意义地分歧，不能再通过 `maybe(async)` 从同一源码实现。
- en: Since for those libraries maintaining two versions is just boilerplate, there
    are perhaps better ways to support this than adding a new abstraction. One approach
    would be to use the macro system, which could be used to generate something like
    reqwest’s blocking interface from an async interface (generating the code which
    spawns a background thread and maps blocking functions into messages to that thread).
    Libraries like the Spotify client could use that macro to avoid the boilerplate
    of supporting their blocking API, at the expense of using an async runtime on
    a background thread for their implementation. But this would apply equally well
    to stateless and stateful libraries, unlike `maybe(async)`.
  id: totrans-split-97
  prefs: []
  type: TYPE_NORMAL
  zh: 由于对于那些需要维护两个版本的库来说，这只是样板文件，可能有更好的方法来支持这一点，而不是添加一个新的抽象层。一个方法是使用宏系统，可以用它来生成类似于
    reqwest 的阻塞接口，从一个异步接口生成代码（生成将阻塞函数映射到后台线程的消息）。像 Spotify 客户端这样的库可以使用该宏来避免支持阻塞 API
    的样板文件，但这会以在后台线程上使用异步运行时为代价来实现。但这同样适用于无状态和有状态的库，不像 `maybe(async)`。
- en: Another approach is what’s called “sans-IO.” The author of ureq, for example,
    also maintains a WebRTC library called [str0m](https://github.com/algesten/str0m)
    written in this style, which avoids the problem of blocking and non-blocking IO
    by not handling the actual IO in the library at all. A similarly written library
    is Cloudflare’s [quiche](https://github.com/cloudflare/quiche), which implements
    the state machine for QUIC, but without performing IO. Building on this concept,
    we could imagine a way to “lift” the problem of IO completely out of these libraries,
    to instead write them against an abstract interface that allows them to be executed
    against any implementation of UDP, TCP, HTTP, or whatever they depend on. Exactly
    how this would be generalized remains to be determined.
  id: totrans-split-98
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是所谓的“无IO”。例如，ureq 的作者还维护着一种以这种风格编写的 WebRTC 库，称为 [str0m](https://github.com/algesten/str0m)，它通过完全不处理库中的实际
    IO 来避免阻塞和非阻塞 IO 的问题。类似地编写的库还有 Cloudflare 的 [quiche](https://github.com/cloudflare/quiche)，它实现了
    QUIC 的状态机，但没有执行 IO。基于这个概念，我们可以想象一种完全将 IO 问题“解放”出这些库的方法，而是编写针对抽象接口的库，允许它们针对任何 UDP、TCP、HTTP
    或它们所依赖的其他协议实现执行。如何通用化这一点还有待确定。
- en: A final digression about coroutines
  id: totrans-split-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后关于协程的离题讨论
- en: 'This post is already too long, but I know that it might gain traction outside
    of the Rust community, and I can predict a certain negative response: the affordances
    of futures I cite are not only achievable with futures! These affordances can
    be provided by any kind of coroutine. Rust uses *stackless* coroutines, which
    have some unpleasant limitations, but a language with *stackful* coroutines could
    also provide the same affordance with less headache.'
  id: totrans-split-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章已经太长了，但我知道它可能会在 Rust 社区之外获得关注，我可以预测到某种消极反应：我引用的 future 的便利性不仅仅可以通过 futures
    实现！任何类型的协程都可以提供这些便利性。Rust 使用 *无栈* 协程，它们有一些令人不快的限制，但是使用 *有栈* 协程的语言也可以以更少的麻烦提供相同的便利性。
- en: I actually agree. Returning the world of made up languages, one could imagine
    a language in which all functions are coroutines, meaning that all functions can
    yield. No function coloring! A “pure” function would be a function that yields
    `Never` (meaning it doesn’t actually yield at all), whereas an “impure” function
    would be a function that yields `Pending` (or some other magic type from your
    runtime meaning you’re waiting on an external event). Impure functions would be
    the default and all functions are coroutines, so the call operator would automatically
    forward `Pending` values outward. You could still mark pure functions somehow
    for when you want to ensure you are not doing any sort of IO or synchronization.
  id: totrans-split-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我实际上同意。回到虚构语言的世界，人们可以想象一种所有函数都是协程的语言，这意味着所有函数都可以产生。没有函数染色！“纯”函数将是一个永远不会产生`Never`的函数（实际上根本不会产生），而“不纯”函数将是一个产生`Pending`（或来自你运行时的其他魔术类型，表示正在等待外部事件）的函数。不纯函数将是默认的，所有函数都是协程，因此调用操作符将自动向外传递`Pending`值。你仍然可以以某种方式标记纯函数，以确保你不做任何IO或同步操作。
- en: 'The language would also want a way to instantiate the coroutine object and
    resume it, instead of calling it to completion. Using that operator, you could
    implement concurrency combinators like select and join. And the language would
    need some way of spawning coroutines as entirely new, concurrent tasks. All of
    this without any need for async/await: that’s what stackful coroutines get you.'
  id: totrans-split-102
  prefs: []
  type: TYPE_NORMAL
  zh: 该语言还需要一种实例化协程对象并恢复它的方法，而不是调用它直到完成。利用该操作符，你可以实现像select和join这样的并发组合器。语言还需要某种方式来作为全新的并发任务生成协程。所有这些都无需async/await：这就是堆栈饱和协程为你提供的。
- en: You might even extend this coroutine feature to also represent other things.
    For example, iterables could be represented as coroutines yielding a meaningful
    value. `for` loops would take that coroutine object and process each of those
    values in turn. Asynchronous iterables would just yield that value *or* `Pending`.
    And you could model exceptions in the same way, yielding an error (probably you
    would have a separate “pathway” from yield and return, in recognition of a fact
    that a function that has thrown an exception cannot be restarted). I don’t have
    the whole language mapped out, but all of this sounds plausible.
  id: totrans-split-103
  prefs: []
  type: TYPE_NORMAL
  zh: 你甚至可以将这种协程特性扩展到代表其他事物。例如，可迭代对象可以表示为产生有意义的值的协程。`for`循环将获取该协程对象并依次处理每个值。异步可迭代对象只会产生该值*或*
    `Pending`。你还可以以相同的方式建模异常，产生一个错误（可能会有一个单独的“路径”，用于识别抛出异常的函数无法重新启动的事实）。我还没有完全设计好这种语言，但所有这些听起来都是合理的。
- en: '(And indeed, this doesn’t have to be done with coroutines. You could also model
    this in an inverted manner, so that instead you register a point in the stack
    to return to for each of these things: one for pending IO operations, one for
    thrown exceptions, one for items yielded from an iterable, and so on. You could
    call that point in the stack a “handler” for those “effects,” in other words a
    kind of “algebraic effect handler.” What I’m saying is that these two language
    concepts, effect handlers and coroutines, are at least partially isomorphic to
    one another.)'
  id: totrans-split-104
  prefs: []
  type: TYPE_NORMAL
  zh: （事实上，这并不一定要通过协程完成。你还可以以倒置方式建模这一点，以便为每个这些事物注册一个返回堆栈的点：用于挂起IO操作的一个点，用于抛出异常的一个点，用于从可迭代对象产生的项的一个点，等等。你可以称之为这些“效果”的堆栈点的“处理程序”，换句话说，一种“代数效果处理程序”。我想说的是，这两种语言概念，效果处理程序和协程，至少部分上是同构的。）
- en: I also believe, but I am not certain, that such a language could achieve the
    same guarantee as Rust that references are not simultaneously mutable and aliased
    without adding lifetimes to the surface syntax. As long as coroutines can yield
    and be resumed with references, references could become modifiers that cannot
    be embedded in object types, and their lifetimes could be entirely inferred. It
    would not allow exactly as optimal code representation as Rust (in the terminology
    of a previous [post](/blog/the-registers-of-rust), there would be no access to
    the “low-level register,”) but it would still give the same correctness guarantees.
  id: totrans-split-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我还认为（但不确定）这样的语言可以在不向表面语法添加生命周期的情况下，实现与Rust相同的保证，即引用不会同时可变且别名化。只要协程能够暂停并使用引用恢复，引用就可以成为不能嵌入对象类型的修饰符，它们的生命周期可以完全推断。这将不允许与Rust一样优化的代码表示（在之前的[文章](/blog/the-registers-of-rust)术语中，将无法访问“低级寄存器”），但仍将提供相同的正确性保证。
- en: 'Why didn’t Rust do something like this? [It did, at first!](https://graydon2.dreamwidth.org/307291.html)
    But it gave way to other requirements. There was a really great [comment](https://lobste.rs/s/jkct2m/avoid_async_rust#c_0dqqlv)
    on lobste.rs the other week that said it better than I could:'
  id: totrans-split-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么Rust不做类似的事情？[起初确实是这样的！](https://graydon2.dreamwidth.org/307291.html)但它让位给了其他要求。上周在lobste.rs上有一个真正好的[评论](https://lobste.rs/s/jkct2m/avoid_async_rust#c_0dqqlv)，比我更好地表达了这一点：
- en: Async style language features are a compromise between your execution model
    being natively compatible with the 1:1 C ABI, C standard library, and C runtime
    and a M:N execution model. C++ async suffers from the same issues, except it’s
    not as strict in terms of lifetime safety (not a good thing). The cost for the
    native compatibility with the C/system runtime is the “function coloring” problem.
  id: totrans-split-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 异步风格语言特性是你的执行模型与1：1的C ABI、C标准库和C运行时本地兼容以及M：N执行模型之间的一种妥协。C++的异步也遇到了相同的问题，只是在生命周期安全性上没有那么严格（这不是一件好事）。与C/系统运行时本地兼容的成本是“函数上色”问题。
- en: Rust has a prior commitment to be compatible with the existing C runtime. This
    means Rust code is made up of a stack of subroutines, and the address of items
    in the stack can be taken, and stored not only in that stack but also in other
    areas of program memory. Rust chose this approach to get zero-cost FFI to the
    enormous amounts of existing C and C++ code written using that model, and because
    the C runtime is the shared minimum of all mainstream platforms. But this runtime
    model is incompatible with *stackful* coroutines, so Rust needed to introduce
    a *stackless* coroutine mechanism instead. Every major language with async/await
    is similarly beholden to an existing runtime with a similar inability to represent
    stackful coroutines, if not C’s then some virtual machine runtime. The only thing
    about the C runtime is that it is so ubiquitous many programmers don’t even realize
    it exists & isn’t a naturally occurring phenomenon.
  id: totrans-split-108
  prefs: []
  type: TYPE_NORMAL
  zh: Rust有一个与现有C运行时兼容的先前承诺。这意味着Rust代码由一堆子例程组成，可以取出堆栈中的项目地址，并且不仅可以存储在该堆栈中，还可以存储在程序内存的其他区域。Rust选择了这种方法，以获取对使用该模型编写的大量现有C和C++代码的零成本FFI支持，因为C运行时是所有主流平台的共享最小标准。但是，这种运行时模型与*栈内*协程不兼容，因此Rust需要引入一种*无栈*协程机制。每一种带有async/await的主要语言同样受限于一个类似的现有运行时，无论是C的还是某个虚拟机运行时。关于C运行时唯一的事情是，它是如此普遍，以至于许多程序员甚至没有意识到它的存在，也不是一个自然发生的现象。
- en: 'One more remark along these lines:'
  id: totrans-split-109
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一条关于这些问题的评论：
- en: If you were a language designer of some renown, you might convince a large and
    wealthy technology company to fund your work on a new language which isn’t so
    beholden to C runtime, especially if you had a sterling reputation as a systems
    engineer with a deep knowledge of C and UNIX and could leverage that (and the
    reputation of the company) to get rapid adoption of your language. Having achieved
    such an influential position, you might introduce a new paradigm, like stackful
    coroutines or effect handlers, liberating programmers from the false choice between
    threads and futures. If Liebniz is right that we live in the best of all possible
    worlds, surely this is what you would do with that once in a generation opportunity.
  id: totrans-split-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是一位享有盛名的语言设计师，你可能会说服一家大型富有的技术公司资助你开发一种新的语言，这种语言不那么依赖于C运行时，特别是如果你作为一位对C和UNIX有深入了解的系统工程师享有卓越声誉，并且能够利用这一点（以及公司的声誉）迅速推广你的语言。在取得这样有影响力的位置后，你可能会引入一种新的范式，比如栈内协程或效果处理程序，从而解放程序员，摆脱线程和future之间的虚假选择。如果莱布尼茨说得对，我们生活在最好的世界中，那么这确实是你在一代人的机会中所能做的。
- en: (If you did this, I hope you at least wouldn’t go on stage and say the reason
    you’ve adopted this approach is that your users are “not capable of understanding
    a brilliant language”!)
  id: totrans-split-111
  prefs: []
  type: TYPE_NORMAL
  zh: （如果你这样做了，我希望你至少不会上台说你采用这种方法的原因是因为你的用户“无法理解一个杰出的语言”！）
- en: In a less than optimal world, you might decide to do something less inspired.
    You might take that break from the C runtime and then just implement threads again,
    with basically the same semantics, except that they are scheduled in userspace.
    Your users would be required to implement concurrency in terms of threads, locks
    and channels, just like they had always been in the past. You might also decide
    your language should have other classic features like null pointers, default constructors,
    data races and GOTO, for reasons known only to you. Maybe you would also drag
    your feet for years on adding generics, despite frequent user requests. You might
    *go* do that, in a less than optimal world.
  id: totrans-split-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在不太理想的世界里，你可能会决定做一些不太有灵感的事情。你可能会从C运行时中休息一下，然后再次实现线程，基本上具有相同的语义，只是它们在用户空间中调度。你的用户将需要根据线程、锁和通道来实现并发，就像过去一直这样。你也可能决定你的语言应该具有其他经典特性，比如空指针、默认构造函数、数据竞争和GOTO，原因只有你自己知道。也许你会在多年之后才添加泛型，尽管用户频繁请求。在不太理想的世界里，你可能*去*做这些事情。
- en: 'Alas. When I’m feeling pessimistic, I think our industry is mired in a certain
    stagnation, so that every decade we shall re-write new programs with the same
    behavior in new languages with the same semantics, having only mild differences
    in performance characteristics more suited to present hardware considerations.
    A sad fate, but perhaps soon to be the lot of large language models and not programmers.
    The reason I am an enthusiastic promoter of Rust is that it makes me feel optimistic
    about programming: Rust is committed to the belief that mainstream programming
    languages can meaningfully evolve for the better.'
  id: totrans-split-113
  prefs: []
  type: TYPE_NORMAL
  zh: 唉。在我感到悲观时，我认为我们的行业陷入了某种停滞，因此每个十年我们都将用新语言重新编写具有相同行为的新程序，这些语言在语义上基本相同，只是在性能特征上有轻微差异，更适合当前的硬件考虑。这是一个悲伤的命运，但也许很快将成为大型语言模型的命运，而不是程序员的命运。我热衷于推广Rust的原因在于它让我对编程感到乐观：Rust致力于相信主流编程语言可以有意义地为更好而进化。
- en: 'Despite being an advancement, Rust is not the language that has broken from
    the C runtime. It is that language’s lower level & more difficult cousin: you
    can get the same guarantees, “with some assembly required.” We should do everything
    we can, given our hard requirements, to reduce the necessary assembly & with async/await
    we have already laid the foundation for that. We should aspire not to simplify
    the system by hiding the differences between futures and threads, but instead
    to find the right set of APIs and language features that build on the affordances
    of futures to make more kinds of engineering achievable than before. Right now
    we only have the foundation, but this is already a huge leap forward from the
    previous world of hand-rolled state machines and directly managing your event
    loop. If we let futures be futures and build on that foundation, even more will
    be possible.'
  id: totrans-split-114
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管是一种进步，但Rust并不是摆脱了C运行时的语言。它是那种语言的低级别、更难处理的表亲：你可以通过一些汇编来获得相同的保证。“需自行组装”。在我们的硬性要求下，我们应该尽一切可能减少必要的汇编，在async/await的基础上，我们已经为此奠定了基础。我们应该志在不通过隐藏futures和线程之间的差异来简化系统，而是找到一套正确的API和语言特性，利用futures的便利性来实现比以往更多种类的工程任务。现在我们只有基础，但这已经比以往手工管理状态机和直接管理事件循环的世界有了巨大的进步。如果我们让futures成为futures并在此基础上建立，将会有更多可能性。
