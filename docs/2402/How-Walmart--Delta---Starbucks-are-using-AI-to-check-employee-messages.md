<!--yml

category: 未分类

date: 2024-05-27 14:45:02

-->

# 沃尔玛、达美航空和星巴克如何利用人工智能检查员工消息

> 来源：[https://www.cnbc.com/2024/02/09/ai-might-be-reading-your-slack-teams-messages-using-tech-from-aware.html](https://www.cnbc.com/2024/02/09/ai-might-be-reading-your-slack-teams-messages-using-tech-from-aware.html)

图片来源：Klaus Vedfelt | Digitalvision | Getty Images

想起了乔治·奥威尔的作品。

根据你所工作的地方，有很大可能性是人工智能在分析你在Slack、Microsoft Teams、[Zoom](/quotes/ZM/)等热门应用中的消息。

诸如[Walmart](/quotes/WMT/)、[Delta Air Lines](/quotes/DAL/)、[T-Mobile](/quotes/TMUS/)、[Chevron](/quotes/CVX/)和[Starbucks](/quotes/SBUX/)等美国大雇主，以及欧洲品牌包括雀巢和[AstraZeneca](/quotes/AZN-GB/)，都已经转向了一家成立七年的初创公司Aware，用于监视其员工之间的交流，该公司表示。

俄亥俄州哥伦布市创业公司的联合创始人兼首席执行官杰夫·舒曼表示，AI帮助公司“了解其通信中的风险”，实时了解员工的情感状态，而不是依赖于每年或每两年的调查。

使用Aware的分析产品中的匿名化数据，客户可以看到某个年龄组或特定地理位置的员工对新的企业政策或营销活动的反应，Schumann说。Aware的数十个AI模型，用于阅读文本和处理图像，还可以识别欺凌、骚扰、歧视、违规行为、色情、裸露和其他行为，他说。

Aware的分析工具——监测员工情绪和毒性的工具——没有能力标记个别员工的姓名，舒曼表示。但是，他补充说，其单独的eDiscovery工具可以在发生极端威胁或其他风险行为的情况下，标记客户预先确定的个人。

Aware表示，沃尔玛、T-Mobile、雪佛龙和星巴克使用其技术进行治理风险和合规性工作，这类工作约占公司业务的80%。

CNBC未收到沃尔玛、T-Mobile、雪佛龙、星巴克或雀巢关于其使用Aware的回复。阿斯利康的代表表示，该公司使用eDiscovery产品，但不使用分析来监测情绪或毒性。达美航空告诉CNBC，公司使用Aware的分析和eDiscovery来监测趋势和情绪，以收集员工和其他利益相关者的反馈，以及在其社交媒体平台中进行法律记录保留。

并非需要狂热的反乌托邦小说爱好者才会看出一切可能都会走向非常错误的地方。

AI问责非营利组织Humane Intelligence联合创始人朱塔·威廉姆斯表示，AI为所谓的内部风险计划增添了新的潜在问题，这些计划多年来一直存在，用于评估诸如企业间谍活动之类的事情，尤其是电子邮件沟通中的情况。

在谈论员工监控 AI 而非 Aware 的技术时，Williams 告诉 CNBC：“很多时候这都成为了思想犯罪。” 她补充道：“这种方式对待人员有些像库存。”

员工监控 AI 是一个迅速扩展但市场细分的 AI 市场的一部分，这个市场在过去一年迅速膨胀，这是在 2022 年底 OpenAI 的 ChatGPT 聊天机器人推出之后。生成式 AI 很快成为企业收益电话会议中的流行短语，某种形式的技术正在自动化几乎每个行业的任务，从金融服务和生物医学研究到物流、在线旅行和[公用事业](https://prod.ucwe.capgemini.com/wp-content/uploads/2023/07/Final-Web-Version-Report-Harnessing-the-Value-of-Gen-AI.1.pdf)。

Schumann 告诉 CNBC，Aware 的收入在过去五年平均增长了 150%，其典型客户约有 30,000 名员工。主要竞争对手包括 Qualtrics、Relativity、Proofpoint、Smarsh 和 Netskope。

根据行业标准，Aware 保持了相当的精简。该公司最后一次融资是在 2021 年，当时它通过一轮融资筹集了 6 千万美元，由[高盛资产管理](/quotes/GS/)主导。与像 OpenAI 和 Anthropic 这样的大语言模型（LLM）公司相比，它们每家都筹集了数十亿美元，主要来自战略合作伙伴。

## '追踪实时毒性'

Schumann 在全国互保公司几乎八年的企业协作工作后于 2017 年创立了这家公司。

在此之前，他是一名企业家。而 Aware 并非他启动的第一家令人联想到奥威尔的公司。

2005 年，Schumann 创立了一个名为 BigBrotherLite.com 的公司。根据他的[LinkedIn 个人资料](https://www.linkedin.com/in/jeffreyschumann/)，该业务开发了一款软件，用于增强 CBS 真人秀系列《Big Brother》的数字和移动观看体验。在奥威尔的经典小说《1984》中，Big Brother 是一个极权国家的领导人，在那里市民被永久监视。

**"**我创建了一个简单的播放器，专注于为人们在他们的计算机上观看电视节目提供更清洁和更简单的消费体验，" Schumann 在一封电子邮件中说。

在 Aware，他正在做一些非常不同的事情。

每年，公司发布一份报告，汇总了来自数十亿条消息的见解 —— 在 2023 年，这一数字为 65 亿 —— 并且列出了公司的感知风险因素和工作场所情绪得分。Schumann 将每年在工作场所沟通平台上发送的数万亿条消息称为“世界上增长最快的非结构化数据集”。

当包含其他类型的内容时，例如图像和视频，Aware的分析AI每天分析超过10亿件内容。 在此过程中，技术创建了公司社交图，查看哪些团队在内部彼此交流更多。

“它始终跟踪实时员工情感，并始终跟踪实时毒性”，Schumann关于分析工具的说法。 “如果您是使用Aware的银行并且工作队伍的正面情绪在最后20分钟激增，那是因为他们集体积极地谈论某事物。 技术能够告诉他们发生了什么。”

Aware向CNBC确认，它使用企业客户的数据来训练其机器学习模型。 公司的数据存储库包含约65亿条消息，代表了约2000亿次不同的互动，涉及超过3百万独特的员工。

当新客户注册分析工具时，Aware的AI模型大约需要两周的时间来学习员工信息并了解公司内情感和情绪模式，以便它能判断什么正常什么异常，Schumann说。

“它不会包含人员姓名，以保护隐私”，Schumann说。相反，他说，客户会看到“在这个美国部分地区，40岁以上的工作队伍可能非常负面地看待政策变化，由于成本，但其他年龄段和地区的所有其他人对此持正面观点，因为它以不同方式影响他们。”

但是Aware的电子发现工具运作方式不同。公司可以根据“极端风险”类别设定基于角色的员工姓名访问权限，这指示Aware的技术在某些情况下会为人力资源或公司代表提取个人姓名。

“其中一些常见的包括极端暴力，极端欺凌，骚扰，但它们随行业而异，“Schumann补充说，他在金融服务领域追踪可疑的内部交易。

例如，客户可以使用Aware的技术指定“暴力威胁”政策，或其他任何类别，并让AI模型监测Slack，Microsoft Teams和Meta所使用的Workplace中的违规行为。 客户还可以与特定短语、声明等的基于规则的标记相关联。 如果AI发现违反了公司规定的政策，则可以向客户的指定代表提供员工姓名。

这种实践已经在电子邮件通信中使用数年。 新事物是使用AI及其在工作场所消息平台（例如Slack和Teams）上的应用程序。

纽约大学AI Now机构的执行主任Amba Kak担心使用AI来帮助判断被认为是危险行为的情况。

“这导致了人们在工作场所所说的话产生了冷淡效应，” Kak说道，补充说，尽管她并未具体谈论Aware公司的技术，“这些问题与工人权利问题同样重要，也是隐私问题。”

Schumann说，尽管Aware的电子发现工具允许安全或人力资源调查团队使用AI搜索大量数据，“今天在Slack、Teams和其他平台中已经存在一个类似但基本的功能。”

“这里的一个关键区别在于，Aware及其AI模型并不做出决策，” Schumann说，“我们的AI只是简化了在新数据集中搜寻潜在风险或政策违规行为的过程。”

## 隐私问题

即使数据被聚合或匿名化，[研究表明](https://crypto.stanford.edu/~pgolle/papers/census.pdf)，这是一个有缺陷的概念。一项关于数据隐私的里程碑研究，使用1990年美国人口普查数据显示，仅通过使用邮政编码、出生日期和性别，就可以识别出87%的美国人。Aware客户使用其分析工具可以为消息跟踪添加元数据，例如员工年龄、位置、部门、任职时间或职能。

“他们所说的依赖于一个非常过时的，我可以说完全被驳斥的观念，即匿名化或聚合是解决隐私问题的万灵药，” Kak说道。

此外，根据[最近的研究](https://openreview.net/pdf?id=kmn0BhQk7p)，Aware使用的AI模型类型可以有效地从聚合数据中生成推断，例如基于语言、上下文、俚语等，准确猜测个人识别符号。

“没有任何公司可以对LLM和这类系统的隐私和安全性做出广泛的保证，” Kak说道，“没有人可以毫不含糊地告诉你这些挑战已经解决。”

“员工申诉怎么办呢？如果某次互动被标记，并导致员工受到处分或解雇，如果他们无法掌握所有涉及数据，那么他们要进行辩护将非常困难，” Williams说道。

“AI解释能力尚不成熟时，你如何面对控告者？” Williams说道。

Schumann回应道：“我们的任何AI模型都不会对员工的纪律做出决定或建议。”

“当模型标记一个互动时，” Schumann说，“它会提供发生了什么以及触发了什么政策的完整背景，为调查团队提供他们根据公司政策和法律作出决定下一步所需的信息。”

**观看：** [AI在最近的技术裁员中扮演着重要角色](https://www.cnbc.com/video/2024/01/25/ai-is-really-at-play-here-with-the-recent-tech-layoffs-says-jason-greer.html)
