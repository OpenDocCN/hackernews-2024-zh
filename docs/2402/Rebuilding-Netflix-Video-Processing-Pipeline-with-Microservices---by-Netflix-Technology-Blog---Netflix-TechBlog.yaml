- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:44:12'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: Rebuilding Netflix Video Processing Pipeline with Microservices | by Netflix
    Technology Blog | Netflix TechBlog
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://netflixtechblog.com/rebuilding-netflix-video-processing-pipeline-with-microservices-4e5e6310e359?gi=d48b3333df75](https://netflixtechblog.com/rebuilding-netflix-video-processing-pipeline-with-microservices-4e5e6310e359?gi=d48b3333df75)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '***Rebuilding Netflix Video Processing Pipeline with Microservices***'
  id: totrans-split-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Liwei Guo](https://www.linkedin.com/in/liwei-guo-a5aa6311/), [Anush Moorthy](https://www.linkedin.com/in/anush-moorthy-b8451142/),
    [Li-Heng Chen](https://www.linkedin.com/in/li-heng-chen-a75458a2/), [Vinicius
    Carvalho](https://www.linkedin.com/in/carvalhovinicius/), [Aditya Mavlankar](https://www.linkedin.com/in/aditya-mavlankar-7139791/),
    [Agata Opalach](https://www.linkedin.com/in/agataopalach/), [Adithya Prakash](https://www.linkedin.com/in/adithyaprakash/),
    Kyle Swanson, [Jessica Tweneboah](https://www.linkedin.com/in/jessicatweneboah/),
    [Subbu Venkatrav](https://www.linkedin.com/in/subbu-venkatrav-126172a/), [Lishan
    Zhu](https://www.linkedin.com/in/lishan-z-51302abb/)'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: '*This is the first blog in a multi-part series on how Netflix rebuilt its video
    processing pipeline with microservices, so we can maintain our rapid pace of innovation
    and continuously improve the system for member streaming and studio operations.
    This introductory blog focuses on an overview of our journey. Future blogs will
    provide deeper dives into each service, sharing insights and lessons learned from
    this process.*'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: 'The Netflix video processing pipeline went live with the launch of our streaming
    service in 2007\. Since then, the video pipeline has undergone substantial improvements
    and broad expansions:'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
- en: Starting with Standard Dynamic Range (SDR) at [Standard-Definitions](https://en.wikipedia.org/wiki/Display_resolution),
    we expanded the encoding pipeline to 4K and High Dynamic Range (HDR) which enabled
    support for our premium offering.
  id: totrans-split-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We moved from centralized linear encoding to [distributed chunk-based encoding](/high-quality-video-encoding-at-scale-d159db052746).
    This architecture shift greatly reduced the processing latency and increased system
    resiliency.
  id: totrans-split-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moving away from the use of dedicated instances that were constrained in quantity,
    we tapped into Netflix’s [internal trough](/creating-your-own-ec2-spot-market-6dd001875f5)
    created due to autoscaling microservices, leading to significant improvements
    in computation elasticity as well as resource utilization efficiency.
  id: totrans-split-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We rolled out encoding innovations such as [per-title](https://medium.com/netflix-techblog/per-title-encode-optimization-7e99442b62a2)
    and [per-shot](/optimized-shot-based-encodes-now-streaming-4b9464204830) optimizations,
    which provided significant quality-of-experience (QoE) improvement to Netflix
    members.
  id: totrans-split-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By integrating with studio content systems, we enabled the pipeline to leverage
    rich metadata from the creative side and create more engaging member experiences
    like [interactive storytelling](https://en.wikipedia.org/wiki/Black_Mirror:_Bandersnatch).
  id: totrans-split-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We expanded pipeline support to serve our studio/content-development use cases,
    which had different latency and resiliency requirements as compared to the traditional
    streaming use case.
  id: totrans-split-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Our experience of the last decade-and-a-half has reinforced our conviction that
    an efficient, flexible video processing pipeline that allows us to innovate and
    support our streaming service, as well as our studio partners, is critical to
    the continued success of Netflix. To that end, the Video and Image Encoding team
    in Encoding Technologies (ET) has spent the last few years rebuilding the video
    processing pipeline on our next-generation microservice-based computing platform
    [Cosmos](/the-netflix-cosmos-platform-35c14d9351ad).
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
- en: From Reloaded to Cosmos
  id: totrans-split-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Reloaded
  id: totrans-split-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Starting in 2014, we developed and operated the video processing pipeline on
    our third-generation platform [Reloaded](https://www.youtube.com/watch?v=JouA10QJiNc).
    Reloaded was well-architected, providing good stability, scalability, and a reasonable
    level of flexibility. It served as the foundation for numerous encoding innovations
    developed by our team.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
- en: 'When Reloaded was designed, we focused on a single use case: converting high-quality
    media files (also known as mezzanines) received from studios into compressed assets
    for Netflix streaming. Reloaded was created as a single monolithic system, where
    developers from various media teams in ET and our platform partner team Content
    Infrastructure and Solutions (CIS)¹ worked on the same codebase, building a single
    system that handled all media assets. Over the years, the system expanded to support
    various new use cases. This led to a significant increase in system complexity,
    and the limitations of Reloaded began to show:'
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
- en: '*Coupled functionality:* Reloaded was composed of a number of worker modules
    and an orchestration module. The setup of a new Reloaded module and its integration
    with the orchestration required a non-trivial amount of effort, which led to a
    bias towards augmentation rather than creation when developing new functionalities.
    For example, in Reloaded [the video quality calculation was implemented inside
    the video encoder module](/netflix-video-quality-at-scale-with-cosmos-microservices-552be631c113).
    With this implementation, it was extremely difficult to recalculate video quality
    without re-encoding.'
  id: totrans-split-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Monolithic structure*: Since Reloaded modules were often co-located in the
    same repository, it was easy to overlook code-isolation rules and there was quite
    a bit of unintended reuse of code across what should have been strong boundaries.
    Such reuse created tight coupling and reduced development velocity. The tight
    coupling among modules further forced us to deploy all modules together.'
  id: totrans-split-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Long release cycles*: The joint deployment meant that there was increased
    fear of unintended production outages as debugging and rollback can be difficult
    for a deployment of this size. This drove the approach of the “release train”.
    Every two weeks, a “snapshot” of all modules was taken, and promoted to be a “release
    candidate”. This release candidate then went through exhaustive testing which
    attempted to cover as large a surface area as possible. This testing stage took
    about two weeks. Thus, depending on when the code change was merged, it could
    take anywhere between two and four weeks to reach production.'
  id: totrans-split-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As time progressed and functionalities grew, the rate of new feature contributions
    in Reloaded dropped. Several promising ideas were abandoned owing to the outsized
    work needed to overcome architectural limitations. The platform that had once
    served us well was now becoming a drag on development.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
- en: Cosmos
  id: totrans-split-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As a response, in 2018 the CIS and ET teams started developing the next-generation
    platform, Cosmos. In addition to the scalability and the stability that the developers
    already enjoyed in Reloaded, Cosmos aimed to significantly increase system flexibility
    and feature development velocity. To achieve this, Cosmos was developed as a computing
    platform for workflow-driven, media-centric microservices.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
- en: The microservice architecture provides strong decoupling between services. Per-microservice
    workflow support eases the burden of implementing complex media workflow logic.
    Finally, relevant abstractions allow media algorithm developers to focus on the
    manipulation of video and audio signals rather than on infrastructural concerns.
    A comprehensive list of benefits offered by Cosmos can be found in the linked
    [blog](/the-netflix-cosmos-platform-35c14d9351ad).
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
- en: Building the Video Processing Pipeline in Cosmos
  id: totrans-split-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Service Boundaries
  id: totrans-split-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the microservice architecture, a system is composed of a number of fine-grained
    services, with each service focusing on a single functionality. So the first (and
    arguably the most important) thing is to identify boundaries and define services.
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
- en: In our pipeline, as media assets travel through creation to ingest to delivery,
    they go through a number of processing steps such as analyses and transformations.
    We analyzed these processing steps to identify “boundaries” and grouped them into
    different domains, which in turn became the building blocks of the microservices
    we engineered.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
- en: 'As an example, in Reloaded, the video encoding module bundles 5 steps:'
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
- en: 1\. divide the input video into small chunks
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
- en: 2\. encode each chunk independently
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
- en: 3\. calculate the quality score ([VMAF](/vmaf-the-journey-continues-44b51ee9ed12))
    of each chunk
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
- en: 4\. assemble all the encoded chunks into a single encoded video
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
- en: 5\. aggregate quality scores from all chunks
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
- en: From a system perspective, the assembled encoded video is of primary concern
    while the internal chunking and separate chunk encodings exist in order to fulfill
    certain latency and resiliency requirements. Further, as alluded to above, the
    video quality calculation provides a totally separate functionality as compared
    to the encoding service.
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从系统角度来看，组装后的编码视频是主要关注的内容，而内部分块和单独的分块编码存在是为了满足某些延迟和弹性需求。此外，正如上文所述，视频质量计算与编码服务提供的功能完全分离。
- en: 'Thus, in Cosmos, we created two independent microservices: Video Encoding Service
    (VES) and [Video Quality Service (VQS)](/netflix-video-quality-at-scale-with-cosmos-microservices-552be631c113),
    each of which serves a clear, decoupled function. As implementation details, the
    chunked encoding and the assembling were abstracted away into the VES.'
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在Cosmos中，我们创建了两个独立的微服务：视频编码服务（VES）和[视频质量服务（VQS）](/netflix-video-quality-at-scale-with-cosmos-microservices-552be631c113)，每个服务都提供清晰的、解耦的功能。在实施细节上，分块编码和组装被抽象为VES中的一部分。
- en: Video Services
  id: totrans-split-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 视频服务
- en: The approach outlined above was applied to the rest of the video processing
    pipeline to identify functionalities and hence service boundaries, leading to
    the creation of the following video services².
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: 上述方法被应用于视频处理管道的其余部分，以识别功能，并因此创建以下视频服务²。
- en: 'Video Inspection Service (VIS): This service takes a mezzanine as the input
    and performs various inspections. It extracts metadata from different layers of
    the mezzanine for downstream services. In addition, the inspection service flags
    issues if invalid or unexpected metadata is observed and provides actionable feedback
    to the upstream team.'
  id: totrans-split-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Video Inspection Service (VIS): 此服务以中间介质作为输入，并执行各种检查。它从中间介质的不同层提取元数据，以供下游服务使用。此外，检查服务在观察到无效或意外元数据时标记问题，并向上游团队提供可操作的反馈。'
- en: 'Complexity Analysis Service (CAS): The optimal encoding recipe is highly content-dependent.
    This service takes a mezzanine as the input and performs analysis to understand
    the content complexity. It calls Video Encoding Service for [pre-encoding](/dynamic-optimizer-a-perceptual-video-encoding-optimization-framework-e19f1e3a277f)
    and Video Quality Service for quality evaluation. The results are saved to a database
    so they can be reused.'
  id: totrans-split-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Complexity Analysis Service (CAS): 最佳编码配方高度依赖于内容。此服务以中间介质为输入，并执行分析以了解内容复杂性。它调用视频编码服务进行[预编码](/dynamic-optimizer-a-perceptual-video-encoding-optimization-framework-e19f1e3a277f)，并调用视频质量服务进行质量评估。结果保存到数据库中以便重复使用。'
- en: 'Ladder Generation Service (LGS): This service creates an entire bitrate ladder
    for a given encoding family (H.264, AV1, etc.). It fetches the complexity data
    from CAS and runs the optimization algorithm to create encoding recipes. The CAS
    and LGS cover much of the innovations that we have previously presented in our
    tech blogs ([per-title](http://techblog.netflix.com/2015/12/per-title-encode-optimization.html),
    [mobile encodes](http://techblog.netflix.com/2016/12/more-efficient-mobile-encodes-for.html),
    [per-shot](/optimized-shot-based-encodes-now-streaming-4b9464204830), [optimized
    4K encoding](/optimized-shot-based-encodes-for-4k-now-streaming-47b516b10bbb),
    etc.). By wrapping ladder generation into a separate microservice (LGS), we decouple
    the ladder optimization algorithms from the creation and management of complexity
    analysis data (which resides in CAS). We expect this to give us greater freedom
    for experimentation and a faster rate of innovation.'
  id: totrans-split-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Ladder Generation Service (LGS): 此服务为给定的编码家族（H.264、AV1等）创建整个比特率阶梯。它从CAS获取复杂性数据，并运行优化算法以创建编码配方。CAS和LGS涵盖了我们先前在技术博客中提出的大部分创新（[按标题](http://techblog.netflix.com/2015/12/per-title-encode-optimization.html)，[移动编码](http://techblog.netflix.com/2016/12/more-efficient-mobile-encodes-for.html)，[按镜头](/optimized-shot-based-encodes-now-streaming-4b9464204830)，[优化的4K编码](/optimized-shot-based-encodes-for-4k-now-streaming-47b516b10bbb)等）。通过将阶梯生成封装到一个独立的微服务（LGS）中，我们将阶梯优化算法与复杂性分析数据的创建和管理（驻留在CAS中）解耦。我们期望这将为我们提供更大的实验自由度和更快的创新速度。'
- en: 'Video Encoding Service (VES): This service takes a mezzanine and an encoding
    recipe and creates an encoded video. The recipe includes the desired encoding
    format and properties of the output, such as resolution, bitrate, etc. The service
    also provides options that allow fine-tuning latency, throughput, etc., depending
    on the use case.'
  id: totrans-split-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'Video Encoding Service (VES): 此服务以中间介质和编码配方作为输入，并创建编码视频。配方包括所需的编码格式和输出属性，如分辨率、比特率等。该服务还提供选项，允许根据使用情况进行延迟、吞吐量等的微调。'
- en: 'Video Validation Service (VVS): This service takes an encoded video and a list
    of expectations about the encode. These expectations include attributes specified
    in the encoding recipe as well as conformance requirements from the codec specification.
    VVS analyzes the encoded video and compares the results against the indicated
    expectations. Any discrepancy is flagged in the response to alert the caller.'
  id: totrans-split-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 视频验证服务（VVS）：该服务接收编码视频和编码预期清单作为输入。这些预期包括编码配方中指定的属性以及编解码器规范中的一致性要求。VVS 分析编码视频，并将结果与指定的预期进行比较。任何差异都会在响应中标记，以提醒调用方。
- en: '[Video Quality Service (VQS)](/netflix-video-quality-at-scale-with-cosmos-microservices-552be631c113):
    This service takes the mezzanine and the encoded video as input, and calculates
    the quality score (VMAF) of the encoded video.'
  id: totrans-split-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[视频质量服务（VQS）](/netflix-video-quality-at-scale-with-cosmos-microservices-552be631c113)：该服务以中介格式和编码视频作为输入，计算编码视频的质量分数（VMAF）。'
- en: Service Orchestration
  id: totrans-split-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务编排
- en: Each video service provides a dedicated functionality and they work together
    to generate the needed video assets. Currently, the two main use cases of the
    Netflix video pipeline are producing assets for member streaming and for studio
    operations. For each use case, we created a dedicated workflow orchestrator so
    the service orchestration can be customized to best meet the corresponding business
    needs.
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: 每个视频服务都提供专门的功能，并且它们协同工作以生成所需的视频资产。目前，Netflix 视频流水线的两个主要用例是为会员流媒体和制片厂运营生成资产。针对每个用例，我们创建了专用的工作流编排器，以便可以根据对应的业务需求进行定制化的服务编排。
- en: For the streaming use case, the generated videos are deployed to our content
    delivery network (CDN) for Netflix members to consume. These videos can easily
    be watched millions of times. The Streaming Workflow Orchestrator utilizes almost
    all video services to create streams for an impeccable member experience. It leverages
    VIS to detect and reject non-conformant or low-quality mezzanines, invokes LGS
    for encoding recipe optimization, encodes video using VES, and calls VQS for quality
    measurement where the quality data is further fed to Netflix’s data pipeline for
    analytics and monitoring purposes. In addition to video services, the Streaming
    Workflow Orchestrator uses audio and timed text services to generate audio and
    text assets, and packaging services to “containerize” assets for streaming.
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: 对于流媒体用例，生成的视频部署到我们的内容传输网络（CDN），供 Netflix 会员消费。这些视频可能会被观看数百万次。流媒体工作流编排器利用几乎所有视频服务，为会员提供卓越的观看体验。它利用
    VIS 检测和拒绝不符合规范或低质量的中介格式，调用 LGS 进行编码配方优化，使用 VES 编码视频，并调用 VQS 进行质量测量，质量数据进一步用于 Netflix
    的数据管道进行分析和监控。除视频服务外，流媒体工作流编排器还使用音频和定时文本服务生成音频和文本资产，以及使用打包服务将资产“容器化”供流媒体使用。
- en: For the studio use case, some example video assets are marketing clips and daily
    production editorial proxies. The requests from the studio side are generally
    latency-sensitive. For example, someone from the production team may be waiting
    for the video to review so they can decide the shooting plan for the next day.
    Because of this, the Studio Workflow Orchestrator optimizes for fast turnaround
    and focuses on core media processing services. At this time, the Studio Workflow
    Orchestrator calls VIS to extract metadata of the ingested assets and calls VES
    with predefined recipes. Compared to member streaming, studio operations have
    different and unique requirements for video processing. Therefore, the Studio
    Workflow Orchestrator is the exclusive user of some encoding features like forensic
    watermarking and timecode/text burn-in.
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: 对于制片厂用例，一些示例视频资产包括营销片段和每日制作编辑代理。来自制片方的请求通常对延迟敏感。例如，制作团队的某人可能正在等待视频进行审阅，以便决定第二天的拍摄计划。因此，制片工作流编排器优化以实现快速周转，并专注于核心媒体处理服务。此时，制片工作流编排器调用
    VIS 提取摄入资产的元数据，并使用预定义的配方调用 VES。与会员流媒体相比，制片运营对视频处理有不同且独特的需求。因此，制片工作流编排器独占一些编码功能，如取证水印和时间码/文本烧录。
