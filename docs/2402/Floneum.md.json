["```\nuse kalosm::language::*;   #[tokio::main] async fn main() {   // You can use tasks with llama, mistral or phi models.\n  let llm = Phi::new_chat();    // Now we can create a task. We will create a simple assistant that identifies keywords in a sentence.\n  let task = Task::builder(&llm, \"You are an assistant who identifies keywords in a sentence. When identifying keywords, you will output the keywords in a comma-separated list.\")   // You can optionally add constraints to the task.\n  // accept 2-5 keywords of 2-15 characters each\n .with_constraints(RegexParser::new(r#\"The keywords are:([ a-z]{2,15},){2,5}\"#).unwrap())   /// You can also add examples to the task to help the agent learn how to solve math problems.\n .with_example(\"What is the weather like in New York?\", \"The keywords are: weather, new york, \")\n .with_example(\"What is the capital of France?\", \"The keywords are: capital, france, \")\n .build();    // The first time we use the task, it will load the model and prompt which will take a bit longer.\n task.run(\"What is the temperature in Chicago?\", &llm)\n .await .unwrap()\n .to_std_out()\n .await .unwrap(); } \n```", "```\n// First, we need to create a Llama instance. We will use the default chat model (open chat) for this example. Tasks work with chat and text generation models. let mut llm = Llama::new_chat();   // Next (optionally), we can define constraints for the task. In this example, we will use a regex to validate the output of the task. let constraints =  RegexParser::new(r\"(Step \\d: \\d+ [+\\-*/] \\d+ = \\d+\\n){1,3}Output: \\d+\").unwrap();   // Now we can create a task. We will create a simple math problem solving task. let task = Task::builder(&llm, \"You are an assistant who solves math problems. When solving problems, you will always solve problems step by step with one step per line. Once you have solved the problem, you will output the result in the format 'Output: <result>'.\")  .with_constraints(constraints)   // You can also add examples to the task to help the agent learn how to solve math problems.  .with_example(\"What is 1 + 2?\", \"Step 1: 1 + 2 = 3\\nOutput: 3\")  .with_example(\"What is 3 + 4?\", \"Step 1: 3 + 4 = 7\\nOutput: 7\")  .with_example(\"What is (4 + 8) / 3?\", \"Step 1: 4 + 8 = 12\\nStep 2: 12 / 3 = 4\\nOutput: 4\")  .build();   // The first time we use the task, it will load the model and prompt which will take a bit longer. task.run(\"What is 2 + 2?\", &llm)  .await  .unwrap()  .to_std_out()  .await  .unwrap(); \n```", "```\nquestion 1 Step 1: 2 + 2 = 4 Output: 4. first question took: 18.371939709s question 2 Step 1: 4 + 4 = 8 Output: 8 second question took: 5.723529959s question 3 Step 1: 7 + 5 = 12 Step 2: 12 / 2 = 6 Output: 6 third question took: 9.303650625s \n```", "```\n+-----------------+-------+ | Statistic       | Value | +=========================+ | Mean            | 0.75 | |-----------------+-------| | Median          | 0.77 | |-----------------+-------| | Min             | 0.49 | |-----------------+-------| | Max             | 0.94 | |-----------------+-------| | 25th Percentile | 0.67 | |-----------------+-------| | 75th Percentile | 0.81 | +-----------------+-------+ +------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+--------------------+ | Expected Output                                                                          | Actual Output                                                                             | Score              | +===========================================================================================================================================================================================================+ | What are Floneum plugins?                                                                | What is designed to support an expanding ecosystem of plugins?                            | 0.49 (low outlier) | |------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+--------------------| | What is supervised learning in machine learning?                                         | What is required for machine learning models in order to make accurate predictions?       | 0.50 (low outlier) | |------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+--------------------| | What distinguishes open-source software from proprietary software?                       | What type of access does open source software provide for its users?                      | 0.64 | |------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+--------------------| | How does blockchain contribute to the security of cryptocurrencies?                      | What is the advantage of cryptocurrency over traditional currencies in terms of security? | 0.65 | |------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+--------------------| | What are the tradeoffs of using chat GPT?                                                | What is an example of how using ChatGPT may become challenging in certain situations?     | 0.65 | |------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+--------------------| | What is the relationship between DevOps, continuous integration and continuous delivery? | What is the main goal of DevOps?                                                          | 0.67 | |------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+--------------------| | ... 18 more                                                                              |                                                                                           | 0.80 (average)     | +------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------+--------------------+ | Score Histogram        | | 0.00 - 0.10:           | | 0.10 - 0.20:           | | 0.20 - 0.30:           | | 0.30 - 0.40:           | | 0.40 - 0.50: *         | | 0.50 - 0.60: *         | | 0.60 - 0.70: ******    | | 0.70 - 0.80: ********* | | 0.80 - 0.90: *****     | | 0.90 - 1.00: **        | \n```", "```\nconst EXAMPLES: &[(&str, &str)]= &[\n (\"An example input to the task\", \"An example output to the task\"),\n  // ...more examples ];   let llm = Phi::v2(); const PREFIX: &str = \"Questions that are answered by the previous text: \"; const QUESTION_STARTERS: [&str; 9] = [\n \"Who\", \"What\", \"When\", \"Where\", \"Why\", \"How\", \"Which\", \"Whom\", \"Whose\", ]; let constraints = LiteralParser::new(PREFIX).then(\n IndexParser::new(  QUESTION_STARTERS\n .iter()\n .copied()\n .map(LiteralParser::new)\n .collect::<Vec<_>>(), ) .then(StopOn::new(\"?\").filter_characters(\n |c| matches!(c, ' ' | '?' | 'a'..='z' | 'A'..='Z' | '0'..='9' | ','),\n )) .repeat(1..=5), ); let task = Task::builder(\"You generate hypothetical questions that may be answered by the given text. The questions restate any information necessary to understand the question\")\n .with_constraints(constraints); let mut annealing = kalosm::PromptAnnealer::builder(&llm, EXAMPLES, task)\n .with_initial_temperature(0.6)\n .with_initial_choice_range(1..4)\n .build()\n .await;   let result = annealing.run().await;   println!(\"Result: {:?}\", result); \n```", "```\nuse kalosm::language::*;   #[tokio::main] async fn main() {\n  let llm = Llama::default();  let prompt = \"Generate a list of 10 words you use to describe yourself: \";    let validator = LiteralParser::new(\"(Responding as a pirate) \").then(OneLine);\n  let stream = llm.stream_structured_text(prompt, validator).await.unwrap();   stream.to_std_out().await.unwrap(); } \n```", "```\nuse kalosm::language::*;   #[tokio::main] async fn main() {\n  let llm = Llama::default();  let prompt = \"Prime numbers: \";    let validator = <[f32; 10] as HasParser>::new_parser();\n  let words = llm.stream_structured_text(prompt, validator).await.unwrap();    let result: [f32; 10] = words.result().await.unwrap();\n println!(\"Prime numbers: {:?}\", result); } \n```", "```\nuse kalosm::language::*;   #[tokio::main] async fn main() {\n  let llm = Llama::default();  let prompt = \"Generate a list of 10 words you use to describe yourself: \";    let validator = RegexParser::new(r\"\\(Responding as a pirate\\) ([a-z]{1,10}, ){10}\").unwrap();\n  let stream = llm.stream_structured_text(prompt, validator).await.unwrap();   stream.to_std_out().await.unwrap(); } \n```", "```\nuse comfy_table::{Cell, Color, Row, Table}; use kalosm::language::*; use kalosm::*; use std::path::PathBuf; use surrealdb::{engine::local::RocksDb, Surreal};   let exists = std::path::Path::new(\"./db\").exists();   // Create or open a new database at ./db/temp.db let db = Surreal::new::<RocksDb>(\"./db/temp.db\").await.unwrap();   // Select a specific namespace / database within the database db.use_ns(\"test\").use_db(\"test\").await.unwrap();   // Create a new document table that uses arroy for fast vector search let document_table = db .document_table_builder(\"documents\")\n  // Store the embedding database in the same directory as the document table\n .at(\"./db/embeddings.db\")\n .build()\n .unwrap();   // If the database doesn't exist, create it and insert some documents if !exists {\n std::fs::create_dir_all(\"documents\").unwrap();\n  // Load some files from a directory\n  let documents = DocumentFolder::try_from(PathBuf::from(\"./documents\")).unwrap();    // Convert the folder into a vector of documents\n  let documents = documents.into_documents().await.unwrap();\n  for document in documents {  // And insert the documents into the table (this will automatically chunk and embed the documents before they are inserted into the table and vector database)\n document_table.insert(document).await.unwrap();\n } }   // Now we can query the table for similar documents based on the meaning of the text loop {\n  // Get a query from the user and embed that query into a vector\n  let user_question = prompt_input(\"Query: \").unwrap();\n  let user_question_embedding = document_table .embedding_model_mut()\n .embed(&user_question)\n .await .unwrap();    // Select the 5 most similar documents to the user's query\n  let nearest_5 = document_table .select_nearest_embedding(user_question_embedding, 5)\n .await .unwrap();    // Display the results in a formatted table with colors based on the distance from the query\n  let mut table = Table::new(); table.set_header(vec![\"Score\", \"Value\"]);    for result in nearest_5 {  let mut row = Row::new();  let color = if result.distance < 0.25 {\n Color::Green } else if result.distance < 0.75 {\n Color::Yellow } else {\n Color::Red }; row.add_cell(Cell::new(result.distance).fg(color))\n .add_cell(Cell::new(result.record.body()[0..50].to_string() + \"...\"));\n table.add_row(row);\n }   println!(\"{}\", table); } \n```", "```\nlet constraints = RegexParser::new(r#\"(The title of the book is [a-z]{2,15}\\n)*\"#).unwrap(); \n```"]