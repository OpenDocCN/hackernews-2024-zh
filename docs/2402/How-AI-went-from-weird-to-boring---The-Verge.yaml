- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:55:19'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: How AI went from weird to boring - The Verge
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://www.theverge.com/24067999/ai-bot-chatgpt-chatbot-dungeon](https://www.theverge.com/24067999/ai-bot-chatgpt-chatbot-dungeon)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'In 2018, a viral joke started going around the internet: scripts based on “making
    a bot watch 1,000 hours” of just about anything. The premise (concocted by comedian
    Keaton Patti) was that you could train an artificial intelligence model on vast
    quantities of *Saw* films, Hallmark specials, or Olive Garden commercials and
    get back a bizarre funhouse-mirror version with lines like “lasagna wings with
    extra Italy” or “her mouth is full of secret soup.” The scripts almost certainly
    weren’tactually written by a bot, but the joke conveyed a common cultural understanding:
    AI was *weird*.'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: Strange AI was everywhere a few years ago. *AI Dungeon*, a text adventure game
    genuinely powered by OpenAI’s GPT-2 and GPT-3, touted its ability to produce deeply
    imagined stories about the inner life of a chair. The first well-known AI art
    tools, like Google’s [computer vision program Deep Dream](/2015/8/5/9104121/dreamify-app-google-deep-dream-ios-android),
    produced unabashedly bizarre [Giger-esque nightmares](/2016/10/24/13379208/ai-nsfw-neural-nets-deep-dream-genitals).
    Perhaps the archetypal example was Janelle Shane’s blog *AI Weirdness*, where
    Shane trained models to create physically impossible nuclear waste warnings or
    sublimely inedible recipes. “Made by a bot” was shorthand for a kind of free-associative,
    nonsensical surrealism — both because of the models’ technical limitations and
    because they were more curiosities than commercial products. Lots of people had
    *seen* what “a bot” (actually or supposedly) produced. Fewer had used one. Even
    fewer had to worry about them in day-to-day life.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: But soon, generative AI tools would explode in popularity. And as they have,
    the cultural shorthand of “chatbot” has changed dramatically — because AI is getting
    boring.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: “If you want to really hurt someone’s feelings in the year 2023, just call them
    an AI,” suggested Caroline Mimbs Nyce in *The Atlantic* last May. Nyce charted
    the rise of “AI” as a term of derision — referring to material that was “dull
    or uninspired, riddled with clich​​és and recycled ideas.” The insult would reach
    new heights at the start of the Republican primary cycle in August, when former
    New Jersey governor Chris Christie dissed rival Vivek Ramaswamy as “a guy who
    sounds like ChatGPT.”
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
- en: And with that, “AI” — as an aesthetic or as a cultural descriptor — stopped
    signifying *weird* and is pretty much just shorthand for *mediocre*.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
- en: The insult would reach new heights at the start of the Republican primary cycle
    in August, when former New Jersey governor Chris Christie dissed rival Vivek Ramaswamy
    as “a guy who sounds like ChatGPT.”
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
- en: Part of the shift stems from AI tools getting dramatically better. The surrealism
    of early generative work was partially a byproduct of its deep limitations. Early
    text models, for instance, had limited memory that made it tough to maintain narrative
    or even grammatical continuity. That produced the trademark dream logic of systems
    like early *AI Dungeon*, where stories drifted between settings, genres, and protagonists
    over the span of sentences.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这种转变的部分原因是AI工具显著改善。早期生成作品的超现实主义部分是其深刻局限性的副产品。例如，早期的文本模型记忆有限，难以维持叙述甚至语法的连贯性。这导致了像早期的*AI
    Dungeon*这样的系统特有的梦幻逻辑，故事在句子间漂移，跨越场景、流派和主人公。
- en: When director Oscar Sharp and researcher Ross Goodwin created the [2016 AI-written
    short film *Sunspring*](https://arstechnica.com/gaming/2021/05/an-ai-wrote-this-movie-and-its-strangely-moving/),
    for instance, the bot they trained to make it couldn’t even “learn” the patterns
    behind proper names — resulting in characters dubbed H, H2, and C. Its dialogue
    is technically correct but almost Borgesian in its oddity. “You should see the
    boys and shut up,” H2 snaps during the film’s opening scene, in which no boys
    have been mentioned. “I was the one who was going to be a hundred years old.”
    Less than a decade later, a program like Sudowrite (built on OpenAI’s GPT-3.5
    and GPT-4 models) can spit out paragraphs of text that closely imitates cliched
    genre prose.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当导演奥斯卡·夏普和研究员罗斯·古德温创作了[2016年由AI编写的短片《Sunspring》](https://arstechnica.com/gaming/2021/05/an-ai-wrote-this-movie-and-its-strangely-moving/)时，他们训练的机器人甚至无法“学习”正确姓名背后的模式，导致角色被称为H、H2和C。它的对话在技术上是正确的，但在奇异性上几乎像博尔赫斯笔下的作品。“你应该看到那些男孩，然后闭嘴，”在电影开场场景中，H2急切地说道，而此时还未提及任何男孩。“我原本是要活到一百岁的那个人。”不到十年后，像Sudowrite（建立在OpenAI的GPT-3.5和GPT-4模型之上）这样的程序能够输出大段文本，几乎模仿了陈词滥调的流派文风。
- en: But AI has also been pushed deliberately away from intriguing strangeness and
    toward banal interactions that often end up wasting humans’ time and money. As
    companies fumble toward a profitable vision of generative artificial intelligence,
    AI tools are becoming big business by blossoming into the least interesting version
    of themselves.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 但AI也被刻意推向有趣的奇异感觉，向平庸的互动靠拢，这往往最终浪费了人类的时间和金钱。随着公司摸索出一个盈利的生成人工智能愿景，AI工具通过开花结果变成了它们最不引人注目的版本。
- en: AI is everywhere right now, including many places it fits poorly. Google and
    Microsoft are pitching it as a search engine — a tool whose core purpose is pointing
    users to facts and information — despite a deep-seated propensity to completely
    make things up. Media outlets have made some [interesting attempts](https://www.nytimes.com/2023/05/23/business/media/buzzfeed-botatouille-chatbot-food.html)
    at leveraging AI’s strengths, but it’s most visible in low-quality spam that’s
    neither informative nor (intentionally) entertaining, designed purely to lure
    visitors into loading a few ads. AI image generators have shifted from being seen
    as [bespoke artistic experiments](https://www.sciencefriday.com/segments/luke-sciarts-video/)
    to [alienating huge swathes](/2024/1/9/24031468/wacom-wizards-of-the-coast-mtg-artists-against-generative-ai)
    of the creative community; they’re now overwhelmingly associated with badly executed
    stock art and invasive pornographic deepfakes, [dubbed](https://www.garbageday.email/p/the-digital-equivalent-of-wearing)
    the digital equivalent of “a fake Chanel bag.”
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: AI现在无处不在，甚至在许多不适合的地方。谷歌和微软将其作为搜索引擎来推广，这种工具的核心目的是指导用户找到事实和信息，尽管它有根深蒂固的倾向完全捏造事实。媒体曾试图利用AI的优势进行一些[有趣的尝试](https://www.nytimes.com/2023/05/23/business/media/buzzfeed-botatouille-chatbot-food.html)，但它最为显眼的是低质量的垃圾邮件，既不具信息性也（有意）不娱乐，纯粹是为了诱使访客加载广告。AI图像生成器已从被视为[独特艺术实验](https://www.sciencefriday.com/segments/luke-sciarts-video/)转变为[疏远创意社区的大片面积](/2024/1/9/24031468/wacom-wizards-of-the-coast-mtg-artists-against-generative-ai)，如今它们主要与执行不佳的库存艺术和侵入性淫秽深假相关联，被称为“数字上的假香奈儿包”。
- en: AI tools are becoming big business by blossoming into the least interesting
    versions of themselves
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: AI工具正变得愈发重要，演变为最不引人注目的版本。
- en: And as the stakes around AI tools’ safety have risen, guardrails and training
    seem to be making them less receptive to creatively unorthodox uses. In early
    2023, [Shane posted transcripts](https://www.aiweirdness.com/the-ai-weirdness-hack/)
    of ChatGPT refusing to play along with scenarios like being a squirrel or creating
    a dystopian sci-fi technology, delivering [its now-trademark](/2023/4/25/23697218/ai-generated-spam-fake-user-reviews-as-an-ai-language-model)
    “I’m sorry, but as an AI language model” short-circuit. Shane had to resort to
    stage-setting with what she dubbed the “AI Weirdness hack,” telling ChatGPT to
    imitate older versions of AI models producing funny responses for a blog about
    weird AI. The AI Weirdness hack has proven surprisingly adept at getting AI tools
    like Bloom to shift from dull or human-replicating results to word-salad surrealism,
    an outcome Shane herself has found a little bit unsettling. “It is creepy to me,”
    she [mused in one post](https://www.aiweirdness.com/baby-onesie-designs/), “that
    the only reason this method gets BLOOM to generate weird designs is because I
    spent years seeding internet training data with lists of weird AI-generated text.”
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 随着AI工具安全性的提升，防护措施和培训似乎使它们对创造性不正规用途的接受程度降低。早在2023年初，[Shane发布了ChatGPT拒绝配合的文字记录](https://www.aiweirdness.com/the-ai-weirdness-hack/)，如不愿扮演松鼠或创造反乌托邦科技，最终达到了[其如今的标志性](/2023/4/25/23697218/ai-generated-spam-fake-user-reviews-as-an-ai-language-model)“很抱歉，但作为AI语言模型”短路。Shane不得不采取她所称的“AI怪异性黑客”手法，告诉ChatGPT模仿旧版本的AI模型产生有趣的回复，用于关于奇怪AI的博客。AI怪异性黑客已经证明非常擅长，使像Bloom这样的AI工具从枯燥或人类复制的结果转向词汇沙拉式的超现实主义，这一结果本身让Shane有些不安。“对我来说很恐怖，”她在一篇[文章中沉思道](https://www.aiweirdness.com/baby-onesie-designs/)，“这种方法让BLOOM生成奇怪设计的唯一原因是我花了几年时间用奇怪的AI生成文本列表来种植互联网训练数据。”
- en: AI tools are still plenty capable of being funny, but it’s most often due to their
    over-the-top performance of commercialized inanity. Witness, [for instance](/2024/1/12/24036156/openai-policy-amazon-ai-listings),
    the “I apologize but I cannot fulfill this request” table-and-chair set on Amazon,
    whose selling points include being “crafted with materials” and “saving you valuable
    and effort.” (You can pay a spammer nearly $2,000 for it, which is less amusing.)
    Or a [sports-writing bot’s detail-free recaps](https://www.washingtonpost.com/nation/2023/08/31/gannett-ai-written-stories-high-school-sports/)
    of matches, complete with odd phrases like “close encounter of the athletic kind.”
    ChatGPT’s absurdity is situational — reliant on real people doing [painfully serious
    work](/2023/12/29/24019067/michael-cohen-former-trump-lawyer-google-bard-ai) with
    a tool they overestimate or fundamentally misunderstand.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: AI工具依然有着足够的幽默潜力，但最常见的原因是它们过度商业化的愚蠢表现。例如，见[这里](/2024/1/12/24036156/openai-policy-amazon-ai-listings)，亚马逊上的“我很抱歉，但我无法完成此请求”桌椅套装，其销售点包括“用材精良”和“节省宝贵和努力”。（你可以花近$2,000买到它，这更少见）。或者是[体育写作机器人的简略复盘](https://www.washingtonpost.com/nation/2023/08/31/gannett-ai-written-stories-high-school-sports/)，充满奇怪短语如“体育界的近距离接触”。ChatGPT的荒谬在于情境
    —— 它依赖于真正的人们用他们高估或基本误解的工具做[令人痛苦的严肃工作](/2023/12/29/24019067/michael-cohen-former-trump-lawyer-google-bard-ai)。
- en: It’s possible we’re simply in an awkward in-between phase for creative AI use.
    AI models are hitting the uncanny valley between “so bad it’s good” and “good
    enough to be bad,” and perhaps with time we’ll see them become genuinely good,
    adept at remixing information in a way that feels fresh and unexpected. Maybe
    the schism between artists and AI developers will resolve, and we’ll see more
    tools that amplify human idiosyncrasy instead of offering a lowest-common-denominator
    replacement for it. At the very least, it’s still possible to guide AI tools into
    clever juxtaposition — like a biblical verse about [removing a sandwich from a
    VCR](https://twitter.com/tqbf/status/1598513757805858820?lang=en) or a [hilariously
    overconfident evaluation](https://www.aiweirdness.com/ascii-art-by-chatbot/) of
    ChatGPT’s art skills. But for now, you probably won’t want to read anything that
    sounds “like a bot” any time soon.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们可能正处于创意AI使用的尴尬过渡阶段。AI模型正处于“如此糟糕以至于好笑”和“足够糟糕以至于变得好笑”的怪异谷之中，也许随着时间的推移，它们会变得真正出色，擅长以新颖和意想不到的方式重新混合信息。也许艺术家与AI开发者之间的分歧将得到解决，我们将看到更多能够增强人类特异性而非仅仅提供最低共同分母替代的工具。至少，目前仍然可以将AI工具引导到巧妙的并置之中
    —— 就像圣经中关于[从录像机中取出三明治](https://twitter.com/tqbf/status/1598513757805858820?lang=en)的一节或者[ChatGPT艺术技能的极度自信评估](https://www.aiweirdness.com/ascii-art-by-chatbot/)。但是目前，你可能不想很快阅读任何听起来“像机器人”的东西。
