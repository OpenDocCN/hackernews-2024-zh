- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-29 13:19:30'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: Jim Keller criticizes Nvidia's CUDA, x86 — 'Cuda’s a swamp, not a moat. x86
    was a swamp too' | Tom's Hardware
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://www.tomshardware.com/tech-industry/artificial-intelligence/jim-keller-criticizes-nvidias-cuda-and-x86-cudas-a-swamp-not-a-moat-x86-was-a-swamp-too](https://www.tomshardware.com/tech-industry/artificial-intelligence/jim-keller-criticizes-nvidias-cuda-and-x86-cudas-a-swamp-not-a-moat-x86-was-a-swamp-too)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Jim Keller](https://www.tomshardware.com/tech-industry/artificial-intelligence/jim-keller-responds-to-sam-altmans-plan-to-raise-dollar7-billion-to-make-ai-chips),
    a legendary processor architect who has worked on x86, Arm, MISC, and RISC-V processors,
    this weekend criticized [Nvidia''s CUDA](https://www.tomshardware.com/reviews/nvidia-cuda-gpu,1954.html)
    architecture and software stack and likened it to x86, which he called a swamp.
    He pointed out that even Nvidia itself has multiple special-purpose software packages
    that rely on open-source frameworks for performance reasons.'
  prefs: []
  type: TYPE_NORMAL
- en: '"CUDA is a swamp, not a moat," Keller wrote in [an X post](https://twitter.com/jimkxa/status/1758943525662769498).
    "x86 was a swamp too. […] CUDA is not beautiful. It was built by piling on one
    thing at a time."'
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, just like x86, CUDA has gradually added functionality while maintaining
    backward compatibility in software and hardware. This makes Nvidia's platform
    complete and backward compatible, but it affects performance and makes program
    development harder. Meanwhile, many open-source software development frameworks
    can be used more efficiently than CUDA.
  prefs: []
  type: TYPE_NORMAL
- en: '"Basically nobody writes CUDA," wrote Keller in a follow-up post. "If you do
    write CUDA, it is probably not fast. […] There is a good reason there is Triton,
    Tensor RT, Neon, and Mojo."'
  prefs: []
  type: TYPE_NORMAL
- en: Even Nvidia itself has tools that do not exclusively rely on CUDA. For example, Triton
    Inference Server is an open-source tool by Nvidia that simplifies deploying AI
    models at scale, supporting frameworks like TensorFlow, PyTorch, and ONNX. Triton
    also provides features like model versioning, multi-model serving, and concurrent
    model execution to optimize the utilization of GPU and CPU resources.
  prefs: []
  type: TYPE_NORMAL
- en: Nvidia's [TensorRT](https://www.tomshardware.com/news/nvidia-boosts-ai-performance-with-tensorrt)
    is a high-performance deep learning inference optimizer and runtime library that
    accelerates deep learning inference on [Nvidia GPUs](https://www.tomshardware.com/reviews/gpu-hierarchy,4388.html).
    TensorRT takes trained models from various frameworks, such as TensorFlow and
    PyTorch, and optimizes them for deployment, reducing latency and increasing throughput
    for real-time applications like image classification, object detection, and natural
    language processing.
  prefs: []
  type: TYPE_NORMAL
- en: But although architectures like [Arm](https://www.tomshardware.com/news/intel-foundry-and-arm-to-collaborate-on-18nm-mobile-socs),
    CUDA, and [x86](https://www.tomshardware.com/features/zhaoxin-kx-u6780a-x86-cpu-tested)
    might be considered swamps because of their relatively slow evolution, mandated
    backward compatibility, and bulkiness, these platforms are also not as fragmented
    as things like [GPGPU](https://www.tomshardware.com/reviews/nvidia-cuda-gpu,1954-4.html),
    which may not be a bad thing at all.
  prefs: []
  type: TYPE_NORMAL
- en: Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.
  prefs: []
  type: TYPE_NORMAL
- en: It isn't clear what Jim Keller thinks of AMD's [ROCm](https://www.tomshardware.com/news/amd-enables-rocm-and-pytorch-on-radeon-rx-7900-xtx)
    and Intel's [OneAPI](https://www.tomshardware.com/news/intel-bringing-oneapi-to-gaming-rendering-toolkit-xe-graphics),
    but it is clear that even though he spent many years of his life designing x86
    architectures, he isn't enamored with its future prospects. His statements also
    imply that even though he has worked stints at some of the largest chipmakers
    in the world, including the likes of Apple, Intel, AMD, Broadcom (and now [Tenstorrent](https://www.tomshardware.com/news/tenstorrent-shares-roadmap-of-ultra-high-performance-risc-v-cpus-and-ai-accelerators)),
    we might not see his name on the Nvidia roster any time soon.
  prefs: []
  type: TYPE_NORMAL
