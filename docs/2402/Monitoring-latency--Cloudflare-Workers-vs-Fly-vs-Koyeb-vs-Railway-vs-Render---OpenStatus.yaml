- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: Êú™ÂàÜÁ±ª'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 14:59:42'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'Monitoring latency: Cloudflare Workers vs Fly vs Koyeb vs Railway vs Render
    | OpenStatus'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Êù•Ê∫êÔºö[https://www.openstatus.dev/blog/monitoring-latency-cf-workers-fly-koyeb-raylway-render](https://www.openstatus.dev/blog/monitoring-latency-cf-workers-fly-koyeb-raylway-render)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ‚ö†Ô∏è We are using the default settings for each provider and conducting datacenter
    to datacenter requests. A real-world application's results are going to be different.
    ‚ö†Ô∏è
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You want to know which cloud providers offer the lowest latency?
  prefs: []
  type: TYPE_NORMAL
- en: In this post, I compare the latency of [Cloudflare Workers](#cloudflare-workers),
    [Fly](#flyio), [Koyeb](#koyeb), [Railway](#railway) and [Render](#render) using
    [OpenStatus](https://www.openstatus.dev).
  prefs: []
  type: TYPE_NORMAL
- en: I deployed the application on the cheapest or free tier offered by each provider.
  prefs: []
  type: TYPE_NORMAL
- en: For this test, I used a basic [Hono](https://hono.dev) server that returns a
    simple text response.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You can find the code [here](https://github.com/openstatusHQ/status-code), it‚Äôs
    open source üòâ.
  prefs: []
  type: TYPE_NORMAL
- en: OpenStatus monitored our endpoint every **10 minutes** from **6 locations**
    located in Amsterdam, Ashburn, Hong Kong, Johannesburg, Sao Paulo and Sydney.
  prefs: []
  type: TYPE_NORMAL
- en: It's a good way to test our own product and improve it.
  prefs: []
  type: TYPE_NORMAL
- en: Let's analyze the data from the past two weeks.
  prefs: []
  type: TYPE_NORMAL
- en: Cloudflare workers[](#cloudflare-workers)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cloudflare Workers is a serverless platform by Cloudflare. It lets you build
    new applications using JavaScript/Typescript. You can deploy up to 100 worker
    scripts for free, running on more than 275 network locations.
  prefs: []
  type: TYPE_NORMAL
- en: Latency metrics[](#latency-metrics)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Timing metrics[](#timing-metrics)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Region | DNS (ms) | Connection (ms) | TLS Handshake (ms) | TTFB (ms) | Transfert
    (ms) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AMS | 17 | 2 | 17 | 27 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| GRU | 38 | 2 | 13 | 28 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| HKG | 19 | 2 | 13 | 29 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| IAD | 24 | 1 | 14 | 30 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | 123 | 168 | 182 | 185 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| SYD | 51 | 1 | 11 | 25 | 0 |'
  prefs: []
  type: TYPE_TB
- en: I can notice that Johannesburg's latency is about ten times higher than that
    of the other monitors.
  prefs: []
  type: TYPE_NORMAL
- en: From the Cloudflare request I can get the location of the workers that handle
    the request, with `Cf-ray` in the headers response.
  prefs: []
  type: TYPE_NORMAL
- en: '| Checker region | Workers region | number of request |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| HKG | HKG | 1831 |'
  prefs: []
  type: TYPE_TB
- en: '| SYD | SYD | 1831 |'
  prefs: []
  type: TYPE_TB
- en: '| AMS | AMS | 1831 |'
  prefs: []
  type: TYPE_TB
- en: '| IAD | IAD | 1831 |'
  prefs: []
  type: TYPE_TB
- en: '| GRU | GRU | 1791 |'
  prefs: []
  type: TYPE_TB
- en: '| GRU | GIG | 40 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | AMS | 741 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | MUC | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | HKG | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | SIN | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | NRT | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | EWR | 10 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | CDG | 82 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | FRA | 276 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | LHR | 699 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | AMS | 741 |'
  prefs: []
  type: TYPE_TB
- en: I can see all the request from JNB is never routed to a nearby data-center.
  prefs: []
  type: TYPE_NORMAL
- en: Apart from the strange routing error in Johannesburg, Cloudflare workers are
    fast worldwide.
  prefs: []
  type: TYPE_NORMAL
- en: I have not experienced any cold start issues.
  prefs: []
  type: TYPE_NORMAL
- en: Fly.io[](#flyio)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Fly.io simplifies deploying and running server-side applications globally. Developers
    can deploy their applications near users worldwide for low latency and high performance.
    It uses a lightweight Firecracker VM to easily deploy Docker images.
  prefs: []
  type: TYPE_NORMAL
- en: Latency metrics[](#latency-metrics-1)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Timing metrics[](#timing-metrics-1)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Region | DNS (ms) | Connection (ms) | TLS Handshake (ms) | TTFB (ms) | Transfert
    (ms) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AMS | 6 | 1 | 8 | 1469 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| GRU | 5 | 0 | 4 | 1431 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| HKG | 4 | 0 | 5 | 1473 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| IAD | 3 | 0 | 5 | 1470 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | 24 | 0 | 5 | 1423 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| SYD | 3 | 0 | 3 | 1489 | 0 |'
  prefs: []
  type: TYPE_TB
- en: The DNS is fast, our checker is attempting to connect to a region in the same
    data center, but our machine's cold start is slowing us down, leading to the high
    TTFB.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here‚Äôs our config for Fly.io:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The primary region of our server is Amsterdam, and the fly instances is getting
    paused after a period of inactivity.
  prefs: []
  type: TYPE_NORMAL
- en: The machine starts slowly, as indicated by the logs showing a start time of
    `1.513643778s.`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: OpenStatus Prod metrics[](#openstatus-prod-metrics)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you update your fly.toml file to include the following, you can get the zero
    cold start and achieve a better latency.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This is our data for our production server deploy on Fly.io.
  prefs: []
  type: TYPE_NORMAL
- en: We use Fly.io in production, and the machine never sleeps, yielding much better
    results.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Koyeb[](#koyeb)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Koyeb is a developer-friendly serverless platform that allows for global app
    deployment without the need for operations, servers, or infrastructure management.
    Koyeb offers a free Starter plan that includes one Web Service, one Database service.
    The platform focuses on ease of deployment and scalability for developers
  prefs: []
  type: TYPE_NORMAL
- en: Latency metrics[](#latency-metrics-2)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Timing metrics[](#timing-metrics-2)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Region | DNS (ms) | Connection (ms) | TLS Handshake (ms) | TTFB (ms) | Transfert
    (ms) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AMS | 50 | 2 | 17 | 107 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| GRU | 139 | 65 | 75 | 407 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| HKG | 48 | 2 | 13 | 321 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| IAD | 35 | 1 | 12 | 129 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | 298 | 1 | 11 | 720 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| SYD | 97 | 1 | 10 | 711 | 0 |'
  prefs: []
  type: TYPE_TB
- en: 'The request headers show that none of our requests are cached. They contain
    `cf-cache-status: dynamic`. Cloudflare handles the Koyeb edge layer. [https://www.koyeb.com/blog/building-a-multi-region-service-mesh-with-kuma-envoy-anycast-bgp-and-mtls](https://www.koyeb.com/blog/building-a-multi-region-service-mesh-with-kuma-envoy-anycast-bgp-and-mtls)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our requests follow this route:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Let‚Äôs see where did we hit the cf workers
  prefs: []
  type: TYPE_NORMAL
- en: '| Checker region | Workers region | number of request |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AMS | AMS | 1866 |'
  prefs: []
  type: TYPE_TB
- en: '| GRU | GRU | 504 |'
  prefs: []
  type: TYPE_TB
- en: '| GRU | IAD | 38 |'
  prefs: []
  type: TYPE_TB
- en: '| GRU | MIA | 688 |'
  prefs: []
  type: TYPE_TB
- en: '| GRU | EWR | 337 |'
  prefs: []
  type: TYPE_TB
- en: '| GRU | CIG | 299 |'
  prefs: []
  type: TYPE_TB
- en: '| HKG | HKG | 1866 |'
  prefs: []
  type: TYPE_TB
- en: '| IAD | IAD | 1866 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | JNB | 1861 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | AMS | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| SYD | SYD | 1866 |'
  prefs: []
  type: TYPE_TB
- en: 'Koyeb Global Load Balancer region we hit:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Checker region | Koyeb Global Load Balancer | number of request |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AMS | FRA1 | 1866 |'
  prefs: []
  type: TYPE_TB
- en: '| GRU | WAS1 | 1866 |'
  prefs: []
  type: TYPE_TB
- en: '| HKG | SIN1 | 1866 |'
  prefs: []
  type: TYPE_TB
- en: '| IAD | WAS1 | 1866 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | PAR1 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | SIN1 | 1864 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | FRA1 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | SIN1 | 1866 |'
  prefs: []
  type: TYPE_TB
- en: I have deployed our app in the Frankfurt data-center.
  prefs: []
  type: TYPE_NORMAL
- en: Railway[](#railway)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Railway is a cloud platform designed for building, shipping, and monitoring
    applications without the need for Platform Engineers. It simplifies the application
    development process by offering seamless deployment and monitoring capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Latency metrics[](#latency-metrics-3)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Timing metrics[](#timing-metrics-3)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Region | DNS (ms) | Connection (ms) | TLS Handshake (ms) | TTFB (ms) | Transfert
    (ms) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AMS | 9 | 21 | 18 | 158 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| GRU | 14 | 115 | 127 | 178 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| HKG | 8 | 45 | 54 | 225 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| IAD | 7 | 2 | 14 | 65 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | 18 | 193 | 178 | 319 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| SYD | 21 | 108 | 105 | 280 | 0 |'
  prefs: []
  type: TYPE_TB
- en: The headers don't provide any information.
  prefs: []
  type: TYPE_NORMAL
- en: Railway is using Google Cloud Platform. It‚Äôs the only service that does not
    allow us to pick a specific region on the free plan. Our test app will be located
    to `us-west1` Portland, Oregon. We can see that the latency is the lowest in IAD.
  prefs: []
  type: TYPE_NORMAL
- en: By default our app did not scale down to 0\. It was always running. We don't
    have any cold start.
  prefs: []
  type: TYPE_NORMAL
- en: Render[](#render)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Render is a platform that simplifies deploying and scaling web applications
    and services. It offers features like automated SSL, automatic scaling, native
    support for popular frameworks, and one-click deployments from Git. The platform
    focuses on simplicity and developer productivity.
  prefs: []
  type: TYPE_NORMAL
- en: Latency metrics[](#latency-metrics-4)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Timing metrics[](#timing-metrics-4)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '| Region | DNS (ms) | Connection (ms) | TLS Handshake (ms) | TTFB (ms) | Transfert
    (ms) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AMS | 20 | 2 | 7 | 107 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| GRU | 61 | 2 | 6 | 407 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| HKG | 76 | 2 | 6 | 321 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| IAD | 15 | 1 | 5 | 129 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| JNB | 36 | 161 | 167 | 720 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| SYD | 103 | 1 | 4 | 711 | 0 |'
  prefs: []
  type: TYPE_TB
- en: The headers don't provide any information.
  prefs: []
  type: TYPE_NORMAL
- en: I have deployed our app in the Frankfurt data-center.
  prefs: []
  type: TYPE_NORMAL
- en: According to the Render docs, the free tier will shut down the service after
    15 minutes of inactivity. However, our app is being accessed by a monitor every
    10 minutes. We should never scale down to 0.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: I think the failures are due to the cold start of our app. We have a default
    timeout of 30s and the render app takes up to 50s to start.We might have hit an
    inflection point between cold and warm.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion[](#conclusion)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Here are the results of our test:'
  prefs: []
  type: TYPE_NORMAL
- en: '| Provider | Uptime | Fails Ping | Total Pings | AVG latency (ms) | P75 (ms)
    | P90 (ms) | P95 (ms) | P99 (ms) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| CF Workers | 100 | 0 | 10,956 | 182 | 138 | 690 | 778 | 991 |'
  prefs: []
  type: TYPE_TB
- en: '| Fly.io | 100 | 0 | 10,952 | 1,471 | 1,514 | 1,555 | 1,626 | 2,547 |'
  prefs: []
  type: TYPE_TB
- en: '| Koyeb | 100 | 0 | 10,955 | 536 | 738 | 881 | 1,013 | 1,525 |'
  prefs: []
  type: TYPE_TB
- en: '| Railway | 99.991 | 1 | 10,955 | 381 | 469 | 653 | 661 | 850 |'
  prefs: []
  type: TYPE_TB
- en: '| Render | 99.89 | 12 | 10,946 | 451 | 447 | 591 | 707 | 902 |'
  prefs: []
  type: TYPE_TB
- en: If you value low latency, Cloudflare Workers are the best option for fast global
    performance without cold start issues. They deploy your app worldwide efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: For multi-region deployment, check out Koyeb and Fly.io.
  prefs: []
  type: TYPE_NORMAL
- en: For specific region deployment, Railway and Render are good choices.
  prefs: []
  type: TYPE_NORMAL
- en: Choosing a cloud provider involves considering not just latency but also user
    experience and pricing.
  prefs: []
  type: TYPE_NORMAL
- en: We use Fly.io in production and are satisfied with it.
  prefs: []
  type: TYPE_NORMAL
- en: Vercel[](#vercel)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: I haven't included Vercel in this test. But we have a blog post comparing Vercel
    Serverless vs Edge vs Serverless. You can find it [here](https://www.openstatus.dev/blog/monitoring-latency-vercel-edge-vs-serverless).
  prefs: []
  type: TYPE_NORMAL
- en: If you want to monitor your API or website, create an account on [OpenStatus](https://www.openstatus.dev/app/sign-up?ref=blog-monitoring).
  prefs: []
  type: TYPE_NORMAL
