- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-29 13:18:35'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI Status - Unexpected responses from ChatGPT
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://status.openai.com/incidents/ssg8fh7sfyz3](https://status.openai.com/incidents/ssg8fh7sfyz3)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: On February 20, 2024, an optimization to the user experience introduced a bug
    with how the model processes language.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: LLMs generate responses by randomly sampling words based in part on probabilities.
    Their “language” consists of numbers that map to tokens.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the bug was in the step where the model chooses these numbers.
    Akin to being lost in translation, the model chose slightly wrong numbers, which
    produced word sequences that made no sense. More technically, inference kernels
    produced incorrect results when used in certain GPU configurations.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: Upon identifying the cause of this incident, we rolled out a fix and confirmed
    that the incident was resolved.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
