- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-29 13:19:50'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: Speed of Rust vs C
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://kornel.ski/rust-c-speed](https://kornel.ski/rust-c-speed)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The run-time speed and memory usage of programs written in Rust should about
    the same as of programs written in C, but overall programming style of these languages
    is different enough that it's hard to generalize their speed. This is a summary
    of where they're the same, where C is faster, and where Rust is faster.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: 'Disclaimer: It''s not meant to be an objective benchmark uncovering indisputable
    truths about these languages. There''s a significant difference between what these
    languages can achieve in theory, and how they''re used in practice. This particular
    comparison is based on my own subjective experience that includes having deadlines,
    writing bugs, and being lazy. I''ve been using Rust as my main language for over
    4 years, and C for a decade before that. I''m specifically comparing to just C
    here, as a comparison with C++ would have many more "ifs" and "buts" that I don''t
    want to get into.'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: 'In short:'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: Rust's abstractions are a double-edged sword. They can hide suboptimal code,
    but also make it easier to make algorithmic improvements and take advantage of
    highly optimized libraries.
  id: totrans-split-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I'm never worried that I'm going to hit a performance dead-end with Rust. There's
    always the `unsafe` escape hatch that allows very low-level optimizations (and
    it's not needed often).
  id: totrans-split-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fearless concurrency is real. The occasional awkwardness of the borrow checker
    pays off in making parallel programming *practical*.
  id: totrans-split-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: My overall feeling is that if I could spend infinite time and effort, my C programs
    would be as fast or faster than Rust, because theoretically there's nothing that
    C can't do that Rust can. But in practice C has fewer abstractions, primitive
    standard library, dreadful dependency situation, and I just don't have the time
    to reinvent the wheel, optimally, every time.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
- en: Both are "portable assemblers"
  id: totrans-split-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Both Rust and C give control over the layout of data structures, integer sizes,
    stack vs heap memory allocation, pointer indirections, and generally translate
    to understandable machine code with little "magic" inserted by the compiler. Rust
    even admits that bytes have 8 bits and signed integers can overflow!
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
- en: Even though Rust has higher-level constructs such as iterators, traits and smart
    pointers, they're designed to predictably optimize to straightforward machine
    code (AKA "zero-cost abstractions"). Memory layout of Rust's types is simple,
    e.g. growable strings and vectors are exactly `{byte*, capacity, length}`. Rust
    doesn't have any concept like move or copy constructors, so passing of objects
    is guaranteed to be no more complicated than passing a pointer or `memcpy`.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
- en: Borrow-checking is only a compile-time static analysis. It doesn't *do* anything,
    and lifetime information is even completely stripped out before code generation.
    There's no autoboxing or anything clever like that.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
- en: One case where Rust falls short of being "dumb" code generator is [unwinding](https://github.com/rust-lang/project-ffi-unwind).
    While Rust doesn't use exceptions for normal error handling, a panic (unhandled
    fatal error) may optionally behave like a C++ exception. It can be disabled at
    compilation time (panic = abort), but even then Rust doesn't like to be mixed
    with C++ exceptions or `longjmp`.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
- en: Same old LLVM back-end
  id: totrans-split-18
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Rust has a good integration with LLVM, so it supports Link-Time Optimization,
    including ThinLTO and even inlining across C/C++/Rust language boundaries. There's
    profile-guided optimization, too. Even though `rustc` generates more verbose LLVM
    IR than `clang`, the optimizer can still deal with it pretty well.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
- en: Some of my C code is a bit faster when compiled with GCC than LLVM, and there's
    no Rust front-end for [GCC yet](https://github.com/Rust-GCC/gccrs), so Rust misses
    out on that.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
- en: In theory, Rust allows even better optimizations than C thanks to stricter immutability
    and aliasing rules, but in practice this doesn't happen yet. Optimizations beyond
    what C does are a work-in-progress in LLVM, so Rust still hasn't reached its full
    potential.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
- en: Both allow hand-tuning, with minor exceptions
  id: totrans-split-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Rust code is low-level and predictable enough that I can hand-tune what assembly
    it will optimize to. Rust supports SIMD intrinsics, has good control over inlining,
    calling conventions, etc. Rust is similar enough to C that C profilers usually
    work with Rust out of the box (e.g. I can use Xcode's Instruments on a program
    that's a Rust-C-Swift sandwich).
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
- en: In general, where the performance is absolutely critical and needs to be hand-optimized
    to the last bit, optimizing Rust isn't much different from C.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
- en: 'There are some low-level features that Rust doesn''t have a proper replacement
    for:'
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
- en: '*computed* goto. "Boring" uses of `goto` can be replaced with other constructs
    in Rust, like `loop {break}`. In C many uses of `goto` are for cleanup, which
    Rust doesn''t need thanks to RAII/destructors. However, there''s a non-standard
    `goto *addr` extension that''s very useful for interpreters. Rust can''t do it
    directly (you can write a `match` and *hope* it''ll optimize), but OTOH if I needed
    an interpreter, I''d try to leverage [Cranelift JIT](https://lib.rs/crates/cranelift)
    instead.'
  id: totrans-split-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`alloca` and C99 variable-length arrays. These are [controversial](https://www.phoronix.com/scan.php?page=news_item&px=Linux-Kills-The-VLA)
    even in C, so Rust stays away from them.'
  id: totrans-split-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It's worth noting that Rust currently supports only one 16-bit architecture.
    The [tier 1 support](https://forge.rust-lang.org/platform-support.html) is focused
    on 32-bit and 64-bit platforms.
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
- en: Small overheads of Rust
  id: totrans-split-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'However, where Rust isn''t hand-tuned, some inefficiencies can creep in:'
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
- en: Rust's lack of implicit type conversion and indexing only with `usize` nudges
    users to use just this type, even where smaller types would suffice. That's in
    contrast with C where a 32-bit `int` is the popular choice. Indexing by `usize`
    is easier to optimize on 64-bit platforms without relying on undefined behavior,
    but the extra bits may put more pressure on registers and memory.
  id: totrans-split-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Idiomatic Rust always passes pointer *and size* for strings and slices. It wasn't
    until I ported a couple codebases from C to Rust, that I realized just how many
    C functions only take a pointer to memory, without a size, and hope for the best
    (the size is either known indirectly from the context, or just assumed to be large
    enough for the task).
  id: totrans-split-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not all bounds checks are optimized out. `for item in arr` or `arr.iter().for_each(…)`
    are as efficient as they can be, but if the form `for i in 0..len {arr[i]}` is
    needed, then performance depends on the LLVM optimizer being able to prove the
    length matches. Sometimes it can't, and the bound checks inhibit autovectorization.
    Of course, there are various workarounds for this, both safe and unsafe.
  id: totrans-split-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '"Clever" memory use is frowned upon in Rust. In C, anything goes. For example,
    in C I''d be tempted to reuse a buffer allocated for one purpose for another purpose
    later (a technique known as HEARTBLEED). It''s convenient to have fixed-size buffers
    for variable-size data (e.g. `PATH_MAX`) to avoid (re)allocation of growing buffers.
    Idiomatic Rust still gives a lot control over memory allocation, and can do basics
    like memory pools, combining multiple allocations into one, preallocating space,
    etc., but in general it steers users towards "boring" use or memory.'
  id: totrans-split-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In cases where borrow checking rules make things hard, the easy way out is to
    do extra copying or use reference counting. Over time I've learned a bunch of
    borrow-checker tricks, and adjusted my coding style to be borrow-checker friendly,
    so this doesn't come up often any more. This never becomes a *major* problem,
    because if necessary, there's always a fallback to "raw" pointers.
  id: totrans-split-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rust's borrow checker is [infamous for hating doubly-linked lists](https://rust-unofficial.github.io/too-many-lists/),
    but luckily it happens that linked lists are slow on 21st-century hardware anyway
    (poor cache locality, no vectorization). Rust's standard library has linked lists,
    as well as faster and borrow-checker-friendly containers to choose from.
  id: totrans-split-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'There are two more cases that the borrow checker can''t tolerate: memory-mapped
    files (magical changes from outside of the process violate immutable^exclusive
    semantics of references) and self-referential structs (passing of the struct by
    value would make its inner pointers dangle). These cases are solved either with
    raw pointers that are as safe as every pointer in C, or mental gymnastics to make
    safe abstractions around them.'
  id: totrans-split-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To Rust, single-threaded programs just don't exist as a concept. Rust allows
    individual data structures to be non-thread-safe for performance, but anything
    that is allowed to be shared between threads (including global variables) has
    to be synchronized or marked as `unsafe`.
  id: totrans-split-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I keep forgetting that Rust's strings support some cheap in-place operations,
    such as `make_ascii_lowercase()` (a direct equivalent of what I'd do in C), and
    unnecessarily use Unicode-aware, copying `.to_lowercase()`. Speaking of strings,
    the UTF-8 encoding is not as big of a problem as it may seem, because strings
    have `.as_bytes()` view, so they can be processed in Unicode-ignorant way if needed.
  id: totrans-split-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: libc bends over backwards to make `stdout` and `putc` reasonably fast. Rust's
    libstd has less magic, so I/O isn't buffered unless wrapped in a `BufWriter`.
    I've seen people complain that their Rust is slower than Python, and it was because
    Rust spent 99% of the time flushing the result byte by byte, exactly as told.
  id: totrans-split-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Executable sizes
  id: totrans-split-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Every operating system ships some built-in standard C library that is ~30MB
    of code that C executables get for "free", e.g. a small "Hello World" C executable
    can't actually print anything, it only calls the `printf` shipped with the OS.
    Rust can't count on OSes having *Rust's* standard library built-in, so Rust executables
    bundle their own standard library (300KB or more). Fortunately, it's a one-time
    overhead and [can be reduced](https://github.com/johnthagen/min-sized-rust). For
    embedded development, the standard library can be turned off and Rust will generate
    "bare" code.
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
- en: On per-function basis Rust code is about the same size as C, but there's a problem
    of "generics bloat". Generic functions get optimized versions for each type they're
    used with, so it's possible to end up with 8 versions of the same function. [`cargo-bloat`](https://lib.rs/cargo-bloat)
    helps finding these.
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
- en: It's super easy to use dependencies in Rust. Similarly to JS/npm, there's a
    culture of making small single-purpose libraries, but they do add up. Eventually
    all my executables end up containing Unicode normalization tables, 7 different
    random number generators, and an HTTP/2 client with Brotli support. `cargo-tree`
    is useful for deduping and culling them.
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
- en: Small wins for Rust
  id: totrans-split-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'I''ve talked a lot about overheads, but Rust also has places where it ends
    up more efficient and faster:'
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
- en: C libraries typically return opaque pointers to their data structures, to hide
    implementation details and ensure there's only one copy of each instance of the
    struct. This costs heap allocations and pointer indirections. Rust's built-in
    privacy, single-ownership rules, and coding conventions let libraries expose their
    objects without indirection, so that callers can decide whether to put them on
    the heap or on the stack. Objects on the stack can can be optimized very aggressively,
    and even optimized out entirely.
  id: totrans-split-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rust by default can inline functions from the standard library, dependencies,
    and other compilation units. In C I'm sometimes reluctant to split files or use
    libraries, because it affects inlining and requires micromanagement of headers
    and symbol visibility.
  id: totrans-split-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Struct fields are reordered to minimize padding. Compiling C with `-Wpadding`
    shows how often I forget about this detail.
  id: totrans-split-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Strings have their size encoded in their "fat" pointer. This makes length checks
    fast, eliminates risk of [accidental O(n²)](https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/)
    string loops, and allows making substrings in-place (e.g. splitting a string into
    tokens) without modifying memory or copying to add the `\0` terminator.
  id: totrans-split-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Like C++ templates, Rust generates copies of generic code for each type they're
    used with, so functions like `sort()` and containers like hash tables are always
    optimized for their type. In C I have to choose between hacks with macros or less
    efficient functions that work on `void*` and run-time variable sizes.
  id: totrans-split-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rust iterators can be combined into chains that get optimized together as one
    unit. So instead of a series of calls `buy(it); use(it); break(it); change(it);
    mail(upgrade(it));` that may end up rewriting the same buffer many times, I can
    call `it.buy().use().break().change().upgrade().mail()` that compiles to one `buy_use_break_change_mail_upgrade(it)`
    optimized to do all of that in a single combined pass. `(0..1000).map(|x| x*2).sum()`
    compiles to `return 999000`.
  id: totrans-split-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, there are `Read` and `Write` interfaces that allow functions to stream
    unbuffered data. They combine nicely, so I can write data to a stream that calculates
    CRC of the data on the fly, adds framing/escaping if needed, compresses it, and
    writes it to the network, all in one call. And I can pass such combined stream
    as an output stream to my HTML templating engine, so now each HTML tag will be
    smart enough to send itself compressed. The underlying mechanism is just a pyramid
    of plain `next_stream.write(bytes)` calls, so technically nothing stops me from
    doing the same in C, except the lack of traits and generics in C means it's very
    hard to actually do that in practice, other than with callbacks set up at run
    time, which isn't as efficient.
  id: totrans-split-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In C it's perfectly rational to overuse linear search and linked lists, because
    who's going to maintain yet another half-assed implementation of hash table? There
    are no built-in containers, dependencies are a pain, so I cut corners to get stuff
    done. Unless absolutely necessary, I won't bother to write a sophisticated implementation
    of a B-tree. I'll use `qsort` + `bisect` and call it a day. OTOH in Rust it takes
    only 1 or 2 lines of code to get very high quality implementations all kinds of
    containers. This means that my Rust programs can afford to use proper, incredibly
    well-optimized data structures *every time*.
  id: totrans-split-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These days everything seems to require JSON. Rust's `serde` is one of the fastest
    JSON parsers in the world, and it parses directly into Rust structs, so use of
    the parsed data is very fast and efficient, too.
  id: totrans-split-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Big win for Rust
  id: totrans-split-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Rust enforces thread-safety of all code and data, even in 3rd party libraries,
    even if authors of that code didn't pay attention to thread safety. Everything
    either upholds specific thread-safety guarantees, or won't be allowed to be used
    across threads. If I write any code that is not thread safe, the compiler will
    point out exactly where it is unsafe.
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
- en: That's a dramatically different situation than C. Usually no library functions
    can be trusted to be thread-safe unless they're clearly documented otherwise.
    It's up to the programmer to ensure all of the code is correct, and the compiler
    generally can't help with any of this. Multi-threaded C code carries a lot more
    responsibility, a lot more risk, so it's appealing to pretend multi-core CPUs
    are just a fad, and imagine users have better things to do with the remaining
    7 or 15 cores.
  id: totrans-split-58
  prefs: []
  type: TYPE_NORMAL
- en: Rust guarantees freedom from data races and memory unsafety (e.g. use-after-free
    bugs, even across threads). Not just some races that could be found with heuristics
    or at runtime in instrumented builds, but *all* data races everywhere. This is
    life-saving, because data races are the worst kind of concurrency bugs. They'll
    happen on my users' machines, but not in my debugger. There are other kinds of
    concurrency bugs, such as poor use of locking primitives causing higher-level
    logical race conditions or deadlocks, and Rust can't eliminate them, but they're
    usually easier to reproduce and fix.
  id: totrans-split-59
  prefs: []
  type: TYPE_NORMAL
- en: In C I won't dare to do more than a couple of OpenMP pragmas on simple `for`
    loops. I've tried being more adventurous with tasks and threads, and ended up
    regretting it every time.
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
- en: Rust has has good libraries for data parallelism, thread pools, queues, tasks,
    lock-free data structures, etc. With the help of such building blocks, and the
    strong safety net of the type system, I can parallelize Rust programs quite easily.
    In some cases it's sufficient to replace `iter()` with `par_iter()`, and if it
    compiles, it works! It's not always a linear speed-up (Amdahl's law is brutal),
    but it's often a 2×-3× speed-up for relatively little work.
  id: totrans-split-61
  prefs: []
  type: TYPE_NORMAL
- en: There's an interesting difference how Rust and C libraries document thread-safety.
    Rust has a vocabulary for specific aspects of thread-safety, such as `Send` and
    `Sync`, guards and cells. In C, there's no word for "you can allocate it on one
    thread, and free it on another thread, but you can't use it from two threads at
    once". Rust describes thread-safety in terms of data types, which generalizes
    to all functions using them. In C thread-safety is talked about in the context
    of individual functions and configuration flags. Rust's guarantees tend to be
    compile-time, or at least unconditional. In C it's common to find "this is thread
    safe only when the turboblub option is set to 7".
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
- en: To sum it up
  id: totrans-split-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Rust is low-level enough that if necessary, it can be optimized for maximum
    performance just as well as C. Higher-level abstractions, easy memory management,
    and abundance of available libraries tend to make Rust programs have more code,
    do more, and if left unchecked, can add up to bloat. However, Rust programs also
    optimize quite well, sometimes better than C. While C is good for writing minimal
    code on byte-by-byte pointer-by-pointer level, Rust has powerful features for
    efficiently combining multiple functions or even whole libraries together.
  id: totrans-split-64
  prefs: []
  type: TYPE_NORMAL
- en: But the biggest potential is in ability to fearlessly parallelize majority of
    Rust code, even when the equivalent C code would be too risky to parallelize.
    In this aspect Rust is a much more mature language than C.
  id: totrans-split-65
  prefs: []
  type: TYPE_NORMAL
