<!--yml

category: 未分类

date: 2024-05-29 13:27:45

-->

# 美光启动HBM3E存储器的生产

> 来源：[https://www.anandtech.com/show/21277/micron-kicks-off-production-of-hbm3e-memory](https://www.anandtech.com/show/21277/micron-kicks-off-production-of-hbm3e-memory)

[美光技术](https://investors.micron.com/news-releases/news-release-details/micron-commences-volume-production-industry-leading-hbm3e)周一宣布已开始量产其HBM3E存储器。该公司的HBM3E知名堆叠芯片（KGSDs）将用于[Nvidia的H200计算GPU](https://www.anandtech.com/show/21136/nvidia-at-sc23-h200-accelerator-with-hbm3e-and-jupiter-supercomputer-for-2024)，用于人工智能（AI）和高性能计算（HPC）应用，这些产品将于2024年第二季度发货。

美光宣布正在大规模生产24 GB 8-Hi HBM3E器件，数据传输速率为9.2 GT/s，每个设备的峰值内存带宽超过1.2 TB/s。与HBM3相比，HBM3E的数据传输速率和峰值内存带宽提高了44%，这对像Nvidia的H200这样对带宽需求巨大的处理器尤为重要。

Nvidia的H200产品依赖于Hopper架构，提供与H100相同的计算性能。与此同时，它配备了141 GB的HBM3E内存，带宽高达4.8 TB/s，这是从HBM3的80 GB和H100的最高3.35 TB/s带宽的显著升级。

美光的AI存储器路线图通过2024年3月即将发布的36 GB 12-Hi HBM3E产品进一步得到巩固。同时，目前尚不清楚这些设备将用于何处。

美光利用其1β（1-beta）工艺技术生产其HBM3E，这对公司来说是一项重大成就，因为它利用最新的生产节点为其数据中心级产品提供支持，这证明了其制造技术的先进性。

美光在SK Hynix和三星之前启动HBM3E存储器的大规模生产是一项重大成就，目前在HBM领域占有10%的市场份额。这一举措对公司至关重要，因为它使美光能够比竞争对手更早推出优质产品，潜在地增加其收入和利润率，同时扩大市场份额。

“*美光通过这一HBM3E里程碑实现了三连胜：市场领先时间、行业最佳性能以及独特的能效特性，*” 美光技术执行副总裁兼首席商务官Sumit Sadana表示。*“AI工作负载严重依赖于内存带宽和容量，而美光通过我们行业领先的HBM3E和HBM4技术路线图以及全面的DRAM和NAND解决方案，非常适合支持未来显著的AI增长。”*

来源：[美光](https://investors.micron.com/news-releases/news-release-details/micron-commences-volume-production-industry-leading-hbm3e)
