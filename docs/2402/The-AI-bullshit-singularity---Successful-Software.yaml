- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 14:58:00'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 14:58:00'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: The AI bullshit singularity | Successful Software
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI胡扯奇点 | 成功软件
- en: 来源：[https://successfulsoftware.net/2024/02/18/the-ai-bullshit-singularity/](https://successfulsoftware.net/2024/02/18/the-ai-bullshit-singularity/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://successfulsoftware.net/2024/02/18/the-ai-bullshit-singularity/](https://successfulsoftware.net/2024/02/18/the-ai-bullshit-singularity/)
- en: I’m sure we are all familiar with the idea of a technological singularity. Humans
    create an AI that is smart enough to create an even smarter successor. That successor
    then creates an even smarter successor. The process accelerates through a positive
    feedback loop, until we reach a technological singularity, where puny human intelligence
    is quickly left far behind.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都对技术奇点的概念非常熟悉。人类创造了一个足够聪明的AI，能够创造一个更聪明的后继者。然后这个后继者又创造了一个更聪明的后继者。这个过程通过正反馈循环加速，直到我们达到技术奇点，人类的智能很快就会被远远甩在后面。
- en: Some people seem to think that Large Language Models could be the start of this
    process. We train the LLMs on vast corpuses of human knowledge. The LLMs then
    help humans create new knowledge, which is then used to train the next generation
    of LLMs. Singularity, here we come!
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人似乎认为大型语言模型可能是这一过程的开端。我们训练LLM（Large Language Models）使用人类知识的广泛语料库。然后LLM帮助人类创造新知识，用于训练下一代LLM。奇点，我们来了！
- en: But I don’t think so. Human nature being what it is, LLMs are inevitably going
    to be used to churn out vast amount of low quality ‘content’ for SEO and other
    commercial purposes. LLM nature being what it is, a lot of this content is going
    to be hallucinated. In otherwords, bullshit. Given that LLMs can generate content
    vastly faster than humans can, we could quickly end up with an Internet that is
    mostly bullshit. Which will then be used to train the next generation of LLM.
    We will eventually reach a bullshit singularlity, where it is almost impossible
    to work out whether anything on the Internet is true. Enshittification at scale.
    Well done us.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 但我不这么认为。鉴于人类的本性，LLM必然会被用来大量生成低质量的“内容”以供SEO和其他商业用途。考虑到LLM的本质，这些内容中很多都是虚构的。换句话说，胡扯。由于LLM可以比人类更快速地生成内容，我们很快可能会得到一个主要由胡扯内容组成的互联网。然后这些内容会被用来训练下一代LLM。我们最终会达到一个胡扯奇点，在这个奇点上几乎不可能判断互联网上的任何事情是否真实。大规模的废话化。我们干得好。
