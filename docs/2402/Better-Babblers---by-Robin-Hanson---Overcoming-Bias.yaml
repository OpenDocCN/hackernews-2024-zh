- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-05-27 14:54:15'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-05-27 14:54:15
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Better Babblers - by Robin Hanson - Overcoming Bias
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更好的胡说八道 - 罗宾·汉森 - 克服偏见
- en: 来源：[https://www.overcomingbias.com/p/better-babblershtml](https://www.overcomingbias.com/p/better-babblershtml)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.overcomingbias.com/p/better-babblershtml](https://www.overcomingbias.com/p/better-babblershtml)
- en: 'You can think of knowing how to write as knowing how to correlate words. Given
    no words, what first word should you write. Then given one word, what second word
    best correlates with that. Then given two words, what third word best fits with
    those two. And so on. Thus your knowledge of how to write can be broken into what
    you know at these different correlation orders: one word, two words, three words,
    and so on. Each time you pick a new word you can combine knowledge at these different
    orders, by weighing all their different recommendations for your next word.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以把写作能力看作是知道如何相关联单词的能力。没有单词，你应该写什么第一个词。然后，给定一个词，什么第二个词最能与之相关联。然后，给定两个词，什么第三个词最适合与这两个词配合。依此类推。因此，你的写作知识可以分解为在不同相关性顺序下的知识：一个词，两个词，三个词，等等。每次你选择一个新词时，你可以通过权衡所有这些不同推荐为你下一个词的建议来结合这些不同阶次的知识。
- en: This correlation order approach can also be applied at different scales. For
    example, given some classification of your first sentence, what kind of second
    sentence should follow? Given a classification of your first chapter, what kind
    of second chapter should follow? Many other kinds of knowledge can be similarly
    broken down into correlation orders, at different scales. We can do this for music,
    paintings, interior decoration, computer programs, math theorems, and so on.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这种相关性顺序方法也可以应用于不同的尺度。例如，给定你的第一句话的某种分类，应该跟着什么样的第二句话？给定你的第一章的分类，应该跟着什么样的第二章？许多其他类型的知识也可以类似地分解为不同尺度上的相关性顺序。我们可以这样做音乐、绘画、室内装饰、计算机程序、数学定理等等。
- en: Given a huge database, such as of writings, it is easy to get good at very low
    orders; you can just use the correlation frequencies found in your dataset. After
    that, simple statistical models applied to this database can give you good estimates
    for correlations to use at somewhat higher orders. And if you have enough data
    (roughly ten million examples per category I’m told) then recently popular machine
    learning techniques can improve your estimates at a next set of higher orders.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果给定一个庞大的数据库，比如文献数据库，要想在非常低的阶数上做得好是很容易的；你只需使用你的数据集中发现的相关频率。之后，对这个数据库应用简单的统计模型可以给出在稍高阶次上使用的相关性的良好估计。如果你有足够的数据（我听说每个类别大约需要一千万个例子），那么最近流行的机器学习技术可以改善你对下一阶高阶相关性的估计。
- en: There are some cases where this is enough; either you can get enormous amounts
    of data, or learning low order correlations well is enough to solve your problem.
    These cases include many games with well defined rules, many physical tasks where
    exact simulations are feasible, and some kinds of language translation. But there
    are still many other cases where this is far from enough to achieve human level
    proficiency. In these cases an important part of what we know can be described
    as very high order correlations produced by “deep” knowledge structures that aren’t
    well reduced to low order correlations.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，这已经足够了；要么你可以获得大量的数据，要么学习低阶相关性就足以解决你的问题。这些情况包括许多具有明确定义规则的游戏，许多精确模拟可行的物理任务以及某些语言翻译。但仍然有许多其他情况，这远远不足以达到人类水平的熟练程度。在这些情况下，我们所知道的一个重要部分可以被描述为由“深层”知识结构产生的非常高阶的相关性，这些知识结构不能很好地归纳为低阶相关性。
- en: After eighteen years of being a professor, I’ve graded *many* student essays.
    And while I usually try to teach a deep structure of concepts, what the median
    student actually learns seems to mostly be a set of low order correlations. They
    know what words to use, which words tend to go together, which combinations tend
    to have positive associations, and so on. But if you ask an exam question where
    the deep structure answer differs from answer you’d guess looking at low order
    correlations, most students usually give the wrong answer.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在做了十八年教授之后，我评阅了*许多*学生的论文。虽然我通常试图教授一套概念的深层结构，但中位数学生实际学到的似乎主要是一组低阶相关性。他们知道要使用哪些单词，哪些单词倾向于搭配在一起，哪些组合倾向于具有积极的关联等等。但是，如果你问一个考试问题，深层结构的答案与你通过查看低阶相关性猜测的答案不同，那么大多数学生通常会给出错误答案。
- en: Simple correlations also seem sufficient to capture most polite conversation
    talk, such as the weather is nice, how is your mother’s illness, and damn that
    other political party. Simple correlations are also most of what I see in inspirational
    TED talks, and when public intellectuals and talk show guests pontificate on topics
    they really don’t understand, such as quantum mechanics, consciousness, postmodernism,
    or the need always for more regulation everywhere. After all, media entertainers
    don’t need to understand deep structures any better than do their audiences.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的相关性似乎也足以捕捉大部分礼貌的交谈，例如天气很好，你母亲的病怎么样，以及该死的另一个政党。简单的相关性也是我在鼓舞人心的 TED 演讲中看到的大部分内容，以及当公共知识分子和脱口秀嘉宾在他们其实并不了解的话题上演讲时，例如量子力学、意识、后现代主义，或者无论何时都需要更多的监管。毕竟，媒体演员不需要比他们的听众更了解深层结构。
- en: Let me call styles of talking (or music, etc.) that rely mostly on low order
    correlations “babbling”. Babbling isn’t meaningless, but to ignorant audiences
    it often appears to be based on a deeper understanding than is actually the case.
    When done well, babbling can be entertaining, comforting, titillating, or exciting.
    It just isn’t usually a good place to learn deep insight.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 让我称之为依赖大部分低阶相关性的谈话风格（或音乐等）为“胡说八道”。胡说八道并不是毫无意义的，但对于无知的听众来说，它常常似乎基于比实际情况更深刻的理解。做得好时，胡说八道可以是有趣的、令人安心的、刺激的，或者令人兴奋的。它通常不是学习深刻见解的好地方。
- en: As we slowly get better at statistics and machine learning, our machines will
    slowly get better at babbling. The famous Eliza chatbot went surprisingly far
    using very low order correlations, and today chatbots best fool us into thinking
    they are human when they stick to babbling style conversations. So what does a
    world of better babblers look like?
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们在统计学和机器学习方面逐渐变得更加娴熟，我们的机器也会逐渐变得更会唠叨。著名的Eliza聊天机器人仅使用非常低阶的相关性就走得非常远，今天的聊天机器人最能让我们以为它们是人类的时候，是它们坚持唠叨式的对话风格。那么，更善于唠叨的世界会是什么样子呢？
- en: First, machines will better mimic low quality student essays, so schools will
    have to try harder to keep such students from using artificial babblers.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，机器将更好地模仿低质量的学生作文，因此学校将不得不更加努力地防止这些学生使用人工唠叨者。
- en: Second, the better machines get at babbling, the more humans will try to distinguish
    themselves from machines via non-babbling conversational styles. So expect less
    use of simple easy-to-understand-and-predict speech in casual polite conversation,
    inspirational speeches, and public intellectual talk.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，机器在唠叨方面变得更好时，人类将通过非唠叨式的对话风格试图与机器区分开来。因此，可以预期在日常礼貌对话、鼓舞人心的演讲和公共知识讨论中，简单易懂且容易预测的语言使用会减少。
- en: One option is to put a higher premium on talk that actually makes deep sense,
    in terms of deep concepts that experts understand. That would be nice for those
    of us who have always emphasized such things. But alas there are other options.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一个选择是更加重视那些在深度概念上有着实际深意的对话，这些概念是专家理解的。对于那些一直强调这些事物的人来说，这将是件好事。但唉，还有其他选择。
- en: A second option is to put a higher premium on developing very distinctive styles
    of talking. This would be like how typical popular songs from two centuries ago
    could be sung and enjoyed by most anyone, compared to how popular music today
    is matched in great detail to the particular features of particular artists. Imagine
    most all future speakers having as distinct a personal talking style.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选择是更加重视发展非常独特的谈话风格。这就像两个世纪前的典型流行歌曲可以被大多数人唱和欣赏一样，与今天的流行音乐详细匹配特定艺术家的特定特征相比。想象一下，未来大多数演讲者都有如此独特的个人说话风格。
- en: A third option is more indirect, ironic, and insider style talk, such as we
    tend to see on Twitter today. People using words and phrases and cultural references
    in ways that only folks very near in cultural space can clearly accept as within
    recent local fashion. Artificial babblers might not have enough data to track
    changing fashions in such narrow groups.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个选择更间接、具有讽刺意味，以及内部人说话风格，例如今天我们在Twitter上看到的。人们使用词语、短语和文化引用的方式，只有文化空间非常接近的人才能明确接受为最近的本地时尚内的一部分。人工唠叨者可能没有足够的数据来追踪这些狭窄群体中时尚的变化。
- en: 'Bottom line: the more kinds of conversation styles that simple machines can
    manage, the more humans will try to avoid talking in those styles, a least when
    not talking to machines.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 底线是：简单机器能够处理的对话风格越多，人类就越会试图避免在那些风格下说话，至少在不与机器交谈时是这样。
