<!--yml

类别: 未分类

日期: 2024-05-27 13:15:05

-->

# 一份关于视觉Transformer的视觉指南 | MDTURP

> 来源：[https://blog.mdturp.ch/posts/2024-04-05-visual_guide_to_vision_transformer.html](https://blog.mdturp.ch/posts/2024-04-05-visual_guide_to_vision_transformer.html)

这是一份关于视觉Transformer（ViTs）的视觉指南，这类深度学习模型在图像分类任务上取得了最先进的性能。视觉Transformer将最初为自然语言处理（NLP）设计的Transformer架构应用于图像数据。本指南将以滚动故事的形式向您介绍视觉Transformer的关键组成部分，使用可视化和简单的解释来帮助您理解这些模型的工作原理以及数据在模型中的流动方式。

像普通的卷积神经网络一样，视觉Transformer是以监督方式进行训练的。这意味着模型在图像数据集及其相应标签的基础上进行训练。

### 1) 关注一个数据点

为了更好地理解视觉Transformer内部发生的事情，让我们专注于一个单独的数据点（批量大小为1）。让我们问一个问题：如何准备这个数据点以便被Transformer消耗？

### 2) 暂时忽略标签

标签稍后会变得更加重要。现在我们唯一剩下的是一幅单独的图像。

### 3) 创建图像的补丁

为了在Transformer内部使用之前准备图像，我们将图像分割成大小为**p x p**的等尺寸补丁。

### 4) 对图像的补丁进行平坦化处理

现在将这些补丁展开为维度为**p'= p²*c**的向量，其中**p**是补丁的大小，**c**是通道数。

### 5) 创建补丁嵌入

现在使用线性转换对这些图像补丁向量进行编码。生成的**补丁嵌入向量**具有固定大小**d**。

### 6) 嵌入所有补丁

现在我们已经将图像块嵌入为固定大小的向量，我们得到了一个大小为**n x d**的数组，其中**n**是图像块的数量，**d**是**块嵌入**的大小。

### 7) 追加分类标记

为了有效训练我们的模型，我们通过添加名为**分类标记（cls token）**的额外向量来扩展块嵌入的数组。这个向量是网络的可学习参数，并且是随机初始化的。注意：我们只有一个cls token，并且我们为所有数据点追加相同的向量。

### 8) 添加位置嵌入向量

目前我们的**块嵌入**没有与其相关联的位置信息。我们通过向所有块嵌入添加一个可学习的随机初始化的**位置嵌入向量**来修复这个问题。我们还向我们的**分类标记**添加了这样一个位置嵌入向量。

### 9) Transformer 输入

添加了位置嵌入向量之后，我们得到了一个大小为**(n+1) x d**的数组。这将成为我们转换器的输入，在接下来的步骤中将有更详细的解释。

### 10.1) Transformer：QKV 创建

我们的转换器输入块嵌入向量被线性嵌入到多个大向量中。这些新向量然后被分成三个大小相等的部分。**Q - 查询向量**，**K - 键向量**和**V - 值向量**。我们将会有(n+1)个所有这些向量。

### 10.2) Transformer：注意力分数计算

现在我们将计算注意力分数矩阵A，方法是将所有查询向量Q与所有键向量K相乘。

### 10.3) Transformer：注意力分数矩阵

现在我们有了注意力分数矩阵A，我们对每一行应用`softmax`函数，使得每一行的总和为1。

### 10.4) Transformer：聚合上下文信息计算

为了计算第一个补丁嵌入向量的**聚合上下文信息**。我们关注注意力矩阵的**第一行**。并将这些条目用作我们**值向量 V**的权重。结果是我们第一个图像补丁嵌入的**聚合上下文信息**向量。

### 10.5)变压器：每个补丁的聚合上下文信息

现在我们对我们的注意力分数矩阵的每一行重复这个过程，结果将是 N+1 个聚合的上下文信息向量。一个是每个补丁的 + 一个是分类标记。这一步骤完成了我们的第一个注意力头。

### 10.6)变压器：多头注意力

现在因为我们处理多头注意力，我们从步骤**10.1 - 10.5**再次重复整个过程，使用不同的 QKV 映射。对于我们的解释设置，我们假设有 2 个头，但典型的 VIT 通常有更多头。最终这将导致多个聚合的上下文信息向量。

### 10.7)变压器：最后的注意力层步骤

这些头部被堆叠在一起，并映射到大小为**d**的向量中，这与我们的补丁嵌入的大小相同。

### 10.8)变压器：注意力层结果

前面的步骤完成了注意力层，我们剩下的是与我们作为输入使用的**完全相同大小**的嵌入。

### 10.9)变压器：残差连接

变压器大量使用**残差连接**，这意味着将前一层的输入简单地加到当前层的输出中。这也是我们现在要做的事情。

### 10.10)变压器：残差连接结果

加法结果是相同大小的向量。

### 10.11)变压器：前馈网络

现在这些输出通过带有非线性激活函数的前馈神经网络进行馈送。

### 10.12)变压器：最终结果

在Transformer步骤之后，还有另一个残差连接，由于篇幅限制我们将跳过。因此，最后一步完成了Transformer层。最终，Transformer生成了与输入大小相同的输出。

### 11) 重复Transformer

重复整个Transformer计算**步骤10.1 - 步骤10.12**多次，例如6次。

### 12) 识别分类标记输出

最后一步是识别分类标记输出。这个向量将在我们视觉Transformer旅程的最后一步中使用。

### 13) 最后一步：预测分类概率

在最后和最后一步中，我们使用这个分类输出标记和另一个全连接神经网络来预测我们输入图像的分类概率。

我们使用标准的交叉熵损失函数来训练视觉Transformer，该函数将预测的类别概率与真实的类别标签进行比较。模型使用反向传播和梯度下降进行训练，更新模型参数以最小化损失函数。

在这个视觉指南中，我们已经详细介绍了视觉Transformer的关键组成部分，从数据准备到模型训练。我们希望这个指南能帮助您理解视觉Transformer的工作原理以及它们如何用于图像分类。

如果您有任何问题或反馈，请随时与我联系。感谢您的阅读！
