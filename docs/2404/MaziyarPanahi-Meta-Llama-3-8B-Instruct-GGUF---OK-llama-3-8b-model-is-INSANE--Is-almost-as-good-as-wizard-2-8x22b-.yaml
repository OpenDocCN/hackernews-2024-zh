- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 13:20:59'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF · OK llama 3 8b model is INSANE.
    Is almost as good as wizard 2 8x22b!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/discussions/5](https://huggingface.co/MaziyarPanahi/Meta-Llama-3-8B-Instruct-GGUF/discussions/5)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Pretty interesting results! These evals utilized LM Studio 0.2.20, leveraging
    its Multi Model Session feature to execute all prompts. Each model was fully loaded
    into RAM using max GPU layers, and sequential prompting was disabled to enable
    parallel execution of models.
  prefs: []
  type: TYPE_NORMAL
- en: '**Machine:** Apple M3 Max (cores: 4E+12P+40GPU)'
  prefs: []
  type: TYPE_NORMAL
- en: '**Temperature:** 0.8'
  prefs: []
  type: TYPE_NORMAL
- en: '**System Prompt:** You are a helpful, smart, kind, and efficient AI assistant.
    You always fulfill the user''s requests to the best of your ability.'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt 1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Expected Result
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 264 tokens, 9.68 tok/sec
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 241 tokens, 6.99 tok/sec
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 292 tokens, 3.84 tok/sec
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Prompt 2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Expected Result
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 535 tokens, 8.13 tok/sec
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 566 tokens, 6.83 tok/sec
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 526 tokens, 3.64 tok/sec
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Prompt 3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Expected Result
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 226 tokens, 10.79 tok/sec
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 268 tokens, 7.98 tok/sec
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 171 tokens, 3.22 tok/sec
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Prompt 4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Expected Result
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 626 tokens, 9.13 tok/sec
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 397 tokens, 6.48 tok/sec
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 471 tokens, 3.66 tok/sec
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
