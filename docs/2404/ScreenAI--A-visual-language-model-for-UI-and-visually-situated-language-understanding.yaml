- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 13:03:11'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: 'ScreenAI: A visual language model for UI and visually-situated language understanding'
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://research.google/blog/screenai-a-visual-language-model-for-ui-and-visually-situated-language-understanding/](https://research.google/blog/screenai-a-visual-language-model-for-ui-and-visually-situated-language-understanding/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*This project is the result of joint work with Maria Wang, Fedir Zubach, Hassan
    Mansoor, Vincent Etter, Victor Carbune, Jason Lin, Jindong Chen and Abhanshu Sharma.
    We thank Fangyu Liu, Xi Chen, Efi Kokiopoulou, Jesse Berent, Gabriel Barcik, Lukas
    Zilka, Oriana Riva, Gang Li,Yang Li, Radu Soricut, and Tania Bedrax-Weiss for
    their insightful feedback and discussions, along with Rahul Aralikatte, Hao Cheng
    and Daniel Kim for their support in data preparation. We also thank Jay Yagnik,
    Blaise Aguera y Arcas, Ewa Dominowska, David Petrou, and Matt Sharifi for their
    leadership, vision and support. We are very grateful toTom Small for helping us
    create the animation in this post.*'
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
