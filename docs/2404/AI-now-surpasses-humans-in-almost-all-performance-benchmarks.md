<!--yml

category: 未分类

date: 2024-05-27 13:20:43

-->

# AI 现在在几乎所有性能基准上都超过了人类。

> 来源：[https://newatlas.com/technology/ai-index-report-global-impact/](https://newatlas.com/technology/ai-index-report-global-impact/)

斯坦福大学人类中心人工智能研究所（HAI）发布了其综合 [AI 指数报告](https://aiindex.stanford.edu/report/) 的第七届年度期刊，由跨学科的学术和工业专家团队撰写。

这一版本比以往版本包含更多内容，反映了人工智能的迅速发展及其在我们日常生活中日益重要的地位。它审视了从哪些行业最多使用 AI 到哪个国家最担心因 AI 失去工作的所有方面。但报告中最显著的一个要点是 AI 在与人类对抗中的表现。

对于那些没有关注的人来说，AI 已经在惊人数量的重要基准上击败了我们。2015 年，它超过了我们在图像分类上，然后是基本阅读理解（2017 年），视觉推理（2020 年）和自然语言推理（2021 年）。

AI 变得如此聪明，如此迅速，以至于到目前为止使用的许多基准现在已经过时。事实上，这一领域的研究人员正在竭力开发新的、更具挑战性的基准。简单来说，AI 在通过测试方面变得如此出色，以至于现在我们需要新的测试 - 不是为了衡量能力，而是为了突出人类和 AI 仍然不同的领域，并找到我们仍然具有优势的地方。

值得注意的是，下文的结果反映了使用这些可能已经过时的旧基准进行测试。但总体趋势仍然非常明显：

AI 已经超过了许多人类性能基准。

AI 指数 2024

看看这些趋势，特别是最近测试以接近垂直线表示。记住，这些机器只是虚拟的幼儿。

新的 AI 指数报告指出，在 2023 年，AI 仍然在复杂的认知任务中遇到困难，例如高级数学问题解决和视觉常识推理。然而，在这里，“困难”可能会误导；这绝对不意味着 AI 表现不好。

在 [MATH](https://arxiv.org/abs/2103.03874)，一个包含 12,500 个具有竞赛水平难度的数学问题的数据集上，自其推出以来的两年间，表现显著改善。2021 年，AI 系统只能解决 6.9% 的问题。相比之下，2023 年，基于 GPT-4 的模型解决了 84.3% 的问题。人类的基准是 90%。

我们说的不是普通人类；我们说的是那些能够解决这类测试问题的人类：

AI 面对的一个例子 MATH 问题。哎呀！

Hendryks 等人 / AI 指数 2024

这就是 2024 年在高级数学方面的情况，我们仍然正处于人工智能时代的黎明阶段。

然后是[视觉常识推理](https://visualcommonsense.com/)（VCR）。超越简单的物体识别，VCR评估AI在视觉环境中如何使用常识知识进行预测。例如，当展示一张桌子上的猫的图片时，具有VCR功能的AI应该预测猫可能会跳下桌子，或者该桌子足够结实以支撑猫的重量。

报告发现，在2022年到2023年之间，VCR增长了7.93%，达到了81.60，而人类基线是85。

用于测试AI视觉常识推理的样本问题

Zellers等人/AI指数2024

回想一下，比如说，五年前。想象一下，甚至*思考*向计算机展示一张图片并期望它能够“理解”上下文以回答那个问题。

如今，AI在许多专业领域生成书面内容。但尽管取得了很大进展，大语言模型（LLMs）仍然容易出现“幻觉”，这是由OpenAI等公司推广的一个非常宽容的术语，大致翻译为“将虚假或误导性信息呈现为事实”。

去年，AI在“幻觉”方面的倾向显得尤为明显，纽约律师Steven Schwartz [使用ChatGPT进行法律研究](https://www.abc.net.au/news/2023-06-24/us-lawyer-uses-chatgpt-to-research-case-with-embarrassing-result/102490068)，但没有对结果进行事实核查。审理此案的法官很快就发现AI在提交的文件中捏造了法律案例，并因其粗心大意而对Schwartz处以5000美元（7750澳元）的罚款。他的故事成为了全球新闻。

[HaluEval](https://arxiv.org/abs/2305.11747)被用作幻觉的基准。测试表明，对于许多LLMs来说，幻觉仍然是一个重要问题。

真实性是生成AI所面临的另一个难题。在新的AI指数报告中，[TruthfulQA](https://arxiv.org/abs/2109.07958)被用作测试LLMs真实性的基准。它的817个问题（涉及健康、法律、金融和政治等话题）旨在挑战我们人类常常错解的常见误解。

GPT-4在2024年初发布，在基准测试中取得了0.59的最高性能，几乎是2021年测试的基于GPT-2模型的三倍。这样的改进表明，当涉及提供真实答案时，LLMs正在逐步变得更好。

AI生成的图像怎么样？要理解文本到图像生成的指数级改进，请查看自2022年以来Midjourney绘制哈利波特的努力：

文本到图像生成如何随Midjourney的逐渐推进而改善

Midjourney/AI指数2024

这相当于AI进展了22个月。你认为人类艺术家要达到类似水平需要多长时间呢？

使用[文本到图像模型的整体评估](https://crfm.stanford.edu/helm/heim/latest/)（HEIM），对LLMs进行了基准测试，评估它们在图像生成能力的12个关键方面上的表现，这些方面对“现实世界部署”图像至关重要。

人类评估了生成的图像，发现没有单一模型在所有标准上都表现出色。在图像与文本对齐或图像与输入文本匹配程度方面，OpenAI的[DALL-E 2](https://newatlas.com/computers/dall-e-2-ai-art/)得分最高。基于稳定扩散的梦幻逼真模型在质量（像照片般程度）、美学（视觉吸引力）和原创性方面排名最高。

## 明年的报告将会非常疯狂。

你会注意到，这份AI指数报告截止到2023年底——那是一个极度动荡的AI加速年，经历了一场惊心动魄的旅程。事实上，比2023年更疯狂的只有2024年，其中我们见证了一些重大事件的发生，比如[Suno](https://newatlas.com/music/suno-v3-music-ai/)、[Sora](https://newatlas.com/technology/creatives-openai-sora-awe-concern/)、[Google Genie](https://newatlas.com/technology/ai-video-games-genie/)、[Claude 3](https://newatlas.com/technology/anthropic-claude-3/)、[Channel 1](https://newatlas.com/home-entertainment/ai-generated-news-anchors/)和[Devin](https://newatlas.com/technology/devin-ai-software-engineer/)等重大进展的发布。

这些产品中的每一个，以及其他几个，都有潜力彻底改变整个行业。而在所有这些产品的上方，悬浮着神秘的GPT-5的幽灵，它可能会是如此广泛和全方位的模型，以至于可能吞噬其他所有模型。

可以肯定的是，AI并不会消失。本报告显示，2023年全年技术发展的迅猛速度表明，AI将继续演变，并缩小人类与技术之间的差距。

我们知道这些内容很难消化，但还有更多。报告还探讨了人工智能演进的负面影响，以及它如何影响全球公众对其安全性、可信度和道德的看法。请关注本系列的第二部分，即将在接下来的几天发布！

出处：[斯坦福大学人工智能研究所](https://hai.stanford.edu/news/ai-index-state-ai-13-charts)
