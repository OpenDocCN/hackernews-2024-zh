<!--yml

category: 未分类

date: 2024-05-27 13:30:00

-->

# NVIDIA将收购GPU编排软件提供商Run:ai | NVIDIA Blog

> 来源：[https://blogs.nvidia.com/blog/runai/](https://blogs.nvidia.com/blog/runai/)

为了帮助客户更有效地利用他们的AI计算资源，NVIDIA今天宣布已达成协议收购Run:ai，这是一个基于Kubernetes的工作负载管理和编排软件提供商。

客户AI部署越来越复杂，工作负载分布在云端、边缘和本地数据中心基础设施之间。

管理和编排生成式AI、推荐系统、搜索引擎和其他工作负载需要复杂的调度以优化系统级别和基础架构上的性能。

Run:ai使企业客户能够管理和优化其计算基础设施，无论是在本地、云端还是混合环境中。

公司在[Kubernetes](https://www.nvidia.com/en-us/glossary/kubernetes/)上建立了一个开放平台，这是现代人工智能和云基础设施的编排层。它支持所有流行的Kubernetes变体，并与第三方AI工具和框架集成。

Run:ai的客户包括全球多个行业中一些最大的企业，这些企业使用Run:ai平台管理数据中心规模的GPU集群。

“自2020年以来，Run:ai与NVIDIA一直是密切合作伙伴，我们共同致力于帮助客户充分利用他们的基础设施，”Run:ai联合创始人兼CEO Omri Geller表示，“我们很高兴能够加入NVIDIA，并期待继续共同前行。”

Run:ai平台为AI开发者及其团队提供：

+   一个集中式界面，管理共享计算基础设施，为复杂的AI工作负载提供更便捷和更快速的访问。

+   实现用户添加功能，将其归类到团队下，提供对集群资源的访问权限、配额、优先级和池的控制，并监控和报告资源使用情况。

+   可以汇集GPU并共享计算能力 —— 从[GPU的分数](https://www.nvidia.com/en-us/technologies/multi-instance-gpu/#:~:text=Multi%2DInstance%20GPU%20(MIG)%20expands%20the%20performance%20and%20value,%2C%20cache%2C%20and%20compute%20cores.)到多个GPU或在不同集群上运行的多个节点的GPU，用于不同的任务。

+   高效的GPU集群资源利用，帮助客户更好地利用其计算投资。

NVIDIA将继续在未来维持Run:ai的产品在同一商业模式下提供。NVIDIA将继续投资于Run:ai的产品路线图，包括在[NVIDIA DGX Cloud](http://www.nvidia.com/dgx-cloud)上实现，这是与领先云平台共同工程的AI平台，提供为生成式AI优化的集成全栈服务。

NVIDIA HGX、DGX 和 DGX Cloud 客户将获得对 Run:ai 的能力的访问，特别是针对大型语言模型部署的AI工作负载。 Run:ai 的解决方案已经与 [NVIDIA DGX](https://www.nvidia.com/en-us/data-center/dgx-platform/)、[NVIDIA DGX SuperPOD](https://www.nvidia.com/en-us/data-center/dgx-superpod/)、[NVIDIA Base Command](https://www.nvidia.com/en-us/data-center/base-command/)、[NGC](https://www.nvidia.com/en-us/gpu-cloud/) 容器和 [NVIDIA AI Enterprise](https://www.nvidia.com/en-us/data-center/products/ai-enterprise/) 软件等产品集成。

NVIDIA 的加速计算平台和 Run:ai 的平台将继续支持广泛的第三方解决方案生态系统，为客户提供选择和灵活性。

与 Run:ai 合作，NVIDIA 将使客户能够在任何地方访问 GPU 解决方案的单一平台。 客户可以期待从开放架构中获得更好的 GPU 利用率、改善的 GPU 基础设施管理以及更大的灵活性。
