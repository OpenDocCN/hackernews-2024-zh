<!--yml
category: 未分类
date: 2024-05-27 13:12:43
-->

# Asking Big Tech to police AI is like turning to ‘oil companies to solve climate change,’ AI researcher says | Fortune

> 来源：[https://fortune.com/2024/04/15/openai-google-microsoft-responsobile-societal-questions-government-responsibility/](https://fortune.com/2024/04/15/openai-google-microsoft-responsobile-societal-questions-government-responsibility/)

Managing artificial intelligence’s impact on society isn’t the responsibility of private companies, noted the founder of a nonprofit AI research lab. Instead, it’s elected governments that should regulate the sector adequately to keep people safe.

Speaking at the [Fortune Brainstorm AI London conference](https://www.linkedin.com/video/live/urn:li:ugcPost:7185622186504654848/) on Monday, Connor Leahy, cofounder of EleutherAI, said the onus of how transformational technologies will impact the public shouldn’t be placed on the tech industry.

“Companies shouldn’t even have to answer” society-wide questions about AI, Leahy told *Fortune*’s Ellie Austin.

He explained: “This might be controversial … but it’s [not the responsibility of oil companies to solve climate change](https://fortune.com/2024/03/19/saudi-aramco-ceo-amin-h-nasser-fantasy-to-phase-out-oil/?utm_source=search&utm_medium=suggested_search&utm_campaign=search_link_clicks).” Instead, he said, it is the [role of governments](https://fortune.com/2024/04/11/pennsylvania-bill-require-companies-consumers-ai-generate-content/?utm_source=search&utm_medium=suggested_search&utm_campaign=search_link_clicks) to stop oil companies from causing climate change “or at least make them pay to clean it up after they’ve caused the mess.”

Rather than guardrails coming from within the industry, they should [cascade down from the government level](https://fortune.com/2024/03/28/ai-regulation-un-eu-us-biden/?utm_source=search&utm_medium=suggested_search&utm_campaign=search_link_clicks)—at least when it comes to society-wide issues, he added.

The boss of EleutherAI—which launched in 2020 and operates primarily through an open Discord server—said responsibility does lie with businesses, however, when it comes to expectations of how much AI can do.

At present the tech is “super unreliable” he continued, adding it does not have “a human level [of] reliability.”

## AI leaders want to be regulated

Some of the most prominent voices in the tech industry agree with Leahy, with even disrupters in the sector imploring the government for some safety nets.

Sam Altman, boss of ChatGPT maker OpenAI, told a Senate Judiciary subcommittee [in May of last year](https://fortune.com/2023/05/16/openai-ceo-sam-altman-congress-regulation-a-i-testimony-eye-on-a-i/) that “the regulation of AI is essential.”

He came out in favor of “appropriate safety requirements, including internal and external testing prior to release” for AI software and also urged some kind of licensing and registration regime for AI systems beyond a certain capability.

However, the [fired-and-rehired billionaire CEO](https://fortune.com/2024/04/03/taylor-swift-sam-altman-net-worth-billionaires/?utm_source=search&utm_medium=suggested_search&utm_campaign=search_link_clicks) also called for a governance framework that is “flexible enough to adapt to new technological developments” and said that regulation should balance “incentivizing safety while ensuring that people are able to access the technology’s benefits.”

Likewise [Tesla CEO Elon Musk](https://fortune.com/2023/11/02/elon-musk-ai-regulations-uk-prime-minister-sunak-ai-safety-summit/#)—who is utilizing AI for everything from large language model Grok to humanoid robot Optimus and autonomous driving—said that regulation will be “annoying” but necessary.

During a conversation with British Prime Minister Rishi Sunak during the U.K. AI Safety Summit, Musk said: “I think we’ve learned over the years that having a referee is a good thing.”

## In the works

CEOs pining after some regulation that will be suitable for multiple markets may have had their wishes granted in recent weeks.

Earlier this month, the U.S. and U.K. governments signed a [memorandum of understanding](https://www.gov.uk/government/news/uk-united-states-announce-partnership-on-science-of-ai-safety) pledging to a shared approach for AI safety [testing and guidance](https://fortune.com/2024/03/18/ai-washing-sec-charges-companies-false-misleading-statments/?utm_source=search&utm_medium=suggested_search&utm_campaign=search_link_clicks).

The governments will work closely with each other and seek other nations to join their approach.

U.S. Commerce Secretary Gina Raimondo said at the time: “Our partnership makes clear that we aren’t running away from these concerns—we’re running at them.

“By working together, we are furthering the long-lasting special relationship between the U.S. and U.K. and laying the groundwork to ensure that we’re keeping AI safe both now and in the future.”

Subscribe to the Eye on AI newsletter to stay abreast of how AI is shaping the future of business.

[Sign up](https://www.fortune.com/newsletters/eye-on-ai?&itm_source=fortune&itm_medium=article_tout&itm_campaign=eye_on_ai)

for free.