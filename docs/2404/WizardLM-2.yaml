- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 13:13:00'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 13:13:00'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: WizardLM 2
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: WizardLM 2
- en: 来源：[https://wizardlm.github.io/WizardLM2/](https://wizardlm.github.io/WizardLM2/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://wizardlm.github.io/WizardLM2/](https://wizardlm.github.io/WizardLM2/)
- en: To present a comprehensive overview of the performance of WizardLM-2, we conduct
    both human and automatic evaluations between our models and diverse baselines.
    As indicated in the following main experimental results, WizardLM-2 demonstrates
    highly competitive performance compared to those leading proprietary works and
    consistently outperforms all the existing state-of-the-art opensource models.
    More associated details and thinking will be presented in our upcoming paper.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面展示 WizardLM-2 的性能，我们对我们的模型与多种基线进行了人工和自动评估。如下所示的主要实验结果表明，与领先的专有作品相比，WizardLM-2
    展示了极具竞争力的性能，并始终优于所有现有的开源模型。更多相关细节和思考将在我们即将发表的论文中呈现。
- en: '**Human Preferences Evaluation**'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**人类偏好评估**'
- en: 'We carefully collected a complex and challenging set consisting of real-world
    instructions, which includes main requirements of humanity, such as writing, coding,
    math, reasoning, agent, and multilingual. We perform a blind pairwise comparison
    between WizardLM-2 and baselines. To each annotator, responses from all models
    are presented, which are randomly shuffled to hide their sources. We report the
    win:loss rate without tie:'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们精心收集了一个包含现实世界指令的复杂和具有挑战性的集合，其中包括人性的主要要求，如写作、编码、数学、推理、代理和多语言。我们对 WizardLM-2
    和基线进行了盲目的两两比较。对每个标注者，所有模型的响应都被随机打乱以隐藏它们的来源。我们报告了胜负比率而没有平局：
- en: WizardLM-2 8x22B is just slightly falling behind GPT-4-1106-preview, and significantly
    stronger than Command R Plus and GPT4-0314.
  id: totrans-split-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WizardLM-2 8x22B 仅稍逊于 GPT-4-1106-preview，并且比 Command R Plus 和 GPT4-0314 强大得多。
- en: WizardLM-2 70B is better than GPT4-0613, Mistral-Large, and Qwen1.5-72B-Chat.
  id: totrans-split-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WizardLM-2 70B 比 GPT4-0613、Mistral-Large 和 Qwen1.5-72B-Chat 都更优秀。
- en: WizardLM-2 7B is comparable with Qwen1.5-32B-Chat, and surpasses Qwen1.5-14B-Chat
    and Starling-LM-7B-beta.
  id: totrans-split-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WizardLM-2 7B 与 Qwen1.5-32B-Chat 相当，并超过了 Qwen1.5-14B-Chat 和 Starling-LM-7B-beta。
- en: Through this human preferences evaluation, WizardLM-2's capabilities are very
    close to the cutting-edge proprietary models such as GPT-4-1106-preview, and significantly
    ahead of all the other open source models.
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这项人类偏好评估，WizardLM-2 的能力非常接近领先的专有模型，如 GPT-4-1106-preview，并且显著领先于所有其他开源模型。
