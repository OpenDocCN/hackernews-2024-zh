- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 13:21:39'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft unveils deepfake tech that's too good to release • The Register
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://www.theregister.com/2024/04/20/microsoft_deepfake_vasa/](https://www.theregister.com/2024/04/20/microsoft_deepfake_vasa/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Microsoft this week demoed VASA–1, a framework for creating videos of people
    talking from a still image, audio sample, and text script, and claims – rightly
    – it's too dangerous to be released to the public.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: These AI-generated videos, in which people can be convincingly animated to speak
    scripted words in a cloned voice, are just the sort of thing the US Federal Trade
    Commission [warned about](https://www.ftc.gov/business-guidance/blog/2023/03/chatbots-deepfakes-voice-clones-ai-deception-sale)
    last month, after previously [proposing a rule](https://www.ftc.gov/news-events/news/press-releases/2024/02/ftc-proposes-new-protections-combat-ai-impersonation-individuals)
    to prevent AI technology from being used for impersonation fraud.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft's team acknowledge as much in their [announcement](https://www.microsoft.com/en-us/research/project/vasa-1/),
    which explains the technology is not being released due to ethical considerations.
    They insist that they're presenting research for generating virtual interactive
    characters and not for impersonating anyone. As such, there's no product or API
    planned.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: '"Our research focuses on generating visual affective skills for virtual AI
    avatars, aiming for positive applications," the Redmond boffins state. "It is
    not intended to create content that is used to mislead or deceive.'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
- en: '"However, like other related content generation techniques, it could still
    potentially be misused for impersonating humans. We are opposed to any behavior
    to create misleading or harmful contents of real persons, and are interested in
    applying our technique for advancing forgery detection."'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
- en: Kevin Surace, Chair of Token, a biometric authentication biz, and frequent speaker
    on generative AI, told *The Register* in an email that while there have been prior
    technology demonstrations of faces animated from a still frame and cloned voice
    file, Microsoft's demonstration reflects the state of the art.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
- en: '"The implications for personalizing emails and other business mass communication
    is fabulous," he opined. "Even animating older pictures as well. To some extent
    this is just fun and to another it has solid business applications we will all
    use in the coming months and years."'
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
- en: The "fun" of deepfakes was 96 percent nonconsensual porn, when [assessed](https://regmedia.co.uk/2019/10/08/deepfake_report.pdf)
    [PDF] in 2019 by cybersecurity firm Deeptrace.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, Microsoft's researchers suggest that being able to create realistic
    looking people and put words in their mouths has positive uses.
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
- en: '"Such technology holds the promise of enriching digital communication, increasing
    accessibility for those with communicative impairments, transforming education,
    methods with interactive AI tutoring, and providing therapeutic support and social
    interaction in healthcare," they propose in a [research paper](https://arxiv.org/abs/2404.10667)
    that does not contain the words "porn" or "misinformation."'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 他们在一篇[研究论文](https://arxiv.org/abs/2404.10667)中提出：“这种技术有望丰富数字通信，增加那些有沟通障碍的人士的可访问性，转变教育，交互式AI辅导方法，并在医疗保健中提供治疗支持和社交互动。”该论文未包含“色情”或“虚假信息”等词语。
- en: While it's arguable AI generated video is not quite the same as a deepfake,
    the latter [defined](https://www.oed.com/dictionary/deepfake_n) by digital manipulation
    as opposed to a generative method, the distinction becomes immaterial when a convincing
    fake can be conjured without cut-and-paste grafting.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然可以争论AI生成的视频与深度伪造图像不完全相同，后者由数字操控而非生成方法[定义](https://www.oed.com/dictionary/deepfake_n)，但当一个令人信服的伪造品可以在没有剪贴接合的情况下被制造出来时，这种区别就变得无关紧要了。
- en: Asked what he makes of the fact that Microsoft is not releasing this technology
    to the public for fear of misuse, Surace expressed doubt about the viability of
    restrictions.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 当被问及微软之所以不将这项技术公开出售的看法时，Surace对限制措施的可行性表示怀疑。
- en: '"Microsoft and others have held back for now until they work out the privacy
    and usage issues," he said. "How will anyone regulate who uses this for the right
    reasons?"'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 他说：“微软和其他公司目前都在观望，直到他们解决了隐私和使用问题。”“谁来规定这项技术只能出于正确的原因使用？”
- en: Surace added that there are already open source models that are similarly sophisticated,
    pointing to [EMO](https://humanaigc.github.io/emote-portrait-alive/). "One can
    pull the source code from GitHub and build a service around it that arguably would
    rival Microsoft's output," he observed. "Because of the open source nature of
    the space, regulating it will be impossible in any case."
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: Surace补充说，已经有类似复杂的开源模型，指向[EMO](https://humanaigc.github.io/emote-portrait-alive/)。他观察到：“人们可以从GitHub上提取源代码，并构建一个围绕它的服务，这个服务可以媲美微软的输出。”由于这个领域的开源特性，无论如何都将无法对其进行有效监管。
- en: That said, countries around the world are trying to regulate AI-fabricated people.
    [Canada](https://www.justice.gc.ca/eng/rp-pr/other-autre/cndii-cdncii/p6.html),
    [China](https://www.nature.com/articles/s42256-022-00513-4), and the [UK](https://www.legislation.gov.uk/ukpga/2023/50/enacted),
    among other nations, all have regulations that can be applied to deepfakes, some
    of which fulfill broader political goals. Britain just this week [made it illegal](https://www.gov.uk/government/news/government-cracks-down-on-deepfakes-creation)
    to create a sexually explicit deepfake image without consent. The sharing of such
    images was already disallowed under the UK's Online Safety Act of 2023.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 各国正在努力监管AI生成的人物。[加拿大](https://www.justice.gc.ca/eng/rp-pr/other-autre/cndii-cdncii/p6.html)，[中国](https://www.nature.com/articles/s42256-022-00513-4)，以及[英国](https://www.legislation.gov.uk/ukpga/2023/50/enacted)，以及其他国家，都有可以适用于深度伪造技术的法规，其中一些法规实现了更广泛的政治目标。英国本周刚刚[宣布](https://www.gov.uk/government/news/government-cracks-down-on-deepfakes-creation)未经同意创建涉及性内容的深度伪造图像属于违法行为。在英国的2023年网络安全法案下，分享这类图像本来就是被禁止的。
- en: In January, a bipartisan group of US lawmakers [introduced](https://www.theregister.com/2024/01/31/ai_defiance_act/)
    the Disrupt Explicit Forged Images and Non-Consensual Edits Act of 2024 (DEFIANCE
    Act), a bill that creates a way for victims of non-consensual deepfake images
    to file a civil claim in court.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在一月份，一群美国跨党派的议员[提出了](https://www.theregister.com/2024/01/31/ai_defiance_act/)2024年《对抗深度伪造图像和非同意编辑法案》（DEFIANCE法案），该法案为非同意深度伪造图像的受害者提供了在法庭上提起民事索赔的途径。
- en: 'And on Tuesday, April 16, the US Senate Committee on the Judiciary, Subcommittee
    on Privacy, Technology, and the Law held [a hearing](https://www.judiciary.senate.gov/committee-activity/hearings/oversight-of-ai-election-deepfakes)
    titled "Oversight of AI: Election Deepfakes."'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 而在4月16日星期二，美国参议院司法委员会隐私、技术和法律小组委员会举行了一场名为“AI监管：选举深度伪造”的[听证会](https://www.judiciary.senate.gov/committee-activity/hearings/oversight-of-ai-election-deepfakes)。
- en: 'In prepared remarks, Rijul Gupta, CEO of DeepMedia, a deepfake detection biz,
    said:'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备好的发言中，DeepMedia公司的首席执行官Rijul Gupta表示：
- en: But think of the marketing applications. ®
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: 但是想象一下市场应用。®
