- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 13:01:38'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '‘Time is running out’: can a future of undetectable deepfakes be avoided? |
    Deepfake | The Guardian'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://www.theguardian.com/technology/2024/apr/08/time-is-running-out-can-a-future-of-undetectable-deepfakes-be-avoided](https://www.theguardian.com/technology/2024/apr/08/time-is-running-out-can-a-future-of-undetectable-deepfakes-be-avoided)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: With more than 4,000 shares, 20,000 comments, and 100,000 reactions on Facebook,
    the photo of the elderly woman, sitting behind her homemade 122nd birthday cake,
    has unquestionably gone viral. “I started decorating cakes from five years old,”
    the caption reads, “and I can’t wait to grow my baking journey.”
  prefs: []
  type: TYPE_NORMAL
- en: The picture is also unquestionably fake. If the curious candles – one seems
    to float in the air, attached to nothing – or the weird amorphous blobs on the
    cake in the foreground didn’t give it away, then the fact the celebrant would
    be the oldest person in the world by almost five years should.
  prefs: []
  type: TYPE_NORMAL
- en: <gu-island name="SignInGateSelector" priority="feature" deferuntil="visible"
    props="{&quot;contentType&quot;:&quot;Article&quot;,&quot;sectionId&quot;:&quot;technology&quot;,&quot;tags&quot;:[{&quot;id&quot;:&quot;technology/deepfake&quot;,&quot;type&quot;:&quot;Keyword&quot;,&quot;title&quot;:&quot;Deepfake&quot;},{&quot;id&quot;:&quot;technology/artificialintelligenceai&quot;,&quot;type&quot;:&quot;Keyword&quot;,&quot;title&quot;:&quot;Artificial
    intelligence (AI)&quot;},{&quot;id&quot;:&quot;technology/computing&quot;,&quot;type&quot;:&quot;Keyword&quot;,&quot;title&quot;:&quot;Computing&quot;},{&quot;id&quot;:&quot;technology/technology&quot;,&quot;type&quot;:&quot;Keyword&quot;,&quot;title&quot;:&quot;Technology&quot;},{&quot;id&quot;:&quot;campaign/email/tech-scape&quot;,&quot;type&quot;:&quot;Campaign&quot;,&quot;title&quot;:&quot;TechScape
    (newsletter signup)&quot;},{&quot;id&quot;:&quot;type/article&quot;,&quot;type&quot;:&quot;Type&quot;,&quot;title&quot;:&quot;Article&quot;},{&quot;id&quot;:&quot;tone/features&quot;,&quot;type&quot;:&quot;Tone&quot;,&quot;title&quot;:&quot;Features&quot;},{&quot;id&quot;:&quot;profile/alex-hern&quot;,&quot;type&quot;:&quot;Contributor&quot;,&quot;title&quot;:&quot;Alex
    Hern&quot;,&quot;twitterHandle&quot;:&quot;alexhern&quot;,&quot;bylineImageUrl&quot;:&quot;https://i.guim.co.uk/img/uploads/2021/02/18/Alex_Hern.jpg?width=300&amp;quality=85&amp;auto=format&amp;fit=max&amp;s=d1c3fa15b8571474cb3275cbd63aeb47&quot;,&quot;bylineLargeImageUrl&quot;:&quot;https://i.guim.co.uk/img/uploads/2021/02/18/Alex_Hern.png?width=300&amp;quality=85&amp;auto=format&amp;fit=max&amp;s=3e949470f77404a2c4e5c723858cafbf&quot;},{&quot;id&quot;:&quot;publication/theguardian&quot;,&quot;type&quot;:&quot;Publication&quot;,&quot;title&quot;:&quot;The
    Guardian&quot;},{&quot;id&quot;:&quot;theguardian/mainsection&quot;,&quot;type&quot;:&quot;NewspaperBook&quot;,&quot;title&quot;:&quot;Main
    section&quot;},{&quot;id&quot;:&quot;theguardian/mainsection/uknews&quot;,&quot;type&quot;:&quot;NewspaperBookSection&quot;,&quot;title&quot;:&quot;UK
    news&quot;},{&quot;id&quot;:&quot;tracking/commissioningdesk/uk-home-news&quot;,&quot;type&quot;:&quot;Tracking&quot;,&quot;title&quot;:&quot;UK
    Home News&quot;}],&quot;isPaidContent&quot;:false,&quot;isPreview&quot;:false,&quot;host&quot;:&quot;https://www.theguardian.com&quot;,&quot;pageId&quot;:&quot;technology/2024/apr/08/time-is-running-out-can-a-future-of-undetectable-deepfakes-be-avoided&quot;,&quot;idUrl&quot;:&quot;https://profile.theguardian.com&quot;,&quot;switches&quot;:{&quot;lightbox&quot;:true,&quot;prebidAppnexusUkRow&quot;:true,&quot;mastheadWithHighlights&quot;:false,&quot;abSignInGateMainVariant&quot;:true,&quot;commercialMetrics&quot;:true,&quot;prebidTrustx&quot;:true,&quot;scAdFreeBanner&quot;:false,&quot;adaptiveSite&quot;:true,&quot;prebidPermutiveAudience&quot;:true,&quot;compareVariantDecision&quot;:false,&quot;enableSentryReporting&quot;:true,&quot;lazyLoadContainers&quot;:true,&quot;ampArticleSwitch&quot;:true,&quot;remarketing&quot;:true,&quot;articleEndSlot&quot;:true,&quot;keyEventsCarousel&quot;:true,&quot;updateLogoAdPartner&quot;:true,&quot;registerWithPhone&quot;:false,&quot;darkModeWeb&quot;:true,&quot;targeting&quot;:true,&quot;remoteHeader&quot;:true,&quot;slotBodyEnd&quot;:true,&quot;prebidImproveDigitalSkins&quot;:true,&quot;ampPrebidOzone&quot;:true,&quot;extendedMostPopularFronts&quot;:true,&quot;emailInlineInFooter&quot;:true,&quot;showNewPrivacyWordingOnEmailSignupEmbeds&quot;:true,&quot;abDeeplyReadRightColumn&quot;:true,&quot;prebidAnalytics&quot;:true,&quot;extendedMostPopular&quot;:true,&quot;ampContentAbTesting&quot;:false,&quot;prebidCriteo&quot;:true,&quot;okta&quot;:true,&quot;imrWorldwide&quot;:true,&quot;acast&quot;:true,&quot;automaticFilters&quot;:true,&quot;twitterUwt&quot;:true,&quot;updatedHeaderDesign&quot;:true,&quot;prebidAppnexusInvcode&quot;:true,&quot;ampPrebidPubmatic&quot;:true,&quot;a9HeaderBidding&quot;:true,&quot;prebidAppnexus&quot;:true,&quot;enableDiscussionSwitch&quot;:true,&quot;prebidXaxis&quot;:true,&quot;stickyVideos&quot;:true,&quot;interactiveFullHeaderSwitch&quot;:true,&quot;discussionAllPageSize&quot;:true,&quot;prebidUserSync&quot;:true,&quot;audioOnwardJourneySwitch&quot;:true,&quot;brazeTaylorReport&quot;:false,&quot;externalVideoEmbeds&quot;:true,&quot;abSignInGateAlternativeWording&quot;:false,&quot;callouts&quot;:true,&quot;sentinelLogger&quot;:true,&quot;geoMostPopular&quot;:true,&quot;weAreHiring&quot;:false,&quot;relatedContent&quot;:true,&quot;thirdPartyEmbedTracking&quot;:true,&quot;prebidOzone&quot;:true,&quot;ampLiveblogSwitch&quot;:true,&quot;ampAmazon&quot;:true,&quot;prebidAdYouLike&quot;:true,&quot;mostViewedFronts&quot;:true,&quot;discussionInApps&quot;:false,&quot;optOutAdvertising&quot;:true,&quot;abSignInGateMainControl&quot;:true,&quot;googleSearch&quot;:true,&quot;brazeSwitch&quot;:true,&quot;darkModeInApps&quot;:true,&quot;prebidKargo&quot;:true,&quot;consentManagement&quot;:true,&quot;personaliseSignInGateAfterCheckout&quot;:true,&quot;redplanetForAus&quot;:true,&quot;prebidSonobi&quot;:true,&quot;idProfileNavigation&quot;:true,&quot;confiantAdVerification&quot;:true,&quot;discussionAllowAnonymousRecommendsSwitch&quot;:false,&quot;dcrTagPages&quot;:true,&quot;absoluteServerTimes&quot;:false,&quot;permutive&quot;:true,&quot;comscore&quot;:true,&quot;ampPrebidCriteo&quot;:true,&quot;tagLinkDesign&quot;:false,&quot;abMpuWhenNoEpic&quot;:false,&quot;newsletterOnwards&quot;:false,&quot;youtubeIma&quot;:true,&quot;webFonts&quot;:true,&quot;prebidImproveDigital&quot;:true,&quot;abAdBlockAsk&quot;:false,&quot;ophan&quot;:true,&quot;crosswordSvgThumbnails&quot;:true,&quot;prebidTriplelift&quot;:true,&quot;weather&quot;:true,&quot;prebidPubmatic&quot;:true,&quot;serverShareCounts&quot;:false,&quot;autoRefresh&quot;:true,&quot;enhanceTweets&quot;:true,&quot;prebidIndexExchange&quot;:true,&quot;prebidOpenx&quot;:true,&quot;prebidHeaderBidding&quot;:true,&quot;idCookieRefresh&quot;:true,&quot;discussionPageSize&quot;:true,&quot;smartAppBanner&quot;:false,&quot;boostGaUserTimingFidelity&quot;:false,&quot;historyTags&quot;:true,&quot;brazeContentCards&quot;:true,&quot;surveys&quot;:true,&quot;remoteBanner&quot;:true,&quot;emailSignupRecaptcha&quot;:true,&quot;prebidSmart&quot;:true,&quot;shouldLoadGoogletag&quot;:true,&quot;inizio&quot;:true}}"
    config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false,&quot;inAdvertisingPartnerABTest&quot;:false,&quot;assetOrigin&quot;:&quot;https://assets.guim.co.uk/&quot;}"></gu-island>
  prefs: []
  type: TYPE_NORMAL
- en: 'Thankfully, the stakes for viral supercentenarian cake decorators are low.
    Which is good, since as [generative AI becomes better and better](https://www.theguardian.com/technology/2024/mar/21/celebrities-victims-of-deepfake-pornography),
    the days of looking for tell-tale signs to spot a fake are nearly over. And that’s
    created a race against time: can we work out other ways to spot fakes, before
    the fakes become indistinguishable from reality?'
  prefs: []
  type: TYPE_NORMAL
- en: “We’re running out of time of still being able to do manual detection,” said
    Mike Speirs, of AI consultancy Faculty, where he leads the company’s work on counter-disinformation.
    “The models are developing at a speed and pace that is, well, incredible from
    a technical point of view, and quite alarming.
  prefs: []
  type: TYPE_NORMAL
- en: '“There are all kinds of manual techniques to spot fake images, from misspelled
    words, to incongruously smooth or wrinkly skin. Hands are a classic one, and then
    eyes are also quite a good tell. But even today, it is time-consuming: It’s not
    something you can truly scale up. And time is running out – the models are getting
    better and better.”'
  prefs: []
  type: TYPE_NORMAL
- en: Since 2021, OpenAI’s image generator, Dall-E, has released three versions, each
    radically more capable than the previous. Indie competitor Midjourney has released
    six in the same period, while the free and open source Stable Diffusion model
    has hit its third version, and Google’s Gemini has joined the fracas. As the technology
    has become more powerful, it’s also become easier to use. The latest version of
    Dall-E is built into ChatGPT and Bing, while Google is offering its own tools
    for free to users.
  prefs: []
  type: TYPE_NORMAL
- en: '<gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:6,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related:
    &quot;,&quot;text&quot;:&quot;Taylor Swift, the pope, Putin: in the age of AI
    and deepfakes, who do you trust? | Alexander Hurst&quot;,&quot;elementId&quot;:&quot;5ce4a907-d9b7-4a90-a0af-fdf0274c5d4a&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/commentisfree/2024/feb/20/ai-deepfakes-taylor-swift-pope-vladimir-putin&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:10}}"
    config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false,&quot;inAdvertisingPartnerABTest&quot;:false,&quot;assetOrigin&quot;:&quot;https://assets.guim.co.uk/&quot;}"></gu-island>'
  prefs: []
  type: TYPE_NORMAL
- en: Tech companies have started to react to the oncoming flood of generated media.
    The Coalition for Content Provenance and Authenticity, which includes among its
    membership the BBC, Google, Microsoft and Sony, has produced standards for watermarking
    and labelling, and in February OpenAI announced it would adopt them for Dall-E
    3\. Now, images generated by the tool have a visible label and machine-readable
    watermark. At the distribution end, Meta has started adding its own labels to
    AI-generated content and says it will remove posts that aren’t labelled.
  prefs: []
  type: TYPE_NORMAL
- en: Those policies might help tackle some of the most viral forms of misinformation,
    like in-jokes or satire that spreads outside its original context. But they can
    also create a false sense of security, says Spiers. “If the public get used to
    seeing AI-generated images with a watermark on it, does that mean they implicitly
    trust any without watermarking?”
  prefs: []
  type: TYPE_NORMAL
- en: That’s a problem, since labelling is by no means universal – nor is it likely
    to be. Big companies like OpenAI might agree to label their creations, but startups
    such as Midjourney don’t have the capacity to devote extra engineering time to
    the problem. And for “open source” projects, like Stable Diffusion, it’s impossible
    to force the watermark to be applied, since it’s always an option to simply “fork”
    the technology and build your own.
  prefs: []
  type: TYPE_NORMAL
- en: And seeing a watermark doesn’t necessarily have the effect one would want, says
    Henry Parker, head of government affairs at factchecking group Logically. The
    company uses both manual and automatic methods to vet content, Parker says, but
    labelling can only go so far. “If you tell somebody they’re looking at a deepfake
    before they even watch it, the social psychology of watching that video is so
    powerful that they will still reference it as if it was fact. So the only thing
    you can do is ask how can we reduce the amount of time this content is in circulation?”
  prefs: []
  type: TYPE_NORMAL
- en: 'Ultimately, that will require finding and removing AI-generated content automatically.
    But that’s hard, says Parker. “We’ve been trying for five years on this, and we’re
    quite honest about the fact that we got to about 70%, in terms of the accuracy
    we can achieve.” In the short term, the issue is an arms race between detection
    and creation: even image generators that have no malicious intent will want to
    try to beat the detectors since the ultimate goal is to create something as true
    to reality as a photo.'
  prefs: []
  type: TYPE_NORMAL
- en: '[skip past newsletter promotion](#EmailSignup-skip-link-12)'
  prefs: []
  type: TYPE_NORMAL
- en: after newsletter promotion
  prefs: []
  type: TYPE_NORMAL
- en: 'Logically thinks the answer is to look around the image, Parker says: “How
    do you actually try to look at the way that disinformation actors behave?” That
    means monitoring conversations around the web to capture malefactors in the planning
    stage on sites like 4chan and Reddit, and keeping an eye on the swarming behaviour
    of suspicious accounts that have been co-opted by a state actor. Even then, the
    problem of false positives is difficult. “Am I looking at a campaign that Russia
    is running? Or am I looking at a bunch of [Taylor Swift](https://www.theguardian.com/technology/2024/jan/31/inside-the-taylor-swift-deepfake-scandal-its-men-telling-a-powerful-woman-to-get-back-in-her-box)
    fans sharing information about concert tickets?”'
  prefs: []
  type: TYPE_NORMAL
- en: Others are more optimistic. Ben Colman, chief executive of image detection startup
    Reality Defender, thinks there will always be the possibility of detection, even
    if the conclusion is simply flagging something as possibly fake rather than ever
    reaching a definitive conclusion. Those signs can be anything from “a filter at
    higher frequencies indicating too much smoothness” to, for video content, the
    failure to render the invisible, but detectable, flushing that everyone shows
    each time their heart beats fresh blood around their face.
  prefs: []
  type: TYPE_NORMAL
- en: “Things are gonna keep advancing on the fake side, but the real side is not
    changing,” Colman concludes. “We believe that we will get closer to a single model
    that is more evergreen.”
  prefs: []
  type: TYPE_NORMAL
- en: Tech, of course, is only part of the solution. If people really believe a photo
    of a 122-year-old woman with a cake she baked herself is real, then it isn’t going
    to take state-of-the-art image generators to trick them into believing other,
    more harmful things. But it’s a start.
  prefs: []
  type: TYPE_NORMAL
- en: Join Alex Hern for a Guardian Live online event about AI, deepfakes and elections,
    on Wednesday 24 April at 8pm BST. [Book tickets here](https://www.theguardian.com/guardian-live-events/2024/mar/07/real-news-v-fake-news-is-ai-a-threat-to-democracy)
  prefs: []
  type: TYPE_NORMAL
