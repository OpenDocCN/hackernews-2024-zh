<!--yml

category: 未分类

date: 2024-05-27 13:20:06

-->

# 早期访问 GPT-4 微调初印象 | Supersimple

> 来源：[https://www.supersimple.io/blog/gpt-4-fine-tuning-early-access](https://www.supersimple.io/blog/gpt-4-fine-tuning-early-access)

几周前，我们终于获得了 GPT-4 微调 API 的访问权限（限量早期访问），并且非常兴奋地查看其表现如何。自从首次可用 GPT-3 达芬奇模型进行微调以来，我们一直是 OpenAI 微调模型的用户。

毫不奇怪，经过微调的 GPT-4 在我们的使用案例中表现远远优于微调的 GPT-3.5（超过 50% 的改进！）。我们将在下文深入探讨如何使用这些模型，但让我们首先比较一下我们在 Supersimple 使用的几种基于 OpenAI 的模型：

+   微调（FT）GPT-3 达芬奇模型，我们最初使用的模型

+   GPT-3.5 和 GPT-4 基础模型

+   使用自定义专有数据集对 GPT-3.5 和 GPT-4 进行了微调

基于我们的测试集的相对模型性能；FT 表示经过微调的模型

讨论的模型是针对特定领域的数据问题使用自然语言进行微调。LLM 被委托组合适当的报告和用户问题的底层查询。

这些评估是使用我们在 Supersimple 使用的专有测试数据集进行的；达芬奇（GPT-3）的表现作为基准。为了更深入地了解这些模型在哪些方面表现良好，让我们更详细地说明我们实际所做的。我们还将包括更多比较数据，包括成本和延迟！

## 背景和 Supersimple 上我们 LLM 的使用情况

Supersimple 是一个数据分析平台，允许用户深入挖掘其数据，以秒级速度回答复杂的临时问题，并发现深入的数据洞察。

我们的用户可以用自然语言（简明英语）提出关于其数据的问题，并通过表格和可视化形式得到答案。AI 通过几个无代码步骤解释其工作，用户可以继续深入 —— 使用自然语言或点击我们的数据平台上的几个按钮。

我们使用 LLM 来回答用户的自然语言问题，目标是为进一步深入数据提供一个很好的起点。LLM 获取用户的问题、其语义数据模型的相关部分、现有的报告和仪表板，并生成一个尽可能有上下文的探索，以回答该问题。

‍

此功能也特别适用作为入门工具，展示我们平台的功能，并教导用户如何使用我们的数据探索 UI。对于长期用户，用简明英语有时仍然是回答问题的最快方式，但有时他们只需点击几下按钮就能达到同样的速度。

## 实施

从技术上讲，LLM输出一种我们为特定用例设计的自定义高级标记语言（DSL），这种DSL在token效率和与预训练语言模型的良好对齐方面表现良好。这个DSL编译成JSON，然后我们将其编译成一个或多个要执行的数据库查询。最后，根据DSL指定的报告结构，我们呈现一个交互式数据探索给用户。

强调一下，这个任务与传统的文本转SQL问题有很多不同之处：

+   输出是一个无代码探索，对用户透明且可解释。这意味着模型直接与我们的数据平台交互。我们认为生成和展示代码或SQL是向用户证明/解释报告的可怕方式——即使这些用户是技术人员，尤其是如果他们不是。

+   结果报告/探索在UI中易于编辑，旨在作为进一步深入探索的起点。在探索数据时，您不希望考虑重构SQL查询。

+   复杂的输出被分成代表推理过程中逻辑步骤的单个块。

+   我们将构建正确的SQL查询的复杂性（包括许多连接、CTE和子查询）转移到平台的“查询引擎”，该引擎将模型输出的语义步骤确定性地编译成有效且高效的SQL。这意味着LLM不需要担心整个问题类别，从而可以在整体上表现更好。

+   在生成输出时，模型会考虑现有的仪表板和用户定义的概念。

由于任务的复杂性和需要自定义的输出格式（我们设计的用于有效构建应用程序UI状态的DSL），我们发现微调模型的性能通常比基础模型显著更好。

重申一下：我们从不使用LLM生成SQL——我们的LLM只直接与我们的应用程序交互。

## **微调和基准测试**

对于微调，我们使用了一个专有数据集，其中包含数千万个token的问答示例，包括数据模型的组合，问题和完美的输出报告以回答这些问题。

GPT-3.5（gpt-3.5-turbo-0125）和GPT-4（gpt-4-0613，目前唯一可微调的GPT-4模型）都进行了3轮的微调。

对于这里的两个基础模型（gpt-3.5-turbo-0125和gpt-4-0125-preview），我们使用了相同的提示，包含8次示例。除了davinci之外的所有模型的性能在2024年3月初进行了评估，而davinci的性能则是在2023年8月进行了最后评估。

性能比较显示在下表中。对于我们的测试集，微调的GPT-4 **性能比GPT-3.5提高了56%**，这是一个显著的改进，尽管略小于从Davinci微调到GPT-3.5微调（96%）的跃升。

微调的GPT-4比微调的GPT-3.5稍慢（21.6 tokens/s对31 tokens/s）。

*注：本文的原始版本显示了GPT-4的延迟统计数据明显更差：我们的第一组基准测试仅实现了5.8个token/s，但OpenAI已经大大改进了服务的稳定性和速度。*

虽然GPT-4的成本显著更高（推断高15倍，训练高11倍，相比GPT-3.5），但根据您的使用情况，这可能不是一个重要因素。

我们在我们的内部测试集上对模型进行了基准测试，该测试集包含100个多样化的问题。下表显示了问题和模型性能的示例：

| 问题 | Davinci FT | GPT-3.5 | GPT-4 | GPT-3.5 FT | GPT-4 FT |
| --- | --- | --- | --- | --- | --- |
| 用户ID为342122的用户 | ✅ | ✅ | ✅ | ✅ | ✅ |
| 使用分析仪表板的公司？ | ✅ | ❌ | ✅ | ✅ | ✅ |
| 我们的ARR是多少，以及随时间的变化如何？ | ❌ | ❌ | ❌ | ✅ | ✅ |
| 本月订阅即将到期的公司 | ❌ | ❌ | ❌ | ✅ | ✅ |
| 账户级别特征使用情况的季度季度变化 | ❌ | ❌ | ❌ | ❌ | ✅ |
| 今年与去年的流失趋势 | ❌ | ❌ | ❌ | ❌ | ✅ |
| 我们的入职漏斗中的主要障碍是什么？ | ❌ | ❌ | ❌ | ❌ | ❌ |

‍

尽管性能有所提升，但模型在试图用单一完成来回答广泛和开放的查询时仍然存在困难。

令人担忧的是，从微调中出现了递减回报的可观趋势。虽然微调的Davinci相比其基础模型显示了显著改进，微调的GPT-3.5提供的收益较少，并且通过微调GPT-4获得的进展更小。

为了解决这些限制，在生产中，我们很少依赖单一模型调用。相反，我们采用各种专门的模型、提示和启发式方法来提高准确性和响应时间，从而实现比任何单一模型更好的性能。

## **结论**

从GPT-3-davinci公开可用的早期，我们就开始在生产中使用微调的LLMs，因此我们非常兴奋地试用了微调GPT-4。一方面，我们对其在性能上超越之前最好的GPT-3.5-FT感到惊讶。

另一方面，我们确实预期到这一点，因为GPT-3.5和GPT-4基础版本之间的差距已经是巨大的。

经过微调的GPT-4在我们的测试集上明显优于经过微调的GPT-3.5和原始GPT-4。我们看到了与去年从GPT-3-FT转换到GPT-3.5-FT时相似的改进。

目前最大模型面临的主要问题是较高的延迟。由于我们的目标是使人与数据的交互变得流畅和轻松，我们不能让用户在人工智能后面等待超过几秒钟。

由于较高的延迟（和成本），我们仅在某些问题的特定子集以及某些最关键的推理步骤中使用GPT-4-FT。对于其余部分，我们使用包括GPT-3.5-FT在内的各种其他模型。

使用当前最先进的模型，我们认为：

1.  一个单一模型及其单一完成（或者使用托管的LLMs进行API调用）对于许多需要非平凡推理能力的真实应用程序是不够的。

1.  在工作环境中，任何AI都需要准确地向用户解释其工作（人们在看到证据之前甚至不相信其他人！）

在我们的网站上阅读更多关于我们的[自然语言问答AI](https://www.supersimple.io/platform/natural-language-ai)，或者立即开始使用我们的下一代商业智能平台。
