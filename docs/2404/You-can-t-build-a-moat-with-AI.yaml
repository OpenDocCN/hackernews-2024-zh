- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 13:06:27'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 13:06:27'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: You can't build a moat with AI
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 你不能仅凭AI来构建壕沟
- en: 来源：[https://generatingconversation.substack.com/p/you-cant-build-a-moat-with-ai](https://generatingconversation.substack.com/p/you-cant-build-a-moat-with-ai)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://generatingconversation.substack.com/p/you-cant-build-a-moat-with-ai](https://generatingconversation.substack.com/p/you-cant-build-a-moat-with-ai)
- en: Differentiating AI applications is a hot topic, and it’s hard. Is everything
    just a RAG application? (No.) If a company gets good enough at RAG in one domain,
    does it neatly transfer to another domain? (Maybe! We’re not sure.) Are all AI
    applications just going to be built by OpenAI? (Probably not.)
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 区分AI应用是一个热门话题，也很困难。一切都只是RAG应用吗？（不是。）如果一家公司在一个领域擅长RAG，这是否会完美地转移到另一个领域？（也许！我们不确定。）所有的AI应用最终会全部由OpenAI构建吗？（很可能不会。）
- en: Managing technical and go-to-market differentiation is an eternal question for
    startups. Some believe it’s all in the technology, and others believe it’s all
    in the execution. Whatever the case may be, it’s become clear to us that there’s
    not very much you can do to differentiate yourself using just LLMs. **The real
    differentiation lies in your data you feed into your models.**
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 对于初创公司来说，管理技术和市场去差异化是一个永恒的问题。有些人认为一切都在技术上，而其他人认为一切都在执行上。无论情况如何，我们清楚地认识到，仅仅依靠LLMs是无法实现真正的差异化的。**真正的差异化在于你为模型提供的数据。**
- en: This might sound surprising at first; after all, it’s the LLMs that have kicked
    off the current AI hype cycle. If they don’t matter, then… what are we all doing
    here?
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 起初这可能听起来令人惊讶；毕竟，正是LLMs引发了当前的AI炒作周期。如果它们不重要，那么我们在这里都在做什么呢？
- en: 'LLMs are obviously incredibly powerful, but we believe the core models and
    their use will effectively be commoditized across competitive products in the
    same space. In that world, having a clever use of LLMs ([especially if you’re
    relying on a single LLM call](https://generatingconversation.substack.com/publish/posts/detail/142618146)!)
    is simply not going to cut it. Instead, you’ll need to think carefully about what
    data you’re using to build your application. Here’s why:'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 'LLMs are obviously incredibly powerful, but we believe the core models and
    their use will effectively be commoditized across competitive products in the
    same space. In that world, having a clever use of LLMs ([尤其是如果你依赖于单一的LLM调用](https://generatingconversation.substack.com/publish/posts/detail/142618146)!)
    is simply not going to cut it. Instead, you’ll need to think carefully about what
    data you’re using to build your application. Here’s why:'
- en: '**Everyone’s using the same model.** Regardless of what you believe the best
    LLM is — we mostly think it’s GPT-4 — there’s probably a model that outperforms
    its competitors for each major category of task. If you had to bet, that model
    is probably still GPT-4 for most use cases, but Claude is catching up quickly.
    Everyone today can easily switch between models and experiment with what works
    best today for their application. That means that whatever you’re building, the
    advantage you get by picking the right model is small.'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**每个人都在使用相同的模型。** 无论你认为最好的LLM是什么 — 我们大多数人认为是GPT-4 — 对于每个主要任务类别，可能有一个模型超越其竞争对手。如果你必须打赌，那个模型对于大多数用例可能仍然是GPT-4，但克劳德追赶速度很快。今天每个人都可以轻松切换模型，并尝试对他们的应用程序来说最有效的方法。这意味着，无论你正在构建什么，通过选择正确的模型获得的优势都是微小的。'
- en: Deviating from the norm is also dangerous — it might get you unexpectedly good
    answers in some cases and unexpectedly bad answers in other cases. When a lot
    of AI startups are working to build trust, that’s a risky proposition, and as
    a result, most teams default back to using the safe models. That means that what
    you put into the model matters more than ever.
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: 偏离常规也是危险的 —— 它可能在某些情况下给你意外的好答案，但在其他情况下给你意外的坏答案。当许多AI初创公司努力建立信任时，这是一个冒险的提议，因此，大多数团队默认回到使用安全的模型。这意味着，你输入模型的内容比以往任何时候都更重要。
- en: '**And your prompts aren’t IP.** It might feel like your applications’ prompts
    or prompt templates are a good form of differentiation. After all, your top-notch
    engineering team has invested days into tuning them to have the right response
    characteristics, tone, and output style. Of course, giving your competitors your
    prompts would probably accelerate their progress, but any good engineering team
    will figure out the right changes quickly. The main reason is that the experimentation
    (with the right evaluation data!) is quick and easy — trying a new prompt template
    isn’t much harder than writing it out. All it really takes is a little bit of
    patience, some creativity, and extra Azure OpenAI credits.'
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**而且你的提示并不是知识产权。** 也许你会觉得你应用程序的提示或提示模板是一种良好的区分形式。毕竟，你的顶级工程团队已经投入了数天来调整它们，以确保具有正确的响应特性、语调和输出风格。当然，将你的提示提供给竞争对手可能会加速他们的进展，但任何优秀的工程团队都将迅速找到正确的变更。主要原因在于，通过正确的评估数据进行实验是迅速而简单的
    —— 尝试新的提示模板几乎和编写它一样简单。真正需要的只是一点耐心、一些创意和额外的Azure OpenAI信用点。'
- en: Your prompts might be better today, but we can almost guarantee you that advantage
    won’t last. You’ll have to look elsewhere.
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: 今天你的提示可能更好，但我们几乎可以保证这种优势不会持续下去。你必须在其他方面寻找。
- en: '**So (as always) it comes down to the data.** If the models are commoditized,
    and the prompts are commoditized, all that’s left to differentiate your AI application
    is the data you feed into your LLMs. **Thankfully, the data makes a huge difference**.
    Any application you build — especially if you’re working with enterprises — is
    going require using your customers’ data to drive your applications’ responses
    and decisions. Every team is going to have slightly different data and slightly
    different preferences about how it’s used.'
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**因此（一如既往）关键在于数据。** 如果模型和提示被商品化，那么区分你的AI应用程序的唯一剩下的就是你输入到LLMs中的数据。**幸运的是，数据确实能够产生巨大的差异**。任何你构建的应用程序
    —— 尤其是如果你正在与企业合作 —— 都需要利用客户的数据来驱动你的应用程序的响应和决策。每个团队对数据的使用方式和偏好都会略有不同。'
- en: The nice thing about LLMs is that the they do well with arbitrary, unstructured
    data. The catch is that your customers have a *ton* of arbitrary, unstructured
    data. Some of it will be absolute gold; some of it will be completely useless.
    As an application builder, it’s on you to figure out how to use that data.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs的好处在于它们能很好地处理任意、非结构化的数据。但问题在于，你的客户有大量的任意、非结构化的数据。其中一些可能是绝对宝藏；而一些则完全无用。作为应用程序构建者，你需要找出如何利用这些数据。
- en: '**And of course… garbage in, garbage out.** LLMs as with any AI model (or any
    system?) are garbage in, garbage out. That puts a huge burden on your ability
    to find and use the right data. For reference, our team at RunLLM has spent roughly
    70% of our engineering cycles in the last quarter on data engineering — everything
    from pre-processing data at ingestion time to implementing hybrid search to reranking
    results. Whenever we get a customer complaint or request, the first solution has
    typically been to improve the data engineering process.'
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**当然…… 垃圾进，垃圾出。** 就像任何AI模型（或任何系统？）一样，LLMs也是垃圾进，垃圾出。这对你找到并使用正确数据的能力施加了巨大的负担。作为参考，我们RunLLM团队在上个季度大约70%的工程周期中都在进行数据工程工作
    —— 从数据摄取预处理到实施混合搜索和重新排序结果。每当我们收到客户投诉或请求时，通常的第一解决方案是改进数据工程流程。'
- en: The result is a fairly complex data pipeline that can account for customer priorities,
    process a wide variety of data types, and generate metadata for downstream complex
    reasoning tasks. It certainly isn’t something that can be reproduced with a little
    bit of experimentation. It’s directly driven by getting hands-on customer feedback.
    The result is what’s allowed us to consistently differentiate ourselves with straightforward,
    grounded responses, and minimal hallucinations.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是一个相当复杂的数据流水线，可以考虑客户的优先事项，处理各种数据类型，并为下游的复杂推理任务生成元数据。这绝不是凭借少量实验就能复制的东西。它直接受到获取实际客户反馈的驱动。其结果使我们能够始终通过简单、扎实的响应和最少的臆想来区分自己。
- en: '* * *'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: We firmly believe the moat for AI application is in the data and the data engineering
    today. At some point, the process of building custom LLMs might get so fast and
    easy that we’ll all return to building our own models. That simply isn’t the case
    today.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们坚信，今天AI应用程序的护城河在于数据和数据工程。在某个时候，定制LLMs的过程可能会变得如此快速和简单，以至于我们都将返回构建自己的模型。但现在情况并非如此。
- en: What that also means is that you don’t need to be an AI genius to succeed in
    building applications. In fact, focusing on the AI might be a detriment to your
    differentiation at a certain point. With thoughtful software engineering and a
    focus on customer data, you’ll build a moat over time.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这也意味着，您不需要成为人工智能天才才能成功构建应用程序。事实上，过度关注人工智能可能会在某个时刻对您的差异化产生不利影响。通过深思熟虑的软件工程和对客户数据的关注，您将逐渐建立起一道护城河。
