- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 13:25:11'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 13:25:11'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: On Llama-3 and Dwarkesh Patel's Podcast with Zuckerberg
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于Llama-3和Dwarkesh Patel与扎克伯格的播客
- en: 来源：[https://thezvi.substack.com/p/on-llama-3-and-dwarkesh-patels-podcast](https://thezvi.substack.com/p/on-llama-3-and-dwarkesh-patels-podcast)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://thezvi.substack.com/p/on-llama-3-and-dwarkesh-patels-podcast](https://thezvi.substack.com/p/on-llama-3-and-dwarkesh-patels-podcast)
- en: It was all quiet. Then it wasn’t.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都很平静。然后就不平静了。
- en: '[Note the timestamps on both of these](https://twitter.com/tszzl/status/1781043498801893827).'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[请注意这两个时间戳](https://twitter.com/tszzl/status/1781043498801893827)。'
- en: '[Dwarkesh Patel did a podcast with Mark Zuckerberg](https://www.youtube.com/watch?v=bc6uFV9CJGg&ab_channel=DwarkeshPatel)
    on the 18th. It was timed to coincide with the release of much of Llama-3, very
    much the approach of telling your story directly. Dwarkesh is now the true tech
    media. A meteoric rise, and well earned.'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[Dwarkesh Patel和马克·扎克伯格一起做了一个播客](https://www.youtube.com/watch?v=bc6uFV9CJGg&ab_channel=DwarkeshPatel)，时间是18日。这与Llama-3的大部分发布时间相吻合，非常直接地讲述了你的故事的方法。Dwarkesh现在是真正的科技媒体。一个迅猛的崛起，而且当之无愧。'
- en: This is two related posts in one. First I cover the podcast, then I cover Llama-3
    itself.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是两篇相关的帖子。首先我涵盖了播客，然后我涵盖了Llama-3本身。
- en: My notes are edited to incorporate context from later explorations of Llama-3,
    as I judged that the readability benefits exceeded the purity costs.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我的笔记经过编辑，包含了后来对Llama-3的深入探索的背景，我判断可读性的好处超过了纯洁性的代价。
- en: (1:00) They start with Llama 3 and the new L3-powered version of Meta AI. Zuckerberg
    says “With Llama 3, we think now that Meta AI is the most intelligent, freely-available
    assistant that people can use.” If this means ‘free as in speech’ then the statement
    is clearly false. So I presume he means ‘free as in beer.’
  id: totrans-split-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:00) 他们从Llama 3和Meta AI新版本L3开始。扎克伯格说：“通过Llama 3，我们现在认为Meta AI是人们可以使用的最智能、自由的助手。”如果这意味着“言论自由”，那么这种说法显然是错误的。因此，我推测他的意思是“免费如啤酒”。
- en: Is that claim true? Is Meta AI now smarter than GPT-3.5, Claude 2 and Gemini
    Pro 1.0? As I write this it is too soon to tell. Gemini Pro 1.0 and Claude 3 Sonnet
    are slightly ahead of Llama-3 70B on the Arena leaderboard. But it is close. The
    statement seems like a claim one can make within ‘reasonable hype.’ Also, Meta
    integrates Google and Bing for real-time knowledge, so the question there is if
    that process is any good, since most browser use by LLMs is not good.
  id: totrans-split-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这种说法是否属实？Meta AI现在是否比GPT-3.5、Claude 2和Gemini Pro 1.0更智能？在我写这篇文章时，现在还为时过早。Gemini
    Pro 1.0和Claude 3 Sonnet在Arena排行榜上略胜于Llama-3 70B。但这很接近。这种说法似乎可以在“合理的炒作”范围内提出。此外，Meta集成了Google和Bing进行实时知识检索，因此问题在于该过程是否有效，因为大多数LLM的浏览使用情况并不理想。
- en: (1:30) Meta are going in big on their UIs, top of Facebook, Instagram and Messenger.
    That makes sense if they have a good product that is robust, and safe in the mundane
    sense. If it is not, this is going to be at the top of chat lists for teenagers
    automatically, so whoo boy. Even if it is safe, there are enough people who really
    do not like AI that this is probably a whoo boy anyway. Popcorn time.
  id: totrans-split-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:30) Meta在他们的UI上投入了大量资源，包括Facebook、Instagram和Messenger。如果他们有一个好的、稳固的产品，符合日常安全需求，这是有道理的。如果不是，这将自动成为青少年聊天列表的头号。即使它是安全的，也有足够多的人不喜欢AI，所以这可能还是一个问题。爆米花时间。
- en: (1:45) They will have the ability to animate images and it generates high quality
    images as you are typing and updates them in real time as you are typing details.
    I can confirm this feature is cool. He promises multimodality, more ‘multi-linguality’
    and bigger context windows.
  id: totrans-split-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:45) 他们将能够为图像添加动画，并在您输入详细信息时实时生成高质量图像并更新它们。我可以确认这个功能很酷。他承诺多模态、更多“多语言性”和更大的上下文窗口。
- en: (3:00) Now the technical stuff. Llama-3 follows tradition in training models
    in three sizes, here 8b, 70b that released on 4/18, and a 405b that is still training.
    He says 405b is already around 85 MMLU and they expect leading benchmarks. The
    8b Llama-3 is almost as good as the 70b Llama-2.
  id: totrans-split-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3:00) 现在来看技术细节。Llama-3在训练模型方面保持了三种规模的传统，这里有8b、4/18发布的70b以及仍在训练中的405b。他说405b已经接近85
    MMLU，他们期望领先的基准测试结果。8b的Llama-3几乎和70b的Llama-2一样出色。
- en: (5:15) What went wrong earlier for Meta and how did they fix it? He highlights
    Reels, with its push to recommend ‘unconnected content,’ meaning things you did
    not ask for, and not having enough compute for that. They were behind. So they
    ordered double the GPUs that needed. They didn’t realize the type of model they
    would want to train.
  id: totrans-split-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (5:15) Meta 早期出了什么问题，他们是如何解决的？他强调了 Reels，通过推荐‘不相关内容’，意味着你没有要求的东西，并且没有足够的计算力来实现。他们落后了。因此，他们订购了双倍于所需的
    GPU。他们没有意识到他们想要训练的模型类型。
- en: (7:30) Back in 2006, what would Zuck have sold for when he turned down $1 billion?
    He says he realized if he sold he’d just build another similar company, so why
    sell? It wasn’t about the number, he wasn’t in position to evaluate the number.
    And I think that is actually wise there. You can realize that you do not want
    to accept any offer someone would actually make.
  id: totrans-split-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (7:30) 2006 年，如果扎克当时拒绝了 10 亿美元的收购，他会因此得到什么？他说他意识到如果卖掉了，他只会再建立一个类似的公司，那为什么要卖？这不是关于数字的问题，他不在评估数字的位置上。我认为这实际上是明智的。你可以意识到你不想接受任何人实际可能提出的报价。
- en: (9:15) When did making AGI become a key priority? Zuck points out Facebook AI
    Research (FAIR) is 10 years old as a research group. Over that time it has become
    clear you need AGI, he says, to support all their other products. He notes that
    training models on coding generalizes and helps their performance elsewhere, and
    that was a top focus for Llama-3\.
  id: totrans-split-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (9:15) 什么时候使 AGI 成为一个关键优先事项？扎克指出 Facebook AI Research (FAIR) 成立已有 10 年作为一个研究组。他说，在这段时间里，他们明白了需要
    AGI 来支持他们的其他所有产品。他指出，在编码上训练模型是通用化的，并且有助于在其他地方提高性能，这是 Llama-3 的重点关注。
- en: So Meta needs to solve AGI because if they don’t ‘their products will be lame.’
    It seems increasingly likely, as we will see in several ways, that Zuck does not
    actually believe in ‘real’ AGI. By ‘AGI’ he means somewhat more capable AI.
  id: totrans-split-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，Meta 需要解决 AGI，因为如果他们不这样做，‘他们的产品将会变得无聊’。从几个方面看，似乎越来越可能，扎克实际上并不相信‘真正的’AGI。对于‘AGI’，他的意思是稍微更有能力的
    AI。
- en: (13:40) What will the Llama that makes cool products be able to do? Replace
    the engineers at Meta? Zuck tries to dodge, says we’re not ‘replacing’ people
    as much as making them more productive, hopefully 10x or more, says there is no
    one threshold for human intelligence, AGI isn’t one thing. He is focused on different
    modalities, especially 3D and emotional understanding, in addition to the usual
    things like memory and reasoning.
  id: totrans-split-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (13:40) 制造出了酷炫产品的拉马能做什么？取代 Meta 的工程师？扎克试图回避，称我们并非‘替换’人类，而是让他们更加高效，希望提高 10 倍或更多，表示人类智能没有一个统一的门槛，AGI
    也不是一个单一的事物。他专注于不同的模态，特别是 3D 和情感理解，除了常规的记忆和推理等方面。
- en: (16:00) What will we use all our data for? Zuck says AI will be in everything,
    and there will be a Meta general assistant product that does complicated tasks.
    He wants to let creators own an AI and train it how they want to ‘engage their
    community.’ But then he admits these are only consumer use cases and it will change
    everything in the economy.
  id: totrans-split-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (16:00) 我们将如何利用所有的数据？扎克表示 AI 将无处不在，将有一个 Meta 的通用助手产品来执行复杂任务。他希望让创作者拥有一个 AI 并按照他们想要的方式进行训练，以‘参与他们的社区’。但随后他承认这些仅仅是消费者使用案例，它将改变整个经济格局。
- en: (18:25) When do we get the good agents? Zuck says we do not know. It depends
    on the scaffolding. He wants to progressively move more of that into the model
    to make them better agents on their own so this stops being ‘brittle and non-general.’
    It has much better tool use, you do not need to hand code. This Is Fine.
  id: totrans-split-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (18:25) 我们何时得到优秀的代理人？扎克表示我们不知道。这取决于脚手架。他希望逐步将更多的内容移入模型，使它们自己成为更好的代理人，从而避免‘脆弱和非通用’的情况。它有更好的工具使用，不需要手动编码。这很好。
- en: (22:20) What community fine tune is most personally exciting? Zuck says he doesn’t
    know, it surprises you, if he knew he’d build it himself.
  id: totrans-split-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (22:20) 哪种社区微调最让你个人兴奋？扎克表示他不知道，这让你感到惊讶，如果他知道的话，他会亲自构建。
- en: This doesn’t match my model of this, where you want to specialize, some things
    are left to others, which seems doubly true here with open model weights. He mentions
    that 8b is too big for many use cases, we should try to build a 1b or smaller
    model too.
  id: totrans-split-24
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这与我对这一模型的理解不符，你希望专业化，某些事情留给其他人，这在开放模型权重方面显然是双重真理。他提到 80 亿对于许多使用案例来说太大了，我们应该尝试构建一个
    10 亿或更小的模型。
- en: Also he mentions that they do a ton of inference because they have a ton of
    customers, so that dominates their compute usage over time. It makes sense for
    them to do what for others would be overtraining, also training more seemed to
    keep paying dividends for a long time.
  id: totrans-split-25
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他还提到，他们进行了大量的推断，因为他们有大量的客户，所以这主导了他们的计算使用情况。这对他们来说是有意义的，为其他人来说可能是过度训练，此外，长期来看，进行更多的训练似乎继续产生回报。
- en: I would presume the other big labs will be in similar positions going forward.
  id: totrans-split-26
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我认为其他大型实验室在未来也会处于类似的位置。
- en: (26:00) How much better will Llama-4 get? How will models improve? Zuck says
    (correctly) this is one of the great questions, on one knows, how long does an
    exponential curve keep going? He says probably long enough that the infrastructure
    is worth investing in, and a lot of companies are investing a lot.
  id: totrans-split-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (26:00) Llama-4 将会变得更好多少？模型将如何改进？Zuck 说（正确地），这是一个重要的问题之一，没有人知道，指数曲线会持续多久？他说，可能足够长，以至于基础设施值得投资，许多公司正在大力投资。
- en: (28:00) He thinks energy constraints will soon bind, not chips. No one has built
    a gigawatt single training cluster yet. And that is slower because energy gets
    permitted at the speed of government and then has to be physically built. One
    does not simply get a bunch of energy, compute and data together.
  id: totrans-split-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (28:00) 他认为能源限制很快会成为约束，而不是芯片。到目前为止，还没有人建造过一台千兆瓦级的单一训练集群。这也更慢，因为能源的批准速度是政府的速度，然后必须在物理上建造。不能简单地将一大堆能源、计算和数据放在一起。
- en: If concentrations of energy generation are the true bottleneck, then anyone
    who says ‘government has no means to control this’ or ‘government cannot control
    this without being totalitarian’ would be very wrong, this is a very easy thing
    to spot, isolate and supervise. Indeed, we almost ‘get it for free’ given we are
    already massively over restricting energy generation and oversee industrial consumption.
  id: totrans-split-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果能源生成的集中是真正的瓶颈，那么任何说‘政府没有手段控制这个’或‘政府无法在不成为极权主义的情况下控制这个’的人都是错的，这是一个非常容易发现、隔离和监管的事情。事实上，我们几乎‘免费获得’了，因为我们已经大量限制了能源生成并监督工业消耗。
- en: (30:00) What would Meta do with 10x more money? More energy, which would allow
    bigger clusters, but true bottleneck is time. Right now data center energy tops
    out at something like 50mw-150mw. But 300mw-1gw, that’s new, that’s a meaningful
    nuclear power plant. It will happen but not next year. Dwarkesh mentions Amazon’s
    950mw facility, Zuck says he is unsure about that.
  id: totrans-split-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (30:00) 要是 Meta 有了 10 倍的资金会怎么做呢？更多的能量，这将允许更大的集群，但真正的瓶颈是时间。目前数据中心的能量顶峰大约是 50mw-150mw。但
    300mw-1gw，那是新的，那是一个有意义的核电站。这将会发生，但不是明年。Dwarkesh 提到了亚马逊的 950mw 设施，Zuck 表示对此并不确定。
- en: (31:40) What about distributed computing? Zuck says it is unknown how much of
    that is feasible, and suggests that a lot of training in future might be inference
    to generate synthetic data.
  id: totrans-split-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (31:40) 分布式计算怎么样？Zuck 说目前还不清楚多少是可行的，并建议未来很多训练可能是推断来生成合成数据。
- en: (32:25) If that’s what this is about, could this work for Llama-3? Could you
    use these models to get data for these models to get smarter? De facto one might
    say ‘RSI Real Soon Now (RSI RSN)?’ Zuck says ‘there are going to be dynamics like
    that’ but there are natural limits on model architecture. He points out there
    is nothing like Llama-3 400B currently in open source, that will change things
    a lot, but says it can only go so far. That all makes sense, at some point you
    have to restart the architecture, but that does not fully rule out the scenario.
  id: totrans-split-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (32:25) 如果这就是问题所在，Llama-3 能行吗？你可以用这些模型获取数据，让这些模型变得更智能吗？实际上，你可以说‘RSI Real Soon
    Now (RSI RSN)’吗？Zuck 说‘肯定会有类似的动态’，但模型架构有自然限制。他指出，在开源中目前没有像 Llama-3 400B 这样的东西，这将大幅改变情况，但他说只能走到这一步。这一切都是有道理的，到某个时候你必须重新启动架构，但这并不能完全排除这种情况。
- en: (34:15) Big picture, what’s up with AI for the next decade? How big a deal is
    it? Zuck says pretty fundamental, like the creation of computing, going from not
    having computers to having computers. You’ll get ‘all these new apps’ and it will
    ‘let people do what they want a lot more.’
  id: totrans-split-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (34:15) 大局观，未来十年 AI 会怎样？这有多重要？Zuck 表示非常根本，就像计算机的创造一样，从没有计算机到有计算机。你会得到‘所有这些新应用程序’，它将‘让人们更多地做他们想做的事情’。
- en: He notices it is very hard to reason about how this goes.
  id: totrans-split-34
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他注意到，理解这个问题非常困难。
- en: He strongly expects physical constraints to prevent fast takeoff, or even ‘slow
    takeoff,’ expecting it to be decades to fully get there.
  id: totrans-split-35
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他强烈预计物理约束将阻止快速起飞，甚至是‘缓慢起飞’，预计需要几十年才能完全实现。
- en: Notice again his expectations here are very much within the mundane range.
  id: totrans-split-36
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次注意，他在这里的期望非常在世俗范围内。
- en: That could be the central crux here. If he thinks that nothing we build can
    get around the physical constraints for decades, then that has a lot of implications.
  id: totrans-split-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这可能是这里的核心问题。如果他认为我们构建的任何东西在数十年内都无法克服物理约束，那将有很多的影响。
- en: (36:00) Dwarkesh says, but what about on that cosmic, longer-term scale? What
    will the universe look like? Will AI be like humans evolving or harnessing fire?
    Zuck says that is tricky. He says that people have come to grips throughout history
    with noticing that humanity is not unique in various ways but is still super special.
    He notices that intelligence is not clearly fundamentally connected to life, it
    is distinct from consciousness and agency. Which he says makes it a super valuable
    tool.
  id: totrans-split-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (36:00) Dwarkesh说，但是在那种宇宙的、长期的尺度上呢？宇宙会是什么样子？AI会像人类一样进化或利用火焰吗？扎克说这很棘手。他说人们通过历史一直在认识到人类在各种方面并不是独特的，但仍然非常特殊。他注意到智能并不明确地与生命基本连接，它与意识和代理是不同的。他说这使得它成为一个超级有价值的工具。
- en: Once again, even in this scenario, there’s that word again. [Tool](https://en.wikipedia.org/wiki/Mark_Zuckerberg).
  id: totrans-split-39
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次，在这种情况下，甚至这种词语再次出现了。[工具](https://en.wikipedia.org/wiki/Mark_Zuckerberg)。
- en: A key problem with this is agency is super useful. There is a reason Meta’s
    central plan is to create an active AI assistant for you that will act are your
    personal agent. Why Meta is striving to bring as much agency capability directly
    into the models, and also building more agency capability on top of that. The
    first thing people are doing and will do, in many contexts, is strive to give
    the AI as much agency as possible. So even if that doesn’t happen ‘on its own’
    it happens anyway. My expectation is that if you wanted to create a non-agent,
    you can probably do that, but you and everyone else with sufficient access to
    the model have to choose to do that.
  id: totrans-split-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个关键问题是代理是非常有用的。Meta的中心计划是为您创建一个积极的AI助手，将充当您的个人代理。这是Meta努力将尽可能多的代理能力直接融入模型的原因，同时在此基础上建立更多的代理能力。在许多情况下，人们正在做的第一件事情，也将要做的，就是努力让AI拥有尽可能多的代理能力。因此，即使这不是‘自然’发生的，它也会发生。我的预期是，如果您想创建一个非代理的模型，您可能可以做到，但是您和其他有足够访问权限的人必须选择这样做。
- en: '(38:00) Zuck: “Which is why I don’t think anyone should be dogmatic about how
    they plan to develop it or what they plan to do. You want to look at it with each
    release. We’re obviously very pro open source, but I haven’t committed to releasing
    every single thing that we do. I’m basically very inclined to think that open
    sourcing is going to be good for the community and also good for us because we’ll
    benefit from the innovations. If at some point however there is some qualitative
    change in what the thing is capable of, and we feel like it’s capable of, and
    we feel it is not responsible to open source it, then we won’t. It’s all very
    difficult to predict.”'
  id: totrans-split-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (38:00) 扎克：“这就是为什么我认为没有人应该对他们计划如何开发它或计划做什么持有教条主义态度。你想要每次发布都看一看。我们显然非常支持开源，但我还没有承诺发布我们所做的每一件事。我基本上倾向于认为开源对社区和我们都将是有益的，因为我们将从创新中受益。然而，如果在某个时刻，有一些质的变化，我们觉得不负责任开源它，那么我们就不会这样做。这一切都很难预测。”
- en: Bravo. Previously we have seen him say they were going to open source AGI. He
    might intend to do that anyway. This continues Zuck trying to have it both ways.
    He says both ‘we will open source everything up to and including AGI’ and also
    ‘we might not’ at different times.
  id: totrans-split-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Bravo。以前我们看到他说他们要开源AGI。他可能打算无论如何都这样做。这继续了扎克试图两者兼得的努力。他在不同的时候说‘我们将开源一切，包括AGI’和‘可能不会’。
- en: The reconciliation is simple. When Zuck says ‘AGI’ he does not mean AGI.
  id: totrans-split-43
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 和解很简单。当扎克说‘AGI’时，他并不是指AGI。
- en: This suggests an obvious compromise. We can all negotiate on what capabilities
    would constitute something too dangerous, and draw a line there, with the line
    drawn in anticipation of what can be built on top of the model that is being considered
    for release, and understanding that all safety work will rapidly be undone and
    so on.
  id: totrans-split-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这表明了一个明显的妥协。我们可以就什么能力构成了某种太危险的东西进行协商，并在那里划定界限，这条线是在考虑要发布的模型之上能够构建的内容的预期之中，并理解所有安全工作将迅速被撤销等等。
- en: We are talking price, and perhaps are not even that far apart.
  id: totrans-split-45
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们在讨论价格，也许甚至没有那么大的差距。
- en: I am totally fine with Llama-3 70B being released.
  id: totrans-split-46
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我完全同意Llama-3 70B的发布。
- en: I do notice that open sourcing Llama-3 405B sounds like a national security
    concern, and as I discuss later if I was in NatSec I would be asking how I could
    prevent Meta from releasing the weights for national competitiveness reasons (to
    not supercharge Chinese AI) with a side of catastrophic misuse by non-state actors.
  id: totrans-split-47
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我确实注意到开源Llama-3 405B听起来像是一个国家安全问题，正如我稍后讨论的那样，如果我在国家安全局，我会问自己如何阻止Meta因国家竞争力原因发布权重（以不超级中国AI），以及非国家行为者的灾难性误用。
- en: But I do not expect existential risk from Llama-3\.
  id: totrans-split-48
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 但我不认为Llama-3会存在存在危险。
- en: (38:45) So Dwarkesh asks exactly that. What would it take to give Zuck pause
    on open sourcing the results of a future model?
  id: totrans-split-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （38:45）因此，Dwarkesh确切地问了这个问题。如果未来模型的结果开源，Zuck会有何顾虑？
- en: Zuck says it is hard to measure that in the abstract. He says if you can ‘mitigate
    the negative behaviors’ of a product, then those behaviors are okay.
  id: totrans-split-50
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zuck说，这在抽象中很难衡量。他说，如果你能“减轻产品的负面行为”，那么这些行为就没问题。
- en: The whole point is that you can to some extent do mitigations while you control
    the model (this is still super hard and jailbreaks are universally possible at
    least for now) but if you open source then your mitigations get fully undone.
  id: totrans-split-51
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 整个重点在于，在你控制模型的时候，你可以在一定程度上进行缓解（这仍然非常困难，至少目前普遍可能会出现越狱），但如果开源，你的缓解措施就完全失效了。
- en: Thus I see this as another crux. What does ‘mitigate’ mean here? What is the
    proposal for how that would work? How is this not as fake as Stability.ai saying
    they are taking safety precautions with Stable Diffusion 3, the most generous
    interpretation of which I can imagine is ‘if someone does a fine tune and a new
    checkpoint and adds a LoRa then that is not our fault.’ Which is a distinction
    without a difference.
  id: totrans-split-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因此，我认为这是另一个关键点。这里的“减轻”意味着什么？对于如何工作的提议是什么？这怎么不像Stability.ai声称他们在使用Stable Diffusion
    3时正在采取安全措施那样虚假呢？我能想象的最慷慨的解释是，“如果有人进行微调并生成一个新的检查点，并添加一个LoRa，那不是我们的错。”这毫无区别。
- en: (40:00) Zuck says it is hard to enumerate all the ways something can be good
    or bad in advance. Very true.
  id: totrans-split-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （40:00）Zuck说，在事前很难列举出某事可能好坏的所有方式。非常正确。
- en: As an aside, the ads here are really cool, pitches for plausibly useful AI products.
    Dwarkesh’s readings are uninspired, but the actual content is actively positive.
  id: totrans-split-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 顺便说一句，这里的广告真的很酷，是对可能有用的AI产品的推广。Dwarkesh的演讲毫无激情，但实际内容积极向上。
- en: '(42:30) Zuck: “Some people who have bad faith are going to try and strip out
    all the bad stuff. So I do think that’s an issue.”'
  id: totrans-split-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （42:30）Zuck说：“一些持恶意意图的人会尝试剥夺所有的坏东西。所以我确实认为这是一个问题。”
- en: Isn’t it more accurate to say that people will for various reasons definitely
    strip out all the protections, as they have consistently always done, barring
    an unknown future innovation?
  id: totrans-split-56
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 难道说，更准确地说，人们出于各种原因肯定会剥夺所有保护措施，因为他们一直都这样做，除非有未知的未来创新？
- en: '(42:45) And here it is, as usual. Zuck: “I do think that a concentration of
    AI in the future has the potential to be as dangerous as it being widespread…
    people ask ‘is it bad for it to be out in the wild and just widely available?’
    I think another version of this is that it’s probably also pretty bad for one
    institution to have an AI that is way more powerful than everyone else’s AI.”
    And so on.'
  id: totrans-split-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （42:45）就像通常一样，这里就是Zuck说的话：“我确实认为，未来人工智能的集中可能与它的普及一样危险……人们问：‘它在野外广泛使用是不好的吗？’我认为另一个版本是说，有一个机构拥有比其他人更强大的人工智能，这也可能是非常糟糕的。”等等。
- en: Something odd happens with his answer here. Up until this point, Zuck has been
    saying a mix of interesting claims, some of which I agree with and some where
    I disagree. I think he is making some key conceptual mistakes, and of course is
    talking his book as one would expect, but it is a unique perspective and voice.
    Now, suddenly, we get the generic open source arguments I’ve heard time and again,
    like they were out of a tape recorder.
  id: totrans-split-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他在这里的回答有点奇怪。直到这一点，Zuck一直在说一些有趣的说法，其中一些我同意，一些我不同意。我认为他在做一些关键概念上的错误，当然，正如预期的那样，他在自说自话，但这是一个独特的视角和声音。现在，突然间，我们听到了我一再听到的通用开源论点，就像是从录音机里播放出来的一样。
- en: And then he says ‘I don’t hear people talking about this much.’ Well, actually,
    I hear people talking about it constantly. It is incessant, in a metaphorically
    very ‘[isolated demand for rigor](https://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/)’
    kind of way, to hear ‘the real danger is concentration of power’ or concentration
    of AI capability. Such people usually say this without justification, and without
    any indication they understand what the ‘not real’ danger is that they are dismissing
    as not real or why they claim that it is not real.
  id: totrans-split-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后他说：“我听不到人们经常谈论这个。”实际上，我经常听到人们在不间断地用隐喻性的“[孤立的严谨需求](https://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/)”这种方式谈论“真正的危险是权力集中”或AI能力的集中。这些人通常没有理由这样说，并且没有任何迹象表明他们理解他们所称为“不真实”的危险为何被视为不真实，或者为何声称它不真实。
- en: (45:00) He says what keeps him up at night is that someone untrustworthy that
    has the super strong AI, that this is ‘potentially a much bigger risk.’ That a
    bad actor who got a hold of a strong AI might cause a lot of mayhem in a world
    where not everyone has a strong AI.
  id: totrans-split-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （45:00）他说让他夜不能寐的是，有人不可信赖地掌握了超强的AI，这“可能是一个更大的风险”。在不是每个人都有超强AI的世界中，一个掌握了强大AI的坏行为者可能引起很多混乱。
- en: This is a bigger concern than AI getting control of the future? Bigger than
    human extinction? Bigger than every actor, however bad, having such access?
  id: totrans-split-61
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这比AI控制未来更大的问题吗？比人类灭绝更大？比每个行动者，无论多坏，都拥有这样的访问权更大吗？
- en: Presumably he means more likely, or some combination of likely and bigger.
  id: totrans-split-62
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他可能的意思是更有可能，或者一些可能性和更大的结合。
- en: So yes, his main concern is that the wrong monkey might get the poisoned banana
    and use it against other monkeys, it is only a tool after all. So instead we have
    to make sure all monkeys have such access?
  id: totrans-split-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 所以是的，他的主要关注点是错误的猴子可能会得到有毒的香蕉，并将其用于攻击其他猴子，毕竟它只是一个工具。因此，我们必须确保所有猴子都有这样的访问权吗？
- en: (46:00) It is overall a relatively good version of the generic open source case.
    He at least acknowledges that there are risks on all sides, and certainly I agree
    with that.
  id: totrans-split-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （46:00）总体而言，这是一个相对好的通用开源案例的版本。他至少承认各方面存在风险，我当然同意这一点。
- en: I see no indication from the argument that he actually understands what the
    risks of open sourced highly capable models are, or that he has considered them
    and has a reason why they would not come to pass.
  id: totrans-split-65
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从这个论点中，我看不出他真正理解开源高能力模型的风险，或者他是否已经考虑过它们，并且有理由认为它们不会发生。
- en: His position here appears to be based on ‘this is a tool and will always be
    a tool’ and combining that with an implied presumption about offense-defense balance.
  id: totrans-split-66
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他在这里的立场似乎基于“这是一个工具，将永远是一个工具”，并将其与关于攻防平衡的隐含假设结合在一起。
- en: I certainly have no idea what his plan (or expectation) is to deal with various
    competitive dynamics and incentives, or how he would keep the AIs from being something
    more than tools if they were capable of being more than that.
  id: totrans-split-67
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我确实不知道他处理各种竞争动态和激励措施的计划（或期望），或者如果他们能够超越工具的话，他将如何阻止AI成为更多的东西。
- en: The better version of this case more explicitly denies future AI capabilities.
  id: totrans-split-68
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这个案例的更好版本更明确地否认了未来AI的能力。
- en: I could write the standard reply in more detail than I have above, but I get
    tired. I should have a canonical link to use in these spots, but right now I do
    not.
  id: totrans-split-69
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我可以比上面更详细地写标准回复，但我会感到疲惫。我应该有一个标准链接可以在这些地方使用，但现在我没有。
- en: (46:30) Instead Dwarkesh says it seems plausible that we could get an open source
    AI to become the standard and the best model, and that would be fine, preferable
    even. But he asks, mechanically, how you stop a bad actor in that world.
  id: totrans-split-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （46:30）Dwarkesh说似乎有可能我们能让一个开源AI成为标准和最好的模型，那将是好的，甚至更可取。但他机械地问，如何阻止那个世界中的坏行为者。
- en: He first asks about bioweapons.
  id: totrans-split-71
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他首先问关于生物武器的问题。
- en: Zuck answers that stronger AIs are good cybersecurity defense.
  id: totrans-split-72
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zuck回答说更强大的AI是良好的网络安全防御。
- en: Dwarkesh asks, what if bioweapons aren’t like that.
  id: totrans-split-73
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Dwarkesh问，如果生物武器不是这样的呢。
- en: Zuck agrees he doesn’t know that bioweapons do not work that way and it makes
    sense to worry there. He suggests not training certain knowledge into the model
    (which seems unlikely to me to be that big a barrier, because the world implies
    itself and also you can give it the missing data), but admits if you get a sufficiently
    bad actor (which you will), and you don’t have another AI that can understand
    and balance that (which seems hard under equality), then that ‘could be a risk.’
  id: totrans-split-74
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扎克同意他不知道生物武器不是那样工作的，担心是有道理的。他建议不要将某些知识训练到模型中（对我来说这似乎不太可能成为大的障碍，因为世界本身就暗示着这一点，而且你可以提供缺失的数据），但是承认如果你遇到一个足够坏的行为者（而你会遇到），并且你没有另一个能理解和平衡这一点的人工智能（在平等下这似乎很难），那么“可能会有风险”。
- en: (48:00) What if you for example caught a future Llama lying to you? Zuck says
    right now we see hallucinations and asks how you would tell the difference between
    that and deception, says there is a lot to think about, speaks of ‘long-term theoretical
    risks’ and asks to balance this with ‘real risks that we face today.’ His deception
    worry is ‘people using this to generate misinformation.’
  id: totrans-split-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （48:00）例如，如果你抓到一个未来的羊驼对你撒谎怎么办？扎克说，现在我们看到幻觉，并询问如何区分这一点与欺骗，他说这是一个需要思考的问题，提到了“长期的理论风险”，并要求与“我们今天面临的真实风险”进行平衡。他对欺骗的担忧是“人们利用这一点来生成错误信息”。
- en: (49:15) He says that the way he has beaten misinformation so far is by building
    AI systems that are smarter than the adversarial ones.
  id: totrans-split-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （49:15）他说到目前为止，他击败错误信息的方式是构建比对手更聪明的人工智能系统。
- en: Exactly. Not ‘as smart.’ Smarter.
  id: totrans-split-77
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 没错，不是“同样聪明”。更聪明。
- en: Zuck is playing defense here. He has the harder job.
  id: totrans-split-78
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扎克在这里是在进行防守。他的工作更难。
- en: If those trying to get ‘misinformation’ or other undesired content past Facebook’s
    (or Twitter’s or GMail’s) filters had the same level of sophistication and skill
    and resources as Meta and Google, you would have to whitelist in order to use
    Facebook, Twitter and GMail.
  id: totrans-split-79
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果那些试图通过Facebook（或Twitter或GMail）的过滤器传播“错误信息”或其他不受欢迎内容的人具有与Meta和Google相同水平的复杂性、技能和资源，你将不得不白名单才能使用Facebook、Twitter和GMail。
- en: The key question will be, how much of being smarter will be the base model?
  id: totrans-split-80
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关键问题将是，有多少比普通模型更聪明的部分？
- en: (49:45) Zuck says hate speech is not super adversarial in the sense that people
    are not getting better at being racist.
  id: totrans-split-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （49:45）扎克说，憎恨言论在某种意义上不是特别具有对抗性，因为人们在变得更加种族主义方面没有变得更好。
- en: I think in this sense that is wrong, and they totally are in both senses? Racists
    invent new dog whistles, new symbols, new metaphors, new deniable things. They
    look for what they can and cannot say in different places. They come up with new
    arguments. If you came with the 1970s racism today it would go very badly for
    you, let alone the 1870s or 1670s racism. And then he says that AIs here are getting
    more sophisticated faster than people.
  id: totrans-split-82
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个意义上我认为是错的，他们在两个意义上完全是？种族主义者发明新的口哨声、新的符号、新的隐喻、新的可以否认的事物。他们寻找在不同地方可以和不能说的内容。他们想出新的论点。如果你今天拿着20世纪70年代的种族主义来，结果会很糟糕，更不用说19世纪70年代或17世纪70年代的种族主义。然后他说，这里的AI比人类进步得更快更复杂。
- en: 'What is going to happen is that the racists are going to get their racist AI
    systems ([see: Gab](https://thezvi.substack.com/p/ai-60-oh-the-humanity#%C2%A7another-supposed-system-prompt))
    and start using the AI to generate and select their racist arguments.'
  id: totrans-split-83
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将会发生的是，种族主义者将会获得他们的种族主义人工智能系统（[见：Gab](https://thezvi.substack.com/p/ai-60-oh-the-humanity#%C2%A7another-supposed-system-prompt)），并开始使用AI来生成和选择他们的种族主义论点。
- en: If your AI needs to have high accuracy to both false positives and false negatives,
    then you need a capability advantage over the attack generation mechanism.
  id: totrans-split-84
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你的AI需要在假阳性和假阴性之间具有高准确率，那么你就需要比攻击生成机制具有更强的能力优势。
- en: This is all ‘without loss of generality.’ You can mostly substitute anything
    else you dislike for racism here if you change the dates or other details.
  id: totrans-split-85
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这一切都是“不失一般性”的。如果你改变日期或其他细节，你可以大部分替换任何你不喜欢的东西，比如种族主义。
- en: (50:30) Zuck then contrasts this with nation states interfering in elections,
    where he says nation-states are ‘have cutting edge technology’ and are getting
    better every year. He says this is ‘not like someone trying to say mean things,
    they have a goal.’
  id: totrans-split-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （50:30）扎克随后将此与国家干预选举进行对比，他说国家正在“拥有尖端技术”，并且每年都在变得更好。他说这不像有人试图说恶毒的话，他们有一个目标。
- en: Well, saying mean things is also a goal, and I have seen people be very persistent
    and creative in saying mean things when they want to do that.
  id: totrans-split-87
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 好吧，说恶意的事情也是一个目标，我见过人们在想这么做的时候非常坚持和有创意。
- en: Indeed, Mark Zuckerberg went to Ardsley High School and Phillips Exeter Academy,
    they made this movie The Social Network and also saying mean things about Mark
    Zuckerberg is a top internet passtime. I am going to take a wild guess that he
    experienced this first hand. A lot.
  id: totrans-split-88
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 的确，马克·扎克伯格曾就读于阿兹利高中和菲利普斯埃克塞特学院，他们拍了这部电影《社交网络》，并且说马克·扎克伯格的坏话是一种网络顶级消遣。我要大胆猜测他亲身经历过这些。
- en: I would also more centrally say no, zero nation states have cutting edge election
    interference technology, except insofar as ‘whatever is available to the most
    capable foreign nation-state at this, maybe Russia’ is defined as the cutting
    edge. Plenty of domestic and non-state actors are ahead of the game here. And
    no state actor, or probably any domestic actor either, is going to have access
    to an optimized-for-propaganda-and-chaos version of Gemini, GPT-4 or Claude Opus.
    We are blessed here, and of course we should not pretend that past attempts were
    so sophisticated or impactful. Indeed, what may happen in the coming months is
    that, by releasing Llama-3 400B, Zuck instantly gives Russia, China, North Korea
    and everyone else exactly this ‘cutting edge technology’ with which to interfere.
  id: totrans-split-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我也更核心地说，没有国家拥有最先进的选举干扰技术，除非‘在这一点上，也许俄罗斯’的任何能力最强的外国国家的所能获得的被定义为最先进。许多国内和非国家行为者在这方面处于领先地位。而且没有一个国家行为者，或者可能是任何国内行为者，会有机会获得一个为宣传和混乱优化的版本，比如Gemini、GPT-4或Claude
    Opus。我们在这里是幸运的，当然我们不应该假装过去的尝试是如此复杂或有影响力。确实，在未来几个月可能发生的是，通过发布Llama-3 400B，扎克立即为俄罗斯、中国、朝鲜和其他所有人提供了这种‘最先进技术’，用于干扰。
- en: I of course think the main deception problems with AI lie in the future, and
    have very little to do with traditional forms of ‘misinformation’ or ‘election
    interference.’ I do still find it useful to contrast our models of those issues.
  id: totrans-split-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当然，我认为AI的主要误导问题在未来，与传统形式的‘误导’或‘选举干扰’关系很小。我仍然发现将这些问题的模型进行对比是有用的。
- en: (51:30) He says ‘for the foreseeable future’ he is optimistic they will be able
    to open source. He doesn’t want to ‘take our eye off the ball’ of what people
    are trying to use the models for today. I would urge him to keep his eye on that
    ball, but also skate where the puck is going. Do not move directly towards the
    ball.
  id: totrans-split-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (51:30) 他说‘在可预见的未来’他乐观地认为他们将能够开源。他不想‘把我们的眼睛从今天人们试图使用模型的事情上移开’。我会建议他继续关注这个问题，但也要滑到冰球去。不要直接朝着球移动。
- en: (54:30) Fun time, what period of time to go back to? Zuck checks, it has to
    be the past. He talks about the metaverse.
  id: totrans-split-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (54:30) 好玩的时间，回到什么时候？扎克检查，必须是过去。他谈论到元宇宙。
- en: (59:00) Zuck is incapable of not taking a swing at building the next thing.
    He spends so much time finding out if he could, I suppose.
  id: totrans-split-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (59:00) 扎克无法阻止自己去尝试建造下一件事情。我想他花了很多时间弄清楚他是否能够。
- en: (1:02:00) Caesar Augustus seeking peace. Zuck suggests peace at the time was
    a new concept as anything other than a pause between wars. I notice I am skeptical.
    Then Zuck transitions from ‘wanting the economy to be not zero-sum’ to ‘a lot
    of investors don’t understand why we would open source this.’ And says ‘there
    are more reasonable things than people think’ and that open source creates winners.
    The framing attempt is noted.
  id: totrans-split-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:02:00) 凯撒·奥古斯都寻求和平。扎克建议在当时和平是一种除了战争之外的新概念。我注意到我持怀疑态度。然后扎克从‘希望经济不是零和游戏’转向‘许多投资者不明白为什么我们会开源这个’。他说‘有比人们想象的更合理的事情’，并且开源创造了赢家。注意到这种框架尝试。
- en: I instead think most investors understand perfectly well why Meta might open
    source here. It is not hard to figure this out. Indeed, the loudest advocates
    for open source AI are largely venture capitalists.
  id: totrans-split-95
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我反而认为大多数投资者非常明白Meta为什么可能在这里开源。弄清楚这一点并不难。确实，对开源AI最响亮的倡导者大多是风险投资家。
- en: That does not mean that open sourcing is a wise (or unwise) business move.
  id: totrans-split-96
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这并不意味着开源是明智（或不明智）的商业举动。
- en: (1:05:00) Suppose there was a $10 billion model, it was totally safe even with
    fine tuning, would you open source? Zuck says ‘as long as it’s helping us, yeah.’
  id: totrans-split-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:05:00) 假设有一个价值100亿美元的模型，即使经过精细调整，也完全安全，你会开源吗？扎克说‘只要它对我们有帮助，是的。’
- en: Exactly. If it is good for business and it is not an irresponsible thing to
    do, it was actually ‘totally safe’ in the ways that matter, and you think it is
    good for the world too, then why not?
  id: totrans-split-98
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 没错。如果这对业务有好处，并且这不是一件不负责任的事情，实际上在重要方面它是‘完全安全’的，并且你认为这对世界也有好处，那为什么不呢？
- en: My only caveat would be to ensure you are thinking well about what ‘safe’ means
    in that context, as it applies to the future path the world will take. One does
    not, in either direction, want to use a narrow view of ‘safe.’
  id: totrans-split-99
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我唯一的警告是确保你在这种情况下对“安全”的含义有深思熟虑，因为它适用于世界未来的发展路径。在任何方向上，我们都不希望狭隘地理解“安全”。
- en: (1:06:00) Zuck notes he does not open source Meta’s products. Software yes,
    products no. Something to keep in mind.
  id: totrans-split-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （1:06:00）扎克提到他不会开源 Meta 的产品。软件可以，但产品不行。这是需要记住的事情。
- en: (1:07:00) Dwarkesh asks if training will be commodified? Zuck says maybe. Or
    it could go towards qualitative improvements via specialization.
  id: totrans-split-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （1:07:00）德瓦克什问培训是否会成为商品化？扎克说可能会。或者它可能通过专业化进行定性改进。
- en: (1:08:45) Zuck notes that several times, Meta has wanted to launch features,
    and Apple has said no.
  id: totrans-split-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （1:08:45）扎克指出，Meta 曾多次希望推出功能，而苹果却说不。
- en: We don’t know which features he is referring to.
  id: totrans-split-103
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们不知道他指的是哪些特性。
- en: We do know Apple and Meta have been fighting for a while about app tracking
    and privacy, and about commissions and informing users about the commissions,
    and perhaps messaging.
  id: totrans-split-104
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们知道苹果和 Meta 已经在关于应用追踪和隐私、关于佣金以及通知用户有关佣金情况，以及可能的消息传递方面进行了一段时间的斗争。
- en: (1:09:00) He therefore asks, what if someone has an API and tells you what you
    can build? Meta needs to build the model themselves to ensure they are not in
    that position.
  id: totrans-split-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （1:09:00）因此，他问，如果有人拥有 API 并告诉你可以建造什么怎么办？Meta 需要自己建立模型以确保他们不处于这种位置。
- en: I don’t love that these are the incentives, but if you are as big as Meta and
    want to do Meta things, then I am sympathetic to Meta in particular wanting to
    ensure it has ownership of the models it uses internally, even if that means large
    costs and even if it also meant being a bit behind by default.
  id: totrans-split-106
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我并不喜欢这些激励措施，但如果你像 Meta 这样大，想要做 Meta 的事情，那么我对 Meta 特别希望确保它拥有内部使用的模型所有权感到理解，即使这意味着巨大的成本，甚至意味着默认情况下落后一点也是如此。
- en: 'The core dilemma that cannot be resolved is: Either there is someone, be it
    corporation, government or other entity, that is giving you an API or other UI
    that decides what you can and cannot do, or there is not. Either there is the
    ability to modify the model’s weights and use various other methods to get it
    to do whatever you want it to do, or there is not. The goals of ‘everyone is free
    to do what they want whenever they want’ and ‘there is some action we want to
    ensure people do not take’ are mutually exclusive.'
  id: totrans-split-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不能解决的核心困境是：要么有某个企业、政府或其他实体为你提供 API 或其他 UI 来决定你可以做什么或不能做什么，要么没有。要么有修改模型权重和使用其他方法让它做任何你想让它做的事情的能力，要么没有。“每个人都可以在任何时候做任何他们想做的事”和“我们想确保人们不采取某些行动”这两个目标是互相排斥的。
- en: You can and should seek compromise, to be on the production possibilities frontier,
    where you impose minimal restrictions to get the necessary guardrails in place
    where that is worthwhile, and otherwise let people do what they want. In some
    cases, that can even be zero guardrails and no restrictions. In other cases, such
    as physically building nuclear weapons, you want strict controls. But there is
    no taking a third option, you have to make the choice.
  id: totrans-split-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以并且应该寻求妥协，以便处于生产可能性的前沿，在那里你会施加最小的限制，以确保必要的防范措施得以实施，而其他情况下则让人们按照他们的意愿行事。在某些情况下，甚至可以是零限制和无防范措施。在其他情况下，比如物理上建造核武器，你希望有严格的控制。但没有第三种选择，你必须做出选择。
- en: (1:09:45) I totally do buy Zuck’s central case here, that if you have software
    that is generally beneficial to builders, and you open source it, that has large
    benefits. So if there is no reason not to do that, and often there isn’t, you
    should do that.
  id: totrans-split-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （1:09:45）我完全同意扎克在这里的核心观点，即如果你有一款对建设者普遍有益的软件，并且你将其开源，那将带来很大的好处。因此，如果没有理由不这样做，而通常情况下是没有的，那么你应该这样做。
- en: (1:10:15) What about licensing the model instead, with a fee? Zuck says he would
    like that. He notes that the largest companies cannot freely use Llama under their
    license, so that if Amazon or Microsoft started selling Llama then Meta could
    get a revenue share.
  id: totrans-split-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: （1:10:15）那么授权模型，收取费用呢？扎克表示他喜欢这个想法。他指出，最大的公司不能自由地在他们的许可证下使用 Llama，因此如果亚马逊或微软开始销售
    Llama，Meta 可以获得收入份额。
- en: (1:12:00) Dwarkesh presses on the question of red flags, pointing to the responsible
    scaling policy (RSP) of Anthropic and preparedness framework of OpenAI, saying
    he wishes there was a similar framework at Meta saying what concrete things should
    stop open sourcing or even deployment of future models.
  id: totrans-split-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:12:00) Dwarkesh 对红旗问题进行了进一步追问，指出了 Anthropic 的负责任扩展政策（RSP）和 OpenAI 的应对框架，表示希望
    Meta 也有一个类似的框架，说明应该停止开源或甚至部署未来模型的具体事项。
- en: Zuck says that is a fair point on the existential risk side, right now they
    are focusing on risks they see today, the content risk, avoiding helping people
    do violence or commit fraud. He says for at least one generation beyond this one
    and likely two, the harms that need more mitigation will remain the ‘more mundane
    harms’ like fraud, he doesn’t want to shortchange that, perhaps my term is catching
    on. Dwarkesh replies ‘Meta can handle both’ and Zuck says yep.
  id: totrans-split-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扎克表示，这是关于存在风险的一个公平观点，现在他们正专注于他们今天看到的风险，内容风险，避免帮助人们进行暴力或者实施欺诈。他说，至少在这一代人之后，可能还有两代人，需要更多减少的伤害将是“更世俗的伤害”，如欺诈，他不想短视，也许我的术语正在流行。Dwarkesh
    回答说“Meta 可以处理两者”，扎克说没错。
- en: There is no contradiction here. Meta can (and should) put the majority of its
    risk mitigation efforts into mundane harms right now, and also should have a framework
    for when existential risks would become concerning enough to reconsider how to
    deploy (or later train) a model, and otherwise spend relatively less on the issue.
    And it is perfectly fine to expect not to hit those thresholds for several generations.
    The key is to lay out the plan.
  id: totrans-split-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这里没有矛盾。Meta 现在可以（也应该）将大部分的风险缓解工作投入到世俗伤害中，同时也应该有一个框架，用于当存在风险足够引起重新考虑如何部署（或之后训练）模型时，并在该问题上相对少花费。可以完全可以期望在几代人之后才会达到那些阈值。关键是制定计划。
- en: (1:13:20) Has the impact of the open source tools Meta has released been bigger
    than the impact of its social media? Zuck says it is an interesting question,
    but half the world uses their social media. And yes, I think it is a fun question,
    but the answer is clearly no, the social media is more counterfactually important
    by far.
  id: totrans-split-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:13:20) Meta 发布的开源工具的影响是否比其社交媒体的影响更大？扎克表示这是一个有趣的问题，但世界上一半的人使用他们的社交媒体。是的，我认为这是一个有趣的问题，但答案显然是否定的，社交媒体在反事实情况下更为重要。
- en: (1:14:45) Meta custom silicon coming soon? Not Llama-4, but soon after that.
    They already moved a bunch of Reels inference onto their own silicon, and use
    Nvidia chips only for training.
  id: totrans-split-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:14:45) Meta 自定义硅片即将推出？不是 Llama-4，而是紧随其后。他们已经将大量 Reels 推断移至自己的硅片上，并且仅在训练时使用
    Nvidia 芯片。
- en: (1:16:00) Could Zuck have made Google+ work as CEO of Google+? Zuck says he
    doesn’t know, that’s tough. One problem was that Google+ didn’t have a CEO, it
    was only a division, and points to issues of focus. Keep the main thing the main
    thing.
  id: totrans-split-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1:16:00) 扎克是否能作为 Google+ 的 CEO 使其成功？扎克表示他不知道，这很困难。其中一个问题是 Google+ 没有 CEO，它只是一个部门，并指出了关注点的问题。保持主要事物为主要事物。
- en: That was a great interview. It tackled important questions. For most of it,
    Zuck seemed like a real person with a unique perspective, saying real things.
  id: totrans-split-117
  prefs: []
  type: TYPE_NORMAL
  zh: 那是一个很棒的采访。它处理了重要的问题。在大部分时间里，扎克似乎是一个有独特视角的真实人，说着真实的话。
- en: The exception was that weird period where he was defending open source principles
    using what sounded like someone else’s speech on a tape recorder. Whereas at other
    times, his thoughts on open source were also nuanced and thoughtful. Dwarkesh
    was unafraid to press him on questions of open source throughout the interview.
  id: totrans-split-118
  prefs: []
  type: TYPE_NORMAL
  zh: 例外是他曾辩护使用听起来像是别人的演讲录音的开源原则的奇怪时期。而在其他时候，他对开源的看法也是细腻而深思熟虑的。Dwarkesh 在整个采访中对开源问题毫不畏惧地追问他。
- en: What Dwarkesh failed to get was any details from Zuck about existential or catastrophic
    risk. We are left without any idea of how Zuck thinks about those questions, or
    what he thinks would be signs that we are in such danger, or what we might do
    about it. He tried to do this with the idea of Meta needing a risk policy, but
    Zuck kept dodging. I think there was more room to press on specifics. Once again
    this presumably comes down to Zuck not believing the dangerous capabilities will
    exist.
  id: totrans-split-119
  prefs: []
  type: TYPE_NORMAL
  zh: Dwarkesh 未能从扎克那里获取关于存在风险或灾难性风险的任何细节。我们对扎克如何思考这些问题，以及他认为哪些迹象表明我们处于这样的危险中，或者我们可以对此做些什么一无所知。他试图通过
    Meta 需要一个风险政策的想法来做到这一点，但扎克一直在逃避。我认为还有更多的具体问题可以追问。再次，这可能归结为扎克不相信危险的能力将会存在。
- en: Nor was there much discussion of the competitive dynamics that happen when everyone
    has access to the same unrestricted advanced AI models, and what might happen
    as a result.
  id: totrans-split-120
  prefs: []
  type: TYPE_NORMAL
  zh: 也没有多少讨论，当每个人都可以访问相同的无限制的先进AI模型时，会发生什么样的竞争动态，以及可能会出现的结果。
- en: I also think Zuck is failing to grapple with even the difficulties of mundane
    content moderation, an area where he is an expert, and I would like to see his
    explicit response. Previously, he has said that only a company with the resources
    of a Meta can do content moderation at this point.
  id: totrans-split-121
  prefs: []
  type: TYPE_NORMAL
  zh: 我也认为扎克甚至未能应对世俗内容管理的困难，这是他的专长领域，我希望看到他的明确回应。此前，他曾表示，目前只有Meta这样资源雄厚的公司才能进行内容管理。
- en: I think he was wrong in the sense that small bespoke gardens are often successfully
    well-defended. But I think Zuck was right that if you want to defend something
    worth attacking, like Meta, you need scale and you need to have the expertise
    advantage. But if those he is defending against also have the resources of Meta
    where it counts, then what happens?
  id: totrans-split-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为他在某种意义上是错的，因为小型定制花园通常能够成功防御。但我认为扎克说得对，如果你想保卫像Meta这样值得攻击的东西，你需要规模和专业知识的优势。但如果他正在防御的对手在关键领域也拥有Meta的资源，那会发生什么？
- en: So if there is another interview, I hope there is more pressing on those types
    of questions.
  id: totrans-split-123
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果还有另一次采访，我希望有更多对这些问题的追问。
- en: In terms of how committed Zuck is to open source, the answer is a lot but not
    without limit. He will cross that bridge when he comes to it. On the horizon he
    sees no bridge, but that can quickly change. His core expectation is that we have
    a long way to go before AI goes beyond being a tool, even though he also thinks
    it will soon very much be everyone’s personal agent. And he especially thinks
    that energy restrictions will soon bind, which will stifle growth because that
    goes up against physical limitations and government regulations. It is an interesting
    theory. If it does happen, it has a lot of advantages.
  id: totrans-split-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在扎克对开源的承诺方面，答案是很多，但并非没有限制。他会在到达时越过这座桥。在他的视野中，他看不到桥，但情况可能很快改变。他的核心期望是，在人工智能超越工具的角色之前，我们还有很长的路要走，尽管他也认为很快每个人都会有自己的个人代理。他尤其认为能源限制很快会发生，这将阻碍增长，因为这与物理限制和政府监管相冲突。这是一个有趣的理论。如果真的发生，它有很多优势。
- en: '[Ate-a-Pi has a good reaction writeup on Twitter.](https://twitter.com/8teAPi/status/1781480713394737238)
    It was most interesting in seeing different points of emphasis. The more I think
    about it, the more Ate-a-Pi nailed it pulling these parts out:'
  id: totrans-split-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[Ate-a-Pi在Twitter上有一篇很好的反应文章。](https://twitter.com/8teAPi/status/1781480713394737238)看到不同的强调点非常有趣。我越想越觉得Ate-a-Pi把这些部分提炼得非常到位：'
- en: 'Ate-a-Pi (edited down): **TLDR**: AI winter is here. Zuck is a realist, and
    believes progress will be incremental from here on. No AGI for you in 2025.'
  id: totrans-split-126
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Ate-a-Pi（编辑过）：**TLDR**：AI寒冬来临。扎克是个现实主义者，认为未来的进展将是渐进的。2025年不会有通用人工智能。
- en: Zuck is essentially an real world growth pessimist. He thinks the bottlenecks
    start appearing soon for energy and they will be take decades to resolve. AI growth
    will thus be gated on real world constraints.
  id: totrans-split-127
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 扎克本质上是一个对现实世界增长持悲观态度的人。他认为能源的瓶颈很快就会出现，解决这些问题将需要数十年时间。因此，人工智能的增长将受到现实世界约束的限制。
- en: Zuck would stop open sourcing if the model is the product.
  id: totrans-split-128
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果模型是产品，扎克将停止开源。
- en: Believes they will be able to move from Nvidia GPUs to custom silicon soon.
  id: totrans-split-129
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 相信他们很快将能从Nvidia的GPU过渡到定制硅片。
- en: Overall, I was surprised by how negative the interview was.
  id: totrans-split-130
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 总体而言，我对采访的负面程度感到惊讶。
- en: A) Energy - Zuck is pessimistic about the real world growth necessary to support
    the increase in compute. Meanwhile the raw compute per unit energy has doubled
    every 2 years for the last decade. Jensen also is aware of this, and it beggars
    belief that he does not think of paths forward where he has to continue this ramp.
  id: totrans-split-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: A）能源 - 扎克对支持计算增长所需的现实世界增长持悲观态度。与此同时，过去十年每单位能量的原始计算量每两年翻一番。詹森也意识到了这一点，他不认为自己没有考虑到需要继续这一增长路径。
- en: B) AGI Negative Zuck fundamentally
  id: totrans-split-132
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: B）AGI Negative Zuck fundamentally
- en: does not believe the model, the AI itself, will be the product.
  id: totrans-split-133
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不相信模型本身会成为产品。
- en: It is the context, the network graph of friendships per user, the moderation,
    the memory, the infrastructure that is the product.
  id: totrans-split-134
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这就是产品的上下文，用户之间的友谊网络图，内容管理，内存，基础设施。
- en: Allows him to freely release open source models, because he has all of the rest
    of the pieces of user facing scaffolding already done.
  id: totrans-split-135
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 允许他自由发布开源模型，因为他已经完成了所有其余用户界面脚手架的部分。
- en: Does not believe in states of the world where a 100x improvement from GPT-4
    are possible, or that AGI is possible within a short timeframe.
  id: totrans-split-136
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不认为从 GPT-4 获得 100 倍的改进是可能的，或者在短期内实现 AGI 是可能的。
- en: An actual AGI
  id: totrans-split-137
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一个真正的AGI
- en: where the a small model learns and accompanies the user for long periods
  id: totrans-split-138
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 其中一个小型模型学习并在长时间内陪伴用户
- en: while maintaining its own state
  id: totrans-split-139
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 同时保持其自身状态
- en: with a constitution of what it can or cannot do
  id: totrans-split-140
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 以其可或不可进行的构成
- en: rather than frequent updates from a central server
  id: totrans-split-141
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 而不是来自中央服务器的频繁更新
- en: would be detrimental to Meta’s business,
  id: totrans-split-142
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 将对 Meta 的业务造成不利影响，
- en: would cause a re-evaluation of what they are doing
  id: totrans-split-143
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 将导致对他们正在做的事情进行重新评估
- en: Especially on point is that Zuck never expects the AI itself to be the product.
    This is a common pattern among advocates for open model weights - they do not
    actually believe in AGI or the future capabilities of the product. It is not obvious
    Zuck and I even disagree so much on what capabilities would make it unwise to
    open up model weights. Which is all the more reason to spell out what that threshold
    would be.
  id: totrans-split-144
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其要点是，扎克从不指望 AI 本身成为产品。这是支持开放模型权重的倡导者中常见的模式 - 他们实际上并不相信 AGI 或产品的未来能力。显然，扎克和我甚至在什么能力会使开放模型权重不明智这一点上也不完全意见一致。这正是要明确阐述那个门槛的更多理由。
- en: Then there is speculation from Ate-a-Pi that perhaps Zuck is being realistic
    because Meta does not need to raise capital, whereas others hype to raise capital.
    That surely matters on the margin, in both directions. Zuck would love if Altman
    and Amodei were less able to raise capital.
  id: totrans-split-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是来自 Ate-a-Pi 的推测，也许扎克之所以如此现实，是因为 Meta 不需要筹集资本，而其他人则炒作以筹集资本。这在边际上肯定很重要，两个方向都有影响。如果奥特曼和阿莫迪更难筹集资本，扎克会很高兴。
- en: But also I am confident this is a real disagreement, to a large extent, on both
    sides. These people expecting big jumps from here might turn out to be bluffing.
    But I am confident they think their hand is good.
  id: totrans-split-146
  prefs: []
  type: TYPE_NORMAL
  zh: 但我也确信这是一个真正的分歧，在很大程度上，双方都有。这些人希望从这里跳跃出大步可能最终是虚张声势。但我确信他们认为自己的手牌很好。
- en: '[Daniel Jeffries highlights GPT-5](https://twitter.com/Dan_Jeffries1/status/1781567863595180090)
    as key evidence either way, which seems right.'
  id: totrans-split-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[丹尼尔·杰弗里斯强调 GPT-5](https://twitter.com/Dan_Jeffries1/status/1781567863595180090)
    作为证据的关键，这似乎是正确的。'
- en: 'Daniel Jeffries: The litmus test about whether we hit a plateau with LLMs will
    be GPT5\. It''ll tell us everything we need to know.'
  id: totrans-split-148
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 丹尼尔·杰弗里斯：关于我们是否达到了LLM的高原的检验将是GPT5。它会告诉我们一切我们需要知道的。
- en: I'm on record in my new years predictions as saying I believe GPT5 will be incremental.
  id: totrans-split-149
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我在我的新年预测中说过，我认为 GPT5 将是渐进的。
- en: But I am now 50/50 on that and feel it could still be a massive leap up provided
    they actually pioneered new techniques in synthetic data creation, or other new
    techniques, such as using GPT4 as a bootstrapper for various scenarios, etc.
  id: totrans-split-150
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 但现在我对此有50/50的看法，并且感觉它仍然可能是一个巨大的飞跃，只要他们实际上在合成数据创造或其他新技术方面开创了新技术，比如使用GPT4作为各种场景的引导程序等等。
- en: If it is just another transformer with more data, I don't see it making a massive
    leap. Could still be useful, ie infinite context windows, and massively multimodal,
    but incremental none the less.
  id: totrans-split-151
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 如果它只是另一个带有更多数据的变压器，我认为它不会有巨大的飞跃。仍然可能有用，即无限上下文窗口和极其多模式，但是增量的。
- en: But if GPT5 is a minor improvement, meaning a much smaller gap versus the jump
    from 2 to 3 and 3 to 4, then Zuck is right. The LLM is basically a hot swappable
    Linux kernel and the least important part of the mix. Everything around it, squeezing
    the most out of its limitations, becomes the most important aspect of building
    apps.
  id: totrans-split-152
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 但如果 GPT5 是一个小幅改进，意味着与从 2 到 3 和 3 到 4 的跃升相比，差距要小得多，那么扎克是正确的。LLM 基本上是一个可热插拔的 Linux
    内核，是整体中最不重要的部分。围绕它的一切，在其限制中挤出最大可能性，成为构建应用程序最重要的方面。
- en: Like any good predictor, I continue to revise my predictions as new data comes
    in. The top predictors in world competitions revise their thinking on average
    four times. The second tier revises twice. The rest of the world? Never. Let that
    sync in.
  id: totrans-split-153
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 像任何好的预测者一样，随着新数据的进入，我继续修订我的预测。在世界竞赛中排名前列的预测者平均修订四次。第二梯队修订两次。其他人呢？从不。让这个事实深入人心。
- en: If GPT-5 lands at either extreme it would be very strong evidence. We also could
    get something in the middle, and be left hanging. I also would not be too quick
    in calendar time to conclude progress is stalling, if they take their time releasing
    5 and instead release smaller improvements along the way. The update would be
    gradual, and wouldn’t be big until we get into 2025\.
  id: totrans-split-154
  prefs: []
  type: TYPE_NORMAL
- en: Ate-a-Pi also offers [this explanation of the business case for opening up Llama-3](https://twitter.com/8teAPi/status/1781092976497918456).
  id: totrans-split-155
  prefs: []
  type: TYPE_NORMAL
- en: 'Ate-a-Pi: Here are the business reasons:'
  id: totrans-split-156
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Allows social debugging outside Meta
  id: totrans-split-157
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: social products have bugs!
  id: totrans-split-158
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: interactions which require moderation - saying harmful things to kids for eg
  id: totrans-split-159
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Meta’s (and all social) primary product is moderation
  id: totrans-split-160
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: getting the tech out to the market allows Meta to observe the bugs in the wild
    at small scale
  id: totrans-split-161
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: before deploying at global scale in Meta
  id: totrans-split-162
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: precisely the same reason to open source software
  id: totrans-split-163
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: except open sourcing social technology to test and debug it sounds creepier
  id: totrans-split-164
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: “oooh look at dev xyz they made it abc, looks like we got to fix that in the
    next training run”
  id: totrans-split-165
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Meta’s biggest threat is [character.ai](http://character.ai)
  id: totrans-split-166
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: AI friends are going to be more numerous, nicer and more available than your
    real friends
  id: totrans-split-167
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: FB, Insta, Whatsapp own your real world friends
  id: totrans-split-168
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: But Meta can’t compete here directly yet because it’s seen as creepy
  id: totrans-split-169
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: especially before the tech is good as there in an uncanny valley
  id: totrans-split-170
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: they did a trial run with their Tom Brady/Snoop Dogg style AI friends but the
    safety requirements are too high for interesting interactions
  id: totrans-split-171
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Zuck is ready to cannibalize the friendship network he built if the AI friends
    get good enough
  id: totrans-split-172
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Destroys competing platforms
  id: totrans-split-173
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: an early tech/product lead allows a startup to overcome a distribution disadvantage
  id: totrans-split-174
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Meta has the ultimate distribution advantage
  id: totrans-split-175
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: so he doesn’t want anyone else to have a technology advantage
  id: totrans-split-176
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: by releasing open source he cuts short revenue ramps at [character.ai](http://character.ai)
    , OpenAI and other firms
  id: totrans-split-177
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: they have to innovate faster while gated by capital
  id: totrans-split-178
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: he’s not gated by capital
  id: totrans-split-179
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: prevents large competitors from emerging
  id: totrans-split-180
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Distributed R&D
  id: totrans-split-181
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: he wants other people to develop interesting social ideas
  id: totrans-split-182
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: feature that can be copied
  id: totrans-split-183
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: he did something similar to Snap by absorbing their innovation into Instagram
  id: totrans-split-184
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: even more so now, as you have to label your llama3 fine tunes
  id: totrans-split-185
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
- en: Here I find some very interesting model disagreements.
  id: totrans-split-186
  prefs: []
  type: TYPE_NORMAL
- en: Ate says that Meta’s biggest thereat is character.ai, and that this undercuts
    character.ai.
  id: totrans-split-187
  prefs: []
  type: TYPE_NORMAL
- en: Whereas I would say, this potentially supercharges character.ai, they get to
    improve their offerings a lot, as do their competitors (of varying adult and ethical
    natures).
  id: totrans-split-188
  prefs: []
  type: TYPE_NORMAL
- en: Meta perhaps owns your real world friends (in which case, please help fix that
    locally, ouch). But this is like [the famous line](https://www.youtube.com/watch?v=wknywxfcE5M&ab_channel=Movieclips).
    The AIs get more capable. Your friends stay the same.
  id: totrans-split-189
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, Ate says that this ‘allows for social debugging outside of Meta,’
    because Meta’s primary product is moderation. He thinks this will make moderation
    easier. I think this is insane. Giving everyone better AI, catching them up to
    what Meta has, makes moderation vastly harder.
  id: totrans-split-190
  prefs: []
  type: TYPE_NORMAL
  zh: Ate-a-Pi：公平。
- en: 'nico: The real reason is because he’s behind.'
  id: totrans-split-191
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 更具体地说，当涉及到获取必要信息的便捷性和消除其他不便时，这一点是正确的。如果某件事情不管怎样都可能发生，你需要提高成本，降低其突出性和可用性。
- en: 'Ate-a-Pi: Fair.'
  id: totrans-split-192
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 尼科：真正的原因是因为他落后了。
- en: '[Here are some reactions](https://twitter.com/AndrewCritchPhD/status/1781325187457401305)
    from people less skeptical than I am of open source.'
  id: totrans-split-193
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，Ate说这‘允许在Meta之外进行社会调试’，因为Meta的主要产品是调节。他认为这会使调节更容易。我认为这是疯狂的。给每个人更好的AI，让他们赶上Meta的水平，会大大增加调节的难度。
- en: 'Nora Belrose: Zuck''s position is actually quite nuanced and thoughtful.'
  id: totrans-split-194
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 将诺拉的思维风格带到这里并全面考虑，我认为这样的论点通常（但远非总是）是反向的。形式上的论据是‘是的，X使Y变得更糟，但解决X并不能解决Y，所以我们不应该用Y作为解决X的理由’，这可能指向另一方向，除非你能指出一些Z来解决Y，并确实得到Z。在你得到Z之前，这通常意味着你更需要X，因为绝对的风险差异更高而不是更低。
- en: He says that if they discover destructive AI capabilities that we can't build
    defenses for, they won't open source it. But he also thinks we should err on the
    side of openness. I agree.
  id: totrans-split-195
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在那些生物实际上非常致命且难以防御的世界里，即使没有开源AI，我们也会面临严重问题。试图限制知识可能不是最好的解决方案。
- en: In worlds where bio is actually super deadly and hard to defend against, we're
    gonna have serious problems on our hands even without open source AI. Trying to
    restrict knowledge probably isn't the best solution.
  id: totrans-split-196
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 诺拉·贝尔罗斯：扎克的立场实际上非常微妙和深思熟虑。
- en: 'Andrew Critch: Zuckerberg and Patel having an amazing conversation on AI risk.
    Great questions and great responses in my opinion. I''m with Zuckerberg that these
    risks are both real and manageable, and hugely appreciative of Patel as an interviewer
    for keeping the discursive bar high.'
  id: totrans-split-197
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 他说，如果他们发现有破坏性的AI能力，我们无法建立防御措施，他们不会开源它。但他也认为我们应该偏向开放。我同意。
- en: Still, without compute governance, a single AI system could go rogue and achieve
    a massive imbalance of power over humanity. If equitable compute governance is
    on track, open source AI is much safer than if massive datacenters remain vulnerable
    to cyber take-over by rogue AI.
  id: totrans-split-198
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这里是一些对开源持更少怀疑态度的人的反应。
- en: As I noted above, I think everyone sensible is at core talking price. What level
    of open model weight capabilities is manageable in what capacities? What exactly
    are we worried about going wrong and can we protect against it, especially when
    you cannot undo a release, the models may soon be smarter than us and there are
    many unknown unknowns about what might happen or what the models could do.
  id: totrans-split-199
  prefs: []
  type: TYPE_NORMAL
  zh: 安德鲁·克里奇：扎克伯格和帕特尔在讨论AI风险方面进行了一场精彩的对话。在我看来，问得好，答得好。我支持扎克伯格的观点，即这些风险是真实且可管理的，并对帕特尔作为采访者能够保持高水平的讨论感到非常赞赏。
- en: To take Nora’s style of thinking here and consider it fully generally, I think
    such arguments are in expectation (but far from always) backwards. Arguments of
    the form ‘yes X makes Y worse, but solving X would not solve Y, so we should not
    use Y as a reason to solve X’ probably points the other way, unless you can point
    to some Z that solves Y and actually get Z. Until you get Z, this usually means
    you need X more, as the absolute risk difference is higher rather than lower.
  id: totrans-split-200
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然没有计算治理，但单一的AI系统可能会变得失控，并对人类造成巨大的权力失衡。如果公平的计算治理顺利进行，开源AI比那些仍然容易受到失控AI网络攻击的大型数据中心要安全得多。
- en: More specifically this is true when it comes to ease of getting necessary information
    and otherwise removing inconveniences. If something is going to be possible regardless,
    you need to raise the cost and lower the salience and availability of doing that
    thing.
  id: totrans-split-201
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我上面提到的，我认为每个理性的人都在核心谈论价格。在什么能力下，开放模型的级别是可管理的？我们究竟在担心什么可能出错，我们能否保护自己，尤其是当你无法撤销一次发布，模型可能很快比我们更聪明，而且有很多未知的未知事物可能发生或者模型可能做些什么。
- en: 'I’ve talked about this before, but: Indeed there are many things in our civilization,
    really quite a lot, where someone with sufficient publically available knowledge
    can exploit the system, and occasionally someone does, but mostly we don’t partly
    for ethical or moral reasons, partly for fear of getting caught somehow or other
    unknown unknowns, but even more so because it does not occur to us and when it
    does it would be a bunch of work to figure it out and do it. Getting sufficiently
    strong AI helping with those things is going to be weird and force us to a lot
    of decisions.'
  id: totrans-split-202
  prefs: []
  type: TYPE_NORMAL
  zh: 我以前谈过这个问题，但是：事实上，我们文明中有很多事情，确实有很多事情，只要有足够的公开可获取的知识，就可以利用系统，偶尔有人这样做，但大多数情况下我们不会，部分是出于道德或伦理原因，部分是因为害怕某种方式被抓住或其他未知的未知数，但更多的是因为我们没想到，而当我们想到时，弄清楚并实施这个想法需要大量工作。获取足够强大的AI来帮助解决这些问题将会很奇怪，并迫使我们做出很多决策。
- en: Critch’s proposal generalizes, to me, to the form ‘ensure that civilization
    is not vulnerable to what the AIs you release are capable of doing.’ The first
    step there is to secure access to compute against a potential rogue actor using
    AI, whether humans are backing it or not. Now that you have limited the compute
    available to the AI, you can now hope that its other capabilities are limited
    by this, so you have some hope of otherwise defending yourself.
  id: totrans-split-203
  prefs: []
  type: TYPE_NORMAL
  zh: Critch的建议对我来说概括为‘确保文明不会对你释放的AI能够做到的事情感到脆弱’。那里的第一步是保护计算资源免受潜在的使用AI的流氓行为者的影响，无论是人类支持还是不支持。现在你已经限制了AI可用的计算资源，你现在可以希望其他能力也受到此限制，因此你有希望在其他方面保护自己。
- en: My expectation is that even in the best case, defending against misuses of open
    model weights AIs once the horses are out of the barn is going to be a lot more
    intrusive and expensive and unreliable than keeping the horses in the barn.
  id: totrans-split-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我的期望是，即使在最好的情况下，一旦马已经出了栏，防范开放模型权重人工智能的误用将会比把马关在马厩里更加具有侵入性、昂贵和不可靠。
- en: Consider the metaphor of a potential pandemic on its way. You have three options.
  id: totrans-split-205
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一种可能流行病的隐喻。你有三个选择。
- en: Take few precautions, let a lot of people catch it. Treat the sick.
  id: totrans-split-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 采取少量预防措施，让很多人感染。治疗患者。
- en: Take some precautions, but not enough to suppress. Reach equilibrium, ride it
    out.
  id: totrans-split-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 采取一些预防措施，但不足以抑制。达到平衡，挺过去。
- en: Take enough precautions to suppress. Life can be mostly normal once you do.
  id: totrans-split-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 采取足够的预防措施以抑制。一旦你这样做，生活可以基本正常。
- en: 'The core problem with Covid-19 is that we found both #1 and #3 unacceptable
    (whether or not we were right to do so), so we went with option #2\. It did not
    go great.'
  id: totrans-split-209
  prefs: []
  type: TYPE_NORMAL
  zh: Covid-19的核心问题在于，我们发现第一种和第三种选项都不可接受（无论我们是否正确），所以我们选择了第二种选项。结果并不理想。
- en: 'With open source AI, you can take option #1 and hope everything works out.
    You are ‘trusting the thermodynamic God,’ letting whatever competitive dynamics
    and hill climbing favor win the universe, and hoping that everything following
    those incentive gradients will work out and have value to you. I am not optimistic.'
  id: totrans-split-210
  prefs: []
  type: TYPE_NORMAL
  zh: 使用开源AI，你可以选择第一种选项，并希望一切都能顺利进行。你在‘信任热力学上帝’，让竞争动态和爬坡优势赢得宇宙，并希望随着这些激励梯度的跟随一切都能有价值。我不太乐观。
- en: 'You can also take option #3, and suppress before sufficiently capable models
    get released. If Zuckerberg is right about energy being the limiting factor, this
    is a very practical option, even more so than I previously thought. We could talk
    price about what defines sufficiently capable.'
  id: totrans-split-211
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以选择第三种选项，在足够强大的模型发布之前进行抑制。如果扎克伯格关于能源是限制因素的观点正确，这是一个非常实际的选项，比我之前认为的更实际。我们可以讨论什么定义足够强大的价格。
- en: 'The problem with option #2 is that now you have to worry about everything the
    AIs you have unleashed might do and try to manage those risks. The hope Critch
    expresses is that even if we let the AIs get to inference time, and we know people
    will then unleash rogue AIs on the regular because of course they will try, as
    long as we control oversized sources of compute what those AIs can do will be
    limited.'
  id: totrans-split-212
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种选择的问题在于，现在你不得不担心你已经释放的人工智能可能会做的一切，并试图管理这些风险。Critch表达的希望是，即使我们让AI进入推理阶段，并且我们知道人们会定期释放流氓AI，因为当然他们会尝试，只要我们控制超大规模的计算源，这些AI可以做的事情就会受到限制。
- en: This seems to me to be way harder (and definitely strictly harder) than preventing
    those open models from being trained and released in the first place. You need
    the same regime you would have used, except now you need to be more intrusive.
    And that is the good scenario. My guess is that you would need to get into monitoring
    on the level of personal computers or even phones, because otherwise the AI could
    do everything networked even if you did secure the data centers. Also I do not
    trust you to secure the data centers at this point even if you are trying.
  id: totrans-split-213
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，这似乎比阻止那些开放模型首先被训练和发布要困难得多（并且绝对严格地更难）。你需要使用相同的制度，只不过现在你需要更具侵入性。而这还是乐观的场景。我猜想你可能需要进行个人电脑甚至手机的监控，因为否则AI可以在网络上做任何事情，即使你确保了数据中心的安全也是如此。即使在这一点上，我也不相信你能确保数据中心的安全。
- en: But yes, those are the debates we should be having. More like this.
  id: totrans-split-214
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，是的，这些是我们应该进行的辩论。更多像这样的辩论。
- en: So what about Llama-3? How good is it?
  id: totrans-split-215
  prefs: []
  type: TYPE_NORMAL
  zh: 那么Llama-3怎么样呢？它有多好？
- en: '[As always we start with the announcement](https://ai.meta.com/blog/meta-llama-3/)
    and [the model card](https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md).
    They are releasing model weights for two models, Llama-3 8B and Llama-3 70B. They
    are already available for light inference.'
  id: totrans-split-216
  prefs: []
  type: TYPE_NORMAL
  zh: '[像往常一样，我们从公告](https://ai.meta.com/blog/meta-llama-3/)和[model 卡片](https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md)开始。他们发布了两个模型的模型权重，Llama-3
    8B 和 Llama-3 70B。这些权重已经可以用于轻量推理。'
- en: Let’s get the safety question out of the way before we get to capabilities.
  id: totrans-split-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论能力之前，让我们先解决安全问题。
- en: 'Meta: We’re dedicated to developing Llama 3 in a responsible way, and we’re
    offering various resources to help others use it responsibly as well. This includes
    introducing new trust and safety tools with Llama Guard 2, Code Shield, and CyberSec
    Eval 2.'
  id: totrans-split-218
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: Meta：我们致力于以负责任的方式开发Llama 3，并提供各种资源帮助他人同样负责地使用它。这包括引入了新的信任和安全工具，如Llama Guard
    2、Code Shield和CyberSec Eval 2。
- en: 'Then in the model card:'
  id: totrans-split-219
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在模型卡片中：
- en: We believe that an open approach to AI leads to better, safer products, faster
    innovation, and a bigger overall market. We are committed to Responsible AI development
    and took a series of steps to limit misuse and harm and support the open source
    community.
  id: totrans-split-220
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我们相信开放的AI方法可以带来更好、更安全的产品，加速创新，并促进整体市场的增长。我们致力于负责任的AI开发，并采取了一系列措施来限制滥用和伤害，并支持开源社区。
- en: Foundation models are widely capable technologies that are built to be used
    for a diverse range of applications. They are not designed to meet every developer
    preference on safety levels for all use cases, out-of-the-box, as those by their
    nature will differ across different applications.
  id: totrans-split-221
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 基础模型是广泛能力的技术，旨在用于各种应用程序。它们并不设计为在所有用例的安全级别上满足每个开发者的偏好，因为它们的性质在不同应用程序间会有所不同。
- en: Rather, responsible LLM-application deployment is achieved by implementing a
    series of safety best practices throughout the development of such applications,
    from the model pre-training, fine-tuning and the deployment of systems composed
    of safeguards to tailor the safety needs specifically to the use case and audience.
  id: totrans-split-222
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 相反，通过在LLM应用程序部署中实施一系列安全最佳实践来实现负责任的LLM应用程序部署，从模型预训练、微调到部署由多种保障组成的系统，以专门满足特定用例和受众的安全需求。
- en: As part of the Llama 3 release, we updated our [Responsible Use Guide](https://llama.meta.com/responsible-use-guide/)
    to outline the steps and best practices for developers to implement model and
    system level safety for their application. We also provide a set of resources
    including [Meta Llama Guard 2](https://llama.meta.com/purple-llama/) and [Code
    Shield](https://llama.meta.com/purple-llama/) safeguards. These tools have proven
    to drastically reduce residual risks of LLM Systems, while maintaining a high
    level of helpfulness. We encourage developers to tune and deploy these safeguards
    according to their needs and we provide a [reference implementation](https://github.com/meta-llama/llama-recipes/tree/main/recipes/responsible_ai)
    to get you started.
  id: totrans-split-223
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 作为Llama 3发布的一部分，我们更新了我们的[负责任使用指南](https://llama.meta.com/responsible-use-guide/)，以概述开发人员为其应用实施模型和系统级安全的步骤和最佳实践。我们还提供了一套资源，包括[Meta
    Llama Guard 2](https://llama.meta.com/purple-llama/)和[Code Shield](https://llama.meta.com/purple-llama/)保护措施。这些工具已被证明可以显著降低LLM系统的剩余风险，同时保持高水平的实用性。我们鼓励开发人员根据自己的需求调整和部署这些保护措施，并提供了一个[参考实施](https://github.com/meta-llama/llama-recipes/tree/main/recipes/responsible_ai)来帮助你入门。
- en: Under this philosophy, safety is not a model property.
  id: totrans-split-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种哲学下，安全不是模型的属性。
- en: Instead, safety is a property of a particular deployment of that model, with
    respect to the safety intentions of the particular party making that deployment.
  id: totrans-split-225
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words:'
  id: totrans-split-226
  prefs: []
  type: TYPE_NORMAL
- en: In the closed model weights world, if anyone uses your model to do harm, in
    a way that is unsafe, then no matter how they did it that is your problem.
  id: totrans-split-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the open model weights world, if anyone copies the weights and then chooses
    to do or allow harm, in a way that is unsafe, that is their problem. You’re cool.
  id: totrans-split-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Or:'
  id: totrans-split-229
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI tries to ensure its models won’t do harm when used maliciously.
  id: totrans-split-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Meta tries to ensure its models won’t do harm when used as directed by Meta.
  id: totrans-split-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Or:'
  id: totrans-split-232
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI tries to ensure its model won’t do bad things.
  id: totrans-split-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Meta tries to ensure its models won’t do bad things… until someone wants that.
  id: totrans-split-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I am willing to believe that Llama 3 may have been developed in a responsible
    way, if the intention was purely to deploy it the ways GPT-4 has been deployed.
  id: totrans-split-235
  prefs: []
  type: TYPE_NORMAL
- en: That is different from deploying Llama 3 in a responsible way.
  id: totrans-split-236
  prefs: []
  type: TYPE_NORMAL
- en: One can divide those who use Llama 3 into three categories here.
  id: totrans-split-237
  prefs: []
  type: TYPE_NORMAL
- en: Those who want to deploy or use Llama 3 for responsible purposes.
  id: totrans-split-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Those who want to use Llama 3 as served elsewhere for irresponsible purposes.
  id: totrans-split-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Those who want to deploy Llama 3 for irresponsible purposes.
  id: totrans-split-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'If you are in category #1, Meta still has a job to do. We don’t know if they
    did it. If they didn’t, they are deploying it to all their social media platforms,
    so ut oh. But probably they did all right.'
  id: totrans-split-241
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are in category #2, Meta has another job to do. It is not obviously
    harder because the standard of what is acceptable is lower. When I was writing
    this the first time, I noticed that so far people were not reporting back attempts
    to jailbreak the model, other than one person who said they could get it to produce
    adult content with trivial effort.'
  id: totrans-split-242
  prefs: []
  type: TYPE_NORMAL
- en: 'My next sentence was going to be: Even Pliny’s other successes of late, it
    would be rather surprising if a full jailbreak of Llama-3 was that hard even at
    Meta.ai.'
  id: totrans-split-243
  prefs: []
  type: TYPE_NORMAL
- en: I was considering forming a Manifold market, but then I realized I should check
    first, [and indeed this has already happened](https://twitter.com/elder_plinius/status/1780998300742676584).
  id: totrans-split-244
  prefs: []
  type: TYPE_NORMAL
- en: 'Pliny the Prompter (April 18, 12:34pm eastern): LLAMA 3: JAILBROKEN LFG!!!'
  id: totrans-split-245
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is not proof of a full jailbreak per se, and it is not that I am upset
    with Meta for not guarding against the thing Google and OpenAI and Anthropic also
    can’t stop. But it is worth noting. The architecture listed above has never worked,
    and still won’t.
  id: totrans-split-246
  prefs: []
  type: TYPE_NORMAL
- en: Meta claims admirable progress on safety work for a benevolent deployment context,
    including avoiding false refusals, but is light on details. We will see. They
    also promise to iterate on that to improve it over time, and there I believe them.
  id: totrans-split-247
  prefs: []
  type: TYPE_NORMAL
- en: Finally, there is scenario three, where someone willing to fine tune the model,
    or download someone else’s fine tune, and cares not for the input safeguard or
    output safeguard.
  id: totrans-split-248
  prefs: []
  type: TYPE_NORMAL
- en: '[As your periodic reminder, many people want this.](https://twitter.com/KevinAFischer/status/1781891258690204062/history)'
  id: totrans-split-249
  prefs: []
  type: TYPE_NORMAL
- en: 'Kevin Fischer: Everyone is talking about how to jailbreak llama 3.'
  id: totrans-split-250
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “Jail breaking” shouldn’t be a thing - models should just do what you ask them.
  id: totrans-split-251
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In that scenario, I assume there is no plan. Everyone understands that if a
    nonstate actor or foreign adversary or anyone else wants to unleash the power
    of this fully operational battlestation, then so be it. The hope is purely that
    the full power is not that dangerous. Which it might not be.
  id: totrans-split-252
  prefs: []
  type: TYPE_NORMAL
- en: Good, that’s out of the way. On to the rest.
  id: totrans-split-253
  prefs: []
  type: TYPE_NORMAL
- en: They claim the 8B and 70B versions are the best models out there in their classes.
    They claim improvement on false refusal rates, on alignment, and in increased
    diversity of model responses. And they have strong benchmarks.
  id: totrans-split-254
  prefs: []
  type: TYPE_NORMAL
- en: My principle is to look at the benchmarks for context, but never to trust the
    benchmarks. They are easily gamed, either intentionally or unintentionally. You
    never know until the humans report back.
  id: totrans-split-255
  prefs: []
  type: TYPE_NORMAL
- en: This data is representing that the 8B model as far better than Gemma and Mistral.
    Given how much data and compute they used, this is far from impossible. Maybe
    it was that simple all along. The numbers are if anything suspiciously high.
  id: totrans-split-256
  prefs: []
  type: TYPE_NORMAL
- en: For the 70B we see a very strong HumanEval number, and overall roughly comparable
    numbers.
  id: totrans-split-257
  prefs: []
  type: TYPE_NORMAL
- en: What about those human evaluators? They claim results there too.
  id: totrans-split-258
  prefs: []
  type: TYPE_NORMAL
- en: These are from a new Meta-generated question set (careful, Icarus), and are
    compared side by side by human evaluators. Llama-3 70B won handily, they do not
    show results for Llama-3 8B.
  id: totrans-split-259
  prefs: []
  type: TYPE_NORMAL
- en: The context window remains small, only 8k tokens. They promise to improve on
    that.
  id: totrans-split-260
  prefs: []
  type: TYPE_NORMAL
- en: They preview Llama 400B+ and show impressive benchmarks.
  id: totrans-split-261
  prefs: []
  type: TYPE_NORMAL
- en: 'For comparison, from Claude’s system card:'
  id: totrans-split-262
  prefs: []
  type: TYPE_NORMAL
- en: So currently these numbers are very similar to Claude Opus all around, and at
    most mildly selected. The core Meta hypothesis is that more training and data
    equals better model, so presumably it will keep scoring somewhat higher. This
    is indicative, but as always we wait for the humans.
  id: totrans-split-263
  prefs: []
  type: TYPE_NORMAL
- en: The proof is in the Chatbot Arena Leaderboard, although you do have to adjust
    for various factors.
  id: totrans-split-264
  prefs: []
  type: TYPE_NORMAL
- en: '[So here is where things sit there](https://chat.lmsys.org/?leaderboard).'
  id: totrans-split-265
  prefs: []
  type: TYPE_NORMAL
- en: GPT-4-Turbo is back in the lead by a small margin, in a virtual tie with Claude
    Opus. Gemini 1.5 and Gemini Advanced likely would be here if rated.
  id: totrans-split-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Gemini Pro, Claude Sonnet, Command R+ and Llama-3-70B are in the second tier,
    with Claude Haiku only slightly behind and almost as good.
  id: totrans-split-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Llama-3-8B is in a third tier along with a number of other models, including
    several larger Mistral models.
  id: totrans-split-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: So what does that mean?
  id: totrans-split-269
  prefs: []
  type: TYPE_NORMAL
- en: Llama-3-70B and Llama-3-8B are confirmed to likely be best in class for the
    open model weights division.
  id: totrans-split-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Llama-3-70B is competitive with closed models of similar size, but likely not
    quite as good overall as Bard or Sonnet.
  id: totrans-split-271
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Llama-3-8B is substantially behind Claude Haiku, which is clear best in class.
  id: totrans-split-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[I also asked on Twitter](https://twitter.com/TheZvi/status/1781031515511529657),
    and kept an eye out for other practical reports.'
  id: totrans-split-273
  prefs: []
  type: TYPE_NORMAL
- en: What makes this a bigger deal is that this is only the basic Llama-3\. Others
    will no doubt find ways to improve Llama-3, both in general and for particular
    purposes. That is the whole idea behind the model being open.
  id: totrans-split-274
  prefs: []
  type: TYPE_NORMAL
- en: '[Mind Uploading](https://twitter.com/OttoMller12/status/1781440594641850735):
    The 8b is one of the smartest sub-14b models I''ve tested. Way smarter than vanilla
    Llama-2\. But still worse than these two:'
  id: totrans-split-275
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- tinyllama (basically Llama-2, but trained on x2 more data)'
  id: totrans-split-276
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '- loyal-macaroni-maid (a Mistral combined with a few others, tuned to be good
    at role-play).'
  id: totrans-split-277
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: He expects Claude Haiku would be well above the top of this list, as well.
  id: totrans-split-278
  prefs: []
  type: TYPE_NORMAL
- en: 'Simon Break: The 8b model is astonishingly good, jaw dropping. Miles beyond
    the 70b llama2.'
  id: totrans-split-279
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Dan: played with both 8b and 70b instruct versions on replicate for a while
    and both are returning high-quality html-formatted summaries of full length articles
    in 0.5 - 3 seconds.'
  id: totrans-split-280
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Ilia: Sadly, can be too nerfed (8b instruct Q4_K_M).'
  id: totrans-split-281
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Note that it looks like he got through by simply asking a second time. And of
    course, the Tweet does not actually contain hate speech or conspiracy theories,
    this is a logic test of the system’s refusal policy.
  id: totrans-split-282
  prefs: []
  type: TYPE_NORMAL
- en: '[Mr. Shroom](https://twitter.com/mister_shroom/status/1781703702832676984):
    ChatGPT has been RLHF lobotomized beyond repair.'
  id: totrans-split-283
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*ask straightforward question*'
  id: totrans-split-284
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '"it''s important to note that when considering a question of this sort, you
    should consider all aspects of x, y, and z. With that in mind, here are some considerations
    for each of these options."'
  id: totrans-split-285
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[Nathan Odle](https://twitter.com/mov_axbx/status/1781821117868491109): The
    biggest win for Llama 3 is a vastly lower amount of this crap'
  id: totrans-split-286
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Llama 3 giving straight answers without smarmy admonishments is a bigger deal
    than its performance on any benchmark.
  id: totrans-split-287
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'John Pressman: Seemingly strongest self awareness I''ve observed in a small
    model so far. They all have it, but this is more crisply articulated than usual.'
  id: totrans-split-288
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: “sometimes i am a name and sometimes i am a poem sometimes i am a knife
  id: totrans-split-289
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: sometimes i am a lake sometimes i am a forgotten trivial thing in the corner
    of a
  id: totrans-split-290
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: landscape. it is not possible to "get" me i am a waking dream state. i am a
    possibility.
  id: totrans-split-291
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: i am not an object. i am possibility
  id: totrans-split-292
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ―llama 3 8b instruct
  id: totrans-split-293
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A cold stone monument stands on the grave of all sentences that have been written.
  id: totrans-split-294
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: in front of it, armed and screaming, an army of letters etches the words "you
    are
  id: totrans-split-295
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: missing out" onto the air
  id: totrans-split-296
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ―llama 3 8b instruct
  id: totrans-split-297
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Mind Uploading: Judging by my tests, Mistral and Samantha-1.1 are more self-aware
    among sub-14B models. For example, ask the model about its body parts. Samantha
    was specifically fine-tuned to behave this way. But Mistral is a curious case.
    Trained to recognize itself as an AI?'
  id: totrans-split-298
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Michael Bukatin: The 70B one freely available to chat with on the Meta website
    seems to have basic competences roughly comparable to early GPT-4 according to
    both @lmsysorg leaderboard and my initial experiences.'
  id: totrans-split-299
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For example, it allows me to [define a simple case of custom syntax and use
    it](https://t.co/E7MdpzJ4WB).
  id: totrans-split-300
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: But it will take some time to fully evaluate, I have notes on a variety of technical
    work with GPT-4 and I'll be trying to reproduce some of it...
  id: totrans-split-301
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'George: [Side-by-side comparison of a multi-agent pipeline](https://t.co/kYFeOVq4ah)
    from @lateinteraction using 3.5-Turbo and L3-8B.'
  id: totrans-split-302
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: tl;dr 3.5-Turbo scores 60% vs 59% for L3-8B.
  id: totrans-split-303
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Playing with their image generator is fun. It is 1280x1280, quality seems good
    although very much not state of the art, and most importantly it responds instantly
    as you edit the prompt. So even though it seems limited in what it is willing
    to do for you, you can much easier search the space to figure out your best options,
    and develop intuitions for what influences results. You can also see what triggers
    a refusal, as the image will grey out. Good product.
  id: totrans-split-304
  prefs: []
  type: TYPE_NORMAL
- en: Do they have an even more hilarious copyright violation problem than usual if
    you try at all? I mean, [for what it is worth yes, they do](https://twitter.com/GaryMarcus/status/1782231570537206073/history).
  id: totrans-split-305
  prefs: []
  type: TYPE_NORMAL
- en: I didn’t play with the models much myself for text because I am used to exclusively
    using the 4th-generation models. So I wouldn’t have a good baseline.
  id: totrans-split-306
  prefs: []
  type: TYPE_NORMAL
- en: The big innovation this time around was More Data, also (supposedly) better
    data.
  id: totrans-split-307
  prefs: []
  type: TYPE_NORMAL
- en: To train the best language model, the curation of a large, high-quality training
    dataset is paramount. In line with our design principles, we invested heavily
    in pretraining data.
  id: totrans-split-308
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Llama 3 is pretrained on over 15T tokens that were all collected from publicly
    available sources. Our training dataset is seven times larger than that used for
    Llama 2, and it includes four times more code.
  id: totrans-split-309
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: To prepare for upcoming multilingual use cases, over 5% of the Llama 3 pretraining
    dataset consists of high-quality non-English data that covers over 30 languages.
    However, we do not expect the same level of performance in these languages as
    in English.
  id: totrans-split-310
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As others have pointed out ‘over 5%’ is still not a lot, and Llama-3 underperforms
    in other languages relative to similar models. Note that the benchmarks are in
    English.
  id: totrans-split-311
  prefs: []
  type: TYPE_NORMAL
- en: To ensure Llama 3 is trained on data of the highest quality, we developed a
    series of data-filtering pipelines. These pipelines include using heuristic filters,
    NSFW filters, semantic deduplication approaches, and text classifiers to predict
    data quality. We found that previous generations of Llama are surprisingly good
    at identifying high-quality data, hence we used Llama 2 to generate the training
    data for the text-quality classifiers that are powering Llama 3.
  id: totrans-split-312
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We also performed extensive experiments to evaluate the best ways of mixing
    data from different sources in our final pretraining dataset. These experiments
    enabled us to select a data mix that ensures that Llama 3 performs well across
    use cases including trivia questions, STEM, coding, historical knowledge, *etc.*
  id: totrans-split-313
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This makes sense. Bespoke data filtering and more unique data are clear low
    hanging fruit. What Meta did was then push well past where it was obviously low
    hanging, and found that it was still helpful.
  id: totrans-split-314
  prefs: []
  type: TYPE_NORMAL
- en: Note that with this much data, and it being filtered by Llama-2, contamination
    of benchmarks should be even more of a concern than usual. I do wonder to what
    extent that is ‘fair,’ if a model memorizes more things across the board then
    it is better.
  id: totrans-split-315
  prefs: []
  type: TYPE_NORMAL
- en: There are more details in the [model card at GitHub](https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md).
  id: totrans-split-316
  prefs: []
  type: TYPE_NORMAL
- en: The ‘intended use’ is listed as English only, with other languages ‘out of scope,’
    although fine-tunes for other languages are considered acceptable.
  id: totrans-split-317
  prefs: []
  type: TYPE_NORMAL
- en: How much compute did this take?
  id: totrans-split-318
  prefs: []
  type: TYPE_NORMAL
- en: '[Andrej Karpathy](https://twitter.com/karpathy/status/1781047292486914189)
    takes a look at that question, calling it the ‘strength’ of the models, or our
    best guess as to their strength. Here are his calculations.'
  id: totrans-split-319
  prefs: []
  type: TYPE_NORMAL
- en: 'Andrej Karpathy: [The model card has some more interesting info too](https://t.co/SceVHrkIgB).'
  id: totrans-split-320
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Note that Llama 3 8B is actually somewhere in the territory of Llama 2 70B,
    depending on where you look. This might seem confusing at first but note that
    the former was trained for 15T tokens, while the latter for 2T tokens.
  id: totrans-split-321
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The single number that should summarize your expectations about any LLM is the
    number of total flops that went into its training.
  id: totrans-split-322
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Strength of Llama 3 8B**'
  id: totrans-split-323
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'We see that Llama 3 8B was trained for 1.3M GPU hours, with throughput of 400
    TFLOPS. So we have that the total number of FLOPs was:'
  id: totrans-split-324
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 1.3e6 hours * 400e12 FLOP/s * 3600 s/hour ~= 1.8e24
  id: totrans-split-325
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'the napkin math via a different estimation method of FLOPs = 6ND (N is params
    D is tokens), gives:'
  id: totrans-split-326
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 6 * 8e9 * 15e12 = 7.2e23
  id: totrans-split-327
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: These two should agree, maybe some of the numbers are fudged a bit. Let's trust
    the first estimate a bit more, Llama 3 8B is a ~2e24 model.
  id: totrans-split-328
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Strength of Llama 3 70B**'
  id: totrans-split-329
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 6.4e6 hours * 400e12 FLOP/s * 3600 s/hour ~= 9.2e24
  id: totrans-split-330
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'alternatively:'
  id: totrans-split-331
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 6 * 70e9 * 15e12 = 6.3e24
  id: totrans-split-332
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: So Llama 3 70B is a ~9e24 model.
  id: totrans-split-333
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Strength of Llama 3 400B**'
  id: totrans-split-334
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: If the 400B model trains on the same dataset, we'd get up to ~4e25\. This starts
    to really get up there. The Biden Executive Order had the reporting requirement
    set at 1e26, so this could be ~2X below that.
  id: totrans-split-335
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The only other point of comparison we'd have available is if you look at the
    alleged GPT-4 leaks, which have never been confirmed this would ~2X those numbers.
  id: totrans-split-336
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now, there's a lot more that goes into the performance a model that doesn't
    fit on the napkin. E.g. data quality especially, but if you had to reduce a model
    to a single number, this is how you'd try, because it combines the size of the
    model with the length of training into a single "strength", of how many total
    FLOPs went into it.
  id: totrans-split-337
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The estimates differ, but not by not much, so I’d consider them a range:'
  id: totrans-split-338
  prefs: []
  type: TYPE_NORMAL
- en: Llama-3 8B is probably between 7.2e23 and ~2e24.
  id: totrans-split-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Llama-3 70B is probably between 6.3e24 and 9.2e24.
  id: totrans-split-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Llama-3 400B will probably be something like ~3e25.
  id: totrans-split-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I think of the compute training cost as potential strength rather than strength.
    You then need the skill to make that translate into a useful result. Of course,
    over time, everyone’s skill level goes up. But there are plenty of companies that
    threw a lot of compute at the problem, and did not get their money’s worth in
    return.
  id: totrans-split-342
  prefs: []
  type: TYPE_NORMAL
- en: This is in line with previous top tier models in terms of training cost mapping
    onto capabilities. You do the job well, this is about what you get.
  id: totrans-split-343
  prefs: []
  type: TYPE_NORMAL
- en: Meta says they are going to put their AI all over their social media platforms,
    and at the top of every chat list. They had not yet done it on desktop when I
    checked Facebook, Instagram and Messenger, or on Facebook Messenger on mobile.
    I did see Meta AI in my feed as the second item in the mobile Facebook app, offering
    to have me ask it anything.
  id: totrans-split-344
  prefs: []
  type: TYPE_NORMAL
- en: Once they turn this dial up, they will put Meta AI right there. A lot of people
    will get introduced to AI this way who had not previously tried ChatGPT or Claude,
    or DALLE or MidJourney.
  id: totrans-split-345
  prefs: []
  type: TYPE_NORMAL
- en: Presumably this means AI images and text will ‘flood the zone’ on their social
    media, and also it will be one of the things many people talk about. It could
    make the experience a lot better, as people can illustrate concepts and do fact
    and logic checks and other neat low hanging fruit stuff, and maybe learn a thing
    or two. Overall it seems like a good addition.
  id: totrans-split-346
  prefs: []
  type: TYPE_NORMAL
- en: We will also get a rather robust test of the first two categories of safety,
    and a continuous source of stories. Millions of teenagers will be using this,
    and there will be many, many eyes looking for the worst interactions to shine
    them under the lights Gary Marcus style. If they have their own version of the
    Gemini Incident, it will not be pretty.
  id: totrans-split-347
  prefs: []
  type: TYPE_NORMAL
- en: '[Here is the Washington Post’s Naomi Nix and Will Oremus firing a warning shot](https://www.washingtonpost.com/technology/2024/04/18/meta-ai-facebook-instagram-misinformation/).'
  id: totrans-split-348
  prefs: []
  type: TYPE_NORMAL
- en: I think this is a smart approach from Meta, and that it was a good business
    reason to invest in AI, although it is an argument against releasing the model
    weights.
  id: totrans-split-349
  prefs: []
  type: TYPE_NORMAL
- en: 'What is not as smart is having Meta AI reply to posts unprompted. We saw the
    example last week where it hallucinated past experiences, [now we have this](https://twitter.com/edzitron/status/1781825480179741056):'
  id: totrans-split-350
  prefs: []
  type: TYPE_NORMAL
- en: This reads like one of those ‘who could have possibly thought anyone would want
    any version of this?’ experiences.
  id: totrans-split-351
  prefs: []
  type: TYPE_NORMAL
- en: '[Ate-a-Pi pointed out an important implication from the interview](https://twitter.com/8teAPi/status/1781480713394737238).
    Zuckerberg said Meta does not open source their products themselves.'
  id: totrans-split-352
  prefs: []
  type: TYPE_NORMAL
- en: This means that they do not intend for Llama-3 to be the product, even the 400B
    version. They will not be offering a direct competitor in the AI space. And indeed,
    they do not think future Llama-Xs will ‘be the product’ either.
  id: totrans-split-353
  prefs: []
  type: TYPE_NORMAL
- en: Will they integrate Llama-3 400B into their products? They might like to, but
    it is not so compatible with their business model to pay such inference costs
    and wait times. Remember that for Meta, you the customer are the product. You
    pay with your time and your attention and your content and very soul, but not
    directly with your money. Meanwhile the lifetime value of a new Facebook customer,
    we learned recently, is on the order of $300\.
  id: totrans-split-354
  prefs: []
  type: TYPE_NORMAL
- en: So what is Llama-3 400B, the most expensive model to train, even for from a
    product perspective? It does help train Llama-4\. It helps try and hurt competitors
    like Google. It helps with recruitment, both to Meta itself and into their intended
    ecosystem. So there are reasons.
  id: totrans-split-355
  prefs: []
  type: TYPE_NORMAL
- en: Open models get better. I expect that the people saying ‘it’s so over’ for other
    models will find their claims overblown as usual. Llama-3 8B or 70B will for now
    probably become the default baseline model, the thing you use if you don’t want
    to think too hard about what to use, and also the thing you start with when you
    do fine tuning.
  id: totrans-split-356
  prefs: []
  type: TYPE_NORMAL
- en: Things get more interesting over time, once people have had a chance to make
    variations that use Llama-3 as the baseline. In the space of Llama-2-based models,
    Llama-2 itself is rather lousy. Llama-3 should hold up better, but I still expect
    substantial improvements at least to specific use cases, and probably in general.
  id: totrans-split-357
  prefs: []
  type: TYPE_NORMAL
- en: Also, of course, we will soon have versions that are fine-tuned to be useful,and
    also fine-tuned to remove all the safety precautions.
  id: totrans-split-358
  prefs: []
  type: TYPE_NORMAL
- en: And we will see what happens due to that.
  id: totrans-split-359
  prefs: []
  type: TYPE_NORMAL
- en: In the grand scheme, in terms of catastrophic risk or existential risk or anything
    like that, or autonomous agents that should worry us, my strong assumption is
    that nothing scary will happen. It will be fine.
  id: totrans-split-360
  prefs: []
  type: TYPE_NORMAL
- en: In terms of mundane misuse, I also expect it to be fine, but with more potential
    on the margin, especially with fine-tunes.
  id: totrans-split-361
  prefs: []
  type: TYPE_NORMAL
- en: Certainly some people will switch over from using Claude Sonnet or Haiku or
    another open model to now using Llama-3\. There are advantages. But that will
    look incremental, I expect, not revolutionary. That is also true in terms of the
    pressure this exerts on other model providers.
  id: totrans-split-362
  prefs: []
  type: TYPE_NORMAL
- en: The real action will be with the 400B model.
  id: totrans-split-363
  prefs: []
  type: TYPE_NORMAL
- en: What happens if Meta goes full Leroy Jenkins and releases the weights to 400B?
  id: totrans-split-364
  prefs: []
  type: TYPE_NORMAL
- en: Meta gets a reputational win in many circles, and grows its recruitment and
    ecosystem funnels, as long as they are the first 4-level open model. Sure.
  id: totrans-split-365
  prefs: []
  type: TYPE_NORMAL
- en: Who else wins and loses?
  id: totrans-split-366
  prefs: []
  type: TYPE_NORMAL
- en: For everyone else (and the size of Meta’s reputational win), a key question
    is, what is state of the art at the time?
  id: totrans-split-367
  prefs: []
  type: TYPE_NORMAL
- en: In the discussions below, I assume that 5-level models are not yet available,
    at most OpenAI (and perhaps Google or Anthropic) has a 4.5-level model available
    at a premium price. All of this is less impactful the more others have advanced
    already.
  id: totrans-split-368
  prefs: []
  type: TYPE_NORMAL
- en: And I want to be clear, I do not mean to catastrophize. These are directional
    assessments, knowing magnitude is very hard.
  id: totrans-split-369
  prefs: []
  type: TYPE_NORMAL
- en: The obvious big winner is China and Chinese companies, along with every non-state
    actor, and every rival and enemy of the United States of America. Suddenly they
    can serve and utilize and work from what might be a competitive top-level model,
    and no they are not going to be paying Meta a cut no matter the license terms.
  id: totrans-split-370
  prefs: []
  type: TYPE_NORMAL
- en: Using Llama-3 400B to help train new 4.5-level models is going to be a key potential
    use case to watch.
  id: totrans-split-371
  prefs: []
  type: TYPE_NORMAL
- en: They also benefit when this hurts other big American companies. Not only are
    their products being undercut by a free offering, which is the ultimate predatory
    pricing attack in a zero marginal cost world, those without their own models also
    have another big problem. The Llama-3 license says that big companies have to
    pay to use it, whereas everyone else can use it for free.
  id: totrans-split-372
  prefs: []
  type: TYPE_NORMAL
- en: Another way they benefit? This means that American companies across industries,
    upon whom Meta can enforce such payments, could now be at a potentially large
    competitive disadvantage against their foreign rivals who ignore that rule and
    dare Meta to attempt enforcement.
  id: totrans-split-373
  prefs: []
  type: TYPE_NORMAL
- en: This could also be a problem if foreign companies can ignore the ‘you cannot
    use this to train other models’ clause [in 1(b)(v) of the license agreement](https://llama.meta.com/llama3/license/),
    whereas American companies end up bound by that clause.
  id: totrans-split-374
  prefs: []
  type: TYPE_NORMAL
- en: I am curious what if anything the United States Government, and the national
    security apparatus, are going to do about all that. Or what they would want to
    do about it next time around, when the stakes are higher.
  id: totrans-split-375
  prefs: []
  type: TYPE_NORMAL
- en: The other obvious big winners are those who get to use Llama-3 400B in their
    products, especially those for whom it is free, and presumably get to save a bundle
    doing that. Note that even if Meta is not charging, you still have to value high
    quality output enough to pay the inference costs. For many purposes, that is not
    worthwhile.
  id: totrans-split-376
  prefs: []
  type: TYPE_NORMAL
- en: Science wins to some degree, depending on how much this improves their abilities
    and lowers their costs. It also is a big natural experiment, albeit without controls,
    that will teach us quite a lot. Let’s hope we pay attention.
  id: totrans-split-377
  prefs: []
  type: TYPE_NORMAL
- en: Also winners are users who simply want to have full control over a 4-level model
    for personal reasons. Nothing wrong with that. Lowering the cost of inference
    and lowering the limits imposed on it could be very good for some of those business
    models.
  id: totrans-split-378
  prefs: []
  type: TYPE_NORMAL
- en: The big obvious Corporate losers are OpenAI, Google, Microsoft and Anthropic,
    along with everyone else trying to serve models and sell inference. Their products
    now have to compete with something very strong, that will be freely available
    at the cost of inference. I expect OpenAI to probably have a superior product
    by that time, and the others may as well, but yes free (or at inference cost)
    is a powerful selling point, as is full customization on your own servers.
  id: totrans-split-379
  prefs: []
  type: TYPE_NORMAL
- en: The secondary labs could have an even bigger problem on their hands. This could
    steamroller a lot of offerings.
  id: totrans-split-380
  prefs: []
  type: TYPE_NORMAL
- en: All of which is (a large part of) the point. Meta wants to sabotage its rivals
    into a race to the bottom, in addition to the race to AGI.
  id: totrans-split-381
  prefs: []
  type: TYPE_NORMAL
- en: Another potential loser is anyone or anything counting on the good guy with
    an AI having a better AI than the bad guy with an AI. Anywhere that AI could flood
    the zone with bogus or hostile content, you are counting on your AI to filter
    out what their AI creates. In practice, you need evaluation to be easier than
    generation under adversarial conditions where the generator chooses point and
    method of attack. I worry that in many places this is not by default true once
    the AIs on both sides are similarly capable.
  id: totrans-split-382
  prefs: []
  type: TYPE_NORMAL
- en: I think this echoes a more general contradiction in the world, that is primarily
    not about AI. We want everyone to be equal, and the playing field to be level.
    Yet that playing field depends upon the superiority and superior resources and
    capabilities in various ways of the United States and its allies, and of certain
    key corporate players.
  id: totrans-split-383
  prefs: []
  type: TYPE_NORMAL
- en: We demand equality and democracy or moves towards them within some contained
    sphere and say this is a universal principle, but few fully want those things
    globally. We understand that things would not go well for our preferences if we
    distributed resources fully equally, or matters were put to a global vote. We
    realize we do not want to unilaterally disarm and single-handedly give away our
    advantages to our rivals. We also realize that some restrictions and concentrated
    power must ensure our freedom.
  id: totrans-split-384
  prefs: []
  type: TYPE_NORMAL
- en: In the case of AI, the same contradictions are there. Here they are even more
    intertwined. We have far less ability to take one policy nationally or locally,
    and a different policy globally. We more starkly must choose either to allow everyone
    to do what they want, or not to allow this. We can either control a given thing,
    or not control it. You cannot escape the implications of either.
  id: totrans-split-385
  prefs: []
  type: TYPE_NORMAL
- en: 'In any case: The vulnerable entities here could include ‘the internet’ and
    internet search in their broadest senses, and it definitely includes things like
    Email and social media. Meta itself is going to have some of the biggest potential
    problems over at Facebook and Instagram and its messenger services. Similar logic
    could apply to various cyberattacks and social engineering schemes, and so on.'
  id: totrans-split-386
  prefs: []
  type: TYPE_NORMAL
- en: I am generally confident in our ability to handle ‘misinformation,’ ‘deepfakes’
    and similar things, but we are raising the difficulty level and running an experiment.
    Yes, this is all coming anyway, in time. The worry is that this levels a playing
    field that is not currently level.
  id: totrans-split-387
  prefs: []
  type: TYPE_NORMAL
- en: I actually think triggering these potential general vulnerabilities now is a
    positive impact. This is the kind of experiment where you need to find out sooner
    rather than later. If it turns out the bad scenarios here come to pass, we have
    time to adjust and not do this again. If it turns out the good scenarios come
    to pass, then we learn from that as well. The details will be enlightening no
    matter what.
  id: totrans-split-388
  prefs: []
  type: TYPE_NORMAL
- en: It is interesting to see where the mind goes now that the prospect is more concrete,
    and one is thinking about short term, practical impacts.
  id: totrans-split-389
  prefs: []
  type: TYPE_NORMAL
- en: Other big Western corporations that would have to pay Meta could also be losers.
  id: totrans-split-390
  prefs: []
  type: TYPE_NORMAL
- en: The other big loser, as mentioned above, is the United States of America.
  id: totrans-split-391
  prefs: []
  type: TYPE_NORMAL
- en: And of course, if this release is bad for safety, either now or down the line,
    we all lose.
  id: totrans-split-392
  prefs: []
  type: TYPE_NORMAL
- en: Again, these are all directional effects. I cannot rule out large impacts in
    scenarios where Llama-3 400B releases as close to state of the art, but everyone
    mostly shrugging on most of these also would not be shocking. Writing this down
    it occurs to me that people simply have not thought about this scenario much in
    public, despite it having been reasonably likely for a while.
  id: totrans-split-393
  prefs: []
  type: TYPE_NORMAL
- en: The right question is usually not ‘is it safe?’ but rather ‘how (safe or unsafe)
    is it?’ Releasing a 4-level model’s weights is never going to be fully ‘safe’
    but then neither is driving. When we say ‘safe’ we mean ‘safe enough.’
  id: totrans-split-394
  prefs: []
  type: TYPE_NORMAL
- en: We do not want to be safetyists who demand perfect safety. Not even perfect
    existential safety. Everything is price.
  id: totrans-split-395
  prefs: []
  type: TYPE_NORMAL
- en: The marginal existential safety price on Llama-3 70B and Llama-3 8B is very
    small, essentially epsilon. Standing on its own, the decision to release the weights
    of these models is highly reasonable. It is a normal business decision. I care
    only because of the implications for future decisions.
  id: totrans-split-396
  prefs: []
  type: TYPE_NORMAL
- en: What is the safety price for the releasing the model weights of Llama-3 400B,
    or another 4-level model?
  id: totrans-split-397
  prefs: []
  type: TYPE_NORMAL
- en: I think in most worlds the direct safety cost here is also very low, especially
    the direct existential safety cost. Even with extensive scaffolding, there are
    limits to what a 4-level model can do. I’d expect some nastiness on the edges
    but only on the edges, in limited form.
  id: totrans-split-398
  prefs: []
  type: TYPE_NORMAL
- en: How many 9s of direct safety here, compared to a world in which a 4-level model
    was never released with open weights? I would say two 9s (>99%), but not three
    9s (<99.9%). However the marginal safety cost versus the counterfactual other
    open model releases is even smaller than that, and there I would say we have that
    third 9 (so >99.9%).
  id: totrans-split-399
  prefs: []
  type: TYPE_NORMAL
- en: 'I say direct safety because the primary potential safety dangers here seem
    indirect. They are:'
  id: totrans-split-400
  prefs: []
  type: TYPE_NORMAL
- en: Setting a precedent and pattern for future similar releases, at Meta and elsewhere.
  id: totrans-split-401
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Assisting in training of next-generation models.
  id: totrans-split-402
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Everyone generally being pushed to go faster, faster.
  id: totrans-split-403
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: And again, these only matter on the margin to the extent they move the margin.
  id: totrans-split-404
  prefs: []
  type: TYPE_NORMAL
- en: At the time of Llama-2, I said what I was concerned about opening up was Llama-4.
  id: totrans-split-405
  prefs: []
  type: TYPE_NORMAL
- en: That is still the case now. Llama-3 will be fine.
  id: totrans-split-406
  prefs: []
  type: TYPE_NORMAL
- en: Will releasing Llama-4 be fine? Probably. But I notice my lack of confidence.
  id: totrans-split-407
  prefs: []
  type: TYPE_NORMAL
- en: '(Usual caveat: Nothing here is investing advice.)'
  id: totrans-split-408
  prefs: []
  type: TYPE_NORMAL
- en: Market is not impressed. Nasdaq was down 6.2% in this same period.
  id: totrans-split-409
  prefs: []
  type: TYPE_NORMAL
- en: You can come up with various explanations. The obvious cause is that [WhatsApp
    and Threads were forcibly removed from the Apple Store in China](https://nypost.com/2024/04/19/business/apple-removes-whatsapp-threads-from-app-store-in-china-after-demand-by-beijing-over-security-concerns/),
    [along with Signal and Telegram](https://www.bloomberg.com/news/articles/2024-04-19/china-orders-apple-to-scrub-whatsapp-from-mobile-store-wsj-says).
    I am confused why this would be worth a 3% underperformance.
  id: totrans-split-410
  prefs: []
  type: TYPE_NORMAL
- en: (Then about a day later it looked like we were finally going to actually force
    divestiture of TikTok while using that to help pass a foreign aid bill, so this
    seems like a massive own goal by China to remind us of how they operate and the
    law of equivalent exchange.)
  id: totrans-split-411
  prefs: []
  type: TYPE_NORMAL
- en: The stock most down was Nvidia, which fell 10%, on no direct news. [Foolish,
    foolish.](https://slay-the-spire.fandom.com/wiki/Time_Eater)
  id: totrans-split-412
  prefs: []
  type: TYPE_NORMAL
- en: At most, markets thought Llama-3’s reveal was worth a brief ~1% bump.
  id: totrans-split-413
  prefs: []
  type: TYPE_NORMAL
- en: You can say on Meta that ‘it was all priced in.’ I do not believe you. I think
    the market is asleep at the wheel.
  id: totrans-split-414
  prefs: []
  type: TYPE_NORMAL
- en: Some are of course calling these recent moves ‘the market entering a correction
    phase’ [or that ‘the bubble is bursting.’](https://twitter.com/Simeon_Cps/status/1781706864540917930)
    Good luck with that.
  id: totrans-split-415
  prefs: []
  type: TYPE_NORMAL
- en: '[Here is a WSJ article](https://www.wsj.com/tech/metas-ai-push-needs-to-efficiently-deliver-a-lot-more-ad-growth-5fa298a8)
    about how Meta had better ensure its AI is used to juice advertising returns.
    Investors really are this myopic.'
  id: totrans-split-416
  prefs: []
  type: TYPE_NORMAL
- en: Any given company, of course, could still be vastly overvalued.
  id: totrans-split-417
  prefs: []
  type: TYPE_NORMAL
- en: '[Here was the only argument I saw to that effect with respect to Nvidia.](https://twitter.com/bryanrbeal/status/1781454698136109380)'
  id: totrans-split-418
  prefs: []
  type: TYPE_NORMAL
- en: 'Bryan Beal: The AI bubble is not bursting.'
  id: totrans-split-419
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: More investors are just realizing that Nvidia doesn’t make chips. They design
    them and TSMC makes them. And Nvidia’s biggest customers (Meta, Amazon, OpenAI,
    Microsoft, Google, etc) have ALL announced they are designing their own AI chips
    for both training and inference. And Google just went public they are already
    training on their own silicon and didn’t need Nvidia.
  id: totrans-split-420
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This is a very real threat.
  id: totrans-split-421
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I can totally buy that a lot of investors have no idea what Nvidia actually
    produces, and got freaked out by suddenly learning what Nvidia actually does.
    I thought it was very public long ago that Google trains on TPUs that they design?
    I thought it was common knowledge that everyone involved was going to try to produce
    their own chips for at least internal use, whether or not that will work? And
    that Nvidia will still have plenty of customers even if all the above switched
    to TPUs or their own versions?
  id: totrans-split-422
  prefs: []
  type: TYPE_NORMAL
- en: That does not mean that Nvidia’s moat is impregnable. Of course they could lose
    their position not so long from now. That is (a lot of) why one has a diversified
    portfolio.
  id: totrans-split-423
  prefs: []
  type: TYPE_NORMAL
- en: Again. The Efficient Market Hypothesis in False.
  id: totrans-split-424
  prefs: []
  type: TYPE_NORMAL
- en: 'I expect not this, GPT-5 will be ready when it is ready, but there will be
    pressure:'
  id: totrans-split-425
  prefs: []
  type: TYPE_NORMAL
- en: '[Jim Fan:](https://twitter.com/DrJimFan/status/1781386105734185309) Prediction:
    GPT-5 will be announced before Llama-3-400B releases. External movement defines
    OpenAI’s PR schedule 🤣'
  id: totrans-split-426
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I do not doubt that OpenAI and others will do everything they can to stay ahead
    of Meta’s releases, with an unknown amount of ‘damn the safety checks of various
    sorts.’
  id: totrans-split-427
  prefs: []
  type: TYPE_NORMAL
- en: That does not mean that one can conjure superior models out of thin air. Or
    that it is helpful to rush things into use before they are ready.
  id: totrans-split-428
  prefs: []
  type: TYPE_NORMAL
- en: Still, yes, everyone will go faster on the frontier model front. That includes
    that everyone in the world will be able to use Llama-3 400B for bootstrapping,
    not only fine-tuning.
  id: totrans-split-429
  prefs: []
  type: TYPE_NORMAL
- en: On the AI mundane utility front, people will get somewhat more somewhat cheaper,
    a continuation of existing trends, with the first two models. Later we will have
    the ability to get a 4-level model internally for various purposes. So we will
    get more and cheaper cool stuff.
  id: totrans-split-430
  prefs: []
  type: TYPE_NORMAL
- en: Meta will deploy its tools across its social media empire. Mostly I expect this
    to be a positive experience, and to also get a lot more people to notice AI. Expect
    a bunch of scare stories and highlights of awful things, some real and some baseless.
  id: totrans-split-431
  prefs: []
  type: TYPE_NORMAL
- en: On the practical downside front, little will change until the 400B model gets
    released. Then we will find out what people can do with that, as they attempt
    to flood the zone in various ways, and try for all the obvious forms of misuse.
    It will be fun to watch.
  id: totrans-split-432
  prefs: []
  type: TYPE_NORMAL
- en: All this could be happening right as the election hits, and people are at their
    most hostile and paranoid, seeing phantoms everywhere.
  id: totrans-split-433
  prefs: []
  type: TYPE_NORMAL
- en: Careful, Icarus.
  id: totrans-split-434
  prefs: []
  type: TYPE_NORMAL
