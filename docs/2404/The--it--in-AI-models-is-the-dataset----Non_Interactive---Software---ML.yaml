- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 13:32:17'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: The “it” in AI models is the dataset. – Non_Interactive – Software & ML
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/](https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: I’ve been at OpenAI for almost a year now. In that time, I’ve trained a **lot**
    of generative models. More than anyone really has any right to train. As I’ve
    spent these hours observing the effects of tweaking various model configurations
    and hyperparameters, one thing that has struck me is the similarities in between
    all the training runs.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: It’s becoming awfully clear to me that these models are truly approximating
    their datasets to an incredible degree. What that means is not only that they
    learn what it means to be a dog or a cat, but the interstitial frequencies between
    distributions that don’t matter, like what photos humans are likely to take or
    words humans commonly write down.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: What this manifests as is – trained on the same dataset for long enough, pretty
    much every model with enough weights and training time converges to the same point.
    Sufficiently large diffusion conv-unets produce the same images as ViT generators.
    AR sampling produces the same images as diffusion.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: This is a surprising observation! It implies that model behavior is not determined
    by architecture, hyperparameters, or optimizer choices. It’s determined by your
    dataset, nothing else. Everything else is a means to an end in efficiently delivery
    compute to approximating that dataset.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
- en: Then, when you refer to “Lambda”, “ChatGPT”, “Bard”, or “Claude” then, it’s
    not the model weights that you are referring to. It’s the dataset.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
