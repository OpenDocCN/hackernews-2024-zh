- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 13:32:17'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 13:32:17'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: The “it” in AI models is the dataset. – Non_Interactive – Software & ML
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI 模型中的“它”指的是数据集。– 非交互 – 软件与机器学习
- en: 来源：[https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/](https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/](https://nonint.com/2023/06/10/the-it-in-ai-models-is-the-dataset/)
- en: I’ve been at OpenAI for almost a year now. In that time, I’ve trained a **lot**
    of generative models. More than anyone really has any right to train. As I’ve
    spent these hours observing the effects of tweaking various model configurations
    and hyperparameters, one thing that has struck me is the similarities in between
    all the training runs.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我在OpenAI已经快一年了。在这段时间里，我训练了**大量**的生成模型。比任何人都有权力训练的更多。当我观察调整各种模型配置和超参数的影响时，有一件事让我印象深刻，那就是所有训练运行之间的相似性。
- en: It’s becoming awfully clear to me that these models are truly approximating
    their datasets to an incredible degree. What that means is not only that they
    learn what it means to be a dog or a cat, but the interstitial frequencies between
    distributions that don’t matter, like what photos humans are likely to take or
    words humans commonly write down.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 我越来越清楚地意识到这些模型确实以令人难以置信的程度逼近它们的数据集。这意味着它们不仅学会了什么是狗或猫，还包括那些不重要的分布之间的间隔频率，比如人类可能拍摄的照片或人类常用的写字。
- en: What this manifests as is – trained on the same dataset for long enough, pretty
    much every model with enough weights and training time converges to the same point.
    Sufficiently large diffusion conv-unets produce the same images as ViT generators.
    AR sampling produces the same images as diffusion.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这体现为——在同一数据集上长时间训练，几乎每个足够权重和训练时间的模型最终都会收敛到同一点。足够大的扩散卷积-UNET生成的图像与ViT生成器产生的图像相同。AR
    抽样生成的图像与扩散图像相同。
- en: This is a surprising observation! It implies that model behavior is not determined
    by architecture, hyperparameters, or optimizer choices. It’s determined by your
    dataset, nothing else. Everything else is a means to an end in efficiently delivery
    compute to approximating that dataset.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个令人惊讶的观察！它暗示着模型的行为不是由架构、超参数或优化器选择决定的。它完全由您的数据集决定，没有别的。其他一切都是高效交付计算以逼近该数据集的手段。
- en: Then, when you refer to “Lambda”, “ChatGPT”, “Bard”, or “Claude” then, it’s
    not the model weights that you are referring to. It’s the dataset.
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 当提到“Lambda”、“ChatGPT”、“Bard”或“Claude”时，您指的不是模型权重。而是数据集。
