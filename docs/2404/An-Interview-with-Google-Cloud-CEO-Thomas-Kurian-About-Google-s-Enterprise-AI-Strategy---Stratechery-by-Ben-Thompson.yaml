- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-05-27 13:06:31'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 13:06:31'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: An Interview with Google Cloud CEO Thomas Kurian About Google’s Enterprise AI
    Strategy – Stratechery by Ben Thompson
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 谷歌云CEO Thomas Kurian关于谷歌企业AI战略的采访 – 由本·汤普森（Ben Thompson）撰写的Stratechery
- en: 来源：[https://stratechery.com/2024/an-interview-with-google-cloud-ceo-thomas-kurian-about-googles-enterprise-ai-strategy/](https://stratechery.com/2024/an-interview-with-google-cloud-ceo-thomas-kurian-about-googles-enterprise-ai-strategy/)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://stratechery.com/2024/an-interview-with-google-cloud-ceo-thomas-kurian-about-googles-enterprise-ai-strategy/](https://stratechery.com/2024/an-interview-with-google-cloud-ceo-thomas-kurian-about-googles-enterprise-ai-strategy/)
- en: Good morning,
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 早上好，
- en: This week’s Stratechery Interview is with Google Cloud CEO [Thomas Kurian](https://twitter.com/ThomasOrTK).
    Kurian joined Google to lead the company’s cloud division in 2018; prior to that
    he was President of Product Development at Oracle, where he worked for 22 years.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本周的Stratechery采访对象是谷歌云CEO[Thomas Kurian](https://twitter.com/ThomasOrTK)。Kurian于2018年加入谷歌，负责领导公司的云部门；在此之前，他在甲骨文担任产品开发总裁长达22年。
- en: In this interview (which was conducted last night after I had already published
    [Gemini 1.5 and Google’s Nature](https://stratechery.com/2024/gemini-1-5-and-googles-nature/)),
    we discuss [Kurian’s keynote](https://www.youtube.com/watch?v=V6DJYGn2SFk) at
    this week’s Google Cloud Next conference, which was almost completely focused
    on AI. To that end, we cover Google Cloud’s strategy, why AI offers a reset in
    competition, and how the company can win in the enterprise space broadly. As yesterday’s
    Article — and this Interview — make clear, I do think that Google is very well
    placed in this area; one certainly gets the impression that Kurian thinks so as
    well.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次采访中（在我已经发布[Gemini 1.5 and Google’s Nature](https://stratechery.com/2024/gemini-1-5-and-googles-nature/)之后的昨晚进行），我们讨论了[Kurian在本周谷歌云Next大会上的主题演讲](https://www.youtube.com/watch?v=V6DJYGn2SFk)，该演讲几乎完全专注于人工智能。因此，我们涵盖了谷歌云的战略，为什么AI提供了竞争的重置，以及公司如何在广泛的企业空间取得胜利。正如昨天的文章和这次采访所明确的那样，我确实认为谷歌在这一领域处于非常有利的位置；显然Kurian也是这么认为的。
- en: As a reminder, all Stratechery content, including interviews, is available as
    a podcast; click the link at the top of this email to add Stratechery to your
    podcast player.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 作为提醒，所有Stratechery内容，包括采访，都可以作为播客获得；点击邮件顶部的链接将Stratechery添加到您的播客播放器中。
- en: 'On to the Interview:'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 进入采访内容：
- en: An Interview with Google Cloud CEO Thomas Kurian About Google’s Enterprise AI
    Strategy
  id: totrans-split-11
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 谷歌云CEO Thomas Kurian关于谷歌企业AI战略的采访
- en: '*This interview is lightly edited for clarity.*'
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: '*此次采访略作编辑以提高清晰度。*'
- en: Google’s Cloud Strategy
  id: totrans-split-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 谷歌的云战略
- en: '**Thomas Kurian, [welcome back to Stratechery](https://stratechery.com/2021/interviews-with-patrick-collison-brad-smith-thomas-kurian-and-matthew-prince-on-moderation-in-infrastructure/#kurian).**'
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**Thomas Kurian，[欢迎回到Stratechery](https://stratechery.com/2021/interviews-with-patrick-collison-brad-smith-thomas-kurian-and-matthew-prince-on-moderation-in-infrastructure/#kurian)。**'
- en: '**Thomas Kurian:** Thank you for having me.'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**Thomas Kurian：** 感谢邀请我。'
- en: '**So I’m going to give you the floor to start. If someone comes to you and
    says, “Hey, Thomas. What was [Google Cloud Next](https://cloud.withgoogle.com/next)
    about [this year](https://stratechery.com/2024/gemini-1-5-and-googles-nature/)?
    You did it a few months early, what is the takeaway you wanted folks to have from
    the keynote?”**'
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**因此，我将让您开场发言。如果有人对您说：“嗨，Thomas。今年稍早些时候的[Google Cloud Next](https://cloud.withgoogle.com/next)大会是关于[什么](https://stratechery.com/2024/gemini-1-5-and-googles-nature/)？您在几个月前就已经进行了，您希望从主题演讲中传达给大家什么主要信息？**"'
- en: '**TK:** The focus of our product strategy is what we’re explaining to clients
    at the keynote, and the product strategy is fairly simple. We are seeing significant
    acceleration in how customers want to use digital tools and AI to transform their
    core business. To enable that, we offer two important things. First, as people
    have moved AI out of proof-of-concepts into production deployments across many
    different parts of their enterprise, they want not to choose a model, but they
    want a platform, and the platform needs certain characteristics. The platform
    needs to provide a set of services to tune models, to connect them with their
    enterprise systems, to be able to delegate tasks to the model, to measure the
    quality of the model, to test it, to deploy it, monitor it. Our platform provides
    that.'
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 我们产品策略的重点是我们在主题演讲中向客户解释的内容，而产品策略非常简单。我们看到客户如何加速使用数字工具和AI来转变其核心业务。为了实现这一点，我们提供了两个重要的事项。首先，随着人们将AI从概念验证转移到其企业多个部分的生产部署中，他们希望的不仅是选择一个模型，而是一个平台，而这个平台需要具备某些特性。平台需要提供一系列服务来调整模型，将其与企业系统连接，能够委托任务给模型，衡量模型的质量，测试、部署和监控它。我们的平台提供了这些功能。'
- en: In addition, we have an open architecture, which gives them the ability to use
    these services, but across a range of different models. Some from Google, obviously
    Gemini, but also from partners.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们拥有一个开放的架构，使他们能够使用这些服务，但跨不同模型范围。有些来自Google，显然是Gemini，但也来自合作伙伴。
- en: We announced in addition that Gemini has made some major advances. We introduced
    the million context window, we showed a number of places where it’s being used
    by customers, we’ve done a significant update to [Imagen](https://imagen.research.google/),
    which is our image model, and we’ve integrated it across our portfolio. When I
    say across our portfolio to assist people in doing things in Workspace, for example,
    writing, email, creating documents, but just as much as assisting in their existing
    workflow, we also showed through the introduction of [Google Vids](https://www.youtube.com/watch?v=4SCjXcBeW1E),
    a brand new experience that you can create using generative AI, which is storytelling.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们宣布Gemini取得了一些重大进展。我们推出了百万上下文窗口，展示了客户正在使用它的多个场景，我们对我们的图像模型[Imagen](https://imagen.research.google/)进行了重大更新，并将其整合到我们的整个产品组合中。当我说整个产品组合时，例如在Workspace中帮助人们进行写作、电子邮件、创建文档，但同样重要的是，在他们现有的工作流程中提供帮助，我们还通过引入[Google
    Vids](https://www.youtube.com/watch?v=4SCjXcBeW1E)，展示了使用生成AI进行故事叙述的全新体验。
- en: Similarly, we brought it across our platform in Google Cloud. We started with
    coding, but we added operations for people who want to operate a cloud. We added
    the capability for analysis of data and in each step as well as cyber. And in
    each step, it is meant to open up how people can talk to their data, open up how
    quickly teams can do cybersecurity analysis by having a real expert work alongside
    them.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 同样地，我们将其引入了我们在Google Cloud平台上的应用。我们从编码开始，但我们为那些希望操作云的人们增加了操作。我们增加了数据分析的能力，并在每一步以及网络安全方面都有所加强。在每一步中，这意味着人们可以更好地与其数据交流，也意味着团队可以通过与真正的专家一起工作来加快网络安全分析的速度。
- en: So one big piece was you need as an enterprise to choose a platform if you’re
    going to use AI at scale, and that platform needs to be open, but it also needs
    to be vertically optimized because if you’re going to use it across your environments
    and across your systems and processes, you need it to be cost efficient and scale
    and we know how to do that at Google.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，作为企业，如果您打算大规模使用AI，您需要选择一个平台，而这个平台既需要是开放的，也需要是垂直优化的，因为如果您要在各种环境和系统以及流程中使用它，您需要它既具备成本效益，又具备扩展性，而我们在Google知道如何做到这一点。
- en: So we introduced a number of new types of advances in our AI and other systems.
    We introduced a [new Axion processor](https://cloud.google.com/blog/products/compute/introducing-googles-new-arm-based-cpu),
    we introduced a number of new advances with Intel in traditional classical computing,
    but we also introduced a variety of new things in our AI systems. TPU v5, some
    new Nvidia systems, and then most importantly, most people think it’s just about
    the chip, it’s not about the chip, it’s the system you build with the chip, and
    there are many things that we do that are super advantageous. One example being
    the new [Parallelstore](https://cloud.google.com/parallelstore) that we introduced
    to provide a 10x improvement in the way that data loads off disk into a model
    when it’s being trained, which is super important if you’re going to large-scale
    training or inferencing.
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们在我们的AI和其他系统中引入了许多新的进展。我们推出了一款[新的Axion处理器](https://cloud.google.com/blog/products/compute/introducing-googles-new-arm-based-cpu)，我们在传统的经典计算中与Intel引入了许多新的进展，但我们还在我们的AI系统中引入了各种新技术。TPU
    v5，一些新的Nvidia系统，而且最重要的是，大多数人认为这只是关于芯片，事实并非如此，重要的是你用这些芯片建立的系统，我们有很多优势的事情。一个例子是我们引入的新的[Parallelstore](https://cloud.google.com/parallelstore)，它可以在模型在训练时从磁盘加载数据时提供10倍的提升，如果您要进行大规模的训练或推理，这非常重要。
- en: So these are some of the advances. We’ve also made the ability to now deploy
    these on extraordinarily large clusters at scale and because we provide an assortment
    of different kinds of accelerators, which are optimized for many different kinds
    of training and serving needs, we’re seeing a lot of pickup and it makes it much
    more efficient for people from a cost-performance-latency point-of-view.
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这些是一些进展。现在我们能够在规模极大的集群上部署这些技术，因为我们提供了各种优化用于多种不同训练和服务需求的加速器，所以我们看到了很多的采用，从成本、性能和延迟的角度来看，这使得整个过程更加高效。
- en: '**Well, that’s a good overview. I think you previewed a lot of the stuff that
    I want to get into, but you did mention that, “People are moving out of proof-of-concept
    into actually doing products”. Is that actually happening? What are the actual
    use cases that companies are actually rolling out broadly as opposed to doing
    experiments on what might be possible?**'
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**嗯，这是一个很好的概述。我觉得你预览了我想深入探讨的很多内容，但你提到了，“人们正在从概念验证转向实际产品”。这是真的吗？公司实际正在广泛推广哪些实际用例，而不是进行可能性实验？**'
- en: '**TK:** Broad-brush, Ben, we can break it into four major categories. One category
    is streamlining internal processes within the organization, streamlining internal
    processes. In finance, you want to automate accounts receivable, collections,
    and cashflow prediction. In human resources, you want to automate your human help
    desk as well as improve the efficiency with which you can do benefits matching,
    for example. In procurement and supply chain, you want for example, look at all
    my suppliers, their contracts with me and tell me which ones have indemnification
    and warranty protection, so I can drive more volume to those that give me indemnification
    and warranties and less to those that don’t. For example, these are all practical
    cases we have customers live in deployment with.'
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK：** 总的来说，本，我们可以将其分为四个主要类别。第一个类别是优化组织内部流程，简化内部流程。在财务领域，您希望自动化应收账款、收款和现金流预测。在人力资源方面，您希望自动化人力帮助台，并提高例如福利匹配的效率。在采购和供应链方面，例如，您希望查看所有我的供应商，他们与我的合同，并告诉我哪些供应商为我提供了赔偿和保修保护，这样我就可以将更多的业务量引导给那些提供了赔偿和保修的供应商，而减少与那些没有的供应商的业务量。例如，这些都是我们的客户正在实施的实际案例。'
- en: Second is transforming the customer experience. Transforming the customer experiences,
    how you market, how you merchandise, how you do commerce, how you do sales and
    service. An example is what Mercedes-Benz CEO [Ola Källenius](https://group.mercedes-benz.com/company/corporate-governance/board-of-management/kaellenius/)
    talked about how they’re building a completely new experience for the way that
    they market and sell and service their vehicles.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个是转变客户体验。转变客户体验，例如您如何市场推广，如何展示商品，如何进行商务以及如何进行销售和服务。一个例子是梅赛德斯-奔驰CEO [奥拉·凯伦尼乌斯](https://group.mercedes-benz.com/company/corporate-governance/board-of-management/kaellenius/)
    谈到了他们如何为他们的车辆市场、销售和服务构建全新的体验。
- en: Third is that some people are integrating it into their products, and when I
    say re-imagining their products, re-imagining their core products using AI. We
    had two examples of companies who are in the devices space. One is Samsung and
    the other one is Oppo, and they’re re-imagining the actual device itself using
    AI with all the multimodality that we provide.
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: 第三点是，一些人正在将智能技术整合到他们的产品中，当我说重新构想他们的产品时，我是指重新构想他们的核心产品使用人工智能。我们有两个公司的例子，它们处于设备领域。一个是三星，另一个是Oppo，他们正在利用我们提供的各种多模态功能，通过人工智能重新构想实际设备本身。
- en: There are quite a few companies now re-thinking that if a model can change the
    way that I see it, that I can process multimodal information. For example, in
    media we have people saying, “If your model can read as much information as it
    can, can it take a long movie and shrink it into highlights? Can I take a sports
    recording of the NCAA basketball final and say, ‘find me all the highlights by
    this particular player’?” and not have to have a human being sit there and splice
    the video, but have it do it and I can create the highlights reel really quickly.
    So there are lots of people re-imagining the product offerings that they have.
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在有很多公司正在重新思考，如果一个模型可以改变我看待事物的方式，那我是否可以处理多模态信息。例如，在媒体领域，有人说，“如果您的模型可以读取尽可能多的信息，那么它可以将长篇的电影缩短成精彩片段吗？我能拿一场NCAA篮球锦标赛的体育录像然后说，“给我找出这个特定球员的所有精彩片段”而不必让一个人坐在那里剪辑视频，而是让它来做，我可以非常快地创建精彩片段。因此，很多人都在重新构想他们的产品提供。
- en: And finally, there are some people saying, “With the cost efficiency of this,
    I can change how I enter a brand new market because, for example, I can do personalized
    offers in a market where I may not have a physical presence, but I can do much
    higher conversion rate for customers with online marketing and advertising because
    now I can do highly tailored campaigns because the cost of creating the content
    is much lower.” So broad-brush, streamline the core processes and back office,
    transform the customer experience and it doesn’t mean call centers or chatbots,
    it can be actually transferring the product itself, transforming the nature of
    the product you build and enter new markets.
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，有一些人说，“凭借这种成本效益，我可以改变我进入全新市场的方式，例如，我可以在没有实体存在的市场上进行个性化的推广，但我可以通过在线营销和广告为客户实现更高的转化率，因为现在我可以进行高度定制的营销活动，因为制作内容的成本要低得多。”因此，大幅度地简化核心流程和后台，转变客户体验，并不仅仅是呼叫中心或聊天机器人，它实际上可以转变产品本身，改变产品的性质，并进入新的市场。
- en: '**Is it fair to say then when you talk about, “Moving from proof-of-concept
    to actual production”, or maybe that’s not the words you used, but people are
    saying, “Okay, we’re going to build this” because this stuff’s not showing up
    yet, in the real world. Is it the case that, “We see that this could be valuable,
    now we’re in”, and that’s why you’re emphasizing the platform choice now because
    they’ve committed to AI broadly, and now it’s like, “Where are we going to build
    it”?**'
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**那么，当您谈到“从概念验证到实际生产”时，或许您并没有用这个词，但人们都在说，“好吧，我们要构建这个”因为这些东西还没有出现在现实世界中。所以，是否可以说，“我们看到这可能是有价值的，现在我们参与进来了”，这就是为什么您现在强调平台选择，因为他们已经全面投入了人工智能，现在就像，“我们要在哪里构建它”？'
- en: '**TK:** We have people experimenting, but we also have people actually live
    deployment and directing traffic. Orange, the telecom company, was talking about
    how many customers they’re handling online, Discover Financial was talking about
    how their agents are actually using a search and AI tools to discover information
    from policy and procedure documents live. So there are people actually literally
    running true traffic through these systems and actually using them to handle real
    customer workload.'
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 我们有人在尝试实验，但我们也有人确实在实时部署和引导交通。橙子电信公司谈到了他们在线处理多少客户，Discover Financial谈到了他们的代理正在使用搜索和人工智能工具从实时政策和流程文件中获取信息。因此，确实有人正在通过这些系统运行真实流量，并确实在处理真实客户工作负载。'
- en: '**Are you seeing the case in a lot of in customers, or maybe you’re hearing
    from potential customers, that AI is rolling out, if that’s the right word, in
    an employee arbitrage situation? Where there’s individual employees that are taking
    on themselves to use these tools and they are personally benefiting from the increased
    productivity — maybe they’re doing less work or maybe they’re getting more done
    — and the companies want to capture that more systematically. Is that a theme
    that you’re seeing?**'
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**您是否看到很多客户或者可能从潜在客户那里听到，AI 正在推出，如果这个词正确，那么在员工套利情况下正在进行？即个别员工正在自行使用这些工具，他们正在个人受益于增加的生产力
    — 也许他们做更少的工作或者他们做更多的工作 — 公司希望更系统地捕捉到这一点。这是您看到的一个主题吗？**'
- en: '**TK:** We’re seeing three flavors. Flavor one is a company has, we’re going
    to try eight or nine, what they call customer journeys or use cases, we’re going
    to pick the three that we see as the maximum return, meaning value and value does
    not mean cost savings always. It could be, for example, we have one who is handling
    1 million calls a day through our customer service system. Now a million calls
    a day, if you think about it, Ben, an average person can do about 250 calls a
    day, that’s a certain volume in an eight-hour day. If you handled a million, that
    is a lot of people, so the reality is that several of them were not being answered
    and people never called because the wait time was so long. So in that case, it
    was not about cost savings, it’s the fact that they’re getting able to reach many
    more customers than they could do before. So that’s one. One part is people saying,
    “I have a bunch of scenarios, I’m going to pick the three”, and in many cases,
    they’re actually augmenting something they’re doing or doing something they couldn’t
    do before, that’s scenario one.'
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 我们看到三种情况。第一种情况是公司有，我们将尝试八九种他们称为客户旅程或用例，我们将选择我们认为具有最大回报的三种，意味着价值和价值并不总是指成本节约。例如，我们有一个每天通过我们的客户服务系统处理
    100 万通电话的情况。现在每天处理 100 万通电话，如果你考虑一下，Ben，一个普通人一天大约可以处理 250 通电话，这是一个八小时的工作日内的一定量。如果你处理了一百万通，那就是很多人，所以事实是其中有几个没有得到答复，人们从未打电话是因为等待时间太长。所以在这种情况下，这不是关于成本节约，而是他们能够接触到比以前更多的客户。所以这是一个。一个部分是人们说，“我有一堆场景，我会挑选其中的三个”，在许多情况下，他们实际上正在增强他们正在做的事情或者做一些以前不能做的事情，这就是第一种情况。'
- en: Scenario two was I have, for example, there’s a large insurance company that’s
    working with us. Today, when they do claims and risk calculation, it takes a long
    time to handle the claims and the risk, particularly the risk calculation, because
    there’s thousands of pages of documents, there’s a lot of spreadsheets going back
    and forth. They put it into Gemini and it was able to run the calculations much,
    much more quickly. So second is I’m picking a very high value use case for my
    organization, which is the core function, and I’m going to implement it because
    I can get a real competitive advantage. In their case, it’s the fact that they
    can both get more accurate scoring on the risk and they can also do a much more
    accurate job, faster job in responding.
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
  zh: 第二种情况是，例如，有一家大型保险公司正在与我们合作。今天，当他们处理索赔和风险计算时，处理索赔和特别是风险计算需要很长时间，因为有成千上万页的文件，有很多来回传递的电子表格。他们将其放入
    Gemini 后，能够大大加快计算速度。所以第二点是，我正在选择一个对我的组织非常有价值的用例，这是核心功能，我将实施它，因为我可以获得真正的竞争优势。在他们的情况下，事实是他们不仅可以获得更精确的风险评分，而且在响应方面也可以更快速、更准确地工作。
- en: And the third scenario is what you said. “Hey, we’ve got a bunch of people,
    we’re going to give it to a certain number of developers”. For example, our coding
    tool, “They are going to test it, they say it helps me generate much better unit
    tests, it helps me write better quality code”. Wayfair’s CTO was talking about
    what their experience is, and then they say, “Let’s go broadly”, so all three
    patterns are being seen.
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 第三种情况是你说的那种。“嘿，我们有一群人，我们将把它交给一定数量的开发者”。例如，我们的编码工具，“他们将测试它，他们说它帮助我生成更好的单元测试，帮助我编写更高质量的代码”。Wayfair
    的首席技术官正在谈论他们的经验，然后他们说，“让我们广泛应用”，所以这三种模式都在被看到。
- en: An “Open” Platform
  id: totrans-split-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一个“开放”的平台
- en: '**This was a Google Cloud event broadly, and most of Google Cloud’s business
    today is some combination of Workspace and actual cloud computing. However, the
    entire presentation was about AI. I mean, maybe not the entire, you had a couple
    Google Meet updates and things like that, but by and large, I think that’s a fair
    characterization. What does that say about Google’s priorities? If I’m just a
    regular Google Cloud customer, I’m like, “Yeah, AI is good and cool, but what
    about my managed databases?”, or whatever it might be?**'
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**这是一个广义上的Google Cloud活动，今天Google Cloud的大部分业务都是Workspace和实际的云计算的结合。然而，整个演讲都是关于AI的。我是说，也许不是完全，你有几个Google
    Meet的更新之类的东西，但总体来说，我认为这是一个公正的描述。这对于Google的优先事项意味着什么？如果我只是一个普通的Google Cloud客户，我会说，“是的，AI很好，很酷，但我的托管数据库怎么样？”或者可能是其他什么？'
- en: '**TK:** Just to be frank, Ben, we have 30,000 people here, and they have hundreds
    of sessions, so a certain set of sessions are on AI, but there’s lots of sessions
    on other topics, I wouldn’t over-index on what you saw in the keynote.'
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK：** 坦率地说，Ben，我们这里有30,000名员工，而且有数百场次的会议，其中一些是关于AI的，但也有许多其他主题的会议，我认为你在主题演讲中看到的并不代表全部。'
- en: We do see though that customers, they’re looking increasingly at when they pick
    a cloud partner, they’re looking at it as not as a point in time, but they’re
    looking at it as, “Who’s going to help me transform my business?”, and the basis
    of how they thought about it in 2007, ’08, ’09, was all about, “How do they help
    me either go faster by building apps or reduce my cost of data centers by allowing
    me to lift and shift workloads?”. Now, they’re thinking about it in a different
    way. They’re looking at it as, “Can I use AI to transform my business? Who’s got
    the best platform and tools to help me do that?”.
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们看到，客户在选择云合作伙伴时，越来越关注的不是一个时间点，而是“谁将帮助我转型我的业务？”的问题。他们在2007年、08年、09年考虑这个问题的基础是，“如何通过构建应用程序加快速度，或者通过允许我迁移和转移工作负载来降低数据中心成本”。现在，他们以不同的方式来思考。他们把它看作是，“我能用AI来改变我的业务吗？谁有最好的平台和工具帮助我做到这一点？”。
- en: Once we get them to use the AI platform and tools, it does drag in many of our
    other services. You need good data to feed the model, and so many people use our
    analytics system, BigQuery, to clean up the data, to handle the segmentation of
    it, et cetera. Other people say, “I want to feed it from an operational databases”,
    like AlloyDB, or Spanner, or one of our operational databases. We get a lot of
    people saying, “I want to keep the output of the model safe, secure. I also want
    to see if people are analyzing, trying to figure out a way to attack my systems”,
    so we sell them our cyber tools. So AI is not just AI by itself, it typically
    is a collection of things that you need in order to do AI well.
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们让他们使用AI平台和工具，它确实会牵扯到我们许多其他的服务。你需要好的数据来喂养模型，所以很多人使用我们的分析系统BigQuery来清理数据，处理数据的分段等。其他人说，“我想从操作数据库，比如AlloyDB、Spanner或我们的其他操作数据库中获取数据”。我们也有很多人说，“我想保证模型的输出安全可靠。我还想看看是否有人在分析，试图攻击我的系统”，所以我们销售我们的网络安全工具。因此，AI不仅仅是AI本身，通常是你在进行AI时需要的各种东西的集合。
- en: '**Is there an interpretation of this sort of idea, AI almost as a tip-of-the-spear
    aspect, along with the messaging you really drilled down at the end? You mentioned
    it already on this talk about being “open”. Open can mean lots of things, but
    I interpreted it as, “You can access whatever you need from us at any level”.
    Does that open a sort of extent to, “Look, if you already have cloud computing
    elsewhere, if you have lots of data elsewhere, we’re going to make it super easy
    to plug into us because maybe you want our AI tools, and we hope you come over
    with everything else, but we’re going to work regardless”? Is that one of the
    ways to think about the open framing?**'
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**对于这种想法的解释，AI几乎作为矛头的一种方面，还有你在最后深入讨论的消息传递？你已经提到过关于“开放”的谈话，开放可以意味着很多事情，但我理解为，“你可以在任何级别访问我们所提供的任何内容”。这是否打开了一种可能性，即，“如果您已经在其他地方使用云计算，如果您在其他地方拥有大量数据，我们将使其非常容易与我们对接，因为也许您需要我们的AI工具，我们希望您带着其他一切过来，但无论如何我们都会合作”？这是否是开放框架的一种思考方式？**'
- en: '**TK:** Open is three elements. First, definitely that. So today, if you’re
    running your applications on another cloud, or if you’re using a SaaS application,
    like a Salesforce, a Workday, an SAP system, et cetera, and you’re wondering,
    “Can I use Google’s AI but connect it into my existing application?” — yes, you
    can, and you don’t need to actually move anything over to us in order to do that.
    So that’s one, and it allows us to use AI to serve every customer, not just existing
    GCP customers.'
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 开放包含三个元素。首先，当然是这样的。所以，如果今天您的应用程序运行在其他云上，或者如果您正在使用像Salesforce、Workday、SAP系统这样的SaaS应用程序，并且您在思考，“我能否使用谷歌的AI并将其连接到我的现有应用程序中？”
    — 答案是肯定的，而且您实际上不需要将任何东西转移到我们这里来实现这一点。这就是第一个元素，它使我们能够利用AI为每个客户提供服务，而不仅仅是现有的GCP客户。'
- en: The second thing, when we say open, it means people can choose models for the
    right purpose in their organization. So for example, we have people who say, “Look,
    I love Gemini, I’m going to use it in my customer-facing function and my back
    office function, but I am in this particular line of business, and I want to derive
    my own model for that purpose because I’m integrating it into my own product experience,
    and I really need to control the model weights”. In which case, they may either
    use our open source, or they can use Mistral or some other open source.
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个要点是，当我们说开放时，这意味着人们可以根据他们组织中的正确目的选择模型。例如，我们有些人说，“看，我喜欢Gemini，我将在我的客户面向功能和后台功能中使用它，但是我在这个特定的业务线上，我想为此目的开发自己的模型，因为我正在将其集成到我自己的产品体验中，并且我真的需要控制模型的权重”。在这种情况下，他们可以使用我们的开源，或者他们可以使用Mistral或其他一些开源工具。
- en: But in the past, they’ve always had to choose. If you chose a model, you had
    to choose a toolset, and that doesn’t make any sense because all the common things
    you need to do, do you need to tune it? Do you need to ground it? Do you need
    to integrate it into your existing data store to do retrieval, augmented generation?
    Those are all things that our platform provides, so that’s the second piece that
    we do.
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: 但在过去，他们总是不得不做出选择。如果您选择了一个模型，您就必须选择一个工具集，这是没有任何意义的，因为您需要做的所有常见事情，比如调整它、接地它、将它集成到您现有的数据存储中以进行检索、增强生成等，这些都是我们平台提供的功能，这就是我们所做的第二部分。
- en: The third piece is we also connect the dots for them into other services and
    GCP if they want to and so it allows us to attract new customers, it allows us
    to be open, to allow them the choice of using a variety of different models to
    serve their own needs organization-wide, while having a common way to manage,
    monitor, and improve the models, and, it also allows us to offer some other services
    along with it.
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个要点是，我们还可以帮助他们将这些点连接到其他服务和GCP，如果他们愿意的话，这样就能吸引新客户，让我们能够开放，让他们选择使用多种不同的模型来满足他们整个组织的需求，同时采用一种通用的方式来管理、监控和改进这些模型，并且，这也使我们能够提供一些其他的服务。
- en: '**I’m curious about overall, is this sort of a reboot of a growth strategy?
    In the context of Google Cloud results, last year in Q3, [growth slowed pretty
    significantly from 28 to 22%](https://stratechery.com/2023/google-earnings-microsoft-earnings-ai-leverage/),
    margins contracted, which reversed a very long trend. Even before we get to the
    AI connection to that or this platform, what happened last year? What was going
    on there?**'
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**我对整体情况很好奇，这种策略增长的重新启动是不是？在Google Cloud的结果背景下，去年Q3，[增长率从28%下降到22%](https://stratechery.com/2023/google-earnings-microsoft-earnings-ai-leverage/)，利润率收缩，这逆转了一个非常长的趋势。在我们讨论AI连接到此平台之前，去年发生了什么？那时候出了什么问题？**'
- en: '**TK:** Clearly, it was not a structural thing, because if you look at our
    Q4 and our results, it bumped up sharply, and we’re very confident about the future.
    We are the only cloud provider, if you go back to 2019 to now, and if you look
    at growing top-line and operating income, no one, not even the one who has the
    largest share, has grown top-line and operating income for as long as we have.'
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 显然，这不是一个结构性的问题，因为如果您看看我们的Q4和我们的结果，它们都显著增长，我们对未来非常有信心。在过去的几年中，如果您回顾2019年至今，我们是唯一一个云提供商，看看我们的收入和运营收入都在增长，没有任何一个，甚至那些市场份额最大的云提供商，能够像我们这样长时间地增长收入和运营收入。'
- en: It’s definitely not a reboot of the strategy. We started this thing called [multicloud](https://cloud.google.com/multicloud),
    which is, “Don’t be locked into a single cloud provider, allow people to use a
    choice of cloud provider, allow them to choose the best cloud provider for the
    task”. So analytics is an area where we did particularly well, we did really well
    in certain areas, like certain kinds of legacy systems, migrating them, our systems
    ran them really well because we can handle scale-up in a different way than other
    people did, and so it allowed us to open a lot of doors.
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这绝对不是战略的重启。我们启动了名为[multicloud](https://cloud.google.com/multicloud)的项目，即“不要被锁定在单一云服务提供商上，允许用户选择云服务提供商，选择最适合任务的云服务提供商”。因此，分析是我们表现特别突出的领域，我们在某些领域表现得非常出色，比如某些类型的传统系统迁移，我们的系统运行得非常出色，因为我们可以以不同于其他人的方式进行规模扩展，这使我们能够打开很多门。
- en: When AI came along, the first cycle was everybody thinking, “I have to pick
    a model,” and the model changes every three weeks and so our point was, “You’re
    chasing the wrong thing when you think about picking a model, what you need to
    do is to think about a platform”, because you need to integrate it into your heterogeneity
    and think about the platform first and the model second, and make sure the platform
    supports a collection of models, because you may choose the latest one from anybody,
    and so that’s the nature of it.
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当AI出现时，第一个周期是每个人都在考虑，“我必须选择一个模型”，而模型每三周就会变化，所以我们的观点是，“当你考虑选择模型时，你正在追逐错误的东西，你需要考虑的是平台”，因为你需要将其集成到你的异构性中，并首先考虑平台，其次是模型，并确保平台支持一系列模型的收集，因为你可以从任何人那里选择最新的模型，这就是问题的本质。
- en: '**Well, that’s the bit though as to why I’m getting to the question of a reboot,
    because I think this idea of you’re going to handle, you can have your multicloud,
    that makes sense given your competitive position in the market, being third place.
    Do you see AI, though, in all this talk about, “You need to choose a platform?
    Sure, our platform’s going to be open, you can use it anywhere” — but do you see
    this as a wedge to be like, “Okay, this is a reboot broadly for the industry as
    far as cloud goes, and sure, your data may be in AWS, or in Azure, or whatever
    it might be, but if you have a platform going forward, you should start with us”?
    Then maybe we’ll look up in ten, fifteen years, and all the center of gravity
    shifted to wherever the platforms are?**'
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**好吧，这就是我为什么要谈到重启的问题，因为我认为，你要处理的这个想法是，你可以拥有你的多云，这在市场上的竞争地位中是有意义的，作为第三名。不过，您是否认为在所有这些关于“您需要选择平台”的讨论中，AI可以作为一个楔子，比如，“好吧，这在云的广泛重启方面是个大动作，当然，您的数据可能在AWS或Azure等等，但是如果您有一个未来的平台，您应该从我们这里开始”？也许十五年后我们会看到，所有的重心都转移到了平台的位置上？**'
- en: '**TK:** For sure. I mean, it’s a change in the way that people make purchase
    decisions, right? Ten years ago, you were worried about commodity computing, and
    you were like, “Who’s going to give me the lowest cost for compute, and the lowest
    cost for storage, and the lowest cost for networking?”. Now the basis of competition
    has changed and we have a very strong position, given our capability both at the
    top, meaning offering a platform, offering models, et cetera, and building products
    that have long integrated models.'
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK：** 当然。我的意思是，这是人们做购买决策方式的改变，对吧？十年前，您担心的是商品化计算，您会想，“谁能给我最低的计算成本、存储成本和网络成本？”现在竞争的基础已经改变了，考虑到我们在顶端的能力，即提供平台、提供模型等等，我们拥有非常强大的位置，并且正在构建长期集成模型的产品。'
- en: Just as an example, Ben, integrating a model into a product is not as easy as
    people think; Gmail has been doing that since 2015\. On any daily basis, there
    are over 500 million operations a day that we run and to do it well, when a partner
    talked about the fact that 75% of people who generate an image for slides actually
    end up presenting it, it’s because we have paid a lot of attention over the years
    on how to integrate it.
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
  zh: 举个例子，Ben，将模型集成到产品中并不像人们想象的那么简单；Gmail自2015年以来一直在这样做。每天我们运行超过5亿次操作，要做好这件事情，当合作伙伴谈到75%的生成幻灯片图像的人最终会呈现时，这是因为多年来我们非常关注如何进行集成。
- en: So we play at the top of the stack, and we have the infrastructure and scale
    to do it really well from a cost, performance, and global scale that changes the
    nature of the competition. So we definitely see this, as you said, as a reset
    moment for how customers thinking of choosing their cloud decision.
  id: totrans-split-53
  prefs: []
  type: TYPE_NORMAL
  zh: 所以我们在顶层玩，我们有基础设施和规模，可以从成本、性能和全球规模上做得非常好，这改变了竞争的本质。所以我们确实看到这一点，正如你所说的，这是客户选择他们的云决策的一个重置时刻。
- en: '**If you’re talking about a lot of choices about models, and customers were
    over-indexed on choosing the correct model, that implies that models are maybe
    a commodity, and that we’ve seen with GPT-4 prices are down something like 90%
    since release. Is that a trend you anticipate continuing, and is it something
    that you want to push and actually accelerate?**'
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**如果你在谈论关于模型的很多选择，并且客户在选择正确的模型时有过度投入，这可能意味着模型可能是商品，我们已经看到，自GPT-4发布以来，价格下降了大约90%。这是一个你预期继续下去的趋势吗？这是你想要推动并实际加速的事情吗？**'
- en: '**TK:** Models — whether they’re a commodity or not, time will tell, these
    are very early innings. All we’re pointing out is every month, there’s a new model
    from a new player, and the existing models get better on many different dimensions.
    It’s like trying to pick a phone based on a camera, and the camera’s changing
    every two weeks, right? Is that the basis on which you want to make your selection?'
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 模型——无论它们是否成为商品，时间会告诉我们，现在还处在非常早期的阶段。我们要指出的是，每个月都会有新的玩家推出新模型，现有模型在多个方面都得到改进。这就像试图根据相机选择手机一样，而相机每两周都在变化，对吗？你愿意以此为基础做出选择吗？'
- en: '**Well, but if you make that basis, then you might be locked into the operating
    system.**'
  id: totrans-split-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**好吧，但如果你以此为基础，那么你可能会被锁定到操作系统上。**'
- en: '**TK:** That’s right, and so that’s why we say you should choose an open platform,
    and you should be able to use a collection of different models, because it’s changing,
    and don’t lock into a particular operating system at a time when the applications
    on top of it are changing, to use your analogy.'
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 是的，这就是为什么我们说你应该选择一个开放的平台，你应该能够使用一系列不同的模型，因为它正在改变，不要在应用程序正在改变的时候锁定到特定的操作系统上，用你的类比说。'
- en: '**Why is your platform open as compared to others? Microsoft has announced
    you can use other models, not just OpenAI models. Amazon is sort of, to the extent
    you can ascertain a strategy, it’s like, “Look, we’re not committing to anything,
    you could do whatever you want.” Why do you feel comfortable saying, “No, we’re
    the open one,” and they’re not?**'
  id: totrans-split-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**为什么你的平台比其他平台更开放？微软已经宣布你可以使用其他模型，而不仅仅是OpenAI的模型。亚马逊似乎在某种程度上确定了一种策略，“看，我们不承诺任何事情，你可以做任何你想做的。”为什么你觉得自己说“不，我们是开放的”，而他们不是？**'
- en: '**TK:** Well, first of all, the completeness of our platform; [Vertex has](https://cloud.google.com/vertex-ai)
    a lot more services than you can get with the other platforms. Secondly, in order
    to improve a platform, you have to have your own model, because there’s a bunch
    of things you do when you engineer services with that model.'
  id: totrans-split-59
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 首先，我们平台的完整性；[Vertex拥有](https://cloud.google.com/vertex-ai)比其他平台提供更多的服务。其次，为了改进平台，你必须有自己的模型，因为在使用该模型工程化服务时会做很多事情。'
- en: I’ll give you a really basic example. You use a model, you decide to [ground
    the answers](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview).
    Grounding improves quality, but can also introduce latency. How do you make sure
    that when you’re grounding, you’re not serially post-processing a model’s answer
    to add latency? Unless you have your own model, you wouldn’t even get to that.
    So because we have our own model, we’re able to engineer these things, but we
    make them available as services with other models, so you can use enterprise grounding
    as a very specific example. There are lots of customers using it with Mistral
    and with Llama and with Anthropic.
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我给你举个非常基础的例子。你使用一个模型，你决定[ground the answers](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/overview)。Grounding可以提高质量，但也可能引入延迟。你如何确保在grounding时不是串行后处理模型的答案以增加延迟？除非你有自己的模型，否则你甚至无法做到这一点。因此，因为我们有自己的模型，我们能够进行这些工程化的事情，但我们将其作为服务与其他模型一起提供，所以你可以使用企业grounding作为一个非常具体的例子。许多客户正在与Mistral、Llama和Anthropic一起使用它。
- en: Second thing, we are not just offering models, but we’re actually helping the
    third party go to customers with us. I met a lot of customers today jointly with
    [CEO] Dario [Amodei] from Anthropic, and it’s a commitment to make sure we’re
    not just giving you our infrastructure, we’re not just training, integrating a
    model into Vertex, we’re not just making it a first-class model, but we’re actually
    bringing it to clients together.
  id: totrans-split-61
  prefs: []
  type: TYPE_NORMAL
  zh: 第二件事，我们不仅仅提供模型，而且我们实际上正在帮助第三方与我们一起接触客户。今天我与[CEO] Dario [Amodei] 共同与来自Anthropic的许多客户见面，这是一种承诺，确保我们不仅仅是提供基础设施，不仅仅是进行训练并将模型集成到Vertex中，不仅仅是使其成为一流模型，而是实际上将其与客户一起推广。
- en: I think that’s what we mean by open. One of the other players has no models
    of their own, so naturally they’re offering a bunch of models, and the other player
    has outsourced their model development to a third party.
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这就是我们所说的开放性。另一家公司没有自己的模型，因此他们自然而然地提供了一堆模型，而另一家公司则将其模型开发外包给了第三方。
- en: Data Gravity and GTM
  id: totrans-split-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据引力和市场推广策略（GTM）
- en: '**How do you think about LLMs in the context of enterprise? You mentioned this
    grounding bit. I think in the consumer space, it’s like, “Wow, I can look up answers”,
    but from an enterprise perspective, I would imagine, I’m actually curious how
    often people bring up concerns about hallucinations. Maybe they’re even overstated
    to an extent. In a lot of the demos, LLMs were more user interfaces to existing
    data. Is that the framing that this is mostly manifesting in? Or are there other
    use cases? I mean, there’s the, “Write email for me”, but do you see it primarily
    as an interface to data, in the enterprise use case?**'
  id: totrans-split-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**在企业背景下，你如何看待LLMs？你提到了这个基础的部分。我认为在消费者领域，就像是“哇，我可以查找答案”，但从企业角度来看，我想知道的是，人们多频繁地提出对幻觉的担忧。也许它们甚至有点夸大。在许多演示中，LLMs更多是现有数据的用户界面。这主要是它的框架吗？或者还有其他用例？我的意思是，“帮我写邮件”，但你是否主要将其视为企业用例中的数据接口？**'
- en: '**TK:** There’s a bunch of people who are using it to do Q&A with their data,
    we call it Open Book Q&A. Think of it as I have a bunch of data, I want to summarize
    it and ask it questions, and it’s not necessarily look in the raw data, but summarize
    it and ask questions. There’s certainly a collection of it but there’s also people
    who are automating a process, and automating a processes like get the output of
    a model, I feed into another model, and drive a process with it. Do you see what
    I mean?'
  id: totrans-split-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK：** 有一群人正在使用它来与他们的数据进行问答，我们称之为Open Book Q&A。可以把它看作是我有一堆数据，我想对它进行总结并问它问题，不一定是直接查看原始数据，而是总结并提问。当然，这是其中一种方式，但也有人正在自动化流程，并且自动化流程就像是将一个模型的输出，喂给另一个模型，并用它驱动一个流程。你明白我的意思吗？'
- en: '**Yep.**'
  id: totrans-split-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**是的。**'
- en: '**TK:** They use function calling, like I give a model a question, it generates
    an answer, I put it into a function, the function does a bunch of things, then
    it calls another model, that next model takes it on.'
  id: totrans-split-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK：** 他们使用函数调用，就像我给一个模型一个问题，它生成一个答案，我把它放进一个函数中，函数做一堆事情，然后它调用另一个模型，接着那个模型接手了。'
- en: Think of it as when you’re doing software engineering or coding, I’ll use that
    as an example, one way you can use the model is, “Introspect my code base and
    see if there’s a security vulnerability”, like if I have a VAS vulnerability pattern
    in my code base, that’s the equivalent of the question and answer on your data.
    Second is, “Hey, if you find it, fix it, and here is the pattern I want you to
    follow to fix it, and then run the scan to see if it still exists and then compile
    it and deploy it. When you deploy it, I want to run an A/B test.” It’s that second
    thing we see a lot of people now doing, which is automating a process, and there
    can be a number of different levels of sophistication of that process.
  id: totrans-split-68
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下当你在做软件工程或编码时，我用它作为一个例子，你可以使用模型来“审视我的代码库，看看是否存在安全漏洞”，比如我在代码库中有一个VSA漏洞模式，这相当于在你的数据上进行问答。第二点是，“嘿，如果你找到了，就修复它，并且这是我希望你遵循的修复模式，然后运行扫描看看它是否仍然存在，然后编译并部署它。当你部署它时，我想运行一个A/B测试。”我们现在看到很多人正在做的第二件事情就是自动化流程，而这个流程的复杂程度可以有很多不同的层次。
- en: '**How important to achieving Q&A with your data or doing some of these processes
    — Is it essential that that data be on GCP or how does that work with external
    data? Because I think the framing and the advantage, say, to your competitor with
    none of their own models, is, well, they have all the data, and so data has a
    lot of gravity, it will pull people to that because models are a commodity, they
    can do XYZ.**'
  id: totrans-split-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**对于实现与你的数据进行问答或执行这些过程来说，数据是否必须在GCP上是至关重要的？或者外部数据如何使用？因为我认为，这个框架和优势，比如说，与没有自己模型的竞争对手相比，他们拥有所有的数据，因此数据具有很大的引力，它将吸引人们去那里，因为模型是一个商品，他们可以做XYZ。**'
- en: '**TK:** We support data from four types of environments, an on-premise data
    center, an application like a software-as-a-service application. Your customer
    service data could be in Salesforce, and Salesforce may not be running at all
    on GCP. It could be on another cloud provider, or it could be in a vector store.'
  id: totrans-split-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 我们支持来自四种环境的数据，包括本地数据中心、类似软件即服务的应用程序。你的客户服务数据可能在Salesforce，而Salesforce可能完全不在GCP上运行。它可能在另一个云服务提供商那里，或者可能在向量存储中。'
- en: '**Is the goal that that doesn’t matter? Or is it just a reality that it’s going
    to work better the more that it’s on Google?**'
  id: totrans-split-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**这个目标是不是无关紧要？还是说，更多数据在Google上运行会更好？**'
- en: '**TK:** You don’t have to be on Google to use it, first. And secondly, the
    big thing we say though is, there are tools you need to do to make sure that there’s
    a lot of basic things we suggest to people to make sure they think about it.'
  id: totrans-split-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 你不必在Google上使用它，首先。其次，我们要说的重要一点是，有些基本的事情我们建议人们做，以确保他们考虑到。'
- en: One example is how you handle access control permissions on your data because
    models don’t have the ability to handle access control rules. You can put it in
    a function after you’ve asked the model set of questions, but that’s post-processing.
    There are techniques to add access control, something that engineers [call ACLs](https://cloud.google.com/storage/docs/access-control/lists)
    — [Access Control Lists] on your data, so we suggest they think about that and
    we give them design patterns.
  id: totrans-split-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子是你如何处理数据的访问控制权限，因为模型本身无法处理访问控制规则。你可以在询问模型一系列问题后将其放在一个函数中，但这是后处理。有技术可以在你的数据上添加访问控制，工程师们称之为[ACLs](https://cloud.google.com/storage/docs/access-control/lists)（访问控制列表），所以我们建议他们考虑这一点，并给他们提供设计模式。
- en: Second, we ask them to measure the tests on the system to make sure that the
    system has predictable latency. Because a model can send a request, and if your
    system has huge queue, sometimes it responds quickly, sometimes it takes a long
    time, the model gets confused whether it’s waiting for an answer or not, that’s
    the second thing.
  id: totrans-split-74
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，我们要求他们对系统进行测试以确保系统具有可预测的延迟。因为一个模型可以发送请求，如果你的系统有一个巨大的队列，有时会快速响应，有时会花费很长时间，模型会混淆是否在等待答案，这是第二件事。
- en: The third thing that we typically ask them to work through is, there are tools
    to evaluate the quality of the data and when I say the quality of the data, to
    make sure you’re not in a situation where it’s garbage in, garbage out. By quality,
    we’re not talking just about structural quality, making sure there are no null
    sets and things like that, but also semantically, it has a correct meaning, because
    if you ask it for revenue and you are looking at invoice revenue but not GAAP
    revenue, you’ll get an answer on invoice revenue and you need to make sure it’s
    correctly defined whether you mean GAAP revenue or invoice revenue. Those are
    examples, and we provide blueprints to customers to do it.
  id: totrans-split-75
  prefs: []
  type: TYPE_NORMAL
  zh: 第三件我们通常要求他们解决的事情是，有工具来评估数据的质量，当我说数据的质量时，确保你不处于垃圾进，垃圾出的情况。所谓的质量，并不仅仅是指结构上的质量，确保没有空集等问题，还包括语义上的正确性，因为如果你要求的是收入，而你看的是发票收入而不是GAAP收入，你会得到一个发票收入的答案，你需要确保它是正确定义的，无论你指的是GAAP收入还是发票收入。这些都是例子，我们为客户提供蓝图来执行它。
- en: '**Where are the decisions made about this? Especially when you’re talking about
    the context of a platform and the way it interacts, is this at the CTO, CIO, CEO
    level where these choices are going to be made? Or is this something that engineering
    leads or program manager leads can say, let’s use the Vertex AI platform — where
    are you thinking about the go-to-market there?**'
  id: totrans-split-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**关于这个的决策是在哪里做出的？特别是当你谈论一个平台的背景和它的互动方式时，这是在CTO、CIO、CEO级别还是在工程领导或项目经理领导层次上做出的选择？或者这是工程师领导或项目经理领导可以说，让我们使用Vertex
    AI平台——你们在这方面的市场推广是怎么考虑的？**'
- en: '**TK:** Typically, the decisions are made jointly between a business unit leader
    and an IT leader. Sometimes the scenario is so important to the company, it’s
    the CEO driving it because it could be a real big change to the business model
    of the company. Often it’s a head of a line of business and the CIO or the CTO.'
  id: totrans-split-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 通常情况下，决策是由业务单位领导和IT领导共同做出的。有时候，这种情况对公司非常重要，是CEO推动，因为这可能对公司的商业模式产生真正重大的改变。通常是业务线负责人和CIO或CTO。'
- en: '**This is kind of a nerdy question, but I’m curious about how costs are allocated
    for all this sort of AI work. I assume that Google Cloud is paying for its own
    share of servers, but there’s a lot of shared R&D and model development that’s
    shared with Google proper. Is Google Cloud just on the cost of serving side of
    things? I’m curious — like I said, it’s very nerdy — I’m just curious how you
    interact with Google proper given there’s so much shared development here.**'
  id: totrans-split-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**这是一个有点书呆子的问题，但我很好奇关于所有这些人工智能工作的成本如何分配。我假设 Google Cloud 自己支付其服务器的费用，但与 Google
    正确的共享研发和模型开发也很多。Google Cloud 只是服务端的成本吗？我很好奇——就像我说的，这是一个非常书呆子的问题——我只是好奇你如何与 Google
    正确互动，考虑到这里有这么多共享的开发。**'
- en: '**TK:** First of all, our global infrastructure for Google is shared between
    Cloud and the rest of Google, you know that it’s been true for a long time.'
  id: totrans-split-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 首先，我们的全球基础设施对于 Google 来说是云和其他部门共享的，你知道这一点已经是很长时间了。'
- en: '**Yeah.**'
  id: totrans-split-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**Yeah.**'
- en: '**TK:** So from the point of the physical infrastructure, we share the infrastructure
    with all the product units, including with the Google DeepMind team that builds
    the models. On how the costs are allocated, I’ll just tell you, we are reported
    as a segment and we pay a fair share.'
  id: totrans-split-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 所以从物理基础设施的角度来看，我们与所有产品单位共享基础设施，包括 Google DeepMind 团队构建模型的部门。关于成本分配的问题，我只能告诉你，我们被报告为一个部门，我们支付公平份额。'
- en: '**This kind of goes back to the commodity sort of question. Is Google Cloud
    and this AI stuff, are you looking to win by being better? Or is there a bit where
    you can really leverage that infrastructure advantage? Of course you should be
    sharing resources, that’s the huge advantage that you have to not just win on
    features but also win on cost and price and TCO and all those sorts of things.**'
  id: totrans-split-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**这有点回到了商品化的问题。Google Cloud 和这些人工智能，你是想通过更优秀来获胜吗？还是说你真的可以利用基础设施的优势？当然，你应该共享资源，这是你不仅在功能上获胜，而且在成本、价格和总体成本拥有巨大优势的地方。**'
- en: '**TK:** Two things, if I may, Ben. First of all, we are winning because we’re
    better. Every customer who has chosen us had the choice to choose anyone else,
    we win because we have great products, including in AI. Second, one of the important
    elements of using AI at scale is cost, but there are other elements along with
    cost. There’s latency. There is, for example, simple things like, “How many times
    do I need to ask a model the question to get the correct answer?”, because every
    time you go to the model, you’re passing in a set of tokens and there’s a set
    of costs. It’s also a customer experience issue. You see what I mean?'
  id: totrans-split-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 如果可以的话，本。首先，我们之所以获胜是因为我们更优秀。每个选择我们的客户都有选择其他人的机会，我们之所以胜出是因为我们拥有出色的产品，包括在人工智能领域。其次，在规模化应用人工智能的重要因素之一是成本，但成本之外还有其他因素。还有延迟。例如，像“我需要问模型多少次才能得到正确答案？”，因为每次访问模型时，您都会传入一组标记，这会产生一定的成本。这也是客户体验的问题。你明白我的意思吗？'
- en: '**Yep.**'
  id: totrans-split-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**Yep.**'
- en: '**TK:** On all those things, there are many, many things we’ve done to sort
    out performance, scale, latency, et cetera. I mean, as a very simple example,
    to get the million tokens to work, there’s changes you need in the way that you
    design the model. There’s changes what you do with the serving stock, et cetera.
    Because we’ve got expertise in both, we’re able to do those things.'
  id: totrans-split-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 在所有这些事情上，我们已经做了很多工作来解决性能、规模、延迟等问题。我的意思是，作为一个非常简单的例子，要使百万个标记工作，您需要在设计模型的方式上进行改变。这会影响到服务的库存等等。因为我们在这两个领域都拥有专业知识，所以我们能够做到这些事情。'
- en: Infrastructure and One Million Tokens
  id: totrans-split-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基础设施和一百万标记
- en: '**How important is that million context window in the story you are telling?
    My perception is, there’s a lot of stuff you could do if you build a lot of infrastructure
    around it, whether it be RAG or other implementations, but it feels like with
    Gemini 1.5 there are jack-of-all-trades possibilities that seem to open up to
    a much greater extent, and there’s a bit where, you had that compliance bit, the
    statements of work and they had to compare it to the 100-page compliance document.
    I got some comments like, “Maybe companies shouldn’t have 100-page compliance
    notebooks or whatever it might be”, but the reality is, that’s the case, the world
    has that. My perception of the keynote is, that was the killer feature, that seemed
    to undergird everything. Was that the correct perception?**'
  id: totrans-split-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**这个百万上下文窗口在你讲述的故事中有多重要？我的感觉是，如果你在其周围构建了大量的基础设施，无论是RAG还是其他实施，你都可以做很多事情，但是我觉得，用Gemini
    1.5，有很多全能可能性似乎可以更大程度地开放，并且有一部分，在那里，你有了合规性部分，工作声明，他们不得不将其与100页的合规性文件进行比较。我得到了一些评论，比如，“也许公司不应该有100页的合规笔记本或其他什么”，但现实是，世界就是这样。我对于这次主题演讲的看法是，那似乎是杀手级功能，似乎为一切奠定了基础。这个感觉是正确的吗？**'
- en: '**TK:** Yeah, there are two reasons. Just to be perfectly clear, Ben, the long
    context window allows you to do three things that are important. First of all,
    when you look at high definition video, for example, and other modalities, and
    just imagine you’re dumping a high definition video in and you want to create
    out of the NCAA final, which just happened, the highlight reel but you don’t want
    to specify every attribute about what you want spliced into the highlight reel.
    The model has to digest it and because it has to process it, it’s a fairly dense
    representation of the video because there are objects, there are people moving,
    there are actions, like I’m throwing a pass. They could be, I have my name on
    the back of my t-shirt, there could be a score like, “When did they change from
    24 to 26 points? Did they score three pointers?”, so there are many, many, many
    dimensions. So reasoning becomes a lot better when you can take a lot more context,
    that’s one, and it’s particularly true of modality.'
  id: totrans-split-88
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 是的，有两个原因。只是为了非常清楚，本，长上下文窗口可以让你做三件重要的事情。首先，当你观看高清视频时，例如其他形式，比如想象你把一个高清视频传入，你想从最近的NCAA比赛中创造出精彩的片段，但你不想具体指定要剪辑到精彩片段中的每个属性。模型必须将其消化，因为它必须处理它，视频的表示就会变得相当密集，因为有物体，有人在移动，有动作，比如我在传球。它可能是，我的球衣上有我的名字，可能有分数，像，“他们是什么时候从24分变成26分的？他们投了三分球吗？”，所以有很多，很多维度。因此，当你可以用更多上下文进行推理时，推理就会变得更好，这是第一个，对形式尤为真实。'
- en: The second is, today people don’t use models to maintain state or memory, meaning
    they ask it a question, the next time they think, “Hey, it may not remember”,
    so when you’re able to maintain a longer context, you can maintain more state,
    and therefore you can do richer and richer things rather than just talk back-and-forth
    with a very simplistic interface. You see what I mean?
  id: totrans-split-89
  prefs: []
  type: TYPE_NORMAL
  zh: 第二点是，如今人们不再使用模型来维护状态或记忆，这意味着他们问一个问题，下一次他们想，“嘿，它可能不记得”，所以当你能够维护更长的上下文时，你就能够维护更多的状态，因此你就能够做出更丰富和更丰富的事情，而不仅仅是和一个非常简单的接口来回交流。你懂我的意思吗？
- en: The third thing is, there are certainly complex scenarios, it’s the unfortunate
    reality, there’s lots of policies and procedure books that are even longer than
    what we showed, and so there are scenarios like that that we have to be able to
    deal with. But in the longer term, the real breakthrough is the following. Context
    length, if you can decouple the capabilities of the model and the latency to serve
    a model from the context length, then you can fundamentally change how quickly
    you can scale a model.
  id: totrans-split-90
  prefs: []
  type: TYPE_NORMAL
  zh: 第三件事是，肯定有复杂的场景，这是不幸的现实，有很多政策和程序手册甚至比我们展示的还要长，所以有这样的场景，我们必须能够处理。但长期来看，真正的突破在于以下。上下文长度，如果你能够从模型的能力和为模型提供服务的延迟中分离出上下文长度，那么你就能从根本上改变模型的扩展速度。
- en: '**Is this ultimately, from your perspective, a question of infrastructure,
    and that just leans into Google’s biggest advantage?**'
  id: totrans-split-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**从你的角度来看，这最终是一个基础设施问题，也是谷歌最大的优势？**'
- en: '**TK:** It’s a question of global infrastructure, but also optimizations at
    every layer in the infrastructure, which we can co-engineer with DeepMind.'
  id: totrans-split-92
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 这是一个全球基础设施的问题，同时也是基础设施的每一层的优化，我们可以与DeepMind共同工程设计。'
- en: '**Right. This gets at the integration point of your own model.**'
  id: totrans-split-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**对，这涉及到你自己模型的集成点。**'
- en: '**TK:** Yeah, and then the second thing is the expertise in Google DeepMind
    to use the infrastructure. If I can give an example, it’s sort of like, years
    and years ago, when Google built its global infrastructure and they acquired YouTube,
    they could instantly scale video distribution globally, and if you go back in
    time, there were many companies in the video business when Google acquired YouTube,
    but they didn’t have that scalable infrastructure. In the end, I think you’ve
    seen our success with it because we can do global distribution. This is a similar
    notion, let’s say, a few years on.'
  id: totrans-split-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 是的，然后第二件事是Google DeepMind在使用基础设施方面的专业知识。如果我可以举个例子，这有点像多年前，当Google建立其全球基础设施并收购YouTube时，他们可以立即在全球范围内扩展视频分发，而如果你回到过去，当Google收购YouTube时，视频行业有很多公司，但他们没有那种可扩展的基础设施。最终，我认为你已经看到我们的成功，因为我们可以进行全球分发。这是一个类似的概念，可以说是几年后的情况。'
- en: '**Yeah, that fits my thinking on the matter and actually to me this was what
    was encouraging about that keynote, was it felt like there is an aspect, of course,
    in any product development, you need to understand your customer, understand their
    use case, but I think there’s a bit where companies need to understand themselves,
    and what I got from that keynote and what I felt encouraging in a way I haven’t
    seen in other Google presentations in the Post-ChatGPT Era, I’ll call it the Modern
    AI Era, was a real, “We know who we are and what we’re good at and here’s ways
    we’re going to manifest that advantage”. I got that very distinctly, which I thought
    was a positive sign.**'
  id: totrans-split-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**是的，这符合我的思考方式，实际上对我来说，这就是那个主题演讲鼓舞人心的地方，因为它感觉上有一个方面，在任何产品开发中，你需要了解你的客户，理解他们的用例，但我认为公司需要了解自己的一部分，而我从那个主题演讲中得到的，以及我在后ChatGPT时代（我称之为现代AI时代）感到鼓舞的方式，是真正的，“我们知道我们是谁，我们擅长什么，以及我们将如何展现这种优势的方式”。我非常清楚地得到了这一点，我认为这是一个积极的迹象。**'
- en: '**TK:** Thank you.'
  id: totrans-split-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 谢谢。'
- en: Challenges and Opportunities
  id: totrans-split-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 挑战与机遇
- en: '**One of the areas where I think Google really dropped the ball, this goes
    back ten years or whatever it is, particularly around Workspace, was building
    an ecosystem. I think I’ve asked you about this before, and the fact that it was
    kind of Microsoft Lite that, “We’re going to do everything”, but Microsoft’s very
    good at that and there’s all these other products in Silicon Valley that are best
    in breed, but no one was tying them together, there wasn’t the glue to have everything
    work together. Does any of those lessons or learnings, or maybe I’m right or wrong,
    apply to this next era? How is Google thinking about partnering with other startups
    or with other entities as far as being able to glue different stuff together?
    Because that is a little bit in contrast to the story you’re telling about, “Look,
    we have real integration advantages by doing a lot of stuff ourselves”. How are
    you thinking about the balance there?**'
  id: totrans-split-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**我认为Google真正失误的一个领域之一，这可能是十年前或其他什么时候，特别是在Workspace周围，是建立一个生态系统。我想我以前问过你这个问题，事实上，它有点像微软的Lite版本，“我们将做一切”，但微软非常擅长这样做，在硅谷还有许多其他最佳产品，但没有人把它们联系在一起，没有粘合剂让所有东西协同工作。这些教训或经验是否适用于这个新时代？Google如何考虑与其他初创公司或其他实体合作，以便能够将不同的东西粘合在一起？因为这与你所讲述的“看，我们通过自己做很多事情确实有真正的集成优势”有些对比。你是如何考虑这个平衡的？**'
- en: '**TK:** We definitely are working with an ecosystem, and the reason is the
    following. We’ve always said the fact that we’re integrating things doesn’t mean
    we’re a closed system. So just recently, since you mentioned Workspace, we have
    integrations to automate workflow for people. People eventually want to use a
    collaboration tool, not to just collaborate, but they actually wanted to automate
    workflow. So we’ve done work with many partners, and there were several at this
    event from Canva to HubSpot to DocuSign to Adobe and several others where we’ve
    actually done the detail work to make that workflow totally seamless, you’re going
    to continue seeing us do more of it.'
  id: totrans-split-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 我们确实正在与一个生态系统合作，原因在于以下。我们一直说，我们集成东西并不意味着我们是一个封闭的系统。所以最近，由于你提到了Workspace，我们已经有了自动化工作流程的集成。人们最终希望使用协作工具，不仅仅是为了协作，而是他们实际上希望自动化工作流程。因此，我们与许多合作伙伴合作，此次活动中有来自Canva、HubSpot、DocuSign、Adobe等几家公司，我们确实做了详细的工作，使工作流程完全无缝化，你会继续看到我们做更多的工作。'
- en: '**Sundar Pichai mentioned in his video greeting, he emphasized the number of
    AI startups, and particularly AI unicorns using Google Cloud. To go back to the
    reboot idea, do you view the AI Era as a restart in terms of capturing the next
    generation of companies? I mean, obviously, AWS had a huge advantage here as far
    as general cloud computing, the entire mobile app ecosystem was by and large built
    on AWS. In the enterprise era, you have to deal with what’s there, what they’ve
    already dealt with, you have to have the integrations. Do you see yourself as
    having this as a big focus, “We’re going to own this era of startups”?**'
  id: totrans-split-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**Sundar Pichai 在他的视频问候中提到，他强调了 AI 初创企业的数量，尤其是使用 Google Cloud 的 AI 独角兽。回到重启的想法，你是否认为
    AI 时代是在捕捉下一代公司方面的重新开始？我的意思是，显然，AWS 在一般云计算方面有着巨大的优势，整个移动应用生态系统基本上是在 AWS 上构建的。在企业时代，你必须处理已有的东西，他们已经处理过的东西，你必须有集成。你是否认为自己把这视为一个重要的焦点，“我们将主导这个初创企业时代”？**'
- en: '**TK:** Yes. And by the way, every one of those startups is being pursued by
    the other two, and the fact that 90% of the unicorns and 60% of all AI-funded
    startups, up in each case by ten points in eight months, and they are the most
    discerning ones. I mean, just to be frank, the unicorns, for them, it is the really
    biggest cost of goods sold in their P&L.'
  id: totrans-split-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK：** 是的。顺便说一句，所有这些初创企业都被另外两家追求，事实上，90% 的独角兽和所有 AI 融资初创企业的 60%，在每种情况下都增加了十个百分点，它们是最明智的。我的意思是，坦率地说，对于他们来说，这确实是他们损益表中的最大成本。'
- en: '**So what’s the driver there?**'
  id: totrans-split-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**所以驱动因素是什么？**'
- en: '**TK:** The efficiency of our infrastructure.'
  id: totrans-split-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK：** 我们基础设施的效率。'
- en: '**They don’t have all the legacy data and legacy things, so you’ll feel like
    on an even playing field without that legacy, no one can touch you?**'
  id: totrans-split-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**他们没有所有的传统数据和传统的事物，所以你会觉得在没有那些传统的情况下，你在一个公平竞争的环境中，没有人可以触及你？**'
- en: '**TK:** We are not looking to raise a trillion dollars to [build a supercomputer](https://www.theinformation.com/articles/microsoft-and-openai-plot-100-billion-stargate-ai-supercomputer?rc=gtxu6q)
    because we’ve been building one for ten years, and it’s our fifth generation of
    building one of those, so we’re not learning on the job for the first time.'
  id: totrans-split-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK：** 我们不打算筹集一万亿美元来建造超级计算机，因为我们已经建造了十年的超级计算机，这是我们第五代建造这样的设备，所以我们不是第一次在工作中学习。'
- en: '**Google is, enterprise customers or startups, whoever it might be, they’re
    buying infrastructure or they’re wanting to use models. Is there any concern about
    Google in the consumer space? I mean, [one of the challenges with becoming an
    answer engine as opposed to a search engine is you’re giving one answer](https://stratechery.com/2024/aggregators-ai-risk/),
    and there’s a lot of fighting over what that answer should be. You’re not offloading
    that to the user. Are you feeling any blow back or worries about just Google being
    a [culture war](https://stratechery.com/2024/gemini-and-googles-culture/) flash
    point or Gemini, or whatever it might be? Or has that been relatively immaterial?**'
  id: totrans-split-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**Google 是，无论是企业客户还是初创企业，他们都在购买基础设施或者希望使用模型。对于 Google 在消费者空间是否有任何担忧吗？我的意思是，成为答案引擎而不是搜索引擎的一个挑战之一是你只提供一个答案，关于答案应该是什么存在很多争议。你不把这些问题交给用户解决。你是否感到任何关于
    Google 成为文化战的反弹或担忧，或者 Gemini，或者其他任何可能的问题？或者这些都相对不重要？**'
- en: '**TK:** That has been completely immaterial.'
  id: totrans-split-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK：** 这完全不重要。'
- en: '**Is it an asset?**'
  id: totrans-split-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**这是一个资产吗？**'
- en: '**TK:** We are known as a company with great engineering prowess. You asked,
    Ben, what’s the nature of Google? Google at the heart of it is a great engineering
    company. We build great products, we know how to build the most scalable infrastructure
    in the world. As people choose to do AI, they want a partner who has been there,
    done that, and unlike people who are for the first time working with a third-party
    model and for the first time trying to introduce their products, we’ve built models
    for years and we’ve integrated our products for years and we’ve run it for years
    on a scalable infrastructure. So every company has issues, we’re proud of who
    we are and customers are proud to work with us.'
  id: totrans-split-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK：** 我们以出色的工程技能而闻名。你问了，本，谷歌的本质是什么？谷歌的核心是一家出色的工程公司。我们制造出色的产品，我们知道如何构建全球最可扩展的基础设施。随着人们选择进行人工智能，他们希望有一个曾经有过经验的伙伴，和第一次使用第三方模型并试图推介他们的产品的人不同，我们已经训练了多年的模型，并且多年来集成了我们的产品，并且在可扩展的基础设施上运行了多年。所以每家公司都有问题，我们为自己感到骄傲，客户也为和我们合作感到骄傲。'
- en: '**I’ve been impressed. I’ve told you this last time you were on here. I’ve
    been really impressed with the work you’ve done with Google Cloud. And I’m curious,
    as you look back on your tenure, to what extent have you succeeded by building
    an organization that’s independent from Google as opposed to integrated with Google?
    What’s the push and pull there, particularly given that the enterprise go-to market
    and the support needs and all those things are very distinct from a many billion
    users consumer product?**'
  id: totrans-split-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**我对你们在谷歌云方面的工作印象深刻。上次你来的时候我已经告诉过你。我对你成功地建立起与谷歌独立而不是与谷歌整合的组织印象深刻，想问问，回头看你的任期，你在多大程度上成功了？尤其是考虑到企业市场和支持需求等方面与拥有数十亿用户的消费品非常不同的地方，这其中有推拉作用是什么？**'
- en: '**TK:** We have different needs, we have shared values. So we have shared values
    on many things, treating our employees fairly, aspiring to excellence, making
    sure that our teams work effectively, empathetically, and collaboratively with
    the rest of Google. At the end of the day, all of our models are served on the
    infrastructure our team builds. When you use search, it runs on the infrastructure
    that our team delivers. When you use YouTube, it runs on the network that our
    team builds. So we work very well with the rest of Google.'
  id: totrans-split-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK：** 我们有不同的需求，我们有共同的价值观。所以我们在很多事情上有共同的价值观，公平对待员工，追求卓越，确保我们的团队与谷歌的其他部门效果好地合作，有同情心地合作。归根结底，我们的所有模型都是由我们的团队构建的基础设施提供服务。当你使用搜索时，它就运行在我们的团队提供的基础设施上。当你使用YouTube时，它就是在我们的团队构建的网络上运作。所以我们与谷歌其他部门合作得非常好。'
- en: At the same time, the necessity to work in an enterprise context requires us
    to have some unique things. As an example, we have many functions that the rest
    of Google doesn’t have. They don’t need professional services, they don’t need
    certain kinds of commercial attorneys, they don’t need certain kinds of systems
    that we do. Even the sales team works differently than the way that our sales
    team has to do because we sell to technology departments while they sell to chief
    marketing officers, so there are differences in what we do.
  id: totrans-split-112
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，在企业环境中工作的必要性要求我们有一些独特之处。举个例子，我们有许多谷歌其他部门没有的功能。他们不需要专业服务，也不需要某种类型的商业律师，我们需要这些。甚至销售团队的工作方式也与我们的销售团队不同，因为他们销售给技术部门，而他们销售给市场营销总监，因此我们的工作内容是不同的。
- en: At the same time, we’ve earned the respect of the rest of Google by the hard
    work we’ve done to win customers and grow the business. And we’re very proud.
  id: totrans-split-113
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，我们通过努力赢得客户和发展业务，赢得了谷歌其他部门的尊重。我们感到非常自豪。
- en: '**And I think you should be. Is there a future where we look back in decades
    and we’re like, “Oh yeah, Google, the AI infrastructure company, they started
    as a search engine, believe it or not”? Is there a potential where what your building
    is actually in this new era what comes to matter most?**'
  id: totrans-split-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**我认为你应该。会不会有一个未来，几十年后，我们会回头看，然后说，“哦，是的，Google，这家人工智能基础设施公司，他们最开始是一个搜索引擎，信不信由你”？你们所建立的东西会不会成为这个新时代最重要的事情？**'
- en: '**TK:** To us, five years ago, nobody gave us a shot, and to be frank, I was
    told it doesn’t matter at all. One way to look at it is, “Are we working on something
    that’s important?”, another way to look at it is, “It’s all upside”, and we took
    the latter. And today it matters, there’s no question about it. When we look at
    the investor community, when we look at the customer community, when we look at
    the relationships that Google has now, because we both serve the technology team
    and the marketing team in many companies, it definitely matters. Will it be the
    most important thing? Time will tell. I’ve learned to never make a forecast in
    technology.'
  id: totrans-split-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 对于我们来说，五年前，没有人看好我们，坦率地说，有人告诉我这一点根本不重要。看待这个问题的一种方式是，“我们在做一些重要的事情吗？”，另一种方式是，“这完全是上升期”，而我们选择了后者。今天，这确实很重要，毫无疑问。当我们看投资者社区时，当我们看客户社区时，当我们看谷歌现在的关系时，因为我们同时为许多公司的技术团队和营销团队提供服务，这确实重要。它会是最重要的事情吗？时间会告诉我们。我学会了在技术领域永远不要做预测。'
- en: '**(laughing) I think you make lots of forecasts in your day-to-day job, but
    you’re not going to share them with me, which is totally fine. Thomas, thanks
    for coming back on. I thought it was a good keynote. There’s a bit about AI where
    we don’t have to discuss on here, it’s not your area, that proposes fundamental
    challenges for the consumer product from a business model perspective, from the
    answer perspective, but at the same time, it’s like a hand-in-glove fit with the
    cloud and enterprise and what you’re doing, and it seems to me that you seem to
    recognize and are capitalizing on the same thing.**'
  id: totrans-split-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**（笑）我认为你在日常工作中做了很多预测，但你不会与我分享，这完全没问题。托马斯，感谢你再次出现。我认为这是一个很好的主题演讲。关于AI有些内容我们这里不必讨论，这不是你的领域，它从商业模型的角度提出了基本的挑战，从答案的角度来看，但同时，它与云和企业的紧密结合，似乎你认识到并正在利用相同的事情。**'
- en: '**TK:** Thank you so much for your time, Ben. Good to talk to you.'
  id: totrans-split-117
  prefs: []
  type: TYPE_NORMAL
  zh: '**TK:** 感谢你抽出时间，本。很高兴与你交谈。'
- en: '* * *'
  id: totrans-split-118
  prefs: []
  type: TYPE_NORMAL
  zh: '* * *'
- en: This Daily Update Interview is also available as a podcast. To receive it in
    your podcast player, [visit Stratechery](https://stratechery.passport.online/member).
  id: totrans-split-119
  prefs: []
  type: TYPE_NORMAL
  zh: 本次每日更新采访也可作为播客提供。要在您的播客播放器中收听，请[访问Stratechery](https://stratechery.passport.online/member)。
- en: The Daily Update is intended for a single recipient, but occasional forwarding
    is totally fine! If you would like to order multiple subscriptions for your team
    with a group discount (minimum 5), please contact me directly.
  id: totrans-split-120
  prefs: []
  type: TYPE_NORMAL
  zh: 每日更新是为单个收件人设计的，但偶尔转发也完全没问题！如果您想为您的团队订购多个订阅并享受团体折扣（最少5个），请直接与我联系。
- en: Thanks for being a supporter, and have a great day!
  id: totrans-split-121
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢您的支持，并祝您有个愉快的一天！
- en: '*Related*'
  id: totrans-split-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '*相关*'
