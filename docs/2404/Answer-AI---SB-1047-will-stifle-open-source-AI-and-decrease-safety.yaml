- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 13:38:25'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: Answer.AI - SB-1047 will stifle open-source AI and decrease safety
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://www.answer.ai/posts/2024-04-29-sb1047.html](https://www.answer.ai/posts/2024-04-29-sb1047.html)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: <main class="content" id="quarto-document-content">
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: '*Note from Jeremy*: This is my personal submission to the authors of [bill
    SB-1047](https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047).
    It’s not an official Answer.AI statement.'
  id: totrans-split-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This is a comment from Jeremy Howard regarding SB-1047\. I am an AI researcher
    and entrepreneur. I am the CEO of Answer.AI, an AI R&D lab registered to do business
    in California. I am the author of popular AI software including the fastai library,
    a widely used AI training system. I am the co-author of *Deep Learning for Coders
    with Fastai and PyTorch: AI Applications Without a PhD*, a widely-praised book
    with a 4.7 rating on Amazon based on nearly 500 reviews, and am the creator of
    the *Practical Deep Learning* series of free courses, the longest-running deep
    learning course in the world, with over 5 million views. I co-authored the paper
    [Universal Language Model Fine-tuning for Text Classification](https://arxiv.org/abs/1801.06146),
    which created the 3-stage language model pre-training and fine-tuning approach
    on which all of today’s language models (including ChatGPT and Gemini) are based.'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: While the intent of SB-1047 to ensure the safe and secure development of AI
    is commendable, certain provisions within the bill raise serious concerns regarding
    their potential impact on open-source developers, small businesses, and overall
    innovation within the AI sector. This response aims to highlight these concerns
    and suggest alternative approaches that could achieve the desired safety goals
    without stifling the dynamism of the AI ecosystem.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
- en: 'Ironically, by imposing these restrictions on open-source development, SB-1047
    could actually reduce overall safety within the AI ecosystem, in particular through
    reducing:'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
- en: '**Transparency and Collaboration**: Open-source development fosters transparency
    and collaboration, allowing a wider range of experts to identify and address potential
    safety concerns. Restricting this open development model limits the ability of
    the broader community to contribute to safety solutions.'
  id: totrans-split-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Diversity and Resilience**: Open-source projects contribute to a more diverse
    and resilient AI landscape. Concentrating control within a few large entities
    creates single points of failure and increases the potential for systemic risks.'
  id: totrans-split-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Concerns Regarding Open-Source Development
  id: totrans-split-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Open source has been a key enabler of the success of the US software industry,
    and has allowed many Americans to access critical software tools which would otherwise
    be unavailable to them. Open source has, in particular, provided many of the fundamental
    building blocks for modern artificial intelligence, and is the basis on which
    nearly all academic research (including safety and security research) is done.
    Harming open source will harm developers, consumers, academics, and obstruct the
    development of new startups. The bill would cause harm in a number of ways:'
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
- en: '**Overly Broad Definitions**: The definition of “covered model” within the
    bill is extremely broad, potentially encompassing a wide range of open-source
    models that pose minimal risk. This could inadvertently criminalize the activities
    of well-intentioned developers working on beneficial AI projects.'
  id: totrans-split-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dual use**: An AI model is a general purpose piece of software that runs
    on a computer, much like a word processor, calculator, or web browser. The creator
    of a model can not ensure that a model is never used to do something harmful –
    any more so that the developer of a web browser, calculator, or word processor
    could. Placing liability on the creators of general purpose tools like these mean
    that, in practice, such tools can not be created at all, except by big businesses
    with well funded legal teams.'
  id: totrans-split-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Restrictive Requirements**: The bill imposes significant burdens on developers,
    including mandatory shutdowns, extensive reporting, and compliance with potentially
    ambiguous “covered guidance.” These requirements could disproportionately impact
    open-source developers who often lack the resources of larger corporations to
    navigate complex regulatory processes.'
  id: totrans-split-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Disincentivizing Openness**: The fear of legal repercussions and bureaucratic
    hurdles could discourage open-source development, hindering the collaborative
    spirit that has been instrumental in driving AI advancements. This reduction in
    transparency could also make it more difficult to identify and address potential
    safety concerns.'
  id: totrans-split-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Impact on Small Businesses and Innovation
  id: totrans-split-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The proposed regulations create significant barriers to entry for small businesses
    and startups looking to innovate in the AI space. The costs associated with compliance,
    coupled with the legal risks, could deter entrepreneurs and limit competition.
    This would ultimately stifle innovation and concentrate power within established
    corporations.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
- en: '**Barrier to Entry**: The substantial costs associated with compliance, including
    fees, audits, and legal counsel, could create a significant barrier to entry for
    small businesses and startups. This would limit competition and concentrate power
    within established corporations, ultimately hindering innovation.'
  id: totrans-split-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Chilling Effect on Research**: The fear of inadvertently triggering the bill’s
    provisions could lead researchers and developers to self-censor or avoid exploring
    promising avenues of AI research. This would stifle scientific progress and limit
    the potential of AI to address societal challenges.'
  id: totrans-split-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对研究的抑制效应**：担心不慎触发法案条款可能会导致研究人员和开发者进行自我审查或避免探索有前景的AI研究途径。这将抑制科学进展，限制AI解决社会挑战的潜力。'
- en: '**Loss of Talent**: The restrictive environment created by the bill could drive
    talented AI researchers and developers out of California, harming the state’s
    economy and weakening its position as a leader in AI innovation.'
  id: totrans-split-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人才流失**：该法案制造的限制性环境可能会驱使有才华的AI研究人员和开发者离开加利福尼亚州，损害该州经济，并削弱其在AI创新方面的地位。'
- en: California plays a critical role in driving US innovation, particularly in the
    technology sector. By placing undue burdens on AI development, SB-1047 risks hindering
    the state’s leadership in this crucial field. This could have ripple effects throughout
    the US, slowing down overall progress in AI research and development.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: 加利福尼亚州在推动美国创新中扮演着关键角色，尤其是在技术领域。通过对AI开发施加不当负担，SB-1047法案存在的风险在于阻碍该州在这一关键领域的领导地位。这可能会对整个美国产生涟漪效应，减缓AI研究与开发的总体进展。
- en: Alternative Approaches
  id: totrans-split-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 替代方法
- en: Instead of focusing on regulating AI model development, I urge you to consider
    alternative approaches that address the actual risks associated with AI applications.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议您不要专注于规范AI模型的开发，而是考虑解决与AI应用实际风险相关的替代方法。
- en: '**Support Open-Source Development**: Encourage and facilitate the open-source
    development of AI models to foster collaboration, transparency, and a more diverse
    and resilient AI ecosystem.'
  id: totrans-split-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持开源开发**：鼓励并促进AI模型的开源开发，以促进协作、透明度和更多样化、更具韧性的AI生态系统。'
- en: '**Focus on Usage, Not Development**: Instead of regulating the development
    of AI models, the focus should be on regulating their applications, particularly
    those that pose high risks to public safety and security. Regulate the use of
    AI in high-risk areas such as healthcare, criminal justice, and critical infrastructure,
    where the potential for harm is greatest, would ensure accountability for harmful
    use, whilst allowing for the continued advancement of AI technology.'
  id: totrans-split-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专注于使用而非开发**：与其规范AI模型的开发，不如专注于规范其应用，特别是那些对公共安全和安全性造成高风险的领域。在医疗保健、刑事司法和关键基础设施等高风险领域规范AI的使用，将确保对有害使用的问责，同时允许AI技术的持续发展。'
- en: '**Promote Transparency and Collaboration**: Encourage the development and adoption
    of best practices for responsible AI development through collaboration between
    industry, academia, and government. This could involve creating industry standards,
    fostering open-source development, and investing in AI safety research.'
  id: totrans-split-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**促进透明度和协作**：通过行业、学术界和政府之间的协作，鼓励负责任的AI开发最佳实践的制定与采纳。这可能涉及制定行业标准、促进开源开发和投资于AI安全研究。'
- en: '**Invest in AI Expertise**: Provide resources to government agencies to develop
    expertise in AI and build capacity to effectively monitor and address potential
    risks. This would enable a more informed and nuanced approach to AI regulation
    that balances safety with innovation.'
  id: totrans-split-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**投资于AI专业知识**：为政府机构提供资源，以发展AI专业知识，并建立有效监测和应对潜在风险的能力。这将使AI监管更为知情和细致，平衡安全与创新。'
- en: Conclusion
  id: totrans-split-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: California has a unique opportunity to lead the way in responsible AI development.
    However, SB-1047, in its current form, risks stifling innovation and undermining
    the state’s leadership in AI. By adopting alternative approaches that prioritize
    accountability for harmful use while fostering a vibrant and open AI ecosystem,
    California can ensure the safe and beneficial advancement of this transformative
    technology.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 加利福尼亚州有机会在负责任的AI发展方面走在前列。然而，目前的SB-1047法案存在的风险在于抑制创新，削弱了该州在AI领域的领导地位。通过采纳优先考虑有害使用责任的替代方法，同时促进充满活力和开放的AI生态系统，加利福尼亚州可以确保这一变革性技术的安全和有益推进。
- en: Specific Sections of Concern
  id: totrans-split-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关注的具体问题部分
- en: '**Section 22602 (f)**: The definition of “covered model” is overly broad and
    could encompass a wide range of open-source models.'
  id: totrans-split-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第22602节（f）**：“覆盖模型”的定义过于宽泛，可能包括各种开源模型。'
- en: '**Section 22603 (b)**: The requirements for developers are overly burdensome
    and could discourage open-source development.'
  id: totrans-split-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第22603节（b）**：对开发者的要求过于繁重，可能会抑制开源开发。'
- en: '**Section 22606 (a)**: The potential for civil penalties could have a chilling
    effect on research and innovation.'
  id: totrans-split-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Section 11547.6 (c)(11)**: The ability to levy fees could create a barrier
    to entry for small businesses.'
  id: totrans-split-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: </main>
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
