- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 13:38:25'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 13:38:25'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: Answer.AI - SB-1047 will stifle open-source AI and decrease safety
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Answer.AI - SB-1047将抑制开源AI并降低安全性
- en: 来源：[https://www.answer.ai/posts/2024-04-29-sb1047.html](https://www.answer.ai/posts/2024-04-29-sb1047.html)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.answer.ai/posts/2024-04-29-sb1047.html](https://www.answer.ai/posts/2024-04-29-sb1047.html)
- en: <main class="content" id="quarto-document-content">
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: <main class="content" id="quarto-document-content">
- en: '*Note from Jeremy*: This is my personal submission to the authors of [bill
    SB-1047](https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047).
    It’s not an official Answer.AI statement.'
  id: totrans-split-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*Jeremy的说明*：这是我对[bill SB-1047](https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047)的个人提交，而非Answer.AI的官方声明。'
- en: 'This is a comment from Jeremy Howard regarding SB-1047\. I am an AI researcher
    and entrepreneur. I am the CEO of Answer.AI, an AI R&D lab registered to do business
    in California. I am the author of popular AI software including the fastai library,
    a widely used AI training system. I am the co-author of *Deep Learning for Coders
    with Fastai and PyTorch: AI Applications Without a PhD*, a widely-praised book
    with a 4.7 rating on Amazon based on nearly 500 reviews, and am the creator of
    the *Practical Deep Learning* series of free courses, the longest-running deep
    learning course in the world, with over 5 million views. I co-authored the paper
    [Universal Language Model Fine-tuning for Text Classification](https://arxiv.org/abs/1801.06146),
    which created the 3-stage language model pre-training and fine-tuning approach
    on which all of today’s language models (including ChatGPT and Gemini) are based.'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: '这是Jeremy Howard关于SB-1047的评论。我是一名AI研究员和企业家，也是Answer.AI的首席执行官，这是一家在加利福尼亚注册的AI研发实验室。我是多款热门AI软件的作者，包括广受欢迎的fastai库，一个广泛使用的AI训练系统的共同作者。我还是《Deep
    Learning for Coders with Fastai and PyTorch: AI Applications Without a PhD》的合著者，这本书在亚马逊上基于近500条评价获得了4.7的评分，同时也是免费课程系列《Practical
    Deep Learning》的创始人，这是世界上历时最长的深度学习课程，拥有超过500万的观看量。我还是《Universal Language Model
    Fine-tuning for Text Classification》的合著者，该论文提出了当前所有语言模型（包括ChatGPT和Gemini）基于的三阶段语言模型预训练和微调方法。'
- en: While the intent of SB-1047 to ensure the safe and secure development of AI
    is commendable, certain provisions within the bill raise serious concerns regarding
    their potential impact on open-source developers, small businesses, and overall
    innovation within the AI sector. This response aims to highlight these concerns
    and suggest alternative approaches that could achieve the desired safety goals
    without stifling the dynamism of the AI ecosystem.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管SB-1047的目的是确保AI的安全和可靠发展，但法案中的某些条款引发了对其对开源开发者、小企业以及AI行业创新总体影响的严重担忧。本回应旨在突出这些问题，并提出可能在不抑制AI生态系统动态性的前提下实现所期望的安全目标的替代方案。
- en: 'Ironically, by imposing these restrictions on open-source development, SB-1047
    could actually reduce overall safety within the AI ecosystem, in particular through
    reducing:'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 具有讽刺意味的是，通过对开源开发实施这些限制，SB-1047实际上可能会减少AI生态系统整体安全性，特别是通过以下方式：
- en: '**Transparency and Collaboration**: Open-source development fosters transparency
    and collaboration, allowing a wider range of experts to identify and address potential
    safety concerns. Restricting this open development model limits the ability of
    the broader community to contribute to safety solutions.'
  id: totrans-split-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**透明度和协作**：开源开发促进透明度和协作，允许更广泛的专家发现和解决潜在的安全问题。限制这种开发模式会减弱更广泛社区为安全解决方案做贡献的能力。'
- en: '**Diversity and Resilience**: Open-source projects contribute to a more diverse
    and resilient AI landscape. Concentrating control within a few large entities
    creates single points of failure and increases the potential for systemic risks.'
  id: totrans-split-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多样性和韧性**：开源项目有助于构建更多样化和韧性的AI生态系统。集中控制在少数大实体手中会造成单点故障，并增加系统风险的可能性。'
- en: Concerns Regarding Open-Source Development
  id: totrans-split-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对开源开发的担忧
- en: 'Open source has been a key enabler of the success of the US software industry,
    and has allowed many Americans to access critical software tools which would otherwise
    be unavailable to them. Open source has, in particular, provided many of the fundamental
    building blocks for modern artificial intelligence, and is the basis on which
    nearly all academic research (including safety and security research) is done.
    Harming open source will harm developers, consumers, academics, and obstruct the
    development of new startups. The bill would cause harm in a number of ways:'
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 开源已成为美国软件行业成功的关键推动因素，使许多美国人能够访问关键的软件工具，否则这些工具对他们来说将无法获得。特别是开源为现代人工智能的基本构建块提供了许多，并且是几乎所有学术研究（包括安全性和安全研究）的基础。损害开源将伤害开发者、消费者、学者，并阻碍新初创企业的发展。该法案将以多种方式造成伤害：
- en: '**Overly Broad Definitions**: The definition of “covered model” within the
    bill is extremely broad, potentially encompassing a wide range of open-source
    models that pose minimal risk. This could inadvertently criminalize the activities
    of well-intentioned developers working on beneficial AI projects.'
  id: totrans-split-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**定义过于宽泛**：法案中对“受覆盖模型”的定义极为宽泛，可能涵盖范围广泛的开源模型，这些模型的风险极小。这可能无意中使致力于有益AI项目的善意开发者的活动成为刑事犯罪。'
- en: '**Dual use**: An AI model is a general purpose piece of software that runs
    on a computer, much like a word processor, calculator, or web browser. The creator
    of a model can not ensure that a model is never used to do something harmful –
    any more so that the developer of a web browser, calculator, or word processor
    could. Placing liability on the creators of general purpose tools like these mean
    that, in practice, such tools can not be created at all, except by big businesses
    with well funded legal teams.'
  id: totrans-split-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**双重用途**：AI模型是在计算机上运行的通用软件，就像文字处理器、计算器或网页浏览器一样。模型的创建者无法确保模型永远不会用于有害行为 - 就像网页浏览器、计算器或文字处理器的开发者一样。将责任放在这些通用工具的创建者身上意味着实际上这些工具几乎无法被创造，除了那些拥有资金雄厚的大公司。'
- en: '**Restrictive Requirements**: The bill imposes significant burdens on developers,
    including mandatory shutdowns, extensive reporting, and compliance with potentially
    ambiguous “covered guidance.” These requirements could disproportionately impact
    open-source developers who often lack the resources of larger corporations to
    navigate complex regulatory processes.'
  id: totrans-split-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**限制性要求**：该法案对开发者施加了重大负担，包括强制关闭、广泛报告和遵守可能含糊不清的“受覆盖指导”。这些要求可能会不成比例地影响开源开发者，后者通常缺乏大公司以导航复杂监管程序所需的资源。'
- en: '**Disincentivizing Openness**: The fear of legal repercussions and bureaucratic
    hurdles could discourage open-source development, hindering the collaborative
    spirit that has been instrumental in driving AI advancements. This reduction in
    transparency could also make it more difficult to identify and address potential
    safety concerns.'
  id: totrans-split-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**削弱开放性**：对法律后果和官僚障碍的恐惧可能会抑制开源开发，阻碍推动AI进步的合作精神。透明度的降低也可能使识别和解决潜在安全问题变得更加困难。'
- en: Impact on Small Businesses and Innovation
  id: totrans-split-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对小企业和创新的影响
- en: The proposed regulations create significant barriers to entry for small businesses
    and startups looking to innovate in the AI space. The costs associated with compliance,
    coupled with the legal risks, could deter entrepreneurs and limit competition.
    This would ultimately stifle innovation and concentrate power within established
    corporations.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 提议的法规为希望在AI领域创新的小企业和初创企业设立了重大的准入壁垒。合规相关的成本以及法律风险可能会阻碍企业家，并限制竞争。这最终将扼杀创新，并使权力集中于已建立的企业。
- en: '**Barrier to Entry**: The substantial costs associated with compliance, including
    fees, audits, and legal counsel, could create a significant barrier to entry for
    small businesses and startups. This would limit competition and concentrate power
    within established corporations, ultimately hindering innovation.'
  id: totrans-split-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**准入壁垒**：与合规相关的昂贵成本，包括费用、审计和法律顾问，可能会为小企业和初创企业创建重大的准入壁垒。这将限制竞争，并最终使权力集中于已建立的企业，从而阻碍创新。'
- en: '**Chilling Effect on Research**: The fear of inadvertently triggering the bill’s
    provisions could lead researchers and developers to self-censor or avoid exploring
    promising avenues of AI research. This would stifle scientific progress and limit
    the potential of AI to address societal challenges.'
  id: totrans-split-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**对研究的抑制效应**：担心不慎触发法案条款可能会导致研究人员和开发者进行自我审查或避免探索有前景的AI研究途径。这将抑制科学进展，限制AI解决社会挑战的潜力。'
- en: '**Loss of Talent**: The restrictive environment created by the bill could drive
    talented AI researchers and developers out of California, harming the state’s
    economy and weakening its position as a leader in AI innovation.'
  id: totrans-split-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人才流失**：该法案制造的限制性环境可能会驱使有才华的AI研究人员和开发者离开加利福尼亚州，损害该州经济，并削弱其在AI创新方面的地位。'
- en: California plays a critical role in driving US innovation, particularly in the
    technology sector. By placing undue burdens on AI development, SB-1047 risks hindering
    the state’s leadership in this crucial field. This could have ripple effects throughout
    the US, slowing down overall progress in AI research and development.
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: 加利福尼亚州在推动美国创新中扮演着关键角色，尤其是在技术领域。通过对AI开发施加不当负担，SB-1047法案存在的风险在于阻碍该州在这一关键领域的领导地位。这可能会对整个美国产生涟漪效应，减缓AI研究与开发的总体进展。
- en: Alternative Approaches
  id: totrans-split-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 替代方法
- en: Instead of focusing on regulating AI model development, I urge you to consider
    alternative approaches that address the actual risks associated with AI applications.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我建议您不要专注于规范AI模型的开发，而是考虑解决与AI应用实际风险相关的替代方法。
- en: '**Support Open-Source Development**: Encourage and facilitate the open-source
    development of AI models to foster collaboration, transparency, and a more diverse
    and resilient AI ecosystem.'
  id: totrans-split-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**支持开源开发**：鼓励并促进AI模型的开源开发，以促进协作、透明度和更多样化、更具韧性的AI生态系统。'
- en: '**Focus on Usage, Not Development**: Instead of regulating the development
    of AI models, the focus should be on regulating their applications, particularly
    those that pose high risks to public safety and security. Regulate the use of
    AI in high-risk areas such as healthcare, criminal justice, and critical infrastructure,
    where the potential for harm is greatest, would ensure accountability for harmful
    use, whilst allowing for the continued advancement of AI technology.'
  id: totrans-split-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专注于使用而非开发**：与其规范AI模型的开发，不如专注于规范其应用，特别是那些对公共安全和安全性造成高风险的领域。在医疗保健、刑事司法和关键基础设施等高风险领域规范AI的使用，将确保对有害使用的问责，同时允许AI技术的持续发展。'
- en: '**Promote Transparency and Collaboration**: Encourage the development and adoption
    of best practices for responsible AI development through collaboration between
    industry, academia, and government. This could involve creating industry standards,
    fostering open-source development, and investing in AI safety research.'
  id: totrans-split-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**促进透明度和协作**：通过行业、学术界和政府之间的协作，鼓励负责任的AI开发最佳实践的制定与采纳。这可能涉及制定行业标准、促进开源开发和投资于AI安全研究。'
- en: '**Invest in AI Expertise**: Provide resources to government agencies to develop
    expertise in AI and build capacity to effectively monitor and address potential
    risks. This would enable a more informed and nuanced approach to AI regulation
    that balances safety with innovation.'
  id: totrans-split-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**投资于AI专业知识**：为政府机构提供资源，以发展AI专业知识，并建立有效监测和应对潜在风险的能力。这将使AI监管更为知情和细致，平衡安全与创新。'
- en: Conclusion
  id: totrans-split-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: California has a unique opportunity to lead the way in responsible AI development.
    However, SB-1047, in its current form, risks stifling innovation and undermining
    the state’s leadership in AI. By adopting alternative approaches that prioritize
    accountability for harmful use while fostering a vibrant and open AI ecosystem,
    California can ensure the safe and beneficial advancement of this transformative
    technology.
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 加利福尼亚州有机会在负责任的AI发展方面走在前列。然而，目前的SB-1047法案存在的风险在于抑制创新，削弱了该州在AI领域的领导地位。通过采纳优先考虑有害使用责任的替代方法，同时促进充满活力和开放的AI生态系统，加利福尼亚州可以确保这一变革性技术的安全和有益推进。
- en: Specific Sections of Concern
  id: totrans-split-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关注的具体问题部分
- en: '**Section 22602 (f)**: The definition of “covered model” is overly broad and
    could encompass a wide range of open-source models.'
  id: totrans-split-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第22602节（f）**：“覆盖模型”的定义过于宽泛，可能包括各种开源模型。'
- en: '**Section 22603 (b)**: The requirements for developers are overly burdensome
    and could discourage open-source development.'
  id: totrans-split-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第22603节（b）**：对开发者的要求过于繁重，可能会抑制开源开发。'
- en: '**Section 22606 (a)**: The potential for civil penalties could have a chilling
    effect on research and innovation.'
  id: totrans-split-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第22606节（a）**：对民事处罚的潜在可能性可能会对研究和创新产生冷却效应。'
- en: '**Section 11547.6 (c)(11)**: The ability to levy fees could create a barrier
    to entry for small businesses.'
  id: totrans-split-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第11547.6节（c）（11）**：征收费用的能力可能会对小企业的进入构成障碍。'
- en: </main>
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
  zh: </main>
