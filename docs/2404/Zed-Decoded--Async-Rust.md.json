["```\nfn show_cursor_names(&mut self, cx: &mut ViewContext<Self>) {\n self.show_cursor_names = true;\n cx.notify();\n cx.spawn(|this, mut cx| async move {\n cx.background_executor().timer(CURSORS_VISIBLE_FOR).await;\n this.update(&mut cx, |this, cx| {\n this.show_cursor_names = false;\n cx.notify()\n })\n .ok()\n })\n .detach();\n}\n```", "```\nlet ex = Executor::new();\nex.spawn(async {\n loop {\n Timer::after(Duration::from_secs(1)).await;\n }\n})\n.detach();\n```", "```\n// crates/gpui/src/app.rs\n\nimpl AppContext {\n pub fn background_executor(&self) -> &BackgroundExecutor {\n &self.background_executor\n }\n\n pub fn foreground_executor(&self) -> &ForegroundExecutor {\n &self.foreground_executor\n }\n\n /// Spawns the future returned by the given function on the thread pool. The closure will be invoked\n /// with [AsyncAppContext], which allows the application state to be accessed across await points.\n pub fn spawn<Fut, R>(&self, f: impl FnOnce(AsyncAppContext) -> Fut) -> Task<R>\n where\n Fut: Future<Output = R> + 'static,\n R: 'static,\n {\n self.foreground_executor.spawn(f(self.to_async()))\n }\n\n // [...]\n}\n```", "```\n// crates/gpui/src/executor.rs\n\nimpl ForegroundExecutor {\n /// Enqueues the given Task to run on the main thread at some point in the future.\n pub fn spawn<R>(&self, future: impl Future<Output = R> + 'static) -> Task<R>\n where\n R: 'static,\n {\n let dispatcher = self.dispatcher.clone();\n fn inner<R: 'static>(\n dispatcher: Arc<dyn PlatformDispatcher>,\n future: AnyLocalFuture<R>,\n ) -> Task<R> {\n let (runnable, task) = async_task::spawn_local(future, move |runnable| {\n dispatcher.dispatch_on_main_thread(runnable)\n });\n runnable.schedule();\n Task::Spawned(task)\n }\n inner::<R>(dispatcher, Box::pin(future))\n }\n\n // [...]\n}\n```", "```\n// crates/gpui/src/platform/mac/dispatcher.rs\n\nimpl PlatformDispatcher for MacDispatcher {\n fn dispatch_on_main_thread(&self, runnable: Runnable) {\n unsafe {\n dispatch_async_f(\n dispatch_get_main_queue(),\n runnable.into_raw().as_ptr() as *mut c_void,\n Some(trampoline),\n );\n }\n }\n // [...]\n}\n\nextern \"C\" fn trampoline(runnable: *mut c_void) {\n let task = unsafe { Runnable::<()>::from_raw(NonNull::new_unchecked(runnable as *mut ())) };\n task.run();\n}\n```", "```\nimpl PlatformDispatcher for MacDispatcher {\n fn dispatch(&self, runnable: Runnable, _: Option<TaskLabel>) {\n unsafe {\n dispatch_async_f(\n dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_HIGH.try_into().unwrap(), 0),\n runnable.into_raw().as_ptr() as *mut c_void,\n Some(trampoline),\n );\n }\n }\n}\n```", "```\n// crates/terminal/src/terminal.rs\n\npub struct Terminal {\n term: Arc<Mutex<alacritty_terminal::Term<ZedListener>>>,\n\n // [... other fields ...]\n}\n\npub fn find_matches(\n &mut self,\n mut searcher: RegexSearch,\n cx: &mut ModelContext<Self>,\n) -> Task<Vec<RangeInclusive<AlacPoint>>> {\n let term = self.term.clone();\n cx.background_executor().spawn(async move {\n let term = term.lock();\n\n all_search_matches(&term, &mut searcher).collect()\n })\n}\n```", "```\n// crates/project/src/project.rs\n\n// Spawn a Task on the background executor. The Task finds all files on disk\n// that contain >1 matches for the given `query` and sends them back over\n// the `matching_paths_tx` channel.\nlet (matching_paths_tx, matching_paths_rx) = smol::channel::bounded(1024);\ncx.background_executor()\n .spawn(Self::background_search(\n // [... other arguments ... ]\n query.clone(),\n matching_paths_tx,\n ))\n .detach();\n\n// Setup a channel on which we stream results to the UI.\nlet (result_tx, result_rx) = smol::channel::bounded(1024);\n\n// On the main thread, spawn a Task that first...\ncx.spawn(|this, mut cx| async move {\n // ... waits for the background thread to return the filepaths of\n // the maximum number of files that we want to search...\n let mut matching_paths = matching_paths_rx\n .take(MAX_SEARCH_RESULT_FILES + 1)\n .collect::<Vec<_>>()\n .await;\n\n // ... then loops over the filepaths in chunks of 64...\n for matching_paths_chunk in matching_paths.chunks(64) {\n let mut chunk_results = Vec::new();\n\n for matching_path in matching_paths_chunk {\n // .... opens each file....\n let buffer = this.update(&mut cx, |this, cx| {\n this.open_buffer((*worktree_id, path.clone()), cx)\n })?;\n\n // ... and pushes into `chunk_results` a Task that\n // runs on the main thread and ...\n chunk_results.push(cx.spawn(|cx| async move {\n // ... waits for the file to be opened ...\n let buffer = buffer.await?;\n // ... creates a snapshot of its contents ...\n let snapshot = buffer.read_with(&cx, |buffer, _| buffer.snapshot())?;\n // ... and again starts a Task on the background executor,\n // which searches through the snapshot for all results.\n let ranges = cx\n .background_executor()\n .spawn(async move {\n query\n .search(&snapshot, None)\n .await\n .iter()\n .collect::<Vec<_>>()\n })\n .await;\n\n Ok((buffer, ranges))\n }));\n }\n\n // On the main thread, non-blocking, wait for all buffers to be searched...\n let chunk_results = futures::future::join_all(chunk_results).await;\n for result in chunk_results {\n if let Some((buffer, ranges)) = result.log_err() {\n // send the results over the results channel\n result_tx\n .send(SearchResult::Buffer { buffer, ranges })\n .await?;\n }\n }\n }\n})\n.detach();\n\nresult_rx\n```"]