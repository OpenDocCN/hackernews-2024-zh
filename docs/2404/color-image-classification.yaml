- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 13:06:56'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 13:06:56'
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: color image classification
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 彩色图像分类
- en: 来源：[https://www.rrighart.com/blog-color-tags.html](https://www.rrighart.com/blog-color-tags.html)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://www.rrighart.com/blog-color-tags.html](https://www.rrighart.com/blog-color-tags.html)
- en: Tags or labels are very useful for finding pictures on the web. Color tags are
    used in e-commerce applications, where these tags can select between products,
    for example green or red shoes.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
  zh: 标签或标签在网上查找图片时非常有用。颜色标签在电子商务应用中使用，这些标签可以在产品之间进行选择，例如绿色或红色的鞋子。
- en: To make a search engine work, each image needs to have tags in its metadata.
    This can be done using machine learning. But why would you use an algorithm if
    you can label images by hand?
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
  zh: 要使搜索引擎工作，每张图像的元数据都需要有标签。这可以通过机器学习来实现。但是，如果可以手动标记图像，为什么还要使用算法呢？
- en: If you have only 100 photos, manual labelling is no problem.
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果只有100张照片，手动标记不成问题。
- en: However, if you have 100 new photos every day or every hour, the repeated task
    of labelling becomes cumbersome.
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果每天或每小时有100张新照片，那么重复标记的任务变得繁琐。
- en: Automating this process using machine learning would save a lot of human effort
    that instead can be spent on other relevant tasks. In addition, it will take away
    the subjective bias and errors in judging colors. Actually, individual and gender
    differences have been found in the way humans perceive, name and classify colors,
    and there are as well discrepancies in color classification between speakers of
    different languages
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
  zh: 使用机器学习自动化此过程将节省大量人力，并可用于其他相关任务。此外，这将消除主观偏见和颜色判断中的错误。实际上，已发现个体和性别在人类感知、命名和分类颜色方面存在差异，并且不同语言的讲话者在颜色分类上也存在差异。
- en: '[1, 2]'
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[1, 2]'
- en: . Not to mention that 8% of men and 0.5% of women suffer from color vision deficiency
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
  zh: . 更不用说8%的男性和0.5%的女性患有色觉缺陷
- en: '[3]'
  id: totrans-split-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[3]'
- en: .
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
  zh: 。
- en: Automating classification by a system is not a walk in the park. There are in
    fact a number of conditions that hinder product color classification by machine
    learning.
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通过系统自动分类并不是一帆风顺的事情。事实上，有许多条件阻碍了机器学习对产品颜色进行分类。
- en: First, photos have different visual quality such as brightness, contrast and
    saturation. The training set should account for these differences. If the photos
    used for training were taken inside, there is a risk that the model will not recognize
    photos that were taken outside since several conditions  may differ (light, shadow).
    In other words, the testset (or data in production) should mirror those used during
    training.
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，照片的视觉质量有所不同，如亮度、对比度和饱和度。训练集应考虑这些差异。如果用于训练的照片是在室内拍摄的，那么有可能模型无法识别在室外拍摄的照片，因为条件可能不同（光线、阴影）。换句话说，测试集（或生产数据）应反映训练中使用的数据。
- en: Second, there are a wide variety of product classes such as cars, clothing,
    furniture etc. depending on the kind of e-commerce shop you run. The question
    is how much product variety a model should account for during color tagging.
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，根据您运营的电子商务店铺类型，产品类别种类多种多样，如汽车、服装、家具等。问题是在颜色标记过程中模型应考虑多少种产品种类。
- en: Third, there is a large diversity of colors that exist in the world and one
    needs to select which classes need to be recognized by the system. For example,
    the principal colors green and blue seem obvious choices but what about the color
    called turquoise that is inbetween green and blue? Therefore, a careful examination
    of the production context is needed.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，世界上存在大量的颜色，需要选择系统需要识别的哪些类别。例如，主要的颜色绿色和蓝色似乎是显而易见的选择，但是介于绿色和蓝色之间的颜色称为绿松石色，那该如何处理？因此，需要对生产环境进行仔细的检查。
- en: Even though it is not a walk in the park, we can come a long way if we persist.
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这不是一帆风顺的事情，但如果我们坚持下去，我们可以走得更远。
- en: Using the Vehicle color dataset
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 使用车辆颜色数据集
- en: '[5]'
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[5]'
- en: ', I have been able to create a machine learning model that is pretty well able
    to classify colors of products. The script is freely available at Kaggle. The
    underlying model was trained using a basic Convolutional Neural Network and an
    EfficientNet, with the latter giving slightly better results.'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: ', 我已经能够创建一个能够相当好地分类产品颜色的机器学习模型。该脚本可以在Kaggle上免费获取。底层模型是使用基本的卷积神经网络和EfficientNet进行训练的，后者的效果略好一些。'
- en: As you will see, some of the tag names seem very specific for cars, such as
    tan and gold. On the other hand, testing it on other non-vehicle product categories
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
- en: '[6]'
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
- en: ', the color classifier seems to be doing a pretty good job. I however need
    to test this more extensively.'
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
- en: To see the results in an interface, I have created an App where you can play
    with your own pictures (
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/code/rrighart/the-prediction-of-color-tags/data](https://www.kaggle.com/code/rrighart/the-prediction-of-color-tags/data)'
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
- en: ). This App was built mainly to interact with the model. In production, probably
    it is best to integrate the model in a data pipeline. This would rapidly tag a
    large batch of new pictures and store the tags in a database.
  id: totrans-split-28
  prefs: []
  type: TYPE_NORMAL
- en: Please feel free to share your ideas or send any questions!
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
- en: '**Contact**'
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
- en: Ruthger Righart
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
- en: Self-employed data scientist in machine learning and computer vision
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
- en: 'Email: rrighart@googlemail.com'
  id: totrans-split-33
  prefs: []
  type: TYPE_NORMAL
- en: 'Web: [https://www.rrighart.com](https://www.rrighart.com)**References**'
  id: totrans-split-34
  prefs: []
  type: TYPE_NORMAL
- en: 1\.
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
- en: 'In the eye of the beholder : is color classification consistent among human
    observers ?[https://onlinelibrary.wiley.com/doi/full/10.1002/ece3.8093](https://onlinelibrary.wiley.com/doi/full/10.1002/ece3.8093)'
  id: totrans-split-36
  prefs: []
  type: TYPE_NORMAL
- en: '2\. Differences in color categorization manifested by males and females : a
    quantitative World Color Survey study.'
  id: totrans-split-37
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.nature.com/articles/s41599-019-0341-7](https://www.nature.com/articles/s41599-019-0341-7)'
  id: totrans-split-38
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Colour blindness.
  id: totrans-split-39
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.nhs.uk/conditions/colour-vision-deficiency/](https://www.nhs.uk/conditions/colour-vision-deficiency/)'
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Kaggle page.
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/code/rrighart/the-prediction-of-color-tags/data](https://www.kaggle.com/code/rrighart/the-prediction-of-color-tags/data)'
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
- en: .
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
- en: 5\. VCoR.
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/datasets/landrykezebou/vcor-vehicle-color-recognition-dataset](https://www.kaggle.com/datasets/landrykezebou/vcor-vehicle-color-recognition-dataset)'
  id: totrans-split-45
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Fashion Product Images.
  id: totrans-split-46
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-small](https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-small)'
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
- en: 'App:'
  id: totrans-split-48
  prefs: []
  type: TYPE_NORMAL
- en: '[https://huggingface.co/spaces/rrighart/color-tags](https://huggingface.co/spaces/rrighart/color-tags)'
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
- en: 'Kaggle notebook:'
  id: totrans-split-50
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.kaggle.com/code/rrighart/the-prediction-of-color-tags](https://www.kaggle.com/code/rrighart/the-prediction-of-color-tags)'
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
