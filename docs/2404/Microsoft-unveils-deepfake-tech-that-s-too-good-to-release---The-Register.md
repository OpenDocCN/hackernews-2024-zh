<!--yml

category: 未分类

date: 2024-05-27 13:21:39

-->

# Microsoft公布了过于出色而不愿公开发布的深度伪造技术 • The Register

> 来源：[https://www.theregister.com/2024/04/20/microsoft_deepfake_vasa/](https://www.theregister.com/2024/04/20/microsoft_deepfake_vasa/)

Microsoft本周演示了VASA-1，这是一个从静态图像、音频样本和文本脚本创建说话视频的框架，并声明 - 正确地说 - 这种技术太危险，不能公开发布。

这些AI生成的视频中，人们可以以逼真的动画形象来说克隆声音的脚本话语，正是美国联邦贸易委员会上个月[警告过的](https://www.ftc.gov/business-guidance/blog/2023/03/chatbots-deepfakes-voice-clones-ai-deception-sale)，此前[提出的一项规定](https://www.ftc.gov/news-events/news/press-releases/2024/02/ftc-proposes-new-protections-combat-ai-impersonation-individuals)以防止AI技术被用于模拟欺诈。

Microsoft的团队在他们的[公告](https://www.microsoft.com/en-us/research/project/vasa-1/)中承认了这一点，解释称由于伦理考量而不会发布该技术。他们坚称他们正在呈现用于生成虚拟互动角色的研究，而不是冒充任何人。因此，没有计划推出产品或API。

"我们的研究侧重于为虚拟AI化身生成视觉情感技能，旨在实现积极应用，"Redmond的专家说。"我们的目标不是创造用于误导或欺骗的内容。"

"然而，就像其他相关的内容生成技术一样，它仍然有可能被滥用来冒充人类。我们反对任何创建误导性或有害真实人物内容的行为，并有意将我们的技术应用于进步伪造检测。"

Token主席Kevin Surace，一个生物识别认证企业和频繁在生成AI上发表演讲的演讲者，在电子邮件中告诉*The Register*说，虽然以前已经有过从静态框架和克隆声音文件动画化面孔的技术演示，但Microsoft的演示反映了最先进的技术水平。

"个性化电子邮件和其他业务大规模通信的潜力是极好的，"他认为。"甚至还可以为老照片添加动画效果。从某种程度上说，这既有趣又具有我们未来数月和数年内都会使用的坚实业务应用。"

在2019年，网络安全公司Deeptrace评估显示，深度伪造的"乐趣"96%都是非自愿的色情内容，详见[报告](https://regmedia.co.uk/2019/10/08/deepfake_report.pdf) [PDF]。

尽管如此，Microsoft的研究人员指出，能够创造逼真的人物并让他们开口说话具有积极的用途。

他们在一篇[研究论文](https://arxiv.org/abs/2404.10667)中提出：“这种技术有望丰富数字通信，增加那些有沟通障碍的人士的可访问性，转变教育，交互式AI辅导方法，并在医疗保健中提供治疗支持和社交互动。”该论文未包含“色情”或“虚假信息”等词语。

虽然可以争论AI生成的视频与深度伪造图像不完全相同，后者由数字操控而非生成方法[定义](https://www.oed.com/dictionary/deepfake_n)，但当一个令人信服的伪造品可以在没有剪贴接合的情况下被制造出来时，这种区别就变得无关紧要了。

当被问及微软之所以不将这项技术公开出售的看法时，Surace对限制措施的可行性表示怀疑。

他说：“微软和其他公司目前都在观望，直到他们解决了隐私和使用问题。”“谁来规定这项技术只能出于正确的原因使用？”

Surace补充说，已经有类似复杂的开源模型，指向[EMO](https://humanaigc.github.io/emote-portrait-alive/)。他观察到：“人们可以从GitHub上提取源代码，并构建一个围绕它的服务，这个服务可以媲美微软的输出。”由于这个领域的开源特性，无论如何都将无法对其进行有效监管。

各国正在努力监管AI生成的人物。[加拿大](https://www.justice.gc.ca/eng/rp-pr/other-autre/cndii-cdncii/p6.html)，[中国](https://www.nature.com/articles/s42256-022-00513-4)，以及[英国](https://www.legislation.gov.uk/ukpga/2023/50/enacted)，以及其他国家，都有可以适用于深度伪造技术的法规，其中一些法规实现了更广泛的政治目标。英国本周刚刚[宣布](https://www.gov.uk/government/news/government-cracks-down-on-deepfakes-creation)未经同意创建涉及性内容的深度伪造图像属于违法行为。在英国的2023年网络安全法案下，分享这类图像本来就是被禁止的。

在一月份，一群美国跨党派的议员[提出了](https://www.theregister.com/2024/01/31/ai_defiance_act/)2024年《对抗深度伪造图像和非同意编辑法案》（DEFIANCE法案），该法案为非同意深度伪造图像的受害者提供了在法庭上提起民事索赔的途径。

而在4月16日星期二，美国参议院司法委员会隐私、技术和法律小组委员会举行了一场名为“AI监管：选举深度伪造”的[听证会](https://www.judiciary.senate.gov/committee-activity/hearings/oversight-of-ai-election-deepfakes)。

在准备好的发言中，DeepMedia公司的首席执行官Rijul Gupta表示：

但是想象一下市场应用。®
