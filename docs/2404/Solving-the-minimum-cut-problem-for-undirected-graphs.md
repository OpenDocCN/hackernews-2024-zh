<!--yml
category: 未分类
date: 2024-05-27 13:16:40
-->

# Solving the minimum cut problem for undirected graphs

> 来源：[https://research.google/blog/solving-the-minimum-cut-problem-for-undirected-graphs/](https://research.google/blog/solving-the-minimum-cut-problem-for-undirected-graphs/)

A [graph](https://en.wikipedia.org/wiki/Graph_(discrete_mathematics)) is a ubiquitous data structure used in computer science that consists of nodes (or vertices) and edges between pairs of nodes to capture objects and their relations. The [minimum cut problem](https://en.wikipedia.org/wiki/Minimum_cut) (often referred to as “min-cut”) is a basic structural question about the connectivity of a graph that asks: what is the least expensive way to disconnect a network? More formally, given an input graph where edges have [no orientation](https://en.wikipedia.org/wiki/Orientation_(graph_theory)) (i.e., the graph is *undirected*) and are associated with positive weights quantifying the importance of the edges (e.g., capacity of a road, or strength of a relationship, level of similarity between the endpoints, etc.), a cut is a partition of the nodes into two sides. The size of a cut is the total weight of edges connecting nodes on different sides of the cut, and the min-cut problem is to find a cut of the minimum size.

Solving it efficiently has been one of the most fundamental problems in algorithmic graph theory. Moreover, min-cut has diverse applications in practice such as image restoration, stereo and segmentation in computer vision, and network resilience analysis (such as for roads or power grids). It is also generally very useful when the underlying graph data is too large and needs to be partitioned into smaller components to be processed in a divide-and-conquer manner.

In the theory of algorithm design, the [asymptotic complexity](https://en.wikipedia.org/wiki/Asymptotic_computational_complexity) for any problem that requires reading the entire input (which is the case for min-cut) is at least linear in the size of the input (since that is the time needed to read the input). A [nearly-linear time](https://web.eecs.umich.edu/~gurevich/Opera/82.pdf) algorithm essentially achieves this lower-bound, and thus is canonically viewed as the optimal result one can achieve. For the min-cut problem, existing nearly-linear time algorithms are either randomized (which may output an incorrect answer with some probability) or only work for the special case when the graph is [simple](https://mathworld.wolfram.com/SimpleGraph.html) (which cannot model many real-world applications), so its optimal complexity remains an open problem.

In “[Deterministic Near-Linear Time Minimum Cut in Weighted Graphs](https://epubs.siam.org/doi/10.1137/1.9781611977912.111)”, which co-won the best paper award at the ACM-SIAM Symposium on Discrete Algorithms ([SODA2024](https://www.siam.org/conferences/cm/conference/soda24)), we design the first nearly-linear algorithm for the min-cut problem that is deterministic (i.e., always finds the correct answer) and that also works for general graphs, thus settling the optimal complexity for the min-cut problem.