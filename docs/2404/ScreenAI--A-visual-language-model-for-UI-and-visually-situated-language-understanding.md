<!--yml
category: 未分类
date: 2024-05-27 13:03:11
-->

# ScreenAI: A visual language model for UI and visually-situated language understanding

> 来源：[https://research.google/blog/screenai-a-visual-language-model-for-ui-and-visually-situated-language-understanding/](https://research.google/blog/screenai-a-visual-language-model-for-ui-and-visually-situated-language-understanding/)

*This project is the result of joint work with Maria Wang, Fedir Zubach, Hassan Mansoor, Vincent Etter, Victor Carbune, Jason Lin, Jindong Chen and Abhanshu Sharma. We thank Fangyu Liu, Xi Chen, Efi Kokiopoulou, Jesse Berent, Gabriel Barcik, Lukas Zilka, Oriana Riva, Gang Li,Yang Li, Radu Soricut, and Tania Bedrax-Weiss for their insightful feedback and discussions, along with Rahul Aralikatte, Hao Cheng and Daniel Kim for their support in data preparation. We also thank Jay Yagnik, Blaise Aguera y Arcas, Ewa Dominowska, David Petrou, and Matt Sharifi for their leadership, vision and support. We are very grateful toTom Small for helping us create the animation in this post.*