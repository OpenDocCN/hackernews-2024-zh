<!--yml

category: 未分类

date: 2024-05-27 13:32:06

-->

# 拼命试图理解咖啡末日论证

> 来源：[https://www.astralcodexten.com/p/desperately-trying-to-fathom-the](https://www.astralcodexten.com/p/desperately-trying-to-fathom-the)

对人工智能安全性的最常见的论点之一是：

> 这里有一个例子，有人担心某事情，但没发生。因此，你担心的人工智能也不会发生。

我总是给出显而易见的答案：“好吧，但还有其他例子，有时候有人担心某事情，*结果*发生了，对吧？我们怎么知道人工智能不更像那些情况呢？” 我与之争论的人总是对这个回答感到非常惊讶，仿佛我在摧毁他们美好的论点时犯了某种背叛行为。

前一百次这种情况发生时，我以为我一定是误解了什么。毕竟，“我能想到一件事情没发生，所以什么也不会发生”是如此明显的逻辑谬误，以至于没有人会愚蠢到会中招。但人们一遍又一遍地提出这个论点。非常聪明的人，我其他方面尊重的人，他们提出这个论点，并真诚地期望它能说服人们！

通常那些没有发生的事情是人口过剩、全球变冷等等。但最近大多数是某种咖啡末日的情况：

你可以[在这里阅读完整的讨论](https://twitter.com/Dan_Jeffries1/status/1741445839053025450)，但我警告你，内容基本上是“有一次人们担心咖啡，但现在我们知道咖啡是安全的。因此人工智能也会安全无虞。”

我一直试图加强这个论点，但它总是抵抗我的加强。例如：

+   或许这个论点是对“大多数技术不会出错”的一个失败尝试？但人们用不是技术的东西做同样的论据，比如全球变冷或人口过剩。

+   或许这个论点是对“世界从未被毁灭过，所以末日预言的记录很糟糕”原则的失败尝试？但人口过剩和全球变冷并没有声称每个人都会死 - 只是会有很多人。并且关于大规模死亡事件的许多预言已经成真（例如黑死病、第二次世界大战、艾滋病）。但这一切都无法解释咖啡啊！

因此，我字面上的、非修辞的问题是：“有谁会愚蠢到认为这有道理呢？” 我并不（只）是想侮辱说这些话的人；我认为他们的存在是一个真正的哲学之谜。在某种意义上，这难道不和说（例如）没有不同吗：

> 我曾经听说过一个愚蠢的人认为大比目鱼不是一种鱼 - 但是天哪，那个人肯定是错的。因此，人工智能也是一种鱼。

咖啡版本是：

> 我曾经听说过一个愚蠢的人认为咖啡会引发很多问题 - 但是天哪，那个人肯定是错的。因此，人工智能也不会引发很多问题。

没有人会认真对待它的比目鱼形式。那么将它重塑为关于咖啡的部分是什么让它更可信？

每当我想知道有人怎么能如此愚蠢时，我首先会问自己，是否在其他情况下我自己也正是如此愚蠢。这次，我记起了斯图尔特·拉塞尔（Stuart Russell）支持AI风险的论据之一。[他指出](https://www.edge.org/response-detail/26157)，物理学家欧内斯特·卢瑟福在亚历山大·西拉德（Szilard）发现核链反应秘密不到二十四小时前宣称核链反应不可能。当时，我认为这是一个有趣而有用的警告，提醒我们不要太过肯定超智能不可能。

但这难道不是与咖啡末日论证相同的论点吗？一个敌对的重新表述可能是：

> 至少有一件事是可能的。因此，超智能AI也是可能的。

并且稍微少一些敌对的重新表述：

> 人们在宣称核反应不可能时是错误的。因此，他们在宣称超智能AI可能时也可能是错误的。

这比咖啡末日论证有何优势？事实上，这比比目鱼论证又更好在哪里？我们在做这些论证时究竟在做什么？

一些想法：

**作为存在的证明？**

当我思考为什么我欣赏拉塞尔教授的论点时，不是因为它是超智能可能性的完全证明。它更像是一个谦卑的论据。“你可能认为这是不可能的。但考虑到至少有一个案例是人们认为不可能却被证明错了，你应该相信它至少是可能的。”

但首先，一个案例不应证明任何事情。如果你怀疑自己会中彩票，我无法通过举出一个中奖者的案例来证明你错了 - 即使在弱、概率化的方式上也不行。我甚至不能证明你应该谦卑 - 你完全可以自负、非常自信地相信你不会中奖！

而且，存在的证明只能让你*稍微*更谦卑一点。它们可以驳斥“我绝对、百分之百确定AI是/不是危险”的说法。但并不是很多人会这样说，怀疑你的对手这样做是[不友善的](https://slatestarcodex.com/2013/06/13/arguments-from-my-opponent-believes-something/)。

或许这场辩论会演变成关于[安全不确定性谬误](https://www.astralcodexten.com/p/mr-tries-the-safe-uncertainty-fallacy)的辩论，一些人认为，如果某事有任何不确定性，你必须假设它完全安全和良好（不，我也不理解），而另一些人认为，如果灾难发生的可能性仅有1%，你就必须将其乘以灾难的规模，最终会非常担忧（在极端情况下，这变成了帕斯卡推理，但没有人能清楚定义何时开始极端情况）。

我仍然认为，证明你的对手在理论上可能是错的存在证明并不远。不过，这基本上是我试图通过这里的双轨水坝例子来做的事情 - 展示一种论证线路有时可能是错误的，这种方式迫使人们尝试更复杂的方法。

**作为触发启发式的尝试？**

也许罗素教授的论点暗示着每个人都有关于失败预测的大量知识 - 比如没有重于空气的飞行器是可能的，可能世界市场上只有五台计算机。你可以将这个特定的预测错误的例子视为试图激活人们已有的记忆库，*很多时候*人们的预测都是错误的。

你可以对咖啡末日做出同样的论点。“人们担心咖啡，但其实没事”，意在激活你心中存储的一长串道德恐慌案例 - 如大麻、暴力视频游戏等，足以提醒你，*很多时候*人们担心的事情其实都是虚惊一场。

但是 - 即使承认这两者有很多案例 - 这些有用吗？有很多道德恐慌最终证明是无中生有。但也有很多道德恐慌最终证明是真实的，或者人们没有担心他们应该担心的事情。人们对烟草没怎么担心，然后它杀死了很多人。人们对汽油中的铅没怎么担心，然后它毒害了很多儿童。人们对全球变暖、奥斯康丁、基地组织、前第一次世界大战欧洲体系的国际紧张局势等没怎么担心，直到这些事情已经失控并伤害了很多人。我们甚至有专门描述这种不听警告的失败的词语和成语 - 就像鸵鸟把头埋在沙子里一样。

（而有很多例子表明，人们预测某些事情是不可能的，而这确实是不可能的，如永动机）。

为了有效地调用启发式（“记住我们都同意是坏的那些道德恐慌的所有案例？那么你应该假设这也可能是一种道德恐慌”），你需要建立道德恐慌比鸵鸟把头埋进沙子更普遍的事实。并且为了有效地反驳预测某事是不可能的启发式，你需要建立失败的不可能性证明比准确的更普遍的事实。

这似乎介于“没有人做到”和“从原理上讲不可能”的地方。坚持这一点将消除90%以上的言论。

参见也[关于偏见论证的警告](https://slatestarcodex.com/2019/07/17/caution-on-bias-arguments/)，在那里我试图表达同样的观点。我认为你可以重新写这一节，让它关于提出的偏见论点（“人们对过度担心的事情有已知的偏见，所以我们应该进行修正”）。但像往常一样，你可以假设一个相反的偏见（“人们有一个已知的偏见，他们把头埋在沙子里，忽视那些令人害怕或昂贵修复的问题”），弄清楚你需要纠正哪一个对立的偏见，这与决定你需要调用哪一个对立的启发式是相同的问题。

**什么是证据？**

假设有人试图为某个特定观点辩护，比如“俄罗斯将赢得与乌克兰的战争”。他们提出了一些证据，比如“俄罗斯有一些非常好的坦克。”

很明显，仅凭这一点并不能证明什么。俄罗斯可能有好的坦克，但乌克兰在其他方面可能更出色。

但是，*任何*量的证据又如何证明一个论点呢？你可以做一百个类似的声明：“俄罗斯有好坦克”，“俄罗斯有好的运兵船”，“西部战区第四区的俄罗斯将军非常有能力”[...]，并且遇到完全相同的问题。但是一个论证俄罗斯会赢得战争的论点必须由若干证据片段组成。那么它如何能够奏效呢？

我认为它必须携带一个隐含的假设“…而且你很擅长权衡证据足以证明某事的量，其他的事情也相当，所以这足以让你相信我的观点。”

例如，如果有人说“俄罗斯会赢，因为他们的兵力是乌克兰的三倍，并且有更好的将军”（然后证明这是真的），这至少似乎是一个不应立即被忽视的合理论据。大家都知道兵力优势是一个很大的优势，有优秀的将军也是如此。这带有一个暗示，“当然，乌克兰没有其他优势来抵消这两个”。但这可能是如此合理，以至于我们接受它（很难抵消三倍的人力优势）。或者它可能对亲乌克兰的人构成挑战（如果你不能说出一些你一方的优势，听起来像这些一样令人信服，那么我们就赢了）。

有人认为俄罗斯会赢，并且长时间讨论过这个问题，所以写一篇关于好坦克的文章是合理的，而不明言“显然这只是我认为俄罗斯会赢的一个部分，不能单独说服任何人；不过，请在这一点上更新一下，并且当你继续前进并遇到其他问题时，你可能会更新更多。”

那些谈论咖啡的人是这么做的吗？

一个反对的论点：你至少应该稍微更新一下对好坦克的看法，对吧？但是咖啡的事情实际上什么也没证明。这只证明了有一次人们担心了一个坏事情，然后它没有发生。你肯定已经知道至少会有一次这样的情况发生！

一个支持的论点：假设有一百种与“拥有好坦克”同等重要的战争要素。如果两个竞争对手相对均衡，其中一个在所有100个要素上都更优秀，另一个都为0，这将是不太可能的。因此，“俄罗斯拥有好坦克”告诉你的只是俄罗斯在至少一个方面更优秀，这是你本来就可以预测到的。这比咖啡情况更像是一个更新吗？

我的提议答案：如果你知道提出论点的人刻意寻找亲俄论据，那么“拥有好坦克”几乎不会给你带来任何更新 - 它只会让你相信俄罗斯在100个领域中至少在一个方面更优秀。如果你认为他们相对公正，只是碰巧发现了这些信息，那么它会稍微更新你的看法（我们已选择一个随机选中的要素，而俄罗斯更胜一筹）。

如果你认为提出咖啡论点的人正在做一个关于所有人们何时担心过的不偏不倚的调查，那么咖啡的事实（在这个特定时间人们担心了，但其实是多余的）可能会感觉像是取样一个随机点。但是我们对于事物是危险还是安全有更多的证据，我不认为取样一个随机点（即使我们可以公正地这样做）会有多大意义。

**结论：我真的不知道这些人在想什么**

我希望能理解那些提出这种论点的人的思维方式，但我不确定我是否成功了。我能说的最好的是，有时候我这边的人也会提出类似的论点（核链反应那个），我并不会立即认为它们愚蠢，也许我可以沿着这个思路来弄清楚为什么有时候它们看起来很诱人。

如果你看到我提出的论点，你觉得它像咖啡末日一样，请告诉我，这样我可以思考是什么因素导致我认为这是一个合理的做法，并看看它们是否也适用于咖啡情况。

虽然我不得不承认，我有点紧张地提出这个要求。道格拉斯·亚当斯曾经说过，如果有人理解了宇宙，它会立即消失，并被更加难以理解的东西替代。我担心如果我真的理解了为什么反对AI安全的人认为他们说的东西算是好论点，同样的事情可能会发生。
