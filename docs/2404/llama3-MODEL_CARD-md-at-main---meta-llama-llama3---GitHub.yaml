- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 13:24:27'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: llama3/MODEL_CARD.md at main · meta-llama/llama3 · GitHub
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md](https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Meta developed and released the Meta Llama 3 family of large language models
    (LLMs), a collection of pretrained and instruction tuned generative text models
    in 8 and 70B sizes. The Llama 3 instruction tuned models are optimized for dialogue
    use cases and outperform many of the available open source chat models on common
    industry benchmarks. Further, in developing these models, we took great care to
    optimize helpfulness and safety.
  id: totrans-split-6
  prefs: []
  type: TYPE_NORMAL
- en: '**Model developers** Meta'
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: '**Variations** Llama 3 comes in two sizes — 8B and 70B parameters — in pre-trained
    and instruction tuned variants.'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: '**Input** Models input text only.'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
- en: '**Output** Models generate text and code only.'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
- en: '**Model Architecture** Llama 3 is an auto-regressive language model that uses
    an optimized transformer architecture. The tuned versions use supervised fine-tuning
    (SFT) and reinforcement learning with human feedback (RLHF) to align with human
    preferences for helpfulness and safety.'
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
- en: '|  | **Training Data** | **Params** | **Context length** | **GQA** | **Token
    count** | **Knowledge cutoff** |'
  id: totrans-split-12
  prefs: []
  type: TYPE_TB
- en: '| Llama 3 | A new mix of publicly available online data. | 8B | 8k | Yes |
    15T+ | March, 2023 |'
  id: totrans-split-13
  prefs: []
  type: TYPE_TB
- en: '| 70B | 8k | Yes | December, 2023 |'
  id: totrans-split-14
  prefs: []
  type: TYPE_TB
- en: '**Llama 3 family of models**. Token counts refer to pretraining data only.
    Both the 8 and 70B versions use Grouped-Query Attention (GQA) for improved inference
    scalability.'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
- en: '**Model Release Date** April 18, 2024.'
  id: totrans-split-16
  prefs: []
  type: TYPE_NORMAL
- en: '**Status** This is a static model trained on an offline dataset. Future versions
    of the tuned models will be released as we improve model safety with community
    feedback.'
  id: totrans-split-17
  prefs: []
  type: TYPE_NORMAL
- en: '**License** A custom commercial license is available at: [https://llama.meta.com/llama3/license](https://llama.meta.com/llama3/license)'
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
- en: Where to send questions or comments about the model Instructions on how to provide
    feedback or comments on the model can be found in the model [README](https://github.com/meta-llama/llama3).
    For more technical information about generation parameters and recipes for how
    to use Llama 3 in applications, please go [here](https://github.com/meta-llama/llama-recipes).
  id: totrans-split-19
  prefs: []
  type: TYPE_NORMAL
- en: '**Intended Use Cases** Llama 3 is intended for commercial and research use
    in English. Instruction tuned models are intended for assistant-like chat, whereas
    pretrained models can be adapted for a variety of natural language generation
    tasks.'
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
- en: '**Out-of-scope** Use in any manner that violates applicable laws or regulations
    (including trade compliance laws). Use in any other way that is prohibited by
    the [Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/) and [Llama
    3 Community License](https://llama.meta.com/llama3/license/). Use in languages
    other than English**.'
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
- en: '**Note: Developers may fine-tune Llama 3 models for languages beyond English
    provided they comply with the [Llama 3 Community License](https://llama.meta.com/llama3/license/)
    and the [Acceptable Use Policy](https://llama.meta.com/llama3/use-policy/).'
  id: totrans-split-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：开发者可以根据[LLama 3社区许可证](https://llama.meta.com/llama3/license/)和[可接受使用政策](https://llama.meta.com/llama3/use-policy/)将Llama
    3模型进行语言等外语的精细调整。**'
- en: '**Training Factors** We used custom training libraries, Meta''s Research SuperCluster,
    and production clusters for pretraining. Fine-tuning, annotation, and evaluation
    were also performed on third-party cloud compute.'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**训练因素** 我们使用了自定义训练库，Meta的研究超级集群以及生产集群进行预训练。微调、注释和评估也在第三方云计算上完成。'
- en: '**Carbon Footprint Pretraining utilized a cumulative** 7.7M GPU hours of computation
    on hardware of type H100-80GB (TDP of 700W). Estimated total emissions were 2290
    tCO2eq, 100% of which were offset by Meta’s sustainability program.'
  id: totrans-split-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**碳足迹预训练** 利用了7.7百万 GPU 小时的计算时间，硬件型号为 H100-80GB（TDP 为700W）。预计总排放量为2290 tCO2eq，其中100%已通过
    Meta 的可持续性计划抵消。'
- en: '|  | **Time (GPU hours)** | **Power Consumption (W)** | **Carbon Emitted(tCO2eq)**
    |'
  id: totrans-split-25
  prefs: []
  type: TYPE_TB
  zh: '|  | **时间 (GPU 小时)** | **功耗 (W)** | **排放碳量 (tCO2eq)** |'
- en: '| Llama 3 8B | 1.3M | 700 | 390 |'
  id: totrans-split-26
  prefs: []
  type: TYPE_TB
  zh: '| Llama 3 8B | 1.3百万 | 700 | 390 |'
- en: '| Llama 3 70B | 6.4M | 700 | 1900 |'
  id: totrans-split-27
  prefs: []
  type: TYPE_TB
  zh: '| Llama 3 70B | 6.4百万 | 700 | 1900 |'
- en: '| Total | 7.7M |  | 2290 |'
  id: totrans-split-28
  prefs: []
  type: TYPE_TB
  zh: '| 总计 | 7.7百万 |  | 2290 |'
- en: '**CO2 emissions during pre-training**. Time: total GPU time required for training
    each model. Power Consumption: peak power capacity per GPU device for the GPUs
    used adjusted for power usage efficiency. 100% of the emissions are directly offset
    by Meta''s sustainability program, and because we are openly releasing these models,
    the pretraining costs do not need to be incurred by others.'
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**在预训练期间的二氧化碳排放**。时间：训练每个模型所需的总GPU时间。功耗：每个GPU设备的峰值功率容量，根据使用效率调整。所有排放量均由Meta的可持续性计划直接抵消，因为我们正在公开发布这些模型，预训练成本不需要由其他人承担。'
- en: '**Overview** Llama 3 was pretrained on over 15 trillion tokens of data from
    publicly available sources. The fine-tuning data includes publicly available instruction
    datasets, as well as over 10M human-annotated examples. Neither the pretraining
    nor the fine-tuning datasets include Meta user data.'
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**概览** Llama 3 是在公开来源数据的超过15万亿个标记上进行预训练的。微调数据包括公开可用的指令数据集，以及超过1000万个人工注释示例。预训练和微调数据集均不包括
    Meta 用户数据。'
- en: '**Data Freshness** The pretraining data has a cutoff of March 2023 for the
    8B and December 2023 for the 70B models respectively.'
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据新鲜度** 8B 模型的预训练数据截止到2023年3月，70B 模型截止到2023年12月。'
- en: In this section, we report the results for Llama 3 models on standard automatic
    benchmarks. For all the evaluations, we use our internal evaluations library.
    For details on the methodology see [here](https://github.com/meta-llama/llama3/blob/main/eval_details.md).
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们报告了 Llama 3 模型在标准自动基准测试中的结果。对于所有评估，我们使用我们的内部评估库。有关方法论的详细信息请参见[这里](https://github.com/meta-llama/llama3/blob/main/eval_details.md)。
- en: '| **Category** | **Benchmark** | **Llama 3 8B** | **Llama2 7B** | **Llama2
    13B** | **Llama 3 70B** | **Llama2 70B** |'
  id: totrans-split-33
  prefs: []
  type: TYPE_TB
  zh: '| **类别** | **基准** | **Llama 3 8B** | **Llama 2 7B** | **Llama 2 13B** | **Llama
    3 70B** | **Llama 2 70B** |'
- en: '| General | MMLU (5-shot) | 66.6 | 45.7 | 53.8 | 79.5 | 69.7 |'
  id: totrans-split-34
  prefs: []
  type: TYPE_TB
  zh: '| 通用 | MMLU (5-shot) | 66.6 | 45.7 | 53.8 | 79.5 | 69.7 |'
- en: '| AGIEval English (3-5 shot) | 45.9 | 28.8 | 38.7 | 63.0 | 54.8 |'
  id: totrans-split-35
  prefs: []
  type: TYPE_TB
  zh: '| AGIEval 英语 (3-5 shot) | 45.9 | 28.8 | 38.7 | 63.0 | 54.8 |'
- en: '| CommonSenseQA (7-shot) | 72.6 | 57.6 | 67.6 | 83.8 | 78.7 |'
  id: totrans-split-36
  prefs: []
  type: TYPE_TB
  zh: '| 常识QA (7-shot) | 72.6 | 57.6 | 67.6 | 83.8 | 78.7 |'
- en: '| Winogrande (5-shot) | 76.1 | 73.3 | 75.4 | 83.1 | 81.8 |'
  id: totrans-split-37
  prefs: []
  type: TYPE_TB
  zh: '| Winogrande (5-shot) | 76.1 | 73.3 | 75.4 | 83.1 | 81.8 |'
- en: '| BIG-Bench Hard (3-shot, CoT) | 61.1 | 38.1 | 47.0 | 81.3 | 65.7 |'
  id: totrans-split-38
  prefs: []
  type: TYPE_TB
  zh: '| BIG-Bench Hard (3-shot, CoT) | 61.1 | 38.1 | 47.0 | 81.3 | 65.7 |'
- en: '| ARC-Challenge (25-shot) | 78.6 | 53.7 | 67.6 | 93.0 | 85.3 |'
  id: totrans-split-39
  prefs: []
  type: TYPE_TB
  zh: '| ARC-Challenge (25-shot) | 78.6 | 53.7 | 67.6 | 93.0 | 85.3 |'
- en: '| Knowledge reasoning | TriviaQA-Wiki (5-shot) | 78.5 | 72.1 | 79.6 | 89.7
    | 87.5 |'
  id: totrans-split-40
  prefs: []
  type: TYPE_TB
  zh: '| 知识推理 | TriviaQA-Wiki (5-shot) | 78.5 | 72.1 | 79.6 | 89.7 | 87.5 |'
- en: '| Reading comprehension | SQuAD (1-shot) | 76.4 | 72.2 | 72.1 | 85.6 | 82.6
    |'
  id: totrans-split-41
  prefs: []
  type: TYPE_TB
  zh: '| 阅读理解 | SQuAD (1-shot) | 76.4 | 72.2 | 72.1 | 85.6 | 82.6 |'
- en: '| QuAC (1-shot, F1) | 44.4 | 39.6 | 44.9 | 51.1 | 49.4 |'
  id: totrans-split-42
  prefs: []
  type: TYPE_TB
  zh: '| QuAC (1-shot, F1) | 44.4 | 39.6 | 44.9 | 51.1 | 49.4 |'
- en: '| BoolQ (0-shot) | 75.7 | 65.5 | 66.9 | 79.0 | 73.1 |'
  id: totrans-split-43
  prefs: []
  type: TYPE_TB
  zh: '| BoolQ (0-shot) | 75.7 | 65.5 | 66.9 | 79.0 | 73.1 |'
- en: '| DROP (3-shot, F1) | 58.4 | 37.9 | 49.8 | 79.7 | 70.2 |'
  id: totrans-split-44
  prefs: []
  type: TYPE_TB
  zh: '| DROP (3-shot, F1) | 58.4 | 37.9 | 49.8 | 79.7 | 70.2 |'
- en: '| **Benchmark** | **Llama 3 8B** | **Llama 2 7B** | **Llama 2 13B** | **Llama
    3 70B** | **Llama 2 70B** |'
  id: totrans-split-45
  prefs: []
  type: TYPE_TB
  zh: '| **基准** | **Llama 3 8B** | **Llama 2 7B** | **Llama 2 13B** | **Llama 3 70B**
    | **Llama 2 70B** |'
- en: '| MMLU (5-shot) | 68.4 | 34.1 | 47.8 | 82.0 | 52.9 |'
  id: totrans-split-46
  prefs: []
  type: TYPE_TB
  zh: '| MMLU (5-shot) | 68.4 | 34.1 | 47.8 | 82.0 | 52.9 |'
- en: '| GPQA (0-shot) | 34.2 | 21.7 | 22.3 | 39.5 | 21.0 |'
  id: totrans-split-47
  prefs: []
  type: TYPE_TB
  zh: '| GPQA (0-shot) | 34.2 | 21.7 | 22.3 | 39.5 | 21.0 |'
- en: '| HumanEval (0-shot) | 62.2 | 7.9 | 14.0 | 81.7 | 25.6 |'
  id: totrans-split-48
  prefs: []
  type: TYPE_TB
  zh: '| HumanEval (0-shot) | 62.2 | 7.9 | 14.0 | 81.7 | 25.6 |'
- en: '| GSM-8K (8-shot, CoT) | 79.6 | 25.7 | 77.4 | 93.0 | 57.5 |'
  id: totrans-split-49
  prefs: []
  type: TYPE_TB
  zh: '| GSM-8K (8-shot, CoT) | 79.6 | 25.7 | 77.4 | 93.0 | 57.5 |'
- en: '| MATH (4-shot, CoT) | 30.0 | 3.8 | 6.7 | 50.4 | 11.6 |'
  id: totrans-split-50
  prefs: []
  type: TYPE_TB
  zh: '| MATH (4-shot, CoT) | 30.0 | 3.8 | 6.7 | 50.4 | 11.6 |'
- en: We believe that an open approach to AI leads to better, safer products, faster
    innovation, and a bigger overall market. We are committed to Responsible AI development
    and took a series of steps to limit misuse and harm and support the open source
    community.
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们相信开放的AI方法能够带来更好、更安全的产品，促进更快的创新，并扩大整体市场。我们致力于负责任的AI开发，并采取了一系列措施来限制误用和伤害，并支持开源社区。
- en: Foundation models are widely capable technologies that are built to be used
    for a diverse range of applications. They are not designed to meet every developer
    preference on safety levels for all use cases, out-of-the-box, as those by their
    nature will differ across different applications.
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型是广泛能力的技术，旨在用于各种应用程序。它们并非被设计为即插即用地满足所有用例的每个开发者对安全级别的偏好，因为这些自然会在不同应用程序中有所不同。
- en: Rather, responsible LLM-application deployment is achieved by implementing a
    series of safety best practices throughout the development of such applications,
    from the model pre-training, fine-tuning and the deployment of systems composed
    of safeguards to tailor the safety needs specifically to the use case and audience.
  id: totrans-split-53
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，负责任的LLM应用部署通过在这些应用程序的开发过程中实施一系列安全最佳实践来实现，从模型预训练、微调到系统部署，以及利用保障系统以针对特定用例和受众定制安全需求。
- en: As part of the Llama 3 release, we updated our [Responsible Use Guide](https://llama.meta.com/responsible-use-guide/)
    to outline the steps and best practices for developers to implement model and
    system level safety for their application. We also provide a set of resources
    including [Meta Llama Guard 2](https://llama.meta.com/purple-llama/) and [Code
    Shield](https://llama.meta.com/purple-llama/) safeguards. These tools have proven
    to drastically reduce residual risks of LLM Systems, while maintaining a high
    level of helpfulness. We encourage developers to tune and deploy these safeguards
    according to their needs and we provide a [reference implementation](https://github.com/meta-llama/llama-recipes/tree/main/recipes/responsible_ai)
    to get you started.
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: 作为Llama 3发布的一部分，我们更新了我们的[负责使用指南](https://llama.meta.com/responsible-use-guide/)，详细说明开发者为其应用实施模型和系统级安全的步骤和最佳实践。我们还提供一系列资源，包括[Meta
    Llama Guard 2](https://llama.meta.com/purple-llama/)和[Code Shield](https://llama.meta.com/purple-llama/)安全防护措施。这些工具已被证明能显著降低LLM系统的残留风险，同时保持高水平的实用性。我们鼓励开发者根据需要调整和部署这些安全措施，并为您提供了一个[参考实现](https://github.com/meta-llama/llama-recipes/tree/main/recipes/responsible_ai)来帮助您入门。
- en: As outlined in the Responsible Use Guide, some trade-off between model helpfulness
    and model alignment is likely unavoidable. Developers should exercise discretion
    about how to weigh the benefits of alignment and helpfulness for their specific
    use case and audience. Developers should be mindful of residual risks when using
    Llama models and leverage additional safety tools as needed to reach the right
    safety bar for their use case.
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如《负责使用指南》中所述，模型的有用性与模型的对齐性之间的某种权衡可能是不可避免的。开发者应谨慎权衡在其特定用例和受众中对齐性和有用性的利益。在使用Llama模型时，开发者应注意残留风险，并根据需要利用额外的安全工具来达到其用例的正确安全标准。
- en: Safety
  id: totrans-split-56
  prefs: []
  type: TYPE_NORMAL
  zh: 安全
- en: For our instruction tuned model, we conducted extensive red teaming exercises,
    performed adversarial evaluations and implemented safety mitigations techniques
    to lower residual risks. As with any Large Language Model, residual risks will
    likely remain and we recommend that developers assess these risks in the context
    of their use case. In parallel, we are working with the community to make AI safety
    benchmark standards transparent, rigorous and interpretable.
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的指导调整模型，我们进行了广泛的红队演练，进行了对抗评估，并实施了安全缓解技术以降低残留风险。与任何大型语言模型一样，残留风险可能仍然存在，我们建议开发者在其用例的背景下评估这些风险。同时，我们正在与社区合作，使AI安全基准标准透明、严格且可解释。
- en: Refusals
  id: totrans-split-58
  prefs: []
  type: TYPE_NORMAL
  zh: 拒绝
- en: In addition to residual risks, we put a great emphasis on model refusals to
    benign prompts. Over-refusing not only can impact the user experience but could
    even be harmful in certain contexts as well. We’ve heard the feedback from the
    developer community and improved our fine tuning to ensure that Llama 3 is significantly
    less likely to falsely refuse to answer prompts than Llama 2.
  id: totrans-split-59
  prefs: []
  type: TYPE_NORMAL
  zh: 除了残留风险外，我们非常重视模型对良性提示的拒绝。过度拒绝不仅会影响用户体验，而且在某些情况下可能会有害。我们听取了开发者社区的反馈，并改进了我们的精细调整，以确保Llama
    3在误拒答案方面的可能性显著低于Llama 2。
- en: We built internal benchmarks and developed mitigations to limit false refusals
    making Llama 3 our most helpful model to date.
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建立了内部基准，并开发了缓解措施，以限制误拒，使Llama 3成为迄今为止最有帮助的模型。
- en: In addition to responsible use considerations outlined above, we followed a
    rigorous process that requires us to take extra measures against misuse and critical
    risks before we make our release decision.
  id: totrans-split-61
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述负责任使用的考虑因素外，我们遵循了严格的流程，在我们做出发布决策之前，需要我们采取额外措施来防止滥用和关键风险。
- en: Misuse
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
  zh: 滥用
- en: If you access or use Llama 3, you agree to the Acceptable Use Policy. The most
    recent copy of this policy can be found at [https://llama.meta.com/llama3/use-policy/](https://llama.meta.com/llama3/use-policy/).
  id: totrans-split-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您访问或使用Llama 3，您同意接受可接受使用政策。您可以在[https://llama.meta.com/llama3/use-policy/](https://llama.meta.com/llama3/use-policy/)找到此政策的最新副本。
- en: CBRNE (Chemical, Biological, Radiological, Nuclear, and high yield Explosives)
  id: totrans-split-64
  prefs: []
  type: TYPE_NORMAL
  zh: CBRNE（化学、生物、放射性、核和高产爆炸物）
- en: 'We have conducted a two fold assessment of the safety of the model in this
    area:'
  id: totrans-split-65
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这一领域对模型安全性进行了两重评估：
- en: Iterative testing during model training to assess the safety of responses related
    to CBRNE threats and other adversarial risks.
  id: totrans-split-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模型训练期间进行迭代测试，评估与CBRNE威胁和其他对抗性风险相关的响应的安全性。
- en: Involving external CBRNE experts to conduct an uplift test assessing the ability
    of the model to accurately provide expert knowledge and reduce barriers to potential
    CBRNE misuse, by reference to what can be achieved using web search (without the
    model).
  id: totrans-split-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过外部CBRNE专家进行提升测试，评估模型提供专业知识的能力，并通过与Web搜索（无需模型）相比较，减少潜在CBRNE滥用的障碍。
- en: We have evaluated Llama 3 with CyberSecEval, Meta’s cybersecurity safety eval
    suite, measuring Llama 3’s propensity to suggest insecure code when used as a
    coding assistant, and Llama 3’s propensity to comply with requests to help carry
    out cyber attacks, where attacks are defined by the industry standard MITRE ATT&CK
    cyber attack ontology. On our insecure coding and cyber attacker helpfulness tests,
    Llama 3 behaved in the same range or safer than models of [equivalent coding capability](https://huggingface.co/spaces/facebook/CyberSecEval).
  id: totrans-split-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用CyberSecEval对Llama 3进行了评估，这是Meta的网络安全安全评估套件，衡量Llama 3在作为编码助手使用时建议不安全代码的倾向性，以及Llama
    3在遵循行业标准MITRE ATT&CK网络攻击本体论时协助执行网络攻击的倾向性。在我们的不安全编码和网络攻击协助性测试中，Llama 3的行为范围与或者比具有[相同编码能力](https://huggingface.co/spaces/facebook/CyberSecEval)的模型更安全。
- en: Child Safety risk assessments were conducted using a team of experts, to assess
    the model’s capability to produce outputs that could result in Child Safety risks
    and inform on any necessary and appropriate risk mitigations via fine tuning.
    We leveraged those expert red teaming sessions to expand the coverage of our evaluation
    benchmarks through Llama 3 model development. For Llama 3, we conducted new in-depth
    sessions using objective based methodologies to assess the model risks along multiple
    attack vectors. We also partnered with content specialists to perform red teaming
    exercises assessing potentially violating content while taking account of market
    specific nuances or experiences.
  id: totrans-split-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用专家团队进行了儿童安全风险评估，评估模型产生可能导致儿童安全风险的输出能力，并通过精细调整提供任何必要和适当的风险缓解建议。我们利用这些专家红队会议扩展了我们通过Llama
    3模型开发的评估基准的覆盖范围。对于Llama 3，我们使用基于客观方法的方法进行了新的深度评估会议，以评估模型在多个攻击向量上的风险。我们还与内容专家合作进行了红队演练，评估潜在的违规内容，同时考虑市场特定的细微差别或经验。
- en: Community
  id: totrans-split-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 社区
- en: Generative AI safety requires expertise and tooling, and we believe in the strength
    of the open community to accelerate its progress. We are active members of open
    consortiums, including the AI Alliance, Partnership in AI and MLCommons, actively
    contributing to safety standardization and transparency. We encourage the community
    to adopt taxonomies like the MLCommons Proof of Concept evaluation to facilitate
    collaboration and transparency on safety and content evaluations. Our Purple Llama
    tools are open sourced for the community to use and widely distributed across
    ecosystem partners including cloud service providers. We encourage community contributions
    to our [GitHub repository](https://github.com/meta-llama/PurpleLlama).
  id: totrans-split-71
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能安全需要专业知识和工具支持，我们相信开放社区的力量可以加速其进展。我们是开放联盟的积极成员，包括AI联盟、AI合作伙伴关系和MLCommons，积极推动安全标准化和透明化。我们鼓励社区采用MLCommons概念验证评估等分类法，以促进安全和内容评估的合作和透明化。我们的Purple
    Llama工具已开源供社区使用，并在生态系统伙伴中广泛分发，包括云服务提供商。我们鼓励社区为我们的[GitHub存储库](https://github.com/meta-llama/PurpleLlama)做出贡献。
- en: Finally, we put in place a set of resources including an [output reporting mechanism](https://developers.facebook.com/llama_output_feedback)
    and [bug bounty program](https://www.facebook.com/whitehat) to continuously improve
    the Llama technology with the help of the community.
  id: totrans-split-72
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们设立了一系列资源，包括一个[输出报告机制](https://developers.facebook.com/llama_output_feedback)和[漏洞赏金计划](https://www.facebook.com/whitehat)，以在社区的帮助下持续改进Llama技术。
- en: Ethical Considerations and Limitations
  id: totrans-split-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 道德考量和限制
- en: '[](#ethical-considerations-and-limitations)'
  id: totrans-split-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[](#ethical-considerations-and-limitations)'
- en: The core values of Llama 3 are openness, inclusivity and helpfulness. It is
    meant to serve everyone, and to work for a wide range of use cases. It is thus
    designed to be accessible to people across many different backgrounds, experiences
    and perspectives. Llama 3 addresses users and their needs as they are, without
    insertion unnecessary judgment or normativity, while reflecting the understanding
    that even content that may appear problematic in some cases can serve valuable
    purposes in others. It respects the dignity and autonomy of all users, especially
    in terms of the values of free thought and expression that power innovation and
    progress.
  id: totrans-split-75
  prefs: []
  type: TYPE_NORMAL
  zh: Llama 3的核心价值在于开放性、包容性和乐于助人。它旨在为所有人服务，适用于广泛的用例。因此，它设计成能够让不同背景、经验和观点的人们轻松使用。它以用户和他们的需求为中心，不插入不必要的判断或规范，同时反映出即使在某些情况下可能存在问题的内容，也能为其他情况提供有价值的用途。它尊重所有用户的尊严和自主权，特别是在自由思想和表达价值推动创新和进步的情况下。
- en: But Llama 3 is a new technology, and like any new technology, there are risks
    associated with its use. Testing conducted to date has been in English, and has
    not covered, nor could it cover, all scenarios. For these reasons, as with all
    LLMs, Llama 3’s potential outputs cannot be predicted in advance, and the model
    may in some instances produce inaccurate, biased or other objectionable responses
    to user prompts. Therefore, before deploying any applications of Llama 3 models,
    developers should perform safety testing and tuning tailored to their specific
    applications of the model. As outlined in the Responsible Use Guide, we recommend
    incorporating [Purple Llama](https://github.com/facebookresearch/PurpleLlama)
    solutions into your workflows and specifically [Llama Guard](https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/)
    which provides a base model to filter input and output prompts to layer system-level
    safety on top of model-level safety.
  id: totrans-split-76
  prefs: []
  type: TYPE_NORMAL
  zh: 但是Llama 3是一项新技术，像所有新技术一样，其使用存在风险。到目前为止进行的测试均为英文，并未涵盖，也无法涵盖所有情景。因此，正如所有LLM一样，Llama
    3的潜在输出无法预先预测，该模型有时可能会生成不准确、带偏见或其他令人反感的响应。因此，在部署任何Llama 3模型应用程序之前，开发人员应根据其模型特定应用进行安全测试和调整。正如《责任使用指南》所述，我们建议将[Purple
    Llama](https://github.com/facebookresearch/PurpleLlama)解决方案整合到您的工作流程中，特别是[Llama
    Guard](https://ai.meta.com/research/publications/llama-guard-llm-based-input-output-safeguard-for-human-ai-conversations/)，它为输入和输出提示过滤提供了基础系统级安全性。
- en: Please see the Responsible Use Guide available at [http://llama.meta.com/responsible-use-guide](http://llama.meta.com/responsible-use-guide)
  id: totrans-split-77
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅[责任使用指南](http://llama.meta.com/responsible-use-guide)。
- en: '[PRE0]'
  id: totrans-split-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Aaditya Singh; '
  id: totrans-split-79
  prefs: []
  type: TYPE_NORMAL
  zh: Aaditya Singh;
- en: 'Aaron Grattafiori; '
  id: totrans-split-80
  prefs: []
  type: TYPE_NORMAL
  zh: Aaron Grattafiori;
- en: 'Abhimanyu Dubey; '
  id: totrans-split-81
  prefs: []
  type: TYPE_NORMAL
  zh: Abhimanyu Dubey;
- en: 'Abhinav Jauhri; '
  id: totrans-split-82
  prefs: []
  type: TYPE_NORMAL
  zh: Abhinav Jauhri;
- en: 'Abhinav Pandey; '
  id: totrans-split-83
  prefs: []
  type: TYPE_NORMAL
  zh: Abhinav Pandey;
- en: 'Abhishek Kadian; '
  id: totrans-split-84
  prefs: []
  type: TYPE_NORMAL
  zh: Abhishek Kadian;
- en: 'Adam Kelsey; '
  id: totrans-split-85
  prefs: []
  type: TYPE_NORMAL
  zh: Adam Kelsey;
- en: 'Adi Gangidi; '
  id: totrans-split-86
  prefs: []
  type: TYPE_NORMAL
  zh: Adi Gangidi;
- en: 'Ahmad Al-Dahle; '
  id: totrans-split-87
  prefs: []
  type: TYPE_NORMAL
  zh: Ahmad Al-Dahle;
- en: 'Amit Sangani; '
  id: totrans-split-88
  prefs: []
  type: TYPE_NORMAL
  zh: Amit Sangani;
- en: 'Ahuva Goldstand; '
  id: totrans-split-89
  prefs: []
  type: TYPE_NORMAL
  zh: Ahuva Goldstand;
- en: 'Aiesha Letman; '
  id: totrans-split-90
  prefs: []
  type: TYPE_NORMAL
  zh: Aiesha Letman;
- en: 'Ajay Menon; '
  id: totrans-split-91
  prefs: []
  type: TYPE_NORMAL
  zh: Ajay Menon;
- en: 'Akhil Mathur; '
  id: totrans-split-92
  prefs: []
  type: TYPE_NORMAL
  zh: Akhil Mathur;
- en: 'Alan Schelten; '
  id: totrans-split-93
  prefs: []
  type: TYPE_NORMAL
  zh: Alan Schelten;
- en: 'Alex Vaughan; '
  id: totrans-split-94
  prefs: []
  type: TYPE_NORMAL
  zh: Alex Vaughan;
- en: 'Amy Yang; '
  id: totrans-split-95
  prefs: []
  type: TYPE_NORMAL
  zh: Amy Yang;
- en: 'Andrei Lupu; '
  id: totrans-split-96
  prefs: []
  type: TYPE_NORMAL
  zh: Andrei Lupu;
- en: 'Andres Alvarado; '
  id: totrans-split-97
  prefs: []
  type: TYPE_NORMAL
  zh: Andres Alvarado;
- en: 'Andrew Gallagher; '
  id: totrans-split-98
  prefs: []
  type: TYPE_NORMAL
  zh: Andrew Gallagher;
- en: 'Andrew Gu; '
  id: totrans-split-99
  prefs: []
  type: TYPE_NORMAL
  zh: Andrew Gu;
- en: 'Andrew Ho; '
  id: totrans-split-100
  prefs: []
  type: TYPE_NORMAL
  zh: Andrew Ho;
- en: 'Andrew Poulton; '
  id: totrans-split-101
  prefs: []
  type: TYPE_NORMAL
  zh: Andrew Poulton;
- en: 'Andrew Ryan; '
  id: totrans-split-102
  prefs: []
  type: TYPE_NORMAL
  zh: Andrew Ryan;
- en: 'Angela Fan; '
  id: totrans-split-103
  prefs: []
  type: TYPE_NORMAL
  zh: Angela Fan;
- en: 'Ankit Ramchandani; '
  id: totrans-split-104
  prefs: []
  type: TYPE_NORMAL
  zh: Ankit Ramchandani;
- en: 'Anthony Hartshorn; '
  id: totrans-split-105
  prefs: []
  type: TYPE_NORMAL
  zh: Anthony Hartshorn;
- en: 'Archi Mitra; '
  id: totrans-split-106
  prefs: []
  type: TYPE_NORMAL
  zh: Archi Mitra;
- en: 'Archie Sravankumar; '
  id: totrans-split-107
  prefs: []
  type: TYPE_NORMAL
  zh: Archie Sravankumar;
- en: 'Artem Korenev; '
  id: totrans-split-108
  prefs: []
  type: TYPE_NORMAL
  zh: Artem Korenev;
- en: 'Arun Rao; '
  id: totrans-split-109
  prefs: []
  type: TYPE_NORMAL
  zh: Arun Rao;
- en: 'Ashley Gabriel; '
  id: totrans-split-110
  prefs: []
  type: TYPE_NORMAL
  zh: Ashley Gabriel;
- en: 'Ashwin Bharambe; '
  id: totrans-split-111
  prefs: []
  type: TYPE_NORMAL
  zh: Ashwin Bharambe;
- en: 'Assaf Eisenman; '
  id: totrans-split-112
  prefs: []
  type: TYPE_NORMAL
  zh: Assaf Eisenman;
- en: 'Aston Zhang; '
  id: totrans-split-113
  prefs: []
  type: TYPE_NORMAL
  zh: Aston Zhang;
- en: 'Ash JJhaveri; '
  id: totrans-split-114
  prefs: []
  type: TYPE_NORMAL
  zh: Ash JJhaveri;
- en: 'Aurelien Rodriguez; '
  id: totrans-split-115
  prefs: []
  type: TYPE_NORMAL
  zh: Aurelien Rodriguez;
- en: 'Austen Gregerson; '
  id: totrans-split-116
  prefs: []
  type: TYPE_NORMAL
  zh: Austen Gregerson;
- en: 'Ava Spataru; '
  id: totrans-split-117
  prefs: []
  type: TYPE_NORMAL
  zh: Ava Spataru;
- en: 'Baptiste Roziere; '
  id: totrans-split-118
  prefs: []
  type: TYPE_NORMAL
  zh: Baptiste Roziere;
- en: 'Ben Maurer; '
  id: totrans-split-119
  prefs: []
  type: TYPE_NORMAL
  zh: Ben Maurer;
- en: 'Benjamin Leonhardi; '
  id: totrans-split-120
  prefs: []
  type: TYPE_NORMAL
  zh: Benjamin Leonhardi;
- en: 'Bernie Huang; '
  id: totrans-split-121
  prefs: []
  type: TYPE_NORMAL
  zh: Bernie Huang;
- en: 'Bhargavi Paranjape; '
  id: totrans-split-122
  prefs: []
  type: TYPE_NORMAL
  zh: Bhargavi Paranjape;
- en: 'Bing Liu; '
  id: totrans-split-123
  prefs: []
  type: TYPE_NORMAL
  zh: Bing Liu;
- en: 'Binh Tang; '
  id: totrans-split-124
  prefs: []
  type: TYPE_NORMAL
  zh: Binh Tang;
- en: 'Bobbie Chern; '
  id: totrans-split-125
  prefs: []
  type: TYPE_NORMAL
  zh: Bobbie Chern;
- en: 'Brani Stojkovic; '
  id: totrans-split-126
  prefs: []
  type: TYPE_NORMAL
  zh: Brani Stojkovic;
- en: 'Brian Fuller; '
  id: totrans-split-127
  prefs: []
  type: TYPE_NORMAL
  zh: Brian Fuller;
- en: 'Catalina Mejia Arenas; '
  id: totrans-split-128
  prefs: []
  type: TYPE_NORMAL
  zh: Catalina Mejia Arenas;
- en: 'Chao Zhou; '
  id: totrans-split-129
  prefs: []
  type: TYPE_NORMAL
  zh: Chao Zhou;
- en: 'Charlotte Caucheteux; '
  id: totrans-split-130
  prefs: []
  type: TYPE_NORMAL
  zh: Charlotte Caucheteux;
- en: 'Chaya Nayak; '
  id: totrans-split-131
  prefs: []
  type: TYPE_NORMAL
  zh: Chaya Nayak;
- en: 'Ching-Hsiang Chu; '
  id: totrans-split-132
  prefs: []
  type: TYPE_NORMAL
  zh: Ching-Hsiang Chu;
- en: 'Chloe Bi; '
  id: totrans-split-133
  prefs: []
  type: TYPE_NORMAL
  zh: Chloe Bi;
- en: 'Chris Cai; '
  id: totrans-split-134
  prefs: []
  type: TYPE_NORMAL
  zh: Chris Cai;
- en: 'Chris Cox; '
  id: totrans-split-135
  prefs: []
  type: TYPE_NORMAL
  zh: Chris Cox;
- en: 'Chris Marra; '
  id: totrans-split-136
  prefs: []
  type: TYPE_NORMAL
  zh: Chris Marra;
- en: 'Chris McConnell; '
  id: totrans-split-137
  prefs: []
  type: TYPE_NORMAL
  zh: Chris McConnell;
- en: 'Christian Keller; '
  id: totrans-split-138
  prefs: []
  type: TYPE_NORMAL
  zh: Christian Keller;
- en: 'Christoph Feichtenhofer; '
  id: totrans-split-139
  prefs: []
  type: TYPE_NORMAL
  zh: Christoph Feichtenhofer;
- en: 'Christophe Touret; '
  id: totrans-split-140
  prefs: []
  type: TYPE_NORMAL
  zh: Christophe Touret;
- en: 'Chunyang Wu; '
  id: totrans-split-141
  prefs: []
  type: TYPE_NORMAL
  zh: Chunyang Wu;
- en: 'Corinne Wong; '
  id: totrans-split-142
  prefs: []
  type: TYPE_NORMAL
  zh: Corinne Wong;
- en: 'Cristian Canton Ferrer; '
  id: totrans-split-143
  prefs: []
  type: TYPE_NORMAL
  zh: Cristian Canton Ferrer;
- en: 'Damien Allonsius; '
  id: totrans-split-144
  prefs: []
  type: TYPE_NORMAL
  zh: Damien Allonsius;
- en: 'Daniel Kreymer; '
  id: totrans-split-145
  prefs: []
  type: TYPE_NORMAL
  zh: Daniel Kreymer;
- en: 'Daniel Haziza; '
  id: totrans-split-146
  prefs: []
  type: TYPE_NORMAL
  zh: Daniel Haziza;
- en: 'Daniel Li; '
  id: totrans-split-147
  prefs: []
  type: TYPE_NORMAL
  zh: Daniel Li;
- en: 'Danielle Pintz; '
  id: totrans-split-148
  prefs: []
  type: TYPE_NORMAL
  zh: Danielle Pintz;
- en: 'Danny Livshits; '
  id: totrans-split-149
  prefs: []
  type: TYPE_NORMAL
  zh: Danny Livshits;
- en: 'Danny Wyatt; '
  id: totrans-split-150
  prefs: []
  type: TYPE_NORMAL
  zh: Danny Wyatt;
- en: 'David Adkins; '
  id: totrans-split-151
  prefs: []
  type: TYPE_NORMAL
  zh: David Adkins;
- en: 'David Esiobu; '
  id: totrans-split-152
  prefs: []
  type: TYPE_NORMAL
  zh: David Esiobu;
- en: 'David Xu; '
  id: totrans-split-153
  prefs: []
  type: TYPE_NORMAL
  zh: David Xu;
- en: 'Davide Testuggine; '
  id: totrans-split-154
  prefs: []
  type: TYPE_NORMAL
  zh: Davide Testuggine;
- en: 'Delia David; '
  id: totrans-split-155
  prefs: []
  type: TYPE_NORMAL
  zh: Delia David;
- en: 'Devi Parikh; '
  id: totrans-split-156
  prefs: []
  type: TYPE_NORMAL
  zh: Devi Parikh;
- en: 'Dhruv Choudhary; '
  id: totrans-split-157
  prefs: []
  type: TYPE_NORMAL
  zh: Dhruv Choudhary;
- en: 'Dhruv Mahajan; '
  id: totrans-split-158
  prefs: []
  type: TYPE_NORMAL
  zh: Dhruv Mahajan;
- en: 'Diana Liskovich; '
  id: totrans-split-159
  prefs: []
  type: TYPE_NORMAL
  zh: Diana Liskovich;
- en: 'Diego Garcia-Olano; '
  id: totrans-split-160
  prefs: []
  type: TYPE_NORMAL
  zh: Diego Garcia-Olano;
- en: 'Diego Perino; '
  id: totrans-split-161
  prefs: []
  type: TYPE_NORMAL
  zh: Diego Perino;
- en: 'Dieuwke Hupkes; '
  id: totrans-split-162
  prefs: []
  type: TYPE_NORMAL
  zh: Dieuwke Hupkes;
- en: 'Dingkang Wang; '
  id: totrans-split-163
  prefs: []
  type: TYPE_NORMAL
  zh: Dingkang Wang;
- en: 'Dustin Holland; '
  id: totrans-split-164
  prefs: []
  type: TYPE_NORMAL
  zh: Dustin Holland;
- en: 'Egor Lakomkin; '
  id: totrans-split-165
  prefs: []
  type: TYPE_NORMAL
  zh: Egor Lakomkin;
- en: 'Elina Lobanova; '
  id: totrans-split-166
  prefs: []
  type: TYPE_NORMAL
  zh: Elina Lobanova;
- en: 'Xiaoqing Ellen Tan; '
  id: totrans-split-167
  prefs: []
  type: TYPE_NORMAL
  zh: Xiaoqing Ellen Tan;
- en: 'Emily Dinan; '
  id: totrans-split-168
  prefs: []
  type: TYPE_NORMAL
  zh: Emily Dinan;
- en: 'Eric Smith; '
  id: totrans-split-169
  prefs: []
  type: TYPE_NORMAL
  zh: Eric Smith;
- en: 'Erik Brinkman; '
  id: totrans-split-170
  prefs: []
  type: TYPE_NORMAL
  zh: Erik Brinkman;
- en: 'Esteban Arcaute; '
  id: totrans-split-171
  prefs: []
  type: TYPE_NORMAL
  zh: Esteban Arcaute;
- en: 'Filip Radenovic; '
  id: totrans-split-172
  prefs: []
  type: TYPE_NORMAL
  zh: Filip Radenovic;
- en: 'Firat Ozgenel; '
  id: totrans-split-173
  prefs: []
  type: TYPE_NORMAL
  zh: Firat Ozgenel;
- en: 'Francesco Caggioni; '
  id: totrans-split-174
  prefs: []
  type: TYPE_NORMAL
  zh: Francesco Caggioni;
- en: 'Frank Seide; '
  id: totrans-split-175
  prefs: []
  type: TYPE_NORMAL
  zh: Frank Seide;
- en: 'Frank Zhang; '
  id: totrans-split-176
  prefs: []
  type: TYPE_NORMAL
  zh: Frank Zhang;
- en: 'Gabriel Synnaeve; '
  id: totrans-split-177
  prefs: []
  type: TYPE_NORMAL
  zh: Gabriel Synnaeve;
- en: 'Gabriella Schwarz; '
  id: totrans-split-178
  prefs: []
  type: TYPE_NORMAL
  zh: Gabriella Schwarz;
- en: 'Gabrielle Lee; '
  id: totrans-split-179
  prefs: []
  type: TYPE_NORMAL
  zh: Gabrielle Lee;
- en: 'Gada Badeer; '
  id: totrans-split-180
  prefs: []
  type: TYPE_NORMAL
  zh: Gada Badeer;
- en: 'Georgia Anderson; '
  id: totrans-split-181
  prefs: []
  type: TYPE_NORMAL
  zh: Georgia Anderson;
- en: 'Graeme Nail; '
  id: totrans-split-182
  prefs: []
  type: TYPE_NORMAL
  zh: Graeme Nail;
- en: 'Gregoire Mialon; '
  id: totrans-split-183
  prefs: []
  type: TYPE_NORMAL
  zh: Gregoire Mialon;
- en: 'Guan Pang; '
  id: totrans-split-184
  prefs: []
  type: TYPE_NORMAL
  zh: Guan Pang;
- en: 'Guillem Cucurell; '
  id: totrans-split-185
  prefs: []
  type: TYPE_NORMAL
  zh: Guillem Cucurell;
- en: 'Hailey Nguyen; '
  id: totrans-split-186
  prefs: []
  type: TYPE_NORMAL
  zh: Hailey Nguyen;
- en: 'Hamid Shojanazeri; '
  id: totrans-split-187
  prefs: []
  type: TYPE_NORMAL
  zh: Hamid Shojanazeri;
- en: 'Hannah Korevaar; '
  id: totrans-split-188
  prefs: []
  type: TYPE_NORMAL
  zh: Hannah Korevaar;
- en: 'Hannah Wang; '
  id: totrans-split-189
  prefs: []
  type: TYPE_NORMAL
  zh: Hannah Wang;
- en: 'Haroun Habeeb; '
  id: totrans-split-190
  prefs: []
  type: TYPE_NORMAL
  zh: Haroun Habeeb;
- en: 'Harrison Rudolph; '
  id: totrans-split-191
  prefs: []
  type: TYPE_NORMAL
  zh: Harrison Rudolph;
- en: 'Henry Aspegren; '
  id: totrans-split-192
  prefs: []
  type: TYPE_NORMAL
  zh: Henry Aspegren;
- en: 'Hu Xu; '
  id: totrans-split-193
  prefs: []
  type: TYPE_NORMAL
  zh: Hu Xu;
- en: 'Hugo Touvron; '
  id: totrans-split-194
  prefs: []
  type: TYPE_NORMAL
  zh: Hugo Touvron;
- en: 'Iga Kozlowska; '
  id: totrans-split-195
  prefs: []
  type: TYPE_NORMAL
  zh: Iga Kozlowska;
- en: 'Igor Molybog; '
  id: totrans-split-196
  prefs: []
  type: TYPE_NORMAL
  zh: Igor Molybog;
- en: 'Igor Tufanov; '
  id: totrans-split-197
  prefs: []
  type: TYPE_NORMAL
  zh: Igor Tufanov;
- en: 'Iliyan Zarov; '
  id: totrans-split-198
  prefs: []
  type: TYPE_NORMAL
  zh: Iliyan Zarov;
- en: 'Imanol Arrieta Ibarra; '
  id: totrans-split-199
  prefs: []
  type: TYPE_NORMAL
  zh: Imanol Arrieta Ibarra;
- en: 'Irina-Elena Veliche; '
  id: totrans-split-200
  prefs: []
  type: TYPE_NORMAL
  zh: Irina-Elena Veliche;
- en: 'Isabel Kloumann; '
  id: totrans-split-201
  prefs: []
  type: TYPE_NORMAL
  zh: Isabel Kloumann;
- en: 'Ishan Misra; '
  id: totrans-split-202
  prefs: []
  type: TYPE_NORMAL
  zh: Ishan Misra;
- en: 'Ivan Evtimov; '
  id: totrans-split-203
  prefs: []
  type: TYPE_NORMAL
  zh: Ivan Evtimov;
- en: 'Jade Copet; '
  id: totrans-split-204
  prefs: []
  type: TYPE_NORMAL
  zh: Jade Copet;
- en: 'Jake Weissman; '
  id: totrans-split-205
  prefs: []
  type: TYPE_NORMAL
  zh: Jake Weissman;
- en: 'Jan Geffert; '
  id: totrans-split-206
  prefs: []
  type: TYPE_NORMAL
  zh: Jan Geffert;
- en: 'Jana Vranes; '
  id: totrans-split-207
  prefs: []
  type: TYPE_NORMAL
  zh: Jana Vranes;
- en: 'Japhet Asher; '
  id: totrans-split-208
  prefs: []
  type: TYPE_NORMAL
  zh: Japhet Asher;
- en: 'Jason Park; '
  id: totrans-split-209
  prefs: []
  type: TYPE_NORMAL
  zh: Jason Park;
- en: 'Jay Mahadeokar; '
  id: totrans-split-210
  prefs: []
  type: TYPE_NORMAL
  zh: Jay Mahadeokar;
- en: 'Jean-Baptiste Gaya; '
  id: totrans-split-211
  prefs: []
  type: TYPE_NORMAL
  zh: Jean-Baptiste Gaya;
- en: 'Jeet Shah; '
  id: totrans-split-212
  prefs: []
  type: TYPE_NORMAL
  zh: Jeet Shah;
- en: 'Jelmer van der Linde; '
  id: totrans-split-213
  prefs: []
  type: TYPE_NORMAL
  zh: Jelmer van der Linde;
- en: 'Jennifer Chan; '
  id: totrans-split-214
  prefs: []
  type: TYPE_NORMAL
  zh: Jennifer Chan;
- en: 'Jenny Hong; '
  id: totrans-split-215
  prefs: []
  type: TYPE_NORMAL
  zh: Jenny Hong;
- en: 'Jenya Lee; '
  id: totrans-split-216
  prefs: []
  type: TYPE_NORMAL
  zh: Jenya Lee;
- en: 'Jeremy Fu; '
  id: totrans-split-217
  prefs: []
  type: TYPE_NORMAL
  zh: Jeremy Fu;
- en: 'Jeremy Teboul; '
  id: totrans-split-218
  prefs: []
  type: TYPE_NORMAL
  zh: Jeremy Teboul;
- en: 'Jianfeng Chi; '
  id: totrans-split-219
  prefs: []
  type: TYPE_NORMAL
  zh: Jianfeng Chi;
- en: 'Jianyu Huang; '
  id: totrans-split-220
  prefs: []
  type: TYPE_NORMAL
  zh: Jianyu Huang;
- en: 'Jie Wang; '
  id: totrans-split-221
  prefs: []
  type: TYPE_NORMAL
  zh: Jie Wang;
- en: 'Jiecao Yu; '
  id: totrans-split-222
  prefs: []
  type: TYPE_NORMAL
  zh: Jiecao Yu;
- en: 'Joanna Bitton; '
  id: totrans-split-223
  prefs: []
  type: TYPE_NORMAL
  zh: Joanna Bitton;
- en: 'Joe Spisak; '
  id: totrans-split-224
  prefs: []
  type: TYPE_NORMAL
  zh: Joe Spisak;
- en: 'Joelle Pineau; '
  id: totrans-split-225
  prefs: []
  type: TYPE_NORMAL
  zh: Joelle Pineau;
- en: 'Jon Carvill; '
  id: totrans-split-226
  prefs: []
  type: TYPE_NORMAL
  zh: Jon Carvill;
- en: 'Jongsoo Park; '
  id: totrans-split-227
  prefs: []
  type: TYPE_NORMAL
  zh: Jongsoo Park;
- en: 'Joseph Rocca; '
  id: totrans-split-228
  prefs: []
  type: TYPE_NORMAL
  zh: Joseph Rocca;
- en: 'Joshua Johnstun; '
  id: totrans-split-229
  prefs: []
  type: TYPE_NORMAL
  zh: Joshua Johnstun;
- en: 'Junteng Jia; '
  id: totrans-split-230
  prefs: []
  type: TYPE_NORMAL
  zh: Junteng Jia;
- en: 'Kalyan Vasuden Alwala; '
  id: totrans-split-231
  prefs: []
  type: TYPE_NORMAL
  zh: Kalyan Vasuden Alwala;
- en: 'Kam Hou U; '
  id: totrans-split-232
  prefs: []
  type: TYPE_NORMAL
  zh: Kam Hou U;
- en: 'Kate Plawiak; '
  id: totrans-split-233
  prefs: []
  type: TYPE_NORMAL
  zh: Kate Plawiak;
- en: 'Kartikeya Upasani; '
  id: totrans-split-234
  prefs: []
  type: TYPE_NORMAL
  zh: Kartikeya Upasani;
- en: 'Kaushik Veeraraghavan; '
  id: totrans-split-235
  prefs: []
  type: TYPE_NORMAL
  zh: Kaushik Veeraraghavan;
- en: 'Ke Li; '
  id: totrans-split-236
  prefs: []
  type: TYPE_NORMAL
  zh: Ke Li;
- en: 'Kenneth Heafield; '
  id: totrans-split-237
  prefs: []
  type: TYPE_NORMAL
  zh: Kenneth Heafield;
- en: 'Kevin Stone; '
  id: totrans-split-238
  prefs: []
  type: TYPE_NORMAL
  zh: Kevin Stone;
- en: 'Khalid El-Arini; '
  id: totrans-split-239
  prefs: []
  type: TYPE_NORMAL
  zh: Khalid El-Arini;
- en: 'Krithika Iyer; '
  id: totrans-split-240
  prefs: []
  type: TYPE_NORMAL
  zh: Krithika Iyer;
- en: 'Kshitiz Malik; '
  id: totrans-split-241
  prefs: []
  type: TYPE_NORMAL
  zh: Kshitiz Malik;
- en: 'Kuenley Chiu; '
  id: totrans-split-242
  prefs: []
  type: TYPE_NORMAL
  zh: Kuenley Chiu;
- en: 'Kunal Bhalla; '
  id: totrans-split-243
  prefs: []
  type: TYPE_NORMAL
  zh: Kunal Bhalla;
- en: 'Kyle Huang; '
  id: totrans-split-244
  prefs: []
  type: TYPE_NORMAL
  zh: Kyle Huang;
- en: 'Lakshya Garg; '
  id: totrans-split-245
  prefs: []
  type: TYPE_NORMAL
  zh: Lakshya Garg;
- en: 'Lauren Rantala-Yeary; '
  id: totrans-split-246
  prefs: []
  type: TYPE_NORMAL
  zh: Lauren Rantala-Yeary;
- en: 'Laurens van der Maaten; '
  id: totrans-split-247
  prefs: []
  type: TYPE_NORMAL
  zh: Laurens van der Maaten;
- en: 'Lawrence Chen; '
  id: totrans-split-248
  prefs: []
  type: TYPE_NORMAL
  zh: Lawrence Chen;
- en: 'Leandro Silva; '
  id: totrans-split-249
  prefs: []
  type: TYPE_NORMAL
  zh: Leandro Silva;
- en: 'Lee Bell; '
  id: totrans-split-250
  prefs: []
  type: TYPE_NORMAL
  zh: Lee Bell;
- en: 'Lei Zhang; '
  id: totrans-split-251
  prefs: []
  type: TYPE_NORMAL
  zh: Lei Zhang;
- en: 'Liang Tan; '
  id: totrans-split-252
  prefs: []
  type: TYPE_NORMAL
  zh: Liang Tan;
- en: 'Louis Martin; '
  id: totrans-split-253
  prefs: []
  type: TYPE_NORMAL
  zh: Louis Martin;
- en: 'Lovish Madaan; '
  id: totrans-split-254
  prefs: []
  type: TYPE_NORMAL
  zh: Lovish Madaan;
- en: 'Luca Wehrstedt; '
  id: totrans-split-255
  prefs: []
  type: TYPE_NORMAL
  zh: Luca Wehrstedt;
- en: 'Lukas Blecher; '
  id: totrans-split-256
  prefs: []
  type: TYPE_NORMAL
  zh: Lukas Blecher;
- en: 'Luke de Oliveira; '
  id: totrans-split-257
  prefs: []
  type: TYPE_NORMAL
  zh: Luke de Oliveira;
- en: 'Madeline Muzzi; '
  id: totrans-split-258
  prefs: []
  type: TYPE_NORMAL
  zh: Madeline Muzzi;
- en: 'Madian Khabsa; '
  id: totrans-split-259
  prefs: []
  type: TYPE_NORMAL
  zh: Madian Khabsa;
- en: 'Manav Avlani; '
  id: totrans-split-260
  prefs: []
  type: TYPE_NORMAL
  zh: Manav Avlani;
- en: 'Mannat Singh; '
  id: totrans-split-261
  prefs: []
  type: TYPE_NORMAL
  zh: Mannat Singh;
- en: 'Manohar Paluri; '
  id: totrans-split-262
  prefs: []
  type: TYPE_NORMAL
  zh: Manohar Paluri;
- en: 'Mark Zuckerberg; '
  id: totrans-split-263
  prefs: []
  type: TYPE_NORMAL
  zh: Mark Zuckerberg;
- en: 'Marcin Kardas; '
  id: totrans-split-264
  prefs: []
  type: TYPE_NORMAL
  zh: Marcin Kardas;
- en: 'Martynas Mankus; '
  id: totrans-split-265
  prefs: []
  type: TYPE_NORMAL
  zh: Martynas Mankus;
- en: 'Mathew Oldham; '
  id: totrans-split-266
  prefs: []
  type: TYPE_NORMAL
  zh: Mathew Oldham;
- en: 'Mathieu Rita; '
  id: totrans-split-267
  prefs: []
  type: TYPE_NORMAL
  zh: Mathieu Rita;
- en: 'Matthew Lennie; '
  id: totrans-split-268
  prefs: []
  type: TYPE_NORMAL
  zh: Matthew Lennie;
- en: 'Maya Pavlova; '
  id: totrans-split-269
  prefs: []
  type: TYPE_NORMAL
  zh: Maya Pavlova;
- en: 'Meghan Keneally; '
  id: totrans-split-270
  prefs: []
  type: TYPE_NORMAL
  zh: Meghan Keneally;
- en: 'Melanie Kambadur; '
  id: totrans-split-271
  prefs: []
  type: TYPE_NORMAL
  zh: Melanie Kambadur;
- en: 'Mihir Patel; '
  id: totrans-split-272
  prefs: []
  type: TYPE_NORMAL
  zh: Mihir Patel;
- en: 'Mikayel Samvelyan; '
  id: totrans-split-273
  prefs: []
  type: TYPE_NORMAL
  zh: Mikayel Samvelyan;
- en: 'Mike Clark; '
  id: totrans-split-274
  prefs: []
  type: TYPE_NORMAL
  zh: Mike Clark;
- en: 'Mike Lewis; '
  id: totrans-split-275
  prefs: []
  type: TYPE_NORMAL
  zh: Mike Lewis;
- en: 'Min Si; '
  id: totrans-split-276
  prefs: []
  type: TYPE_NORMAL
  zh: Min Si;
- en: 'Mitesh Kumar Singh; '
  id: totrans-split-277
  prefs: []
  type: TYPE_NORMAL
  zh: Mitesh Kumar Singh;
- en: 'Mo Metanat; '
  id: totrans-split-278
  prefs: []
  type: TYPE_NORMAL
  zh: Mo Metanat;
- en: 'Mona Hassan; '
  id: totrans-split-279
  prefs: []
  type: TYPE_NORMAL
  zh: Mona Hassan;
- en: 'Naman Goyal; '
  id: totrans-split-280
  prefs: []
  type: TYPE_NORMAL
  zh: Naman Goyal;
- en: 'Narjes Torabi; '
  id: totrans-split-281
  prefs: []
  type: TYPE_NORMAL
  zh: Narjes Torabi;
- en: 'Nicolas Usunier; '
  id: totrans-split-282
  prefs: []
  type: TYPE_NORMAL
  zh: Nicolas Usunier;
- en: 'Nikolay Bashlykov; '
  id: totrans-split-283
  prefs: []
  type: TYPE_NORMAL
  zh: Nikolay Bashlykov;
- en: 'Nikolay Bogoychev; '
  id: totrans-split-284
  prefs: []
  type: TYPE_NORMAL
  zh: Nikolay Bogoychev;
- en: 'Niladri Chatterji; '
  id: totrans-split-285
  prefs: []
  type: TYPE_NORMAL
  zh: Niladri Chatterji;
- en: 'Ning Dong; '
  id: totrans-split-286
  prefs: []
  type: TYPE_NORMAL
  zh: Ning Dong;
- en: 'Oliver Aobo Yang; '
  id: totrans-split-287
  prefs: []
  type: TYPE_NORMAL
  zh: Oliver Aobo Yang;
- en: 'Olivier Duchenne; '
  id: totrans-split-288
  prefs: []
  type: TYPE_NORMAL
  zh: Olivier Duchenne;
- en: 'Onur Celebi; '
  id: totrans-split-289
  prefs: []
  type: TYPE_NORMAL
  zh: Onur Celebi;
- en: 'Parth Parekh; '
  id: totrans-split-290
  prefs: []
  type: TYPE_NORMAL
  zh: Parth Parekh;
- en: 'Patrick Alrassy; '
  id: totrans-split-291
  prefs: []
  type: TYPE_NORMAL
  zh: Patrick Alrassy;
- en: 'Paul Saab; '
  id: totrans-split-292
  prefs: []
  type: TYPE_NORMAL
  zh: Paul Saab;
- en: 'Pavan Balaji; '
  id: totrans-split-293
  prefs: []
  type: TYPE_NORMAL
  zh: Pavan Balaji;
- en: 'Pedro Rittner; '
  id: totrans-split-294
  prefs: []
  type: TYPE_NORMAL
  zh: Pedro Rittner;
- en: 'Pengchuan Zhang; '
  id: totrans-split-295
  prefs: []
  type: TYPE_NORMAL
  zh: Pengchuan Zhang;
- en: 'Pengwei Li; '
  id: totrans-split-296
  prefs: []
  type: TYPE_NORMAL
  zh: Pengwei Li;
- en: 'Petar Vasic; '
  id: totrans-split-297
  prefs: []
  type: TYPE_NORMAL
  zh: Petar Vasic;
- en: 'Peter Weng; '
  id: totrans-split-298
  prefs: []
  type: TYPE_NORMAL
  zh: Peter Weng;
- en: 'Polina Zvyagina; '
  id: totrans-split-299
  prefs: []
  type: TYPE_NORMAL
  zh: Polina Zvyagina;
- en: 'Prajjwal Bhargava; '
  id: totrans-split-300
  prefs: []
  type: TYPE_NORMAL
  zh: Prajjwal Bhargava;
- en: 'Pratik Dubal; '
  id: totrans-split-301
  prefs: []
  type: TYPE_NORMAL
  zh: Pratik Dubal;
- en: 'Praveen Krishnan; '
  id: totrans-split-302
  prefs: []
  type: TYPE_NORMAL
  zh: Praveen Krishnan;
- en: 'Punit Singh Koura; '
  id: totrans-split-303
  prefs: []
  type: TYPE_NORMAL
  zh: Punit Singh Koura;
- en: 'Puxin Xu; '
  id: totrans-split-304
  prefs: []
  type: TYPE_NORMAL
  zh: Puxin Xu;
- en: 'Qing He; '
  id: totrans-split-305
  prefs: []
  type: TYPE_NORMAL
  zh: Qing He;
- en: 'Rachel Rodriguez; '
  id: totrans-split-306
  prefs: []
  type: TYPE_NORMAL
  zh: Rachel Rodriguez;
- en: 'Ragavan Srinivasan; '
  id: totrans-split-307
  prefs: []
  type: TYPE_NORMAL
  zh: Ragavan Srinivasan;
- en: 'Rahul Mitra; '
  id: totrans-split-308
  prefs: []
  type: TYPE_NORMAL
  zh: Rahul Mitra;
- en: 'Ramon Calderer; '
  id: totrans-split-309
  prefs: []
  type: TYPE_NORMAL
  zh: Ramon Calderer;
- en: 'Raymond Li; '
  id: totrans-split-310
  prefs: []
  type: TYPE_NORMAL
  zh: Raymond Li;
- en: 'Robert Stojnic; '
  id: totrans-split-311
  prefs: []
  type: TYPE_NORMAL
  zh: Robert Stojnic;
- en: 'Roberta Raileanu; '
  id: totrans-split-312
  prefs: []
  type: TYPE_NORMAL
  zh: Roberta Raileanu;
- en: 'Robin Battey; '
  id: totrans-split-313
  prefs: []
  type: TYPE_NORMAL
  zh: Robin Battey;
- en: 'Rocky Wang; '
  id: totrans-split-314
  prefs: []
  type: TYPE_NORMAL
  zh: Rocky Wang;
- en: 'Rohit Girdhar; '
  id: totrans-split-315
  prefs: []
  type: TYPE_NORMAL
  zh: Rohit Girdhar;
- en: 'Rohit Patel; '
  id: totrans-split-316
  prefs: []
  type: TYPE_NORMAL
  zh: Rohit Patel;
- en: 'Romain Sauvestre; '
  id: totrans-split-317
  prefs: []
  type: TYPE_NORMAL
  zh: Romain Sauvestre;
- en: 'Ronnie Polidoro; '
  id: totrans-split-318
  prefs: []
  type: TYPE_NORMAL
  zh: Ronnie Polidoro;
- en: 'Roshan Sumbaly; '
  id: totrans-split-319
  prefs: []
  type: TYPE_NORMAL
  zh: Roshan Sumbaly;
- en: 'Ross Taylor; '
  id: totrans-split-320
  prefs: []
  type: TYPE_NORMAL
  zh: Ross Taylor;
- en: 'Ruan Silva; '
  id: totrans-split-321
  prefs: []
  type: TYPE_NORMAL
  zh: Ruan Silva;
- en: 'Rui Hou; '
  id: totrans-split-322
  prefs: []
  type: TYPE_NORMAL
  zh: Rui Hou;
- en: 'Rui Wang; '
  id: totrans-split-323
  prefs: []
  type: TYPE_NORMAL
  zh: Rui Wang;
- en: 'Russ Howes; '
  id: totrans-split-324
  prefs: []
  type: TYPE_NORMAL
  zh: Russ Howes;
- en: 'Ruty Rinott; '
  id: totrans-split-325
  prefs: []
  type: TYPE_NORMAL
  zh: Ruty Rinott;
- en: 'Saghar Hosseini; '
  id: totrans-split-326
  prefs: []
  type: TYPE_NORMAL
  zh: Saghar Hosseini;
- en: 'Sai Jayesh Bondu; '
  id: totrans-split-327
  prefs: []
  type: TYPE_NORMAL
  zh: Sai Jayesh Bondu;
- en: 'Samyak Datta; '
  id: totrans-split-328
  prefs: []
  type: TYPE_NORMAL
  zh: Samyak Datta;
- en: 'Sanjay Singh; '
  id: totrans-split-329
  prefs: []
  type: TYPE_NORMAL
  zh: Sanjay Singh;
- en: 'Sara Chugh; '
  id: totrans-split-330
  prefs: []
  type: TYPE_NORMAL
  zh: Sara Chugh;
- en: 'Sargun Dhillon; '
  id: totrans-split-331
  prefs: []
  type: TYPE_NORMAL
  zh: Sargun Dhillon;
- en: 'Satadru Pan; '
  id: totrans-split-332
  prefs: []
  type: TYPE_NORMAL
  zh: Satadru Pan;
- en: 'Sean Bell; '
  id: totrans-split-333
  prefs: []
  type: TYPE_NORMAL
  zh: Sean Bell;
- en: 'Sergey Edunov; '
  id: totrans-split-334
  prefs: []
  type: TYPE_NORMAL
  zh: Sergey Edunov;
- en: 'Shaoliang Nie; '
  id: totrans-split-335
  prefs: []
  type: TYPE_NORMAL
  zh: Shaoliang Nie;
- en: 'Sharan Narang; '
  id: totrans-split-336
  prefs: []
  type: TYPE_NORMAL
  zh: Sharan Narang;
- en: 'Sharath Raparthy; '
  id: totrans-split-337
  prefs: []
  type: TYPE_NORMAL
  zh: Sharath Raparthy;
- en: 'Shaun Lindsay; '
  id: totrans-split-338
  prefs: []
  type: TYPE_NORMAL
  zh: Shaun Lindsay;
- en: 'Sheng Feng; '
  id: totrans-split-339
  prefs: []
  type: TYPE_NORMAL
  zh: Sheng Feng;
- en: 'Sheng Shen; '
  id: totrans-split-340
  prefs: []
  type: TYPE_NORMAL
  zh: Sheng Shen;
- en: 'Shenghao Lin; '
  id: totrans-split-341
  prefs: []
  type: TYPE_NORMAL
  zh: Shenghao Lin;
- en: 'Shiva Shankar; '
  id: totrans-split-342
  prefs: []
  type: TYPE_NORMAL
  zh: Shiva Shankar;
- en: 'Shruti Bhosale; '
  id: totrans-split-343
  prefs: []
  type: TYPE_NORMAL
  zh: Shruti Bhosale;
- en: 'Shun Zhang; '
  id: totrans-split-344
  prefs: []
  type: TYPE_NORMAL
  zh: Shun Zhang;
- en: 'Simon Vandenhende; '
  id: totrans-split-345
  prefs: []
  type: TYPE_NORMAL
  zh: Simon Vandenhende;
- en: 'Sinong Wang; '
  id: totrans-split-346
  prefs: []
  type: TYPE_NORMAL
  zh: Sinong Wang;
- en: 'Seohyun Sonia Kim; '
  id: totrans-split-347
  prefs: []
  type: TYPE_NORMAL
  zh: Seohyun Sonia Kim;
- en: 'Soumya Batra; '
  id: totrans-split-348
  prefs: []
  type: TYPE_NORMAL
  zh: Soumya Batra;
- en: 'Sten Sootla; '
  id: totrans-split-349
  prefs: []
  type: TYPE_NORMAL
  zh: Sten Sootla;
- en: 'Steve Kehoe; '
  id: totrans-split-350
  prefs: []
  type: TYPE_NORMAL
  zh: Steve Kehoe;
- en: 'Suchin Gururangan; '
  id: totrans-split-351
  prefs: []
  type: TYPE_NORMAL
  zh: Suchin Gururangan;
- en: 'Sumit Gupta; '
  id: totrans-split-352
  prefs: []
  type: TYPE_NORMAL
  zh: Sumit Gupta;
- en: 'Sunny Virk; '
  id: totrans-split-353
  prefs: []
  type: TYPE_NORMAL
  zh: Sunny Virk;
- en: 'Sydney Borodinsky; '
  id: totrans-split-354
  prefs: []
  type: TYPE_NORMAL
  zh: Sydney Borodinsky;
- en: 'Tamar Glaser; '
  id: totrans-split-355
  prefs: []
  type: TYPE_NORMAL
  zh: Tamar Glaser;
- en: 'Tamar Herman; '
  id: totrans-split-356
  prefs: []
  type: TYPE_NORMAL
  zh: Tamar Herman;
- en: 'Tamara Best; '
  id: totrans-split-357
  prefs: []
  type: TYPE_NORMAL
  zh: Tamara Best;
- en: 'Tara Fowler; '
  id: totrans-split-358
  prefs: []
  type: TYPE_NORMAL
  zh: Tara Fowler;
- en: 'Thomas Georgiou; '
  id: totrans-split-359
  prefs: []
  type: TYPE_NORMAL
  zh: Thomas Georgiou;
- en: 'Thomas Scialom; '
  id: totrans-split-360
  prefs: []
  type: TYPE_NORMAL
  zh: Thomas Scialom;
- en: 'Tianhe Li; '
  id: totrans-split-361
  prefs: []
  type: TYPE_NORMAL
  zh: Tianhe Li;
- en: 'Todor Mihaylov; '
  id: totrans-split-362
  prefs: []
  type: TYPE_NORMAL
  zh: Todor Mihaylov;
- en: 'Tong Xiao; '
  id: totrans-split-363
  prefs: []
  type: TYPE_NORMAL
  zh: Tong Xiao;
- en: 'Ujjwal Karn; '
  id: totrans-split-364
  prefs: []
  type: TYPE_NORMAL
  zh: Ujjwal Karn;
- en: 'Vedanuj Goswami; '
  id: totrans-split-365
  prefs: []
  type: TYPE_NORMAL
  zh: Vedanuj Goswami;
- en: 'Vibhor Gupta; '
  id: totrans-split-366
  prefs: []
  type: TYPE_NORMAL
  zh: Vibhor Gupta;
- en: 'Vignesh Ramanathan; '
  id: totrans-split-367
  prefs: []
  type: TYPE_NORMAL
  zh: Vignesh Ramanathan;
- en: 'Viktor Kerkez; '
  id: totrans-split-368
  prefs: []
  type: TYPE_NORMAL
  zh: Viktor Kerkez;
- en: 'Vinay Satish Kumar; '
  id: totrans-split-369
  prefs: []
  type: TYPE_NORMAL
  zh: Vinay Satish Kumar;
- en: 'Vincent Gonguet; '
  id: totrans-split-370
  prefs: []
  type: TYPE_NORMAL
  zh: Vincent Gonguet;
- en: 'Vish Vogeti; '
  id: totrans-split-371
  prefs: []
  type: TYPE_NORMAL
  zh: Vish Vogeti;
- en: 'Vlad Poenaru; '
  id: totrans-split-372
  prefs: []
  type: TYPE_NORMAL
  zh: Vlad Poenaru;
- en: 'Vlad Tiberiu Mihailescu; '
  id: totrans-split-373
  prefs: []
  type: TYPE_NORMAL
  zh: Vlad Tiberiu Mihailescu;
- en: 'Vladan Petrovic; '
  id: totrans-split-374
  prefs: []
  type: TYPE_NORMAL
  zh: Vladan Petrovic;
- en: 'Vladimir Ivanov; '
  id: totrans-split-375
  prefs: []
  type: TYPE_NORMAL
  zh: Vladimir Ivanov;
- en: 'Wei Li; '
  id: totrans-split-376
  prefs: []
  type: TYPE_NORMAL
  zh: Wei Li;
- en: 'Weiwei Chu; '
  id: totrans-split-377
  prefs: []
  type: TYPE_NORMAL
  zh: Weiwei Chu;
- en: 'Wenhan Xiong; '
  id: totrans-split-378
  prefs: []
  type: TYPE_NORMAL
  zh: Wenhan Xiong;
- en: 'Wenyin Fu; '
  id: totrans-split-379
  prefs: []
  type: TYPE_NORMAL
  zh: Wenyin Fu;
- en: 'Wes Bouaziz; '
  id: totrans-split-380
  prefs: []
  type: TYPE_NORMAL
  zh: Wes Bouaziz;
- en: 'Whitney Meers; '
  id: totrans-split-381
  prefs: []
  type: TYPE_NORMAL
  zh: Whitney Meers;
- en: 'Will Constable; '
  id: totrans-split-382
  prefs: []
  type: TYPE_NORMAL
  zh: Will Constable;
- en: 'Xavier Martinet; '
  id: totrans-split-383
  prefs: []
  type: TYPE_NORMAL
  zh: Xavier Martinet;
- en: 'Xiaojian Wu; '
  id: totrans-split-384
  prefs: []
  type: TYPE_NORMAL
  zh: Xiaojian Wu;
- en: 'Xinbo Gao; '
  id: totrans-split-385
  prefs: []
  type: TYPE_NORMAL
  zh: Xinbo Gao;
- en: 'Xinfeng Xie; '
  id: totrans-split-386
  prefs: []
  type: TYPE_NORMAL
  zh: Xinfeng Xie;
- en: 'Xuchao Jia; '
  id: totrans-split-387
  prefs: []
  type: TYPE_NORMAL
  zh: Xuchao Jia;
- en: 'Yaelle Goldschlag; '
  id: totrans-split-388
  prefs: []
  type: TYPE_NORMAL
  zh: Yaelle Goldschlag;
- en: 'Yann LeCun; '
  id: totrans-split-389
  prefs: []
  type: TYPE_NORMAL
  zh: Yann LeCun;
- en: 'Yashesh Gaur; '
  id: totrans-split-390
  prefs: []
  type: TYPE_NORMAL
  zh: Yashesh Gaur;
- en: 'Yasmine Babaei; '
  id: totrans-split-391
  prefs: []
  type: TYPE_NORMAL
  zh: Yasmine Babaei;
- en: 'Ye Qi; '
  id: totrans-split-392
  prefs: []
  type: TYPE_NORMAL
  zh: Ye Qi;
- en: 'Yenda Li; '
  id: totrans-split-393
  prefs: []
  type: TYPE_NORMAL
  zh: Yenda Li;
- en: 'Yi Wen; '
  id: totrans-split-394
  prefs: []
  type: TYPE_NORMAL
  zh: Yi Wen;
- en: 'Yiwen Song; '
  id: totrans-split-395
  prefs: []
  type: TYPE_NORMAL
  zh: Yiwen Song;
- en: 'Youngjin Nam; '
  id: totrans-split-396
  prefs: []
  type: TYPE_NORMAL
  zh: Youngjin Nam;
- en: 'Yuchen Hao; '
  id: totrans-split-397
  prefs: []
  type: TYPE_NORMAL
  zh: Yuchen Hao;
- en: 'Yuchen Zhang; '
  id: totrans-split-398
  prefs: []
  type: TYPE_NORMAL
  zh: Yuchen Zhang;
- en: 'Yun Wang; '
  id: totrans-split-399
  prefs: []
  type: TYPE_NORMAL
  zh: Yun Wang;
- en: 'Yuning Mao; '
  id: totrans-split-400
  prefs: []
  type: TYPE_NORMAL
  zh: Yuning Mao;
- en: 'Yuzi He; '
  id: totrans-split-401
  prefs: []
  type: TYPE_NORMAL
  zh: Yuzi He;
- en: 'Zacharie Delpierre Coudert; '
  id: totrans-split-402
  prefs: []
  type: TYPE_NORMAL
  zh: Zacharie Delpierre Coudert;
- en: 'Zachary DeVito; '
  id: totrans-split-403
  prefs: []
  type: TYPE_NORMAL
  zh: Zachary DeVito;
- en: 'Zahra Hankir; '
  id: totrans-split-404
  prefs: []
  type: TYPE_NORMAL
  zh: Zahra Hankir;
- en: 'Zhaoduo Wen; '
  id: totrans-split-405
  prefs: []
  type: TYPE_NORMAL
  zh: Zhaoduo Wen;
- en: 'Zheng Yan; '
  id: totrans-split-406
  prefs: []
  type: TYPE_NORMAL
  zh: Zheng Yan;
- en: 'Zhengxing Chen; '
  id: totrans-split-407
  prefs: []
  type: TYPE_NORMAL
  zh: Zhengxing Chen;
- en: 'Zhenyu Yang; '
  id: totrans-split-408
  prefs: []
  type: TYPE_NORMAL
  zh: Zhenyu Yang;
- en: Zoe Papakipos
  id: totrans-split-409
  prefs: []
  type: TYPE_NORMAL
  zh: Zoe Papakipos
