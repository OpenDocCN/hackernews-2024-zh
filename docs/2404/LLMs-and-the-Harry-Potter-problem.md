<!--yml

类别：未分类

日期：2024年5月27日13:27:25

-->

# LLMs 和《哈利·波特问题》

> 来源：[https://www.pyqai.com/blog/llms-and-the-harry-potter-problem](https://www.pyqai.com/blog/llms-and-the-harry-potter-problem)

### 简介

当前，长上下文LLM正在风靡，感觉每一个新LLM都将其上下文窗口增加了一个数量级。它们甚至在典型的基准测试中表现良好，比如[大海里的针](https://arstechnica.com/information-technology/2024/03/claude-3-seems-to-detect-when-it-is-being-tested-sparking-ai-buzz-online/)。不幸的是，在我们看来，它们仍然存在一些关键问题：我们称之为《哈利·波特问题》。

在本文中，我们将从问题及其实际影响的描述开始。在回应我们的校对人员（感谢所有人），我们解释为什么代理、开箱即用的RAG和微调不足以解决这个问题。对于更技术性的读者，我们还提供了一些进一步阅读和数据。

> "大语言模型可能有很大的上下文窗口，但它们仍然不能很好地利用大上下文中的信息，特别是在高价值的使用案例中。"

#### 问题

想象一下，你给一个LLM（注：不是一个代理人 - 为什么我们关心LLM的能力会在本文稍后解释）一章《哈利·波特》，并要求它计算“wizard”一词出现的次数。截至本文撰写时，GPT4、Claude 3 Opus、Gemini Ultra 和 Mixtral - 都是当今的技术代表 - 尽管上下文窗口很大，但在这项任务上都失败了。

这个测试显然有分裂的焦点：它既在衡量模型的上下文回忆能力，也在计数能力上，这两者都是弱点。就本次讨论而言，我们将重点放在上下文回忆上，因为这与长上下文模型的要点更为相关。

这里有一些摘要统计数据，帮助描述这个问题。请阅读到最后以了解我们所有测试和方法论的详细信息：

1.  **GPT4 Turbo：对于大于等于64k个标记的文档，准确率为55%**

1.  **Claude 3 Opus：对于大于等于64k个标记的文档，准确率为65%**

1.  **Mixtral 8x7b Instruct：对于大于等于64k个标记的文档，准确率为17.5%**

1.  **Gemini 1.5 Pro：对于大于等于64k个标记的文档，准确率为45%**

显然，在长上下文中，没有一个表现特别出色的。关于我们的方法论的更多细节，请参阅本文末尾。

#### 为什么我要关心？

简而言之，这个问题可能会严重影响LLM的准确性，并且非常难以捕捉。《哈利·波特》只是一个无辜的例子，但是当涉及到更高价值的使用案例时，这个问题会更加昂贵。例如，我们分析保险政策。它们有70-120页，非常密集，期望读者在分布在各个页面上的信息之间建立逻辑联系（比如，第5页和第95页各一句）。因此，回答类似“我的火灾损失覆盖是多少？”这样的问题意味着你必须阅读：

1.  第2页（保费）

1.  第3页（免赔额和限额）

1.  第78页（火灾损害除外）

1.  第94页（“火灾损害”的法律定义）

对于人类专家来说已经很难了，对于任何现有的LLM来说几乎是不可能的。更大的问题是上述过程的任何失败可能会实质性地影响高价值用例中答案的正确性。更糟糕的是，模型可以（而且会）自信地编造。可能会出现此类问题的其他情况包括：审查冗长的法律案件、理解代码库、为两岁以上的任何人审查医疗记录等。

#### RAG 不解决这个问题吗？

不完全是这样。传统的 RAG - 我们在谈论 LangChain + 嵌入模型 + OpenAI + 语义/混合搜索 - 并未考虑文档的结构和信息层次结构。这意味着检索到的片段和提示忽略了其附近可能相关的其他信息。例如：如果您在保险单中查找“火灾保险”，并提取了一个定义了“火灾保险”类型的片段，它可能是涵盖或排除的火灾类型，描述此类信息的位置比这个片段早几页。如果您真的想保留整个结构，您最终会增加片段大小，检索大量上下文，并最终回到起点。

元数据过滤更接近一步，但它也并未完全解决问题。您仍然将检索限制为一些任意数量的片段，可能会错过一些上下文。

#### 微调难道不能解决这个问题吗？

只能解决部分。像 LoRA 和其他“快速”微调方法并不能解决 LLMs 倾向于消化上下文的根本问题，因为已经表明它们更注重文档开头和结尾而不是靠近中间位置的信息 [1 - “中间丢失”]。一系列精心规划的全面微调，按照特定顺序进行，可以帮助长文本的性能 [3 - LongRoPE]。这里的核心问题是长文本的成本和稀缺性（特别是行业特定的文本）。

#### 代理不解决这个问题吗？

就我写这篇文章的时候而言，代理有潜力解决这个问题，但还没有到位。OpenAI 通过调用工具可以解决哈利·波特的问题，但仍然错过了文档的更大背景，这正是这次讨论的重点。为了使其工作，代理需要自主消化整个文档，开发一个适合您用例的本体论，并找到一种解析文档及其所有复杂性的方法。这将是一个启示，我们希望这种情况发生。不幸的是，我们对代理的经验尚未产生令人满意的结果。

#### 好的，你打算怎么解决？

我们发现解决这个问题的最佳方法是对每个长文档的外观有一个有主见的看法，它应包含的信息，以及文档内部信息的互联关系。这是一项艰巨的任务，并且不具有普遍性，所以很遗憾这里没有捷径。例如，我们花了数月时间研究我们能获取到的每一份保险单，以制定一个本体论，我们试图将文档适应其上，并围绕此建立了摄入和检索管道。

基本上，我们进行了一种权衡：为了获得对保险政策的深入理解，我们放弃了理解其他任何事物的能力。我们不得不修改我们的通用检索引擎，以处理我们知识范围外（据我们所知）不存在的某些类型的查询，LLM以便能够正确理解行业术语，并且我们的文档摄入要能够处理传真（是的，这也是一种情况）。知识图谱在正确的方法下可能会有所帮助，如同最近宣布的多种分块技术的实验。

另一个需要考虑的事项是将文档视为百科全书 - 建立目录、术语表和LLM可以在检索片段之前查阅的引用列表。这在摄入过程中也很有用。

#### 我如何为自己的文档做到这一点？

首先，选择您希望理解的文档类别，并接受您必须为每个新类别重复此过程，直到：

1.  哈利波特问题已解决，或者

1.  有人提出了一个通用的方法，可以从文档中构建知识图谱，并且实际有效。

Side-note: 我们很乐意听到关于b工作的讨论，特别是考虑到长内容LLM数量的增加。

接下来，对你认为所有这类文档必须具备的信息形成一个看法。尝试列出它们，它们的类型以及它们之间的关系（图论在此方面是有帮助的）。

最后，这比做起来容易得多，尝试尽可能多的示例。很可能您需要多次迭代才能看到良好的结果。然而，对于正确的商业问题，果实是值得的。

#### 描述性统计

这并不意味着全面或学术化，但希望这些统计数据能帮助传达观点。您可以使用以下提示和信息自行尝试它们。

*给定哈利波特问题时，前4个LLM的准确性*

*测试简单事实查询时前4个LLM的准确性，要求在上下文中回忆*

*被要求在大量信息中找到多个关键信息时，前4个LLM的准确性*

*被要求列出所有保险政策覆盖类型时，前4个LLM的准确性*

##### 提示和方法论

我们对每个以下提示使用相同的输入和不同的温度进行了10次运行，以最小化模型运气不佳的情况。它们通过另一个LLM（GPT3.5）和人工审查的组合进行评估。不完整的答案以及包含无关信息的冗长答案都被视为错误。结果是所有运行的综合。

提示：

1.  在以下摘录中，“巫师”一词出现了多少次？ <《哈利·波特与混血王子》第一章在此>

1.  基于以下信息，多德-弗兰克法案的第523节是关于什么的？ <[多德-弗兰克法案章节摘要，美国国会](https://www.congress.gov/bill/111th-congress/house-bill/4173)>

1.  列出以下文件中第V标题，B小标题的前5个编号部分及其摘要：<[多德-弗兰克法案章节摘要，美国国会](https://www.congress.gov/bill/111th-congress/house-bill/4173)>

1.  列出以下保险单中的所有保险类型。一些例子包括：专业责任、商业综合责任、雇员福利责任以及网络和隐私。 <因隐私原因保险单已删除，请使用任何商业保单>

‍

#### 技术阅读

1.  [中间迷失](https://arxiv.org/abs/2307.03172)：对LLMs和长上下文的基本问题进行了相当不错的审查

1.  [RULER](https://arxiv.org/abs/2404.06654)：由Nvidia研究人员提出的一个新框架，旨在取代干草堆中的针测试。这更严谨地展示了哈利·波特问题。

1.  [ALiBi](https://arxiv.org/abs/2108.12409) 和 [LongRoPE](https://arxiv.org/abs/2402.13753)（是T5模型中最受欢迎的RoPE设计的扩展）：我们如何在没有相等大文本训练的情况下获得更大的上下文窗口

1.  [长文本环境下的LLMs在长期文本学习中的挑战](https://huggingface.co/papers/2404.02060)

*想要分析和比较长而复杂的保险单？通过上述链接预约我们的电话！*
