- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 12:54:12'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: 'AI & the Web: Understanding and managing the impact of Machine Learning models
    on the Web'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://www.w3.org/reports/ai-web-impact/](https://www.w3.org/reports/ai-web-impact/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This document proposes an analysis of the systemic impact of [AI systems](#dfn-artificial-intelligence-system),
    and in particular ones based on [Machine Learning models](#dfn-model), on the
    Web, and the role that Web standardization may play in managing that impact.
  prefs: []
  type: TYPE_NORMAL
- en: Status of This Document
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This document is intended to capture the current shared understanding of the
    [W3C Team](https://www.w3.org/staff/) on the current and expected impact of developments
    linked to [Artificial Intelligence systems](#dfn-artificial-intelligence-system)
    on the Web, and identifying explorations the World Wide Web Consortium community
    has started or ought to be starting, to manage that impact. It does not represent
    any consensus from the W3C Membership nor is it a standardization document.
  prefs: []
  type: TYPE_NORMAL
- en: The document was authored by Dominique Hazaël-Massieux ([dom@w3.org](mailto:dom@w3.org)),
    with significant contributions from the rest of the W3C Team.
  prefs: []
  type: TYPE_NORMAL
- en: This document aims first and foremost to help structure discussions on what
    may be needed at the standardization level to make the systemic impact of AI (and
    specifically, [Machine Learning models](#dfn-model)) less harmful or more manageable.
    It is bound to be incomplete and sometimes wrong - we are gathering input and
    feedback in [GitHub](https://github.com/w3c/ai-web-impact/issues), preferably
    before June 30, 2024.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the feedback received, possible next steps include more in-depth
    stakeholder interviews, a dedicated W3C Workshop, or developing a standardization
    roadmap.
  prefs: []
  type: TYPE_NORMAL
- en: Table of Contents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Abstract](#abstract)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Status of This Document](#sotd)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">1\.</bdi> Executive Summary](#executive-summary)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">2\.</bdi> Introduction](#introduction)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">2.1</bdi> Terminology](#terminology)'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">3\.</bdi> Intersections between AI systems and the Web](#intersections-between-ai-systems-and-the-web)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">4\.</bdi> Ethics and societal impact](#ethics-and-societal-impact)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">4.1</bdi> Respecting autonomy and transparency](#respecting-autonomy-and-transparency)'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">4.1.1</bdi> Transparency on AI-generated content](#transparency-on-ai-generated-content)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">4.1.2</bdi> Transparency on AI-mediated services](#transparency-on-ai-mediated-services)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">4.2</bdi> Right to privacy and data control](#right-to-privacy-and-data-control)'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">4.3</bdi> Safety and security](#safety-and-security)'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">4.4</bdi> Sustainability](#sustainability)'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">4.5</bdi> Balancing content creators incentives and consumers
    rights](#balancing-content-creators-incentives-and-consumers-rights)'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">4.5.1</bdi> Comparison with search engines](#comparison-with-search-engines)'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">5\.</bdi> Impact of AI systems on interoperability](#interop)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">A.</bdi> References](#references)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[<bdi class="secno">A.1</bdi> Informative references](#informative-references)'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Machine Learning models](#dfn-model) support a new generation of [AI systems](#dfn-artificial-intelligence-system).
    These models are often [trained](#dfn-training) on a large amount of Web content,
    deployed at scale through web interfaces, and can be used to generate plausible
    content at unprecedented speed and cost.'
  prefs: []
  type: TYPE_NORMAL
- en: Given the scope and scale of these intersections, this wave of [AI systems](#dfn-artificial-intelligence-system)
    is having potential systemic impact on the Web and some of the equilibriums on
    which its ecosystem had grown.
  prefs: []
  type: TYPE_NORMAL
- en: 'This document reviews these intersections through their ethical, societal and
    technical impacts and highlights a number of areas where standardization, guidelines
    and interoperability could help manage these changes:'
  prefs: []
  type: TYPE_NORMAL
- en: We are [seeking input](https://github.com/w3c/ai-web-impact/issues) from the
    community on proposals that could help make progress on these topics, and on other
    topics that this document has failed to identify.
  prefs: []
  type: TYPE_NORMAL
- en: Recent developments in the decades-long computer science field of Artificial
    Intelligence have made a number of systems emerge that already have started having
    **systemic** impacts on the Web and can be expected to further transform a number
    of shared expectations on which the health of the Web had relied so far.
  prefs: []
  type: TYPE_NORMAL
- en: To help structure a conversation within the W3C community (and possibly with
    other Web-related standards organization) about these transformations, this document
    collects the current shared understanding among the W3C Team of the intersections
    of "[Artificial Intelligence](#dfn-artificial-intelligence)", more specifically
    in the field of [Machine Learning models](#dfn-model) (including Large Language
    Models and other so called generative AI models), with the Web as a system, and
    ongoing W3C development in this space. It is also a goal to raise questions about
    additional explorations that may be needed as further developments in this space
    arise.
  prefs: []
  type: TYPE_NORMAL
- en: That current understanding is bound to be incomplete or sometimes plain wrong;
    we hope that by publishing this document and inviting community reviews on it,
    we iteratively improve this shared understanding and help build a community roadmap
    to increase the positive impact and decrease the harms that are emerging in this
    intersection.
  prefs: []
  type: TYPE_NORMAL
- en: The term "Artificial Intelligence" covers a very broad spectrum of algorithms,
    techniques and technologies. [[ISO/IEC-22989](#bib-iso/iec-22989 "Artificial intelligence
    concepts and terminology")] defines <dfn id="dfn-artificial-intelligence" tabindex="0"
    aria-haspopup="dialog" data-dfn-type="dfn">Artificial Intelligence</dfn> as "research
    and development of mechanisms and applications of [AI systems](#dfn-artificial-intelligence-system)",
    with <dfn data-lt="Artificial Intelligence system|AI system" data-plurals="ai
    systems|artificial intelligence systems" id="dfn-artificial-intelligence-system"
    tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">AI system</dfn>s being
    "an engineered system that generates outputs such as content, forecasts, recommendations
    or decisions for a given set of human-defined objectives". At the time of the
    writing of this document in early 2024, the gist of the Web ecosystem conversation
    on Artificial Intelligence is mostly about systems based on <dfn id="dfn-machine-learning"
    tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Machine Learning</dfn>
    ("process of optimizing model parameters through computational techniques, such
    that the model's behavior reflects the data or experience") and its software manifestation,
    <dfn data-lt="model|Machine Learning model" data-plurals="machine learning models"
    id="dfn-model" tabindex="0" aria-haspopup="dialog" data-dfn-type="dfn">Machine
    Learning model</dfn>s ("mathematical construct that generates an inference or
    prediction based on input data or information").
  prefs: []
  type: TYPE_NORMAL
- en: While we acknowledge the much broader meaning of Artificial Intelligence and
    its intersection with a number of other Web- and W3C-related activities (e.g.,
    the Semantic Web and Linked Data), this document willfully focuses only on the
    current conversation around the impact that these [Machine Learning models](#dfn-model)
    are bringing to the Web. We further acknowledge that this document has been developed
    during, and is partially a response to, a cycle of inflated expectations and investments
    in that space. That situation underlines the need for a framework to structure
    the conversation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because of this focus on [Machine Learning](#dfn-machine-learning), this document
    analyzes AI impact through the two main phases needed to operate [Machine Learning
    models](#dfn-model): <dfn id="dfn-training" tabindex="0" aria-haspopup="dialog"
    data-dfn-type="dfn">training</dfn> ("process to determine or to improve the parameters
    of a Machine Learning model, based on a Machine Learning algorithm, by using training
    data") and <dfn data-lt="run|running|inference" id="dfn-run" tabindex="0" aria-haspopup="dialog"
    data-dfn-type="dfn">inference</dfn> (the actual usage of these models to produce
    their expected outcomes), which we also casually refer as running a model.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A major role the Web plays is as a platform for content creators to expose
    at scale their content to content consumers. AI directly relates to these two
    sides of the platform:'
  prefs: []
  type: TYPE_NORMAL
- en: In a number of cases, models are trained based on content crawled from the Web;
    the combination of scale and structure in that content (made possible by the underlying
    standards) has made it an invaluable source of training data that backs some of
    the most visible results in recent AI developments, such as large language models
    or image/video generators;
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conversely, a number of these AI models can be used to generate content at unprecedented
    scale, which the reach of the Web allows to deploy seamlessly to the billions
    of users of the platform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When looking more specifically at the browser-mediated part of the Web which
    remains primarily a client/server architecture, AI models can be [run](#dfn-run)
    either on the server-side or on the client-side (and somewhat more marginally
    at this point, in a [hybrid-fashion between the two](https://github.com/webmachinelearning/proposals/issues/5)).
    On the client side, they can either be provided and operated by the browser (either
    at the user's request, or at the application's request), or entirely by the client-side
    application itself.
  prefs: []
  type: TYPE_NORMAL
- en: It's also worth noting that as [AI systems](#dfn-artificial-intelligence-system)
    are gaining rapid adoption, their intersection with the Web is bound to evolve
    and possibly trigger new systemic impact; for instance, emerging [AI systems](#dfn-artificial-intelligence-system)
    that combine [Machine Learning models](#dfn-model) and content loaded from the
    Web in real-time may induce revisiting in depth the role and user experience of
    Web browsers in consuming or searching content.
  prefs: []
  type: TYPE_NORMAL
- en: The [W3C's Technical Architecture Group Ethical Web Principles](https://www.w3.org/TR/ethical-web-principles/)
    [[ethical-web-principles](#bib-ethical-web-principles "Ethical Web Principles")]
    includes ensuring "[the Web should not cause harm to society](https://www.w3.org/TR/ethical-web-principles/#noharm)".
  prefs: []
  type: TYPE_NORMAL
- en: As described above, the Web is already a key enabler in some of the recent developments
    in Artificial Intelligence, and the usage and impact of Artificial Intelligence
    is being multiplied in scale through its distribution via the Web. This calls
    for the W3C community as stewards of the Web to understand potential harms emerging
    from that combination and to identify potential mitigations to these harms.
  prefs: []
  type: TYPE_NORMAL
- en: The [Ethical Principles for Web Machine Learning](https://www.w3.org/TR/webmachinelearning-ethics/)
    [[webmachinelearning-ethics](#bib-webmachinelearning-ethics "Ethical Principles
    for Web Machine Learning")] started in the [Web Machine Learning Working Group](https://www.w3.org/groups/wg/webmachinelearning)
    combine values and principles from the UNESCO [Recommendation on the Ethics of
    Artificial Intelligence](https://unesdoc.unesco.org/ark:/48223/pf0000380455) [[UNESCO-AI](#bib-unesco-ai
    "Recommendation on the Ethics of Artificial Intelligence")] with Web-specific
    principles from the Ethical Web Principles to identify 4 values and 11 principles
    that integration of Machine Learning on the Web should follow, and which have
    helped structure this document.
  prefs: []
  type: TYPE_NORMAL
- en: Recent [AI systems](#dfn-artificial-intelligence-system) are able to assist
    in the partial or complete creation of content (textual, graphic, audio and video)
    at a level of (at least superficially) credible quality and in quantities beyond
    that developed by humans. This provides both opportunities and risks for content
    creators, but more importantly, it creates a systemic risk for content consumers
    in no longer being able to distinguish or discover authoritative or curated content
    in a sea of credible (but either possibly or willfully wrong) generated content.
  prefs: []
  type: TYPE_NORMAL
- en: 'That need is pressing directly for end-users as they individually consume content,
    but also applies to agents that end-users rely on: typically, search engines would
    likely benefit from transparency on purely AI generated content. Somewhat ironically,
    crawlers used to train AI models are likely to need such a signal as well, since
    [training](#dfn-training) models on the output of models may create unexpected
    and unwanted results.'
  prefs: []
  type: TYPE_NORMAL
- en: We do not know of any solution that could guarantee (e.g., through cryptography)
    that a given piece of content was or was not generated (partially or entirely)
    by [AI systems](#dfn-artificial-intelligence-system). That gap unfortunately leaves
    a systemic risk in terms of misinformation and spam that should be of grave concern
    for the health of the Web as a content distribution platform and of society as
    a whole.
  prefs: []
  type: TYPE_NORMAL
- en: A plausible role of standards in this space would be to at least facilitate
    the **labeling of content** to indicate whether it is the result of a **computer-generated
    process**. While such labels are unlikely to be enforceable through technical
    means, they could gain broad adoption with a combination of being automatically
    added by [AI systems](#dfn-artificial-intelligence-system) (possibly with enough
    friction that removing them would be at least somewhat costly at scale), and possibly
    serve as hooks in the regulatory context.
  prefs: []
  type: TYPE_NORMAL
- en: 'A number of proposals have already emerged in this space, which may benefit
    from more visibility, discussion and ultimately, scalable deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: An area that could be explored is role Web browsers might play in surfacing
    labelling or provenance information of content, e.g., embedded content such as
    images or video. This can currently be done by publishers' websites or independent
    verifiers, but integrating this capability into the browser could make the information
    more convenient for users to access, as well as being independent of any particular
    publisher or website where the same content may be viewed.
  prefs: []
  type: TYPE_NORMAL
- en: Models trained on un-triaged or partially triaged content off the Web are bound
    to include personally identifiable information (PII). The same is true for models
    trained on data that users have chosen to share (for public consumption or not)
    with service providers. These models can often be made to retrieve and share that
    information with any user who knows how to ask, which breaks expectations of privacy
    for those whose personal information was collected, and is likely to be in breach
    with privacy regulations in a number of jurisdictions. Worse, they create risks
    for new types of attacks (see [<bdi class="secno">4.3</bdi> Safety and security](#safety-and-security)).
  prefs: []
  type: TYPE_NORMAL
- en: While the exclusion rules discussed in the context of content creation could
    partially help with the first situation, they would not help with the second one.
    This problem space is likely to be under heavy regulatory and legal scrutiny.
  prefs: []
  type: TYPE_NORMAL
- en: From a technical standardization perspective, beyond labeling content, the emergence
    of user data being repurposed for model [training](#dfn-training) and some of
    the pushback it is generating may bring renewed momentum (from user and service
    provider alike) behind decentralized architectures that leave user data under
    less centralized control (as illustrated by the recent widening adoption of Activity
    Streams).
  prefs: []
  type: TYPE_NORMAL
- en: 'A particularly relevant instance of that pattern is emerging with so-called
    **personal data stores**: these provide ways for users to exert more fine-grained
    control of their data, by separating more clearly the roles of data store and
    data processor (which, in a traditional cloud infrastructure, would otherwise
    typically be handled by a single entity).'
  prefs: []
  type: TYPE_NORMAL
- en: That topic has most recently surfaced in W3C through the [proposed charter for
    a SOLID Working Group](https://lists.w3.org/Archives/Public/public-new-work/2023Sep/0007.html)
    late 2023 (a charter that the W3C community has recognized as important, but where
    there is not yet consensus).
  prefs: []
  type: TYPE_NORMAL
- en: Allowing to [run](#dfn-run) a model on personal data without uploading that
    data to a server is one of the key motivations behind the browser [Web Neural
    Network API](https://www.w3.org/TR/webnn/) [[WEBNN](#bib-webnn "Web Neural Network
    API")] which, completing the computing capabilities already provided by [WebAssembly](https://www.w3.org/groups/wg/wasm/)
    [[WASM-CORE-2](#bib-wasm-core-2 "WebAssembly Core Specification")] and [WebGPU](https://www.w3.org/groups/wg/gpu/)
    [[WEBGPU](#bib-webgpu "WebGPU")], provides additional Machine Learning specific
    optimizations to [run](#dfn-run) models efficiently from within the browser (and
    thus, on the end-user device).
  prefs: []
  type: TYPE_NORMAL
- en: A number of [Machine Learning models](#dfn-model) have significantly lowered
    the cost of generating credible textual, as well as audio and video (real-time
    or recorded) impersonations of real persons. This creates significant risks of
    upscaling the capabilities of phishing and other types of frauds, and thus raising
    much higher the barriers to establish trust in online interactions. If users no
    longer feel safe in their digitally-mediated interactions, the Web will no longer
    be able to play its role as a platform for these interactions.
  prefs: []
  type: TYPE_NORMAL
- en: Some of the largest and most visible [Machine Learning models](#dfn-model) are
    known or assumed to have been trained with materials crawled from the Web, without
    the explicit consent of their creators or publishers.
  prefs: []
  type: TYPE_NORMAL
- en: The controversy that has emerged from that situation is being debated (and in
    some cases, arbitrated) through the lens of copyright law.
  prefs: []
  type: TYPE_NORMAL
- en: It is not our place to determine if and how various copyright legislation bears
    on that particular usage. Beyond legal considerations, the copyright system creates
    a (relatively) shared understanding between creators and consumers that, by default,
    content cannot be redistributed, remixed, adapted or built upon without creators'
    consent. This shared understanding made it possible for a lot of content to be
    openly distributed on the Web. It also allowed creators to consider a variety
    of monetization options (subscription, pay per view, advertising) for their content
    grounded on the assumption that consumers will always reach their pages.
  prefs: []
  type: TYPE_NORMAL
- en: A number of [AI systems](#dfn-artificial-intelligence-system) combine (1) automated
    large-scale consumption of Web content, and (2) production at scale of content,
    in ways that do not recognize or otherwise compensate content it was trained from.
  prefs: []
  type: TYPE_NORMAL
- en: 'While some of these tensions are not new (as discussed below), systems based
    on Machine Learning are poised to upend the existing balance. Unless a new sustainable
    equilibrium is found, this exposes the Web to the following undesirable outcomes:'
  prefs: []
  type: TYPE_NORMAL
- en: Significantly less open distributed content (which would likely have a disproportionate
    impact on the less wealthy part of the population)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A less appealing platform to distribute content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A less direct risk may emerge from changes in copyright laws meant to help to
    rebalance the situation but which would reduce the rights from content consumers
    and then undermine the value of the Web as a platform for which content distribution
    is a key value proposition.
  prefs: []
  type: TYPE_NORMAL
- en: A number of the tensions emerging around the re-use of content crawled at scale
    from the Web have a long history given the central role that search engines play
    for the Web. Indeed, search engines provide (and absorb) value from their ability
    to retrieve and organize information from content on the Web, and they heavily
    rely on the standardized infrastructure this content is built on to achieve these
    results.
  prefs: []
  type: TYPE_NORMAL
- en: The more or less implicit contract that emerged between search engines and content
    providers has been that search engines can retrieve, parse and partially display
    content from the providers, in exchange of bringing more visibility and traffic
    to them. A further assumption has been encoded in the way the Web operates that
    this contract is the default for anyone making content available publicly on the
    Web, with an opt-out mechanism encoded via the [`robots.txt` directives](https://www.rfc-editor.org/rfc/rfc9309.html)
    [[RFC9309](#bib-rfc9309 "Robots Exclusion Protocol")].
  prefs: []
  type: TYPE_NORMAL
- en: 'Over time, in addition to the links to sites matching the user''s query, search
    engines have integrated more ways to surface content directly from the target
    Web sites: either through rich snippets (typically made possible by the use of
    schema.org metadata) or through embedded preview (e.g., what the [AMP project](https://amp.dev/)
    enabled). These changes were frequently accompanied by sometimes challenging discussions
    around the balance between bringing additional visibility to crawled content and
    reducing the incentive from end-users to visit the source website (e.g., because
    they may have already received sufficient information from the search results
    page).'
  prefs: []
  type: TYPE_NORMAL
- en: In a certain number of cases, [AI systems](#dfn-artificial-intelligence-system)
    are used as an alternative or complement to what users would traditionally have
    used a search engine for (and indeed, are increasingly integrated into search
    engine interfaces). So it seems useful to explore to what extent the lessons learned
    from the evolutionary process balancing the needs from search engines and from
    content creators can inform the discussion on crawlers used to train [Machine
    Learning models](#dfn-model).
  prefs: []
  type: TYPE_NORMAL
- en: 'In making that comparison, it''s also important to note significant differences:'
  prefs: []
  type: TYPE_NORMAL
- en: The implicit contract that content creators expect from search engines crawlers
    –i.e., that they will bring exposure to their content– does not have a systematic
    equivalent for content integrated into [AI systems](#dfn-artificial-intelligence-system);
    while some such systems are gaining the ability to point back to the source of
    their training data used in a given [inference](#dfn-run), this is hardly a widespread
    feature of these systems, nor is it obvious it could be applied systematically
    (e.g., would linking back to sources for a generated image even make sense?);
    even if it could, fewer sources would likely be exposed than in a typical search
    engine results page, and the incentives for the user to follow the links would
    likely be substantially lower.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`robots.txt` directives allow specific rules to be given to specific crawlers
    based on their user agent; while this has been practically manageable when dealing
    with (for better or for worse) few well-known search engine crawlers, expecting
    content creators to maintain potential allow- and block-lists of the rapidly expanding
    number of crawlers deployed to retrieve training data seems unlikely to achieve
    sustainable results.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given the likely different expectations around the quid-pro-quo of crawling
    in the context of [AI systems](#dfn-artificial-intelligence-system), it is not
    obvious that the permission-less pattern inherited from the early days of the
    Web (robots.txt was designed in 1994) would be a satisfactory match to ensure
    the long term sustainability of content publication on the Web (itself presumably
    in the long term interest of AI crawlers themselves).
  prefs: []
  type: TYPE_NORMAL
- en: In general, a possibly helpful line of inquiry for standards in this space would
    be to identify solutions that help **content producers and AI crawlers to find
    agreeable terms, ideally at a scale** that would make it appealing to all parties.
  prefs: []
  type: TYPE_NORMAL
- en: 'Several groups and individuals have been exploring how to make it possible
    for content publishers to express their willingness to get their content used
    for [training](#dfn-training) [Machine Learning models](#dfn-model):'
  prefs: []
  type: TYPE_NORMAL
- en: 'A key part of [W3C''s vision for the Web](https://www.w3.org/TR/w3c-vision/#vision-web)
    [[w3c-vision](#bib-w3c-vision "Vision for W3C")] is to ensure the Web is developed
    around principles of interoperability: that is, for technologies that W3C codifies
    as Web standards, to ensure they are implemented and deployed in a way that will
    work the same across products, allowing for greater choice for users and fostering
    the long term viability of the content.'
  prefs: []
  type: TYPE_NORMAL
- en: When the algorithm on which interoperability relies is deterministic, ensuring
    interoperability is a matter of describing in sufficient detail and clarity the
    said algorithm, and running sufficient testing on the products to verify they
    achieve the intended result. The move to more [algorithmic specifications](https://www.w3.org/TR/design-principles/#algorithms)
    [[design-principles](#bib-design-principles "Web Platform Design Principles")]
    and thorough automated testing (e.g., through the [Web Platform Tests project](https://web-platform-tests.org/))
    has largely been driven by the goal of providing a robust interoperable platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'As discussed above, [Machine Learning models](#dfn-model) are already finding
    their way into standardized Web APIs. These creates two challenges to our interoperability
    goals:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Machine Learning models](#dfn-model) are mostly not built or described as
    a series of algorithmic steps. If a given standardized behavior is expected to
    be best fulfilled by [Machine Learning models](#dfn-model), how should that behavior
    be specified? How can it be tested to a level that sufficiently verifies an **interoperable
    outcome across products that would use different models**? What impact would it
    have on the fingerprinting surface of the browsers?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A number of important [Machine Learning models](#dfn-model) are not deterministic;
    if or when some of these **non-deterministic models** get exposed in standardized
    APIs, this consistency question is no longer limited to two products using two
    different models, since a given input would no longer produce a predetermined
    output. It is not clear to us at the moment how to prepare for interoperable behaviors
    based on non-deterministic models, which probably raises the question of whether
    and how such models should be acceptable as part of interoperable implementations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A possible consequence of these challenges is a reduction of the scope of what
    can be meaningfully made interoperable and standardized as a possibly growing
    number of features get mediated by [Machine Learning models](#dfn-model) (similar
    to the [postulated impact of growing capabilities of web applications on the need
    to standardize protocols](https://datatracker.ietf.org/doc/html/draft-tschofenig-post-standardization-02)).
    In that context, discussions e.g., around AI-based codecs point towards possible
    significant changes in the interoperability landscape.
  prefs: []
  type: TYPE_NORMAL
- en: '[↑](#title)'
  prefs: []
  type: TYPE_NORMAL
