["```\nsource = Source(\n    events=EventSource(\n        table=\"data.purchases\", # This points to the log table in the warehouse with historical purchase events, updated in batch daily\n        topic=\"events/purchases\", # The streaming source topic\n        query=Query(\n            selects=select(\"user_id\",\"purchase_price\"), # Select the fields we care about\n            time_column=\"ts\") # The event time\n    ))\n\nwindow_sizes = [Window(length=day, timeUnit=TimeUnit.DAYS) for day in [3, 14, 30]] # Define some window sizes to use below\n\nv1 = GroupBy(\n    sources=[source],\n    keys=[\"user_id\"], # We are aggregating by user\n    online=True,\n    aggregations=[Aggregation(\n            input_column=\"purchase_price\",\n            operation=Operation.SUM,\n            windows=window_sizes\n        ), # The sum of purchases prices in various windows\n        Aggregation(\n            input_column=\"purchase_price\",\n            operation=Operation.COUNT,\n            windows=window_sizes\n        ), # The count of purchases in various windows\n        Aggregation(\n            input_column=\"purchase_price\",\n            operation=Operation.AVERAGE,\n            windows=window_sizes\n        ), # The average purchases by user in various windows\n        Aggregation(\n            input_column=\"purchase_price\",\n            operation=Operation.LAST_K(10),\n        ), # The last 10 purchase prices aggregated as a list\n    ],\n)\n```", "```\nsource = Source(\n    entities=EntitySource(\n        snapshotTable=\"data.users\", # This points to a table that contains daily snapshots of all users\n        query=Query(\n            selects=select(\"user_id\",\"account_created_ds\",\"email_verified\"), # Select the fields we care about\n        )\n    ))\n\nv1 = GroupBy(\n    sources=[source],\n    keys=[\"user_id\"], # Primary key is the same as the primary key for the source table\n    aggregations=None, # In this case, there are no aggregations or windows to define\n    online=True,\n) \n```", "```\n source = Source(\n    events=EventSource(\n        table=\"data.checkouts\", \n        query=Query(\n            selects=select(\"user_id\"), # The primary key used to join various GroupBys together\n            time_column=\"ts\",\n            ) # The event time used to compute feature values as-of\n    ))\n\nv1 = Join(  \n    left=source,\n    right_parts=[JoinPart(group_by=group_by) for group_by in [purchases_v1, returns_v1, users]] # Include the three GroupBys\n)\n```", "```\n// Fetching all features for user=123\nMap<String, String> keyMap = new HashMap<>();\nkeyMap.put(\"user\", \"123\")\nFetcher.fetch_join(new Request(\"quickstart_training_set_v1\", keyMap));\n// Sample response (map of feature name to value)\n'{\"purchase_price_avg_3d\":14.2341, \"purchase_price_avg_14d\":11.89352, ...}'\n```", "```\nrun.py --mode=fetch -k '{\"user_id\":123}' -n quickstart/training_set -t join\n\n> {\"purchase_price_avg_3d\":14.2341, \"purchase_price_avg_14d\":11.89352, ...}\n```"]