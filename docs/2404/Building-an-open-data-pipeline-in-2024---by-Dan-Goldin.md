<!--yml

category: 未分类

date: 2024-05-27 13:33:04

-->

# 在2024年建立一个开放的数据管道 - 丹·戈尔丁

> 来源：[https://blog.twingdata.com/p/building-an-open-data-pipeline-in](https://blog.twingdata.com/p/building-an-open-data-pipeline-in)

在之前关于[SQL通用化](https://blog.twingdata.com/p/embrace-the-differences-between-development)的文章中，我提到了构建利用这种方法的数据堆栈的概念。这种架构的一个关键元素是利用[Iceberg](https://iceberg.apache.org/)作为核心数据存储层，灵活选择最适合的计算环境，具体取决于你的用例的特定需求。例如，如果你为BI报告提供动力，通常会优先考虑速度，以便客户能快速获取他们所需的数据。相反，如果你在批处理数据管道作业上工作，成本可能是最大的因素。此外，你可能有外部数据客户，这种情况下，你希望优先考虑可用性而不是其他任何因素。虽然没有一种大小适合所有的解决方案，但了解你独特的用例和要求可以让你相应地调整你的方法。

这里涉及几个维度，我希望分别讨论每一个，尽管在实践中它们通常是因素的组合。

我们生活在一个“大数据”的世界中，但即使在大数据范围内，我们也有完全不同的层次。较小的数据集可以在单节点实例上使用[DuckDB](https://duckdb.org/)处理。较大的数据集则需要某种映射-减少的方法，并可以利用现代数据仓库，如[Snowflake](https://www.snowflake.com/en/)或[Databricks](https://www.databricks.com/)。如果你处理的是真正海量的数据集，你可以利用GPU来处理数据作业。

有两种类型的延迟需要考虑。第一种类型是数据处理延迟，指的是转换和处理数据所需的时间。第二种类型是在交互或报告用例中执行查询的速度。想象一下，你有一个服务收集电子商务交易数据，帮助客户更好地了解他们的销售情况。每笔交易都会触发一个事件，但考虑到规模，你选择每小时汇总数据，汇总过程需要10分钟才能完成。当数据汇总后，用户可以通过BI工具查询数据，95%的查询在5秒内执行。在这种情况下，你的数据处理延迟最多是70分钟，但查询延迟只有几秒钟。

你可以通过更频繁地运行作业或使用更大的硬件来改善数据处理延迟。为了改善查询延迟，你可以使用更大的硬件，并尽量将尽可能多的数据“热”存储在内存中，而不是从“冷”存储中提取。和大多数事情一样，减少延迟会增加成本。

一般来说，与开源解决方案相比，受管工具将为您提供更强大的治理和访问控制。对于需要强大安全模型的敏感数据处理业务，商业解决方案可能值得投资，因为它们可以提供额外的保证层和更强大的审计追踪。

不同类型的数据通常具有不同的需求。通常，原始事件通常涉及个人身份信息并具有较高的敏感性。然而，随着数据被汇总和聚合，敏感性水平往往会降低，允许对数据敏感性级别进行更明确定义的角色和责任。

成本是以上因素的函数，但也是一个关键维度。根据您的业务经济情况，成本实际上可能是迫使您在其他需求上做出妥协的约束因素。想象一下，如果成本不是因素，那么理想的架构是什么样子的，然后在逐渐增加成本考虑的层次时进行削减和妥协，这也会给您一个很好的了解您的优先事项和如何在它们之间进行权衡的感觉。例如，您可能会意识到实现次秒级查询延迟并不像建立强大的安全模型那样关键。

在考虑成本时，一个有用的方法是问自己如果预算增加一倍会是什么样子？如果减半呢？这可能会激发一些创造性思维，并导致一些最初并不明显的解决方案。

在开始[Twing Data](https://www.twingdata.com/)之前，我在广告技术公司[TripleLift](https://triplelift.com/)工作，积累了宝贵的经验，在那里我在10年的时间里担任了几个工程领导职位。在那段时间里，我们经历了数据流水线的多次迭代。基于那段经历，我想利用上述提到的框架，创建一个专门满足各种要求的架构，同时利用Iceberg和不同的计算环境。

这里是如何组合在一起的分解。

1.  日志级别事件在[Redpanda](https://redpanda.com/)中进行收集，并持久存储到[Cloudflare R2](https://www.cloudflare.com/developer-platform/r2/)（[比AWS S3更好](https://dansdatathoughts.substack.com/p/from-s3-to-r2-an-economic-opportunity)）使用[Parquet](https://parquet.apache.org/)和Iceberg。每天有数千亿事件，涉及的内容从正在进行的广告拍卖的信息，到每次拍卖的获胜者，再到收集关于广告是否被查看以及持续多久的信息。

1.  数据建模使用 [SQLMesh](https://sqlmesh.com/) 进行，并在 [dagster](https://dagster.io/) 中编排。需要使用大规模连接进行分布式工作的复杂转换在 Snowflake 中运行。一个例子是连接第一步的所有事件，以创建一个宽表，其中每行表示我们对单个拍卖的所有了解。

1.  DuckDB 用于可以在单个节点上运行的更简单的作业。例如，从第二步中获取宽表和大表，并得出具有子集维度和高度聚合的较小表。

1.  [Cube](https://cube.dev/) 用作我们定义关心的度量标准的语义层，并确保它们在多个访问路径上保持一致的标准方式。

1.  一个访问路径是 [Metabase](https://www.metabase.com/) ，它充当我们的 BI 工具。通过 Cube 我们可以确保使用标准定义，并利用 Cube 的预聚合/缓存层。

1.  我们的一些工程师直接使用 Python ，并且还可以利用 Cube 提供的语义层。

1.  我们还希望允许数据科学家等高级用户直接从 R2 查询数据，使用他们想要的计算层。他们可能想要使用 Spark ，甚至 Snowflake ，但他们可以使用，因为数据使用开放存储格式 Iceberg 存储。

这种方法以 Iceberg 及其开放性为中心。在上面的例子中，我们可以毫不费力地用 Databricks 替换 Snowflake 。此外，我们可以根据需要采用不同的编排、数据建模和语义层。这种灵活性的基础在于系统的核心，数据本身，不受专有格式的约束。这不仅带来了成本效益，还促进了创新，因为您和生态系统都在扩大和发展。
