<!--yml

category: 未分类

date: 2024-05-27 13:26:11

-->

# '人类智能' - 由海伦·比瑟姆撰写

> 来源：[https://helenbeetham.substack.com/p/human-intelligence](https://helenbeetham.substack.com/p/human-intelligence)
> 
> *哦，那些演员们，我曾见过他们表演，并听到别人称赞，而且非常称赞，不是亵渎地说，他们既没有基督徒的口音，也没有基督徒的步态，不是异教徒，也不是人，像是一些自然的临时工把人制造了出来，但却做得不好，他们模仿人类是如此的可憎。*
> 
> 威廉·莎士比亚，《哈姆雷特》III(ii)

约翰·麦卡锡在1955年在斯坦福创造的‘*制造智能机器的科学与工程*’的原始定义，当时对于‘智能’的含义已经太过明显，不再详细说明。马文·明斯基在1970年的写作中重申道：‘*人工智能是使机器做需要人类智能才能完成的事情的科学*’。今天使用的许多关于‘人工智能’的定义仍然依赖于这样一种假设，即计算‘智能’简单地反映了‘智能人类’所能做到的。诸如[这里](https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/explaining-decisions-made-with-artificial-intelligence/part-1-the-basics-of-explaining-ai/definitions/)、[这里](https://www.ibm.com/topics/artificial-intelligence)、[这里](https://www.merriam-webster.com/dictionary/artificial%20intelligence)，以及今天的斯坦福人类中心人工智能中心[这里](https://hai.stanford.edu/sites/default/files/2023-03/AI-Key-Terms-Glossary-Definition.pdf)等定义都遵循着同样的模式。现今的‘智能人’甚至不一定是男性，但‘我们’知道‘他们’是谁。

伪装成从某些不言自明的事物出发的项目“人工智能”，实际上是用来定义什么是“智能”及其价值，从而也定义了如何评价多样化的人类价值。教育者有充分理由对“智能”的概念持谨慎态度，特别是将其视为人们在可度量程度上的单一潜能等级。它是一个[统计学产物](http://bactra.org/weblog/523.html)，早已[在科学上被驳斥](https://www.sciencedirect.com/science/article/abs/pii/S2211368119300658#!)。它曾被用来在教育中[强化种族和性别歧视](https://wellcomecollection.org/articles/YxDGExEAACMAdaX9)，并为多种[歧视性暴力行为](https://learninglab.si.edu/collections/exploring-heredity-race-eugenics-and-the-history-of-intelligence-testing/ytlaOzLVuq36ejHP#r/988783)，特别是对殖民地居民的辩护。

生物学家史蒂芬·杰伊·古尔德（Stephen Jay Gould）将该项目描述为：

> ‘*将智能抽象为单一实体，将其定位于大脑内部，将其量化为每个个体的一个数字，并使用这些数字在一个单一的价值序列中对人们进行排名，最终发现被压迫和弱势群体——种族、阶级或性别——天生劣等。*’（古尔德 1981: 25\. 引自斯蒂芬·凯夫（2020）*[智能的问题：其充满价值色彩的历史和人工智能的未来](https://www.researchgate.net/publication/339105054_The_Problem_with_Intelligence_Its_Value-Laden_History_and_the_Future_of_AI)*）。

术语‘人类’出于类似的原因是有问题的。除非其使用经过仔细限定（即使如此），‘人类’往往以特定的人类群体为参照点和标准，比如白人、盎格鲁-欧洲人、男性、受过教育等。大多数学者对这两个术语的历史有足够的了解，避免不经审视地使用它们。特别是在涉及学生学习时，我们意识到教室中存在多样的抱负、身份、经历、能力和文化，所有这些都可以成为学习的资源。然而，自从‘人工智能’占领了教育话语权以来，‘人类智能’开始被当作不仅是一个真实而且是不言自明的事物，即[教育的核心](https://technode.global/2023/11/23/artificial-intelligence-ai-and-human-intelligence-hi-in-the-future-of-education/)。

这个术语对人工智能行业的价值显而易见。‘人类智能’是对工作重组和不稳定化的焦虑的一种缓解：别担心，我们的模型还有一些事情做不了（暂时）。然而，今天、明天或后天未被宣布为可计算的工作领域正在变窄，而只有人工智能行业有资格定义它。关于‘人类’与‘人工’智能的关系将人类变成数据系统的道具（人在回路中）。这些道具使系统输出更准确、安全、符合伦理、稳健和可用，只有在他们的输入被建模和数据化后才会被移除。（或者，也许是当[确保人工智能安全和可用性后变得太昂贵时](https://fortune.com/2024/01/22/ai-jobs-humans-cost-mit-study/)。）

这就是WEF所说的‘与人工智能共同高效工作’。

但对我来说，不清楚为什么关心教育的人会从那些愤世嫉俗的人那里捕捉到“人类智能”这个术语。毫不奇怪，考虑到这两个术语的历史，如果你留意一下，你会听到它是多么倒退和分裂。少数“人类智能”将能够自由发挥其创新和原创性的潜力，其创业决策能力和明智的领导能力。因此，请放心，AI工程师和公司高管将有高薪工作。

然而，只有当这些人摆脱其他种类的工作时——枯燥、重复和缺乏创意的工作时——他们才能发挥出他们的人类优势。我们被告知这些工作正在被“自动化”以造福大家，但显然并非如此。当“AI研究助理”上线时，研究助理并没有被提升到其他更有趣的角色。相反，他们所做的工作很可能会变得更加紧张、更少被重视，或者消失。自动驾驶汽车背后仍然有[驾驶员（“人类监督员”）](https://urgentcomm.com/2023/03/13/will-driverless-cars-need-remote-human-supervision/)，大型语言模型背后仍然有[注释员（“数据工作者”）](https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots)，以及教师为“教师机器人”上传课程计划和主题地图[的人类人员](https://explore.teacherbot.io/about)。事实证明，[亚马逊的“完全自动化”商店背后有1000名印度数据工作者](https://arstechnica.com/gadgets/2024/04/amazon-ends-ai-powered-store-checkout-which-needed-1000-video-reviewers/)在英国。工作并没有消失，它只是常规化、廉价化、贬低化，经常被外包，而且总是消失在视野之外。

AI声称要“解放”我们的，告诉我们AI行业认为什么是值得做的。不是个性化辅导！尽管令人困惑的是，这似乎也是“教师不可替代的角色”。还要小心，不要过于迎合数据引擎的要求，否则你就该被替换了。

在AI镜像中出现的另一个“人类”，并非经营公司或注册专利，而是在进行“情感”工作：也就是那些历来报酬微薄或完全脱离有薪工作范畴的工作。照顾、服务、社区建设、不可货币化的创造形式（手工艺、休闲、游戏）、修补损坏的东西和人。这些形式的“人类智慧”根本不被“越来越重视”。相反，大学管理者正在计算可以由聊天机器人取代多少学生支持人员。在学生（“人的触感”）身上投入时间和关怀的学者们面临被裁员的威胁。学校依赖志愿辅导员来应对心理困扰的海啸（我所在地的学校有13个），同时雇佣高薪数据分析师。事实上，那些最大程度地实现大规模教育的人性化体验的人似乎是最可替代的。享受这种感受，因为“情感智能”并不要求工作安全性。

这种情况很有趣，但似乎高度奖励的工作，因为它是“独特的人类”，很可能是由白人、西方受过良好教育的男性完成，最好是在STEM学科中。而那些因为“仅仅是人类”而被低估的工作，很可能是由世界其他地区的人来承担。这种工作不断地被重组为数据工作。每一个可以被数据捕捉的动作都被建模，而剩下的则被表现为*行为*，由模型和其数据驱动的例行程序来管理。在高薪“创新”和基础经济中不可计算的工作——这些工作实际上需要人类的接触——之间，AI正致力于将其他一切数据化的项目。

[TechTarget上的最新文章](https://www.techtarget.com/searchenterpriseai/tip/Artificial-intelligence-vs-human-intelligence-How-are-they-different)定义了人工智能和人类智能之间的“重要区别”，明确表明右栏中的一切已经在左栏可用。显然，“人类智能”被奉承，实际上却被抹去。这些定义如此肤浅、愤世嫉俗和空洞，我只能将其理解为对教育体系的故意挑衅，希望教育体系会感激它们。*“心理感知和现象概念，这些感知和概念不在场”*？我觉得即使是ChatGPT的底线垃圾探测器也无法接受这种说法。

这些自私的比较产生的结果是对学生和知识工作者的双重约束。迎合节奏、生产力和数据化算法系统的要求，同时又要“[更加人性化](https://saren.ai/be-more-human-cultivating-your-uniquely-human-skills-in-the-age-of-ai-c24fbe945d05)”。更加人性化，以便你能为算法增加价值。更加人性化，这样更多的你的行为就能被建模并用来削弱你的价值。更加人性化，这样当AI未能满足人类需求时，所需的“修复”工作就能清晰指明并廉价地实现。

我们可以看到学生对这些要求的理解，既需要按照标准化的评分标准或者说满足自动评分系统的要求来优化文本，*同时*也需要以显然“人性化”的方式书写（这究竟意味着什么）。难怪他们感到焦虑和困惑。

我最近在伦敦大学学院写作中心的一期播客中谈到了这种对学生的双重束缚：[学生写作作为‘过关’。](https://www.ucl.ac.uk/ioe/events/2024/mar/writing-passing-and-role-generative-ai)（录音即将从此链接提供）。我还在一篇关于‘不可靠图灵测试’的文章中探讨了一些这些问题。由‘AI’引发的问题和干扰不仅仅是教育所遭受的，而是‘过关’，即作为真实人类和对数据经济有价值的问题在教育系统中特别紧迫地浮出水面。这些问题在评估和学术诚信的所有关注中都显现出来。但只有在那里解决它，才会未能认识到大科技公司在认知论和教育论上以及通过[人才流失](https://www.timeshighereducation.com/depth/can-academy-rein-big-tech)，购买[政治](https://cybernews.com/editorial/big-tech-meta-google-donations-research-harvard/)和[竞争教育业务](https://www.kornferry.com/insights/briefings-magazine/issue-48/tech-takes-on-higher-ed)等更为世俗的挑战中向大学提出的挑战。

我希望你喜欢这些新的提议。所有它们的人类不完美都是我自己的。
