- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-05-27 13:26:11'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-05-27 13:26:11'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '''Human intelligence'' - by Helen Beetham'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '''人类智能'' - 由海伦·比瑟姆撰写'
- en: 来源：[https://helenbeetham.substack.com/p/human-intelligence](https://helenbeetham.substack.com/p/human-intelligence)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://helenbeetham.substack.com/p/human-intelligence](https://helenbeetham.substack.com/p/human-intelligence)
- en: '*O, there be players that I have seen play, and heard others praise, and that
    highly, not to speak it profanely, that, neither having the accent of Christians
    nor the gait of Christian, pagan, nor man, have so strutted and bellowed that
    I have thought some of nature’s journeymen had made men and not made them well,
    they imitated humanity so abominably.*'
  id: totrans-6
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*哦，那些演员们，我曾见过他们表演，并听到别人称赞，而且非常称赞，不是亵渎地说，他们既没有基督徒的口音，也没有基督徒的步态，不是异教徒，也不是人，像是一些自然的临时工把人制造了出来，但却做得不好，他们模仿人类是如此的可憎。*'
- en: ''
  id: totrans-7
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Will Shakespeare, *Hamlet* III(ii)
  id: totrans-8
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 威廉·莎士比亚，《哈姆雷特》III(ii)
- en: 'The original definition of ‘AI’, coined by John McCarthy in Stanford in 1955,
    was ‘*the science and engineering of making intelligent machines’*. To McCarthy
    and his Stanford colleagues, the meaning of ‘intelligent’ was too obvious to spell
    out any further. Marvin Minsky, writing in 1970, reiterated that: ‘*Artificial
    intelligence is the science of making machines do things that would require intelligence
    if done by men’*. Many definitions of ‘artificial intelligence’ in use today rely
    on the same assumption that computational ‘intelligence’ simply reflects what
    ‘intelligent people’ can do. Definitions such as [here](https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/explaining-decisions-made-with-artificial-intelligence/part-1-the-basics-of-explaining-ai/definitions/),
    [here](https://www.ibm.com/topics/artificial-intelligence), [here](https://www.merriam-webster.com/dictionary/artificial%20intelligence),
    and from today’s Stanford Centre for Human-Centred AI [here](https://hai.stanford.edu/sites/default/files/2023-03/AI-Key-Terms-Glossary-Definition.pdf)
    all follow the same pattern. Intelligent people don’t even have to be men these
    days, but ‘we’ know who ‘they’ are.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 约翰·麦卡锡在1955年在斯坦福创造的‘*制造智能机器的科学与工程*’的原始定义，当时对于‘智能’的含义已经太过明显，不再详细说明。马文·明斯基在1970年的写作中重申道：‘*人工智能是使机器做需要人类智能才能完成的事情的科学*’。今天使用的许多关于‘人工智能’的定义仍然依赖于这样一种假设，即计算‘智能’简单地反映了‘智能人类’所能做到的。诸如[这里](https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/explaining-decisions-made-with-artificial-intelligence/part-1-the-basics-of-explaining-ai/definitions/)、[这里](https://www.ibm.com/topics/artificial-intelligence)、[这里](https://www.merriam-webster.com/dictionary/artificial%20intelligence)，以及今天的斯坦福人类中心人工智能中心[这里](https://hai.stanford.edu/sites/default/files/2023-03/AI-Key-Terms-Glossary-Definition.pdf)等定义都遵循着同样的模式。现今的‘智能人’甚至不一定是男性，但‘我们’知道‘他们’是谁。
- en: In the guise of starting from something self-evident, the project of ‘artificial
    intelligence’ in fact serves to define what ‘intelligence’ is and how to value
    it, and therefore how diverse people should be valued too. Educators have good
    reason to be wary of the concept of ‘intelligence’ at all, but particularly as
    a single scale of potential that people have in measurable degrees. It is a [statistical
    artefact](http://bactra.org/weblog/523.html) that has long been [scientifically
    discredited](https://www.sciencedirect.com/science/article/abs/pii/S2211368119300658#!).
    It has been used to [enforce racial and gender discrimination](https://wellcomecollection.org/articles/YxDGExEAACMAdaX9)
    in education and to justify diverse forms of [discriminatory violence](https://learninglab.si.edu/collections/exploring-heredity-race-eugenics-and-the-history-of-intelligence-testing/ytlaOzLVuq36ejHP#r/988783),
    particularly over colonial subjects.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 伪装成从某些不言自明的事物出发的项目“人工智能”，实际上是用来定义什么是“智能”及其价值，从而也定义了如何评价多样化的人类价值。教育者有充分理由对“智能”的概念持谨慎态度，特别是将其视为人们在可度量程度上的单一潜能等级。它是一个[统计学产物](http://bactra.org/weblog/523.html)，早已[在科学上被驳斥](https://www.sciencedirect.com/science/article/abs/pii/S2211368119300658#!)。它曾被用来在教育中[强化种族和性别歧视](https://wellcomecollection.org/articles/YxDGExEAACMAdaX9)，并为多种[歧视性暴力行为](https://learninglab.si.edu/collections/exploring-heredity-race-eugenics-and-the-history-of-intelligence-testing/ytlaOzLVuq36ejHP#r/988783)，特别是对殖民地居民的辩护。
- en: 'Biologist Stephen Jay Gould described the project as:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 生物学家史蒂芬·杰伊·古尔德（Stephen Jay Gould）将该项目描述为：
- en: '‘*the abstraction of intelligence as a single entity, its location within the
    brain, its quantification as one number for each individual, and the use of these
    numbers to rank people in a single series of worthiness, invariably to find that
    oppressed and disadvantaged groups—races, classes, or sexes—are innately inferior.’*
    (Gould 1981: 25\. Cited in Stephen Cave (2020) *[The Problem with Intelligence:
    Its Value-Laden History and the Future of AI](https://www.researchgate.net/publication/339105054_The_Problem_with_Intelligence_Its_Value-Laden_History_and_the_Future_of_AI)*.'
  id: totrans-12
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '‘*将智能抽象为单一实体，将其定位于大脑内部，将其量化为每个个体的一个数字，并使用这些数字在一个单一的价值序列中对人们进行排名，最终发现被压迫和弱势群体——种族、阶级或性别——天生劣等。*’（古尔德
    1981: 25\. 引自斯蒂芬·凯夫（2020）*[智能的问题：其充满价值色彩的历史和人工智能的未来](https://www.researchgate.net/publication/339105054_The_Problem_with_Intelligence_Its_Value-Laden_History_and_the_Future_of_AI)*）。'
- en: The term ‘human’ is problematic for similar reasons. Unless its use is carefully
    qualified (and even then) ‘human’ all too often takes a particular fraction of
    humanity - white, anglo-european, male, educated, for example – as its reference
    point and norm. Most academics have enough sense of the history of these two terms
    - ‘human’ and ‘intelligence’ - to avoid using them in an unexamined way. Particularly
    when it comes to student learning, when we recognise there are a diversity of
    ambitions, identities, experiences, capabilities and cultures in the classroom,
    all of which can be resources for learning. And yet, since ‘artificial intelligence’
    colonised the educational discourse, ‘human intelligence’ has begun to be used
    as though it is not only a real and self-evident thing, but [self-evidently what
    education is about](https://technode.global/2023/11/23/artificial-intelligence-ai-and-human-intelligence-hi-in-the-future-of-education/).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 术语‘人类’出于类似的原因是有问题的。除非其使用经过仔细限定（即使如此），‘人类’往往以特定的人类群体为参照点和标准，比如白人、盎格鲁-欧洲人、男性、受过教育等。大多数学者对这两个术语的历史有足够的了解，避免不经审视地使用它们。特别是在涉及学生学习时，我们意识到教室中存在多样的抱负、身份、经历、能力和文化，所有这些都可以成为学习的资源。然而，自从‘人工智能’占领了教育话语权以来，‘人类智能’开始被当作不仅是一个真实而且是不言自明的事物，即[教育的核心](https://technode.global/2023/11/23/artificial-intelligence-ai-and-human-intelligence-hi-in-the-future-of-education/)。
- en: 'The value of this term to the AI industry is obvious. ‘Human intelligence’
    is a palliative to anxieties about the restructuring and precaritsiation of work:
    don’t worry, there are still some things our models can’t do (yet). And yet the
    space of work that has not been declared computable today, or tomorrow, or the
    day after tomorrow is narrow and narrowing, and only the AI industry is qualified
    to define it. ‘Human’ in relation to ‘artificial’ intelligence turns people into
    props for data systems (humans in the loop). Props that make system outputs more
    accurate, safe, ethical, robust and useable, only to be removed once their input
    has been modelled and datafied. (Or, perhaps, when [making AI safe and useable
    proves too expensive after all](https://fortune.com/2024/01/22/ai-jobs-humans-cost-mit-study/).)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这个术语对人工智能行业的价值显而易见。‘人类智能’是对工作重组和不稳定化的焦虑的一种缓解：别担心，我们的模型还有一些事情做不了（暂时）。然而，今天、明天或后天未被宣布为可计算的工作领域正在变窄，而只有人工智能行业有资格定义它。关于‘人类’与‘人工’智能的关系将人类变成数据系统的道具（人在回路中）。这些道具使系统输出更准确、安全、符合伦理、稳健和可用，只有在他们的输入被建模和数据化后才会被移除。（或者，也许是当[确保人工智能安全和可用性后变得太昂贵时](https://fortune.com/2024/01/22/ai-jobs-humans-cost-mit-study/)。）
- en: This is what the WEF means by ‘working productively alongside AI’.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是WEF所说的‘与人工智能共同高效工作’。
- en: But it is not clear to me why anyone who cares about education would catch the
    term ‘human intelligence’ from the cynics who are throwing it our way. Not surprisingly,
    given the history of both terms, if you pay any attention you can hear how regressive
    and divisive it is. A small number of ‘human intelligences’ will be free to maximise
    their potential for innovation and originality, their entrepreneurial decision-making
    and wise leadership. So rest easy that there will be highly paid jobs for AI engineers
    and company executives.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 但对我来说，不清楚为什么关心教育的人会从那些愤世嫉俗的人那里捕捉到“人类智能”这个术语。毫不奇怪，考虑到这两个术语的历史，如果你留意一下，你会听到它是多么倒退和分裂。少数“人类智能”将能够自由发挥其创新和原创性的潜力，其创业决策能力和明智的领导能力。因此，请放心，AI工程师和公司高管将有高薪工作。
- en: However, these people can only max out their human qualities if they are set
    free from other kinds of work - the boring, repetitive and uncreative. We are
    supposed to believe that this work is being ‘automated’ for everyone’s benefit,
    but this is manifestly not so. Research assistants aren’t promoted to other, more
    interesting roles when ‘AI research assistants’ come online. Rather, the work
    they do is likely to become more pressured and less valued, or to disappear. There
    are still [drivers (‘human overseers’) behind self-driving cars](https://urgentcomm.com/2023/03/13/will-driverless-cars-need-remote-human-supervision/),
    [annotators (‘data workers’) behind large language models,](https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots)  [human
    personnel swiping left](https://www.972mag.com/lavender-ai-israeli-army-gaza/)
    to authorise AI ‘targets’ for bombing, and teachers uploading lesson plans and
    topic maps [for ‘teacherbots’](https://explore.teacherbot.io/about). And it turns
    out there were [1000 Indian data workers behind Amazon’s ‘fully automated’ stores](https://arstechnica.com/gadgets/2024/04/amazon-ends-ai-powered-store-checkout-which-needed-1000-video-reviewers/)
    in the UK. The work does not vanish, it is just routinised, cheapened, denigrated,
    frequently offshored, and always disappeared from view.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，只有当这些人摆脱其他种类的工作时——枯燥、重复和缺乏创意的工作时——他们才能发挥出他们的人类优势。我们被告知这些工作正在被“自动化”以造福大家，但显然并非如此。当“AI研究助理”上线时，研究助理并没有被提升到其他更有趣的角色。相反，他们所做的工作很可能会变得更加紧张、更少被重视，或者消失。自动驾驶汽车背后仍然有[驾驶员（“人类监督员”）](https://urgentcomm.com/2023/03/13/will-driverless-cars-need-remote-human-supervision/)，大型语言模型背后仍然有[注释员（“数据工作者”）](https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots)，以及教师为“教师机器人”上传课程计划和主题地图[的人类人员](https://explore.teacherbot.io/about)。事实证明，[亚马逊的“完全自动化”商店背后有1000名印度数据工作者](https://arstechnica.com/gadgets/2024/04/amazon-ends-ai-powered-store-checkout-which-needed-1000-video-reviewers/)在英国。工作并没有消失，它只是常规化、廉价化、贬低化，经常被外包，而且总是消失在视野之外。
- en: What AI claims to ‘liberate’ us from tells us what the AI industry thinks is
    worth doing. Not personal tutoring! Though, confusingly, this seems also to be
    the ‘irreplaceable role of teachers’. And beware conforming too much to the demands
    of the data engine or you deserve to be replaced.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: AI声称要“解放”我们的，告诉我们AI行业认为什么是值得做的。不是个性化辅导！尽管令人困惑的是，这似乎也是“教师不可替代的角色”。还要小心，不要过于迎合数据引擎的要求，否则你就该被替换了。
- en: 'The other ‘human’ who appears in the AI mirror is not running companies or
    registering patents but doing ‘emotional’ work: that is, work that has always
    been badly paid or removed from the sphere of paid work altogether. The work of
    care, service, community building, non-monetisable forms of creativity (craft,
    leisure, play), mending things and people who are broken. These forms of ‘human
    intelligence’ are not ‘increasingly prized’ at all. Instead, university managers
    are calculating how many student support staff can be replaced by chatbots. Academics
    who invest time and care in students (‘the human touch’) are threatened with redundancy.
    Schools are relying on volunteer counsellors to cope with the tsunami of mental
    distress (my local school has 13) while employing highly paid data analysts. In
    fact, the people who do the most to actually humanise the experience of mass education
    for students seem to be the most replaceable.  Enjoy the feels, because ‘emotional
    intelligence’ doesn’t ask for job security.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI镜像中出现的另一个“人类”，并非经营公司或注册专利，而是在进行“情感”工作：也就是那些历来报酬微薄或完全脱离有薪工作范畴的工作。照顾、服务、社区建设、不可货币化的创造形式（手工艺、休闲、游戏）、修补损坏的东西和人。这些形式的“人类智慧”根本不被“越来越重视”。相反，大学管理者正在计算可以由聊天机器人取代多少学生支持人员。在学生（“人的触感”）身上投入时间和关怀的学者们面临被裁员的威胁。学校依赖志愿辅导员来应对心理困扰的海啸（我所在地的学校有13个），同时雇佣高薪数据分析师。事实上，那些最大程度地实现大规模教育的人性化体验的人似乎是最可替代的。享受这种感受，因为“情感智能”并不要求工作安全性。
- en: It’s funny how this happens, but it seems work that is highly rewarded because
    ‘uniquely human’ is most likely to be done by white, western, well educated men,
    preferably in STEM disciplines. While work that is undervalued because it is ‘only
    human’ is most likely to be shouldered by the rest of the world. And this work
    is constantly being reorganised as data work. Every gesture that can be captured
    as data is modelled, and whatever is left is rendered as a *behaviour*, to be
    governed by the model and its data-driven routines. Between highly paid ‘innovation’
    and the non-computable work of the foundation economy - work that literally requires
    the human touch - AI is the project of datafying everything else.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况很有趣，但似乎高度奖励的工作，因为它是“独特的人类”，很可能是由白人、西方受过良好教育的男性完成，最好是在STEM学科中。而那些因为“仅仅是人类”而被低估的工作，很可能是由世界其他地区的人来承担。这种工作不断地被重组为数据工作。每一个可以被数据捕捉的动作都被建模，而剩下的则被表现为*行为*，由模型和其数据驱动的例行程序来管理。在高薪“创新”和基础经济中不可计算的工作——这些工作实际上需要人类的接触——之间，AI正致力于将其他一切数据化的项目。
- en: A [recent post on TechTarget](https://www.techtarget.com/searchenterpriseai/tip/Artificial-intelligence-vs-human-intelligence-How-are-they-different)
    defined the ‘important differences’ between artificial and human ‘intelligence’
    in ways that make clear everything in the right hand column is already available
    on the left. ‘Human intelligence’ is apparently being flattered but actually being
    erased. These definitions are so shallow, cynical and vacuous, I can only read
    them as deliberate provocations to the education system that is supposed to fall
    on them gratefully. *‘Mental sensations and concepts of phenomena that are not
    present’*? I can’t see that passing even ChatGPT’s floor-level bullshit detector.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[TechTarget上的最新文章](https://www.techtarget.com/searchenterpriseai/tip/Artificial-intelligence-vs-human-intelligence-How-are-they-different)定义了人工智能和人类智能之间的“重要区别”，明确表明右栏中的一切已经在左栏可用。显然，“人类智能”被奉承，实际上却被抹去。这些定义如此肤浅、愤世嫉俗和空洞，我只能将其理解为对教育体系的故意挑衅，希望教育体系会感激它们。*“心理感知和现象概念，这些感知和概念不在场”*？我觉得即使是ChatGPT的底线垃圾探测器也无法接受这种说法。'
- en: What these self-serving comparisons produce is a double bind for students and
    intellectual workers. Submit yourself to the pace, the productivity, the datafied
    routines of algorithmic systems, and at the same time ‘[be more human](https://saren.ai/be-more-human-cultivating-your-uniquely-human-skills-in-the-age-of-ai-c24fbe945d05)’.
    Be more human, so that you can add value to the algorithms. Be more human , so
    more of your behaviour can be modelled and used to undercut your value. Be more
    human so that when AI fails to meet human needs, the work required to ‘fix’ it
    is clearly specified and can cheaply be fulfilled.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这些自私的比较产生的结果是对学生和知识工作者的双重约束。迎合节奏、生产力和数据化算法系统的要求，同时又要“[更加人性化](https://saren.ai/be-more-human-cultivating-your-uniquely-human-skills-in-the-age-of-ai-c24fbe945d05)”。更加人性化，以便你能为算法增加价值。更加人性化，这样更多的你的行为就能被建模并用来削弱你的价值。更加人性化，这样当AI未能满足人类需求时，所需的“修复”工作就能清晰指明并廉价地实现。
- en: We can see these demands being interpreted by students as *both* a need to produce
    optimised texts – according to a standardised rubric or, perhaps, to satisfy an
    automated grading system – *and* to write in ways that are demonstrably ‘human’
    (whatever this means). No wonder they are anxious and confused.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到学生对这些要求的理解，既需要按照标准化的评分标准或者说满足自动评分系统的要求来优化文本，*同时*也需要以显然“人性化”的方式书写（这究竟意味着什么）。难怪他们感到焦虑和困惑。
- en: 'I spoke about this double bind for students in a recent podcast for the UCL
    Writing Centre: [Student writing as ‘passing’.](https://www.ucl.ac.uk/ioe/events/2024/mar/writing-passing-and-role-generative-ai)
    (recording soon available from this link). I also explore some of these issues
    in a post on the ‘unreliable Turing test’. The problems and disruptions posed
    by ‘AI’ are not only for education to suffer, but the question of what it means
    to *pass as* both authentically human and valuable to the data economy is particularly
    pressing in the education system. It surfaces in all the concerns about assessment
    and academic integrity. But only to address it there is to fail to recognise the
    challenge that is being thrown down to universities by big tech, epistemologically
    and pedagogically, as well as through the more mundane challenges of [draining
    talent](https://www.timeshighereducation.com/depth/can-academy-rein-big-tech),
    buying [political](https://cybernews.com/editorial/big-tech-meta-google-donations-research-harvard/)  [influence](https://www.washingtonpost.com/technology/2023/12/06/academic-research-meta-google-university-influence/),
    and [competing for educational business](https://www.kornferry.com/insights/briefings-magazine/issue-48/tech-takes-on-higher-ed).'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我最近在伦敦大学学院写作中心的一期播客中谈到了这种对学生的双重束缚：[学生写作作为‘过关’。](https://www.ucl.ac.uk/ioe/events/2024/mar/writing-passing-and-role-generative-ai)（录音即将从此链接提供）。我还在一篇关于‘不可靠图灵测试’的文章中探讨了一些这些问题。由‘AI’引发的问题和干扰不仅仅是教育所遭受的，而是‘过关’，即作为真实人类和对数据经济有价值的问题在教育系统中特别紧迫地浮出水面。这些问题在评估和学术诚信的所有关注中都显现出来。但只有在那里解决它，才会未能认识到大科技公司在认知论和教育论上以及通过[人才流失](https://www.timeshighereducation.com/depth/can-academy-rein-big-tech)，购买[政治](https://cybernews.com/editorial/big-tech-meta-google-donations-research-harvard/)和[竞争教育业务](https://www.kornferry.com/insights/briefings-magazine/issue-48/tech-takes-on-higher-ed)等更为世俗的挑战中向大学提出的挑战。
- en: I hope you enjoy these new offerings. All their human imperfections are my own.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望你喜欢这些新的提议。所有它们的人类不完美都是我自己的。
