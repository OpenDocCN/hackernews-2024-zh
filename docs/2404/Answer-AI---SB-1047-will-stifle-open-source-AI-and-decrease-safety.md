<!--yml

category: 未分类

date: 2024-05-27 13:38:25

-->

# Answer.AI - SB-1047将抑制开源AI并降低安全性

> 来源：[https://www.answer.ai/posts/2024-04-29-sb1047.html](https://www.answer.ai/posts/2024-04-29-sb1047.html)

<main class="content" id="quarto-document-content">

> *Jeremy的说明*：这是我对[bill SB-1047](https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB1047)的个人提交，而非Answer.AI的官方声明。

这是Jeremy Howard关于SB-1047的评论。我是一名AI研究员和企业家，也是Answer.AI的首席执行官，这是一家在加利福尼亚注册的AI研发实验室。我是多款热门AI软件的作者，包括广受欢迎的fastai库，一个广泛使用的AI训练系统的共同作者。我还是《Deep Learning for Coders with Fastai and PyTorch: AI Applications Without a PhD》的合著者，这本书在亚马逊上基于近500条评价获得了4.7的评分，同时也是免费课程系列《Practical Deep Learning》的创始人，这是世界上历时最长的深度学习课程，拥有超过500万的观看量。我还是《Universal Language Model Fine-tuning for Text Classification》的合著者，该论文提出了当前所有语言模型（包括ChatGPT和Gemini）基于的三阶段语言模型预训练和微调方法。

尽管SB-1047的目的是确保AI的安全和可靠发展，但法案中的某些条款引发了对其对开源开发者、小企业以及AI行业创新总体影响的严重担忧。本回应旨在突出这些问题，并提出可能在不抑制AI生态系统动态性的前提下实现所期望的安全目标的替代方案。

具有讽刺意味的是，通过对开源开发实施这些限制，SB-1047实际上可能会减少AI生态系统整体安全性，特别是通过以下方式：

+   **透明度和协作**：开源开发促进透明度和协作，允许更广泛的专家发现和解决潜在的安全问题。限制这种开发模式会减弱更广泛社区为安全解决方案做贡献的能力。

+   **多样性和韧性**：开源项目有助于构建更多样化和韧性的AI生态系统。集中控制在少数大实体手中会造成单点故障，并增加系统风险的可能性。

## 对开源开发的担忧

开源已成为美国软件行业成功的关键推动因素，使许多美国人能够访问关键的软件工具，否则这些工具对他们来说将无法获得。特别是开源为现代人工智能的基本构建块提供了许多，并且是几乎所有学术研究（包括安全性和安全研究）的基础。损害开源将伤害开发者、消费者、学者，并阻碍新初创企业的发展。该法案将以多种方式造成伤害：

+   **定义过于宽泛**：法案中对“受覆盖模型”的定义极为宽泛，可能涵盖范围广泛的开源模型，这些模型的风险极小。这可能无意中使致力于有益AI项目的善意开发者的活动成为刑事犯罪。

+   **双重用途**：AI模型是在计算机上运行的通用软件，就像文字处理器、计算器或网页浏览器一样。模型的创建者无法确保模型永远不会用于有害行为 - 就像网页浏览器、计算器或文字处理器的开发者一样。将责任放在这些通用工具的创建者身上意味着实际上这些工具几乎无法被创造，除了那些拥有资金雄厚的大公司。

+   **限制性要求**：该法案对开发者施加了重大负担，包括强制关闭、广泛报告和遵守可能含糊不清的“受覆盖指导”。这些要求可能会不成比例地影响开源开发者，后者通常缺乏大公司以导航复杂监管程序所需的资源。

+   **削弱开放性**：对法律后果和官僚障碍的恐惧可能会抑制开源开发，阻碍推动AI进步的合作精神。透明度的降低也可能使识别和解决潜在安全问题变得更加困难。

## 对小企业和创新的影响

提议的法规为希望在AI领域创新的小企业和初创企业设立了重大的准入壁垒。合规相关的成本以及法律风险可能会阻碍企业家，并限制竞争。这最终将扼杀创新，并使权力集中于已建立的企业。

+   **准入壁垒**：与合规相关的昂贵成本，包括费用、审计和法律顾问，可能会为小企业和初创企业创建重大的准入壁垒。这将限制竞争，并最终使权力集中于已建立的企业，从而阻碍创新。

+   **对研究的抑制效应**：担心不慎触发法案条款可能会导致研究人员和开发者进行自我审查或避免探索有前景的AI研究途径。这将抑制科学进展，限制AI解决社会挑战的潜力。

+   **人才流失**：该法案制造的限制性环境可能会驱使有才华的AI研究人员和开发者离开加利福尼亚州，损害该州经济，并削弱其在AI创新方面的地位。

加利福尼亚州在推动美国创新中扮演着关键角色，尤其是在技术领域。通过对AI开发施加不当负担，SB-1047法案存在的风险在于阻碍该州在这一关键领域的领导地位。这可能会对整个美国产生涟漪效应，减缓AI研究与开发的总体进展。

## 替代方法

我建议您不要专注于规范AI模型的开发，而是考虑解决与AI应用实际风险相关的替代方法。

+   **支持开源开发**：鼓励并促进AI模型的开源开发，以促进协作、透明度和更多样化、更具韧性的AI生态系统。

+   **专注于使用而非开发**：与其规范AI模型的开发，不如专注于规范其应用，特别是那些对公共安全和安全性造成高风险的领域。在医疗保健、刑事司法和关键基础设施等高风险领域规范AI的使用，将确保对有害使用的问责，同时允许AI技术的持续发展。

+   **促进透明度和协作**：通过行业、学术界和政府之间的协作，鼓励负责任的AI开发最佳实践的制定与采纳。这可能涉及制定行业标准、促进开源开发和投资于AI安全研究。

+   **投资于AI专业知识**：为政府机构提供资源，以发展AI专业知识，并建立有效监测和应对潜在风险的能力。这将使AI监管更为知情和细致，平衡安全与创新。

## 结论

加利福尼亚州有机会在负责任的AI发展方面走在前列。然而，目前的SB-1047法案存在的风险在于抑制创新，削弱了该州在AI领域的领导地位。通过采纳优先考虑有害使用责任的替代方法，同时促进充满活力和开放的AI生态系统，加利福尼亚州可以确保这一变革性技术的安全和有益推进。

## 关注的具体问题部分

+   **第22602节（f）**：“覆盖模型”的定义过于宽泛，可能包括各种开源模型。

+   **第22603节（b）**：对开发者的要求过于繁重，可能会抑制开源开发。

+   **第22606节（a）**：对民事处罚的潜在可能性可能会对研究和创新产生冷却效应。

+   **第11547.6节（c）（11）**：征收费用的能力可能会对小企业的进入构成障碍。

</main>
