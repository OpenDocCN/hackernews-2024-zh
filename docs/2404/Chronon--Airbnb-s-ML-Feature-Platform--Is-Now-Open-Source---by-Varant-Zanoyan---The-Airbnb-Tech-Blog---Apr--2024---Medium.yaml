- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 13:03:39'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: Chronon, Airbnb’s ML Feature Platform, Is Now Open Source | by Varant Zanoyan
    | The Airbnb Tech Blog | Apr, 2024 | Medium
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://medium.com/airbnb-engineering/chronon-airbnbs-ml-feature-platform-is-now-open-source-d9c4dba859e8](https://medium.com/airbnb-engineering/chronon-airbnbs-ml-feature-platform-is-now-open-source-d9c4dba859e8)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Chronon, Airbnb’s ML Feature Platform, Is Now Open Source**'
  id: totrans-split-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A feature platform that offers observability and management tools, allows ML
    practitioners to use a variety of data sources, while handling the complexity
    of data engineering, and provides low latency streaming.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: 'By: [Varant Zanoyan](https://www.linkedin.com/in/vzanoyan/), [Nikhil Simha
    Raprolu](https://www.linkedin.com/in/nikhilsimha/)'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: '*Chronon allows ML practitioners to use a variety of data sources as inputs
    to feature transformations. It handles the complexity of data plumbing, such as
    batch and streaming compute, provides low latency serving, and offers a host of
    observability and management tools.*'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
- en: '**Airbnb is happy to announce that** [**Chronon**](https://www.chronon.ai)**,
    our ML Feature Platform, is now open source. Join our** [**community Discord channel**](https://discord.gg/GbmGATNqqP)
    **to chat with us.**'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
- en: '**We’re excited to be making this announcement along with our partners at Stripe,
    who are early adopters and co-maintainers of the project.**'
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
- en: This blog post covers the main motivation and functionality of Chronon. For
    an overview of core concepts in Chronon, please see [this previous post](/airbnb-engineering/chronon-a-declarative-feature-engineering-framework-b7b8ce796e04).
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
- en: Background
  id: totrans-split-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We built Chronon to relieve a common pain point for ML practitioners: they
    were spending the majority of their time managing the data that powers their models
    rather than on modeling itself.'
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
- en: 'Prior to Chronon, practitioners would use one of the following two approaches:'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
- en: '**Replicate offline-online:** ML practitioners train the model with data from
    the data warehouse, then figure out ways to replicate those features in the online
    environment. The benefit of this approach is that it allows practitioners to utilize
    the full data warehouse, both the data sources and powerful tools for large-scale
    data transformation. The downside is that this leaves no clear way to serve model
    features for online inference, resulting in inconsistencies and label leakage
    that severely affect model performance.'
  id: totrans-split-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Log and wait:** ML practitioners start with the data that is available in
    the online serving environment from which the model inference will run. They log
    relevant features to the data warehouse. Once enough data has accumulated, they
    train the model on the logs, and serve with the same data. The benefit of this
    approach is that consistency is guaranteed and leakage is unlikely. However the
    major drawback is that it can result in long wait times, hindering the ability
    to respond quickly to changing user behavior.'
  id: totrans-split-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Chronon approach allows for the best of both worlds. Chronon requires ML
    practitioners to define their features only once, powering both offline flows
    for model training as well as online flows for model inference. Additionally,
    Chronon offers powerful tooling for feature chaining, observability and data quality,
    and feature sharing and management.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
  zh: Chronon 方法允许同时拥有最佳的两种情况。Chronon 要求机器学习从业者仅定义他们的特性一次，既能为模型训练的离线流程提供动力，也能为模型推断的在线流程提供动力。此外，Chronon
    还提供了强大的工具，用于特性链接、可观察性和数据质量、特性共享和管理。
- en: How It Works
  id: totrans-split-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工作原理
- en: Below we explore the main components that power most of Chronon’s functionality
    using a simple example derived from the [quickstart guide](https://chronon.ai/getting_started/Tutorial.html).
    You can follow that guide to run this example.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
  zh: 下面我们通过从[快速入门指南](https://chronon.ai/getting_started/Tutorial.html)中衍生的一个简单示例来探索支持
    Chronon 大部分功能的主要组件。您可以按照该指南运行此示例。
- en: Let’s assume that we’re a large online retailer, and we’ve detected a fraud
    vector based on users making purchases and later returning items. We want to train
    a model to predict whether a given transaction is likely to result in a fraudulent
    return. We will call this model each time a user starts the checkout flow.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们是一家大型在线零售商，我们已经检测到一种基于用户购买后退货的欺诈风险。我们希望训练一个模型来预测某个交易是否可能导致欺诈性退货。每当用户开始结账流程时，我们都会调用这个模型。
- en: Defining Features
  id: totrans-split-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义特性
- en: '**Purchases Data:** We can aggregate the purchases log data to the user level
    to give us a view into this user’s previous activity on our platform. Specifically,
    we can compute SUMs, COUNTs and AVERAGEs of their previous purchase amounts over
    various time windows.'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**购买数据：** 我们可以将购买日志数据按用户级别聚合，以查看用户在我们平台上的先前活动。具体来说，我们可以计算他们在各种时间窗口内的购买金额的 SUM、COUNT
    和 AVERAGE。'
- en: '[PRE0]'
  id: totrans-split-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*This creates a `GroupBy` which transforms the `purchases` event data into
    useful features by aggregating various fields over various time windows, with
    `user_id` as a primary key.*'
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*这会创建一个 `GroupBy`，通过在各种时间窗口内对各种字段进行聚合，以 `user_id` 作为主键，将 `purchases` 事件数据转换为有用特性。*'
- en: This transforms raw purchases log data into useful features at the user level.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这将原始购买日志数据转换为用户级别的有用特性。
- en: '**User Data:** Turning User data into features is a littler simpler, primarily
    because we don’t have to worry about performing aggregations. In this case, the
    primary key of the source data is the same as the primary key of the feature,
    so we can simply extract column values rather than perform aggregations over rows:'
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**用户数据：** 将用户数据转换为特性稍微简单些，主要因为我们不必担心执行聚合操作。在这种情况下，源数据的主键与特性的主键相同，因此我们只需提取列值，而不必在行上执行聚合操作：'
- en: '[PRE1]'
  id: totrans-split-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '*This creates a `GroupBy` which extracts dimensions from the `data.users` table
    for use as features, with `user_id` as a primary key.*'
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*这会创建一个 `GroupBy`，从 `data.users` 表中提取维度作为特性，以 `user_id` 作为主键。*'
- en: '**Joining these features together:** Next, we need to combine the previously
    defined features into a single view that can be both backfilled for model training
    and served online as a complete vector for model inference. We can achieve this
    using the Join API.'
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**将这些特性组合在一起：** 接下来，我们需要将先前定义的特性组合成一个单一视图，既可以用于模型训练时的数据回填，也可以作为模型推断时的完整向量服务在线提供。我们可以通过使用
    Join API 来实现这一点。'
- en: For our use case, it’s very important that features are computed as of the correct
    timestamp. Because our model runs when the checkout flow begins, we want to use
    the corresponding timestamp in our backfill, such that feature values for model
    training logically match what the model will see in online inference.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的用例，特别重要的是要在正确的时间戳下计算特性。因为我们的模型在结账流程开始时运行，我们希望在回填中使用相应的时间戳，以便模型训练时的特性值逻辑上匹配在线推断中模型将看到的内容。
- en: Here’s what the definition would look like. Note that it combines our previously
    defined features in the right_parts portion of the API (along with another feature
    set called returns).
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是定义的样子。请注意，它将我们之前在 API 的 right_parts 部分定义的特性组合在一起（还有另一个称为 returns 的特性集）。
- en: '[PRE2]'
  id: totrans-split-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Backfills/Offline Computation
  id: totrans-split-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据回填/离线计算
- en: 'The first thing that a user would likely do with the above Join definition
    is run a backfill with it to produce historical feature values for model training.
    Chronon performs this backfill with a few key benefits:'
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可能会首先使用上述 Join 定义运行回填，以生成用于模型训练的历史特性值。Chronon 在执行此回填时具有一些关键优势：
- en: '**Point-in-time accuracy:** Notice the source that is used as the “left” side
    of the join above. It is built on top of the “data.checkouts” source, which includes
    a “ts” timestamp on each row that corresponds to the logical time of that particular
    checkout. Every feature computation is guaranteed to be window-accurate as of
    that timestamp. So for the one-month sum of previous user purchases, every row
    will be computed for the user as of the timestamp provided by the left-hand source.'
  id: totrans-split-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**时间点准确性：** 注意作为上述连接“左”侧使用的源。它建立在“data.checkouts”源之上，每行都包括一个“ts”时间戳，对应于该特定结账的逻辑时间。每个特性计算都保证与该时间戳的窗口准确对应。因此，对于前用户购买总额的一个月求和，每一行将根据左侧源提供的时间戳进行计算。'
- en: '**Skew handling:** Chronon’s backfill algorithms are optimized for handling
    highly skewed datasets, avoiding frustrating OOMs and hanging jobs.'
  id: totrans-split-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**偏斜处理：** Chronon 的回填算法经过优化，用于处理高度偏斜的数据集，避免令人沮丧的内存溢出和挂起作业。'
- en: '**Computational efficiency optimizations:** Chronon is able to bake in a number
    of optimizations directly into the backend, reducing compute time and cost.'
  id: totrans-split-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**计算效率优化：** Chronon 能够直接在后端内置多种优化，减少计算时间和成本。'
- en: Online Computation
  id: totrans-split-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在线计算
- en: Chronon abstracts away a lot of complexity for online feature computation. In
    the above examples, it would compute features based on whether the feature is
    a batch feature or a streaming feature.
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
  zh: Chronon 在在线特性计算中抽象了大量复杂性。在上述示例中，它将根据特性是批处理特性还是流处理特性进行计算。
- en: '**Batch features (for example, the User features above)**'
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**批处理特性（例如上述的用户特性）**'
- en: Because the User features are built on top of a batch table, Chronon will simply
    run a daily batch job to compute the new feature values as new data lands in the
    batch data store and upload them to the online KV store for serving.
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由于用户特性是建立在批处理表之上，Chronon 将简单地运行每日批处理作业，计算新的特性数值，随着新数据进入批处理数据存储，并将其上传到在线 KV 存储以提供服务。
- en: '**Streaming features (for example, the Purchases features above)**'
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**流处理特性（例如上述的购买特性）**'
- en: 'The Purchases features are built on a source that includes a streaming component,
    as indicated by the inclusion of a “topic” in the source. In this case, Chronon
    will still run a batch upload in addition to a streaming job for real time updates.
    The batch jobs is responsible for:'
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
  zh: 购买特性建立在包括流组件的源上，源中包含“topic”，表明Chronon将除了实时更新的流作业外，仍然运行批处理上传作业。批处理作业负责：
- en: '**Seeding the values:** For long windows, it wouldn’t be practical to rewind
    the stream and play back all raw events.'
  id: totrans-split-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**种子值设定：** 对于长时间窗口，回放所有原始事件并不实际。'
- en: '**Compressing “the middle of the window” and providing tail accuracy:** For
    precise window accuracy, we need raw events at both the head and the tail of the
    window.'
  id: totrans-split-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**压缩“窗口中部”并提供尾部准确性：** 为了精确窗口准确性，我们需要在窗口的头部和尾部都有原始事件。'
- en: The streaming job then writes updates to the KV store to keep feature values
    up to date at fetch time.
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，流作业将更新写入 KV 存储，以保持在获取时特性值的最新状态。
- en: Online Serving / Fetch API
  id: totrans-split-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在线服务 / 抓取 API
- en: 'Chronon offers an API to fetch features with low latency. We can either fetch
    values for individual GroupBys (i.e. the Users or Purchases features defined above)
    or for a Join. Here’s an example of what one such request and response for a Join
    would look like:'
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
  zh: Chronon 提供了一个 API 来以低延迟获取特性。我们可以为单个 GroupBy（例如上述的用户或购买特性）或进行连接获取值。以下是一个这样的连接请求和响应的示例：
- en: '[PRE3]'
  id: totrans-split-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '*Java code that fetches all features for user 123\. The return type is a map
    of feature name to feature value.*'
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
  zh: '*Java 代码，用于获取用户123的所有特性。返回类型是特性名称到特性值的映射。*'
- en: 'The above example uses the Java client. There is also a Scala client and a
    Python CLI tool for easy testing and debugging:'
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例使用了 Java 客户端。还有 Scala 客户端和 Python CLI 工具，用于简便测试和调试：
- en: '[PRE4]'
  id: totrans-split-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*Utilizes the run.py CLI tool to make the same fetch request as the Java code
    above. run.py is a convenient way to quickly test Chronon workflows like fetching.*'
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
  zh: '*利用 run.py CLI 工具来执行与上述 Java 代码相同的获取请求。run.py 是快速测试 Chronon 工作流（如获取）的便捷方式。*'
- en: Another option is to wrap these APIs into a service and make requests via a
    REST endpoint. This approach is used within Airbnb for fetching features in non-Java
    environments such as Ruby.
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是将这些 API 封装成一个服务，并通过 REST 端点进行请求。这种方法在 Airbnb 中用于在非 Java 环境（如 Ruby）中获取特性。
- en: Online-Offline Consistency
  id: totrans-split-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在线-离线一致性
- en: Chronon not only helps online-offline accuracy, it also offers a way to measure
    it. The measurement pipeline starts with the logs of the online fetch requests.
    These logs include the primary keys and timestamp of the request, along with the
    fetched feature values. Chronon then passes the keys and timestamps to a Join
    backfill as the left side, asking the compute engine to backfill the feature values.
    It then compares the backfilled values to actual fetched values to measure consistency.
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
- en: What’s Next?
  id: totrans-split-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Open source is just the first step in an exciting journey that we look forward
    to taking with our partners at Stripe and the broader community.
  id: totrans-split-59
  prefs: []
  type: TYPE_NORMAL
- en: 'Our vision is to create a platform that enables ML practitioners to make the
    best possible decisions about how to leverage their data and makes enacting those
    decisions as easy as possible. Here are some questions that we’re currently using
    to inform our roadmap:'
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
- en: '**How much further can we lower the cost of iteration and computation?**'
  id: totrans-split-61
  prefs: []
  type: TYPE_NORMAL
- en: Chronon is already built for the scale of data processed by large companies
    such as Airbnb and Stripe. However, there are always further optimizations that
    we can make to our compute engine, both to reduce the compute cost and the “time
    cost” of creating and experimenting with new features.
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
- en: '**How much easier can we make authoring a new feature?**'
  id: totrans-split-63
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering is the process by which humans express their domain knowledge
    to create signals that the model can leverage. Chronon could integrate NLP to
    allow ML practitioners to express these feature ideas in natural language and
    generate working feature definition code as a starting point for their iteration.
  id: totrans-split-64
  prefs: []
  type: TYPE_NORMAL
- en: Lowering the technical bar to feature creation would in turn open the door to
    new kinds of collaboration between ML practitioners and partners who have valuable
    domain expertise.
  id: totrans-split-65
  prefs: []
  type: TYPE_NORMAL
- en: '**Can we improve the way models are maintained?**'
  id: totrans-split-66
  prefs: []
  type: TYPE_NORMAL
- en: Changing user behavior can cause shifts in model performance because the data
    that the model was trained on no longer applies to the current situation. We imagine
    a platform that can detect these shifts and create a strategy to address them
    early and proactively, either by retraining, adding new features, modifying existing
    features, or some combination of the above.
  id: totrans-split-67
  prefs: []
  type: TYPE_NORMAL
- en: '**Can the platform itself become an intelligent agent that helps ML practitioners
    build and deploy the best possible models?**'
  id: totrans-split-68
  prefs: []
  type: TYPE_NORMAL
- en: The more metadata that we gather into the platform layer, the more powerful
    it can become as a general ML assistant.
  id: totrans-split-69
  prefs: []
  type: TYPE_NORMAL
- en: We mentioned the goal of creating a platform that can automatically run experiments
    with new data to identify ways to improve models. Such a platform might also help
    with data management by allowing ML practitioners to ask questions such as “What
    kinds of features tend to be most useful when modeling this use case?” or “What
    data sources might help me create features that capture signal about this target?”
    A platform that could answer these types of questions represents the next level
    of intelligent automation.
  id: totrans-split-70
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提到了创建一个平台的目标，该平台可以自动运行实验，使用新数据来识别改进模型的方法。这样的平台还可以通过允许机器学习从业者提出问题来帮助数据管理，比如“在建模这个用例时，哪些特征类型通常最有用？”或“哪些数据源可以帮助我创建捕捉与此目标有关的信号的特征？”一个能够回答这些问题的平台代表了智能自动化的下一个层次。
- en: Getting Started
  id: totrans-split-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 入门指南
- en: Here are some resources to help you get started or to evaluate if Chronon is
    a good fit for your team.
  id: totrans-split-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些资源，可以帮助您开始或评估Chronon是否适合您的团队。
- en: Interested in this type of work? Check out our open roles [here](https://careers.airbnb.com/)
    — we’re hiring.
  id: totrans-split-73
  prefs: []
  type: TYPE_NORMAL
  zh: 对这种类型的工作感兴趣吗？请查看我们的空缺职位[这里](https://careers.airbnb.com/) — 我们正在招聘。
- en: Acknowledgements
  id: totrans-split-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致谢
- en: '**Sponsors:** [Henry Saputra](mailto:henry.saputra@airbnb.com) [Yi Li](mailto:yi.li@airbnb.com)
    [Jack Song](mailto:jack.song@airbnb.com)'
  id: totrans-split-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**赞助商：** [Henry Saputra](mailto:henry.saputra@airbnb.com) [李毅](mailto:yi.li@airbnb.com)
    [宋杰](mailto:jack.song@airbnb.com)'
- en: '**Contributors:** [Pengyu Hou](mailto:pengyu.hou@airbnb.com) [Cristian Figueroa](mailto:cristian.figueroa@airbnb.com)
    [Haozhen Ding](mailto:haozhen.ding@airbnb.com) [Sophie Wang](mailto:sophie.wang@airbnb.com)
    [Vamsee Yarlagadda](mailto:vamsee.y@airbnb.com) [Haichun Chen](mailto:haichun.chen@airbnb.com)
    [Donghan Zhang](mailto:donghan.zhang@airbnb.com) [Hao Cen](mailto:hao.cen@airbnb.com)
    [Yuli Han](mailto:yuli.han@airbnb.com) [Evgenii Shapiro](mailto:evgeny.shapiro@airbnb.com)
    [Atul Kale](http://atul.kale@airbnb.com) Patrick Yoon'
  id: totrans-split-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**贡献者：** [侯鹏宇](mailto:pengyu.hou@airbnb.com) [Cristian Figueroa](mailto:cristian.figueroa@airbnb.com)
    [丁浩臻](mailto:haozhen.ding@airbnb.com) [王若男](mailto:sophie.wang@airbnb.com) [Vamsee
    Yarlagadda](mailto:vamsee.y@airbnb.com) [陈海春](mailto:haichun.chen@airbnb.com)
    [张东涵](mailto:donghan.zhang@airbnb.com) [岑昊](mailto:hao.cen@airbnb.com) [韩雨莉](mailto:yuli.han@airbnb.com)
    [Evgenii Shapiro](mailto:evgeny.shapiro@airbnb.com) [Atul Kale](http://atul.kale@airbnb.com)
    Patrick Yoon'
