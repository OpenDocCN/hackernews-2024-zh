- en: <!--yml
  id: totrans-split-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-split-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-05-27 13:03:39'
  id: totrans-split-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-split-3
  prefs: []
  type: TYPE_NORMAL
- en: Chronon, Airbnb’s ML Feature Platform, Is Now Open Source | by Varant Zanoyan
    | The Airbnb Tech Blog | Apr, 2024 | Medium
  id: totrans-split-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://medium.com/airbnb-engineering/chronon-airbnbs-ml-feature-platform-is-now-open-source-d9c4dba859e8](https://medium.com/airbnb-engineering/chronon-airbnbs-ml-feature-platform-is-now-open-source-d9c4dba859e8)
  id: totrans-split-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Chronon, Airbnb’s ML Feature Platform, Is Now Open Source**'
  id: totrans-split-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A feature platform that offers observability and management tools, allows ML
    practitioners to use a variety of data sources, while handling the complexity
    of data engineering, and provides low latency streaming.
  id: totrans-split-7
  prefs: []
  type: TYPE_NORMAL
- en: 'By: [Varant Zanoyan](https://www.linkedin.com/in/vzanoyan/), [Nikhil Simha
    Raprolu](https://www.linkedin.com/in/nikhilsimha/)'
  id: totrans-split-8
  prefs: []
  type: TYPE_NORMAL
- en: '*Chronon allows ML practitioners to use a variety of data sources as inputs
    to feature transformations. It handles the complexity of data plumbing, such as
    batch and streaming compute, provides low latency serving, and offers a host of
    observability and management tools.*'
  id: totrans-split-9
  prefs: []
  type: TYPE_NORMAL
- en: '**Airbnb is happy to announce that** [**Chronon**](https://www.chronon.ai)**,
    our ML Feature Platform, is now open source. Join our** [**community Discord channel**](https://discord.gg/GbmGATNqqP)
    **to chat with us.**'
  id: totrans-split-10
  prefs: []
  type: TYPE_NORMAL
- en: '**We’re excited to be making this announcement along with our partners at Stripe,
    who are early adopters and co-maintainers of the project.**'
  id: totrans-split-11
  prefs: []
  type: TYPE_NORMAL
- en: This blog post covers the main motivation and functionality of Chronon. For
    an overview of core concepts in Chronon, please see [this previous post](/airbnb-engineering/chronon-a-declarative-feature-engineering-framework-b7b8ce796e04).
  id: totrans-split-12
  prefs: []
  type: TYPE_NORMAL
- en: Background
  id: totrans-split-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We built Chronon to relieve a common pain point for ML practitioners: they
    were spending the majority of their time managing the data that powers their models
    rather than on modeling itself.'
  id: totrans-split-14
  prefs: []
  type: TYPE_NORMAL
- en: 'Prior to Chronon, practitioners would use one of the following two approaches:'
  id: totrans-split-15
  prefs: []
  type: TYPE_NORMAL
- en: '**Replicate offline-online:** ML practitioners train the model with data from
    the data warehouse, then figure out ways to replicate those features in the online
    environment. The benefit of this approach is that it allows practitioners to utilize
    the full data warehouse, both the data sources and powerful tools for large-scale
    data transformation. The downside is that this leaves no clear way to serve model
    features for online inference, resulting in inconsistencies and label leakage
    that severely affect model performance.'
  id: totrans-split-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Log and wait:** ML practitioners start with the data that is available in
    the online serving environment from which the model inference will run. They log
    relevant features to the data warehouse. Once enough data has accumulated, they
    train the model on the logs, and serve with the same data. The benefit of this
    approach is that consistency is guaranteed and leakage is unlikely. However the
    major drawback is that it can result in long wait times, hindering the ability
    to respond quickly to changing user behavior.'
  id: totrans-split-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Chronon approach allows for the best of both worlds. Chronon requires ML
    practitioners to define their features only once, powering both offline flows
    for model training as well as online flows for model inference. Additionally,
    Chronon offers powerful tooling for feature chaining, observability and data quality,
    and feature sharing and management.
  id: totrans-split-18
  prefs: []
  type: TYPE_NORMAL
- en: How It Works
  id: totrans-split-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Below we explore the main components that power most of Chronon’s functionality
    using a simple example derived from the [quickstart guide](https://chronon.ai/getting_started/Tutorial.html).
    You can follow that guide to run this example.
  id: totrans-split-20
  prefs: []
  type: TYPE_NORMAL
- en: Let’s assume that we’re a large online retailer, and we’ve detected a fraud
    vector based on users making purchases and later returning items. We want to train
    a model to predict whether a given transaction is likely to result in a fraudulent
    return. We will call this model each time a user starts the checkout flow.
  id: totrans-split-21
  prefs: []
  type: TYPE_NORMAL
- en: Defining Features
  id: totrans-split-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Purchases Data:** We can aggregate the purchases log data to the user level
    to give us a view into this user’s previous activity on our platform. Specifically,
    we can compute SUMs, COUNTs and AVERAGEs of their previous purchase amounts over
    various time windows.'
  id: totrans-split-23
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-split-24
  prefs: []
  type: TYPE_PRE
- en: '*This creates a `GroupBy` which transforms the `purchases` event data into
    useful features by aggregating various fields over various time windows, with
    `user_id` as a primary key.*'
  id: totrans-split-25
  prefs: []
  type: TYPE_NORMAL
- en: This transforms raw purchases log data into useful features at the user level.
  id: totrans-split-26
  prefs: []
  type: TYPE_NORMAL
- en: '**User Data:** Turning User data into features is a littler simpler, primarily
    because we don’t have to worry about performing aggregations. In this case, the
    primary key of the source data is the same as the primary key of the feature,
    so we can simply extract column values rather than perform aggregations over rows:'
  id: totrans-split-27
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-split-28
  prefs: []
  type: TYPE_PRE
- en: '*This creates a `GroupBy` which extracts dimensions from the `data.users` table
    for use as features, with `user_id` as a primary key.*'
  id: totrans-split-29
  prefs: []
  type: TYPE_NORMAL
- en: '**Joining these features together:** Next, we need to combine the previously
    defined features into a single view that can be both backfilled for model training
    and served online as a complete vector for model inference. We can achieve this
    using the Join API.'
  id: totrans-split-30
  prefs: []
  type: TYPE_NORMAL
- en: For our use case, it’s very important that features are computed as of the correct
    timestamp. Because our model runs when the checkout flow begins, we want to use
    the corresponding timestamp in our backfill, such that feature values for model
    training logically match what the model will see in online inference.
  id: totrans-split-31
  prefs: []
  type: TYPE_NORMAL
- en: Here’s what the definition would look like. Note that it combines our previously
    defined features in the right_parts portion of the API (along with another feature
    set called returns).
  id: totrans-split-32
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-split-33
  prefs: []
  type: TYPE_PRE
- en: Backfills/Offline Computation
  id: totrans-split-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The first thing that a user would likely do with the above Join definition
    is run a backfill with it to produce historical feature values for model training.
    Chronon performs this backfill with a few key benefits:'
  id: totrans-split-35
  prefs: []
  type: TYPE_NORMAL
- en: '**Point-in-time accuracy:** Notice the source that is used as the “left” side
    of the join above. It is built on top of the “data.checkouts” source, which includes
    a “ts” timestamp on each row that corresponds to the logical time of that particular
    checkout. Every feature computation is guaranteed to be window-accurate as of
    that timestamp. So for the one-month sum of previous user purchases, every row
    will be computed for the user as of the timestamp provided by the left-hand source.'
  id: totrans-split-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Skew handling:** Chronon’s backfill algorithms are optimized for handling
    highly skewed datasets, avoiding frustrating OOMs and hanging jobs.'
  id: totrans-split-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Computational efficiency optimizations:** Chronon is able to bake in a number
    of optimizations directly into the backend, reducing compute time and cost.'
  id: totrans-split-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Online Computation
  id: totrans-split-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chronon abstracts away a lot of complexity for online feature computation. In
    the above examples, it would compute features based on whether the feature is
    a batch feature or a streaming feature.
  id: totrans-split-40
  prefs: []
  type: TYPE_NORMAL
- en: '**Batch features (for example, the User features above)**'
  id: totrans-split-41
  prefs: []
  type: TYPE_NORMAL
- en: Because the User features are built on top of a batch table, Chronon will simply
    run a daily batch job to compute the new feature values as new data lands in the
    batch data store and upload them to the online KV store for serving.
  id: totrans-split-42
  prefs: []
  type: TYPE_NORMAL
- en: '**Streaming features (for example, the Purchases features above)**'
  id: totrans-split-43
  prefs: []
  type: TYPE_NORMAL
- en: 'The Purchases features are built on a source that includes a streaming component,
    as indicated by the inclusion of a “topic” in the source. In this case, Chronon
    will still run a batch upload in addition to a streaming job for real time updates.
    The batch jobs is responsible for:'
  id: totrans-split-44
  prefs: []
  type: TYPE_NORMAL
- en: '**Seeding the values:** For long windows, it wouldn’t be practical to rewind
    the stream and play back all raw events.'
  id: totrans-split-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Compressing “the middle of the window” and providing tail accuracy:** For
    precise window accuracy, we need raw events at both the head and the tail of the
    window.'
  id: totrans-split-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The streaming job then writes updates to the KV store to keep feature values
    up to date at fetch time.
  id: totrans-split-47
  prefs: []
  type: TYPE_NORMAL
- en: Online Serving / Fetch API
  id: totrans-split-48
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Chronon offers an API to fetch features with low latency. We can either fetch
    values for individual GroupBys (i.e. the Users or Purchases features defined above)
    or for a Join. Here’s an example of what one such request and response for a Join
    would look like:'
  id: totrans-split-49
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-split-50
  prefs: []
  type: TYPE_PRE
- en: '*Java code that fetches all features for user 123\. The return type is a map
    of feature name to feature value.*'
  id: totrans-split-51
  prefs: []
  type: TYPE_NORMAL
- en: 'The above example uses the Java client. There is also a Scala client and a
    Python CLI tool for easy testing and debugging:'
  id: totrans-split-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-split-53
  prefs: []
  type: TYPE_PRE
- en: '*Utilizes the run.py CLI tool to make the same fetch request as the Java code
    above. run.py is a convenient way to quickly test Chronon workflows like fetching.*'
  id: totrans-split-54
  prefs: []
  type: TYPE_NORMAL
- en: Another option is to wrap these APIs into a service and make requests via a
    REST endpoint. This approach is used within Airbnb for fetching features in non-Java
    environments such as Ruby.
  id: totrans-split-55
  prefs: []
  type: TYPE_NORMAL
- en: Online-Offline Consistency
  id: totrans-split-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chronon not only helps online-offline accuracy, it also offers a way to measure
    it. The measurement pipeline starts with the logs of the online fetch requests.
    These logs include the primary keys and timestamp of the request, along with the
    fetched feature values. Chronon then passes the keys and timestamps to a Join
    backfill as the left side, asking the compute engine to backfill the feature values.
    It then compares the backfilled values to actual fetched values to measure consistency.
  id: totrans-split-57
  prefs: []
  type: TYPE_NORMAL
- en: What’s Next?
  id: totrans-split-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Open source is just the first step in an exciting journey that we look forward
    to taking with our partners at Stripe and the broader community.
  id: totrans-split-59
  prefs: []
  type: TYPE_NORMAL
- en: 'Our vision is to create a platform that enables ML practitioners to make the
    best possible decisions about how to leverage their data and makes enacting those
    decisions as easy as possible. Here are some questions that we’re currently using
    to inform our roadmap:'
  id: totrans-split-60
  prefs: []
  type: TYPE_NORMAL
- en: '**How much further can we lower the cost of iteration and computation?**'
  id: totrans-split-61
  prefs: []
  type: TYPE_NORMAL
- en: Chronon is already built for the scale of data processed by large companies
    such as Airbnb and Stripe. However, there are always further optimizations that
    we can make to our compute engine, both to reduce the compute cost and the “time
    cost” of creating and experimenting with new features.
  id: totrans-split-62
  prefs: []
  type: TYPE_NORMAL
- en: '**How much easier can we make authoring a new feature?**'
  id: totrans-split-63
  prefs: []
  type: TYPE_NORMAL
- en: Feature engineering is the process by which humans express their domain knowledge
    to create signals that the model can leverage. Chronon could integrate NLP to
    allow ML practitioners to express these feature ideas in natural language and
    generate working feature definition code as a starting point for their iteration.
  id: totrans-split-64
  prefs: []
  type: TYPE_NORMAL
- en: Lowering the technical bar to feature creation would in turn open the door to
    new kinds of collaboration between ML practitioners and partners who have valuable
    domain expertise.
  id: totrans-split-65
  prefs: []
  type: TYPE_NORMAL
- en: '**Can we improve the way models are maintained?**'
  id: totrans-split-66
  prefs: []
  type: TYPE_NORMAL
- en: Changing user behavior can cause shifts in model performance because the data
    that the model was trained on no longer applies to the current situation. We imagine
    a platform that can detect these shifts and create a strategy to address them
    early and proactively, either by retraining, adding new features, modifying existing
    features, or some combination of the above.
  id: totrans-split-67
  prefs: []
  type: TYPE_NORMAL
- en: '**Can the platform itself become an intelligent agent that helps ML practitioners
    build and deploy the best possible models?**'
  id: totrans-split-68
  prefs: []
  type: TYPE_NORMAL
- en: The more metadata that we gather into the platform layer, the more powerful
    it can become as a general ML assistant.
  id: totrans-split-69
  prefs: []
  type: TYPE_NORMAL
- en: We mentioned the goal of creating a platform that can automatically run experiments
    with new data to identify ways to improve models. Such a platform might also help
    with data management by allowing ML practitioners to ask questions such as “What
    kinds of features tend to be most useful when modeling this use case?” or “What
    data sources might help me create features that capture signal about this target?”
    A platform that could answer these types of questions represents the next level
    of intelligent automation.
  id: totrans-split-70
  prefs: []
  type: TYPE_NORMAL
- en: Getting Started
  id: totrans-split-71
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here are some resources to help you get started or to evaluate if Chronon is
    a good fit for your team.
  id: totrans-split-72
  prefs: []
  type: TYPE_NORMAL
- en: Interested in this type of work? Check out our open roles [here](https://careers.airbnb.com/)
    — we’re hiring.
  id: totrans-split-73
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements
  id: totrans-split-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Sponsors:** [Henry Saputra](mailto:henry.saputra@airbnb.com) [Yi Li](mailto:yi.li@airbnb.com)
    [Jack Song](mailto:jack.song@airbnb.com)'
  id: totrans-split-75
  prefs: []
  type: TYPE_NORMAL
- en: '**Contributors:** [Pengyu Hou](mailto:pengyu.hou@airbnb.com) [Cristian Figueroa](mailto:cristian.figueroa@airbnb.com)
    [Haozhen Ding](mailto:haozhen.ding@airbnb.com) [Sophie Wang](mailto:sophie.wang@airbnb.com)
    [Vamsee Yarlagadda](mailto:vamsee.y@airbnb.com) [Haichun Chen](mailto:haichun.chen@airbnb.com)
    [Donghan Zhang](mailto:donghan.zhang@airbnb.com) [Hao Cen](mailto:hao.cen@airbnb.com)
    [Yuli Han](mailto:yuli.han@airbnb.com) [Evgenii Shapiro](mailto:evgeny.shapiro@airbnb.com)
    [Atul Kale](http://atul.kale@airbnb.com) Patrick Yoon'
  id: totrans-split-76
  prefs: []
  type: TYPE_NORMAL
