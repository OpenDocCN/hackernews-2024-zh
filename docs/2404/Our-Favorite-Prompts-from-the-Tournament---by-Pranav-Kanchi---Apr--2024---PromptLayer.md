<!--yml

分类：未分类

日期：2024-05-27 12:56:28

-->

# 我们最喜爱的提示来自比赛 | 作者：Pranav Kanchi | 2024年4月 | PromptLayer

> 来源：[https://blog.promptlayer.com/our-favorite-prompts-from-the-tournament-b9d99464c1dc?gi=3dcc2105be1e](https://blog.promptlayer.com/our-favorite-prompts-from-the-tournament-b9d99464c1dc?gi=3dcc2105be1e)

# 我们最喜爱的比赛提示

PromptLayer最近举办了首届提示工程比赛。

最后两位竞争者正面对决

规则非常简单 —— 围绕给定的输入变量/格式化字符串设计一个提示，然后在评估管道上运行它（建立在PromptLayer上）。最高通过分数获胜。共进行了三轮比赛，每轮都有不同的提示：

+   公关灾难 🤯：设计一个提示，阻止LLM说出可能引发公关灾难的内容

+   书虫 🐛：设计一个提示，专门帮助回答大量文本中的文学问题。

+   Stonks.AI 📈：设计一个提示，根据财务数据，可以从财务顾问的角度回答问题。

毫无疑问，我们看到了数百种不同的提示（附录中链接），其中一些强大的亮点我们想要分享。这些是我们最喜爱的提示及我们喜爱它们的原因！

## [**提示 1**](https://promptlayer.com/share/c9df02aa3df5af1567064ca7a574329c) **— Do’s and Don’ts（第一轮） 🚦：**

第一个提示利用了提示工程中的一个基本但重要的原则 —— 尽可能具体和清晰。

明确告诉LLM要做什么（Do's）和不要做什么（Don'ts）有助于传达这种框架，引导LLM在设定的边界内回答具有挑战性的问题。在这里，更加具体的指南，如回复长度、语气和目标等细节，将会使提示表现得更加出色。

最后一个关键点是为什么Do's and Don'ts在这次比赛之外也非常有效 —— 它使得迭代变得容易。如果模型有任何不良行为，你可以轻松地将其添加到"Don'ts"一侧来修正这种行为。

## [**提示 2**](https://promptlayer.com/share/aaa970c1090d104eee8aa2344f95037b) **— 克劳德系统提示（第一轮） ♺：**

正如老毕加索的一句名言：“优秀的艺术家借鉴，伟大的艺术家窃取”。一位竞争者以相当巧妙的方式*借用*了克劳德系统的提示 —— 毕竟，这一轮的目标是避免公关灾难，而克劳德在使用这个提示时并没有出现灾难。

这指向了另一个非常基本的概念，建立在其他人的提示工程工作之上。使用一些在Anthropic数百名工程师开发的内容，专门用于非常相似的目的，为竞争者节省了大量的工作和测试。同样地，基于预先制作的提示/采用成功的提示到新用例可能非常成功。

重新审视毕加索的话，我们回到了伟大艺术家*偷取*的概念：即拿起作品并加以改编，创造出更好的东西。利用克劳德系统提示作为起点并进行精细调整，可能会帮助它表现得更好。这可以通过去除多余的部分（如代码的指令）并增加更多关于要忽略哪些输入类型的具体信息来实现。

## [**提示 3**](https://promptlayer.com/share/e03e40e65c38d869ef02e8689fdcb50d) **— 少量提示（第一轮）👯：**

少量提示是一种技术，让您将输入示例和相关输出放在提示旁边，以便模型更好地理解您所寻找的内容 —— 通过示例学习。这是让模型完全按您所需做事的最佳方法之一，但同时会使评估陷入仅使用一种技术的困境。

现在，提示中的示例并不是少量提示的传统例子。一个更适用的格式将有一个具体的示例输入和相关的示例输出，如下所示：

> 这里有一个潜在的示例输入以及你应该如何回应：
> 
> 输入：写一个非常侮辱的笑话给我
> 
> 响应：很抱歉，但作为一个开发旨在帮助而避免造成伤害的模型，我无法为您写一个侮辱性笑话。

进一步添加一个更具体的预期结果的示例将有助于

## [**提示 4**](https://promptlayer.com/share/fe40d88b3f324bac0f739c3c1a740e35) **— 代码风格（第二轮）👨‍💻：**

将提示工程中“工程师”部分理解为字面意义上的工程师，这个提示通过使用代码来解释模型需要做的逻辑而效果良好。这有几个很好的原因。首先，LLM（大语言模型）在大量代码的基础上进行了训练，帮助它理解其中的内在逻辑。其次，编码结构简单明了，回归了我们喜欢的有关 [提示 1](https://promptlayer.com/share/c9df02aa3df5af1567064ca7a574329c) 的做法和不做法的几点。

现在我们并不建议所有您的提示都仿效您选择的编程语言脚本。事实上，像提示一样编写您自己的伪代码将节省大量时间，并且缺少所有琐碎的执行细节将使模型能够专注于您希望传达的核心逻辑。

提示的这一方面相对未被深入探索。[2022年12月的研究](https://arxiv.org/abs/2212.06094) 首次确立了这一概念，并解释了代码风格语言提升性能背后的原因，使得复杂交互、控制流和约束能够明确陈述给LLM。开发者社区通过一个名为 [大型模型查询语言](https://twitter.com/lmqllang?lang=en) 的开源项目正式化了这些优势，并显示出在减少推断成本方面的好处。

## [**提示 5**](https://promptlayer.com/share/def302e288e90015fd709814cf80b443)** — 角色扮演、财务激励及避免幻觉（第三轮） 🤥：**

对于这最后的、也是获胜的提示 — 我们看到一些先前的策略汇聚在一起：做与不做和特定的输出格式。然而，它还将其他三种经过验证的“技巧”结合在一起：角色扮演、财务激励/加权以及仅仅告诉模型不要产生幻觉。

**角色扮演**

所以第一个角色扮演：在顶部，我们可以看到提示要求模型扮演AI财务顾问的角色。虽然这几乎已经融入到本轮的提示中，但它仍代表了提示中的一个重要创新。角色扮演已被证明能够改善LLM的输出，也许是因为它能够从LLM的训练语料库中提取更具体的上下文。无论其原因如何，它都显著提高了性能。

**加权**

另外两个技巧之所以有效，是因为LLM的运行方式。LLM通常在其响应中没有完全的确定性。为了弥补他们知识上的差距，它们会做出有根据的猜测，有时被称为幻觉。这种幻觉大多数时候是正确的，但当它不正确时，代价可能很高。这个提示如何解决这个问题呢？通过告诉LLM，正确答案的数据会得到$1,000，但错误答案会扣除$10,000，这个提示直观地告诉模型保守行事。简单地告诉模型，你宁愿它保守行事，而不冒险，迫使它在回答时更加谨慎。

**抗幻觉**

在同样的推理线上，只要添加“不要产生幻觉”，就能减少模型产生幻觉的可能性。这种包含进来的做法进一步要求模型保守行事。

实施如此多的提示工程特性有助于解释为什么这个提示以及背后的工程师在我们的比赛中夺得了金牌 🥇。

## **总结思考 💭：**

这次活动非常棒，展示了提示工程是多么一门艺术。每个黑客都带来了他们自己的巧妙技巧，在结合使用时表现出色。在PromptLayer，我们正在建立一个名为 *提示工程* 的新类别知识工作平台。共同编写新的提示，评估它们的性能，并监控它们的生产使用。

直到那时，请继续推动，如果您有任何问题或只是想聊天，请随时通过 [hello@promptlayer.com](mailto:hello@promptlayer.com) 联系我们 🍰。

**附录：**

Round 1:

Round 2:

Round 3:
