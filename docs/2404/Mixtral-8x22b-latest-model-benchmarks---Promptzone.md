<!--yml

category: 未分类

date: 2024-05-27 13:06:33

-->

# Mixtral 8x22b最新模型基准测试 - Promptzone

> 来源：[https://www.promptzone.com/promptzone/mixtral-8x22b-latest-model-benchmarks-4mh9](https://www.promptzone.com/promptzone/mixtral-8x22b-latest-model-benchmarks-4mh9)

在OpenAI和Google之后，Mistral AI悄然进入了大型语言模型竞赛，发布了迄今为止最强大的模型之一：Mixtral 8x22B。

**亮点：**

+   法国初创公司Mistral AI推出了其最新的开源LLM，Mixtral 8x22B。

+   该模型采用复杂的专家混合（MoE）架构，并且相较于Mixtral 8x7B等先前模型，显示出了有前景的初始基准测试结果。

+   模型权重可在Hugging Face上下载，并附有安装说明。

**Mixtral 8x22B为何如此强大？**

Mixtral 8x22B利用MoE架构，拥有1760亿参数和65,000个令牌的上下文窗口。该架构允许稀疏的MoE策略，提供访问各种专门领域模型，平衡了性能和计算成本。

**可访问性和开源承诺：**

Mistral AI继续通过坚持开源原则挑战专有模型，使Mixtral 8x22B通过Hugging Face提供种子下载。提供了详细的运行模型的说明，以适应不同系统能力的需求。

**市场定位与创新：**

作为生成AI市场上最新的LLM，Mixtral 8x22B与最近发布的产品（如Databricks的DBRX、OpenAI的GPT-4 Turbo Vision和Anthropic的Claude 3）并列。尽管其主要设计为自动补全模型，而非聊天或指导模型，但它在广泛任务中提供了有效的计算和性能。

**基准测试和比较：**

尽管缺乏官方基准测试，但Hugging Face社区进行的测试显示，Mixtral 8x22B与Google和OpenAI的闭源模型密切竞争。它在各种基准测试中取得了显著分数：

+   **ARC-C推理能力**：得分70.5，展示出强大的推理能力。

+   **常识推理**：在HellaSwag基准测试中得分为88.9，显示出强大的常识推理能力。

+   **自然语言理解**：在MMLU基准测试中获得77.3分，反映出竞争力强的自然语言处理能力。

+   **真实性**：在对抗模型生成的幻觉方面表现出改进。

+   **数学推理**：在GSM8K中获得76.5分，非常适合基本数学问题的解决。

**结论：**

Mistral AI发布的Mixtral 8x22B反映了向更加透明和合作的人工智能开发方法的重要趋势。该模型在人工智能社区内引起了极大的兴奋，因其具有突破性的应用和研究潜力，有望全球范围内改变各种技术领域。
